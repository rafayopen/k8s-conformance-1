I0613 09:55:14.183739      22 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-257530218
I0613 09:55:14.184022      22 e2e.go:92] Starting e2e run "b3445254-194a-4018-9d3b-a083d0b2f4f5" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1592042111 - Will randomize all specs
Will run 276 of 4731 specs

Jun 13 09:55:14.196: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 09:55:14.199: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Jun 13 09:55:14.216: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Jun 13 09:55:14.274: INFO: 11 / 11 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Jun 13 09:55:14.274: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Jun 13 09:55:14.274: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Jun 13 09:55:14.287: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'csi-oci-node' (0 seconds elapsed)
Jun 13 09:55:14.287: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-flannel-ds' (0 seconds elapsed)
Jun 13 09:55:14.287: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Jun 13 09:55:14.287: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin' (0 seconds elapsed)
Jun 13 09:55:14.287: INFO: 0 / 0 pods ready in namespace 'kube-system' in daemonset 'nvidia-gpu-device-plugin-1-8' (0 seconds elapsed)
Jun 13 09:55:14.287: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'proxymux-client' (0 seconds elapsed)
Jun 13 09:55:14.287: INFO: e2e test version: v1.16.8
Jun 13 09:55:14.290: INFO: kube-apiserver version: v1.16.8
Jun 13 09:55:14.290: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 09:55:14.299: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 09:55:14.300: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename dns
Jun 13 09:55:14.345: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3857.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-3857.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3857.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-3857.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-3857.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3857.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 13 09:55:18.586: INFO: DNS probes using dns-3857/dns-test-81e434c0-1c93-4f81-b283-1ba8223fc30b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 09:55:18.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3857" for this suite.
Jun 13 09:55:24.621: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 09:55:25.049: INFO: namespace dns-3857 deletion completed in 6.444066446s

• [SLOW TEST:10.749 seconds]
[sig-network] DNS
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 09:55:25.051: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-k68q
STEP: Creating a pod to test atomic-volume-subpath
Jun 13 09:55:25.125: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-k68q" in namespace "subpath-9557" to be "success or failure"
Jun 13 09:55:25.130: INFO: Pod "pod-subpath-test-projected-k68q": Phase="Pending", Reason="", readiness=false. Elapsed: 4.211477ms
Jun 13 09:55:27.134: INFO: Pod "pod-subpath-test-projected-k68q": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008352764s
Jun 13 09:55:29.138: INFO: Pod "pod-subpath-test-projected-k68q": Phase="Running", Reason="", readiness=true. Elapsed: 4.013066966s
Jun 13 09:55:31.143: INFO: Pod "pod-subpath-test-projected-k68q": Phase="Running", Reason="", readiness=true. Elapsed: 6.017395258s
Jun 13 09:55:33.149: INFO: Pod "pod-subpath-test-projected-k68q": Phase="Running", Reason="", readiness=true. Elapsed: 8.02331178s
Jun 13 09:55:35.154: INFO: Pod "pod-subpath-test-projected-k68q": Phase="Running", Reason="", readiness=true. Elapsed: 10.029131283s
Jun 13 09:55:37.160: INFO: Pod "pod-subpath-test-projected-k68q": Phase="Running", Reason="", readiness=true. Elapsed: 12.034536673s
Jun 13 09:55:39.164: INFO: Pod "pod-subpath-test-projected-k68q": Phase="Running", Reason="", readiness=true. Elapsed: 14.039146769s
Jun 13 09:55:41.169: INFO: Pod "pod-subpath-test-projected-k68q": Phase="Running", Reason="", readiness=true. Elapsed: 16.043275773s
Jun 13 09:55:43.173: INFO: Pod "pod-subpath-test-projected-k68q": Phase="Running", Reason="", readiness=true. Elapsed: 18.047832649s
Jun 13 09:55:45.179: INFO: Pod "pod-subpath-test-projected-k68q": Phase="Running", Reason="", readiness=true. Elapsed: 20.053919775s
Jun 13 09:55:47.184: INFO: Pod "pod-subpath-test-projected-k68q": Phase="Running", Reason="", readiness=true. Elapsed: 22.058539154s
Jun 13 09:55:49.189: INFO: Pod "pod-subpath-test-projected-k68q": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.063372494s
STEP: Saw pod success
Jun 13 09:55:49.189: INFO: Pod "pod-subpath-test-projected-k68q" satisfied condition "success or failure"
Jun 13 09:55:49.193: INFO: Trying to get logs from node 10.0.10.2 pod pod-subpath-test-projected-k68q container test-container-subpath-projected-k68q: <nil>
STEP: delete the pod
Jun 13 09:55:49.369: INFO: Waiting for pod pod-subpath-test-projected-k68q to disappear
Jun 13 09:55:49.373: INFO: Pod pod-subpath-test-projected-k68q no longer exists
STEP: Deleting pod pod-subpath-test-projected-k68q
Jun 13 09:55:49.373: INFO: Deleting pod "pod-subpath-test-projected-k68q" in namespace "subpath-9557"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 09:55:49.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9557" for this suite.
Jun 13 09:55:55.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 09:55:55.524: INFO: namespace subpath-9557 deletion completed in 6.142803699s

• [SLOW TEST:30.474 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 09:55:55.525: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-6659
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 13 09:55:55.565: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun 13 09:56:19.649: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.1.114:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6659 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 13 09:56:19.649: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 09:56:19.882: INFO: Found all expected endpoints: [netserver-0]
Jun 13 09:56:19.886: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.0.82:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6659 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 13 09:56:19.886: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 09:56:20.153: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 09:56:20.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6659" for this suite.
Jun 13 09:56:32.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 09:56:32.294: INFO: namespace pod-network-test-6659 deletion completed in 12.135400101s

• [SLOW TEST:36.769 seconds]
[sig-network] Networking
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 09:56:32.297: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-a001d449-ece4-4288-9dfa-76eee3e7e850
STEP: Creating a pod to test consume configMaps
Jun 13 09:56:32.355: INFO: Waiting up to 5m0s for pod "pod-configmaps-8b4382c2-52ba-4628-a357-4040b13495cd" in namespace "configmap-3525" to be "success or failure"
Jun 13 09:56:32.359: INFO: Pod "pod-configmaps-8b4382c2-52ba-4628-a357-4040b13495cd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.24719ms
Jun 13 09:56:34.364: INFO: Pod "pod-configmaps-8b4382c2-52ba-4628-a357-4040b13495cd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009228238s
Jun 13 09:56:36.369: INFO: Pod "pod-configmaps-8b4382c2-52ba-4628-a357-4040b13495cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014018591s
STEP: Saw pod success
Jun 13 09:56:36.369: INFO: Pod "pod-configmaps-8b4382c2-52ba-4628-a357-4040b13495cd" satisfied condition "success or failure"
Jun 13 09:56:36.373: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-8b4382c2-52ba-4628-a357-4040b13495cd container configmap-volume-test: <nil>
STEP: delete the pod
Jun 13 09:56:36.398: INFO: Waiting for pod pod-configmaps-8b4382c2-52ba-4628-a357-4040b13495cd to disappear
Jun 13 09:56:36.402: INFO: Pod pod-configmaps-8b4382c2-52ba-4628-a357-4040b13495cd no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 09:56:36.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3525" for this suite.
Jun 13 09:56:42.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 09:56:42.551: INFO: namespace configmap-3525 deletion completed in 6.144027946s

• [SLOW TEST:10.254 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 09:56:42.551: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Jun 13 09:56:42.607: INFO: Waiting up to 5m0s for pod "pod-9365b061-ea2e-4888-9116-9c7719b12661" in namespace "emptydir-4089" to be "success or failure"
Jun 13 09:56:42.613: INFO: Pod "pod-9365b061-ea2e-4888-9116-9c7719b12661": Phase="Pending", Reason="", readiness=false. Elapsed: 5.927409ms
Jun 13 09:56:44.619: INFO: Pod "pod-9365b061-ea2e-4888-9116-9c7719b12661": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011373398s
Jun 13 09:56:46.624: INFO: Pod "pod-9365b061-ea2e-4888-9116-9c7719b12661": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016254964s
STEP: Saw pod success
Jun 13 09:56:46.624: INFO: Pod "pod-9365b061-ea2e-4888-9116-9c7719b12661" satisfied condition "success or failure"
Jun 13 09:56:46.627: INFO: Trying to get logs from node 10.0.10.2 pod pod-9365b061-ea2e-4888-9116-9c7719b12661 container test-container: <nil>
STEP: delete the pod
Jun 13 09:56:46.653: INFO: Waiting for pod pod-9365b061-ea2e-4888-9116-9c7719b12661 to disappear
Jun 13 09:56:46.657: INFO: Pod pod-9365b061-ea2e-4888-9116-9c7719b12661 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 09:56:46.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4089" for this suite.
Jun 13 09:56:52.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 09:56:52.798: INFO: namespace emptydir-4089 deletion completed in 6.136837878s

• [SLOW TEST:10.247 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 09:56:52.799: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Jun 13 09:56:52.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-5422'
Jun 13 09:56:53.049: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun 13 09:56:53.049: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Jun 13 09:56:55.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 delete deployment e2e-test-httpd-deployment --namespace=kubectl-5422'
Jun 13 09:56:55.166: INFO: stderr: ""
Jun 13 09:56:55.166: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 09:56:55.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5422" for this suite.
Jun 13 09:57:01.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 09:57:01.305: INFO: namespace kubectl-5422 deletion completed in 6.133676825s

• [SLOW TEST:8.506 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 09:57:01.306: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3227.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3227.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3227.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3227.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 13 09:57:05.460: INFO: DNS probes using dns-test-a97648eb-ace7-47b0-97d0-3a17db5e0a50 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3227.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-3227.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3227.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-3227.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 13 09:57:09.654: INFO: DNS probes using dns-test-7f77e821-3c0c-46d0-aef3-91e7906f452b succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3227.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-3227.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-3227.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-3227.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 13 09:57:13.796: INFO: DNS probes using dns-test-09500331-0b77-4a3e-9395-8e27df9aff87 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 09:57:13.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3227" for this suite.
Jun 13 09:57:19.848: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 09:57:19.979: INFO: namespace dns-3227 deletion completed in 6.148155684s

• [SLOW TEST:18.674 seconds]
[sig-network] DNS
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 09:57:19.979: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Jun 13 09:57:20.022: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 create -f - --namespace=kubectl-7701'
Jun 13 09:57:20.272: INFO: stderr: ""
Jun 13 09:57:20.272: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 13 09:57:20.273: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7701'
Jun 13 09:57:20.398: INFO: stderr: ""
Jun 13 09:57:20.398: INFO: stdout: "update-demo-nautilus-5h5g8 update-demo-nautilus-5srp6 "
Jun 13 09:57:20.398: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-5h5g8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7701'
Jun 13 09:57:20.509: INFO: stderr: ""
Jun 13 09:57:20.509: INFO: stdout: ""
Jun 13 09:57:20.509: INFO: update-demo-nautilus-5h5g8 is created but not running
Jun 13 09:57:25.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7701'
Jun 13 09:57:25.598: INFO: stderr: ""
Jun 13 09:57:25.598: INFO: stdout: "update-demo-nautilus-5h5g8 update-demo-nautilus-5srp6 "
Jun 13 09:57:25.598: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-5h5g8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7701'
Jun 13 09:57:25.683: INFO: stderr: ""
Jun 13 09:57:25.683: INFO: stdout: "true"
Jun 13 09:57:25.684: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-5h5g8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7701'
Jun 13 09:57:25.769: INFO: stderr: ""
Jun 13 09:57:25.769: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 13 09:57:25.769: INFO: validating pod update-demo-nautilus-5h5g8
Jun 13 09:57:25.947: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 13 09:57:25.947: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 13 09:57:25.947: INFO: update-demo-nautilus-5h5g8 is verified up and running
Jun 13 09:57:25.947: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-5srp6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7701'
Jun 13 09:57:26.034: INFO: stderr: ""
Jun 13 09:57:26.034: INFO: stdout: "true"
Jun 13 09:57:26.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-5srp6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7701'
Jun 13 09:57:26.119: INFO: stderr: ""
Jun 13 09:57:26.119: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 13 09:57:26.119: INFO: validating pod update-demo-nautilus-5srp6
Jun 13 09:57:26.190: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 13 09:57:26.190: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 13 09:57:26.190: INFO: update-demo-nautilus-5srp6 is verified up and running
STEP: scaling down the replication controller
Jun 13 09:57:26.192: INFO: scanned /root for discovery docs: <nil>
Jun 13 09:57:26.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-7701'
Jun 13 09:57:27.390: INFO: stderr: ""
Jun 13 09:57:27.390: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 13 09:57:27.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7701'
Jun 13 09:57:27.512: INFO: stderr: ""
Jun 13 09:57:27.512: INFO: stdout: "update-demo-nautilus-5h5g8 update-demo-nautilus-5srp6 "
STEP: Replicas for name=update-demo: expected=1 actual=2
Jun 13 09:57:32.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7701'
Jun 13 09:57:32.601: INFO: stderr: ""
Jun 13 09:57:32.601: INFO: stdout: "update-demo-nautilus-5h5g8 "
Jun 13 09:57:32.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-5h5g8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7701'
Jun 13 09:57:32.683: INFO: stderr: ""
Jun 13 09:57:32.683: INFO: stdout: "true"
Jun 13 09:57:32.683: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-5h5g8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7701'
Jun 13 09:57:32.775: INFO: stderr: ""
Jun 13 09:57:32.775: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 13 09:57:32.775: INFO: validating pod update-demo-nautilus-5h5g8
Jun 13 09:57:32.781: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 13 09:57:32.782: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 13 09:57:32.782: INFO: update-demo-nautilus-5h5g8 is verified up and running
STEP: scaling up the replication controller
Jun 13 09:57:32.784: INFO: scanned /root for discovery docs: <nil>
Jun 13 09:57:32.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-7701'
Jun 13 09:57:33.902: INFO: stderr: ""
Jun 13 09:57:33.903: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 13 09:57:33.903: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7701'
Jun 13 09:57:33.995: INFO: stderr: ""
Jun 13 09:57:33.995: INFO: stdout: "update-demo-nautilus-5h5g8 update-demo-nautilus-8d5jc "
Jun 13 09:57:33.995: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-5h5g8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7701'
Jun 13 09:57:34.081: INFO: stderr: ""
Jun 13 09:57:34.081: INFO: stdout: "true"
Jun 13 09:57:34.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-5h5g8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7701'
Jun 13 09:57:34.163: INFO: stderr: ""
Jun 13 09:57:34.164: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 13 09:57:34.164: INFO: validating pod update-demo-nautilus-5h5g8
Jun 13 09:57:34.170: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 13 09:57:34.170: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 13 09:57:34.170: INFO: update-demo-nautilus-5h5g8 is verified up and running
Jun 13 09:57:34.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-8d5jc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7701'
Jun 13 09:57:34.256: INFO: stderr: ""
Jun 13 09:57:34.256: INFO: stdout: ""
Jun 13 09:57:34.256: INFO: update-demo-nautilus-8d5jc is created but not running
Jun 13 09:57:39.256: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-7701'
Jun 13 09:57:39.346: INFO: stderr: ""
Jun 13 09:57:39.346: INFO: stdout: "update-demo-nautilus-5h5g8 update-demo-nautilus-8d5jc "
Jun 13 09:57:39.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-5h5g8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7701'
Jun 13 09:57:39.431: INFO: stderr: ""
Jun 13 09:57:39.431: INFO: stdout: "true"
Jun 13 09:57:39.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-5h5g8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7701'
Jun 13 09:57:39.552: INFO: stderr: ""
Jun 13 09:57:39.552: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 13 09:57:39.552: INFO: validating pod update-demo-nautilus-5h5g8
Jun 13 09:57:39.559: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 13 09:57:39.559: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 13 09:57:39.559: INFO: update-demo-nautilus-5h5g8 is verified up and running
Jun 13 09:57:39.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-8d5jc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7701'
Jun 13 09:57:39.658: INFO: stderr: ""
Jun 13 09:57:39.658: INFO: stdout: "true"
Jun 13 09:57:39.658: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-8d5jc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7701'
Jun 13 09:57:39.742: INFO: stderr: ""
Jun 13 09:57:39.742: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 13 09:57:39.742: INFO: validating pod update-demo-nautilus-8d5jc
Jun 13 09:57:39.828: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 13 09:57:39.828: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 13 09:57:39.828: INFO: update-demo-nautilus-8d5jc is verified up and running
STEP: using delete to clean up resources
Jun 13 09:57:39.828: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 delete --grace-period=0 --force -f - --namespace=kubectl-7701'
Jun 13 09:57:39.920: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 13 09:57:39.920: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jun 13 09:57:39.920: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7701'
Jun 13 09:57:40.013: INFO: stderr: "No resources found in kubectl-7701 namespace.\n"
Jun 13 09:57:40.013: INFO: stdout: ""
Jun 13 09:57:40.013: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods -l name=update-demo --namespace=kubectl-7701 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 13 09:57:40.101: INFO: stderr: ""
Jun 13 09:57:40.101: INFO: stdout: "update-demo-nautilus-5h5g8\nupdate-demo-nautilus-8d5jc\n"
Jun 13 09:57:40.601: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-7701'
Jun 13 09:57:40.721: INFO: stderr: "No resources found in kubectl-7701 namespace.\n"
Jun 13 09:57:40.721: INFO: stdout: ""
Jun 13 09:57:40.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods -l name=update-demo --namespace=kubectl-7701 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 13 09:57:40.836: INFO: stderr: ""
Jun 13 09:57:40.836: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 09:57:40.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7701" for this suite.
Jun 13 09:57:46.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 09:57:46.981: INFO: namespace kubectl-7701 deletion completed in 6.139840832s

• [SLOW TEST:27.002 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 09:57:46.982: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jun 13 09:57:51.094: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 13 09:57:51.100: INFO: Pod pod-with-poststart-http-hook still exists
Jun 13 09:57:53.100: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 13 09:57:53.105: INFO: Pod pod-with-poststart-http-hook still exists
Jun 13 09:57:55.100: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Jun 13 09:57:55.105: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 09:57:55.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9126" for this suite.
Jun 13 09:58:07.128: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 09:58:07.249: INFO: namespace container-lifecycle-hook-9126 deletion completed in 12.138469612s

• [SLOW TEST:20.267 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 09:58:07.249: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Jun 13 09:58:07.302: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f7d343d0-1c80-4d5b-9783-afc18a87e867" in namespace "projected-1089" to be "success or failure"
Jun 13 09:58:07.306: INFO: Pod "downwardapi-volume-f7d343d0-1c80-4d5b-9783-afc18a87e867": Phase="Pending", Reason="", readiness=false. Elapsed: 4.35611ms
Jun 13 09:58:09.311: INFO: Pod "downwardapi-volume-f7d343d0-1c80-4d5b-9783-afc18a87e867": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00956353s
Jun 13 09:58:11.316: INFO: Pod "downwardapi-volume-f7d343d0-1c80-4d5b-9783-afc18a87e867": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014386386s
STEP: Saw pod success
Jun 13 09:58:11.316: INFO: Pod "downwardapi-volume-f7d343d0-1c80-4d5b-9783-afc18a87e867" satisfied condition "success or failure"
Jun 13 09:58:11.320: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-f7d343d0-1c80-4d5b-9783-afc18a87e867 container client-container: <nil>
STEP: delete the pod
Jun 13 09:58:11.360: INFO: Waiting for pod downwardapi-volume-f7d343d0-1c80-4d5b-9783-afc18a87e867 to disappear
Jun 13 09:58:11.364: INFO: Pod downwardapi-volume-f7d343d0-1c80-4d5b-9783-afc18a87e867 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 09:58:11.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1089" for this suite.
Jun 13 09:58:17.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 09:58:17.504: INFO: namespace projected-1089 deletion completed in 6.135119638s

• [SLOW TEST:10.255 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 09:58:17.505: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Jun 13 09:58:17.550: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 09:58:34.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5358" for this suite.
Jun 13 09:58:40.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 09:58:40.527: INFO: namespace pods-5358 deletion completed in 6.143219452s

• [SLOW TEST:23.022 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 09:58:40.528: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 09:58:40.567: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Jun 13 09:58:43.075: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 --namespace=crd-publish-openapi-2692 create -f -'
Jun 13 09:58:43.663: INFO: stderr: ""
Jun 13 09:58:43.663: INFO: stdout: "e2e-test-crd-publish-openapi-542-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Jun 13 09:58:43.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 --namespace=crd-publish-openapi-2692 delete e2e-test-crd-publish-openapi-542-crds test-cr'
Jun 13 09:58:43.763: INFO: stderr: ""
Jun 13 09:58:43.763: INFO: stdout: "e2e-test-crd-publish-openapi-542-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Jun 13 09:58:43.763: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 --namespace=crd-publish-openapi-2692 apply -f -'
Jun 13 09:58:44.079: INFO: stderr: ""
Jun 13 09:58:44.079: INFO: stdout: "e2e-test-crd-publish-openapi-542-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Jun 13 09:58:44.079: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 --namespace=crd-publish-openapi-2692 delete e2e-test-crd-publish-openapi-542-crds test-cr'
Jun 13 09:58:44.177: INFO: stderr: ""
Jun 13 09:58:44.177: INFO: stdout: "e2e-test-crd-publish-openapi-542-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Jun 13 09:58:44.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 explain e2e-test-crd-publish-openapi-542-crds'
Jun 13 09:58:44.417: INFO: stderr: ""
Jun 13 09:58:44.417: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-542-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 09:58:47.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2692" for this suite.
Jun 13 09:58:53.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 09:58:53.496: INFO: namespace crd-publish-openapi-2692 deletion completed in 6.138846681s

• [SLOW TEST:12.969 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 09:58:53.497: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Jun 13 09:58:53.955: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Jun 13 09:58:55.970: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639133, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639133, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639133, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639133, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 13 09:58:58.988: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 09:58:58.993: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 09:59:00.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-7547" for this suite.
Jun 13 09:59:06.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 09:59:06.585: INFO: namespace crd-webhook-7547 deletion completed in 6.138365796s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:13.114 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 09:59:06.611: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-5107/secret-test-d15aaf3f-bb13-4516-9d93-130678f72d63
STEP: Creating a pod to test consume secrets
Jun 13 09:59:06.668: INFO: Waiting up to 5m0s for pod "pod-configmaps-8b9b6e44-522f-47b2-8a88-325245e9c53e" in namespace "secrets-5107" to be "success or failure"
Jun 13 09:59:06.672: INFO: Pod "pod-configmaps-8b9b6e44-522f-47b2-8a88-325245e9c53e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.999913ms
Jun 13 09:59:08.675: INFO: Pod "pod-configmaps-8b9b6e44-522f-47b2-8a88-325245e9c53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007550937s
STEP: Saw pod success
Jun 13 09:59:08.675: INFO: Pod "pod-configmaps-8b9b6e44-522f-47b2-8a88-325245e9c53e" satisfied condition "success or failure"
Jun 13 09:59:08.679: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-8b9b6e44-522f-47b2-8a88-325245e9c53e container env-test: <nil>
STEP: delete the pod
Jun 13 09:59:08.858: INFO: Waiting for pod pod-configmaps-8b9b6e44-522f-47b2-8a88-325245e9c53e to disappear
Jun 13 09:59:08.867: INFO: Pod pod-configmaps-8b9b6e44-522f-47b2-8a88-325245e9c53e no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 09:59:08.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5107" for this suite.
Jun 13 09:59:14.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 09:59:15.007: INFO: namespace secrets-5107 deletion completed in 6.135178584s

• [SLOW TEST:8.396 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 09:59:15.009: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 13 09:59:15.578: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jun 13 09:59:17.591: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639155, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639155, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639155, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639155, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 13 09:59:20.609: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 09:59:20.614: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 09:59:21.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5274" for this suite.
Jun 13 09:59:27.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 09:59:28.009: INFO: namespace webhook-5274 deletion completed in 6.136492981s
STEP: Destroying namespace "webhook-5274-markers" for this suite.
Jun 13 09:59:34.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 09:59:34.141: INFO: namespace webhook-5274-markers deletion completed in 6.132023101s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.155 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 09:59:34.165: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Jun 13 09:59:34.218: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1975eab6-c27b-4d92-8e3f-6300d4c8e1b0" in namespace "projected-1058" to be "success or failure"
Jun 13 09:59:34.223: INFO: Pod "downwardapi-volume-1975eab6-c27b-4d92-8e3f-6300d4c8e1b0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.766836ms
Jun 13 09:59:36.229: INFO: Pod "downwardapi-volume-1975eab6-c27b-4d92-8e3f-6300d4c8e1b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009987733s
STEP: Saw pod success
Jun 13 09:59:36.229: INFO: Pod "downwardapi-volume-1975eab6-c27b-4d92-8e3f-6300d4c8e1b0" satisfied condition "success or failure"
Jun 13 09:59:36.233: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-1975eab6-c27b-4d92-8e3f-6300d4c8e1b0 container client-container: <nil>
STEP: delete the pod
Jun 13 09:59:36.258: INFO: Waiting for pod downwardapi-volume-1975eab6-c27b-4d92-8e3f-6300d4c8e1b0 to disappear
Jun 13 09:59:36.261: INFO: Pod downwardapi-volume-1975eab6-c27b-4d92-8e3f-6300d4c8e1b0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 09:59:36.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1058" for this suite.
Jun 13 09:59:42.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 09:59:42.404: INFO: namespace projected-1058 deletion completed in 6.139220953s

• [SLOW TEST:8.239 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 09:59:42.405: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 09:59:42.443: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 09:59:42.988: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8637" for this suite.
Jun 13 09:59:49.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 09:59:49.128: INFO: namespace custom-resource-definition-8637 deletion completed in 6.135849178s

• [SLOW TEST:6.724 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 09:59:49.129: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 09:59:49.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 create -f - --namespace=kubectl-8719'
Jun 13 09:59:49.450: INFO: stderr: ""
Jun 13 09:59:49.450: INFO: stdout: "replicationcontroller/redis-master created\n"
Jun 13 09:59:49.450: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 create -f - --namespace=kubectl-8719'
Jun 13 09:59:49.686: INFO: stderr: ""
Jun 13 09:59:49.686: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Jun 13 09:59:50.692: INFO: Selector matched 1 pods for map[app:redis]
Jun 13 09:59:50.692: INFO: Found 0 / 1
Jun 13 09:59:51.691: INFO: Selector matched 1 pods for map[app:redis]
Jun 13 09:59:51.691: INFO: Found 1 / 1
Jun 13 09:59:51.691: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jun 13 09:59:51.694: INFO: Selector matched 1 pods for map[app:redis]
Jun 13 09:59:51.694: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jun 13 09:59:51.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 describe pod redis-master-jk4ml --namespace=kubectl-8719'
Jun 13 09:59:51.802: INFO: stderr: ""
Jun 13 09:59:51.802: INFO: stdout: "Name:         redis-master-jk4ml\nNamespace:    kubectl-8719\nPriority:     0\nNode:         10.0.10.2/10.0.10.2\nStart Time:   Sat, 13 Jun 2020 09:59:49 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nStatus:       Running\nIP:           10.244.1.132\nIPs:\n  IP:           10.244.1.132\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://ec023a48b0871e1087d61a1c2471bbb88b7ec35481ca1836e6e84aceed1adab3\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Sat, 13 Jun 2020 09:59:50 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-scnxt (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-scnxt:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-scnxt\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age   From                Message\n  ----    ------     ----  ----                -------\n  Normal  Scheduled  2s    default-scheduler   Successfully assigned kubectl-8719/redis-master-jk4ml to 10.0.10.2\n  Normal  Pulled     1s    kubelet, 10.0.10.2  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    1s    kubelet, 10.0.10.2  Created container redis-master\n  Normal  Started    1s    kubelet, 10.0.10.2  Started container redis-master\n"
Jun 13 09:59:51.802: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 describe rc redis-master --namespace=kubectl-8719'
Jun 13 09:59:51.923: INFO: stderr: ""
Jun 13 09:59:51.923: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-8719\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-jk4ml\n"
Jun 13 09:59:51.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 describe service redis-master --namespace=kubectl-8719'
Jun 13 09:59:52.029: INFO: stderr: ""
Jun 13 09:59:52.029: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-8719\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.96.45.165\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.1.132:6379\nSession Affinity:  None\nEvents:            <none>\n"
Jun 13 09:59:52.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 describe node 10.0.10.2'
Jun 13 09:59:52.155: INFO: stderr: ""
Jun 13 09:59:52.155: INFO: stdout: "Name:               10.0.10.2\nRoles:              node\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=VM.Standard2.1\n                    beta.kubernetes.io/os=linux\n                    displayName=oke-c3dgmtcmu4t-nztonbtmm3d-shi3ttux4va-1\n                    failure-domain.beta.kubernetes.io/region=ca-montreal-1\n                    failure-domain.beta.kubernetes.io/zone=CA-MONTREAL-1-AD-1\n                    hostname=oke-c3dgmtcmu4t-nztonbtmm3d-shi3ttux4va-1\n                    internal_addr=10.0.10.2\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.0.10.2\n                    kubernetes.io/os=linux\n                    name=pool1\n                    node-role.kubernetes.io/node=\n                    node.info.ds_proxymux_client=true\n                    node.info/compartment.id_prefix=ocid1.compartment.oc1\n                    node.info/compartment.id_suffix=aaaaaaaarm6fbxyjwnhwsb574wk6uc7qco3lfsx5kszlx5c77tvyb3mov2ga\n                    node.info/compartment.name=deployment-verification\n                    node.info/kubeletVersion=v1.16\n                    oke.oraclecloud.com/node.info.private_subnet=false\n                    oke.oraclecloud.com/node.info.private_worker=true\n                    oke.oraclecloud.com/tenant_agent.version=1.25.4-9a221fa-217\nAnnotations:        alpha.kubernetes.io/provided-node-ip: 10.0.10.2\n                    csi.volume.kubernetes.io/nodeid: {\"blockvolume.csi.oraclecloud.com\":\"10.0.10.2\"}\n                    flannel.alpha.coreos.com/backend-data: {\"VtepMAC\":\"ee:0a:6c:dd:d6:c3\"}\n                    flannel.alpha.coreos.com/backend-type: vxlan\n                    flannel.alpha.coreos.com/kube-subnet-manager: true\n                    flannel.alpha.coreos.com/public-ip: 10.0.10.2\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Sat, 13 Jun 2020 03:16:34 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Sat, 13 Jun 2020 09:58:57 +0000   Sat, 13 Jun 2020 03:16:34 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Sat, 13 Jun 2020 09:58:57 +0000   Sat, 13 Jun 2020 03:16:34 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Sat, 13 Jun 2020 09:58:57 +0000   Sat, 13 Jun 2020 03:16:34 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Sat, 13 Jun 2020 09:58:57 +0000   Sat, 13 Jun 2020 03:16:54 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  10.0.10.2\n  ExternalIP:  168.138.67.181\n  Hostname:    10.0.10.2\nCapacity:\n cpu:                2\n ephemeral-storage:  40223552Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             15116056Ki\n pods:               110\nAllocatable:\n cpu:                2\n ephemeral-storage:  37070025462\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             15013656Ki\n pods:               110\nSystem Info:\n Machine ID:                 1081f750f6f14129b7d61f244e140fc0\n System UUID:                D70FD84A-EC82-42D9-8335-2523E252A148\n Boot ID:                    cc4c054a-b2ef-4af6-84e2-2322dd646f92\n Kernel Version:             4.14.35-1902.303.4.1.el7uek.x86_64\n OS Image:                   Oracle Linux Server 7.8\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.8\n Kubelet Version:            v1.16.8\n Kube-Proxy Version:         v1.16.8\nPodCIDR:                     10.244.1.0/24\nPodCIDRs:                    10.244.1.0/24\nProviderID:                  ocid1.instance.oc1.ca-montreal-1.an4xkljrh4gjgpyc7rzyty27c5zpjhotlcvmaqdnb5pkrcs3oek4aowocr7q\nNon-terminated Pods:         (7 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                coredns-6f9ff9bd47-ctdhp                                   100m (5%)     0 (0%)      70Mi (0%)        170Mi (1%)     6h48m\n  kube-system                csi-oci-node-4dfqn                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         6h42m\n  kube-system                kube-flannel-ds-mddmt                                      100m (5%)     1 (50%)     50Mi (0%)        500Mi (3%)     6h43m\n  kube-system                kube-proxy-mbpxz                                           0 (0%)        0 (0%)      0 (0%)           0 (0%)         6h43m\n  kube-system                proxymux-client-hhdsr                                      50m (2%)      500m (25%)  64Mi (0%)        256Mi (1%)     6h42m\n  kubectl-8719               redis-master-jk4ml                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         3s\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-89d5b422bcff4ee4-jptvl    0 (0%)        0 (0%)      0 (0%)           0 (0%)         4m45s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                250m (12%)  1500m (75%)\n  memory             184Mi (1%)  926Mi (6%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:              <none>\n"
Jun 13 09:59:52.155: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 describe namespace kubectl-8719'
Jun 13 09:59:52.254: INFO: stderr: ""
Jun 13 09:59:52.254: INFO: stdout: "Name:         kubectl-8719\nLabels:       e2e-framework=kubectl\n              e2e-run=b3445254-194a-4018-9d3b-a083d0b2f4f5\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 09:59:52.254: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8719" for this suite.
Jun 13 10:00:10.274: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:00:10.408: INFO: namespace kubectl-8719 deletion completed in 18.148598644s

• [SLOW TEST:21.279 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:00:10.411: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-97497ff9-08d4-4c1e-8433-73f02afe6bc0
STEP: Creating a pod to test consume secrets
Jun 13 10:00:10.479: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e02f63c9-ec48-4e64-bc3c-e1d7a515c75b" in namespace "projected-1892" to be "success or failure"
Jun 13 10:00:10.484: INFO: Pod "pod-projected-secrets-e02f63c9-ec48-4e64-bc3c-e1d7a515c75b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.436541ms
Jun 13 10:00:12.489: INFO: Pod "pod-projected-secrets-e02f63c9-ec48-4e64-bc3c-e1d7a515c75b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009627562s
Jun 13 10:00:14.494: INFO: Pod "pod-projected-secrets-e02f63c9-ec48-4e64-bc3c-e1d7a515c75b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014635538s
STEP: Saw pod success
Jun 13 10:00:14.494: INFO: Pod "pod-projected-secrets-e02f63c9-ec48-4e64-bc3c-e1d7a515c75b" satisfied condition "success or failure"
Jun 13 10:00:14.498: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-secrets-e02f63c9-ec48-4e64-bc3c-e1d7a515c75b container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 13 10:00:14.524: INFO: Waiting for pod pod-projected-secrets-e02f63c9-ec48-4e64-bc3c-e1d7a515c75b to disappear
Jun 13 10:00:14.528: INFO: Pod pod-projected-secrets-e02f63c9-ec48-4e64-bc3c-e1d7a515c75b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:00:14.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1892" for this suite.
Jun 13 10:00:20.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:00:20.672: INFO: namespace projected-1892 deletion completed in 6.139114506s

• [SLOW TEST:10.261 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:00:20.675: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Jun 13 10:00:20.722: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6582 /api/v1/namespaces/watch-6582/configmaps/e2e-watch-test-configmap-a 7cd8425b-2653-4aa8-a90c-623779a831c7 88252 0 2020-06-13 10:00:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 13 10:00:20.723: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6582 /api/v1/namespaces/watch-6582/configmaps/e2e-watch-test-configmap-a 7cd8425b-2653-4aa8-a90c-623779a831c7 88252 0 2020-06-13 10:00:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Jun 13 10:00:30.734: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6582 /api/v1/namespaces/watch-6582/configmaps/e2e-watch-test-configmap-a 7cd8425b-2653-4aa8-a90c-623779a831c7 88282 0 2020-06-13 10:00:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jun 13 10:00:30.734: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6582 /api/v1/namespaces/watch-6582/configmaps/e2e-watch-test-configmap-a 7cd8425b-2653-4aa8-a90c-623779a831c7 88282 0 2020-06-13 10:00:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Jun 13 10:00:40.745: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6582 /api/v1/namespaces/watch-6582/configmaps/e2e-watch-test-configmap-a 7cd8425b-2653-4aa8-a90c-623779a831c7 88312 0 2020-06-13 10:00:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 13 10:00:40.745: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6582 /api/v1/namespaces/watch-6582/configmaps/e2e-watch-test-configmap-a 7cd8425b-2653-4aa8-a90c-623779a831c7 88312 0 2020-06-13 10:00:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Jun 13 10:00:50.755: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6582 /api/v1/namespaces/watch-6582/configmaps/e2e-watch-test-configmap-a 7cd8425b-2653-4aa8-a90c-623779a831c7 88342 0 2020-06-13 10:00:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 13 10:00:50.756: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-6582 /api/v1/namespaces/watch-6582/configmaps/e2e-watch-test-configmap-a 7cd8425b-2653-4aa8-a90c-623779a831c7 88342 0 2020-06-13 10:00:20 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Jun 13 10:01:00.766: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6582 /api/v1/namespaces/watch-6582/configmaps/e2e-watch-test-configmap-b 6b55cba3-e748-4e1b-8320-1c749117488a 88374 0 2020-06-13 10:01:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 13 10:01:00.766: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6582 /api/v1/namespaces/watch-6582/configmaps/e2e-watch-test-configmap-b 6b55cba3-e748-4e1b-8320-1c749117488a 88374 0 2020-06-13 10:01:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Jun 13 10:01:10.776: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6582 /api/v1/namespaces/watch-6582/configmaps/e2e-watch-test-configmap-b 6b55cba3-e748-4e1b-8320-1c749117488a 88403 0 2020-06-13 10:01:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 13 10:01:10.776: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-6582 /api/v1/namespaces/watch-6582/configmaps/e2e-watch-test-configmap-b 6b55cba3-e748-4e1b-8320-1c749117488a 88403 0 2020-06-13 10:01:00 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:01:20.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6582" for this suite.
Jun 13 10:01:26.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:01:26.921: INFO: namespace watch-6582 deletion completed in 6.13921651s

• [SLOW TEST:66.246 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:01:26.922: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4692.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-4692.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4692.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4692.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-4692.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4692.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 13 10:01:31.185: INFO: DNS probes using dns-4692/dns-test-2c77db45-3527-462c-a435-b871c023ef1c succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:01:31.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4692" for this suite.
Jun 13 10:01:37.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:01:37.355: INFO: namespace dns-4692 deletion completed in 6.132431022s

• [SLOW TEST:10.433 seconds]
[sig-network] DNS
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:01:37.355: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:01:42.413: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2280" for this suite.
Jun 13 10:01:48.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:01:48.692: INFO: namespace watch-2280 deletion completed in 6.229801976s

• [SLOW TEST:11.337 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:01:48.693: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-4569fa45-c507-49cf-9648-68922bf7d1e5
STEP: Creating a pod to test consume secrets
Jun 13 10:01:48.748: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b433c148-2443-4c7b-b003-8069e5927421" in namespace "projected-4539" to be "success or failure"
Jun 13 10:01:48.752: INFO: Pod "pod-projected-secrets-b433c148-2443-4c7b-b003-8069e5927421": Phase="Pending", Reason="", readiness=false. Elapsed: 3.740196ms
Jun 13 10:01:50.757: INFO: Pod "pod-projected-secrets-b433c148-2443-4c7b-b003-8069e5927421": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008828308s
Jun 13 10:01:52.762: INFO: Pod "pod-projected-secrets-b433c148-2443-4c7b-b003-8069e5927421": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013461767s
STEP: Saw pod success
Jun 13 10:01:52.762: INFO: Pod "pod-projected-secrets-b433c148-2443-4c7b-b003-8069e5927421" satisfied condition "success or failure"
Jun 13 10:01:52.766: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-secrets-b433c148-2443-4c7b-b003-8069e5927421 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 13 10:01:52.974: INFO: Waiting for pod pod-projected-secrets-b433c148-2443-4c7b-b003-8069e5927421 to disappear
Jun 13 10:01:52.978: INFO: Pod pod-projected-secrets-b433c148-2443-4c7b-b003-8069e5927421 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:01:52.979: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4539" for this suite.
Jun 13 10:01:58.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:01:59.118: INFO: namespace projected-4539 deletion completed in 6.135095341s

• [SLOW TEST:10.425 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:01:59.119: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:01:59.181: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3680" for this suite.
Jun 13 10:02:05.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:02:05.322: INFO: namespace kubelet-test-3680 deletion completed in 6.136231466s

• [SLOW TEST:6.203 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:02:05.323: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Jun 13 10:02:05.361: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:02:08.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2574" for this suite.
Jun 13 10:02:14.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:02:14.483: INFO: namespace init-container-2574 deletion completed in 6.137732757s

• [SLOW TEST:9.161 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:02:14.484: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Jun 13 10:02:14.531: INFO: Waiting up to 5m0s for pod "pod-3dee17f0-5189-46d8-9285-7f5b696ac239" in namespace "emptydir-8758" to be "success or failure"
Jun 13 10:02:14.535: INFO: Pod "pod-3dee17f0-5189-46d8-9285-7f5b696ac239": Phase="Pending", Reason="", readiness=false. Elapsed: 3.885238ms
Jun 13 10:02:16.540: INFO: Pod "pod-3dee17f0-5189-46d8-9285-7f5b696ac239": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008722273s
Jun 13 10:02:18.548: INFO: Pod "pod-3dee17f0-5189-46d8-9285-7f5b696ac239": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016710626s
STEP: Saw pod success
Jun 13 10:02:18.548: INFO: Pod "pod-3dee17f0-5189-46d8-9285-7f5b696ac239" satisfied condition "success or failure"
Jun 13 10:02:18.552: INFO: Trying to get logs from node 10.0.10.2 pod pod-3dee17f0-5189-46d8-9285-7f5b696ac239 container test-container: <nil>
STEP: delete the pod
Jun 13 10:02:18.576: INFO: Waiting for pod pod-3dee17f0-5189-46d8-9285-7f5b696ac239 to disappear
Jun 13 10:02:18.582: INFO: Pod pod-3dee17f0-5189-46d8-9285-7f5b696ac239 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:02:18.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8758" for this suite.
Jun 13 10:02:24.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:02:24.723: INFO: namespace emptydir-8758 deletion completed in 6.135023748s

• [SLOW TEST:10.239 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:02:24.724: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Jun 13 10:02:24.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 api-versions'
Jun 13 10:02:24.844: INFO: stderr: ""
Jun 13 10:02:24.844: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:02:24.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7959" for this suite.
Jun 13 10:02:30.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:02:30.993: INFO: namespace kubectl-7959 deletion completed in 6.144149901s

• [SLOW TEST:6.269 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:02:30.993: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 10:02:31.037: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Jun 13 10:02:34.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 --namespace=crd-publish-openapi-3173 create -f -'
Jun 13 10:02:34.655: INFO: stderr: ""
Jun 13 10:02:34.655: INFO: stdout: "e2e-test-crd-publish-openapi-235-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Jun 13 10:02:34.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 --namespace=crd-publish-openapi-3173 delete e2e-test-crd-publish-openapi-235-crds test-foo'
Jun 13 10:02:34.752: INFO: stderr: ""
Jun 13 10:02:34.752: INFO: stdout: "e2e-test-crd-publish-openapi-235-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Jun 13 10:02:34.752: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 --namespace=crd-publish-openapi-3173 apply -f -'
Jun 13 10:02:35.225: INFO: stderr: ""
Jun 13 10:02:35.225: INFO: stdout: "e2e-test-crd-publish-openapi-235-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Jun 13 10:02:35.225: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 --namespace=crd-publish-openapi-3173 delete e2e-test-crd-publish-openapi-235-crds test-foo'
Jun 13 10:02:35.407: INFO: stderr: ""
Jun 13 10:02:35.407: INFO: stdout: "e2e-test-crd-publish-openapi-235-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Jun 13 10:02:35.408: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 --namespace=crd-publish-openapi-3173 create -f -'
Jun 13 10:02:35.743: INFO: rc: 1
Jun 13 10:02:35.743: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 --namespace=crd-publish-openapi-3173 apply -f -'
Jun 13 10:02:35.990: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Jun 13 10:02:35.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 --namespace=crd-publish-openapi-3173 create -f -'
Jun 13 10:02:36.178: INFO: rc: 1
Jun 13 10:02:36.179: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 --namespace=crd-publish-openapi-3173 apply -f -'
Jun 13 10:02:36.358: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Jun 13 10:02:36.358: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 explain e2e-test-crd-publish-openapi-235-crds'
Jun 13 10:02:36.552: INFO: stderr: ""
Jun 13 10:02:36.552: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-235-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Jun 13 10:02:36.553: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 explain e2e-test-crd-publish-openapi-235-crds.metadata'
Jun 13 10:02:36.806: INFO: stderr: ""
Jun 13 10:02:36.806: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-235-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Jun 13 10:02:36.807: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 explain e2e-test-crd-publish-openapi-235-crds.spec'
Jun 13 10:02:37.059: INFO: stderr: ""
Jun 13 10:02:37.060: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-235-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Jun 13 10:02:37.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 explain e2e-test-crd-publish-openapi-235-crds.spec.bars'
Jun 13 10:02:37.249: INFO: stderr: ""
Jun 13 10:02:37.249: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-235-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Jun 13 10:02:37.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 explain e2e-test-crd-publish-openapi-235-crds.spec.bars2'
Jun 13 10:02:37.510: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:02:40.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3173" for this suite.
Jun 13 10:02:46.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:02:46.772: INFO: namespace crd-publish-openapi-3173 deletion completed in 6.136297139s

• [SLOW TEST:15.778 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:02:46.772: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-85e47982-4642-4d20-853f-b10e2b9ad410
STEP: Creating a pod to test consume secrets
Jun 13 10:02:46.826: INFO: Waiting up to 5m0s for pod "pod-secrets-eab9a7dc-d363-4d4d-9672-b410c0e1f1a2" in namespace "secrets-9554" to be "success or failure"
Jun 13 10:02:46.830: INFO: Pod "pod-secrets-eab9a7dc-d363-4d4d-9672-b410c0e1f1a2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.072733ms
Jun 13 10:02:48.835: INFO: Pod "pod-secrets-eab9a7dc-d363-4d4d-9672-b410c0e1f1a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008440918s
STEP: Saw pod success
Jun 13 10:02:48.835: INFO: Pod "pod-secrets-eab9a7dc-d363-4d4d-9672-b410c0e1f1a2" satisfied condition "success or failure"
Jun 13 10:02:48.838: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-eab9a7dc-d363-4d4d-9672-b410c0e1f1a2 container secret-volume-test: <nil>
STEP: delete the pod
Jun 13 10:02:48.863: INFO: Waiting for pod pod-secrets-eab9a7dc-d363-4d4d-9672-b410c0e1f1a2 to disappear
Jun 13 10:02:48.867: INFO: Pod pod-secrets-eab9a7dc-d363-4d4d-9672-b410c0e1f1a2 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:02:48.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9554" for this suite.
Jun 13 10:02:54.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:02:55.145: INFO: namespace secrets-9554 deletion completed in 6.27375401s

• [SLOW TEST:8.373 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:02:55.145: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-086bc470-c8e9-40bc-8ff1-2a74fd3e41d4
STEP: Creating secret with name secret-projected-all-test-volume-92b343ca-12da-417a-9739-d5720dc30ceb
STEP: Creating a pod to test Check all projections for projected volume plugin
Jun 13 10:02:55.213: INFO: Waiting up to 5m0s for pod "projected-volume-a9e6ec5d-7b2c-4b7f-b394-ae73b83711a3" in namespace "projected-9580" to be "success or failure"
Jun 13 10:02:55.217: INFO: Pod "projected-volume-a9e6ec5d-7b2c-4b7f-b394-ae73b83711a3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.003099ms
Jun 13 10:02:57.223: INFO: Pod "projected-volume-a9e6ec5d-7b2c-4b7f-b394-ae73b83711a3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009337484s
Jun 13 10:02:59.228: INFO: Pod "projected-volume-a9e6ec5d-7b2c-4b7f-b394-ae73b83711a3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014519968s
STEP: Saw pod success
Jun 13 10:02:59.228: INFO: Pod "projected-volume-a9e6ec5d-7b2c-4b7f-b394-ae73b83711a3" satisfied condition "success or failure"
Jun 13 10:02:59.232: INFO: Trying to get logs from node 10.0.10.2 pod projected-volume-a9e6ec5d-7b2c-4b7f-b394-ae73b83711a3 container projected-all-volume-test: <nil>
STEP: delete the pod
Jun 13 10:02:59.259: INFO: Waiting for pod projected-volume-a9e6ec5d-7b2c-4b7f-b394-ae73b83711a3 to disappear
Jun 13 10:02:59.265: INFO: Pod projected-volume-a9e6ec5d-7b2c-4b7f-b394-ae73b83711a3 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:02:59.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9580" for this suite.
Jun 13 10:03:05.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:03:05.675: INFO: namespace projected-9580 deletion completed in 6.405716526s

• [SLOW TEST:10.530 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:03:05.677: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-6fc009bd-a949-4d0b-a9b7-f605da3ede1b
STEP: Creating a pod to test consume secrets
Jun 13 10:03:05.733: INFO: Waiting up to 5m0s for pod "pod-secrets-4ebc1073-5565-468b-b600-e375610984e6" in namespace "secrets-1712" to be "success or failure"
Jun 13 10:03:05.737: INFO: Pod "pod-secrets-4ebc1073-5565-468b-b600-e375610984e6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.450104ms
Jun 13 10:03:07.742: INFO: Pod "pod-secrets-4ebc1073-5565-468b-b600-e375610984e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009420912s
STEP: Saw pod success
Jun 13 10:03:07.742: INFO: Pod "pod-secrets-4ebc1073-5565-468b-b600-e375610984e6" satisfied condition "success or failure"
Jun 13 10:03:07.746: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-4ebc1073-5565-468b-b600-e375610984e6 container secret-volume-test: <nil>
STEP: delete the pod
Jun 13 10:03:07.772: INFO: Waiting for pod pod-secrets-4ebc1073-5565-468b-b600-e375610984e6 to disappear
Jun 13 10:03:07.777: INFO: Pod pod-secrets-4ebc1073-5565-468b-b600-e375610984e6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:03:07.777: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1712" for this suite.
Jun 13 10:03:13.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:03:13.925: INFO: namespace secrets-1712 deletion completed in 6.144364111s

• [SLOW TEST:8.248 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:03:13.926: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:03:25.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3410" for this suite.
Jun 13 10:03:31.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:03:31.157: INFO: namespace resourcequota-3410 deletion completed in 6.133556106s

• [SLOW TEST:17.231 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:03:31.157: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Jun 13 10:03:31.194: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun 13 10:03:31.207: INFO: Waiting for terminating namespaces to be deleted...
Jun 13 10:03:31.212: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.2 before test
Jun 13 10:03:31.222: INFO: kube-proxy-mbpxz from kube-system started at 2020-06-13 03:16:34 +0000 UTC (1 container statuses recorded)
Jun 13 10:03:31.222: INFO: 	Container kube-proxy ready: true, restart count 0
Jun 13 10:03:31.222: INFO: kube-flannel-ds-mddmt from kube-system started at 2020-06-13 03:16:34 +0000 UTC (1 container statuses recorded)
Jun 13 10:03:31.222: INFO: 	Container kube-flannel ready: true, restart count 1
Jun 13 10:03:31.222: INFO: coredns-6f9ff9bd47-ctdhp from kube-system started at 2020-06-13 03:17:03 +0000 UTC (1 container statuses recorded)
Jun 13 10:03:31.222: INFO: 	Container coredns ready: true, restart count 0
Jun 13 10:03:31.222: INFO: proxymux-client-hhdsr from kube-system started at 2020-06-13 03:16:54 +0000 UTC (1 container statuses recorded)
Jun 13 10:03:31.222: INFO: 	Container proxymux-client ready: true, restart count 0
Jun 13 10:03:31.222: INFO: csi-oci-node-4dfqn from kube-system started at 2020-06-13 03:16:54 +0000 UTC (1 container statuses recorded)
Jun 13 10:03:31.222: INFO: 	Container csi-node-driver ready: true, restart count 0
Jun 13 10:03:31.222: INFO: sonobuoy-systemd-logs-daemon-set-89d5b422bcff4ee4-jptvl from sonobuoy started at 2020-06-13 09:55:07 +0000 UTC (2 container statuses recorded)
Jun 13 10:03:31.222: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 13 10:03:31.222: INFO: 	Container systemd-logs ready: true, restart count 0
Jun 13 10:03:31.222: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.3 before test
Jun 13 10:03:31.350: INFO: kube-dns-autoscaler-75565f7896-hm82m from kube-system started at 2020-06-13 03:17:03 +0000 UTC (1 container statuses recorded)
Jun 13 10:03:31.350: INFO: 	Container autoscaler ready: true, restart count 0
Jun 13 10:03:31.350: INFO: kube-flannel-ds-6cxw2 from kube-system started at 2020-06-13 03:16:34 +0000 UTC (1 container statuses recorded)
Jun 13 10:03:31.350: INFO: 	Container kube-flannel ready: true, restart count 1
Jun 13 10:03:31.350: INFO: proxymux-client-mshct from kube-system started at 2020-06-13 03:16:54 +0000 UTC (1 container statuses recorded)
Jun 13 10:03:31.350: INFO: 	Container proxymux-client ready: true, restart count 0
Jun 13 10:03:31.350: INFO: sonobuoy-e2e-job-eae45311abd24acb from sonobuoy started at 2020-06-13 09:55:07 +0000 UTC (2 container statuses recorded)
Jun 13 10:03:31.350: INFO: 	Container e2e ready: true, restart count 0
Jun 13 10:03:31.350: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 13 10:03:31.350: INFO: kubernetes-dashboard-56b6bf4bf-65jz6 from kube-system started at 2020-06-13 03:16:53 +0000 UTC (1 container statuses recorded)
Jun 13 10:03:31.350: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jun 13 10:03:31.350: INFO: kube-proxy-6vf8c from kube-system started at 2020-06-13 03:16:34 +0000 UTC (1 container statuses recorded)
Jun 13 10:03:31.350: INFO: 	Container kube-proxy ready: true, restart count 0
Jun 13 10:03:31.350: INFO: csi-oci-node-hhfs6 from kube-system started at 2020-06-13 03:16:54 +0000 UTC (1 container statuses recorded)
Jun 13 10:03:31.350: INFO: 	Container csi-node-driver ready: true, restart count 0
Jun 13 10:03:31.350: INFO: sonobuoy from sonobuoy started at 2020-06-13 09:55:05 +0000 UTC (1 container statuses recorded)
Jun 13 10:03:31.350: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun 13 10:03:31.350: INFO: sonobuoy-systemd-logs-daemon-set-89d5b422bcff4ee4-z5xtf from sonobuoy started at 2020-06-13 09:55:07 +0000 UTC (2 container statuses recorded)
Jun 13 10:03:31.350: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 13 10:03:31.350: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-0cc723ce-e089-4d07-8aa4-c4d8a1152836 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-0cc723ce-e089-4d07-8aa4-c4d8a1152836 off the node 10.0.10.2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-0cc723ce-e089-4d07-8aa4-c4d8a1152836
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:03:41.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-641" for this suite.
Jun 13 10:03:55.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:03:55.864: INFO: namespace sched-pred-641 deletion completed in 14.404871073s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:24.706 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:03:55.864: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-8505a87b-940f-4e51-bfd3-d815a8906cdc
STEP: Creating a pod to test consume configMaps
Jun 13 10:03:55.921: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-702f938f-5eaa-42fd-ae46-459300b80ecb" in namespace "projected-3858" to be "success or failure"
Jun 13 10:03:55.925: INFO: Pod "pod-projected-configmaps-702f938f-5eaa-42fd-ae46-459300b80ecb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.13838ms
Jun 13 10:03:57.929: INFO: Pod "pod-projected-configmaps-702f938f-5eaa-42fd-ae46-459300b80ecb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008344871s
STEP: Saw pod success
Jun 13 10:03:57.929: INFO: Pod "pod-projected-configmaps-702f938f-5eaa-42fd-ae46-459300b80ecb" satisfied condition "success or failure"
Jun 13 10:03:57.933: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-configmaps-702f938f-5eaa-42fd-ae46-459300b80ecb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 13 10:03:58.215: INFO: Waiting for pod pod-projected-configmaps-702f938f-5eaa-42fd-ae46-459300b80ecb to disappear
Jun 13 10:03:58.221: INFO: Pod pod-projected-configmaps-702f938f-5eaa-42fd-ae46-459300b80ecb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:03:58.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3858" for this suite.
Jun 13 10:04:04.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:04:04.373: INFO: namespace projected-3858 deletion completed in 6.146020603s

• [SLOW TEST:8.510 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:04:04.374: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-8608
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 13 10:04:04.408: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun 13 10:04:24.480: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.147:8080/dial?request=hostName&protocol=http&host=10.244.1.146&port=8080&tries=1'] Namespace:pod-network-test-8608 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 13 10:04:24.480: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 10:04:24.764: INFO: Waiting for endpoints: map[]
Jun 13 10:04:24.768: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.147:8080/dial?request=hostName&protocol=http&host=10.244.0.84&port=8080&tries=1'] Namespace:pod-network-test-8608 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 13 10:04:24.768: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 10:04:25.011: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:04:25.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8608" for this suite.
Jun 13 10:04:37.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:04:37.152: INFO: namespace pod-network-test-8608 deletion completed in 12.135866434s

• [SLOW TEST:32.779 seconds]
[sig-network] Networking
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:04:37.155: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-482410a7-3af9-41a8-8daa-a4e451a05831
STEP: Creating a pod to test consume secrets
Jun 13 10:04:37.209: INFO: Waiting up to 5m0s for pod "pod-secrets-46a4af32-3cee-466c-bf6a-b378db07ff6b" in namespace "secrets-5840" to be "success or failure"
Jun 13 10:04:37.213: INFO: Pod "pod-secrets-46a4af32-3cee-466c-bf6a-b378db07ff6b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.275723ms
Jun 13 10:04:39.218: INFO: Pod "pod-secrets-46a4af32-3cee-466c-bf6a-b378db07ff6b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008739303s
Jun 13 10:04:41.226: INFO: Pod "pod-secrets-46a4af32-3cee-466c-bf6a-b378db07ff6b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016931319s
STEP: Saw pod success
Jun 13 10:04:41.226: INFO: Pod "pod-secrets-46a4af32-3cee-466c-bf6a-b378db07ff6b" satisfied condition "success or failure"
Jun 13 10:04:41.231: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-46a4af32-3cee-466c-bf6a-b378db07ff6b container secret-volume-test: <nil>
STEP: delete the pod
Jun 13 10:04:41.255: INFO: Waiting for pod pod-secrets-46a4af32-3cee-466c-bf6a-b378db07ff6b to disappear
Jun 13 10:04:41.259: INFO: Pod pod-secrets-46a4af32-3cee-466c-bf6a-b378db07ff6b no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:04:41.260: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5840" for this suite.
Jun 13 10:04:47.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:04:47.399: INFO: namespace secrets-5840 deletion completed in 6.134655848s

• [SLOW TEST:10.244 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:04:47.399: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-384
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-384
STEP: Deleting pre-stop pod
Jun 13 10:04:58.570: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:04:58.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-384" for this suite.
Jun 13 10:05:42.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:05:42.719: INFO: namespace prestop-384 deletion completed in 44.137246237s

• [SLOW TEST:55.320 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:05:42.720: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-403ad003-34a1-4098-a915-5993a34c8d27
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-403ad003-34a1-4098-a915-5993a34c8d27
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:05:46.859: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7026" for this suite.
Jun 13 10:06:04.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:06:05.005: INFO: namespace projected-7026 deletion completed in 18.141798681s

• [SLOW TEST:22.285 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:06:05.006: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Jun 13 10:06:05.067: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8956 /api/v1/namespaces/watch-8956/configmaps/e2e-watch-test-watch-closed 8bbc3565-e3b0-4d55-8114-11e428c02917 89949 0 2020-06-13 10:06:05 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 13 10:06:05.067: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8956 /api/v1/namespaces/watch-8956/configmaps/e2e-watch-test-watch-closed 8bbc3565-e3b0-4d55-8114-11e428c02917 89950 0 2020-06-13 10:06:05 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Jun 13 10:06:05.089: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8956 /api/v1/namespaces/watch-8956/configmaps/e2e-watch-test-watch-closed 8bbc3565-e3b0-4d55-8114-11e428c02917 89951 0 2020-06-13 10:06:05 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 13 10:06:05.090: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8956 /api/v1/namespaces/watch-8956/configmaps/e2e-watch-test-watch-closed 8bbc3565-e3b0-4d55-8114-11e428c02917 89952 0 2020-06-13 10:06:05 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:06:05.090: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8956" for this suite.
Jun 13 10:06:11.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:06:11.239: INFO: namespace watch-8956 deletion completed in 6.145635125s

• [SLOW TEST:6.234 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:06:11.240: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 10:06:11.287: INFO: Waiting up to 5m0s for pod "busybox-user-65534-aac9a44c-575e-44f5-9353-34062aa0512a" in namespace "security-context-test-6330" to be "success or failure"
Jun 13 10:06:11.291: INFO: Pod "busybox-user-65534-aac9a44c-575e-44f5-9353-34062aa0512a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.767868ms
Jun 13 10:06:13.296: INFO: Pod "busybox-user-65534-aac9a44c-575e-44f5-9353-34062aa0512a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009093939s
Jun 13 10:06:13.296: INFO: Pod "busybox-user-65534-aac9a44c-575e-44f5-9353-34062aa0512a" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:06:13.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-6330" for this suite.
Jun 13 10:06:19.315: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:06:19.437: INFO: namespace security-context-test-6330 deletion completed in 6.136178398s

• [SLOW TEST:8.197 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:06:19.437: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 13 10:06:20.157: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jun 13 10:06:22.170: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639580, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639580, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639580, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639580, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 13 10:06:25.187: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Jun 13 10:06:25.358: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:06:25.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6836" for this suite.
Jun 13 10:06:31.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:06:31.520: INFO: namespace webhook-6836 deletion completed in 6.134992589s
STEP: Destroying namespace "webhook-6836-markers" for this suite.
Jun 13 10:06:37.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:06:37.661: INFO: namespace webhook-6836-markers deletion completed in 6.140813643s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.251 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:06:37.688: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:06:37.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8710" for this suite.
Jun 13 10:06:43.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:06:43.872: INFO: namespace custom-resource-definition-8710 deletion completed in 6.136824264s

• [SLOW TEST:6.184 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:06:43.873: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Jun 13 10:06:43.938: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6040 /api/v1/namespaces/watch-6040/configmaps/e2e-watch-test-label-changed 82ccdf39-befd-4e7b-8b05-f1b5cfb35adf 90170 0 2020-06-13 10:06:43 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Jun 13 10:06:43.938: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6040 /api/v1/namespaces/watch-6040/configmaps/e2e-watch-test-label-changed 82ccdf39-befd-4e7b-8b05-f1b5cfb35adf 90171 0 2020-06-13 10:06:43 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Jun 13 10:06:43.938: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6040 /api/v1/namespaces/watch-6040/configmaps/e2e-watch-test-label-changed 82ccdf39-befd-4e7b-8b05-f1b5cfb35adf 90172 0 2020-06-13 10:06:43 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Jun 13 10:06:53.977: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6040 /api/v1/namespaces/watch-6040/configmaps/e2e-watch-test-label-changed 82ccdf39-befd-4e7b-8b05-f1b5cfb35adf 90203 0 2020-06-13 10:06:43 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 13 10:06:53.977: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6040 /api/v1/namespaces/watch-6040/configmaps/e2e-watch-test-label-changed 82ccdf39-befd-4e7b-8b05-f1b5cfb35adf 90204 0 2020-06-13 10:06:43 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Jun 13 10:06:53.977: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6040 /api/v1/namespaces/watch-6040/configmaps/e2e-watch-test-label-changed 82ccdf39-befd-4e7b-8b05-f1b5cfb35adf 90205 0 2020-06-13 10:06:43 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:06:53.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6040" for this suite.
Jun 13 10:06:59.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:07:00.119: INFO: namespace watch-6040 deletion completed in 6.138531022s

• [SLOW TEST:16.247 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:07:00.120: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-757135dd-9fac-47b1-94b4-e329f3e1cd2d
STEP: Creating a pod to test consume configMaps
Jun 13 10:07:00.175: INFO: Waiting up to 5m0s for pod "pod-configmaps-1f7c5f0b-9c1b-46aa-bfe2-729aa8bf149f" in namespace "configmap-9728" to be "success or failure"
Jun 13 10:07:00.179: INFO: Pod "pod-configmaps-1f7c5f0b-9c1b-46aa-bfe2-729aa8bf149f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.816477ms
Jun 13 10:07:02.212: INFO: Pod "pod-configmaps-1f7c5f0b-9c1b-46aa-bfe2-729aa8bf149f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036418566s
STEP: Saw pod success
Jun 13 10:07:02.212: INFO: Pod "pod-configmaps-1f7c5f0b-9c1b-46aa-bfe2-729aa8bf149f" satisfied condition "success or failure"
Jun 13 10:07:02.216: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-1f7c5f0b-9c1b-46aa-bfe2-729aa8bf149f container configmap-volume-test: <nil>
STEP: delete the pod
Jun 13 10:07:02.340: INFO: Waiting for pod pod-configmaps-1f7c5f0b-9c1b-46aa-bfe2-729aa8bf149f to disappear
Jun 13 10:07:02.345: INFO: Pod pod-configmaps-1f7c5f0b-9c1b-46aa-bfe2-729aa8bf149f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:07:02.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9728" for this suite.
Jun 13 10:07:08.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:07:08.489: INFO: namespace configmap-9728 deletion completed in 6.139789725s

• [SLOW TEST:8.370 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:07:08.490: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 13 10:07:08.911: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jun 13 10:07:10.925: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639628, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639628, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639628, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639628, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 13 10:07:13.941: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Jun 13 10:07:18.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 attach --namespace=webhook-4482 to-be-attached-pod -i -c=container1'
Jun 13 10:07:18.276: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:07:18.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4482" for this suite.
Jun 13 10:07:30.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:07:30.430: INFO: namespace webhook-4482 deletion completed in 12.137802937s
STEP: Destroying namespace "webhook-4482-markers" for this suite.
Jun 13 10:07:36.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:07:36.569: INFO: namespace webhook-4482-markers deletion completed in 6.13910633s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.101 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:07:36.592: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jun 13 10:07:36.642: INFO: Waiting up to 5m0s for pod "pod-d5d6fda1-1662-4392-ac5f-775db47a4a9a" in namespace "emptydir-7461" to be "success or failure"
Jun 13 10:07:36.646: INFO: Pod "pod-d5d6fda1-1662-4392-ac5f-775db47a4a9a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.8838ms
Jun 13 10:07:38.650: INFO: Pod "pod-d5d6fda1-1662-4392-ac5f-775db47a4a9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008536919s
Jun 13 10:07:40.655: INFO: Pod "pod-d5d6fda1-1662-4392-ac5f-775db47a4a9a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012806686s
STEP: Saw pod success
Jun 13 10:07:40.655: INFO: Pod "pod-d5d6fda1-1662-4392-ac5f-775db47a4a9a" satisfied condition "success or failure"
Jun 13 10:07:40.659: INFO: Trying to get logs from node 10.0.10.2 pod pod-d5d6fda1-1662-4392-ac5f-775db47a4a9a container test-container: <nil>
STEP: delete the pod
Jun 13 10:07:40.682: INFO: Waiting for pod pod-d5d6fda1-1662-4392-ac5f-775db47a4a9a to disappear
Jun 13 10:07:40.686: INFO: Pod pod-d5d6fda1-1662-4392-ac5f-775db47a4a9a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:07:40.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7461" for this suite.
Jun 13 10:07:46.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:07:46.825: INFO: namespace emptydir-7461 deletion completed in 6.134640596s

• [SLOW TEST:10.233 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:07:46.826: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jun 13 10:07:46.903: INFO: Number of nodes with available pods: 0
Jun 13 10:07:46.903: INFO: Node 10.0.10.2 is running more than one daemon pod
Jun 13 10:07:47.912: INFO: Number of nodes with available pods: 0
Jun 13 10:07:47.912: INFO: Node 10.0.10.2 is running more than one daemon pod
Jun 13 10:07:48.912: INFO: Number of nodes with available pods: 1
Jun 13 10:07:48.912: INFO: Node 10.0.10.2 is running more than one daemon pod
Jun 13 10:07:49.913: INFO: Number of nodes with available pods: 2
Jun 13 10:07:49.913: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Jun 13 10:07:49.934: INFO: Number of nodes with available pods: 2
Jun 13 10:07:49.934: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3340, will wait for the garbage collector to delete the pods
Jun 13 10:07:51.010: INFO: Deleting DaemonSet.extensions daemon-set took: 9.63489ms
Jun 13 10:07:51.310: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.267325ms
Jun 13 10:09:15.115: INFO: Number of nodes with available pods: 0
Jun 13 10:09:15.115: INFO: Number of running nodes: 0, number of available pods: 0
Jun 13 10:09:15.121: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3340/daemonsets","resourceVersion":"90808"},"items":null}

Jun 13 10:09:15.125: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3340/pods","resourceVersion":"90808"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:09:15.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3340" for this suite.
Jun 13 10:09:21.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:09:21.509: INFO: namespace daemonsets-3340 deletion completed in 6.366415909s

• [SLOW TEST:94.682 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:09:21.509: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 10:09:21.549: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Jun 13 10:09:23.592: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:09:24.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3626" for this suite.
Jun 13 10:09:30.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:09:30.754: INFO: namespace replication-controller-3626 deletion completed in 6.147248569s

• [SLOW TEST:9.245 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:09:30.754: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:09:30.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2681" for this suite.
Jun 13 10:09:36.815: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:09:36.940: INFO: namespace services-2681 deletion completed in 6.138736545s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.186 seconds]
[sig-network] Services
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:09:36.940: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-wngt
STEP: Creating a pod to test atomic-volume-subpath
Jun 13 10:09:37.004: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-wngt" in namespace "subpath-1350" to be "success or failure"
Jun 13 10:09:37.008: INFO: Pod "pod-subpath-test-downwardapi-wngt": Phase="Pending", Reason="", readiness=false. Elapsed: 3.850834ms
Jun 13 10:09:39.012: INFO: Pod "pod-subpath-test-downwardapi-wngt": Phase="Running", Reason="", readiness=true. Elapsed: 2.007826894s
Jun 13 10:09:41.017: INFO: Pod "pod-subpath-test-downwardapi-wngt": Phase="Running", Reason="", readiness=true. Elapsed: 4.012651226s
Jun 13 10:09:43.021: INFO: Pod "pod-subpath-test-downwardapi-wngt": Phase="Running", Reason="", readiness=true. Elapsed: 6.017025658s
Jun 13 10:09:45.026: INFO: Pod "pod-subpath-test-downwardapi-wngt": Phase="Running", Reason="", readiness=true. Elapsed: 8.021644384s
Jun 13 10:09:47.030: INFO: Pod "pod-subpath-test-downwardapi-wngt": Phase="Running", Reason="", readiness=true. Elapsed: 10.026507535s
Jun 13 10:09:49.035: INFO: Pod "pod-subpath-test-downwardapi-wngt": Phase="Running", Reason="", readiness=true. Elapsed: 12.031457988s
Jun 13 10:09:51.040: INFO: Pod "pod-subpath-test-downwardapi-wngt": Phase="Running", Reason="", readiness=true. Elapsed: 14.036002789s
Jun 13 10:09:53.044: INFO: Pod "pod-subpath-test-downwardapi-wngt": Phase="Running", Reason="", readiness=true. Elapsed: 16.040243539s
Jun 13 10:09:55.049: INFO: Pod "pod-subpath-test-downwardapi-wngt": Phase="Running", Reason="", readiness=true. Elapsed: 18.045511614s
Jun 13 10:09:57.055: INFO: Pod "pod-subpath-test-downwardapi-wngt": Phase="Running", Reason="", readiness=true. Elapsed: 20.050652317s
Jun 13 10:09:59.059: INFO: Pod "pod-subpath-test-downwardapi-wngt": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.055080189s
STEP: Saw pod success
Jun 13 10:09:59.059: INFO: Pod "pod-subpath-test-downwardapi-wngt" satisfied condition "success or failure"
Jun 13 10:09:59.063: INFO: Trying to get logs from node 10.0.10.2 pod pod-subpath-test-downwardapi-wngt container test-container-subpath-downwardapi-wngt: <nil>
STEP: delete the pod
Jun 13 10:09:59.266: INFO: Waiting for pod pod-subpath-test-downwardapi-wngt to disappear
Jun 13 10:09:59.270: INFO: Pod pod-subpath-test-downwardapi-wngt no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-wngt
Jun 13 10:09:59.270: INFO: Deleting pod "pod-subpath-test-downwardapi-wngt" in namespace "subpath-1350"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:09:59.273: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1350" for this suite.
Jun 13 10:10:05.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:10:05.416: INFO: namespace subpath-1350 deletion completed in 6.13928226s

• [SLOW TEST:28.477 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:10:05.416: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:10:15.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3093" for this suite.
Jun 13 10:10:21.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:10:21.619: INFO: namespace job-3093 deletion completed in 6.143534798s

• [SLOW TEST:16.202 seconds]
[sig-apps] Job
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:10:21.620: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:10:37.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4418" for this suite.
Jun 13 10:10:43.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:10:43.914: INFO: namespace resourcequota-4418 deletion completed in 6.147330813s

• [SLOW TEST:22.295 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:10:43.916: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 10:10:43.967: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-48f1d802-305f-4a1e-87eb-1ff1dad5d60a" in namespace "security-context-test-4764" to be "success or failure"
Jun 13 10:10:43.972: INFO: Pod "busybox-readonly-false-48f1d802-305f-4a1e-87eb-1ff1dad5d60a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.124437ms
Jun 13 10:10:45.977: INFO: Pod "busybox-readonly-false-48f1d802-305f-4a1e-87eb-1ff1dad5d60a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009108297s
Jun 13 10:10:45.977: INFO: Pod "busybox-readonly-false-48f1d802-305f-4a1e-87eb-1ff1dad5d60a" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:10:45.977: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4764" for this suite.
Jun 13 10:10:51.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:10:52.121: INFO: namespace security-context-test-4764 deletion completed in 6.138910772s

• [SLOW TEST:8.205 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:10:52.122: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Jun 13 10:10:52.159: INFO: namespace kubectl-6351
Jun 13 10:10:52.159: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 create -f - --namespace=kubectl-6351'
Jun 13 10:10:52.431: INFO: stderr: ""
Jun 13 10:10:52.431: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jun 13 10:10:53.437: INFO: Selector matched 1 pods for map[app:redis]
Jun 13 10:10:53.437: INFO: Found 0 / 1
Jun 13 10:10:54.437: INFO: Selector matched 1 pods for map[app:redis]
Jun 13 10:10:54.437: INFO: Found 0 / 1
Jun 13 10:10:55.437: INFO: Selector matched 1 pods for map[app:redis]
Jun 13 10:10:55.437: INFO: Found 1 / 1
Jun 13 10:10:55.437: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Jun 13 10:10:55.441: INFO: Selector matched 1 pods for map[app:redis]
Jun 13 10:10:55.441: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jun 13 10:10:55.441: INFO: wait on redis-master startup in kubectl-6351 
Jun 13 10:10:55.441: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 logs redis-master-n5zqt redis-master --namespace=kubectl-6351'
Jun 13 10:10:55.648: INFO: stderr: ""
Jun 13 10:10:55.648: INFO: stdout: "1:C 13 Jun 2020 10:10:53.611 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 13 Jun 2020 10:10:53.612 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 13 Jun 2020 10:10:53.612 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 13 Jun 2020 10:10:53.614 * Running mode=standalone, port=6379.\n1:M 13 Jun 2020 10:10:53.615 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 13 Jun 2020 10:10:53.615 # Server initialized\n1:M 13 Jun 2020 10:10:53.615 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 13 Jun 2020 10:10:53.615 * Ready to accept connections\n"
STEP: exposing RC
Jun 13 10:10:55.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-6351'
Jun 13 10:10:55.768: INFO: stderr: ""
Jun 13 10:10:55.768: INFO: stdout: "service/rm2 exposed\n"
Jun 13 10:10:55.773: INFO: Service rm2 in namespace kubectl-6351 found.
STEP: exposing service
Jun 13 10:10:57.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-6351'
Jun 13 10:10:57.910: INFO: stderr: ""
Jun 13 10:10:57.910: INFO: stdout: "service/rm3 exposed\n"
Jun 13 10:10:57.915: INFO: Service rm3 in namespace kubectl-6351 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:10:59.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6351" for this suite.
Jun 13 10:11:11.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:11:12.078: INFO: namespace kubectl-6351 deletion completed in 12.149053864s

• [SLOW TEST:19.957 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:11:12.079: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Jun 13 10:11:12.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 create -f - --namespace=kubectl-4952'
Jun 13 10:11:12.334: INFO: stderr: ""
Jun 13 10:11:12.334: INFO: stdout: "pod/pause created\n"
Jun 13 10:11:12.334: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Jun 13 10:11:12.334: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-4952" to be "running and ready"
Jun 13 10:11:12.340: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 6.672587ms
Jun 13 10:11:14.345: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.0113982s
Jun 13 10:11:14.345: INFO: Pod "pause" satisfied condition "running and ready"
Jun 13 10:11:14.345: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Jun 13 10:11:14.345: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 label pods pause testing-label=testing-label-value --namespace=kubectl-4952'
Jun 13 10:11:14.529: INFO: stderr: ""
Jun 13 10:11:14.529: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Jun 13 10:11:14.529: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pod pause -L testing-label --namespace=kubectl-4952'
Jun 13 10:11:14.732: INFO: stderr: ""
Jun 13 10:11:14.732: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Jun 13 10:11:14.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 label pods pause testing-label- --namespace=kubectl-4952'
Jun 13 10:11:14.872: INFO: stderr: ""
Jun 13 10:11:14.872: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Jun 13 10:11:14.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pod pause -L testing-label --namespace=kubectl-4952'
Jun 13 10:11:14.960: INFO: stderr: ""
Jun 13 10:11:14.960: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Jun 13 10:11:14.960: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 delete --grace-period=0 --force -f - --namespace=kubectl-4952'
Jun 13 10:11:15.056: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 13 10:11:15.056: INFO: stdout: "pod \"pause\" force deleted\n"
Jun 13 10:11:15.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get rc,svc -l name=pause --no-headers --namespace=kubectl-4952'
Jun 13 10:11:15.171: INFO: stderr: "No resources found in kubectl-4952 namespace.\n"
Jun 13 10:11:15.171: INFO: stdout: ""
Jun 13 10:11:15.171: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods -l name=pause --namespace=kubectl-4952 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 13 10:11:15.272: INFO: stderr: ""
Jun 13 10:11:15.272: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:11:15.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4952" for this suite.
Jun 13 10:11:21.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:11:21.426: INFO: namespace kubectl-4952 deletion completed in 6.148528438s

• [SLOW TEST:9.347 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:11:21.431: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 13 10:11:21.814: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jun 13 10:11:23.828: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639881, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639881, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639881, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639881, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 13 10:11:26.860: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:11:27.104: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-442" for this suite.
Jun 13 10:11:33.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:11:33.240: INFO: namespace webhook-442 deletion completed in 6.131227812s
STEP: Destroying namespace "webhook-442-markers" for this suite.
Jun 13 10:11:39.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:11:39.390: INFO: namespace webhook-442-markers deletion completed in 6.149439694s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.983 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:11:39.416: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Jun 13 10:11:39.455: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:11:56.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9516" for this suite.
Jun 13 10:12:02.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:12:02.737: INFO: namespace crd-publish-openapi-9516 deletion completed in 6.143660956s

• [SLOW TEST:23.322 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:12:02.738: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-8020a003-bc4f-47c6-a97f-873fac73aa33
STEP: Creating a pod to test consume configMaps
Jun 13 10:12:02.796: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-142d32b5-e236-421d-bcbc-ab9e15a48386" in namespace "projected-4840" to be "success or failure"
Jun 13 10:12:02.801: INFO: Pod "pod-projected-configmaps-142d32b5-e236-421d-bcbc-ab9e15a48386": Phase="Pending", Reason="", readiness=false. Elapsed: 4.710912ms
Jun 13 10:12:04.805: INFO: Pod "pod-projected-configmaps-142d32b5-e236-421d-bcbc-ab9e15a48386": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009444582s
Jun 13 10:12:06.810: INFO: Pod "pod-projected-configmaps-142d32b5-e236-421d-bcbc-ab9e15a48386": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01400491s
STEP: Saw pod success
Jun 13 10:12:06.810: INFO: Pod "pod-projected-configmaps-142d32b5-e236-421d-bcbc-ab9e15a48386" satisfied condition "success or failure"
Jun 13 10:12:06.813: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-configmaps-142d32b5-e236-421d-bcbc-ab9e15a48386 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 13 10:12:06.840: INFO: Waiting for pod pod-projected-configmaps-142d32b5-e236-421d-bcbc-ab9e15a48386 to disappear
Jun 13 10:12:06.844: INFO: Pod pod-projected-configmaps-142d32b5-e236-421d-bcbc-ab9e15a48386 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:12:06.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4840" for this suite.
Jun 13 10:12:12.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:12:12.987: INFO: namespace projected-4840 deletion completed in 6.138668634s

• [SLOW TEST:10.250 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:12:12.988: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:12:26.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5941" for this suite.
Jun 13 10:12:32.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:12:32.247: INFO: namespace resourcequota-5941 deletion completed in 6.143338242s

• [SLOW TEST:19.259 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:12:32.247: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9792.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-9792.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9792.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-9792.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9792.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-9792.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9792.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-9792.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9792.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-9792.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9792.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-9792.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9792.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 33.141.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.141.33_udp@PTR;check="$$(dig +tcp +noall +answer +search 33.141.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.141.33_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-9792.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-9792.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-9792.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-9792.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-9792.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-9792.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-9792.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-9792.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-9792.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-9792.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-9792.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-9792.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9792.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 33.141.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.141.33_udp@PTR;check="$$(dig +tcp +noall +answer +search 33.141.96.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.96.141.33_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 13 10:12:34.400: INFO: Unable to read wheezy_udp@dns-test-service.dns-9792.svc.cluster.local from pod dns-9792/dns-test-92ee7565-98b9-4080-8b6d-13d5e314f5ef: the server could not find the requested resource (get pods dns-test-92ee7565-98b9-4080-8b6d-13d5e314f5ef)
Jun 13 10:12:34.406: INFO: Unable to read wheezy_tcp@dns-test-service.dns-9792.svc.cluster.local from pod dns-9792/dns-test-92ee7565-98b9-4080-8b6d-13d5e314f5ef: the server could not find the requested resource (get pods dns-test-92ee7565-98b9-4080-8b6d-13d5e314f5ef)
Jun 13 10:12:34.411: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-9792.svc.cluster.local from pod dns-9792/dns-test-92ee7565-98b9-4080-8b6d-13d5e314f5ef: the server could not find the requested resource (get pods dns-test-92ee7565-98b9-4080-8b6d-13d5e314f5ef)
Jun 13 10:12:34.447: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-9792.svc.cluster.local from pod dns-9792/dns-test-92ee7565-98b9-4080-8b6d-13d5e314f5ef: the server could not find the requested resource (get pods dns-test-92ee7565-98b9-4080-8b6d-13d5e314f5ef)
Jun 13 10:12:34.484: INFO: Unable to read jessie_udp@dns-test-service.dns-9792.svc.cluster.local from pod dns-9792/dns-test-92ee7565-98b9-4080-8b6d-13d5e314f5ef: the server could not find the requested resource (get pods dns-test-92ee7565-98b9-4080-8b6d-13d5e314f5ef)
Jun 13 10:12:34.489: INFO: Unable to read jessie_tcp@dns-test-service.dns-9792.svc.cluster.local from pod dns-9792/dns-test-92ee7565-98b9-4080-8b6d-13d5e314f5ef: the server could not find the requested resource (get pods dns-test-92ee7565-98b9-4080-8b6d-13d5e314f5ef)
Jun 13 10:12:34.495: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-9792.svc.cluster.local from pod dns-9792/dns-test-92ee7565-98b9-4080-8b6d-13d5e314f5ef: the server could not find the requested resource (get pods dns-test-92ee7565-98b9-4080-8b6d-13d5e314f5ef)
Jun 13 10:12:34.501: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-9792.svc.cluster.local from pod dns-9792/dns-test-92ee7565-98b9-4080-8b6d-13d5e314f5ef: the server could not find the requested resource (get pods dns-test-92ee7565-98b9-4080-8b6d-13d5e314f5ef)
Jun 13 10:12:34.532: INFO: Lookups using dns-9792/dns-test-92ee7565-98b9-4080-8b6d-13d5e314f5ef failed for: [wheezy_udp@dns-test-service.dns-9792.svc.cluster.local wheezy_tcp@dns-test-service.dns-9792.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-9792.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-9792.svc.cluster.local jessie_udp@dns-test-service.dns-9792.svc.cluster.local jessie_tcp@dns-test-service.dns-9792.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-9792.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-9792.svc.cluster.local]

Jun 13 10:12:39.641: INFO: DNS probes using dns-9792/dns-test-92ee7565-98b9-4080-8b6d-13d5e314f5ef succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:12:39.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9792" for this suite.
Jun 13 10:12:45.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:12:45.841: INFO: namespace dns-9792 deletion completed in 6.14478239s

• [SLOW TEST:13.593 seconds]
[sig-network] DNS
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:12:45.841: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Jun 13 10:12:46.408: INFO: created pod pod-service-account-defaultsa
Jun 13 10:12:46.408: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Jun 13 10:12:46.413: INFO: created pod pod-service-account-mountsa
Jun 13 10:12:46.413: INFO: pod pod-service-account-mountsa service account token volume mount: true
Jun 13 10:12:46.418: INFO: created pod pod-service-account-nomountsa
Jun 13 10:12:46.418: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Jun 13 10:12:46.423: INFO: created pod pod-service-account-defaultsa-mountspec
Jun 13 10:12:46.423: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Jun 13 10:12:46.429: INFO: created pod pod-service-account-mountsa-mountspec
Jun 13 10:12:46.429: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Jun 13 10:12:46.434: INFO: created pod pod-service-account-nomountsa-mountspec
Jun 13 10:12:46.434: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Jun 13 10:12:46.441: INFO: created pod pod-service-account-defaultsa-nomountspec
Jun 13 10:12:46.442: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Jun 13 10:12:46.447: INFO: created pod pod-service-account-mountsa-nomountspec
Jun 13 10:12:46.447: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Jun 13 10:12:46.454: INFO: created pod pod-service-account-nomountsa-nomountspec
Jun 13 10:12:46.454: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:12:46.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7050" for this suite.
Jun 13 10:12:52.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:12:52.599: INFO: namespace svcaccounts-7050 deletion completed in 6.139937244s

• [SLOW TEST:6.758 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:12:52.599: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jun 13 10:12:56.686: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 13 10:12:56.691: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 13 10:12:58.691: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 13 10:12:58.696: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 13 10:13:00.691: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 13 10:13:00.696: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 13 10:13:02.691: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 13 10:13:02.696: INFO: Pod pod-with-prestop-exec-hook still exists
Jun 13 10:13:04.691: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Jun 13 10:13:04.696: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:13:04.747: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7501" for this suite.
Jun 13 10:13:16.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:13:16.889: INFO: namespace container-lifecycle-hook-7501 deletion completed in 12.137845945s

• [SLOW TEST:24.290 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:13:16.889: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Jun 13 10:13:17.997: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Jun 13 10:13:20.013: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639998, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639998, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639998, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727639997, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 13 10:13:23.031: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 10:13:23.037: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:13:24.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-1980" for this suite.
Jun 13 10:13:30.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:13:30.457: INFO: namespace crd-webhook-1980 deletion completed in 6.141568477s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:13.591 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:13:30.481: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Jun 13 10:13:30.531: INFO: Waiting up to 5m0s for pod "client-containers-3e448a05-2e2f-4dad-9e9e-39e93ffc5eac" in namespace "containers-3696" to be "success or failure"
Jun 13 10:13:30.534: INFO: Pod "client-containers-3e448a05-2e2f-4dad-9e9e-39e93ffc5eac": Phase="Pending", Reason="", readiness=false. Elapsed: 3.87874ms
Jun 13 10:13:32.538: INFO: Pod "client-containers-3e448a05-2e2f-4dad-9e9e-39e93ffc5eac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007705999s
Jun 13 10:13:34.543: INFO: Pod "client-containers-3e448a05-2e2f-4dad-9e9e-39e93ffc5eac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012434223s
STEP: Saw pod success
Jun 13 10:13:34.543: INFO: Pod "client-containers-3e448a05-2e2f-4dad-9e9e-39e93ffc5eac" satisfied condition "success or failure"
Jun 13 10:13:34.547: INFO: Trying to get logs from node 10.0.10.2 pod client-containers-3e448a05-2e2f-4dad-9e9e-39e93ffc5eac container test-container: <nil>
STEP: delete the pod
Jun 13 10:13:34.571: INFO: Waiting for pod client-containers-3e448a05-2e2f-4dad-9e9e-39e93ffc5eac to disappear
Jun 13 10:13:34.574: INFO: Pod client-containers-3e448a05-2e2f-4dad-9e9e-39e93ffc5eac no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:13:34.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3696" for this suite.
Jun 13 10:13:40.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:13:40.717: INFO: namespace containers-3696 deletion completed in 6.137529265s

• [SLOW TEST:10.236 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:13:40.717: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-06120a68-6638-49d7-a7a5-272d9aa980f7 in namespace container-probe-3059
Jun 13 10:13:42.774: INFO: Started pod busybox-06120a68-6638-49d7-a7a5-272d9aa980f7 in namespace container-probe-3059
STEP: checking the pod's current state and verifying that restartCount is present
Jun 13 10:13:42.778: INFO: Initial restart count of pod busybox-06120a68-6638-49d7-a7a5-272d9aa980f7 is 0
Jun 13 10:14:32.895: INFO: Restart count of pod container-probe-3059/busybox-06120a68-6638-49d7-a7a5-272d9aa980f7 is now 1 (50.116741422s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:14:32.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3059" for this suite.
Jun 13 10:14:38.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:14:39.277: INFO: namespace container-probe-3059 deletion completed in 6.36419825s

• [SLOW TEST:58.560 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:14:39.278: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-7557978d-281d-461e-8a63-a7166706295b
STEP: Creating a pod to test consume configMaps
Jun 13 10:14:39.329: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-298daa96-a974-498b-897d-ee4cfc7f7610" in namespace "projected-3919" to be "success or failure"
Jun 13 10:14:39.333: INFO: Pod "pod-projected-configmaps-298daa96-a974-498b-897d-ee4cfc7f7610": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01376ms
Jun 13 10:14:41.337: INFO: Pod "pod-projected-configmaps-298daa96-a974-498b-897d-ee4cfc7f7610": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008154262s
Jun 13 10:14:43.341: INFO: Pod "pod-projected-configmaps-298daa96-a974-498b-897d-ee4cfc7f7610": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012781564s
STEP: Saw pod success
Jun 13 10:14:43.342: INFO: Pod "pod-projected-configmaps-298daa96-a974-498b-897d-ee4cfc7f7610" satisfied condition "success or failure"
Jun 13 10:14:43.345: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-configmaps-298daa96-a974-498b-897d-ee4cfc7f7610 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 13 10:14:43.371: INFO: Waiting for pod pod-projected-configmaps-298daa96-a974-498b-897d-ee4cfc7f7610 to disappear
Jun 13 10:14:43.374: INFO: Pod pod-projected-configmaps-298daa96-a974-498b-897d-ee4cfc7f7610 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:14:43.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3919" for this suite.
Jun 13 10:14:49.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:14:49.524: INFO: namespace projected-3919 deletion completed in 6.144317289s

• [SLOW TEST:10.247 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:14:49.525: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Jun 13 10:14:49.575: INFO: Waiting up to 5m0s for pod "var-expansion-65c37872-0474-447c-a05e-41114f853be9" in namespace "var-expansion-2573" to be "success or failure"
Jun 13 10:14:49.578: INFO: Pod "var-expansion-65c37872-0474-447c-a05e-41114f853be9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.694943ms
Jun 13 10:14:51.583: INFO: Pod "var-expansion-65c37872-0474-447c-a05e-41114f853be9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008050856s
STEP: Saw pod success
Jun 13 10:14:51.583: INFO: Pod "var-expansion-65c37872-0474-447c-a05e-41114f853be9" satisfied condition "success or failure"
Jun 13 10:14:51.586: INFO: Trying to get logs from node 10.0.10.2 pod var-expansion-65c37872-0474-447c-a05e-41114f853be9 container dapi-container: <nil>
STEP: delete the pod
Jun 13 10:14:51.613: INFO: Waiting for pod var-expansion-65c37872-0474-447c-a05e-41114f853be9 to disappear
Jun 13 10:14:51.618: INFO: Pod var-expansion-65c37872-0474-447c-a05e-41114f853be9 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:14:51.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-2573" for this suite.
Jun 13 10:14:57.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:14:57.760: INFO: namespace var-expansion-2573 deletion completed in 6.135349969s

• [SLOW TEST:8.235 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:14:57.760: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:15:28.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-2502" for this suite.
Jun 13 10:15:34.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:15:35.052: INFO: namespace namespaces-2502 deletion completed in 6.141558248s
STEP: Destroying namespace "nsdeletetest-3438" for this suite.
Jun 13 10:15:35.055: INFO: Namespace nsdeletetest-3438 was already deleted
STEP: Destroying namespace "nsdeletetest-3296" for this suite.
Jun 13 10:15:41.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:15:41.196: INFO: namespace nsdeletetest-3296 deletion completed in 6.140579489s

• [SLOW TEST:43.436 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:15:41.196: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-1882034e-8d38-42c3-8fde-81387c4b2ad1
STEP: Creating secret with name s-test-opt-upd-5c92deb6-c430-4395-8b9a-29bdea8e11c6
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-1882034e-8d38-42c3-8fde-81387c4b2ad1
STEP: Updating secret s-test-opt-upd-5c92deb6-c430-4395-8b9a-29bdea8e11c6
STEP: Creating secret with name s-test-opt-create-15d60487-a8f9-4220-aa82-b02883267e01
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:17:13.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-877" for this suite.
Jun 13 10:17:25.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:17:25.593: INFO: namespace secrets-877 deletion completed in 12.141714894s

• [SLOW TEST:104.397 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:17:25.593: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Jun 13 10:17:25.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 create -f - --namespace=kubectl-691'
Jun 13 10:17:26.003: INFO: stderr: ""
Jun 13 10:17:26.003: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 13 10:17:26.003: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-691'
Jun 13 10:17:26.174: INFO: stderr: ""
Jun 13 10:17:26.174: INFO: stdout: "update-demo-nautilus-9x9ps update-demo-nautilus-v896k "
Jun 13 10:17:26.174: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-9x9ps -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-691'
Jun 13 10:17:26.316: INFO: stderr: ""
Jun 13 10:17:26.316: INFO: stdout: ""
Jun 13 10:17:26.316: INFO: update-demo-nautilus-9x9ps is created but not running
Jun 13 10:17:31.316: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-691'
Jun 13 10:17:31.407: INFO: stderr: ""
Jun 13 10:17:31.407: INFO: stdout: "update-demo-nautilus-9x9ps update-demo-nautilus-v896k "
Jun 13 10:17:31.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-9x9ps -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-691'
Jun 13 10:17:31.527: INFO: stderr: ""
Jun 13 10:17:31.527: INFO: stdout: "true"
Jun 13 10:17:31.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-9x9ps -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-691'
Jun 13 10:17:31.618: INFO: stderr: ""
Jun 13 10:17:31.618: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 13 10:17:31.618: INFO: validating pod update-demo-nautilus-9x9ps
Jun 13 10:17:31.689: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 13 10:17:31.689: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 13 10:17:31.689: INFO: update-demo-nautilus-9x9ps is verified up and running
Jun 13 10:17:31.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-v896k -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-691'
Jun 13 10:17:31.798: INFO: stderr: ""
Jun 13 10:17:31.798: INFO: stdout: "true"
Jun 13 10:17:31.798: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-v896k -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-691'
Jun 13 10:17:31.887: INFO: stderr: ""
Jun 13 10:17:31.887: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 13 10:17:31.887: INFO: validating pod update-demo-nautilus-v896k
Jun 13 10:17:32.036: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 13 10:17:32.036: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 13 10:17:32.036: INFO: update-demo-nautilus-v896k is verified up and running
STEP: using delete to clean up resources
Jun 13 10:17:32.037: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 delete --grace-period=0 --force -f - --namespace=kubectl-691'
Jun 13 10:17:32.139: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 13 10:17:32.139: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Jun 13 10:17:32.140: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-691'
Jun 13 10:17:32.245: INFO: stderr: "No resources found in kubectl-691 namespace.\n"
Jun 13 10:17:32.245: INFO: stdout: ""
Jun 13 10:17:32.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods -l name=update-demo --namespace=kubectl-691 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 13 10:17:32.343: INFO: stderr: ""
Jun 13 10:17:32.344: INFO: stdout: "update-demo-nautilus-9x9ps\nupdate-demo-nautilus-v896k\n"
Jun 13 10:17:32.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-691'
Jun 13 10:17:32.973: INFO: stderr: "No resources found in kubectl-691 namespace.\n"
Jun 13 10:17:32.973: INFO: stdout: ""
Jun 13 10:17:32.974: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods -l name=update-demo --namespace=kubectl-691 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Jun 13 10:17:33.069: INFO: stderr: ""
Jun 13 10:17:33.069: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:17:33.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-691" for this suite.
Jun 13 10:18:01.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:18:01.219: INFO: namespace kubectl-691 deletion completed in 28.143841384s

• [SLOW TEST:35.626 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:18:01.226: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Jun 13 10:18:01.286: INFO: Waiting up to 5m0s for pod "var-expansion-b72c1cf3-b1cc-4d6b-850c-3ae48d00dc21" in namespace "var-expansion-3966" to be "success or failure"
Jun 13 10:18:01.293: INFO: Pod "var-expansion-b72c1cf3-b1cc-4d6b-850c-3ae48d00dc21": Phase="Pending", Reason="", readiness=false. Elapsed: 7.086269ms
Jun 13 10:18:03.297: INFO: Pod "var-expansion-b72c1cf3-b1cc-4d6b-850c-3ae48d00dc21": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.011253565s
STEP: Saw pod success
Jun 13 10:18:03.297: INFO: Pod "var-expansion-b72c1cf3-b1cc-4d6b-850c-3ae48d00dc21" satisfied condition "success or failure"
Jun 13 10:18:03.301: INFO: Trying to get logs from node 10.0.10.2 pod var-expansion-b72c1cf3-b1cc-4d6b-850c-3ae48d00dc21 container dapi-container: <nil>
STEP: delete the pod
Jun 13 10:18:03.325: INFO: Waiting for pod var-expansion-b72c1cf3-b1cc-4d6b-850c-3ae48d00dc21 to disappear
Jun 13 10:18:03.328: INFO: Pod var-expansion-b72c1cf3-b1cc-4d6b-850c-3ae48d00dc21 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:18:03.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3966" for this suite.
Jun 13 10:18:09.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:18:09.471: INFO: namespace var-expansion-3966 deletion completed in 6.138341413s

• [SLOW TEST:8.244 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:18:09.473: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 13 10:18:09.978: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jun 13 10:18:11.992: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727640289, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727640289, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727640290, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727640289, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 13 10:18:15.012: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 10:18:15.017: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9485-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:18:16.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2961" for this suite.
Jun 13 10:18:22.266: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:18:22.410: INFO: namespace webhook-2961 deletion completed in 6.170582375s
STEP: Destroying namespace "webhook-2961-markers" for this suite.
Jun 13 10:18:28.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:18:28.562: INFO: namespace webhook-2961-markers deletion completed in 6.152074747s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.112 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:18:28.585: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 10:18:28.625: INFO: Creating deployment "test-recreate-deployment"
Jun 13 10:18:28.631: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Jun 13 10:18:28.649: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Jun 13 10:18:30.659: INFO: Waiting deployment "test-recreate-deployment" to complete
Jun 13 10:18:30.663: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Jun 13 10:18:30.674: INFO: Updating deployment test-recreate-deployment
Jun 13 10:18:30.674: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Jun 13 10:18:30.742: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-2110 /apis/apps/v1/namespaces/deployment-2110/deployments/test-recreate-deployment 206a8720-7b9f-4f5d-abc3-248a3bd6116b 93628 2 2020-06-13 10:18:28 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0035d8718 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-06-13 10:18:30 +0000 UTC,LastTransitionTime:2020-06-13 10:18:30 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2020-06-13 10:18:30 +0000 UTC,LastTransitionTime:2020-06-13 10:18:28 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Jun 13 10:18:30.748: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-2110 /apis/apps/v1/namespaces/deployment-2110/replicasets/test-recreate-deployment-5f94c574ff d2ba742f-8e78-4c15-9fb6-bb5344e6083e 93626 1 2020-06-13 10:18:30 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 206a8720-7b9f-4f5d-abc3-248a3bd6116b 0xc0035d8ce7 0xc0035d8ce8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0035d8d78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jun 13 10:18:30.748: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Jun 13 10:18:30.748: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-2110 /apis/apps/v1/namespaces/deployment-2110/replicasets/test-recreate-deployment-68fc85c7bb b5f2c9e4-b776-4b8a-b050-28348e85eea8 93616 2 2020-06-13 10:18:28 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 206a8720-7b9f-4f5d-abc3-248a3bd6116b 0xc0035d8e87 0xc0035d8e88}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0035d8f88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jun 13 10:18:30.752: INFO: Pod "test-recreate-deployment-5f94c574ff-6pfpb" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-6pfpb test-recreate-deployment-5f94c574ff- deployment-2110 /api/v1/namespaces/deployment-2110/pods/test-recreate-deployment-5f94c574ff-6pfpb b5286a8d-d749-4e13-bf79-ad4bbf688c69 93629 0 2020-06-13 10:18:30 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff d2ba742f-8e78-4c15-9fb6-bb5344e6083e 0xc003633b47 0xc003633b48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8qcwl,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8qcwl,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8qcwl,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 10:18:30 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 10:18:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 10:18:30 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 10:18:30 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.10.2,PodIP:,StartTime:2020-06-13 10:18:30 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:18:30.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2110" for this suite.
Jun 13 10:18:36.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:18:36.894: INFO: namespace deployment-2110 deletion completed in 6.134943847s

• [SLOW TEST:8.310 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:18:36.896: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Jun 13 10:18:40.983: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 13 10:18:40.988: INFO: Pod pod-with-prestop-http-hook still exists
Jun 13 10:18:42.988: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 13 10:18:42.993: INFO: Pod pod-with-prestop-http-hook still exists
Jun 13 10:18:44.988: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Jun 13 10:18:44.993: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:18:45.007: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6850" for this suite.
Jun 13 10:18:57.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:18:57.159: INFO: namespace container-lifecycle-hook-6850 deletion completed in 12.146951644s

• [SLOW TEST:20.263 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:18:57.160: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-4xtx
STEP: Creating a pod to test atomic-volume-subpath
Jun 13 10:18:57.224: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-4xtx" in namespace "subpath-4151" to be "success or failure"
Jun 13 10:18:57.228: INFO: Pod "pod-subpath-test-secret-4xtx": Phase="Pending", Reason="", readiness=false. Elapsed: 3.895371ms
Jun 13 10:18:59.232: INFO: Pod "pod-subpath-test-secret-4xtx": Phase="Running", Reason="", readiness=true. Elapsed: 2.007802549s
Jun 13 10:19:01.236: INFO: Pod "pod-subpath-test-secret-4xtx": Phase="Running", Reason="", readiness=true. Elapsed: 4.012062728s
Jun 13 10:19:03.240: INFO: Pod "pod-subpath-test-secret-4xtx": Phase="Running", Reason="", readiness=true. Elapsed: 6.01648478s
Jun 13 10:19:05.245: INFO: Pod "pod-subpath-test-secret-4xtx": Phase="Running", Reason="", readiness=true. Elapsed: 8.021325905s
Jun 13 10:19:07.251: INFO: Pod "pod-subpath-test-secret-4xtx": Phase="Running", Reason="", readiness=true. Elapsed: 10.026946744s
Jun 13 10:19:09.255: INFO: Pod "pod-subpath-test-secret-4xtx": Phase="Running", Reason="", readiness=true. Elapsed: 12.031297617s
Jun 13 10:19:11.260: INFO: Pod "pod-subpath-test-secret-4xtx": Phase="Running", Reason="", readiness=true. Elapsed: 14.035957424s
Jun 13 10:19:13.265: INFO: Pod "pod-subpath-test-secret-4xtx": Phase="Running", Reason="", readiness=true. Elapsed: 16.040597034s
Jun 13 10:19:15.269: INFO: Pod "pod-subpath-test-secret-4xtx": Phase="Running", Reason="", readiness=true. Elapsed: 18.044891774s
Jun 13 10:19:17.273: INFO: Pod "pod-subpath-test-secret-4xtx": Phase="Running", Reason="", readiness=true. Elapsed: 20.049249399s
Jun 13 10:19:19.281: INFO: Pod "pod-subpath-test-secret-4xtx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.057107551s
STEP: Saw pod success
Jun 13 10:19:19.281: INFO: Pod "pod-subpath-test-secret-4xtx" satisfied condition "success or failure"
Jun 13 10:19:19.287: INFO: Trying to get logs from node 10.0.10.2 pod pod-subpath-test-secret-4xtx container test-container-subpath-secret-4xtx: <nil>
STEP: delete the pod
Jun 13 10:19:19.360: INFO: Waiting for pod pod-subpath-test-secret-4xtx to disappear
Jun 13 10:19:19.363: INFO: Pod pod-subpath-test-secret-4xtx no longer exists
STEP: Deleting pod pod-subpath-test-secret-4xtx
Jun 13 10:19:19.364: INFO: Deleting pod "pod-subpath-test-secret-4xtx" in namespace "subpath-4151"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:19:19.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4151" for this suite.
Jun 13 10:19:25.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:19:25.508: INFO: namespace subpath-4151 deletion completed in 6.137031635s

• [SLOW TEST:28.349 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:19:25.509: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Jun 13 10:19:25.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-3428 -- logs-generator --log-lines-total 100 --run-duration 20s'
Jun 13 10:19:25.698: INFO: stderr: ""
Jun 13 10:19:25.698: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Jun 13 10:19:25.698: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Jun 13 10:19:25.698: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-3428" to be "running and ready, or succeeded"
Jun 13 10:19:25.702: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.521306ms
Jun 13 10:19:27.707: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.009063025s
Jun 13 10:19:27.707: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Jun 13 10:19:27.707: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Jun 13 10:19:27.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 logs logs-generator logs-generator --namespace=kubectl-3428'
Jun 13 10:19:27.955: INFO: stderr: ""
Jun 13 10:19:27.955: INFO: stdout: "I0613 10:19:26.678499       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/x4db 577\nI0613 10:19:26.878636       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/klbg 466\nI0613 10:19:27.078641       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/plmb 557\nI0613 10:19:27.278641       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/dh2r 222\nI0613 10:19:27.478632       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/qj5 280\nI0613 10:19:27.678636       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/9nk 526\nI0613 10:19:27.878640       1 logs_generator.go:76] 6 POST /api/v1/namespaces/default/pods/4l96 596\n"
STEP: limiting log lines
Jun 13 10:19:27.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 logs logs-generator logs-generator --namespace=kubectl-3428 --tail=1'
Jun 13 10:19:28.136: INFO: stderr: ""
Jun 13 10:19:28.136: INFO: stdout: "I0613 10:19:28.078643       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/jfl 420\n"
STEP: limiting log bytes
Jun 13 10:19:28.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 logs logs-generator logs-generator --namespace=kubectl-3428 --limit-bytes=1'
Jun 13 10:19:28.238: INFO: stderr: ""
Jun 13 10:19:28.238: INFO: stdout: "I"
STEP: exposing timestamps
Jun 13 10:19:28.238: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 logs logs-generator logs-generator --namespace=kubectl-3428 --tail=1 --timestamps'
Jun 13 10:19:28.345: INFO: stderr: ""
Jun 13 10:19:28.345: INFO: stdout: "2020-06-13T10:19:28.278787552Z I0613 10:19:28.278643       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/tzv9 377\n"
STEP: restricting to a time range
Jun 13 10:19:30.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 logs logs-generator logs-generator --namespace=kubectl-3428 --since=1s'
Jun 13 10:19:30.949: INFO: stderr: ""
Jun 13 10:19:30.949: INFO: stdout: "I0613 10:19:30.078661       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/5kml 446\nI0613 10:19:30.278646       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/q4s 308\nI0613 10:19:30.478643       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/kjfg 404\nI0613 10:19:30.678639       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/vrff 360\nI0613 10:19:30.878635       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/ns/pods/zrn 280\n"
Jun 13 10:19:30.949: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 logs logs-generator logs-generator --namespace=kubectl-3428 --since=24h'
Jun 13 10:19:31.056: INFO: stderr: ""
Jun 13 10:19:31.056: INFO: stdout: "I0613 10:19:26.678499       1 logs_generator.go:76] 0 GET /api/v1/namespaces/kube-system/pods/x4db 577\nI0613 10:19:26.878636       1 logs_generator.go:76] 1 PUT /api/v1/namespaces/kube-system/pods/klbg 466\nI0613 10:19:27.078641       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/plmb 557\nI0613 10:19:27.278641       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/dh2r 222\nI0613 10:19:27.478632       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/qj5 280\nI0613 10:19:27.678636       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/9nk 526\nI0613 10:19:27.878640       1 logs_generator.go:76] 6 POST /api/v1/namespaces/default/pods/4l96 596\nI0613 10:19:28.078643       1 logs_generator.go:76] 7 GET /api/v1/namespaces/ns/pods/jfl 420\nI0613 10:19:28.278643       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/tzv9 377\nI0613 10:19:28.478643       1 logs_generator.go:76] 9 POST /api/v1/namespaces/ns/pods/x2x 349\nI0613 10:19:28.678645       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/m4b4 520\nI0613 10:19:28.878642       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/vd8 336\nI0613 10:19:29.078649       1 logs_generator.go:76] 12 POST /api/v1/namespaces/kube-system/pods/4cn5 447\nI0613 10:19:29.278640       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/ltvp 356\nI0613 10:19:29.478650       1 logs_generator.go:76] 14 POST /api/v1/namespaces/ns/pods/qcp 435\nI0613 10:19:29.678639       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/6nwb 381\nI0613 10:19:29.878638       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/mpr 368\nI0613 10:19:30.078661       1 logs_generator.go:76] 17 GET /api/v1/namespaces/default/pods/5kml 446\nI0613 10:19:30.278646       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/q4s 308\nI0613 10:19:30.478643       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/kjfg 404\nI0613 10:19:30.678639       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/vrff 360\nI0613 10:19:30.878635       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/ns/pods/zrn 280\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Jun 13 10:19:31.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 delete pod logs-generator --namespace=kubectl-3428'
Jun 13 10:19:32.533: INFO: stderr: ""
Jun 13 10:19:32.533: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:19:32.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3428" for this suite.
Jun 13 10:19:38.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:19:38.679: INFO: namespace kubectl-3428 deletion completed in 6.142004199s

• [SLOW TEST:13.170 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:19:38.679: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 13 10:19:39.116: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jun 13 10:19:41.130: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727640379, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727640379, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727640379, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727640379, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 13 10:19:44.146: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 10:19:44.151: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1438-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:19:45.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9485" for this suite.
Jun 13 10:19:51.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:19:51.876: INFO: namespace webhook-9485 deletion completed in 6.321429951s
STEP: Destroying namespace "webhook-9485-markers" for this suite.
Jun 13 10:19:57.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:19:58.011: INFO: namespace webhook-9485-markers deletion completed in 6.13433901s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.353 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:19:58.033: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Jun 13 10:19:58.106: INFO: Number of nodes with available pods: 0
Jun 13 10:19:58.106: INFO: Node 10.0.10.2 is running more than one daemon pod
Jun 13 10:19:59.115: INFO: Number of nodes with available pods: 0
Jun 13 10:19:59.115: INFO: Node 10.0.10.2 is running more than one daemon pod
Jun 13 10:20:00.117: INFO: Number of nodes with available pods: 1
Jun 13 10:20:00.117: INFO: Node 10.0.10.3 is running more than one daemon pod
Jun 13 10:20:01.116: INFO: Number of nodes with available pods: 2
Jun 13 10:20:01.116: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Jun 13 10:20:01.140: INFO: Number of nodes with available pods: 1
Jun 13 10:20:01.140: INFO: Node 10.0.10.3 is running more than one daemon pod
Jun 13 10:20:02.151: INFO: Number of nodes with available pods: 1
Jun 13 10:20:02.151: INFO: Node 10.0.10.3 is running more than one daemon pod
Jun 13 10:20:03.150: INFO: Number of nodes with available pods: 1
Jun 13 10:20:03.150: INFO: Node 10.0.10.3 is running more than one daemon pod
Jun 13 10:20:04.150: INFO: Number of nodes with available pods: 1
Jun 13 10:20:04.150: INFO: Node 10.0.10.3 is running more than one daemon pod
Jun 13 10:20:05.150: INFO: Number of nodes with available pods: 1
Jun 13 10:20:05.150: INFO: Node 10.0.10.3 is running more than one daemon pod
Jun 13 10:20:06.150: INFO: Number of nodes with available pods: 1
Jun 13 10:20:06.150: INFO: Node 10.0.10.3 is running more than one daemon pod
Jun 13 10:20:07.149: INFO: Number of nodes with available pods: 2
Jun 13 10:20:07.149: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1978, will wait for the garbage collector to delete the pods
Jun 13 10:20:07.220: INFO: Deleting DaemonSet.extensions daemon-set took: 11.164782ms
Jun 13 10:20:07.320: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.240317ms
Jun 13 10:20:13.524: INFO: Number of nodes with available pods: 0
Jun 13 10:20:13.525: INFO: Number of running nodes: 0, number of available pods: 0
Jun 13 10:20:13.528: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1978/daemonsets","resourceVersion":"94195"},"items":null}

Jun 13 10:20:13.532: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1978/pods","resourceVersion":"94195"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:20:13.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1978" for this suite.
Jun 13 10:20:19.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:20:19.699: INFO: namespace daemonsets-1978 deletion completed in 6.149822496s

• [SLOW TEST:21.666 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:20:19.700: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W0613 10:20:29.782530      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 13 10:20:29.782: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:20:29.782: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4118" for this suite.
Jun 13 10:20:35.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:20:35.933: INFO: namespace gc-4118 deletion completed in 6.146149321s

• [SLOW TEST:16.233 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:20:35.935: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 10:20:38.018: INFO: Waiting up to 5m0s for pod "client-envvars-87250ee1-8a00-40d2-8b0d-e29ed01899dc" in namespace "pods-4470" to be "success or failure"
Jun 13 10:20:38.022: INFO: Pod "client-envvars-87250ee1-8a00-40d2-8b0d-e29ed01899dc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.24615ms
Jun 13 10:20:40.029: INFO: Pod "client-envvars-87250ee1-8a00-40d2-8b0d-e29ed01899dc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010810059s
STEP: Saw pod success
Jun 13 10:20:40.029: INFO: Pod "client-envvars-87250ee1-8a00-40d2-8b0d-e29ed01899dc" satisfied condition "success or failure"
Jun 13 10:20:40.034: INFO: Trying to get logs from node 10.0.10.2 pod client-envvars-87250ee1-8a00-40d2-8b0d-e29ed01899dc container env3cont: <nil>
STEP: delete the pod
Jun 13 10:20:40.058: INFO: Waiting for pod client-envvars-87250ee1-8a00-40d2-8b0d-e29ed01899dc to disappear
Jun 13 10:20:40.063: INFO: Pod client-envvars-87250ee1-8a00-40d2-8b0d-e29ed01899dc no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:20:40.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4470" for this suite.
Jun 13 10:20:52.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:20:52.208: INFO: namespace pods-4470 deletion completed in 12.139358742s

• [SLOW TEST:16.273 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:20:52.209: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Jun 13 10:20:52.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 create -f - --namespace=kubectl-8191'
Jun 13 10:20:52.550: INFO: stderr: ""
Jun 13 10:20:52.550: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Jun 13 10:20:53.556: INFO: Selector matched 1 pods for map[app:redis]
Jun 13 10:20:53.556: INFO: Found 0 / 1
Jun 13 10:20:54.555: INFO: Selector matched 1 pods for map[app:redis]
Jun 13 10:20:54.555: INFO: Found 1 / 1
Jun 13 10:20:54.555: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Jun 13 10:20:54.559: INFO: Selector matched 1 pods for map[app:redis]
Jun 13 10:20:54.559: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Jun 13 10:20:54.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 patch pod redis-master-lbknz --namespace=kubectl-8191 -p {"metadata":{"annotations":{"x":"y"}}}'
Jun 13 10:20:54.664: INFO: stderr: ""
Jun 13 10:20:54.664: INFO: stdout: "pod/redis-master-lbknz patched\n"
STEP: checking annotations
Jun 13 10:20:54.669: INFO: Selector matched 1 pods for map[app:redis]
Jun 13 10:20:54.669: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:20:54.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8191" for this suite.
Jun 13 10:21:06.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:21:06.817: INFO: namespace kubectl-8191 deletion completed in 12.14376094s

• [SLOW TEST:14.609 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:21:06.819: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 10:21:06.859: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Jun 13 10:21:09.842: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 --namespace=crd-publish-openapi-2738 create -f -'
Jun 13 10:21:10.457: INFO: stderr: ""
Jun 13 10:21:10.457: INFO: stdout: "e2e-test-crd-publish-openapi-2984-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Jun 13 10:21:10.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 --namespace=crd-publish-openapi-2738 delete e2e-test-crd-publish-openapi-2984-crds test-cr'
Jun 13 10:21:10.566: INFO: stderr: ""
Jun 13 10:21:10.566: INFO: stdout: "e2e-test-crd-publish-openapi-2984-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Jun 13 10:21:10.566: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 --namespace=crd-publish-openapi-2738 apply -f -'
Jun 13 10:21:10.901: INFO: stderr: ""
Jun 13 10:21:10.901: INFO: stdout: "e2e-test-crd-publish-openapi-2984-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Jun 13 10:21:10.901: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 --namespace=crd-publish-openapi-2738 delete e2e-test-crd-publish-openapi-2984-crds test-cr'
Jun 13 10:21:11.009: INFO: stderr: ""
Jun 13 10:21:11.009: INFO: stdout: "e2e-test-crd-publish-openapi-2984-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Jun 13 10:21:11.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 explain e2e-test-crd-publish-openapi-2984-crds'
Jun 13 10:21:11.253: INFO: stderr: ""
Jun 13 10:21:11.253: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2984-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:21:14.218: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2738" for this suite.
Jun 13 10:21:20.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:21:20.373: INFO: namespace crd-publish-openapi-2738 deletion completed in 6.14967067s

• [SLOW TEST:13.554 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:21:20.374: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-2swxb in namespace proxy-3190
I0613 10:21:20.434672      22 runners.go:184] Created replication controller with name: proxy-service-2swxb, namespace: proxy-3190, replica count: 1
I0613 10:21:21.487449      22 runners.go:184] proxy-service-2swxb Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0613 10:21:22.487713      22 runners.go:184] proxy-service-2swxb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0613 10:21:23.487922      22 runners.go:184] proxy-service-2swxb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0613 10:21:24.488142      22 runners.go:184] proxy-service-2swxb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0613 10:21:25.488336      22 runners.go:184] proxy-service-2swxb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0613 10:21:26.488562      22 runners.go:184] proxy-service-2swxb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0613 10:21:27.488769      22 runners.go:184] proxy-service-2swxb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0613 10:21:28.488980      22 runners.go:184] proxy-service-2swxb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0613 10:21:29.489165      22 runners.go:184] proxy-service-2swxb Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0613 10:21:30.489359      22 runners.go:184] proxy-service-2swxb Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jun 13 10:21:30.494: INFO: setup took 10.079571262s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Jun 13 10:21:30.623: INFO: (0) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname2/proxy/: bar (200; 127.934126ms)
Jun 13 10:21:30.636: INFO: (0) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 139.350017ms)
Jun 13 10:21:30.638: INFO: (0) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname2/proxy/: bar (200; 143.048477ms)
Jun 13 10:21:30.641: INFO: (0) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 143.760951ms)
Jun 13 10:21:30.646: INFO: (0) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 150.305971ms)
Jun 13 10:21:30.648: INFO: (0) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 150.80064ms)
Jun 13 10:21:30.650: INFO: (0) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname1/proxy/: foo (200; 153.709169ms)
Jun 13 10:21:30.652: INFO: (0) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname1/proxy/: foo (200; 155.642464ms)
Jun 13 10:21:30.680: INFO: (0) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname2/proxy/: tls qux (200; 182.322384ms)
Jun 13 10:21:30.680: INFO: (0) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:462/proxy/: tls qux (200; 183.669868ms)
Jun 13 10:21:30.683: INFO: (0) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:460/proxy/: tls baz (200; 183.33433ms)
Jun 13 10:21:30.683: INFO: (0) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname1/proxy/: tls baz (200; 186.63616ms)
Jun 13 10:21:30.685: INFO: (0) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/rewriteme">test</a> (200; 187.902243ms)
Jun 13 10:21:30.689: INFO: (0) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">test<... (200; 193.980447ms)
Jun 13 10:21:30.691: INFO: (0) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">... (200; 195.640841ms)
Jun 13 10:21:30.701: INFO: (0) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/tlsrewritem... (200; 204.261887ms)
Jun 13 10:21:30.707: INFO: (1) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 5.593409ms)
Jun 13 10:21:30.707: INFO: (1) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">... (200; 6.354225ms)
Jun 13 10:21:30.707: INFO: (1) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:460/proxy/: tls baz (200; 5.876718ms)
Jun 13 10:21:30.709: INFO: (1) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">test<... (200; 7.819166ms)
Jun 13 10:21:30.709: INFO: (1) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 8.035025ms)
Jun 13 10:21:30.709: INFO: (1) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/rewriteme">test</a> (200; 8.197692ms)
Jun 13 10:21:30.709: INFO: (1) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:462/proxy/: tls qux (200; 8.068378ms)
Jun 13 10:21:30.709: INFO: (1) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/tlsrewritem... (200; 7.820565ms)
Jun 13 10:21:30.709: INFO: (1) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 7.876442ms)
Jun 13 10:21:30.710: INFO: (1) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 8.098249ms)
Jun 13 10:21:30.710: INFO: (1) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname1/proxy/: tls baz (200; 9.332645ms)
Jun 13 10:21:30.710: INFO: (1) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname2/proxy/: tls qux (200; 8.748292ms)
Jun 13 10:21:30.711: INFO: (1) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname2/proxy/: bar (200; 9.588855ms)
Jun 13 10:21:30.711: INFO: (1) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname1/proxy/: foo (200; 10.023382ms)
Jun 13 10:21:30.713: INFO: (1) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname2/proxy/: bar (200; 12.042104ms)
Jun 13 10:21:30.714: INFO: (1) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname1/proxy/: foo (200; 12.430874ms)
Jun 13 10:21:30.722: INFO: (2) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 7.446332ms)
Jun 13 10:21:30.722: INFO: (2) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname2/proxy/: bar (200; 7.415006ms)
Jun 13 10:21:30.723: INFO: (2) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:460/proxy/: tls baz (200; 8.585015ms)
Jun 13 10:21:30.723: INFO: (2) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">test<... (200; 8.730115ms)
Jun 13 10:21:30.724: INFO: (2) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 9.082953ms)
Jun 13 10:21:30.725: INFO: (2) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 8.492097ms)
Jun 13 10:21:30.725: INFO: (2) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname2/proxy/: tls qux (200; 10.289025ms)
Jun 13 10:21:30.725: INFO: (2) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/rewriteme">test</a> (200; 8.409102ms)
Jun 13 10:21:30.725: INFO: (2) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">... (200; 8.401217ms)
Jun 13 10:21:30.726: INFO: (2) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname2/proxy/: bar (200; 11.491788ms)
Jun 13 10:21:30.726: INFO: (2) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/tlsrewritem... (200; 9.572429ms)
Jun 13 10:21:30.728: INFO: (2) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:462/proxy/: tls qux (200; 11.53273ms)
Jun 13 10:21:30.728: INFO: (2) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 11.692199ms)
Jun 13 10:21:30.728: INFO: (2) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname1/proxy/: tls baz (200; 12.047605ms)
Jun 13 10:21:30.729: INFO: (2) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname1/proxy/: foo (200; 12.270196ms)
Jun 13 10:21:30.732: INFO: (2) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname1/proxy/: foo (200; 17.274332ms)
Jun 13 10:21:30.738: INFO: (3) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/tlsrewritem... (200; 5.951326ms)
Jun 13 10:21:30.739: INFO: (3) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 6.214171ms)
Jun 13 10:21:30.740: INFO: (3) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">test<... (200; 8.069379ms)
Jun 13 10:21:30.740: INFO: (3) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:462/proxy/: tls qux (200; 7.563758ms)
Jun 13 10:21:30.740: INFO: (3) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/rewriteme">test</a> (200; 7.309718ms)
Jun 13 10:21:30.741: INFO: (3) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 7.661688ms)
Jun 13 10:21:30.741: INFO: (3) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">... (200; 7.35309ms)
Jun 13 10:21:30.741: INFO: (3) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:460/proxy/: tls baz (200; 8.141707ms)
Jun 13 10:21:30.743: INFO: (3) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 10.381133ms)
Jun 13 10:21:30.743: INFO: (3) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname1/proxy/: tls baz (200; 9.745024ms)
Jun 13 10:21:30.743: INFO: (3) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname2/proxy/: tls qux (200; 10.313909ms)
Jun 13 10:21:30.746: INFO: (3) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 13.143905ms)
Jun 13 10:21:30.747: INFO: (3) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname1/proxy/: foo (200; 14.548495ms)
Jun 13 10:21:30.750: INFO: (3) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname2/proxy/: bar (200; 16.168057ms)
Jun 13 10:21:30.750: INFO: (3) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname2/proxy/: bar (200; 16.38389ms)
Jun 13 10:21:30.750: INFO: (3) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname1/proxy/: foo (200; 16.306149ms)
Jun 13 10:21:30.760: INFO: (4) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">test<... (200; 9.812398ms)
Jun 13 10:21:30.760: INFO: (4) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/rewriteme">test</a> (200; 9.133568ms)
Jun 13 10:21:30.760: INFO: (4) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">... (200; 8.980964ms)
Jun 13 10:21:30.761: INFO: (4) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 10.763227ms)
Jun 13 10:21:30.762: INFO: (4) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/tlsrewritem... (200; 10.853816ms)
Jun 13 10:21:30.762: INFO: (4) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname1/proxy/: tls baz (200; 10.184013ms)
Jun 13 10:21:30.762: INFO: (4) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname2/proxy/: tls qux (200; 11.66376ms)
Jun 13 10:21:30.762: INFO: (4) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:460/proxy/: tls baz (200; 10.548619ms)
Jun 13 10:21:30.762: INFO: (4) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:462/proxy/: tls qux (200; 10.508058ms)
Jun 13 10:21:30.763: INFO: (4) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 11.795508ms)
Jun 13 10:21:30.764: INFO: (4) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname1/proxy/: foo (200; 13.643925ms)
Jun 13 10:21:30.769: INFO: (4) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname1/proxy/: foo (200; 18.269165ms)
Jun 13 10:21:30.774: INFO: (4) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 22.554788ms)
Jun 13 10:21:30.776: INFO: (4) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 24.924746ms)
Jun 13 10:21:30.778: INFO: (4) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname2/proxy/: bar (200; 27.588189ms)
Jun 13 10:21:30.780: INFO: (4) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname2/proxy/: bar (200; 28.996418ms)
Jun 13 10:21:30.790: INFO: (5) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/rewriteme">test</a> (200; 8.197805ms)
Jun 13 10:21:30.790: INFO: (5) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:460/proxy/: tls baz (200; 9.28464ms)
Jun 13 10:21:30.793: INFO: (5) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/tlsrewritem... (200; 11.272465ms)
Jun 13 10:21:30.793: INFO: (5) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 11.745661ms)
Jun 13 10:21:30.793: INFO: (5) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">test<... (200; 12.142462ms)
Jun 13 10:21:30.793: INFO: (5) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:462/proxy/: tls qux (200; 10.721072ms)
Jun 13 10:21:30.793: INFO: (5) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">... (200; 10.823014ms)
Jun 13 10:21:30.793: INFO: (5) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname2/proxy/: tls qux (200; 11.311129ms)
Jun 13 10:21:30.793: INFO: (5) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname1/proxy/: tls baz (200; 11.365406ms)
Jun 13 10:21:30.794: INFO: (5) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 12.513061ms)
Jun 13 10:21:30.796: INFO: (5) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 14.093083ms)
Jun 13 10:21:30.800: INFO: (5) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname1/proxy/: foo (200; 19.37784ms)
Jun 13 10:21:30.803: INFO: (5) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname1/proxy/: foo (200; 20.832506ms)
Jun 13 10:21:30.804: INFO: (5) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 22.299004ms)
Jun 13 10:21:30.822: INFO: (5) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname2/proxy/: bar (200; 39.708895ms)
Jun 13 10:21:30.836: INFO: (5) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname2/proxy/: bar (200; 54.125644ms)
Jun 13 10:21:30.849: INFO: (6) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:462/proxy/: tls qux (200; 12.917753ms)
Jun 13 10:21:30.853: INFO: (6) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname1/proxy/: tls baz (200; 15.765221ms)
Jun 13 10:21:30.853: INFO: (6) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:460/proxy/: tls baz (200; 16.391306ms)
Jun 13 10:21:30.856: INFO: (6) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 19.03281ms)
Jun 13 10:21:30.856: INFO: (6) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">test<... (200; 19.645566ms)
Jun 13 10:21:30.856: INFO: (6) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">... (200; 19.158205ms)
Jun 13 10:21:30.856: INFO: (6) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname2/proxy/: tls qux (200; 19.217813ms)
Jun 13 10:21:30.856: INFO: (6) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/tlsrewritem... (200; 19.233652ms)
Jun 13 10:21:30.856: INFO: (6) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/rewriteme">test</a> (200; 19.211138ms)
Jun 13 10:21:30.860: INFO: (6) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 22.591262ms)
Jun 13 10:21:30.861: INFO: (6) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 23.778757ms)
Jun 13 10:21:30.865: INFO: (6) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname2/proxy/: bar (200; 28.28055ms)
Jun 13 10:21:30.868: INFO: (6) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname2/proxy/: bar (200; 31.603994ms)
Jun 13 10:21:30.870: INFO: (6) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 33.87268ms)
Jun 13 10:21:30.881: INFO: (6) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname1/proxy/: foo (200; 43.991609ms)
Jun 13 10:21:30.885: INFO: (6) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname1/proxy/: foo (200; 49.048712ms)
Jun 13 10:21:30.900: INFO: (7) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 12.7662ms)
Jun 13 10:21:30.901: INFO: (7) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">test<... (200; 12.602064ms)
Jun 13 10:21:30.901: INFO: (7) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:460/proxy/: tls baz (200; 14.460938ms)
Jun 13 10:21:30.901: INFO: (7) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">... (200; 14.05146ms)
Jun 13 10:21:30.901: INFO: (7) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:462/proxy/: tls qux (200; 14.459244ms)
Jun 13 10:21:30.901: INFO: (7) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/tlsrewritem... (200; 15.415915ms)
Jun 13 10:21:30.901: INFO: (7) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/rewriteme">test</a> (200; 15.297848ms)
Jun 13 10:21:30.905: INFO: (7) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 18.811707ms)
Jun 13 10:21:30.905: INFO: (7) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 16.951001ms)
Jun 13 10:21:30.905: INFO: (7) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname2/proxy/: tls qux (200; 19.541369ms)
Jun 13 10:21:30.907: INFO: (7) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname1/proxy/: tls baz (200; 16.127649ms)
Jun 13 10:21:30.910: INFO: (7) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname1/proxy/: foo (200; 23.008004ms)
Jun 13 10:21:30.911: INFO: (7) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname1/proxy/: foo (200; 23.744392ms)
Jun 13 10:21:30.914: INFO: (7) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 23.681474ms)
Jun 13 10:21:30.921: INFO: (7) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname2/proxy/: bar (200; 34.526042ms)
Jun 13 10:21:30.939: INFO: (7) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname2/proxy/: bar (200; 52.441898ms)
Jun 13 10:21:30.954: INFO: (8) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 13.623965ms)
Jun 13 10:21:30.959: INFO: (8) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 18.940659ms)
Jun 13 10:21:30.961: INFO: (8) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/rewriteme">test</a> (200; 20.998685ms)
Jun 13 10:21:30.962: INFO: (8) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 22.742909ms)
Jun 13 10:21:30.963: INFO: (8) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">test<... (200; 23.26198ms)
Jun 13 10:21:30.965: INFO: (8) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname1/proxy/: foo (200; 25.996743ms)
Jun 13 10:21:30.965: INFO: (8) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname1/proxy/: tls baz (200; 26.044069ms)
Jun 13 10:21:30.966: INFO: (8) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">... (200; 24.596371ms)
Jun 13 10:21:30.966: INFO: (8) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname2/proxy/: tls qux (200; 25.791383ms)
Jun 13 10:21:30.966: INFO: (8) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:460/proxy/: tls baz (200; 25.322088ms)
Jun 13 10:21:30.966: INFO: (8) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:462/proxy/: tls qux (200; 25.706222ms)
Jun 13 10:21:30.966: INFO: (8) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname2/proxy/: bar (200; 25.446372ms)
Jun 13 10:21:30.966: INFO: (8) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/tlsrewritem... (200; 26.382601ms)
Jun 13 10:21:30.968: INFO: (8) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname2/proxy/: bar (200; 27.168057ms)
Jun 13 10:21:30.969: INFO: (8) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 28.019084ms)
Jun 13 10:21:30.972: INFO: (8) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname1/proxy/: foo (200; 32.400938ms)
Jun 13 10:21:30.984: INFO: (9) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname2/proxy/: bar (200; 12.236879ms)
Jun 13 10:21:30.985: INFO: (9) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:460/proxy/: tls baz (200; 12.451671ms)
Jun 13 10:21:30.985: INFO: (9) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname2/proxy/: bar (200; 13.068549ms)
Jun 13 10:21:30.988: INFO: (9) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:462/proxy/: tls qux (200; 15.094283ms)
Jun 13 10:21:30.988: INFO: (9) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 15.54526ms)
Jun 13 10:21:30.989: INFO: (9) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/rewriteme">test</a> (200; 13.884403ms)
Jun 13 10:21:30.989: INFO: (9) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname1/proxy/: tls baz (200; 15.141151ms)
Jun 13 10:21:30.989: INFO: (9) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">... (200; 16.627778ms)
Jun 13 10:21:30.989: INFO: (9) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname2/proxy/: tls qux (200; 14.587955ms)
Jun 13 10:21:30.989: INFO: (9) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">test<... (200; 15.430729ms)
Jun 13 10:21:30.989: INFO: (9) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/tlsrewritem... (200; 14.864276ms)
Jun 13 10:21:30.991: INFO: (9) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 16.923284ms)
Jun 13 10:21:30.994: INFO: (9) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 19.873301ms)
Jun 13 10:21:30.996: INFO: (9) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 19.380622ms)
Jun 13 10:21:31.005: INFO: (9) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname1/proxy/: foo (200; 31.244021ms)
Jun 13 10:21:31.010: INFO: (9) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname1/proxy/: foo (200; 35.69173ms)
Jun 13 10:21:31.022: INFO: (10) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">... (200; 10.634344ms)
Jun 13 10:21:31.022: INFO: (10) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:460/proxy/: tls baz (200; 11.955002ms)
Jun 13 10:21:31.022: INFO: (10) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:462/proxy/: tls qux (200; 11.845263ms)
Jun 13 10:21:31.022: INFO: (10) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 10.974347ms)
Jun 13 10:21:31.023: INFO: (10) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">test<... (200; 9.747442ms)
Jun 13 10:21:31.026: INFO: (10) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 14.45203ms)
Jun 13 10:21:31.026: INFO: (10) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 13.994579ms)
Jun 13 10:21:31.026: INFO: (10) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname1/proxy/: tls baz (200; 12.696949ms)
Jun 13 10:21:31.026: INFO: (10) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname2/proxy/: tls qux (200; 13.968627ms)
Jun 13 10:21:31.027: INFO: (10) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname1/proxy/: foo (200; 13.732629ms)
Jun 13 10:21:31.029: INFO: (10) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname2/proxy/: bar (200; 18.026606ms)
Jun 13 10:21:31.031: INFO: (10) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/tlsrewritem... (200; 19.034437ms)
Jun 13 10:21:31.031: INFO: (10) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname1/proxy/: foo (200; 17.783577ms)
Jun 13 10:21:31.032: INFO: (10) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/rewriteme">test</a> (200; 19.509839ms)
Jun 13 10:21:31.039: INFO: (10) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname2/proxy/: bar (200; 28.54939ms)
Jun 13 10:21:31.040: INFO: (10) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 27.133403ms)
Jun 13 10:21:31.051: INFO: (11) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 10.771358ms)
Jun 13 10:21:31.051: INFO: (11) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:460/proxy/: tls baz (200; 11.298402ms)
Jun 13 10:21:31.054: INFO: (11) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">test<... (200; 13.088991ms)
Jun 13 10:21:31.054: INFO: (11) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:462/proxy/: tls qux (200; 13.13623ms)
Jun 13 10:21:31.054: INFO: (11) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname2/proxy/: tls qux (200; 13.756203ms)
Jun 13 10:21:31.054: INFO: (11) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname2/proxy/: bar (200; 13.860124ms)
Jun 13 10:21:31.055: INFO: (11) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/rewriteme">test</a> (200; 15.110936ms)
Jun 13 10:21:31.055: INFO: (11) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/tlsrewritem... (200; 14.180831ms)
Jun 13 10:21:31.056: INFO: (11) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 16.104077ms)
Jun 13 10:21:31.056: INFO: (11) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname1/proxy/: tls baz (200; 14.823043ms)
Jun 13 10:21:31.056: INFO: (11) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">... (200; 15.886592ms)
Jun 13 10:21:31.058: INFO: (11) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 17.254883ms)
Jun 13 10:21:31.059: INFO: (11) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 18.269631ms)
Jun 13 10:21:31.062: INFO: (11) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname1/proxy/: foo (200; 22.112399ms)
Jun 13 10:21:31.065: INFO: (11) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname1/proxy/: foo (200; 24.223029ms)
Jun 13 10:21:31.065: INFO: (11) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname2/proxy/: bar (200; 24.505148ms)
Jun 13 10:21:31.080: INFO: (12) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">... (200; 13.389019ms)
Jun 13 10:21:31.081: INFO: (12) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">test<... (200; 13.280011ms)
Jun 13 10:21:31.081: INFO: (12) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 15.212444ms)
Jun 13 10:21:31.085: INFO: (12) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:460/proxy/: tls baz (200; 17.343049ms)
Jun 13 10:21:31.085: INFO: (12) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 17.668015ms)
Jun 13 10:21:31.085: INFO: (12) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/rewriteme">test</a> (200; 17.571618ms)
Jun 13 10:21:31.085: INFO: (12) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/tlsrewritem... (200; 17.902331ms)
Jun 13 10:21:31.085: INFO: (12) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 17.803984ms)
Jun 13 10:21:31.085: INFO: (12) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:462/proxy/: tls qux (200; 19.031601ms)
Jun 13 10:21:31.085: INFO: (12) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname1/proxy/: tls baz (200; 18.332516ms)
Jun 13 10:21:31.085: INFO: (12) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname2/proxy/: tls qux (200; 17.709397ms)
Jun 13 10:21:31.089: INFO: (12) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname1/proxy/: foo (200; 21.565108ms)
Jun 13 10:21:31.093: INFO: (12) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname1/proxy/: foo (200; 24.97472ms)
Jun 13 10:21:31.093: INFO: (12) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname2/proxy/: bar (200; 26.809115ms)
Jun 13 10:21:31.101: INFO: (12) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname2/proxy/: bar (200; 34.051735ms)
Jun 13 10:21:31.104: INFO: (12) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 38.467062ms)
Jun 13 10:21:31.116: INFO: (13) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname2/proxy/: tls qux (200; 12.175038ms)
Jun 13 10:21:31.117: INFO: (13) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">test<... (200; 11.102282ms)
Jun 13 10:21:31.117: INFO: (13) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:462/proxy/: tls qux (200; 12.030092ms)
Jun 13 10:21:31.117: INFO: (13) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">... (200; 11.068708ms)
Jun 13 10:21:31.119: INFO: (13) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/tlsrewritem... (200; 15.113072ms)
Jun 13 10:21:31.119: INFO: (13) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname1/proxy/: tls baz (200; 14.099798ms)
Jun 13 10:21:31.119: INFO: (13) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 13.372329ms)
Jun 13 10:21:31.119: INFO: (13) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:460/proxy/: tls baz (200; 14.632772ms)
Jun 13 10:21:31.119: INFO: (13) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/rewriteme">test</a> (200; 14.963707ms)
Jun 13 10:21:31.119: INFO: (13) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 14.830097ms)
Jun 13 10:21:31.129: INFO: (13) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 23.114771ms)
Jun 13 10:21:31.132: INFO: (13) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname2/proxy/: bar (200; 27.190737ms)
Jun 13 10:21:31.134: INFO: (13) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname2/proxy/: bar (200; 29.011913ms)
Jun 13 10:21:31.140: INFO: (13) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 34.435626ms)
Jun 13 10:21:31.147: INFO: (13) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname1/proxy/: foo (200; 41.692253ms)
Jun 13 10:21:31.158: INFO: (13) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname1/proxy/: foo (200; 52.162247ms)
Jun 13 10:21:31.166: INFO: (14) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 6.998039ms)
Jun 13 10:21:31.167: INFO: (14) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 8.429155ms)
Jun 13 10:21:31.168: INFO: (14) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">test<... (200; 9.041216ms)
Jun 13 10:21:31.177: INFO: (14) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 17.770499ms)
Jun 13 10:21:31.180: INFO: (14) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname2/proxy/: bar (200; 20.417237ms)
Jun 13 10:21:31.182: INFO: (14) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname2/proxy/: bar (200; 22.914369ms)
Jun 13 10:21:31.183: INFO: (14) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">... (200; 23.904466ms)
Jun 13 10:21:31.189: INFO: (14) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 29.899097ms)
Jun 13 10:21:31.190: INFO: (14) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:462/proxy/: tls qux (200; 30.336276ms)
Jun 13 10:21:31.190: INFO: (14) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/rewriteme">test</a> (200; 30.572307ms)
Jun 13 10:21:31.190: INFO: (14) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/tlsrewritem... (200; 30.666333ms)
Jun 13 10:21:31.190: INFO: (14) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname2/proxy/: tls qux (200; 30.654958ms)
Jun 13 10:21:31.193: INFO: (14) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:460/proxy/: tls baz (200; 34.613752ms)
Jun 13 10:21:31.193: INFO: (14) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname1/proxy/: tls baz (200; 33.821098ms)
Jun 13 10:21:31.207: INFO: (14) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname1/proxy/: foo (200; 48.012797ms)
Jun 13 10:21:31.217: INFO: (14) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname1/proxy/: foo (200; 57.386549ms)
Jun 13 10:21:31.225: INFO: (15) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">test<... (200; 8.125488ms)
Jun 13 10:21:31.228: INFO: (15) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 10.755652ms)
Jun 13 10:21:31.233: INFO: (15) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/tlsrewritem... (200; 15.93082ms)
Jun 13 10:21:31.233: INFO: (15) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/rewriteme">test</a> (200; 15.248644ms)
Jun 13 10:21:31.233: INFO: (15) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:460/proxy/: tls baz (200; 15.61282ms)
Jun 13 10:21:31.233: INFO: (15) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 15.916052ms)
Jun 13 10:21:31.233: INFO: (15) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">... (200; 14.712685ms)
Jun 13 10:21:31.235: INFO: (15) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname2/proxy/: tls qux (200; 17.697616ms)
Jun 13 10:21:31.235: INFO: (15) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname1/proxy/: tls baz (200; 16.64113ms)
Jun 13 10:21:31.236: INFO: (15) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:462/proxy/: tls qux (200; 17.454479ms)
Jun 13 10:21:31.237: INFO: (15) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 19.461637ms)
Jun 13 10:21:31.237: INFO: (15) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 19.333553ms)
Jun 13 10:21:31.250: INFO: (15) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname2/proxy/: bar (200; 31.345334ms)
Jun 13 10:21:31.252: INFO: (15) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname1/proxy/: foo (200; 34.794915ms)
Jun 13 10:21:31.252: INFO: (15) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname2/proxy/: bar (200; 33.773872ms)
Jun 13 10:21:31.256: INFO: (15) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname1/proxy/: foo (200; 37.832636ms)
Jun 13 10:21:31.266: INFO: (16) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 8.170478ms)
Jun 13 10:21:31.267: INFO: (16) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 10.178346ms)
Jun 13 10:21:31.271: INFO: (16) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:460/proxy/: tls baz (200; 14.121551ms)
Jun 13 10:21:31.271: INFO: (16) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname1/proxy/: tls baz (200; 14.157263ms)
Jun 13 10:21:31.272: INFO: (16) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">... (200; 15.824445ms)
Jun 13 10:21:31.272: INFO: (16) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/rewriteme">test</a> (200; 15.131676ms)
Jun 13 10:21:31.272: INFO: (16) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/tlsrewritem... (200; 15.397345ms)
Jun 13 10:21:31.273: INFO: (16) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">test<... (200; 15.618541ms)
Jun 13 10:21:31.273: INFO: (16) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname2/proxy/: tls qux (200; 15.543166ms)
Jun 13 10:21:31.273: INFO: (16) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 15.141619ms)
Jun 13 10:21:31.273: INFO: (16) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:462/proxy/: tls qux (200; 15.352664ms)
Jun 13 10:21:31.275: INFO: (16) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname2/proxy/: bar (200; 17.905922ms)
Jun 13 10:21:31.276: INFO: (16) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 18.349527ms)
Jun 13 10:21:31.279: INFO: (16) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname1/proxy/: foo (200; 21.482171ms)
Jun 13 10:21:31.279: INFO: (16) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname2/proxy/: bar (200; 21.146407ms)
Jun 13 10:21:31.290: INFO: (16) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname1/proxy/: foo (200; 33.552507ms)
Jun 13 10:21:31.300: INFO: (17) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:460/proxy/: tls baz (200; 9.116601ms)
Jun 13 10:21:31.300: INFO: (17) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">test<... (200; 9.329369ms)
Jun 13 10:21:31.300: INFO: (17) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:462/proxy/: tls qux (200; 9.746963ms)
Jun 13 10:21:31.300: INFO: (17) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 9.389858ms)
Jun 13 10:21:31.302: INFO: (17) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 10.616304ms)
Jun 13 10:21:31.302: INFO: (17) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/tlsrewritem... (200; 10.693097ms)
Jun 13 10:21:31.302: INFO: (17) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/rewriteme">test</a> (200; 10.663561ms)
Jun 13 10:21:31.302: INFO: (17) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname2/proxy/: tls qux (200; 11.146257ms)
Jun 13 10:21:31.303: INFO: (17) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 11.442225ms)
Jun 13 10:21:31.303: INFO: (17) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">... (200; 12.209695ms)
Jun 13 10:21:31.306: INFO: (17) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 14.610912ms)
Jun 13 10:21:31.306: INFO: (17) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname1/proxy/: tls baz (200; 14.700968ms)
Jun 13 10:21:31.307: INFO: (17) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname1/proxy/: foo (200; 15.887536ms)
Jun 13 10:21:31.310: INFO: (17) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname1/proxy/: foo (200; 19.061145ms)
Jun 13 10:21:31.311: INFO: (17) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname2/proxy/: bar (200; 19.769559ms)
Jun 13 10:21:31.314: INFO: (17) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname2/proxy/: bar (200; 23.360179ms)
Jun 13 10:21:31.325: INFO: (18) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 9.469817ms)
Jun 13 10:21:31.325: INFO: (18) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/rewriteme">test</a> (200; 10.065394ms)
Jun 13 10:21:31.328: INFO: (18) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">... (200; 13.422747ms)
Jun 13 10:21:31.328: INFO: (18) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 13.619241ms)
Jun 13 10:21:31.328: INFO: (18) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/tlsrewritem... (200; 13.263282ms)
Jun 13 10:21:31.328: INFO: (18) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:462/proxy/: tls qux (200; 13.66259ms)
Jun 13 10:21:31.328: INFO: (18) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname1/proxy/: tls baz (200; 14.138567ms)
Jun 13 10:21:31.329: INFO: (18) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 14.525892ms)
Jun 13 10:21:31.330: INFO: (18) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:460/proxy/: tls baz (200; 15.182188ms)
Jun 13 10:21:31.331: INFO: (18) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname2/proxy/: tls qux (200; 15.451875ms)
Jun 13 10:21:31.331: INFO: (18) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">test<... (200; 15.430653ms)
Jun 13 10:21:31.339: INFO: (18) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname2/proxy/: bar (200; 24.459169ms)
Jun 13 10:21:31.341: INFO: (18) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 26.307591ms)
Jun 13 10:21:31.345: INFO: (18) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname1/proxy/: foo (200; 30.305996ms)
Jun 13 10:21:31.349: INFO: (18) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname2/proxy/: bar (200; 33.989337ms)
Jun 13 10:21:31.354: INFO: (18) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname1/proxy/: foo (200; 39.184033ms)
Jun 13 10:21:31.364: INFO: (19) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">test<... (200; 8.939659ms)
Jun 13 10:21:31.364: INFO: (19) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 9.662649ms)
Jun 13 10:21:31.365: INFO: (19) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:443/proxy/tlsrewritem... (200; 9.311463ms)
Jun 13 10:21:31.365: INFO: (19) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:460/proxy/: tls baz (200; 8.947234ms)
Jun 13 10:21:31.365: INFO: (19) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:1080/proxy/rewriteme">... (200; 9.438011ms)
Jun 13 10:21:31.365: INFO: (19) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/: <a href="/api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj/proxy/rewriteme">test</a> (200; 9.118342ms)
Jun 13 10:21:31.366: INFO: (19) /api/v1/namespaces/proxy-3190/pods/https:proxy-service-2swxb-p4fqj:462/proxy/: tls qux (200; 10.2285ms)
Jun 13 10:21:31.367: INFO: (19) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname1/proxy/: tls baz (200; 11.095043ms)
Jun 13 10:21:31.367: INFO: (19) /api/v1/namespaces/proxy-3190/pods/http:proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 11.69736ms)
Jun 13 10:21:31.368: INFO: (19) /api/v1/namespaces/proxy-3190/services/https:proxy-service-2swxb:tlsportname2/proxy/: tls qux (200; 12.873953ms)
Jun 13 10:21:31.372: INFO: (19) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:162/proxy/: bar (200; 15.992317ms)
Jun 13 10:21:31.375: INFO: (19) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname2/proxy/: bar (200; 19.972412ms)
Jun 13 10:21:31.375: INFO: (19) /api/v1/namespaces/proxy-3190/pods/proxy-service-2swxb-p4fqj:160/proxy/: foo (200; 19.725089ms)
Jun 13 10:21:31.379: INFO: (19) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname2/proxy/: bar (200; 23.449371ms)
Jun 13 10:21:31.380: INFO: (19) /api/v1/namespaces/proxy-3190/services/http:proxy-service-2swxb:portname1/proxy/: foo (200; 25.541058ms)
Jun 13 10:21:31.389: INFO: (19) /api/v1/namespaces/proxy-3190/services/proxy-service-2swxb:portname1/proxy/: foo (200; 33.118533ms)
STEP: deleting ReplicationController proxy-service-2swxb in namespace proxy-3190, will wait for the garbage collector to delete the pods
Jun 13 10:21:31.471: INFO: Deleting ReplicationController proxy-service-2swxb took: 24.773479ms
Jun 13 10:21:31.771: INFO: Terminating ReplicationController proxy-service-2swxb pods took: 300.335367ms
[AfterEach] version v1
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:21:44.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-3190" for this suite.
Jun 13 10:21:50.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:21:50.623: INFO: namespace proxy-3190 deletion completed in 6.145224603s

• [SLOW TEST:30.249 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:21:50.623: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Jun 13 10:21:50.671: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun 13 10:21:50.685: INFO: Waiting for terminating namespaces to be deleted...
Jun 13 10:21:50.689: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.2 before test
Jun 13 10:21:50.701: INFO: csi-oci-node-4dfqn from kube-system started at 2020-06-13 03:16:54 +0000 UTC (1 container statuses recorded)
Jun 13 10:21:50.701: INFO: 	Container csi-node-driver ready: true, restart count 0
Jun 13 10:21:50.701: INFO: sonobuoy-systemd-logs-daemon-set-89d5b422bcff4ee4-jptvl from sonobuoy started at 2020-06-13 09:55:07 +0000 UTC (2 container statuses recorded)
Jun 13 10:21:50.701: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 13 10:21:50.701: INFO: 	Container systemd-logs ready: true, restart count 0
Jun 13 10:21:50.701: INFO: proxymux-client-hhdsr from kube-system started at 2020-06-13 03:16:54 +0000 UTC (1 container statuses recorded)
Jun 13 10:21:50.701: INFO: 	Container proxymux-client ready: true, restart count 0
Jun 13 10:21:50.701: INFO: kube-flannel-ds-mddmt from kube-system started at 2020-06-13 03:16:34 +0000 UTC (1 container statuses recorded)
Jun 13 10:21:50.701: INFO: 	Container kube-flannel ready: true, restart count 1
Jun 13 10:21:50.701: INFO: kube-proxy-mbpxz from kube-system started at 2020-06-13 03:16:34 +0000 UTC (1 container statuses recorded)
Jun 13 10:21:50.701: INFO: 	Container kube-proxy ready: true, restart count 0
Jun 13 10:21:50.701: INFO: coredns-6f9ff9bd47-ctdhp from kube-system started at 2020-06-13 03:17:03 +0000 UTC (1 container statuses recorded)
Jun 13 10:21:50.701: INFO: 	Container coredns ready: true, restart count 0
Jun 13 10:21:50.703: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.3 before test
Jun 13 10:21:50.801: INFO: kube-flannel-ds-6cxw2 from kube-system started at 2020-06-13 03:16:34 +0000 UTC (1 container statuses recorded)
Jun 13 10:21:50.801: INFO: 	Container kube-flannel ready: true, restart count 1
Jun 13 10:21:50.801: INFO: proxymux-client-mshct from kube-system started at 2020-06-13 03:16:54 +0000 UTC (1 container statuses recorded)
Jun 13 10:21:50.801: INFO: 	Container proxymux-client ready: true, restart count 0
Jun 13 10:21:50.801: INFO: sonobuoy-e2e-job-eae45311abd24acb from sonobuoy started at 2020-06-13 09:55:07 +0000 UTC (2 container statuses recorded)
Jun 13 10:21:50.801: INFO: 	Container e2e ready: true, restart count 0
Jun 13 10:21:50.801: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 13 10:21:50.801: INFO: kubernetes-dashboard-56b6bf4bf-65jz6 from kube-system started at 2020-06-13 03:16:53 +0000 UTC (1 container statuses recorded)
Jun 13 10:21:50.801: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jun 13 10:21:50.801: INFO: kube-proxy-6vf8c from kube-system started at 2020-06-13 03:16:34 +0000 UTC (1 container statuses recorded)
Jun 13 10:21:50.801: INFO: 	Container kube-proxy ready: true, restart count 0
Jun 13 10:21:50.801: INFO: csi-oci-node-hhfs6 from kube-system started at 2020-06-13 03:16:54 +0000 UTC (1 container statuses recorded)
Jun 13 10:21:50.801: INFO: 	Container csi-node-driver ready: true, restart count 0
Jun 13 10:21:50.802: INFO: sonobuoy from sonobuoy started at 2020-06-13 09:55:05 +0000 UTC (1 container statuses recorded)
Jun 13 10:21:50.802: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun 13 10:21:50.802: INFO: sonobuoy-systemd-logs-daemon-set-89d5b422bcff4ee4-z5xtf from sonobuoy started at 2020-06-13 09:55:07 +0000 UTC (2 container statuses recorded)
Jun 13 10:21:50.802: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 13 10:21:50.802: INFO: 	Container systemd-logs ready: true, restart count 0
Jun 13 10:21:50.802: INFO: kube-dns-autoscaler-75565f7896-hm82m from kube-system started at 2020-06-13 03:17:03 +0000 UTC (1 container statuses recorded)
Jun 13 10:21:50.802: INFO: 	Container autoscaler ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.16181351eb219aab], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:21:51.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2355" for this suite.
Jun 13 10:21:57.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:21:57.990: INFO: namespace sched-pred-2355 deletion completed in 6.145160518s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.367 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:21:57.991: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Jun 13 10:21:58.043: INFO: Pod name pod-release: Found 0 pods out of 1
Jun 13 10:22:03.047: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:22:04.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6845" for this suite.
Jun 13 10:22:10.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:22:10.217: INFO: namespace replication-controller-6845 deletion completed in 6.145935529s

• [SLOW TEST:12.226 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:22:10.217: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 10:22:10.274: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Jun 13 10:22:15.278: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jun 13 10:22:15.279: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Jun 13 10:22:15.307: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-3022 /apis/apps/v1/namespaces/deployment-3022/deployments/test-cleanup-deployment 59af9253-84fb-4368-93ce-a320b8d087e8 94853 1 2020-06-13 10:22:15 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc00507e8f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Jun 13 10:22:15.313: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Jun 13 10:22:15.313: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Jun 13 10:22:15.313: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-3022 /apis/apps/v1/namespaces/deployment-3022/replicasets/test-cleanup-controller e822211f-4c4e-4ab5-aa2e-86bb6215b91e 94854 1 2020-06-13 10:22:10 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 59af9253-84fb-4368-93ce-a320b8d087e8 0xc00507ec57 0xc00507ec58}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc00507ecb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jun 13 10:22:15.317: INFO: Pod "test-cleanup-controller-h5r8q" is available:
&Pod{ObjectMeta:{test-cleanup-controller-h5r8q test-cleanup-controller- deployment-3022 /api/v1/namespaces/deployment-3022/pods/test-cleanup-controller-h5r8q f9c67a44-a05b-4fdc-9215-e3b72258adb9 94839 0 2020-06-13 10:22:10 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller e822211f-4c4e-4ab5-aa2e-86bb6215b91e 0xc00507efc7 0xc00507efc8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8n9gz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8n9gz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8n9gz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 10:22:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 10:22:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 10:22:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 10:22:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.1.211,StartTime:2020-06-13 10:22:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-13 10:22:11 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://250426a4f42c0ebb26a2d2532a2f0c63593a6783f9b38822294e1aa87b8e4028,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.211,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:22:15.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3022" for this suite.
Jun 13 10:22:21.338: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:22:21.464: INFO: namespace deployment-3022 deletion completed in 6.142375529s

• [SLOW TEST:11.247 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:22:21.465: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6754
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-6754
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6754
Jun 13 10:22:21.524: INFO: Found 0 stateful pods, waiting for 1
Jun 13 10:22:31.530: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Jun 13 10:22:31.533: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jun 13 10:22:31.884: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jun 13 10:22:31.884: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jun 13 10:22:31.884: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jun 13 10:22:31.889: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jun 13 10:22:41.894: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 13 10:22:41.894: INFO: Waiting for statefulset status.replicas updated to 0
Jun 13 10:22:41.914: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Jun 13 10:22:41.914: INFO: ss-0  10.0.10.2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  }]
Jun 13 10:22:41.914: INFO: 
Jun 13 10:22:41.914: INFO: StatefulSet ss has not reached scale 3, at 1
Jun 13 10:22:42.920: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995524857s
Jun 13 10:22:43.925: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989508003s
Jun 13 10:22:44.931: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.984540361s
Jun 13 10:22:45.935: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.97918707s
Jun 13 10:22:46.941: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.974454888s
Jun 13 10:22:47.946: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.968189988s
Jun 13 10:22:48.951: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.963676033s
Jun 13 10:22:49.955: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.959190086s
Jun 13 10:22:50.960: INFO: Verifying statefulset ss doesn't scale past 3 for another 954.728169ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6754
Jun 13 10:22:51.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:22:52.274: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jun 13 10:22:52.274: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jun 13 10:22:52.274: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jun 13 10:22:52.274: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:22:52.653: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jun 13 10:22:52.653: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jun 13 10:22:52.653: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jun 13 10:22:52.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:22:53.097: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Jun 13 10:22:53.097: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jun 13 10:22:53.097: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jun 13 10:22:53.101: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 13 10:22:53.101: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 13 10:22:53.101: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Jun 13 10:22:53.106: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jun 13 10:22:53.454: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jun 13 10:22:53.454: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jun 13 10:22:53.454: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jun 13 10:22:53.454: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jun 13 10:22:53.850: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jun 13 10:22:53.850: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jun 13 10:22:53.850: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jun 13 10:22:53.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jun 13 10:22:54.189: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jun 13 10:22:54.189: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jun 13 10:22:54.189: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jun 13 10:22:54.189: INFO: Waiting for statefulset status.replicas updated to 0
Jun 13 10:22:54.196: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Jun 13 10:23:04.206: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 13 10:23:04.206: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jun 13 10:23:04.206: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jun 13 10:23:04.219: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Jun 13 10:23:04.219: INFO: ss-0  10.0.10.2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  }]
Jun 13 10:23:04.219: INFO: ss-1  10.0.10.3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  }]
Jun 13 10:23:04.220: INFO: ss-2  10.0.10.2  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  }]
Jun 13 10:23:04.220: INFO: 
Jun 13 10:23:04.220: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 13 10:23:05.226: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Jun 13 10:23:05.227: INFO: ss-0  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  }]
Jun 13 10:23:05.227: INFO: ss-1  10.0.10.3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  }]
Jun 13 10:23:05.227: INFO: ss-2  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  }]
Jun 13 10:23:05.227: INFO: 
Jun 13 10:23:05.227: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 13 10:23:06.239: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Jun 13 10:23:06.239: INFO: ss-0  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  }]
Jun 13 10:23:06.239: INFO: ss-1  10.0.10.3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  }]
Jun 13 10:23:06.239: INFO: ss-2  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  }]
Jun 13 10:23:06.239: INFO: 
Jun 13 10:23:06.239: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 13 10:23:07.245: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Jun 13 10:23:07.245: INFO: ss-0  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  }]
Jun 13 10:23:07.245: INFO: ss-1  10.0.10.3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  }]
Jun 13 10:23:07.246: INFO: ss-2  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  }]
Jun 13 10:23:07.246: INFO: 
Jun 13 10:23:07.246: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 13 10:23:08.251: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Jun 13 10:23:08.251: INFO: ss-0  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  }]
Jun 13 10:23:08.251: INFO: ss-1  10.0.10.3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  }]
Jun 13 10:23:08.251: INFO: ss-2  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  }]
Jun 13 10:23:08.251: INFO: 
Jun 13 10:23:08.251: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 13 10:23:09.257: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Jun 13 10:23:09.257: INFO: ss-0  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  }]
Jun 13 10:23:09.257: INFO: ss-1  10.0.10.3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  }]
Jun 13 10:23:09.257: INFO: ss-2  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  }]
Jun 13 10:23:09.257: INFO: 
Jun 13 10:23:09.257: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 13 10:23:10.262: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Jun 13 10:23:10.262: INFO: ss-0  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  }]
Jun 13 10:23:10.262: INFO: ss-1  10.0.10.3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  }]
Jun 13 10:23:10.262: INFO: ss-2  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  }]
Jun 13 10:23:10.262: INFO: 
Jun 13 10:23:10.263: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 13 10:23:11.268: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Jun 13 10:23:11.268: INFO: ss-0  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  }]
Jun 13 10:23:11.268: INFO: ss-1  10.0.10.3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  }]
Jun 13 10:23:11.268: INFO: ss-2  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  }]
Jun 13 10:23:11.268: INFO: 
Jun 13 10:23:11.268: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 13 10:23:12.274: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Jun 13 10:23:12.274: INFO: ss-0  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  }]
Jun 13 10:23:12.274: INFO: ss-1  10.0.10.3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  }]
Jun 13 10:23:12.274: INFO: ss-2  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  }]
Jun 13 10:23:12.274: INFO: 
Jun 13 10:23:12.274: INFO: StatefulSet ss has not reached scale 0, at 3
Jun 13 10:23:13.279: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Jun 13 10:23:13.279: INFO: ss-0  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:53 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:21 +0000 UTC  }]
Jun 13 10:23:13.279: INFO: ss-1  10.0.10.3  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  }]
Jun 13 10:23:13.279: INFO: ss-2  10.0.10.2  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:54 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-06-13 10:22:41 +0000 UTC  }]
Jun 13 10:23:13.279: INFO: 
Jun 13 10:23:13.279: INFO: StatefulSet ss has not reached scale 0, at 3
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6754
Jun 13 10:23:14.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:23:14.549: INFO: rc: 1
Jun 13 10:23:14.549: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: pod does not exist

error:
exit status 1
Jun 13 10:23:24.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:23:24.640: INFO: rc: 1
Jun 13 10:23:24.640: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:23:34.640: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:23:34.732: INFO: rc: 1
Jun 13 10:23:34.732: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:23:44.733: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:23:44.873: INFO: rc: 1
Jun 13 10:23:44.873: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:23:54.874: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:23:54.961: INFO: rc: 1
Jun 13 10:23:54.961: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:24:04.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:24:05.055: INFO: rc: 1
Jun 13 10:24:05.055: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:24:15.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:24:15.143: INFO: rc: 1
Jun 13 10:24:15.143: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:24:25.144: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:24:25.235: INFO: rc: 1
Jun 13 10:24:25.235: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:24:35.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:24:35.328: INFO: rc: 1
Jun 13 10:24:35.328: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:24:45.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:24:45.415: INFO: rc: 1
Jun 13 10:24:45.415: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:24:55.416: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:24:55.527: INFO: rc: 1
Jun 13 10:24:55.527: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:25:05.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:25:05.614: INFO: rc: 1
Jun 13 10:25:05.615: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:25:15.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:25:15.704: INFO: rc: 1
Jun 13 10:25:15.704: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:25:25.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:25:25.795: INFO: rc: 1
Jun 13 10:25:25.795: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:25:35.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:25:35.888: INFO: rc: 1
Jun 13 10:25:35.888: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:25:45.888: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:25:46.002: INFO: rc: 1
Jun 13 10:25:46.002: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:25:56.002: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:25:56.093: INFO: rc: 1
Jun 13 10:25:56.093: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:26:06.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:26:06.195: INFO: rc: 1
Jun 13 10:26:06.195: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:26:16.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:26:16.292: INFO: rc: 1
Jun 13 10:26:16.292: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:26:26.293: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:26:26.382: INFO: rc: 1
Jun 13 10:26:26.382: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:26:36.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:26:36.471: INFO: rc: 1
Jun 13 10:26:36.471: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:26:46.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:26:46.561: INFO: rc: 1
Jun 13 10:26:46.561: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:26:56.562: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:26:56.651: INFO: rc: 1
Jun 13 10:26:56.651: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:27:06.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:27:06.756: INFO: rc: 1
Jun 13 10:27:06.756: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:27:16.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:27:16.845: INFO: rc: 1
Jun 13 10:27:16.845: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:27:26.845: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:27:26.933: INFO: rc: 1
Jun 13 10:27:26.933: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:27:36.933: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:27:37.022: INFO: rc: 1
Jun 13 10:27:37.022: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:27:47.023: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:27:47.111: INFO: rc: 1
Jun 13 10:27:47.111: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:27:57.112: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:27:57.202: INFO: rc: 1
Jun 13 10:27:57.202: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:28:07.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:28:07.290: INFO: rc: 1
Jun 13 10:28:07.290: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Jun 13 10:28:17.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-6754 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:28:17.385: INFO: rc: 1
Jun 13 10:28:17.385: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: 
Jun 13 10:28:17.385: INFO: Scaling statefulset ss to 0
Jun 13 10:28:17.416: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Jun 13 10:28:17.420: INFO: Deleting all statefulset in ns statefulset-6754
Jun 13 10:28:17.425: INFO: Scaling statefulset ss to 0
Jun 13 10:28:17.437: INFO: Waiting for statefulset status.replicas updated to 0
Jun 13 10:28:17.441: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:28:17.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6754" for this suite.
Jun 13 10:28:23.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:28:23.610: INFO: namespace statefulset-6754 deletion completed in 6.145006274s

• [SLOW TEST:362.146 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:28:23.611: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Jun 13 10:28:23.662: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0a03748b-d797-406f-9433-284f6bb9870b" in namespace "projected-2867" to be "success or failure"
Jun 13 10:28:23.666: INFO: Pod "downwardapi-volume-0a03748b-d797-406f-9433-284f6bb9870b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.651442ms
Jun 13 10:28:25.671: INFO: Pod "downwardapi-volume-0a03748b-d797-406f-9433-284f6bb9870b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008842637s
Jun 13 10:28:27.675: INFO: Pod "downwardapi-volume-0a03748b-d797-406f-9433-284f6bb9870b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013287225s
STEP: Saw pod success
Jun 13 10:28:27.675: INFO: Pod "downwardapi-volume-0a03748b-d797-406f-9433-284f6bb9870b" satisfied condition "success or failure"
Jun 13 10:28:27.679: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-0a03748b-d797-406f-9433-284f6bb9870b container client-container: <nil>
STEP: delete the pod
Jun 13 10:28:27.861: INFO: Waiting for pod downwardapi-volume-0a03748b-d797-406f-9433-284f6bb9870b to disappear
Jun 13 10:28:27.865: INFO: Pod downwardapi-volume-0a03748b-d797-406f-9433-284f6bb9870b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:28:27.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2867" for this suite.
Jun 13 10:28:33.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:28:34.016: INFO: namespace projected-2867 deletion completed in 6.142876722s

• [SLOW TEST:10.406 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:28:34.018: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Jun 13 10:28:34.071: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ecf65677-095c-40c5-8562-7693b69b985c" in namespace "projected-5178" to be "success or failure"
Jun 13 10:28:34.075: INFO: Pod "downwardapi-volume-ecf65677-095c-40c5-8562-7693b69b985c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.251643ms
Jun 13 10:28:36.080: INFO: Pod "downwardapi-volume-ecf65677-095c-40c5-8562-7693b69b985c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008771439s
STEP: Saw pod success
Jun 13 10:28:36.080: INFO: Pod "downwardapi-volume-ecf65677-095c-40c5-8562-7693b69b985c" satisfied condition "success or failure"
Jun 13 10:28:36.084: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-ecf65677-095c-40c5-8562-7693b69b985c container client-container: <nil>
STEP: delete the pod
Jun 13 10:28:36.111: INFO: Waiting for pod downwardapi-volume-ecf65677-095c-40c5-8562-7693b69b985c to disappear
Jun 13 10:28:36.115: INFO: Pod downwardapi-volume-ecf65677-095c-40c5-8562-7693b69b985c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:28:36.115: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5178" for this suite.
Jun 13 10:28:42.134: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:28:42.252: INFO: namespace projected-5178 deletion completed in 6.132327475s

• [SLOW TEST:8.234 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:28:42.252: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Jun 13 10:28:45.327: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:28:45.342: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6087" for this suite.
Jun 13 10:28:51.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:28:51.485: INFO: namespace container-runtime-6087 deletion completed in 6.13900789s

• [SLOW TEST:9.233 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:28:51.486: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Jun 13 10:28:56.074: INFO: Successfully updated pod "annotationupdatef29f8f83-884a-4db0-9fd5-69812d1d532a"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:28:58.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7653" for this suite.
Jun 13 10:29:16.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:29:16.295: INFO: namespace downward-api-7653 deletion completed in 18.14447421s

• [SLOW TEST:24.810 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:29:16.296: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:29:16.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-5246" for this suite.
Jun 13 10:29:22.364: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:29:22.486: INFO: namespace tables-5246 deletion completed in 6.13600614s

• [SLOW TEST:6.190 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:29:22.487: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 10:29:22.546: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Jun 13 10:29:22.559: INFO: Number of nodes with available pods: 0
Jun 13 10:29:22.559: INFO: Node 10.0.10.2 is running more than one daemon pod
Jun 13 10:29:23.568: INFO: Number of nodes with available pods: 0
Jun 13 10:29:23.568: INFO: Node 10.0.10.2 is running more than one daemon pod
Jun 13 10:29:24.568: INFO: Number of nodes with available pods: 2
Jun 13 10:29:24.568: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Jun 13 10:29:24.600: INFO: Wrong image for pod: daemon-set-p9x7q. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:24.600: INFO: Wrong image for pod: daemon-set-snbff. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:25.609: INFO: Wrong image for pod: daemon-set-p9x7q. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:25.609: INFO: Wrong image for pod: daemon-set-snbff. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:26.609: INFO: Wrong image for pod: daemon-set-p9x7q. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:26.610: INFO: Wrong image for pod: daemon-set-snbff. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:27.609: INFO: Wrong image for pod: daemon-set-p9x7q. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:27.609: INFO: Pod daemon-set-p9x7q is not available
Jun 13 10:29:27.609: INFO: Wrong image for pod: daemon-set-snbff. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:28.609: INFO: Wrong image for pod: daemon-set-p9x7q. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:28.609: INFO: Pod daemon-set-p9x7q is not available
Jun 13 10:29:28.609: INFO: Wrong image for pod: daemon-set-snbff. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:29.609: INFO: Wrong image for pod: daemon-set-p9x7q. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:29.609: INFO: Pod daemon-set-p9x7q is not available
Jun 13 10:29:29.609: INFO: Wrong image for pod: daemon-set-snbff. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:30.609: INFO: Wrong image for pod: daemon-set-p9x7q. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:30.609: INFO: Pod daemon-set-p9x7q is not available
Jun 13 10:29:30.609: INFO: Wrong image for pod: daemon-set-snbff. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:31.609: INFO: Wrong image for pod: daemon-set-p9x7q. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:31.609: INFO: Pod daemon-set-p9x7q is not available
Jun 13 10:29:31.609: INFO: Wrong image for pod: daemon-set-snbff. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:32.611: INFO: Wrong image for pod: daemon-set-p9x7q. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:32.611: INFO: Pod daemon-set-p9x7q is not available
Jun 13 10:29:32.611: INFO: Wrong image for pod: daemon-set-snbff. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:33.609: INFO: Pod daemon-set-c88pf is not available
Jun 13 10:29:33.609: INFO: Wrong image for pod: daemon-set-snbff. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:34.610: INFO: Pod daemon-set-c88pf is not available
Jun 13 10:29:34.610: INFO: Wrong image for pod: daemon-set-snbff. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:35.609: INFO: Pod daemon-set-c88pf is not available
Jun 13 10:29:35.609: INFO: Wrong image for pod: daemon-set-snbff. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:36.609: INFO: Wrong image for pod: daemon-set-snbff. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:36.609: INFO: Pod daemon-set-snbff is not available
Jun 13 10:29:37.609: INFO: Wrong image for pod: daemon-set-snbff. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:37.609: INFO: Pod daemon-set-snbff is not available
Jun 13 10:29:38.609: INFO: Wrong image for pod: daemon-set-snbff. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:38.609: INFO: Pod daemon-set-snbff is not available
Jun 13 10:29:39.609: INFO: Wrong image for pod: daemon-set-snbff. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:39.609: INFO: Pod daemon-set-snbff is not available
Jun 13 10:29:40.611: INFO: Wrong image for pod: daemon-set-snbff. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:40.611: INFO: Pod daemon-set-snbff is not available
Jun 13 10:29:41.609: INFO: Wrong image for pod: daemon-set-snbff. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:41.609: INFO: Pod daemon-set-snbff is not available
Jun 13 10:29:42.610: INFO: Wrong image for pod: daemon-set-snbff. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:42.610: INFO: Pod daemon-set-snbff is not available
Jun 13 10:29:43.610: INFO: Wrong image for pod: daemon-set-snbff. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Jun 13 10:29:43.610: INFO: Pod daemon-set-snbff is not available
Jun 13 10:29:44.609: INFO: Pod daemon-set-7zqlc is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Jun 13 10:29:44.621: INFO: Number of nodes with available pods: 1
Jun 13 10:29:44.621: INFO: Node 10.0.10.2 is running more than one daemon pod
Jun 13 10:29:45.629: INFO: Number of nodes with available pods: 1
Jun 13 10:29:45.629: INFO: Node 10.0.10.2 is running more than one daemon pod
Jun 13 10:29:46.634: INFO: Number of nodes with available pods: 1
Jun 13 10:29:46.634: INFO: Node 10.0.10.2 is running more than one daemon pod
Jun 13 10:29:47.630: INFO: Number of nodes with available pods: 2
Jun 13 10:29:47.630: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9431, will wait for the garbage collector to delete the pods
Jun 13 10:29:47.717: INFO: Deleting DaemonSet.extensions daemon-set took: 9.370762ms
Jun 13 10:29:48.018: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.250829ms
Jun 13 10:29:50.821: INFO: Number of nodes with available pods: 0
Jun 13 10:29:50.821: INFO: Number of running nodes: 0, number of available pods: 0
Jun 13 10:29:50.824: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9431/daemonsets","resourceVersion":"96588"},"items":null}

Jun 13 10:29:50.828: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9431/pods","resourceVersion":"96588"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:29:50.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9431" for this suite.
Jun 13 10:29:56.860: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:29:56.985: INFO: namespace daemonsets-9431 deletion completed in 6.140151888s

• [SLOW TEST:34.498 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:29:56.987: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-554c16b2-04cc-4a52-94a2-bf8a401bf19b
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:29:57.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6540" for this suite.
Jun 13 10:30:03.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:30:03.176: INFO: namespace configmap-6540 deletion completed in 6.139084695s

• [SLOW TEST:6.190 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:30:03.177: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Jun 13 10:30:05.247: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:30:05.262: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9734" for this suite.
Jun 13 10:30:11.281: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:30:11.413: INFO: namespace container-runtime-9734 deletion completed in 6.147110056s

• [SLOW TEST:8.237 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:30:11.415: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Jun 13 10:30:11.457: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 create -f - --namespace=kubectl-9835'
Jun 13 10:30:11.779: INFO: stderr: ""
Jun 13 10:30:11.779: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 13 10:30:11.779: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9835'
Jun 13 10:30:11.893: INFO: stderr: ""
Jun 13 10:30:11.893: INFO: stdout: "update-demo-nautilus-6z7xg update-demo-nautilus-mvv5x "
Jun 13 10:30:11.893: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-6z7xg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9835'
Jun 13 10:30:12.036: INFO: stderr: ""
Jun 13 10:30:12.036: INFO: stdout: ""
Jun 13 10:30:12.036: INFO: update-demo-nautilus-6z7xg is created but not running
Jun 13 10:30:17.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9835'
Jun 13 10:30:17.135: INFO: stderr: ""
Jun 13 10:30:17.136: INFO: stdout: "update-demo-nautilus-6z7xg update-demo-nautilus-mvv5x "
Jun 13 10:30:17.136: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-6z7xg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9835'
Jun 13 10:30:17.226: INFO: stderr: ""
Jun 13 10:30:17.226: INFO: stdout: "true"
Jun 13 10:30:17.226: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-6z7xg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9835'
Jun 13 10:30:17.323: INFO: stderr: ""
Jun 13 10:30:17.323: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 13 10:30:17.323: INFO: validating pod update-demo-nautilus-6z7xg
Jun 13 10:30:17.407: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 13 10:30:17.407: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 13 10:30:17.407: INFO: update-demo-nautilus-6z7xg is verified up and running
Jun 13 10:30:17.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-mvv5x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9835'
Jun 13 10:30:17.546: INFO: stderr: ""
Jun 13 10:30:17.546: INFO: stdout: "true"
Jun 13 10:30:17.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-nautilus-mvv5x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9835'
Jun 13 10:30:17.643: INFO: stderr: ""
Jun 13 10:30:17.643: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Jun 13 10:30:17.643: INFO: validating pod update-demo-nautilus-mvv5x
Jun 13 10:30:17.747: INFO: got data: {
  "image": "nautilus.jpg"
}

Jun 13 10:30:17.747: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Jun 13 10:30:17.747: INFO: update-demo-nautilus-mvv5x is verified up and running
STEP: rolling-update to new replication controller
Jun 13 10:30:17.751: INFO: scanned /root for discovery docs: <nil>
Jun 13 10:30:17.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-9835'
Jun 13 10:30:40.331: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jun 13 10:30:40.331: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Jun 13 10:30:40.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-9835'
Jun 13 10:30:40.426: INFO: stderr: ""
Jun 13 10:30:40.426: INFO: stdout: "update-demo-kitten-2zxrj update-demo-kitten-t8kr9 "
Jun 13 10:30:40.426: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-kitten-2zxrj -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9835'
Jun 13 10:30:40.517: INFO: stderr: ""
Jun 13 10:30:40.517: INFO: stdout: "true"
Jun 13 10:30:40.517: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-kitten-2zxrj -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9835'
Jun 13 10:30:40.608: INFO: stderr: ""
Jun 13 10:30:40.608: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jun 13 10:30:40.608: INFO: validating pod update-demo-kitten-2zxrj
Jun 13 10:30:40.747: INFO: got data: {
  "image": "kitten.jpg"
}

Jun 13 10:30:40.747: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jun 13 10:30:40.747: INFO: update-demo-kitten-2zxrj is verified up and running
Jun 13 10:30:40.747: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-kitten-t8kr9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9835'
Jun 13 10:30:40.850: INFO: stderr: ""
Jun 13 10:30:40.850: INFO: stdout: "true"
Jun 13 10:30:40.850: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods update-demo-kitten-t8kr9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9835'
Jun 13 10:30:40.941: INFO: stderr: ""
Jun 13 10:30:40.941: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Jun 13 10:30:40.941: INFO: validating pod update-demo-kitten-t8kr9
Jun 13 10:30:41.013: INFO: got data: {
  "image": "kitten.jpg"
}

Jun 13 10:30:41.013: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Jun 13 10:30:41.013: INFO: update-demo-kitten-t8kr9 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:30:41.013: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9835" for this suite.
Jun 13 10:30:53.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:30:53.159: INFO: namespace kubectl-9835 deletion completed in 12.139699552s

• [SLOW TEST:41.744 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:30:53.160: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 10:31:11.224: INFO: Container started at 2020-06-13 10:30:54 +0000 UTC, pod became ready at 2020-06-13 10:31:11 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:31:11.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5966" for this suite.
Jun 13 10:31:39.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:31:39.367: INFO: namespace container-probe-5966 deletion completed in 28.138738014s

• [SLOW TEST:46.208 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:31:39.368: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-3009
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-3009
STEP: creating replication controller externalsvc in namespace services-3009
I0613 10:31:39.442949      22 runners.go:184] Created replication controller with name: externalsvc, namespace: services-3009, replica count: 2
I0613 10:31:42.505204      22 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Jun 13 10:31:42.527: INFO: Creating new exec pod
Jun 13 10:31:44.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=services-3009 execpods8b6b -- /bin/sh -x -c nslookup clusterip-service'
Jun 13 10:31:44.990: INFO: stderr: "+ nslookup clusterip-service\n"
Jun 13 10:31:44.990: INFO: stdout: "Server:\t\t10.96.5.5\nAddress:\t10.96.5.5#53\n\nclusterip-service.services-3009.svc.cluster.local\tcanonical name = externalsvc.services-3009.svc.cluster.local.\nName:\texternalsvc.services-3009.svc.cluster.local\nAddress: 10.96.211.81\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-3009, will wait for the garbage collector to delete the pods
Jun 13 10:31:45.062: INFO: Deleting ReplicationController externalsvc took: 11.292567ms
Jun 13 10:31:45.362: INFO: Terminating ReplicationController externalsvc pods took: 300.264766ms
Jun 13 10:31:53.584: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:31:53.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3009" for this suite.
Jun 13 10:31:59.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:31:59.746: INFO: namespace services-3009 deletion completed in 6.140142399s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:20.378 seconds]
[sig-network] Services
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:31:59.753: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 13 10:32:00.357: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 13 10:32:03.383: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:32:03.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5829" for this suite.
Jun 13 10:32:09.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:32:09.731: INFO: namespace webhook-5829 deletion completed in 6.145707813s
STEP: Destroying namespace "webhook-5829-markers" for this suite.
Jun 13 10:32:15.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:32:15.875: INFO: namespace webhook-5829-markers deletion completed in 6.14382126s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.147 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:32:15.900: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-d71f6b6e-23ef-4f9f-826c-17206555a945 in namespace container-probe-558
Jun 13 10:32:19.958: INFO: Started pod liveness-d71f6b6e-23ef-4f9f-826c-17206555a945 in namespace container-probe-558
STEP: checking the pod's current state and verifying that restartCount is present
Jun 13 10:32:19.962: INFO: Initial restart count of pod liveness-d71f6b6e-23ef-4f9f-826c-17206555a945 is 0
Jun 13 10:32:38.007: INFO: Restart count of pod container-probe-558/liveness-d71f6b6e-23ef-4f9f-826c-17206555a945 is now 1 (18.044950487s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:32:38.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-558" for this suite.
Jun 13 10:32:44.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:32:44.164: INFO: namespace container-probe-558 deletion completed in 6.140714243s

• [SLOW TEST:28.265 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:32:44.165: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Jun 13 10:32:44.206: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun 13 10:32:44.222: INFO: Waiting for terminating namespaces to be deleted...
Jun 13 10:32:44.226: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.2 before test
Jun 13 10:32:44.355: INFO: sonobuoy-systemd-logs-daemon-set-89d5b422bcff4ee4-jptvl from sonobuoy started at 2020-06-13 09:55:07 +0000 UTC (2 container statuses recorded)
Jun 13 10:32:44.355: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 13 10:32:44.355: INFO: 	Container systemd-logs ready: true, restart count 0
Jun 13 10:32:44.355: INFO: proxymux-client-hhdsr from kube-system started at 2020-06-13 03:16:54 +0000 UTC (1 container statuses recorded)
Jun 13 10:32:44.355: INFO: 	Container proxymux-client ready: true, restart count 0
Jun 13 10:32:44.355: INFO: csi-oci-node-4dfqn from kube-system started at 2020-06-13 03:16:54 +0000 UTC (1 container statuses recorded)
Jun 13 10:32:44.355: INFO: 	Container csi-node-driver ready: true, restart count 0
Jun 13 10:32:44.355: INFO: kube-proxy-mbpxz from kube-system started at 2020-06-13 03:16:34 +0000 UTC (1 container statuses recorded)
Jun 13 10:32:44.355: INFO: 	Container kube-proxy ready: true, restart count 0
Jun 13 10:32:44.355: INFO: kube-flannel-ds-mddmt from kube-system started at 2020-06-13 03:16:34 +0000 UTC (1 container statuses recorded)
Jun 13 10:32:44.355: INFO: 	Container kube-flannel ready: true, restart count 1
Jun 13 10:32:44.355: INFO: coredns-6f9ff9bd47-ctdhp from kube-system started at 2020-06-13 03:17:03 +0000 UTC (1 container statuses recorded)
Jun 13 10:32:44.355: INFO: 	Container coredns ready: true, restart count 0
Jun 13 10:32:44.355: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.3 before test
Jun 13 10:32:44.440: INFO: kube-dns-autoscaler-75565f7896-hm82m from kube-system started at 2020-06-13 03:17:03 +0000 UTC (1 container statuses recorded)
Jun 13 10:32:44.440: INFO: 	Container autoscaler ready: true, restart count 0
Jun 13 10:32:44.440: INFO: kube-flannel-ds-6cxw2 from kube-system started at 2020-06-13 03:16:34 +0000 UTC (1 container statuses recorded)
Jun 13 10:32:44.440: INFO: 	Container kube-flannel ready: true, restart count 1
Jun 13 10:32:44.440: INFO: proxymux-client-mshct from kube-system started at 2020-06-13 03:16:54 +0000 UTC (1 container statuses recorded)
Jun 13 10:32:44.440: INFO: 	Container proxymux-client ready: true, restart count 0
Jun 13 10:32:44.440: INFO: sonobuoy-e2e-job-eae45311abd24acb from sonobuoy started at 2020-06-13 09:55:07 +0000 UTC (2 container statuses recorded)
Jun 13 10:32:44.440: INFO: 	Container e2e ready: true, restart count 0
Jun 13 10:32:44.440: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 13 10:32:44.440: INFO: kubernetes-dashboard-56b6bf4bf-65jz6 from kube-system started at 2020-06-13 03:16:53 +0000 UTC (1 container statuses recorded)
Jun 13 10:32:44.440: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jun 13 10:32:44.440: INFO: kube-proxy-6vf8c from kube-system started at 2020-06-13 03:16:34 +0000 UTC (1 container statuses recorded)
Jun 13 10:32:44.440: INFO: 	Container kube-proxy ready: true, restart count 0
Jun 13 10:32:44.440: INFO: csi-oci-node-hhfs6 from kube-system started at 2020-06-13 03:16:54 +0000 UTC (1 container statuses recorded)
Jun 13 10:32:44.440: INFO: 	Container csi-node-driver ready: true, restart count 0
Jun 13 10:32:44.440: INFO: sonobuoy from sonobuoy started at 2020-06-13 09:55:05 +0000 UTC (1 container statuses recorded)
Jun 13 10:32:44.440: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun 13 10:32:44.440: INFO: sonobuoy-systemd-logs-daemon-set-89d5b422bcff4ee4-z5xtf from sonobuoy started at 2020-06-13 09:55:07 +0000 UTC (2 container statuses recorded)
Jun 13 10:32:44.440: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 13 10:32:44.440: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node 10.0.10.2
STEP: verifying the node has the label node 10.0.10.3
Jun 13 10:32:44.483: INFO: Pod coredns-6f9ff9bd47-ctdhp requesting resource cpu=100m on Node 10.0.10.2
Jun 13 10:32:44.483: INFO: Pod csi-oci-node-4dfqn requesting resource cpu=0m on Node 10.0.10.2
Jun 13 10:32:44.483: INFO: Pod csi-oci-node-hhfs6 requesting resource cpu=0m on Node 10.0.10.3
Jun 13 10:32:44.483: INFO: Pod kube-dns-autoscaler-75565f7896-hm82m requesting resource cpu=20m on Node 10.0.10.3
Jun 13 10:32:44.483: INFO: Pod kube-flannel-ds-6cxw2 requesting resource cpu=100m on Node 10.0.10.3
Jun 13 10:32:44.483: INFO: Pod kube-flannel-ds-mddmt requesting resource cpu=100m on Node 10.0.10.2
Jun 13 10:32:44.483: INFO: Pod kube-proxy-6vf8c requesting resource cpu=0m on Node 10.0.10.3
Jun 13 10:32:44.483: INFO: Pod kube-proxy-mbpxz requesting resource cpu=0m on Node 10.0.10.2
Jun 13 10:32:44.484: INFO: Pod kubernetes-dashboard-56b6bf4bf-65jz6 requesting resource cpu=0m on Node 10.0.10.3
Jun 13 10:32:44.484: INFO: Pod proxymux-client-hhdsr requesting resource cpu=50m on Node 10.0.10.2
Jun 13 10:32:44.484: INFO: Pod proxymux-client-mshct requesting resource cpu=50m on Node 10.0.10.3
Jun 13 10:32:44.484: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.0.10.3
Jun 13 10:32:44.484: INFO: Pod sonobuoy-e2e-job-eae45311abd24acb requesting resource cpu=0m on Node 10.0.10.3
Jun 13 10:32:44.484: INFO: Pod sonobuoy-systemd-logs-daemon-set-89d5b422bcff4ee4-jptvl requesting resource cpu=0m on Node 10.0.10.2
Jun 13 10:32:44.484: INFO: Pod sonobuoy-systemd-logs-daemon-set-89d5b422bcff4ee4-z5xtf requesting resource cpu=0m on Node 10.0.10.3
STEP: Starting Pods to consume most of the cluster CPU.
Jun 13 10:32:44.484: INFO: Creating a pod which consumes cpu=1225m on Node 10.0.10.2
Jun 13 10:32:44.496: INFO: Creating a pod which consumes cpu=1281m on Node 10.0.10.3
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5b14d1cc-3014-4df0-a4d9-9730a4174c8a.161813ea1cdd482b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2891/filler-pod-5b14d1cc-3014-4df0-a4d9-9730a4174c8a to 10.0.10.2]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5b14d1cc-3014-4df0-a4d9-9730a4174c8a.161813ea4a973eba], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5b14d1cc-3014-4df0-a4d9-9730a4174c8a.161813ea4c9b367e], Reason = [Created], Message = [Created container filler-pod-5b14d1cc-3014-4df0-a4d9-9730a4174c8a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5b14d1cc-3014-4df0-a4d9-9730a4174c8a.161813ea59e77fda], Reason = [Started], Message = [Started container filler-pod-5b14d1cc-3014-4df0-a4d9-9730a4174c8a]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f472241d-b8f0-47ee-b6e2-a6e563d5baf1.161813ea1d6c58fa], Reason = [Scheduled], Message = [Successfully assigned sched-pred-2891/filler-pod-f472241d-b8f0-47ee-b6e2-a6e563d5baf1 to 10.0.10.3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f472241d-b8f0-47ee-b6e2-a6e563d5baf1.161813ea60fe282e], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f472241d-b8f0-47ee-b6e2-a6e563d5baf1.161813ea6311c391], Reason = [Created], Message = [Created container filler-pod-f472241d-b8f0-47ee-b6e2-a6e563d5baf1]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-f472241d-b8f0-47ee-b6e2-a6e563d5baf1.161813ea72149e9e], Reason = [Started], Message = [Started container filler-pod-f472241d-b8f0-47ee-b6e2-a6e563d5baf1]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.161813eb0d7df863], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node 10.0.10.2
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.0.10.3
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:32:49.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2891" for this suite.
Jun 13 10:32:55.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:32:55.739: INFO: namespace sched-pred-2891 deletion completed in 6.143574116s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:11.574 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:32:55.739: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-aa7c72b1-498c-4aa5-8586-26117f935c6f
STEP: Creating a pod to test consume secrets
Jun 13 10:32:55.799: INFO: Waiting up to 5m0s for pod "pod-secrets-dba2e8c4-d68d-4477-9323-298395364e13" in namespace "secrets-725" to be "success or failure"
Jun 13 10:32:55.803: INFO: Pod "pod-secrets-dba2e8c4-d68d-4477-9323-298395364e13": Phase="Pending", Reason="", readiness=false. Elapsed: 3.934148ms
Jun 13 10:32:57.807: INFO: Pod "pod-secrets-dba2e8c4-d68d-4477-9323-298395364e13": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008071846s
Jun 13 10:32:59.812: INFO: Pod "pod-secrets-dba2e8c4-d68d-4477-9323-298395364e13": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012712798s
STEP: Saw pod success
Jun 13 10:32:59.812: INFO: Pod "pod-secrets-dba2e8c4-d68d-4477-9323-298395364e13" satisfied condition "success or failure"
Jun 13 10:32:59.816: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-dba2e8c4-d68d-4477-9323-298395364e13 container secret-volume-test: <nil>
STEP: delete the pod
Jun 13 10:32:59.841: INFO: Waiting for pod pod-secrets-dba2e8c4-d68d-4477-9323-298395364e13 to disappear
Jun 13 10:32:59.845: INFO: Pod pod-secrets-dba2e8c4-d68d-4477-9323-298395364e13 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:32:59.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-725" for this suite.
Jun 13 10:33:05.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:33:05.988: INFO: namespace secrets-725 deletion completed in 6.138983281s

• [SLOW TEST:10.249 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:33:05.993: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-1181, will wait for the garbage collector to delete the pods
Jun 13 10:33:10.117: INFO: Deleting Job.batch foo took: 9.876562ms
Jun 13 10:33:10.417: INFO: Terminating Job.batch foo pods took: 300.245323ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:33:54.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1181" for this suite.
Jun 13 10:34:00.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:34:00.567: INFO: namespace job-1181 deletion completed in 6.140620786s

• [SLOW TEST:54.574 seconds]
[sig-apps] Job
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:34:00.568: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Jun 13 10:34:00.619: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6ec806ca-1b5b-47c7-afeb-2391e5e2fe56" in namespace "projected-6508" to be "success or failure"
Jun 13 10:34:00.623: INFO: Pod "downwardapi-volume-6ec806ca-1b5b-47c7-afeb-2391e5e2fe56": Phase="Pending", Reason="", readiness=false. Elapsed: 4.092468ms
Jun 13 10:34:02.627: INFO: Pod "downwardapi-volume-6ec806ca-1b5b-47c7-afeb-2391e5e2fe56": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008528028s
Jun 13 10:34:04.632: INFO: Pod "downwardapi-volume-6ec806ca-1b5b-47c7-afeb-2391e5e2fe56": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012757139s
STEP: Saw pod success
Jun 13 10:34:04.632: INFO: Pod "downwardapi-volume-6ec806ca-1b5b-47c7-afeb-2391e5e2fe56" satisfied condition "success or failure"
Jun 13 10:34:04.635: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-6ec806ca-1b5b-47c7-afeb-2391e5e2fe56 container client-container: <nil>
STEP: delete the pod
Jun 13 10:34:04.760: INFO: Waiting for pod downwardapi-volume-6ec806ca-1b5b-47c7-afeb-2391e5e2fe56 to disappear
Jun 13 10:34:04.764: INFO: Pod downwardapi-volume-6ec806ca-1b5b-47c7-afeb-2391e5e2fe56 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:34:04.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6508" for this suite.
Jun 13 10:34:10.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:34:10.902: INFO: namespace projected-6508 deletion completed in 6.133652863s

• [SLOW TEST:10.335 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:34:10.903: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8627.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8627.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 13 10:34:15.078: INFO: DNS probes using dns-8627/dns-test-16b3827d-639d-40d6-8d27-f693ee2afe48 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:34:15.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8627" for this suite.
Jun 13 10:34:21.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:34:21.260: INFO: namespace dns-8627 deletion completed in 6.16397406s

• [SLOW TEST:10.358 seconds]
[sig-network] DNS
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:34:21.266: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0613 10:34:51.870878      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 13 10:34:51.871: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:34:51.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9678" for this suite.
Jun 13 10:34:57.892: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:34:58.023: INFO: namespace gc-9678 deletion completed in 6.146647571s

• [SLOW TEST:36.758 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:34:58.031: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-6880b2ff-276e-4a11-969a-cfaebf2c4cba
STEP: Creating a pod to test consume secrets
Jun 13 10:34:58.087: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-37938421-15ce-4572-bb67-b9da7f25868d" in namespace "projected-2457" to be "success or failure"
Jun 13 10:34:58.092: INFO: Pod "pod-projected-secrets-37938421-15ce-4572-bb67-b9da7f25868d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.578193ms
Jun 13 10:35:00.095: INFO: Pod "pod-projected-secrets-37938421-15ce-4572-bb67-b9da7f25868d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008457597s
STEP: Saw pod success
Jun 13 10:35:00.096: INFO: Pod "pod-projected-secrets-37938421-15ce-4572-bb67-b9da7f25868d" satisfied condition "success or failure"
Jun 13 10:35:00.099: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-secrets-37938421-15ce-4572-bb67-b9da7f25868d container secret-volume-test: <nil>
STEP: delete the pod
Jun 13 10:35:00.125: INFO: Waiting for pod pod-projected-secrets-37938421-15ce-4572-bb67-b9da7f25868d to disappear
Jun 13 10:35:00.128: INFO: Pod pod-projected-secrets-37938421-15ce-4572-bb67-b9da7f25868d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:35:00.129: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2457" for this suite.
Jun 13 10:35:06.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:35:06.272: INFO: namespace projected-2457 deletion completed in 6.13417059s

• [SLOW TEST:8.242 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:35:06.273: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-9bp7
STEP: Creating a pod to test atomic-volume-subpath
Jun 13 10:35:06.334: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-9bp7" in namespace "subpath-6173" to be "success or failure"
Jun 13 10:35:06.339: INFO: Pod "pod-subpath-test-configmap-9bp7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.28459ms
Jun 13 10:35:08.343: INFO: Pod "pod-subpath-test-configmap-9bp7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008445631s
Jun 13 10:35:10.348: INFO: Pod "pod-subpath-test-configmap-9bp7": Phase="Running", Reason="", readiness=true. Elapsed: 4.013873462s
Jun 13 10:35:12.354: INFO: Pod "pod-subpath-test-configmap-9bp7": Phase="Running", Reason="", readiness=true. Elapsed: 6.01922008s
Jun 13 10:35:14.359: INFO: Pod "pod-subpath-test-configmap-9bp7": Phase="Running", Reason="", readiness=true. Elapsed: 8.02414206s
Jun 13 10:35:16.363: INFO: Pod "pod-subpath-test-configmap-9bp7": Phase="Running", Reason="", readiness=true. Elapsed: 10.028703169s
Jun 13 10:35:18.368: INFO: Pod "pod-subpath-test-configmap-9bp7": Phase="Running", Reason="", readiness=true. Elapsed: 12.033402663s
Jun 13 10:35:20.372: INFO: Pod "pod-subpath-test-configmap-9bp7": Phase="Running", Reason="", readiness=true. Elapsed: 14.037743331s
Jun 13 10:35:22.377: INFO: Pod "pod-subpath-test-configmap-9bp7": Phase="Running", Reason="", readiness=true. Elapsed: 16.042952825s
Jun 13 10:35:24.382: INFO: Pod "pod-subpath-test-configmap-9bp7": Phase="Running", Reason="", readiness=true. Elapsed: 18.047659465s
Jun 13 10:35:26.387: INFO: Pod "pod-subpath-test-configmap-9bp7": Phase="Running", Reason="", readiness=true. Elapsed: 20.052363233s
Jun 13 10:35:28.391: INFO: Pod "pod-subpath-test-configmap-9bp7": Phase="Running", Reason="", readiness=true. Elapsed: 22.057000516s
Jun 13 10:35:30.396: INFO: Pod "pod-subpath-test-configmap-9bp7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.062017302s
STEP: Saw pod success
Jun 13 10:35:30.396: INFO: Pod "pod-subpath-test-configmap-9bp7" satisfied condition "success or failure"
Jun 13 10:35:30.400: INFO: Trying to get logs from node 10.0.10.2 pod pod-subpath-test-configmap-9bp7 container test-container-subpath-configmap-9bp7: <nil>
STEP: delete the pod
Jun 13 10:35:30.459: INFO: Waiting for pod pod-subpath-test-configmap-9bp7 to disappear
Jun 13 10:35:30.463: INFO: Pod pod-subpath-test-configmap-9bp7 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-9bp7
Jun 13 10:35:30.463: INFO: Deleting pod "pod-subpath-test-configmap-9bp7" in namespace "subpath-6173"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:35:30.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6173" for this suite.
Jun 13 10:35:36.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:35:36.636: INFO: namespace subpath-6173 deletion completed in 6.164958514s

• [SLOW TEST:30.363 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:35:36.636: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Jun 13 10:35:36.677: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Jun 13 10:35:49.202: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 10:35:51.171: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:36:03.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5509" for this suite.
Jun 13 10:36:09.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:36:10.147: INFO: namespace crd-publish-openapi-5509 deletion completed in 6.502389823s

• [SLOW TEST:33.511 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:36:10.147: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Jun 13 10:36:10.207: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7b8ccd85-2686-4650-91f6-9134252add1d" in namespace "downward-api-7196" to be "success or failure"
Jun 13 10:36:10.213: INFO: Pod "downwardapi-volume-7b8ccd85-2686-4650-91f6-9134252add1d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.879818ms
Jun 13 10:36:12.218: INFO: Pod "downwardapi-volume-7b8ccd85-2686-4650-91f6-9134252add1d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011518448s
Jun 13 10:36:14.223: INFO: Pod "downwardapi-volume-7b8ccd85-2686-4650-91f6-9134252add1d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016303459s
STEP: Saw pod success
Jun 13 10:36:14.223: INFO: Pod "downwardapi-volume-7b8ccd85-2686-4650-91f6-9134252add1d" satisfied condition "success or failure"
Jun 13 10:36:14.227: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-7b8ccd85-2686-4650-91f6-9134252add1d container client-container: <nil>
STEP: delete the pod
Jun 13 10:36:14.379: INFO: Waiting for pod downwardapi-volume-7b8ccd85-2686-4650-91f6-9134252add1d to disappear
Jun 13 10:36:14.383: INFO: Pod downwardapi-volume-7b8ccd85-2686-4650-91f6-9134252add1d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:36:14.384: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7196" for this suite.
Jun 13 10:36:20.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:36:20.848: INFO: namespace downward-api-7196 deletion completed in 6.460874398s

• [SLOW TEST:10.701 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:36:20.849: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Jun 13 10:36:20.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-3378'
Jun 13 10:36:20.993: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun 13 10:36:20.993: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Jun 13 10:36:21.006: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-l2f42]
Jun 13 10:36:21.006: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-l2f42" in namespace "kubectl-3378" to be "running and ready"
Jun 13 10:36:21.012: INFO: Pod "e2e-test-httpd-rc-l2f42": Phase="Pending", Reason="", readiness=false. Elapsed: 5.25783ms
Jun 13 10:36:23.016: INFO: Pod "e2e-test-httpd-rc-l2f42": Phase="Running", Reason="", readiness=true. Elapsed: 2.009681917s
Jun 13 10:36:23.016: INFO: Pod "e2e-test-httpd-rc-l2f42" satisfied condition "running and ready"
Jun 13 10:36:23.016: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-l2f42]
Jun 13 10:36:23.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 logs rc/e2e-test-httpd-rc --namespace=kubectl-3378'
Jun 13 10:36:23.259: INFO: stderr: ""
Jun 13 10:36:23.259: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.244.1.239. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.244.1.239. Set the 'ServerName' directive globally to suppress this message\n[Sat Jun 13 10:36:22.041412 2020] [mpm_event:notice] [pid 1:tid 140165396872040] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Sat Jun 13 10:36:22.041489 2020] [core:notice] [pid 1:tid 140165396872040] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Jun 13 10:36:23.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 delete rc e2e-test-httpd-rc --namespace=kubectl-3378'
Jun 13 10:36:23.370: INFO: stderr: ""
Jun 13 10:36:23.370: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:36:23.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3378" for this suite.
Jun 13 10:36:29.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:36:29.530: INFO: namespace kubectl-3378 deletion completed in 6.151175815s

• [SLOW TEST:8.681 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:36:29.530: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 10:36:29.569: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:36:31.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4385" for this suite.
Jun 13 10:37:15.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:37:15.795: INFO: namespace pods-4385 deletion completed in 44.143717053s

• [SLOW TEST:46.265 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:37:15.797: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:37:15.887: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9642" for this suite.
Jun 13 10:37:21.911: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:37:22.040: INFO: namespace resourcequota-9642 deletion completed in 6.147435873s

• [SLOW TEST:6.243 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:37:22.040: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Jun 13 10:37:22.095: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e92c83cf-720b-4657-a261-8617d73c9e5c" in namespace "downward-api-217" to be "success or failure"
Jun 13 10:37:22.099: INFO: Pod "downwardapi-volume-e92c83cf-720b-4657-a261-8617d73c9e5c": Phase="Pending", Reason="", readiness=false. Elapsed: 3.908749ms
Jun 13 10:37:24.104: INFO: Pod "downwardapi-volume-e92c83cf-720b-4657-a261-8617d73c9e5c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008864616s
STEP: Saw pod success
Jun 13 10:37:24.104: INFO: Pod "downwardapi-volume-e92c83cf-720b-4657-a261-8617d73c9e5c" satisfied condition "success or failure"
Jun 13 10:37:24.108: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-e92c83cf-720b-4657-a261-8617d73c9e5c container client-container: <nil>
STEP: delete the pod
Jun 13 10:37:24.134: INFO: Waiting for pod downwardapi-volume-e92c83cf-720b-4657-a261-8617d73c9e5c to disappear
Jun 13 10:37:24.138: INFO: Pod downwardapi-volume-e92c83cf-720b-4657-a261-8617d73c9e5c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:37:24.138: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-217" for this suite.
Jun 13 10:37:30.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:37:30.292: INFO: namespace downward-api-217 deletion completed in 6.149776497s

• [SLOW TEST:8.253 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:37:30.292: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jun 13 10:37:30.684: INFO: Waiting up to 5m0s for pod "pod-f698c8ca-5860-48ac-8a1f-4b4ee664de12" in namespace "emptydir-1174" to be "success or failure"
Jun 13 10:37:30.689: INFO: Pod "pod-f698c8ca-5860-48ac-8a1f-4b4ee664de12": Phase="Pending", Reason="", readiness=false. Elapsed: 4.351185ms
Jun 13 10:37:32.700: INFO: Pod "pod-f698c8ca-5860-48ac-8a1f-4b4ee664de12": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015871798s
Jun 13 10:37:34.705: INFO: Pod "pod-f698c8ca-5860-48ac-8a1f-4b4ee664de12": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.020868634s
STEP: Saw pod success
Jun 13 10:37:34.705: INFO: Pod "pod-f698c8ca-5860-48ac-8a1f-4b4ee664de12" satisfied condition "success or failure"
Jun 13 10:37:34.709: INFO: Trying to get logs from node 10.0.10.2 pod pod-f698c8ca-5860-48ac-8a1f-4b4ee664de12 container test-container: <nil>
STEP: delete the pod
Jun 13 10:37:34.734: INFO: Waiting for pod pod-f698c8ca-5860-48ac-8a1f-4b4ee664de12 to disappear
Jun 13 10:37:34.738: INFO: Pod pod-f698c8ca-5860-48ac-8a1f-4b4ee664de12 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:37:34.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1174" for this suite.
Jun 13 10:37:40.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:37:40.894: INFO: namespace emptydir-1174 deletion completed in 6.150468661s

• [SLOW TEST:10.601 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:37:40.894: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-571c1ae0-bf98-47df-aa1a-69b4dd1397da
STEP: Creating a pod to test consume configMaps
Jun 13 10:37:40.956: INFO: Waiting up to 5m0s for pod "pod-configmaps-d28f749c-18ab-4b55-a13f-bd785a621215" in namespace "configmap-2593" to be "success or failure"
Jun 13 10:37:40.961: INFO: Pod "pod-configmaps-d28f749c-18ab-4b55-a13f-bd785a621215": Phase="Pending", Reason="", readiness=false. Elapsed: 5.118972ms
Jun 13 10:37:42.967: INFO: Pod "pod-configmaps-d28f749c-18ab-4b55-a13f-bd785a621215": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010574427s
Jun 13 10:37:44.971: INFO: Pod "pod-configmaps-d28f749c-18ab-4b55-a13f-bd785a621215": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015443162s
STEP: Saw pod success
Jun 13 10:37:44.971: INFO: Pod "pod-configmaps-d28f749c-18ab-4b55-a13f-bd785a621215" satisfied condition "success or failure"
Jun 13 10:37:44.975: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-d28f749c-18ab-4b55-a13f-bd785a621215 container configmap-volume-test: <nil>
STEP: delete the pod
Jun 13 10:37:45.002: INFO: Waiting for pod pod-configmaps-d28f749c-18ab-4b55-a13f-bd785a621215 to disappear
Jun 13 10:37:45.006: INFO: Pod pod-configmaps-d28f749c-18ab-4b55-a13f-bd785a621215 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:37:45.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2593" for this suite.
Jun 13 10:37:51.026: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:37:51.151: INFO: namespace configmap-2593 deletion completed in 6.139763239s

• [SLOW TEST:10.257 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:37:51.151: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Jun 13 10:37:51.442: INFO: Pod name wrapped-volume-race-dcb807bd-25e4-46e9-9f8a-3714b635f7b5: Found 0 pods out of 5
Jun 13 10:37:56.450: INFO: Pod name wrapped-volume-race-dcb807bd-25e4-46e9-9f8a-3714b635f7b5: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-dcb807bd-25e4-46e9-9f8a-3714b635f7b5 in namespace emptydir-wrapper-527, will wait for the garbage collector to delete the pods
Jun 13 10:38:04.551: INFO: Deleting ReplicationController wrapped-volume-race-dcb807bd-25e4-46e9-9f8a-3714b635f7b5 took: 14.092486ms
Jun 13 10:38:04.852: INFO: Terminating ReplicationController wrapped-volume-race-dcb807bd-25e4-46e9-9f8a-3714b635f7b5 pods took: 300.255283ms
STEP: Creating RC which spawns configmap-volume pods
Jun 13 10:38:45.475: INFO: Pod name wrapped-volume-race-8310a5f6-694b-4f24-9555-cbb8abf2f59e: Found 0 pods out of 5
Jun 13 10:38:50.482: INFO: Pod name wrapped-volume-race-8310a5f6-694b-4f24-9555-cbb8abf2f59e: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-8310a5f6-694b-4f24-9555-cbb8abf2f59e in namespace emptydir-wrapper-527, will wait for the garbage collector to delete the pods
Jun 13 10:39:04.589: INFO: Deleting ReplicationController wrapped-volume-race-8310a5f6-694b-4f24-9555-cbb8abf2f59e took: 12.817737ms
Jun 13 10:39:04.890: INFO: Terminating ReplicationController wrapped-volume-race-8310a5f6-694b-4f24-9555-cbb8abf2f59e pods took: 300.289993ms
STEP: Creating RC which spawns configmap-volume pods
Jun 13 10:39:45.411: INFO: Pod name wrapped-volume-race-4aa172e4-c8b1-4ec9-ab09-4b9b187c0c1d: Found 0 pods out of 5
Jun 13 10:39:50.418: INFO: Pod name wrapped-volume-race-4aa172e4-c8b1-4ec9-ab09-4b9b187c0c1d: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-4aa172e4-c8b1-4ec9-ab09-4b9b187c0c1d in namespace emptydir-wrapper-527, will wait for the garbage collector to delete the pods
Jun 13 10:40:00.518: INFO: Deleting ReplicationController wrapped-volume-race-4aa172e4-c8b1-4ec9-ab09-4b9b187c0c1d took: 11.955989ms
Jun 13 10:40:01.018: INFO: Terminating ReplicationController wrapped-volume-race-4aa172e4-c8b1-4ec9-ab09-4b9b187c0c1d pods took: 500.338157ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:40:46.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-527" for this suite.
Jun 13 10:40:54.034: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:40:54.161: INFO: namespace emptydir-wrapper-527 deletion completed in 8.142682517s

• [SLOW TEST:183.011 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:40:54.162: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Jun 13 10:40:56.881: INFO: Successfully updated pod "labelsupdatebda342c1-0a2e-4fe7-ae72-f97822b35c7e"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:40:58.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3304" for this suite.
Jun 13 10:41:18.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:41:19.339: INFO: namespace projected-3304 deletion completed in 20.429467019s

• [SLOW TEST:25.177 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:41:19.339: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:41:23.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7391" for this suite.
Jun 13 10:42:07.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:42:07.568: INFO: namespace kubelet-test-7391 deletion completed in 44.140148625s

• [SLOW TEST:48.229 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:42:07.569: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:42:09.660: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5870" for this suite.
Jun 13 10:42:53.680: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:42:53.815: INFO: namespace kubelet-test-5870 deletion completed in 44.150579724s

• [SLOW TEST:46.247 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:42:53.817: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Jun 13 10:42:53.859: INFO: Waiting up to 1m0s for all nodes to be ready
Jun 13 10:43:53.879: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 10:43:53.884: INFO: Starting informer...
STEP: Starting pods...
Jun 13 10:43:54.172: INFO: Pod1 is running on 10.0.10.2. Tainting Node
Jun 13 10:43:56.397: INFO: Pod2 is running on 10.0.10.2. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Jun 13 10:44:14.395: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Jun 13 10:44:34.372: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:44:34.392: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-1259" for this suite.
Jun 13 10:44:40.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:44:40.537: INFO: namespace taint-multiple-pods-1259 deletion completed in 6.139877687s

• [SLOW TEST:106.720 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:44:40.550: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:44:57.645: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9289" for this suite.
Jun 13 10:45:03.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:45:03.795: INFO: namespace resourcequota-9289 deletion completed in 6.145063896s

• [SLOW TEST:23.246 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:45:03.799: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Jun 13 10:45:03.854: INFO: Waiting up to 5m0s for pod "downward-api-8f21cad2-8019-4a5d-abe7-50b7b2005dab" in namespace "downward-api-2382" to be "success or failure"
Jun 13 10:45:03.859: INFO: Pod "downward-api-8f21cad2-8019-4a5d-abe7-50b7b2005dab": Phase="Pending", Reason="", readiness=false. Elapsed: 4.205258ms
Jun 13 10:45:05.864: INFO: Pod "downward-api-8f21cad2-8019-4a5d-abe7-50b7b2005dab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009545771s
STEP: Saw pod success
Jun 13 10:45:05.864: INFO: Pod "downward-api-8f21cad2-8019-4a5d-abe7-50b7b2005dab" satisfied condition "success or failure"
Jun 13 10:45:05.868: INFO: Trying to get logs from node 10.0.10.2 pod downward-api-8f21cad2-8019-4a5d-abe7-50b7b2005dab container dapi-container: <nil>
STEP: delete the pod
Jun 13 10:45:06.069: INFO: Waiting for pod downward-api-8f21cad2-8019-4a5d-abe7-50b7b2005dab to disappear
Jun 13 10:45:06.074: INFO: Pod downward-api-8f21cad2-8019-4a5d-abe7-50b7b2005dab no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:45:06.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2382" for this suite.
Jun 13 10:45:12.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:45:12.219: INFO: namespace downward-api-2382 deletion completed in 6.140743366s

• [SLOW TEST:8.421 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:45:12.219: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:45:18.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9012" for this suite.
Jun 13 10:45:24.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:45:24.558: INFO: namespace namespaces-9012 deletion completed in 6.169907429s
STEP: Destroying namespace "nsdeletetest-2690" for this suite.
Jun 13 10:45:24.562: INFO: Namespace nsdeletetest-2690 was already deleted
STEP: Destroying namespace "nsdeletetest-7853" for this suite.
Jun 13 10:45:30.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:45:30.707: INFO: namespace nsdeletetest-7853 deletion completed in 6.145507746s

• [SLOW TEST:18.488 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:45:30.710: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Jun 13 10:45:34.800: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-992 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 13 10:45:34.800: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 10:45:35.070: INFO: Exec stderr: ""
Jun 13 10:45:35.070: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-992 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 13 10:45:35.070: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 10:45:35.280: INFO: Exec stderr: ""
Jun 13 10:45:35.280: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-992 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 13 10:45:35.280: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 10:45:35.479: INFO: Exec stderr: ""
Jun 13 10:45:35.480: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-992 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 13 10:45:35.480: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 10:45:35.704: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Jun 13 10:45:35.705: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-992 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 13 10:45:35.705: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 10:45:35.922: INFO: Exec stderr: ""
Jun 13 10:45:35.922: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-992 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 13 10:45:35.922: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 10:45:36.172: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Jun 13 10:45:36.173: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-992 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 13 10:45:36.174: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 10:45:36.411: INFO: Exec stderr: ""
Jun 13 10:45:36.411: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-992 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 13 10:45:36.411: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 10:45:36.634: INFO: Exec stderr: ""
Jun 13 10:45:36.634: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-992 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 13 10:45:36.634: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 10:45:36.842: INFO: Exec stderr: ""
Jun 13 10:45:36.842: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-992 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 13 10:45:36.842: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 10:45:37.034: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:45:37.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-992" for this suite.
Jun 13 10:46:25.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:46:25.491: INFO: namespace e2e-kubelet-etc-hosts-992 deletion completed in 48.451998971s

• [SLOW TEST:54.782 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:46:25.491: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-042e1e46-0852-4862-8bff-4db6fd5f7b99
STEP: Creating a pod to test consume secrets
Jun 13 10:46:25.555: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ccf5b883-c3d9-480c-bde4-1594343b8bf5" in namespace "projected-3994" to be "success or failure"
Jun 13 10:46:25.560: INFO: Pod "pod-projected-secrets-ccf5b883-c3d9-480c-bde4-1594343b8bf5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.777723ms
Jun 13 10:46:27.566: INFO: Pod "pod-projected-secrets-ccf5b883-c3d9-480c-bde4-1594343b8bf5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010061592s
STEP: Saw pod success
Jun 13 10:46:27.566: INFO: Pod "pod-projected-secrets-ccf5b883-c3d9-480c-bde4-1594343b8bf5" satisfied condition "success or failure"
Jun 13 10:46:27.570: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-secrets-ccf5b883-c3d9-480c-bde4-1594343b8bf5 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 13 10:46:27.598: INFO: Waiting for pod pod-projected-secrets-ccf5b883-c3d9-480c-bde4-1594343b8bf5 to disappear
Jun 13 10:46:27.609: INFO: Pod pod-projected-secrets-ccf5b883-c3d9-480c-bde4-1594343b8bf5 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:46:27.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3994" for this suite.
Jun 13 10:46:33.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:46:33.818: INFO: namespace projected-3994 deletion completed in 6.202171008s

• [SLOW TEST:8.326 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:46:33.821: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:46:35.922: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5336" for this suite.
Jun 13 10:47:19.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:47:20.077: INFO: namespace kubelet-test-5336 deletion completed in 44.150235407s

• [SLOW TEST:46.258 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:47:20.078: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 13 10:47:20.911: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jun 13 10:47:22.923: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727642040, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727642040, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727642040, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727642040, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 13 10:47:25.939: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:47:26.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5352" for this suite.
Jun 13 10:47:32.337: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:47:32.459: INFO: namespace webhook-5352 deletion completed in 6.13782042s
STEP: Destroying namespace "webhook-5352-markers" for this suite.
Jun 13 10:47:38.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:47:38.604: INFO: namespace webhook-5352-markers deletion completed in 6.145003042s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.546 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:47:38.625: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Jun 13 10:47:38.679: INFO: Waiting up to 5m0s for pod "pod-afcfcc5d-a2fe-42ce-ad54-31a49cbf9c4e" in namespace "emptydir-3061" to be "success or failure"
Jun 13 10:47:38.684: INFO: Pod "pod-afcfcc5d-a2fe-42ce-ad54-31a49cbf9c4e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.448246ms
Jun 13 10:47:40.689: INFO: Pod "pod-afcfcc5d-a2fe-42ce-ad54-31a49cbf9c4e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009697302s
STEP: Saw pod success
Jun 13 10:47:40.689: INFO: Pod "pod-afcfcc5d-a2fe-42ce-ad54-31a49cbf9c4e" satisfied condition "success or failure"
Jun 13 10:47:40.693: INFO: Trying to get logs from node 10.0.10.2 pod pod-afcfcc5d-a2fe-42ce-ad54-31a49cbf9c4e container test-container: <nil>
STEP: delete the pod
Jun 13 10:47:40.730: INFO: Waiting for pod pod-afcfcc5d-a2fe-42ce-ad54-31a49cbf9c4e to disappear
Jun 13 10:47:40.735: INFO: Pod pod-afcfcc5d-a2fe-42ce-ad54-31a49cbf9c4e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:47:40.736: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3061" for this suite.
Jun 13 10:47:46.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:47:46.880: INFO: namespace emptydir-3061 deletion completed in 6.139477879s

• [SLOW TEST:8.256 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:47:46.881: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Jun 13 10:47:46.939: INFO: Waiting up to 5m0s for pod "pod-a6e7bdef-9126-4178-bc9c-c304019a62ba" in namespace "emptydir-6291" to be "success or failure"
Jun 13 10:47:46.943: INFO: Pod "pod-a6e7bdef-9126-4178-bc9c-c304019a62ba": Phase="Pending", Reason="", readiness=false. Elapsed: 4.664609ms
Jun 13 10:47:48.948: INFO: Pod "pod-a6e7bdef-9126-4178-bc9c-c304019a62ba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009143568s
STEP: Saw pod success
Jun 13 10:47:48.948: INFO: Pod "pod-a6e7bdef-9126-4178-bc9c-c304019a62ba" satisfied condition "success or failure"
Jun 13 10:47:48.951: INFO: Trying to get logs from node 10.0.10.2 pod pod-a6e7bdef-9126-4178-bc9c-c304019a62ba container test-container: <nil>
STEP: delete the pod
Jun 13 10:47:48.978: INFO: Waiting for pod pod-a6e7bdef-9126-4178-bc9c-c304019a62ba to disappear
Jun 13 10:47:48.982: INFO: Pod pod-a6e7bdef-9126-4178-bc9c-c304019a62ba no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:47:48.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6291" for this suite.
Jun 13 10:47:55.002: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:47:55.134: INFO: namespace emptydir-6291 deletion completed in 6.147678348s

• [SLOW TEST:8.254 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:47:55.136: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Jun 13 10:47:55.191: INFO: Waiting up to 5m0s for pod "downwardapi-volume-62f8d1c9-5835-48bd-a77e-0509d06b14a7" in namespace "projected-8032" to be "success or failure"
Jun 13 10:47:55.196: INFO: Pod "downwardapi-volume-62f8d1c9-5835-48bd-a77e-0509d06b14a7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.701866ms
Jun 13 10:47:57.201: INFO: Pod "downwardapi-volume-62f8d1c9-5835-48bd-a77e-0509d06b14a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009977039s
STEP: Saw pod success
Jun 13 10:47:57.201: INFO: Pod "downwardapi-volume-62f8d1c9-5835-48bd-a77e-0509d06b14a7" satisfied condition "success or failure"
Jun 13 10:47:57.205: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-62f8d1c9-5835-48bd-a77e-0509d06b14a7 container client-container: <nil>
STEP: delete the pod
Jun 13 10:47:57.260: INFO: Waiting for pod downwardapi-volume-62f8d1c9-5835-48bd-a77e-0509d06b14a7 to disappear
Jun 13 10:47:57.264: INFO: Pod downwardapi-volume-62f8d1c9-5835-48bd-a77e-0509d06b14a7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:47:57.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8032" for this suite.
Jun 13 10:48:03.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:48:03.409: INFO: namespace projected-8032 deletion completed in 6.141295236s

• [SLOW TEST:8.273 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:48:03.411: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Jun 13 10:48:03.466: INFO: Waiting up to 5m0s for pod "pod-cf186ef8-21c6-48a4-ae92-d7862b190f29" in namespace "emptydir-9521" to be "success or failure"
Jun 13 10:48:03.470: INFO: Pod "pod-cf186ef8-21c6-48a4-ae92-d7862b190f29": Phase="Pending", Reason="", readiness=false. Elapsed: 4.486017ms
Jun 13 10:48:05.476: INFO: Pod "pod-cf186ef8-21c6-48a4-ae92-d7862b190f29": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010187048s
STEP: Saw pod success
Jun 13 10:48:05.476: INFO: Pod "pod-cf186ef8-21c6-48a4-ae92-d7862b190f29" satisfied condition "success or failure"
Jun 13 10:48:05.480: INFO: Trying to get logs from node 10.0.10.2 pod pod-cf186ef8-21c6-48a4-ae92-d7862b190f29 container test-container: <nil>
STEP: delete the pod
Jun 13 10:48:05.503: INFO: Waiting for pod pod-cf186ef8-21c6-48a4-ae92-d7862b190f29 to disappear
Jun 13 10:48:05.507: INFO: Pod pod-cf186ef8-21c6-48a4-ae92-d7862b190f29 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:48:05.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9521" for this suite.
Jun 13 10:48:11.526: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:48:11.653: INFO: namespace emptydir-9521 deletion completed in 6.141231983s

• [SLOW TEST:8.242 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:48:11.653: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 10:48:11.713: INFO: (0) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 10.006206ms)
Jun 13 10:48:11.720: INFO: (1) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.756921ms)
Jun 13 10:48:11.727: INFO: (2) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.463566ms)
Jun 13 10:48:11.733: INFO: (3) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.076471ms)
Jun 13 10:48:11.747: INFO: (4) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 14.12442ms)
Jun 13 10:48:11.754: INFO: (5) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.487132ms)
Jun 13 10:48:11.760: INFO: (6) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.508198ms)
Jun 13 10:48:11.766: INFO: (7) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.851444ms)
Jun 13 10:48:11.773: INFO: (8) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 7.006425ms)
Jun 13 10:48:11.780: INFO: (9) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.945782ms)
Jun 13 10:48:11.787: INFO: (10) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.55086ms)
Jun 13 10:48:11.793: INFO: (11) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.186738ms)
Jun 13 10:48:11.799: INFO: (12) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.059347ms)
Jun 13 10:48:11.805: INFO: (13) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.721308ms)
Jun 13 10:48:11.811: INFO: (14) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.858231ms)
Jun 13 10:48:11.817: INFO: (15) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.893783ms)
Jun 13 10:48:11.825: INFO: (16) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.374148ms)
Jun 13 10:48:11.832: INFO: (17) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.570569ms)
Jun 13 10:48:11.838: INFO: (18) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.091008ms)
Jun 13 10:48:11.844: INFO: (19) /api/v1/nodes/10.0.10.2/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.149499ms)
[AfterEach] version v1
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:48:11.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1409" for this suite.
Jun 13 10:48:17.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:48:17.990: INFO: namespace proxy-1409 deletion completed in 6.141251794s

• [SLOW TEST:6.337 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:48:17.990: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1892
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-1892
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1892
Jun 13 10:48:18.061: INFO: Found 0 stateful pods, waiting for 1
Jun 13 10:48:28.077: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Jun 13 10:48:28.083: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jun 13 10:48:28.565: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jun 13 10:48:28.565: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jun 13 10:48:28.565: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jun 13 10:48:28.570: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Jun 13 10:48:38.575: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 13 10:48:38.575: INFO: Waiting for statefulset status.replicas updated to 0
Jun 13 10:48:38.595: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999506s
Jun 13 10:48:39.601: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996175051s
Jun 13 10:48:40.606: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.990847055s
Jun 13 10:48:41.612: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.985902122s
Jun 13 10:48:42.617: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.979598692s
Jun 13 10:48:43.622: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.9748881s
Jun 13 10:48:44.627: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.969499479s
Jun 13 10:48:45.632: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.96427664s
Jun 13 10:48:46.637: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.959343345s
Jun 13 10:48:47.642: INFO: Verifying statefulset ss doesn't scale past 1 for another 954.130298ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1892
Jun 13 10:48:48.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:48:48.959: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jun 13 10:48:48.959: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jun 13 10:48:48.959: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jun 13 10:48:48.964: INFO: Found 1 stateful pods, waiting for 3
Jun 13 10:48:58.970: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 13 10:48:58.970: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 13 10:48:58.970: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Jun 13 10:48:58.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jun 13 10:48:59.383: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jun 13 10:48:59.384: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jun 13 10:48:59.384: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jun 13 10:48:59.384: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jun 13 10:48:59.756: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jun 13 10:48:59.756: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jun 13 10:48:59.756: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jun 13 10:48:59.756: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jun 13 10:49:00.191: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jun 13 10:49:00.191: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jun 13 10:49:00.191: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jun 13 10:49:00.191: INFO: Waiting for statefulset status.replicas updated to 0
Jun 13 10:49:00.196: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Jun 13 10:49:10.208: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Jun 13 10:49:10.208: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Jun 13 10:49:10.208: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Jun 13 10:49:10.224: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999715s
Jun 13 10:49:11.229: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995925992s
Jun 13 10:49:12.234: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.990484826s
Jun 13 10:49:13.239: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.985325551s
Jun 13 10:49:14.244: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.980281113s
Jun 13 10:49:15.249: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.975344994s
Jun 13 10:49:16.255: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.970137724s
Jun 13 10:49:17.260: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.964831626s
Jun 13 10:49:18.265: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.9593659s
Jun 13 10:49:19.271: INFO: Verifying statefulset ss doesn't scale past 3 for another 954.285521ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1892
Jun 13 10:49:20.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:49:20.670: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jun 13 10:49:20.671: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jun 13 10:49:20.671: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jun 13 10:49:20.671: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:49:21.094: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jun 13 10:49:21.094: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jun 13 10:49:21.094: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jun 13 10:49:21.094: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:49:21.545: INFO: rc: 126
Jun 13 10:49:21.545: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:
OCI runtime exec failed: exec failed: cannot exec a container that has stopped: unknown

stderr:
command terminated with exit code 126

error:
exit status 126
Jun 13 10:49:31.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:49:31.763: INFO: rc: 1
Jun 13 10:49:31.766: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Jun 13 10:49:41.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:49:41.869: INFO: rc: 1
Jun 13 10:49:41.869: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:49:51.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:49:51.961: INFO: rc: 1
Jun 13 10:49:51.961: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:50:01.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:50:02.060: INFO: rc: 1
Jun 13 10:50:02.060: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:50:12.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:50:12.160: INFO: rc: 1
Jun 13 10:50:12.160: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:50:22.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:50:22.248: INFO: rc: 1
Jun 13 10:50:22.248: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:50:32.248: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:50:32.337: INFO: rc: 1
Jun 13 10:50:32.337: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:50:42.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:50:42.432: INFO: rc: 1
Jun 13 10:50:42.432: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:50:52.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:50:52.524: INFO: rc: 1
Jun 13 10:50:52.524: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:51:02.524: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:51:02.616: INFO: rc: 1
Jun 13 10:51:02.616: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:51:12.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:51:12.712: INFO: rc: 1
Jun 13 10:51:12.712: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:51:22.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:51:22.816: INFO: rc: 1
Jun 13 10:51:22.820: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:51:32.821: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:51:32.912: INFO: rc: 1
Jun 13 10:51:32.912: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:51:42.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:51:43.008: INFO: rc: 1
Jun 13 10:51:43.008: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:51:53.009: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:51:53.097: INFO: rc: 1
Jun 13 10:51:53.097: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:52:03.098: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:52:03.186: INFO: rc: 1
Jun 13 10:52:03.186: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:52:13.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:52:13.276: INFO: rc: 1
Jun 13 10:52:13.276: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:52:23.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:52:23.365: INFO: rc: 1
Jun 13 10:52:23.365: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:52:33.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:52:33.471: INFO: rc: 1
Jun 13 10:52:33.471: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:52:43.471: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:52:43.593: INFO: rc: 1
Jun 13 10:52:43.593: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:52:53.593: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:52:53.682: INFO: rc: 1
Jun 13 10:52:53.682: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:53:03.682: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:53:03.773: INFO: rc: 1
Jun 13 10:53:03.773: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:53:13.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:53:13.867: INFO: rc: 1
Jun 13 10:53:13.867: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:53:23.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:53:23.965: INFO: rc: 1
Jun 13 10:53:23.965: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:53:33.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:53:34.056: INFO: rc: 1
Jun 13 10:53:34.056: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:53:44.056: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:53:44.143: INFO: rc: 1
Jun 13 10:53:44.143: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:53:54.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:53:54.234: INFO: rc: 1
Jun 13 10:53:54.234: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:54:04.234: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:54:04.336: INFO: rc: 1
Jun 13 10:54:04.336: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:54:14.336: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:54:14.430: INFO: rc: 1
Jun 13 10:54:14.430: INFO: Waiting 10s to retry failed RunHostCmd: error running /usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Jun 13 10:54:24.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-1892 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 10:54:24.519: INFO: rc: 1
Jun 13 10:54:24.519: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
Jun 13 10:54:24.519: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Jun 13 10:54:24.539: INFO: Deleting all statefulset in ns statefulset-1892
Jun 13 10:54:24.545: INFO: Scaling statefulset ss to 0
Jun 13 10:54:24.556: INFO: Waiting for statefulset status.replicas updated to 0
Jun 13 10:54:24.560: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:54:24.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1892" for this suite.
Jun 13 10:54:30.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:54:31.019: INFO: namespace statefulset-1892 deletion completed in 6.433265095s

• [SLOW TEST:373.029 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:54:31.021: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jun 13 10:54:33.614: INFO: Successfully updated pod "pod-update-20f43fb0-3008-4ab6-bd8c-1b353058b9d6"
STEP: verifying the updated pod is in kubernetes
Jun 13 10:54:33.621: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:54:33.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9482" for this suite.
Jun 13 10:54:45.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:54:45.767: INFO: namespace pods-9482 deletion completed in 12.141665711s

• [SLOW TEST:14.748 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:54:45.772: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-2279
STEP: creating replication controller nodeport-test in namespace services-2279
I0613 10:54:45.839618      22 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-2279, replica count: 2
I0613 10:54:48.890102      22 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jun 13 10:54:48.890: INFO: Creating new exec pod
Jun 13 10:54:53.915: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=services-2279 execpodx2qjt -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Jun 13 10:54:54.284: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Jun 13 10:54:54.284: INFO: stdout: ""
Jun 13 10:54:54.286: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=services-2279 execpodx2qjt -- /bin/sh -x -c nc -zv -t -w 2 10.96.217.57 80'
Jun 13 10:54:54.656: INFO: stderr: "+ nc -zv -t -w 2 10.96.217.57 80\nConnection to 10.96.217.57 80 port [tcp/http] succeeded!\n"
Jun 13 10:54:54.656: INFO: stdout: ""
Jun 13 10:54:54.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=services-2279 execpodx2qjt -- /bin/sh -x -c nc -zv -t -w 2 10.0.10.2 31909'
Jun 13 10:54:54.955: INFO: stderr: "+ nc -zv -t -w 2 10.0.10.2 31909\nConnection to 10.0.10.2 31909 port [tcp/31909] succeeded!\n"
Jun 13 10:54:54.955: INFO: stdout: ""
Jun 13 10:54:54.955: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=services-2279 execpodx2qjt -- /bin/sh -x -c nc -zv -t -w 2 10.0.10.3 31909'
Jun 13 10:54:55.269: INFO: stderr: "+ nc -zv -t -w 2 10.0.10.3 31909\nConnection to 10.0.10.3 31909 port [tcp/31909] succeeded!\n"
Jun 13 10:54:55.269: INFO: stdout: ""
Jun 13 10:54:55.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=services-2279 execpodx2qjt -- /bin/sh -x -c nc -zv -t -w 2 168.138.67.181 31909'
Jun 13 10:54:55.567: INFO: stderr: "+ nc -zv -t -w 2 168.138.67.181 31909\nConnection to 168.138.67.181 31909 port [tcp/31909] succeeded!\n"
Jun 13 10:54:55.567: INFO: stdout: ""
Jun 13 10:54:55.567: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=services-2279 execpodx2qjt -- /bin/sh -x -c nc -zv -t -w 2 168.138.66.177 31909'
Jun 13 10:54:55.863: INFO: stderr: "+ nc -zv -t -w 2 168.138.66.177 31909\nConnection to 168.138.66.177 31909 port [tcp/31909] succeeded!\n"
Jun 13 10:54:55.863: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:54:55.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2279" for this suite.
Jun 13 10:55:01.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:55:02.020: INFO: namespace services-2279 deletion completed in 6.152002268s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:16.249 seconds]
[sig-network] Services
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:55:02.021: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Jun 13 10:55:02.099: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c1e1aacf-34f1-48b7-9c34-c21a6bfe444a" in namespace "projected-5700" to be "success or failure"
Jun 13 10:55:02.104: INFO: Pod "downwardapi-volume-c1e1aacf-34f1-48b7-9c34-c21a6bfe444a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.081658ms
Jun 13 10:55:04.108: INFO: Pod "downwardapi-volume-c1e1aacf-34f1-48b7-9c34-c21a6bfe444a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00879135s
Jun 13 10:55:06.114: INFO: Pod "downwardapi-volume-c1e1aacf-34f1-48b7-9c34-c21a6bfe444a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01434806s
STEP: Saw pod success
Jun 13 10:55:06.114: INFO: Pod "downwardapi-volume-c1e1aacf-34f1-48b7-9c34-c21a6bfe444a" satisfied condition "success or failure"
Jun 13 10:55:06.119: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-c1e1aacf-34f1-48b7-9c34-c21a6bfe444a container client-container: <nil>
STEP: delete the pod
Jun 13 10:55:06.275: INFO: Waiting for pod downwardapi-volume-c1e1aacf-34f1-48b7-9c34-c21a6bfe444a to disappear
Jun 13 10:55:06.280: INFO: Pod downwardapi-volume-c1e1aacf-34f1-48b7-9c34-c21a6bfe444a no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:55:06.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5700" for this suite.
Jun 13 10:55:12.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:55:12.426: INFO: namespace projected-5700 deletion completed in 6.141935577s

• [SLOW TEST:10.404 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:55:12.426: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Jun 13 10:55:12.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-1864'
Jun 13 10:55:12.583: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun 13 10:55:12.583: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Jun 13 10:55:12.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 delete jobs e2e-test-httpd-job --namespace=kubectl-1864'
Jun 13 10:55:12.696: INFO: stderr: ""
Jun 13 10:55:12.696: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:55:12.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1864" for this suite.
Jun 13 10:55:40.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:55:40.848: INFO: namespace kubectl-1864 deletion completed in 28.145691146s

• [SLOW TEST:28.422 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:55:40.849: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 10:55:40.896: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:55:43.125: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6390" for this suite.
Jun 13 10:56:27.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:56:27.266: INFO: namespace pods-6390 deletion completed in 44.135512639s

• [SLOW TEST:46.416 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:56:27.266: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-6195
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-6195
STEP: creating replication controller externalsvc in namespace services-6195
I0613 10:56:27.348611      22 runners.go:184] Created replication controller with name: externalsvc, namespace: services-6195, replica count: 2
I0613 10:56:30.401412      22 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Jun 13 10:56:30.427: INFO: Creating new exec pod
Jun 13 10:56:32.452: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=services-6195 execpodlx8ln -- /bin/sh -x -c nslookup nodeport-service'
Jun 13 10:56:32.786: INFO: stderr: "+ nslookup nodeport-service\n"
Jun 13 10:56:32.786: INFO: stdout: "Server:\t\t10.96.5.5\nAddress:\t10.96.5.5#53\n\nnodeport-service.services-6195.svc.cluster.local\tcanonical name = externalsvc.services-6195.svc.cluster.local.\nName:\texternalsvc.services-6195.svc.cluster.local\nAddress: 10.96.45.249\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-6195, will wait for the garbage collector to delete the pods
Jun 13 10:56:32.853: INFO: Deleting ReplicationController externalsvc took: 11.630064ms
Jun 13 10:56:33.153: INFO: Terminating ReplicationController externalsvc pods took: 300.248884ms
Jun 13 10:56:43.576: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:56:43.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6195" for this suite.
Jun 13 10:56:49.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:56:49.749: INFO: namespace services-6195 deletion completed in 6.149239309s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:22.483 seconds]
[sig-network] Services
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:56:49.752: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-fc5293aa-1142-4b75-8336-ff964e6ae1fc
STEP: Creating configMap with name cm-test-opt-upd-09ab93d1-5b4b-4902-b634-5cdbc41fcef0
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-fc5293aa-1142-4b75-8336-ff964e6ae1fc
STEP: Updating configmap cm-test-opt-upd-09ab93d1-5b4b-4902-b634-5cdbc41fcef0
STEP: Creating configMap with name cm-test-opt-create-6c916c77-7d9d-497d-84af-5015524a6211
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:58:21.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3594" for this suite.
Jun 13 10:58:35.781: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:58:35.914: INFO: namespace projected-3594 deletion completed in 14.149404529s

• [SLOW TEST:106.163 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:58:35.917: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-6905
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-6905
I0613 10:58:35.998656      22 runners.go:184] Created replication controller with name: externalname-service, namespace: services-6905, replica count: 2
Jun 13 10:58:39.111: INFO: Creating new exec pod
I0613 10:58:39.111702      22 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jun 13 10:58:42.133: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=services-6905 execpodjxspf -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Jun 13 10:58:42.620: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Jun 13 10:58:42.620: INFO: stdout: ""
Jun 13 10:58:42.620: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=services-6905 execpodjxspf -- /bin/sh -x -c nc -zv -t -w 2 10.96.116.125 80'
Jun 13 10:58:43.172: INFO: stderr: "+ nc -zv -t -w 2 10.96.116.125 80\nConnection to 10.96.116.125 80 port [tcp/http] succeeded!\n"
Jun 13 10:58:43.172: INFO: stdout: ""
Jun 13 10:58:43.172: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:58:43.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6905" for this suite.
Jun 13 10:58:49.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:58:49.350: INFO: namespace services-6905 deletion completed in 6.146265422s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.433 seconds]
[sig-network] Services
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:58:49.350: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 13 10:58:50.213: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jun 13 10:58:52.225: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727642730, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727642730, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727642730, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727642730, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 13 10:58:55.242: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:58:55.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6212" for this suite.
Jun 13 10:59:01.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:59:01.602: INFO: namespace webhook-6212 deletion completed in 6.143098976s
STEP: Destroying namespace "webhook-6212-markers" for this suite.
Jun 13 10:59:07.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:59:07.737: INFO: namespace webhook-6212-markers deletion completed in 6.135762661s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.407 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:59:07.757: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 13 10:59:08.562: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 13 10:59:11.590: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:59:11.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7240" for this suite.
Jun 13 10:59:17.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:59:17.899: INFO: namespace webhook-7240 deletion completed in 6.137526019s
STEP: Destroying namespace "webhook-7240-markers" for this suite.
Jun 13 10:59:23.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:59:24.052: INFO: namespace webhook-7240-markers deletion completed in 6.152232266s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.314 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:59:24.073: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Jun 13 10:59:24.133: INFO: Waiting up to 5m0s for pod "client-containers-a2f7e8c0-5d95-4050-ab32-3d1613e439bd" in namespace "containers-5813" to be "success or failure"
Jun 13 10:59:24.137: INFO: Pod "client-containers-a2f7e8c0-5d95-4050-ab32-3d1613e439bd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.400038ms
Jun 13 10:59:26.142: INFO: Pod "client-containers-a2f7e8c0-5d95-4050-ab32-3d1613e439bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009341041s
STEP: Saw pod success
Jun 13 10:59:26.142: INFO: Pod "client-containers-a2f7e8c0-5d95-4050-ab32-3d1613e439bd" satisfied condition "success or failure"
Jun 13 10:59:26.147: INFO: Trying to get logs from node 10.0.10.2 pod client-containers-a2f7e8c0-5d95-4050-ab32-3d1613e439bd container test-container: <nil>
STEP: delete the pod
Jun 13 10:59:26.171: INFO: Waiting for pod client-containers-a2f7e8c0-5d95-4050-ab32-3d1613e439bd to disappear
Jun 13 10:59:26.174: INFO: Pod client-containers-a2f7e8c0-5d95-4050-ab32-3d1613e439bd no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:59:26.175: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5813" for this suite.
Jun 13 10:59:32.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 10:59:32.597: INFO: namespace containers-5813 deletion completed in 6.418201422s

• [SLOW TEST:8.525 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 10:59:32.598: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-50cea698-89a4-4ff7-84bd-a66ee6126fed
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 10:59:36.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3477" for this suite.
Jun 13 11:00:00.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:00:00.900: INFO: namespace configmap-3477 deletion completed in 24.14896189s

• [SLOW TEST:28.302 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:00:00.901: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:00:05.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4654" for this suite.
Jun 13 11:00:17.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:00:17.275: INFO: namespace containers-4654 deletion completed in 12.155056438s

• [SLOW TEST:16.375 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:00:17.276: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-35e45245-db3c-4365-83f1-15c050ab477b
STEP: Creating a pod to test consume secrets
Jun 13 11:00:17.336: INFO: Waiting up to 5m0s for pod "pod-secrets-33607e1b-89c1-4893-a39d-3ff7848f0dec" in namespace "secrets-2666" to be "success or failure"
Jun 13 11:00:17.340: INFO: Pod "pod-secrets-33607e1b-89c1-4893-a39d-3ff7848f0dec": Phase="Pending", Reason="", readiness=false. Elapsed: 4.393129ms
Jun 13 11:00:19.345: INFO: Pod "pod-secrets-33607e1b-89c1-4893-a39d-3ff7848f0dec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008968669s
STEP: Saw pod success
Jun 13 11:00:19.345: INFO: Pod "pod-secrets-33607e1b-89c1-4893-a39d-3ff7848f0dec" satisfied condition "success or failure"
Jun 13 11:00:19.349: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-33607e1b-89c1-4893-a39d-3ff7848f0dec container secret-env-test: <nil>
STEP: delete the pod
Jun 13 11:00:19.460: INFO: Waiting for pod pod-secrets-33607e1b-89c1-4893-a39d-3ff7848f0dec to disappear
Jun 13 11:00:19.464: INFO: Pod pod-secrets-33607e1b-89c1-4893-a39d-3ff7848f0dec no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:00:19.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2666" for this suite.
Jun 13 11:00:25.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:00:25.612: INFO: namespace secrets-2666 deletion completed in 6.143860155s

• [SLOW TEST:8.336 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:00:25.614: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 13 11:00:26.447: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jun 13 11:00:28.459: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727642826, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727642826, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727642826, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727642826, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 13 11:00:31.477: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 11:00:31.484: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-9112-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:00:32.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1937" for this suite.
Jun 13 11:00:38.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:00:38.900: INFO: namespace webhook-1937 deletion completed in 6.139727565s
STEP: Destroying namespace "webhook-1937-markers" for this suite.
Jun 13 11:00:44.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:00:45.043: INFO: namespace webhook-1937-markers deletion completed in 6.143059781s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.449 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:00:45.064: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:00:49.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3035" for this suite.
Jun 13 11:00:55.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:00:55.287: INFO: namespace kubelet-test-3035 deletion completed in 6.152011401s

• [SLOW TEST:10.224 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:00:55.288: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Jun 13 11:00:55.347: INFO: Waiting up to 5m0s for pod "downwardapi-volume-888e8c66-685d-4206-b0c0-4895887df186" in namespace "downward-api-1192" to be "success or failure"
Jun 13 11:00:55.351: INFO: Pod "downwardapi-volume-888e8c66-685d-4206-b0c0-4895887df186": Phase="Pending", Reason="", readiness=false. Elapsed: 4.093472ms
Jun 13 11:00:57.356: INFO: Pod "downwardapi-volume-888e8c66-685d-4206-b0c0-4895887df186": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008366446s
Jun 13 11:00:59.362: INFO: Pod "downwardapi-volume-888e8c66-685d-4206-b0c0-4895887df186": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014350228s
STEP: Saw pod success
Jun 13 11:00:59.362: INFO: Pod "downwardapi-volume-888e8c66-685d-4206-b0c0-4895887df186" satisfied condition "success or failure"
Jun 13 11:00:59.366: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-888e8c66-685d-4206-b0c0-4895887df186 container client-container: <nil>
STEP: delete the pod
Jun 13 11:00:59.392: INFO: Waiting for pod downwardapi-volume-888e8c66-685d-4206-b0c0-4895887df186 to disappear
Jun 13 11:00:59.397: INFO: Pod downwardapi-volume-888e8c66-685d-4206-b0c0-4895887df186 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:00:59.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1192" for this suite.
Jun 13 11:01:05.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:01:05.558: INFO: namespace downward-api-1192 deletion completed in 6.155490285s

• [SLOW TEST:10.270 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:01:05.559: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Jun 13 11:01:05.606: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun 13 11:01:05.623: INFO: Waiting for terminating namespaces to be deleted...
Jun 13 11:01:05.628: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.2 before test
Jun 13 11:01:05.641: INFO: kube-proxy-mbpxz from kube-system started at 2020-06-13 03:16:34 +0000 UTC (1 container statuses recorded)
Jun 13 11:01:05.641: INFO: 	Container kube-proxy ready: true, restart count 0
Jun 13 11:01:05.641: INFO: kube-flannel-ds-mddmt from kube-system started at 2020-06-13 03:16:34 +0000 UTC (1 container statuses recorded)
Jun 13 11:01:05.641: INFO: 	Container kube-flannel ready: true, restart count 1
Jun 13 11:01:05.641: INFO: proxymux-client-m58g5 from kube-system started at 2020-06-13 10:44:34 +0000 UTC (1 container statuses recorded)
Jun 13 11:01:05.641: INFO: 	Container proxymux-client ready: true, restart count 0
Jun 13 11:01:05.641: INFO: csi-oci-node-gnmh9 from kube-system started at 2020-06-13 10:44:34 +0000 UTC (1 container statuses recorded)
Jun 13 11:01:05.641: INFO: 	Container csi-node-driver ready: true, restart count 0
Jun 13 11:01:05.641: INFO: sonobuoy-systemd-logs-daemon-set-89d5b422bcff4ee4-jptvl from sonobuoy started at 2020-06-13 09:55:07 +0000 UTC (2 container statuses recorded)
Jun 13 11:01:05.641: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jun 13 11:01:05.641: INFO: 	Container systemd-logs ready: true, restart count 0
Jun 13 11:01:05.641: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.3 before test
Jun 13 11:01:05.742: INFO: kube-flannel-ds-6cxw2 from kube-system started at 2020-06-13 03:16:34 +0000 UTC (1 container statuses recorded)
Jun 13 11:01:05.742: INFO: 	Container kube-flannel ready: true, restart count 1
Jun 13 11:01:05.742: INFO: proxymux-client-mshct from kube-system started at 2020-06-13 03:16:54 +0000 UTC (1 container statuses recorded)
Jun 13 11:01:05.742: INFO: 	Container proxymux-client ready: true, restart count 0
Jun 13 11:01:05.742: INFO: sonobuoy-e2e-job-eae45311abd24acb from sonobuoy started at 2020-06-13 09:55:07 +0000 UTC (2 container statuses recorded)
Jun 13 11:01:05.742: INFO: 	Container e2e ready: true, restart count 0
Jun 13 11:01:05.742: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 13 11:01:05.742: INFO: coredns-6f9ff9bd47-kp5rh from kube-system started at 2020-06-13 10:43:57 +0000 UTC (1 container statuses recorded)
Jun 13 11:01:05.742: INFO: 	Container coredns ready: true, restart count 0
Jun 13 11:01:05.742: INFO: kubernetes-dashboard-56b6bf4bf-65jz6 from kube-system started at 2020-06-13 03:16:53 +0000 UTC (1 container statuses recorded)
Jun 13 11:01:05.742: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jun 13 11:01:05.742: INFO: kube-proxy-6vf8c from kube-system started at 2020-06-13 03:16:34 +0000 UTC (1 container statuses recorded)
Jun 13 11:01:05.742: INFO: 	Container kube-proxy ready: true, restart count 0
Jun 13 11:01:05.742: INFO: csi-oci-node-hhfs6 from kube-system started at 2020-06-13 03:16:54 +0000 UTC (1 container statuses recorded)
Jun 13 11:01:05.742: INFO: 	Container csi-node-driver ready: true, restart count 0
Jun 13 11:01:05.742: INFO: sonobuoy from sonobuoy started at 2020-06-13 09:55:05 +0000 UTC (1 container statuses recorded)
Jun 13 11:01:05.742: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun 13 11:01:05.742: INFO: sonobuoy-systemd-logs-daemon-set-89d5b422bcff4ee4-z5xtf from sonobuoy started at 2020-06-13 09:55:07 +0000 UTC (2 container statuses recorded)
Jun 13 11:01:05.742: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jun 13 11:01:05.742: INFO: 	Container systemd-logs ready: true, restart count 0
Jun 13 11:01:05.742: INFO: kube-dns-autoscaler-75565f7896-hm82m from kube-system started at 2020-06-13 03:17:03 +0000 UTC (1 container statuses recorded)
Jun 13 11:01:05.742: INFO: 	Container autoscaler ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-8f7f0837-ba1e-4188-945c-02d3f5139b13 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-8f7f0837-ba1e-4188-945c-02d3f5139b13 off the node 10.0.10.2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-8f7f0837-ba1e-4188-945c-02d3f5139b13
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:01:11.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4847" for this suite.
Jun 13 11:01:19.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:01:19.990: INFO: namespace sched-pred-4847 deletion completed in 8.144406356s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:14.432 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:01:19.991: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-49c7bdd0-60fa-4a27-b2bc-ce35261b14ba
STEP: Creating configMap with name cm-test-opt-upd-8669a019-5a58-49a6-8ab4-418e749d7739
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-49c7bdd0-60fa-4a27-b2bc-ce35261b14ba
STEP: Updating configmap cm-test-opt-upd-8669a019-5a58-49a6-8ab4-418e749d7739
STEP: Creating configMap with name cm-test-opt-create-2c872d1e-d422-4255-baac-2b05e2f04297
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:02:54.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3308" for this suite.
Jun 13 11:03:06.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:03:06.293: INFO: namespace configmap-3308 deletion completed in 12.139869967s

• [SLOW TEST:106.302 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:03:06.294: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Jun 13 11:03:10.929: INFO: Successfully updated pod "adopt-release-cw8tq"
STEP: Checking that the Job readopts the Pod
Jun 13 11:03:10.929: INFO: Waiting up to 15m0s for pod "adopt-release-cw8tq" in namespace "job-9007" to be "adopted"
Jun 13 11:03:10.932: INFO: Pod "adopt-release-cw8tq": Phase="Running", Reason="", readiness=true. Elapsed: 3.738049ms
Jun 13 11:03:12.937: INFO: Pod "adopt-release-cw8tq": Phase="Running", Reason="", readiness=true. Elapsed: 2.008369135s
Jun 13 11:03:12.937: INFO: Pod "adopt-release-cw8tq" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Jun 13 11:03:13.447: INFO: Successfully updated pod "adopt-release-cw8tq"
STEP: Checking that the Job releases the Pod
Jun 13 11:03:13.447: INFO: Waiting up to 15m0s for pod "adopt-release-cw8tq" in namespace "job-9007" to be "released"
Jun 13 11:03:13.451: INFO: Pod "adopt-release-cw8tq": Phase="Running", Reason="", readiness=true. Elapsed: 3.012843ms
Jun 13 11:03:15.456: INFO: Pod "adopt-release-cw8tq": Phase="Running", Reason="", readiness=true. Elapsed: 2.008094377s
Jun 13 11:03:15.456: INFO: Pod "adopt-release-cw8tq" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:03:15.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9007" for this suite.
Jun 13 11:04:07.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:04:07.604: INFO: namespace job-9007 deletion completed in 52.142956618s

• [SLOW TEST:61.310 seconds]
[sig-apps] Job
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:04:07.605: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:04:14.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1523" for this suite.
Jun 13 11:04:20.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:04:20.814: INFO: namespace resourcequota-1523 deletion completed in 6.141933962s

• [SLOW TEST:13.210 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:04:20.815: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 11:04:20.872: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Jun 13 11:04:20.887: INFO: Number of nodes with available pods: 0
Jun 13 11:04:20.888: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Jun 13 11:04:20.907: INFO: Number of nodes with available pods: 0
Jun 13 11:04:20.907: INFO: Node 10.0.10.2 is running more than one daemon pod
Jun 13 11:04:21.911: INFO: Number of nodes with available pods: 0
Jun 13 11:04:21.911: INFO: Node 10.0.10.2 is running more than one daemon pod
Jun 13 11:04:22.911: INFO: Number of nodes with available pods: 1
Jun 13 11:04:22.911: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Jun 13 11:04:22.931: INFO: Number of nodes with available pods: 1
Jun 13 11:04:22.931: INFO: Number of running nodes: 0, number of available pods: 1
Jun 13 11:04:23.936: INFO: Number of nodes with available pods: 0
Jun 13 11:04:23.936: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Jun 13 11:04:23.951: INFO: Number of nodes with available pods: 0
Jun 13 11:04:23.951: INFO: Node 10.0.10.2 is running more than one daemon pod
Jun 13 11:04:24.956: INFO: Number of nodes with available pods: 0
Jun 13 11:04:24.956: INFO: Node 10.0.10.2 is running more than one daemon pod
Jun 13 11:04:25.956: INFO: Number of nodes with available pods: 0
Jun 13 11:04:25.956: INFO: Node 10.0.10.2 is running more than one daemon pod
Jun 13 11:04:26.957: INFO: Number of nodes with available pods: 0
Jun 13 11:04:26.957: INFO: Node 10.0.10.2 is running more than one daemon pod
Jun 13 11:04:27.956: INFO: Number of nodes with available pods: 0
Jun 13 11:04:27.956: INFO: Node 10.0.10.2 is running more than one daemon pod
Jun 13 11:04:28.956: INFO: Number of nodes with available pods: 1
Jun 13 11:04:28.956: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1958, will wait for the garbage collector to delete the pods
Jun 13 11:04:29.029: INFO: Deleting DaemonSet.extensions daemon-set took: 11.890495ms
Jun 13 11:04:29.330: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.228975ms
Jun 13 11:04:32.934: INFO: Number of nodes with available pods: 0
Jun 13 11:04:32.934: INFO: Number of running nodes: 0, number of available pods: 0
Jun 13 11:04:32.938: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1958/daemonsets","resourceVersion":"106058"},"items":null}

Jun 13 11:04:32.941: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1958/pods","resourceVersion":"106058"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:04:32.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1958" for this suite.
Jun 13 11:04:38.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:04:39.400: INFO: namespace daemonsets-1958 deletion completed in 6.433077978s

• [SLOW TEST:18.585 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:04:39.401: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Jun 13 11:04:39.471: INFO: Waiting up to 5m0s for pod "pod-0f0802ba-0037-472f-bd18-713905371fdf" in namespace "emptydir-1430" to be "success or failure"
Jun 13 11:04:39.476: INFO: Pod "pod-0f0802ba-0037-472f-bd18-713905371fdf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.356391ms
Jun 13 11:04:41.480: INFO: Pod "pod-0f0802ba-0037-472f-bd18-713905371fdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008715345s
STEP: Saw pod success
Jun 13 11:04:41.480: INFO: Pod "pod-0f0802ba-0037-472f-bd18-713905371fdf" satisfied condition "success or failure"
Jun 13 11:04:41.484: INFO: Trying to get logs from node 10.0.10.2 pod pod-0f0802ba-0037-472f-bd18-713905371fdf container test-container: <nil>
STEP: delete the pod
Jun 13 11:04:41.665: INFO: Waiting for pod pod-0f0802ba-0037-472f-bd18-713905371fdf to disappear
Jun 13 11:04:41.670: INFO: Pod pod-0f0802ba-0037-472f-bd18-713905371fdf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:04:41.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1430" for this suite.
Jun 13 11:04:47.690: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:04:47.810: INFO: namespace emptydir-1430 deletion completed in 6.135991421s

• [SLOW TEST:8.410 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:04:47.811: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Jun 13 11:04:50.898: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:04:51.916: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-8803" for this suite.
Jun 13 11:05:09.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:05:10.065: INFO: namespace replicaset-8803 deletion completed in 18.145113979s

• [SLOW TEST:22.255 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:05:10.067: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Jun 13 11:05:10.122: INFO: Waiting up to 5m0s for pod "downward-api-a2a0683a-12be-4b66-9d38-9918033fdcb0" in namespace "downward-api-7442" to be "success or failure"
Jun 13 11:05:10.126: INFO: Pod "downward-api-a2a0683a-12be-4b66-9d38-9918033fdcb0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.304095ms
Jun 13 11:05:12.131: INFO: Pod "downward-api-a2a0683a-12be-4b66-9d38-9918033fdcb0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009351147s
STEP: Saw pod success
Jun 13 11:05:12.131: INFO: Pod "downward-api-a2a0683a-12be-4b66-9d38-9918033fdcb0" satisfied condition "success or failure"
Jun 13 11:05:12.136: INFO: Trying to get logs from node 10.0.10.2 pod downward-api-a2a0683a-12be-4b66-9d38-9918033fdcb0 container dapi-container: <nil>
STEP: delete the pod
Jun 13 11:05:12.161: INFO: Waiting for pod downward-api-a2a0683a-12be-4b66-9d38-9918033fdcb0 to disappear
Jun 13 11:05:12.166: INFO: Pod downward-api-a2a0683a-12be-4b66-9d38-9918033fdcb0 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:05:12.166: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7442" for this suite.
Jun 13 11:05:18.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:05:18.306: INFO: namespace downward-api-7442 deletion completed in 6.135450445s

• [SLOW TEST:8.238 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:05:18.315: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Jun 13 11:05:18.361: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:05:22.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7641" for this suite.
Jun 13 11:05:28.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:05:28.695: INFO: namespace init-container-7641 deletion completed in 6.145074719s

• [SLOW TEST:10.381 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:05:28.696: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Jun 13 11:05:28.736: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-257530218 proxy --unix-socket=/tmp/kubectl-proxy-unix595171637/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:05:28.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7955" for this suite.
Jun 13 11:05:34.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:05:34.993: INFO: namespace kubectl-7955 deletion completed in 6.15809263s

• [SLOW TEST:6.297 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:05:34.994: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-6bbb1842-b91b-4d75-819e-43371dbc6a3d
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-6bbb1842-b91b-4d75-819e-43371dbc6a3d
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:05:39.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8251" for this suite.
Jun 13 11:05:55.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:05:55.307: INFO: namespace configmap-8251 deletion completed in 16.143687756s

• [SLOW TEST:20.313 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:05:55.308: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 11:05:55.367: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-fe223edd-86b3-4713-8f4b-a4f04bf8b6a8" in namespace "security-context-test-4495" to be "success or failure"
Jun 13 11:05:55.372: INFO: Pod "alpine-nnp-false-fe223edd-86b3-4713-8f4b-a4f04bf8b6a8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.315232ms
Jun 13 11:05:57.376: INFO: Pod "alpine-nnp-false-fe223edd-86b3-4713-8f4b-a4f04bf8b6a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008618368s
Jun 13 11:05:57.376: INFO: Pod "alpine-nnp-false-fe223edd-86b3-4713-8f4b-a4f04bf8b6a8" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:05:57.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4495" for this suite.
Jun 13 11:06:03.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:06:03.561: INFO: namespace security-context-test-4495 deletion completed in 6.166236915s

• [SLOW TEST:8.254 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:06:03.569: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 11:06:03.612: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Jun 13 11:06:03.626: INFO: Pod name sample-pod: Found 0 pods out of 1
Jun 13 11:06:08.631: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jun 13 11:06:08.632: INFO: Creating deployment "test-rolling-update-deployment"
Jun 13 11:06:08.640: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Jun 13 11:06:08.649: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Jun 13 11:06:10.659: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Jun 13 11:06:10.663: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727643168, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727643168, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727643168, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727643168, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 13 11:06:12.668: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Jun 13 11:06:12.683: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-9217 /apis/apps/v1/namespaces/deployment-9217/deployments/test-rolling-update-deployment 90585c01-a9e8-4360-9bd9-360c1b15e086 106609 1 2020-06-13 11:06:08 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0036a9798 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-06-13 11:06:08 +0000 UTC,LastTransitionTime:2020-06-13 11:06:08 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2020-06-13 11:06:10 +0000 UTC,LastTransitionTime:2020-06-13 11:06:08 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jun 13 11:06:12.688: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-9217 /apis/apps/v1/namespaces/deployment-9217/replicasets/test-rolling-update-deployment-55d946486 aec7f458-f1d4-4638-abba-0391bea38c1f 106599 1 2020-06-13 11:06:08 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 90585c01-a9e8-4360-9bd9-360c1b15e086 0xc0036a9c80 0xc0036a9c81}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0036a9ce8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jun 13 11:06:12.688: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Jun 13 11:06:12.688: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-9217 /apis/apps/v1/namespaces/deployment-9217/replicasets/test-rolling-update-controller 28774607-3484-4af4-82f6-48090671a532 106608 2 2020-06-13 11:06:03 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 90585c01-a9e8-4360-9bd9-360c1b15e086 0xc0036a9bb7 0xc0036a9bb8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0036a9c18 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jun 13 11:06:12.693: INFO: Pod "test-rolling-update-deployment-55d946486-b8nt2" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-b8nt2 test-rolling-update-deployment-55d946486- deployment-9217 /api/v1/namespaces/deployment-9217/pods/test-rolling-update-deployment-55d946486-b8nt2 27c4625a-9661-4f76-a075-40dd0dc0c1f8 106598 0 2020-06-13 11:06:08 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 aec7f458-f1d4-4638-abba-0391bea38c1f 0xc0066181d0 0xc0066181d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2gzfx,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2gzfx,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2gzfx,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:06:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:06:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:06:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:06:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.1.60,StartTime:2020-06-13 11:06:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-13 11:06:10 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://3b192df55c73867d6a88d6faf5cb76dff72f0938a8f1d185676c6b20efc20c05,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.60,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:06:12.693: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9217" for this suite.
Jun 13 11:06:18.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:06:18.851: INFO: namespace deployment-9217 deletion completed in 6.153202587s

• [SLOW TEST:15.282 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:06:18.856: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Jun 13 11:06:20.978: INFO: Pod pod-hostip-e3596a23-e3dd-4605-bcde-780df3b1598f has hostIP: 10.0.10.2
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:06:20.978: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3568" for this suite.
Jun 13 11:06:48.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:06:49.133: INFO: namespace pods-3568 deletion completed in 28.150851211s

• [SLOW TEST:30.277 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:06:49.134: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3932
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-3932
Jun 13 11:06:49.200: INFO: Found 0 stateful pods, waiting for 1
Jun 13 11:06:59.207: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Jun 13 11:06:59.236: INFO: Deleting all statefulset in ns statefulset-3932
Jun 13 11:06:59.242: INFO: Scaling statefulset ss to 0
Jun 13 11:07:19.262: INFO: Waiting for statefulset status.replicas updated to 0
Jun 13 11:07:19.267: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:07:19.287: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3932" for this suite.
Jun 13 11:07:25.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:07:25.430: INFO: namespace statefulset-3932 deletion completed in 6.138071914s

• [SLOW TEST:36.296 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:07:25.438: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Jun 13 11:07:25.548: INFO: Waiting up to 5m0s for pod "downward-api-c07a3b52-51a6-406a-9702-9c48e9590486" in namespace "downward-api-7204" to be "success or failure"
Jun 13 11:07:25.553: INFO: Pod "downward-api-c07a3b52-51a6-406a-9702-9c48e9590486": Phase="Pending", Reason="", readiness=false. Elapsed: 4.821662ms
Jun 13 11:07:27.558: INFO: Pod "downward-api-c07a3b52-51a6-406a-9702-9c48e9590486": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009487569s
Jun 13 11:07:29.564: INFO: Pod "downward-api-c07a3b52-51a6-406a-9702-9c48e9590486": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015326779s
STEP: Saw pod success
Jun 13 11:07:29.564: INFO: Pod "downward-api-c07a3b52-51a6-406a-9702-9c48e9590486" satisfied condition "success or failure"
Jun 13 11:07:29.567: INFO: Trying to get logs from node 10.0.10.2 pod downward-api-c07a3b52-51a6-406a-9702-9c48e9590486 container dapi-container: <nil>
STEP: delete the pod
Jun 13 11:07:29.761: INFO: Waiting for pod downward-api-c07a3b52-51a6-406a-9702-9c48e9590486 to disappear
Jun 13 11:07:29.769: INFO: Pod downward-api-c07a3b52-51a6-406a-9702-9c48e9590486 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:07:29.769: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7204" for this suite.
Jun 13 11:07:35.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:07:35.925: INFO: namespace downward-api-7204 deletion completed in 6.151474864s

• [SLOW TEST:10.487 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:07:35.935: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Jun 13 11:07:35.977: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-6437'
Jun 13 11:07:36.094: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun 13 11:07:36.094: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Jun 13 11:07:36.104: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 0 spec.replicas 1 status.replicas 0
Jun 13 11:07:36.105: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Jun 13 11:07:36.115: INFO: scanned /root for discovery docs: <nil>
Jun 13 11:07:36.116: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-6437'
Jun 13 11:07:51.943: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Jun 13 11:07:51.943: INFO: stdout: "Created e2e-test-httpd-rc-f281589d5f0ba928ad4ea5a6f3297b2b\nScaling up e2e-test-httpd-rc-f281589d5f0ba928ad4ea5a6f3297b2b from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-f281589d5f0ba928ad4ea5a6f3297b2b up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-f281589d5f0ba928ad4ea5a6f3297b2b to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Jun 13 11:07:51.943: INFO: stdout: "Created e2e-test-httpd-rc-f281589d5f0ba928ad4ea5a6f3297b2b\nScaling up e2e-test-httpd-rc-f281589d5f0ba928ad4ea5a6f3297b2b from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-f281589d5f0ba928ad4ea5a6f3297b2b up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-f281589d5f0ba928ad4ea5a6f3297b2b to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Jun 13 11:07:51.943: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-6437'
Jun 13 11:07:52.035: INFO: stderr: ""
Jun 13 11:07:52.035: INFO: stdout: "e2e-test-httpd-rc-f281589d5f0ba928ad4ea5a6f3297b2b-s9fn7 "
Jun 13 11:07:52.035: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods e2e-test-httpd-rc-f281589d5f0ba928ad4ea5a6f3297b2b-s9fn7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6437'
Jun 13 11:07:52.121: INFO: stderr: ""
Jun 13 11:07:52.121: INFO: stdout: "true"
Jun 13 11:07:52.121: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pods e2e-test-httpd-rc-f281589d5f0ba928ad4ea5a6f3297b2b-s9fn7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6437'
Jun 13 11:07:52.444: INFO: stderr: ""
Jun 13 11:07:52.444: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Jun 13 11:07:52.444: INFO: e2e-test-httpd-rc-f281589d5f0ba928ad4ea5a6f3297b2b-s9fn7 is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Jun 13 11:07:52.444: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 delete rc e2e-test-httpd-rc --namespace=kubectl-6437'
Jun 13 11:07:52.543: INFO: stderr: ""
Jun 13 11:07:52.543: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:07:52.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6437" for this suite.
Jun 13 11:08:20.565: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:08:20.701: INFO: namespace kubectl-6437 deletion completed in 28.150864563s

• [SLOW TEST:44.766 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:08:20.701: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-26ef886c-c688-4844-9214-e24548293478
STEP: Creating a pod to test consume configMaps
Jun 13 11:08:20.767: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4e6fdeb0-6188-4fb8-abe5-5b1e4533b9b8" in namespace "projected-3547" to be "success or failure"
Jun 13 11:08:20.772: INFO: Pod "pod-projected-configmaps-4e6fdeb0-6188-4fb8-abe5-5b1e4533b9b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.315849ms
Jun 13 11:08:22.776: INFO: Pod "pod-projected-configmaps-4e6fdeb0-6188-4fb8-abe5-5b1e4533b9b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008806227s
STEP: Saw pod success
Jun 13 11:08:22.776: INFO: Pod "pod-projected-configmaps-4e6fdeb0-6188-4fb8-abe5-5b1e4533b9b8" satisfied condition "success or failure"
Jun 13 11:08:22.780: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-configmaps-4e6fdeb0-6188-4fb8-abe5-5b1e4533b9b8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 13 11:08:22.861: INFO: Waiting for pod pod-projected-configmaps-4e6fdeb0-6188-4fb8-abe5-5b1e4533b9b8 to disappear
Jun 13 11:08:22.865: INFO: Pod pod-projected-configmaps-4e6fdeb0-6188-4fb8-abe5-5b1e4533b9b8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:08:22.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3547" for this suite.
Jun 13 11:08:28.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:08:29.019: INFO: namespace projected-3547 deletion completed in 6.148756222s

• [SLOW TEST:8.318 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:08:29.022: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Jun 13 11:08:29.137: INFO: Waiting up to 5m0s for pod "downward-api-7a838168-418f-4fce-95ec-38b9ebe0a8a4" in namespace "downward-api-4284" to be "success or failure"
Jun 13 11:08:29.141: INFO: Pod "downward-api-7a838168-418f-4fce-95ec-38b9ebe0a8a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.448879ms
Jun 13 11:08:31.146: INFO: Pod "downward-api-7a838168-418f-4fce-95ec-38b9ebe0a8a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008857932s
STEP: Saw pod success
Jun 13 11:08:31.146: INFO: Pod "downward-api-7a838168-418f-4fce-95ec-38b9ebe0a8a4" satisfied condition "success or failure"
Jun 13 11:08:31.154: INFO: Trying to get logs from node 10.0.10.2 pod downward-api-7a838168-418f-4fce-95ec-38b9ebe0a8a4 container dapi-container: <nil>
STEP: delete the pod
Jun 13 11:08:31.262: INFO: Waiting for pod downward-api-7a838168-418f-4fce-95ec-38b9ebe0a8a4 to disappear
Jun 13 11:08:31.266: INFO: Pod downward-api-7a838168-418f-4fce-95ec-38b9ebe0a8a4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:08:31.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4284" for this suite.
Jun 13 11:08:37.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:08:37.414: INFO: namespace downward-api-4284 deletion completed in 6.140163055s

• [SLOW TEST:8.392 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:08:37.417: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:08:48.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5504" for this suite.
Jun 13 11:08:54.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:08:54.667: INFO: namespace resourcequota-5504 deletion completed in 6.148842183s

• [SLOW TEST:17.251 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:08:54.668: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Jun 13 11:08:54.723: INFO: Waiting up to 5m0s for pod "pod-0f80f098-6f88-478f-adcb-bad8a591fb6b" in namespace "emptydir-173" to be "success or failure"
Jun 13 11:08:54.728: INFO: Pod "pod-0f80f098-6f88-478f-adcb-bad8a591fb6b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.633463ms
Jun 13 11:08:56.733: INFO: Pod "pod-0f80f098-6f88-478f-adcb-bad8a591fb6b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010187528s
Jun 13 11:08:58.738: INFO: Pod "pod-0f80f098-6f88-478f-adcb-bad8a591fb6b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015017316s
STEP: Saw pod success
Jun 13 11:08:58.738: INFO: Pod "pod-0f80f098-6f88-478f-adcb-bad8a591fb6b" satisfied condition "success or failure"
Jun 13 11:08:58.742: INFO: Trying to get logs from node 10.0.10.2 pod pod-0f80f098-6f88-478f-adcb-bad8a591fb6b container test-container: <nil>
STEP: delete the pod
Jun 13 11:08:58.863: INFO: Waiting for pod pod-0f80f098-6f88-478f-adcb-bad8a591fb6b to disappear
Jun 13 11:08:58.869: INFO: Pod pod-0f80f098-6f88-478f-adcb-bad8a591fb6b no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:08:58.869: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-173" for this suite.
Jun 13 11:09:04.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:09:05.020: INFO: namespace emptydir-173 deletion completed in 6.146613826s

• [SLOW TEST:10.352 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:09:05.030: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Jun 13 11:09:05.084: INFO: Waiting up to 5m0s for pod "pod-b29ecd08-dc8e-464b-b452-3d2b15ebe505" in namespace "emptydir-9516" to be "success or failure"
Jun 13 11:09:05.088: INFO: Pod "pod-b29ecd08-dc8e-464b-b452-3d2b15ebe505": Phase="Pending", Reason="", readiness=false. Elapsed: 3.850509ms
Jun 13 11:09:07.093: INFO: Pod "pod-b29ecd08-dc8e-464b-b452-3d2b15ebe505": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008989839s
STEP: Saw pod success
Jun 13 11:09:07.097: INFO: Pod "pod-b29ecd08-dc8e-464b-b452-3d2b15ebe505" satisfied condition "success or failure"
Jun 13 11:09:07.102: INFO: Trying to get logs from node 10.0.10.2 pod pod-b29ecd08-dc8e-464b-b452-3d2b15ebe505 container test-container: <nil>
STEP: delete the pod
Jun 13 11:09:07.165: INFO: Waiting for pod pod-b29ecd08-dc8e-464b-b452-3d2b15ebe505 to disappear
Jun 13 11:09:07.170: INFO: Pod pod-b29ecd08-dc8e-464b-b452-3d2b15ebe505 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:09:07.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9516" for this suite.
Jun 13 11:09:13.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:09:13.321: INFO: namespace emptydir-9516 deletion completed in 6.146663958s

• [SLOW TEST:8.291 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:09:13.321: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Jun 13 11:09:13.363: INFO: Waiting up to 1m0s for all nodes to be ready
Jun 13 11:10:13.384: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 11:10:13.391: INFO: Starting informer...
STEP: Starting pod...
Jun 13 11:10:13.615: INFO: Pod is running on 10.0.10.2. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Jun 13 11:10:13.632: INFO: Pod wasn't evicted. Proceeding
Jun 13 11:10:13.632: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Jun 13 11:11:28.647: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:11:28.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-3731" for this suite.
Jun 13 11:11:56.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:11:57.087: INFO: namespace taint-single-pod-3731 deletion completed in 28.433529987s

• [SLOW TEST:163.766 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:11:57.088: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-8238/configmap-test-cced06bc-08e8-44ac-b35d-e2ba22e9ce45
STEP: Creating a pod to test consume configMaps
Jun 13 11:11:57.156: INFO: Waiting up to 5m0s for pod "pod-configmaps-64722250-86a1-42ff-854a-23bbf4be8087" in namespace "configmap-8238" to be "success or failure"
Jun 13 11:11:57.161: INFO: Pod "pod-configmaps-64722250-86a1-42ff-854a-23bbf4be8087": Phase="Pending", Reason="", readiness=false. Elapsed: 5.420175ms
Jun 13 11:11:59.165: INFO: Pod "pod-configmaps-64722250-86a1-42ff-854a-23bbf4be8087": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009858477s
STEP: Saw pod success
Jun 13 11:11:59.166: INFO: Pod "pod-configmaps-64722250-86a1-42ff-854a-23bbf4be8087" satisfied condition "success or failure"
Jun 13 11:11:59.169: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-64722250-86a1-42ff-854a-23bbf4be8087 container env-test: <nil>
STEP: delete the pod
Jun 13 11:11:59.266: INFO: Waiting for pod pod-configmaps-64722250-86a1-42ff-854a-23bbf4be8087 to disappear
Jun 13 11:11:59.271: INFO: Pod pod-configmaps-64722250-86a1-42ff-854a-23bbf4be8087 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:11:59.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8238" for this suite.
Jun 13 11:12:05.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:12:05.425: INFO: namespace configmap-8238 deletion completed in 6.148333638s

• [SLOW TEST:8.337 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:12:05.427: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 11:12:05.478: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Creating first CR 
Jun 13 11:12:05.607: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-06-13T11:12:05Z generation:1 name:name1 resourceVersion:108102 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:f2fefa5c-bf9e-4542-b7ed-446a6ca76248] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Jun 13 11:12:15.615: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-06-13T11:12:15Z generation:1 name:name2 resourceVersion:108133 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:c18362a7-fec0-43d2-b024-f96f32a7044a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Jun 13 11:12:25.625: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-06-13T11:12:05Z generation:2 name:name1 resourceVersion:108164 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:f2fefa5c-bf9e-4542-b7ed-446a6ca76248] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Jun 13 11:12:35.633: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-06-13T11:12:15Z generation:2 name:name2 resourceVersion:108194 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:c18362a7-fec0-43d2-b024-f96f32a7044a] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Jun 13 11:12:45.645: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-06-13T11:12:05Z generation:2 name:name1 resourceVersion:108224 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:f2fefa5c-bf9e-4542-b7ed-446a6ca76248] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Jun 13 11:12:55.658: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-06-13T11:12:15Z generation:2 name:name2 resourceVersion:108253 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:c18362a7-fec0-43d2-b024-f96f32a7044a] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:13:06.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-8625" for this suite.
Jun 13 11:13:12.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:13:12.571: INFO: namespace crd-watch-8625 deletion completed in 6.147296193s

• [SLOW TEST:67.144 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:13:12.574: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 13 11:13:13.568: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jun 13 11:13:15.580: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727643593, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727643593, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727643593, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727643593, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 13 11:13:18.597: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:13:29.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3633" for this suite.
Jun 13 11:13:35.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:13:35.235: INFO: namespace webhook-3633 deletion completed in 6.132523346s
STEP: Destroying namespace "webhook-3633-markers" for this suite.
Jun 13 11:13:41.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:13:41.373: INFO: namespace webhook-3633-markers deletion completed in 6.137535674s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.819 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:13:41.394: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-a2a62487-b880-40a0-a4ca-54aa6983dd5b
STEP: Creating a pod to test consume configMaps
Jun 13 11:13:41.456: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ec11fa42-ca86-4d81-b034-ea0120a46c3e" in namespace "projected-4463" to be "success or failure"
Jun 13 11:13:41.460: INFO: Pod "pod-projected-configmaps-ec11fa42-ca86-4d81-b034-ea0120a46c3e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.109667ms
Jun 13 11:13:43.465: INFO: Pod "pod-projected-configmaps-ec11fa42-ca86-4d81-b034-ea0120a46c3e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008695078s
STEP: Saw pod success
Jun 13 11:13:43.465: INFO: Pod "pod-projected-configmaps-ec11fa42-ca86-4d81-b034-ea0120a46c3e" satisfied condition "success or failure"
Jun 13 11:13:43.469: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-configmaps-ec11fa42-ca86-4d81-b034-ea0120a46c3e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 13 11:13:43.566: INFO: Waiting for pod pod-projected-configmaps-ec11fa42-ca86-4d81-b034-ea0120a46c3e to disappear
Jun 13 11:13:43.571: INFO: Pod pod-projected-configmaps-ec11fa42-ca86-4d81-b034-ea0120a46c3e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:13:43.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4463" for this suite.
Jun 13 11:13:49.591: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:13:49.718: INFO: namespace projected-4463 deletion completed in 6.142071543s

• [SLOW TEST:8.325 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:13:49.719: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Jun 13 11:13:49.773: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e8e85c97-265d-4a2c-978e-e45986a4e655" in namespace "downward-api-2305" to be "success or failure"
Jun 13 11:13:49.777: INFO: Pod "downwardapi-volume-e8e85c97-265d-4a2c-978e-e45986a4e655": Phase="Pending", Reason="", readiness=false. Elapsed: 4.127895ms
Jun 13 11:13:51.781: INFO: Pod "downwardapi-volume-e8e85c97-265d-4a2c-978e-e45986a4e655": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008244114s
STEP: Saw pod success
Jun 13 11:13:51.781: INFO: Pod "downwardapi-volume-e8e85c97-265d-4a2c-978e-e45986a4e655" satisfied condition "success or failure"
Jun 13 11:13:51.785: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-e8e85c97-265d-4a2c-978e-e45986a4e655 container client-container: <nil>
STEP: delete the pod
Jun 13 11:13:51.809: INFO: Waiting for pod downwardapi-volume-e8e85c97-265d-4a2c-978e-e45986a4e655 to disappear
Jun 13 11:13:51.813: INFO: Pod downwardapi-volume-e8e85c97-265d-4a2c-978e-e45986a4e655 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:13:51.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2305" for this suite.
Jun 13 11:13:57.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:13:57.968: INFO: namespace downward-api-2305 deletion completed in 6.151004415s

• [SLOW TEST:8.250 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:13:57.969: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Jun 13 11:13:58.026: INFO: Waiting up to 5m0s for pod "var-expansion-07d9b0ad-c751-4c4d-9dc0-69f413ae71ac" in namespace "var-expansion-3350" to be "success or failure"
Jun 13 11:13:58.030: INFO: Pod "var-expansion-07d9b0ad-c751-4c4d-9dc0-69f413ae71ac": Phase="Pending", Reason="", readiness=false. Elapsed: 4.365833ms
Jun 13 11:14:00.036: INFO: Pod "var-expansion-07d9b0ad-c751-4c4d-9dc0-69f413ae71ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010476045s
STEP: Saw pod success
Jun 13 11:14:00.036: INFO: Pod "var-expansion-07d9b0ad-c751-4c4d-9dc0-69f413ae71ac" satisfied condition "success or failure"
Jun 13 11:14:00.040: INFO: Trying to get logs from node 10.0.10.2 pod var-expansion-07d9b0ad-c751-4c4d-9dc0-69f413ae71ac container dapi-container: <nil>
STEP: delete the pod
Jun 13 11:14:00.066: INFO: Waiting for pod var-expansion-07d9b0ad-c751-4c4d-9dc0-69f413ae71ac to disappear
Jun 13 11:14:00.070: INFO: Pod var-expansion-07d9b0ad-c751-4c4d-9dc0-69f413ae71ac no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:14:00.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3350" for this suite.
Jun 13 11:14:06.092: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:14:06.233: INFO: namespace var-expansion-3350 deletion completed in 6.159794808s

• [SLOW TEST:8.264 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:14:06.239: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 13 11:14:06.748: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jun 13 11:14:08.763: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727643646, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727643646, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727643646, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727643646, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 13 11:14:11.783: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:14:12.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1921" for this suite.
Jun 13 11:14:18.167: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:14:18.286: INFO: namespace webhook-1921 deletion completed in 6.133765216s
STEP: Destroying namespace "webhook-1921-markers" for this suite.
Jun 13 11:14:24.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:14:24.429: INFO: namespace webhook-1921-markers deletion completed in 6.142927548s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.209 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:14:24.449: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 11:14:24.493: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 version'
Jun 13 11:14:24.570: INFO: stderr: ""
Jun 13 11:14:24.570: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.8\", GitCommit:\"ec6eb119b81be488b030e849b9e64fda4caaf33c\", GitTreeState:\"clean\", BuildDate:\"2020-03-12T21:00:06Z\", GoVersion:\"go1.13.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.8\", GitCommit:\"fdba62c353cc548995bbe730321f64176e4f6e4b\", GitTreeState:\"clean\", BuildDate:\"2020-04-08T18:15:19Z\", GoVersion:\"go1.13.8 BoringCrypto\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:14:24.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7159" for this suite.
Jun 13 11:14:30.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:14:30.726: INFO: namespace kubectl-7159 deletion completed in 6.150176512s

• [SLOW TEST:6.278 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:14:30.727: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W0613 11:14:36.814656      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 13 11:14:36.814: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:14:36.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5157" for this suite.
Jun 13 11:14:42.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:14:42.960: INFO: namespace gc-5157 deletion completed in 6.141032481s

• [SLOW TEST:12.234 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:14:42.961: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Jun 13 11:14:43.019: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fbfcec15-cfab-49a5-9f7c-bda6e7cd3694" in namespace "projected-1064" to be "success or failure"
Jun 13 11:14:43.023: INFO: Pod "downwardapi-volume-fbfcec15-cfab-49a5-9f7c-bda6e7cd3694": Phase="Pending", Reason="", readiness=false. Elapsed: 4.46747ms
Jun 13 11:14:45.028: INFO: Pod "downwardapi-volume-fbfcec15-cfab-49a5-9f7c-bda6e7cd3694": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009312609s
STEP: Saw pod success
Jun 13 11:14:45.028: INFO: Pod "downwardapi-volume-fbfcec15-cfab-49a5-9f7c-bda6e7cd3694" satisfied condition "success or failure"
Jun 13 11:14:45.032: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-fbfcec15-cfab-49a5-9f7c-bda6e7cd3694 container client-container: <nil>
STEP: delete the pod
Jun 13 11:14:45.058: INFO: Waiting for pod downwardapi-volume-fbfcec15-cfab-49a5-9f7c-bda6e7cd3694 to disappear
Jun 13 11:14:45.062: INFO: Pod downwardapi-volume-fbfcec15-cfab-49a5-9f7c-bda6e7cd3694 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:14:45.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1064" for this suite.
Jun 13 11:14:51.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:14:51.216: INFO: namespace projected-1064 deletion completed in 6.148080355s

• [SLOW TEST:8.255 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:14:51.217: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Jun 13 11:14:51.269: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-4174" to be "success or failure"
Jun 13 11:14:51.273: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.296545ms
Jun 13 11:14:53.278: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008690848s
STEP: Saw pod success
Jun 13 11:14:53.278: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Jun 13 11:14:53.282: INFO: Trying to get logs from node 10.0.10.2 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Jun 13 11:14:53.306: INFO: Waiting for pod pod-host-path-test to disappear
Jun 13 11:14:53.311: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:14:53.311: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-4174" for this suite.
Jun 13 11:14:59.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:14:59.472: INFO: namespace hostpath-4174 deletion completed in 6.156615803s

• [SLOW TEST:8.255 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:14:59.472: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 11:14:59.512: INFO: Creating deployment "webserver-deployment"
Jun 13 11:14:59.522: INFO: Waiting for observed generation 1
Jun 13 11:15:01.636: INFO: Waiting for all required pods to come up
Jun 13 11:15:01.650: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Jun 13 11:15:05.667: INFO: Waiting for deployment "webserver-deployment" to complete
Jun 13 11:15:05.676: INFO: Updating deployment "webserver-deployment" with a non-existent image
Jun 13 11:15:05.686: INFO: Updating deployment webserver-deployment
Jun 13 11:15:05.686: INFO: Waiting for observed generation 2
Jun 13 11:15:07.694: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Jun 13 11:15:07.700: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Jun 13 11:15:07.704: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Jun 13 11:15:07.716: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Jun 13 11:15:07.716: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Jun 13 11:15:07.719: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Jun 13 11:15:07.725: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Jun 13 11:15:07.725: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Jun 13 11:15:07.733: INFO: Updating deployment webserver-deployment
Jun 13 11:15:07.733: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Jun 13 11:15:07.740: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Jun 13 11:15:07.744: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Jun 13 11:15:07.755: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-31 /apis/apps/v1/namespaces/deployment-31/deployments/webserver-deployment 61addcd0-02e0-4e5a-8a7a-121288f23a02 109365 3 2020-06-13 11:14:59 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0056043b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-06-13 11:15:03 +0000 UTC,LastTransitionTime:2020-06-13 11:15:03 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2020-06-13 11:15:05 +0000 UTC,LastTransitionTime:2020-06-13 11:14:59 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Jun 13 11:15:07.762: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-31 /apis/apps/v1/namespaces/deployment-31/replicasets/webserver-deployment-c7997dcc8 426b5d79-79bc-41a6-8022-272cf0a672bc 109368 3 2020-06-13 11:15:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 61addcd0-02e0-4e5a-8a7a-121288f23a02 0xc0056048b7 0xc0056048b8}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005604928 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jun 13 11:15:07.762: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Jun 13 11:15:07.762: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-31 /apis/apps/v1/namespaces/deployment-31/replicasets/webserver-deployment-595b5b9587 cc6822cc-de28-4a7b-990e-3b37f9d6aef4 109366 3 2020-06-13 11:14:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 61addcd0-02e0-4e5a-8a7a-121288f23a02 0xc0056047f7 0xc0056047f8}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005604858 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Jun 13 11:15:07.771: INFO: Pod "webserver-deployment-595b5b9587-4p447" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-4p447 webserver-deployment-595b5b9587- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-595b5b9587-4p447 c01788f3-993b-4255-a928-ee4467d7372e 109391 0 2020-06-13 11:15:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cc6822cc-de28-4a7b-990e-3b37f9d6aef4 0xc000ef5397 0xc000ef5398}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.772: INFO: Pod "webserver-deployment-595b5b9587-5b6g8" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-5b6g8 webserver-deployment-595b5b9587- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-595b5b9587-5b6g8 aab6b40a-8c8b-423c-ba21-a5e90a2ff3ba 109389 0 2020-06-13 11:15:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cc6822cc-de28-4a7b-990e-3b37f9d6aef4 0xc000ef5490 0xc000ef5491}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.772: INFO: Pod "webserver-deployment-595b5b9587-6lkkl" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6lkkl webserver-deployment-595b5b9587- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-595b5b9587-6lkkl d3f68af4-bc1e-466e-a9cc-5580e06d1852 109255 0 2020-06-13 11:14:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cc6822cc-de28-4a7b-990e-3b37f9d6aef4 0xc000ef5580 0xc000ef5581}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:14:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:14:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.10.3,PodIP:10.244.0.112,StartTime:2020-06-13 11:14:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-13 11:15:02 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://27e799f82173be180d5e8531fa4113d5e88a60c9dcfc65b669e13d7791c0aaa8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.112,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.772: INFO: Pod "webserver-deployment-595b5b9587-d8tn9" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-d8tn9 webserver-deployment-595b5b9587- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-595b5b9587-d8tn9 736c0055-4337-4caa-9f35-c529d68afb35 109227 0 2020-06-13 11:14:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cc6822cc-de28-4a7b-990e-3b37f9d6aef4 0xc000ef56f0 0xc000ef56f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:14:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:14:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.10.3,PodIP:10.244.0.109,StartTime:2020-06-13 11:14:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-13 11:15:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://c934daa68e80d80c5a145e85c1c627a5888ed1a185901e2b94a968dba10b914c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.109,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.772: INFO: Pod "webserver-deployment-595b5b9587-gdc98" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gdc98 webserver-deployment-595b5b9587- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-595b5b9587-gdc98 8fdd21cc-7b52-4910-a3dc-458547fb0433 109384 0 2020-06-13 11:15:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cc6822cc-de28-4a7b-990e-3b37f9d6aef4 0xc000ef5860 0xc000ef5861}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.773: INFO: Pod "webserver-deployment-595b5b9587-j65hl" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-j65hl webserver-deployment-595b5b9587- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-595b5b9587-j65hl 698d3891-df98-42a7-9eb4-74a01f8da2a6 109377 0 2020-06-13 11:15:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cc6822cc-de28-4a7b-990e-3b37f9d6aef4 0xc000ef5970 0xc000ef5971}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.773: INFO: Pod "webserver-deployment-595b5b9587-jgh6n" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-jgh6n webserver-deployment-595b5b9587- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-595b5b9587-jgh6n 0abf71f7-7a2f-4ea1-b41f-1603b795c488 109390 0 2020-06-13 11:15:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cc6822cc-de28-4a7b-990e-3b37f9d6aef4 0xc000ef5a90 0xc000ef5a91}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.773: INFO: Pod "webserver-deployment-595b5b9587-lpbzv" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-lpbzv webserver-deployment-595b5b9587- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-595b5b9587-lpbzv cff3c700-d850-4c42-82ef-cab053fe8dc5 109388 0 2020-06-13 11:15:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cc6822cc-de28-4a7b-990e-3b37f9d6aef4 0xc000ef5b80 0xc000ef5b81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.774: INFO: Pod "webserver-deployment-595b5b9587-n4hs2" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-n4hs2 webserver-deployment-595b5b9587- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-595b5b9587-n4hs2 3857a504-890f-4857-b93a-d58a35c22dad 109393 0 2020-06-13 11:15:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cc6822cc-de28-4a7b-990e-3b37f9d6aef4 0xc000ef5ca0 0xc000ef5ca1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.774: INFO: Pod "webserver-deployment-595b5b9587-nlb99" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-nlb99 webserver-deployment-595b5b9587- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-595b5b9587-nlb99 0aa130a8-7157-4a4b-8ae4-74a002adba74 109380 0 2020-06-13 11:15:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cc6822cc-de28-4a7b-990e-3b37f9d6aef4 0xc000ef5dd0 0xc000ef5dd1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.776: INFO: Pod "webserver-deployment-595b5b9587-pd4x4" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pd4x4 webserver-deployment-595b5b9587- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-595b5b9587-pd4x4 7dd366ce-6676-4ec7-a86f-8aaf6e3184e8 109269 0 2020-06-13 11:14:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cc6822cc-de28-4a7b-990e-3b37f9d6aef4 0xc000ef5f10 0xc000ef5f11}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:14:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:14:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.1.94,StartTime:2020-06-13 11:14:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-13 11:15:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://ac0df660fa0bcc140405fdde1842ad7b130372d618035f29a55c947140a75d0f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.94,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.776: INFO: Pod "webserver-deployment-595b5b9587-pkpm6" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pkpm6 webserver-deployment-595b5b9587- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-595b5b9587-pkpm6 06e274af-9627-4847-b7af-3bc7c5f38c1a 109273 0 2020-06-13 11:14:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cc6822cc-de28-4a7b-990e-3b37f9d6aef4 0xc0050aa090 0xc0050aa091}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:14:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:14:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.1.93,StartTime:2020-06-13 11:14:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-13 11:15:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://f9db5073f076c8c4e89696238d9adeaac00a3f8cbd1c3a23661b4713f52e23eb,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.93,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.777: INFO: Pod "webserver-deployment-595b5b9587-q5kr2" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-q5kr2 webserver-deployment-595b5b9587- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-595b5b9587-q5kr2 a2346d5e-841a-4541-aa95-335a45c5b97c 109392 0 2020-06-13 11:15:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cc6822cc-de28-4a7b-990e-3b37f9d6aef4 0xc0050aa210 0xc0050aa211}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.777: INFO: Pod "webserver-deployment-595b5b9587-qzm8r" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-qzm8r webserver-deployment-595b5b9587- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-595b5b9587-qzm8r f4145eaa-2d5d-4764-bcdd-8c8de09bb9c3 109249 0 2020-06-13 11:14:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cc6822cc-de28-4a7b-990e-3b37f9d6aef4 0xc0050aa300 0xc0050aa301}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:14:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:14:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.10.3,PodIP:10.244.0.110,StartTime:2020-06-13 11:14:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-13 11:15:02 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://5139281207f2dad06c5d60e8f8aab471d7cf8bb86a95aa56b1daafd801b482de,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.110,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.777: INFO: Pod "webserver-deployment-595b5b9587-rkwtk" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-rkwtk webserver-deployment-595b5b9587- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-595b5b9587-rkwtk a7a10f81-f75d-46cd-aa08-466268248cf3 109264 0 2020-06-13 11:14:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cc6822cc-de28-4a7b-990e-3b37f9d6aef4 0xc0050aa470 0xc0050aa471}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:14:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:14:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.1.92,StartTime:2020-06-13 11:14:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-13 11:15:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://9fadc6b14c9374b0c2ef69c24cc3e7c9b323770a958d47d5e354ff76b6a38dd6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.92,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.778: INFO: Pod "webserver-deployment-595b5b9587-rtbn4" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-rtbn4 webserver-deployment-595b5b9587- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-595b5b9587-rtbn4 36bc21bd-a28c-4f1f-80fb-bfbf8338eb2c 109260 0 2020-06-13 11:14:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cc6822cc-de28-4a7b-990e-3b37f9d6aef4 0xc0050aa5e0 0xc0050aa5e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:14:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:14:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.1.89,StartTime:2020-06-13 11:14:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-13 11:15:02 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://8a7e911df815a0bdf161a1aed57ce3c863ee3d838bdd20a02dc952ae0411cf57,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.89,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.778: INFO: Pod "webserver-deployment-595b5b9587-tczcx" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-tczcx webserver-deployment-595b5b9587- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-595b5b9587-tczcx 8f72208a-76ad-4475-836f-83594cab268f 109379 0 2020-06-13 11:15:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cc6822cc-de28-4a7b-990e-3b37f9d6aef4 0xc0050aa750 0xc0050aa751}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.779: INFO: Pod "webserver-deployment-595b5b9587-tm2fd" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-tm2fd webserver-deployment-595b5b9587- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-595b5b9587-tm2fd ea65221f-b6c8-490e-9969-c50a7179f732 109277 0 2020-06-13 11:14:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cc6822cc-de28-4a7b-990e-3b37f9d6aef4 0xc0050aa860 0xc0050aa861}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:14:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:03 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:14:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.1.90,StartTime:2020-06-13 11:14:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-13 11:15:02 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://dda2307d14672988d3eef7b3cc16b0badb2efe8c29e2f16a22834d3781a440e5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.90,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.779: INFO: Pod "webserver-deployment-595b5b9587-wqhs6" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-wqhs6 webserver-deployment-595b5b9587- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-595b5b9587-wqhs6 a6213a2b-6f56-4c04-ac45-ef225a457ab3 109378 0 2020-06-13 11:15:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cc6822cc-de28-4a7b-990e-3b37f9d6aef4 0xc0050aa9d0 0xc0050aa9d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.781: INFO: Pod "webserver-deployment-595b5b9587-xw5tw" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-xw5tw webserver-deployment-595b5b9587- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-595b5b9587-xw5tw 0b9265aa-533e-4fd8-ae42-845f9ed60384 109375 0 2020-06-13 11:15:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 cc6822cc-de28-4a7b-990e-3b37f9d6aef4 0xc0050aaac0 0xc0050aaac1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.782: INFO: Pod "webserver-deployment-c7997dcc8-26zfs" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-26zfs webserver-deployment-c7997dcc8- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-c7997dcc8-26zfs 96a7e4d6-362a-4112-b500-e96c33376601 109335 0 2020-06-13 11:15:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 426b5d79-79bc-41a6-8022-272cf0a672bc 0xc0050aabd0 0xc0050aabd1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:05 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:05 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.10.2,PodIP:,StartTime:2020-06-13 11:15:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.782: INFO: Pod "webserver-deployment-c7997dcc8-2gz2n" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-2gz2n webserver-deployment-c7997dcc8- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-c7997dcc8-2gz2n 3c3b9ace-12ec-4891-be33-8eb3ad0770e1 109395 0 2020-06-13 11:15:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 426b5d79-79bc-41a6-8022-272cf0a672bc 0xc0050aad40 0xc0050aad41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.782: INFO: Pod "webserver-deployment-c7997dcc8-c5mkq" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-c5mkq webserver-deployment-c7997dcc8- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-c7997dcc8-c5mkq 432f830b-f587-47d8-b027-d8482c84db28 109382 0 2020-06-13 11:15:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 426b5d79-79bc-41a6-8022-272cf0a672bc 0xc0050aae40 0xc0050aae41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.782: INFO: Pod "webserver-deployment-c7997dcc8-f87wv" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-f87wv webserver-deployment-c7997dcc8- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-c7997dcc8-f87wv 3e78017e-f0ba-4c85-9193-2f5ef6d792e3 109349 0 2020-06-13 11:15:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 426b5d79-79bc-41a6-8022-272cf0a672bc 0xc0050aaf40 0xc0050aaf41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:05 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:05 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.10.3,PodIP:10.244.0.113,StartTime:2020-06-13 11:15:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = pull access denied for webserver, repository does not exist or may require 'docker login',},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.113,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.783: INFO: Pod "webserver-deployment-c7997dcc8-fl899" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-fl899 webserver-deployment-c7997dcc8- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-c7997dcc8-fl899 647675ef-3422-47f8-ac49-39e473b48440 109394 0 2020-06-13 11:15:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 426b5d79-79bc-41a6-8022-272cf0a672bc 0xc0050ab0e0 0xc0050ab0e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.783: INFO: Pod "webserver-deployment-c7997dcc8-ntl8t" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-ntl8t webserver-deployment-c7997dcc8- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-c7997dcc8-ntl8t 6cc4a714-b5ab-4f80-8a86-a1c8866ba656 109352 0 2020-06-13 11:15:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 426b5d79-79bc-41a6-8022-272cf0a672bc 0xc0050ab1e0 0xc0050ab1e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:05 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:05 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.10.3,PodIP:10.244.0.114,StartTime:2020-06-13 11:15:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = pull access denied for webserver, repository does not exist or may require 'docker login',},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.0.114,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.783: INFO: Pod "webserver-deployment-c7997dcc8-r9jzn" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-r9jzn webserver-deployment-c7997dcc8- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-c7997dcc8-r9jzn 606b8a82-f577-44fd-93bd-4722b1534cd5 109396 0 2020-06-13 11:15:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 426b5d79-79bc-41a6-8022-272cf0a672bc 0xc0050ab380 0xc0050ab381}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.783: INFO: Pod "webserver-deployment-c7997dcc8-rnxzt" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-rnxzt webserver-deployment-c7997dcc8- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-c7997dcc8-rnxzt 00bccb54-37ab-4e99-b098-a00f915f6ff5 109321 0 2020-06-13 11:15:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 426b5d79-79bc-41a6-8022-272cf0a672bc 0xc0050ab480 0xc0050ab481}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:05 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:05 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.10.2,PodIP:,StartTime:2020-06-13 11:15:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.784: INFO: Pod "webserver-deployment-c7997dcc8-v8wjn" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-v8wjn webserver-deployment-c7997dcc8- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-c7997dcc8-v8wjn feb2da91-2f83-4290-9d6f-490e99477d75 109360 0 2020-06-13 11:15:05 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 426b5d79-79bc-41a6-8022-272cf0a672bc 0xc0050ab5f0 0xc0050ab5f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:05 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:05 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:05 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.1.95,StartTime:2020-06-13 11:15:05 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = pull access denied for webserver, repository does not exist or may require 'docker login',},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.95,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.784: INFO: Pod "webserver-deployment-c7997dcc8-vp5r2" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-vp5r2 webserver-deployment-c7997dcc8- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-c7997dcc8-vp5r2 70996992-90ff-44d1-8b25-46cc4ecf639f 109385 0 2020-06-13 11:15:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 426b5d79-79bc-41a6-8022-272cf0a672bc 0xc0050ab790 0xc0050ab791}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:15:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Jun 13 11:15:07.785: INFO: Pod "webserver-deployment-c7997dcc8-zq72x" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-zq72x webserver-deployment-c7997dcc8- deployment-31 /api/v1/namespaces/deployment-31/pods/webserver-deployment-c7997dcc8-zq72x 3e5b176e-3d62-488b-8f4e-38009ae8fd47 109381 0 2020-06-13 11:15:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 426b5d79-79bc-41a6-8022-272cf0a672bc 0xc0050ab8b0 0xc0050ab8b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qfwhw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qfwhw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qfwhw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:15:07.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-31" for this suite.
Jun 13 11:15:15.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:15:15.937: INFO: namespace deployment-31 deletion completed in 8.146870166s

• [SLOW TEST:16.465 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:15:15.938: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-b3929898-a443-441b-bf76-cc3c2de681c3 in namespace container-probe-4406
Jun 13 11:15:24.004: INFO: Started pod liveness-b3929898-a443-441b-bf76-cc3c2de681c3 in namespace container-probe-4406
STEP: checking the pod's current state and verifying that restartCount is present
Jun 13 11:15:24.008: INFO: Initial restart count of pod liveness-b3929898-a443-441b-bf76-cc3c2de681c3 is 0
Jun 13 11:15:34.035: INFO: Restart count of pod container-probe-4406/liveness-b3929898-a443-441b-bf76-cc3c2de681c3 is now 1 (10.027281934s elapsed)
Jun 13 11:15:54.084: INFO: Restart count of pod container-probe-4406/liveness-b3929898-a443-441b-bf76-cc3c2de681c3 is now 2 (30.076245266s elapsed)
Jun 13 11:16:14.131: INFO: Restart count of pod container-probe-4406/liveness-b3929898-a443-441b-bf76-cc3c2de681c3 is now 3 (50.122725448s elapsed)
Jun 13 11:16:34.176: INFO: Restart count of pod container-probe-4406/liveness-b3929898-a443-441b-bf76-cc3c2de681c3 is now 4 (1m10.168452755s elapsed)
Jun 13 11:17:34.319: INFO: Restart count of pod container-probe-4406/liveness-b3929898-a443-441b-bf76-cc3c2de681c3 is now 5 (2m10.310738532s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:17:34.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4406" for this suite.
Jun 13 11:17:40.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:17:40.769: INFO: namespace container-probe-4406 deletion completed in 6.431715303s

• [SLOW TEST:144.831 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:17:40.769: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-2855
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-2855
I0613 11:17:40.867502      22 runners.go:184] Created replication controller with name: externalname-service, namespace: services-2855, replica count: 2
I0613 11:17:43.918500      22 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jun 13 11:17:43.918: INFO: Creating new exec pod
Jun 13 11:17:48.946: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=services-2855 execpodchlv5 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Jun 13 11:17:49.390: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Jun 13 11:17:49.390: INFO: stdout: ""
Jun 13 11:17:49.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=services-2855 execpodchlv5 -- /bin/sh -x -c nc -zv -t -w 2 10.96.106.137 80'
Jun 13 11:17:49.766: INFO: stderr: "+ nc -zv -t -w 2 10.96.106.137 80\nConnection to 10.96.106.137 80 port [tcp/http] succeeded!\n"
Jun 13 11:17:49.767: INFO: stdout: ""
Jun 13 11:17:49.767: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=services-2855 execpodchlv5 -- /bin/sh -x -c nc -zv -t -w 2 10.0.10.2 30538'
Jun 13 11:17:50.067: INFO: stderr: "+ nc -zv -t -w 2 10.0.10.2 30538\nConnection to 10.0.10.2 30538 port [tcp/30538] succeeded!\n"
Jun 13 11:17:50.067: INFO: stdout: ""
Jun 13 11:17:50.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=services-2855 execpodchlv5 -- /bin/sh -x -c nc -zv -t -w 2 10.0.10.3 30538'
Jun 13 11:17:50.495: INFO: stderr: "+ nc -zv -t -w 2 10.0.10.3 30538\nConnection to 10.0.10.3 30538 port [tcp/30538] succeeded!\n"
Jun 13 11:17:50.495: INFO: stdout: ""
Jun 13 11:17:50.495: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=services-2855 execpodchlv5 -- /bin/sh -x -c nc -zv -t -w 2 168.138.67.181 30538'
Jun 13 11:17:50.859: INFO: stderr: "+ nc -zv -t -w 2 168.138.67.181 30538\nConnection to 168.138.67.181 30538 port [tcp/30538] succeeded!\n"
Jun 13 11:17:50.859: INFO: stdout: ""
Jun 13 11:17:50.860: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=services-2855 execpodchlv5 -- /bin/sh -x -c nc -zv -t -w 2 168.138.66.177 30538'
Jun 13 11:17:51.256: INFO: stderr: "+ nc -zv -t -w 2 168.138.66.177 30538\nConnection to 168.138.66.177 30538 port [tcp/30538] succeeded!\n"
Jun 13 11:17:51.256: INFO: stdout: ""
Jun 13 11:17:51.256: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:17:51.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2855" for this suite.
Jun 13 11:17:57.305: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:17:57.428: INFO: namespace services-2855 deletion completed in 6.139237317s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:16.659 seconds]
[sig-network] Services
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:17:57.428: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Jun 13 11:17:57.549: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f0aec4a4-2dc7-4e77-b294-80e58ea4f196" in namespace "downward-api-8259" to be "success or failure"
Jun 13 11:17:57.555: INFO: Pod "downwardapi-volume-f0aec4a4-2dc7-4e77-b294-80e58ea4f196": Phase="Pending", Reason="", readiness=false. Elapsed: 5.340224ms
Jun 13 11:17:59.561: INFO: Pod "downwardapi-volume-f0aec4a4-2dc7-4e77-b294-80e58ea4f196": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011580866s
Jun 13 11:18:01.566: INFO: Pod "downwardapi-volume-f0aec4a4-2dc7-4e77-b294-80e58ea4f196": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016400019s
STEP: Saw pod success
Jun 13 11:18:01.566: INFO: Pod "downwardapi-volume-f0aec4a4-2dc7-4e77-b294-80e58ea4f196" satisfied condition "success or failure"
Jun 13 11:18:01.570: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-f0aec4a4-2dc7-4e77-b294-80e58ea4f196 container client-container: <nil>
STEP: delete the pod
Jun 13 11:18:01.673: INFO: Waiting for pod downwardapi-volume-f0aec4a4-2dc7-4e77-b294-80e58ea4f196 to disappear
Jun 13 11:18:01.677: INFO: Pod downwardapi-volume-f0aec4a4-2dc7-4e77-b294-80e58ea4f196 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:18:01.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8259" for this suite.
Jun 13 11:18:07.701: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:18:07.840: INFO: namespace downward-api-8259 deletion completed in 6.158129662s

• [SLOW TEST:10.412 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:18:07.843: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Jun 13 11:18:07.941: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6131 /api/v1/namespaces/watch-6131/configmaps/e2e-watch-test-resource-version 036cf4b5-73e9-4b78-b0a1-d658b160f9e3 110350 0 2020-06-13 11:18:07 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Jun 13 11:18:07.942: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-6131 /api/v1/namespaces/watch-6131/configmaps/e2e-watch-test-resource-version 036cf4b5-73e9-4b78-b0a1-d658b160f9e3 110351 0 2020-06-13 11:18:07 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:18:07.942: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6131" for this suite.
Jun 13 11:18:13.964: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:18:14.099: INFO: namespace watch-6131 deletion completed in 6.151854758s

• [SLOW TEST:6.256 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:18:14.099: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:19:14.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6178" for this suite.
Jun 13 11:19:26.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:19:26.305: INFO: namespace container-probe-6178 deletion completed in 12.137138128s

• [SLOW TEST:72.206 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:19:26.306: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 11:19:26.359: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-79ff96e3-ea2c-4cd9-b071-a41e431e790a" in namespace "security-context-test-9199" to be "success or failure"
Jun 13 11:19:26.363: INFO: Pod "busybox-privileged-false-79ff96e3-ea2c-4cd9-b071-a41e431e790a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.373312ms
Jun 13 11:19:28.368: INFO: Pod "busybox-privileged-false-79ff96e3-ea2c-4cd9-b071-a41e431e790a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008866836s
Jun 13 11:19:28.368: INFO: Pod "busybox-privileged-false-79ff96e3-ea2c-4cd9-b071-a41e431e790a" satisfied condition "success or failure"
Jun 13 11:19:28.382: INFO: Got logs for pod "busybox-privileged-false-79ff96e3-ea2c-4cd9-b071-a41e431e790a": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:19:28.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9199" for this suite.
Jun 13 11:19:34.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:19:34.527: INFO: namespace security-context-test-9199 deletion completed in 6.140273738s

• [SLOW TEST:8.221 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:19:34.527: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-5218/configmap-test-5ca424fc-d6e0-4ec5-8b21-dc0e0302d6fc
STEP: Creating a pod to test consume configMaps
Jun 13 11:19:34.587: INFO: Waiting up to 5m0s for pod "pod-configmaps-c396633c-918f-4db0-a8ed-72e633316861" in namespace "configmap-5218" to be "success or failure"
Jun 13 11:19:34.591: INFO: Pod "pod-configmaps-c396633c-918f-4db0-a8ed-72e633316861": Phase="Pending", Reason="", readiness=false. Elapsed: 4.245887ms
Jun 13 11:19:36.596: INFO: Pod "pod-configmaps-c396633c-918f-4db0-a8ed-72e633316861": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008757038s
STEP: Saw pod success
Jun 13 11:19:36.596: INFO: Pod "pod-configmaps-c396633c-918f-4db0-a8ed-72e633316861" satisfied condition "success or failure"
Jun 13 11:19:36.600: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-c396633c-918f-4db0-a8ed-72e633316861 container env-test: <nil>
STEP: delete the pod
Jun 13 11:19:36.661: INFO: Waiting for pod pod-configmaps-c396633c-918f-4db0-a8ed-72e633316861 to disappear
Jun 13 11:19:36.666: INFO: Pod pod-configmaps-c396633c-918f-4db0-a8ed-72e633316861 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:19:36.666: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5218" for this suite.
Jun 13 11:19:42.685: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:19:42.816: INFO: namespace configmap-5218 deletion completed in 6.146104891s

• [SLOW TEST:8.289 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:19:42.817: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 11:19:42.868: INFO: Creating ReplicaSet my-hostname-basic-94406374-eb83-43d1-8718-95bf3ab2a970
Jun 13 11:19:42.883: INFO: Pod name my-hostname-basic-94406374-eb83-43d1-8718-95bf3ab2a970: Found 0 pods out of 1
Jun 13 11:19:47.889: INFO: Pod name my-hostname-basic-94406374-eb83-43d1-8718-95bf3ab2a970: Found 1 pods out of 1
Jun 13 11:19:47.889: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-94406374-eb83-43d1-8718-95bf3ab2a970" is running
Jun 13 11:19:47.894: INFO: Pod "my-hostname-basic-94406374-eb83-43d1-8718-95bf3ab2a970-tgtvs" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-06-13 11:19:42 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-06-13 11:19:44 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-06-13 11:19:44 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-06-13 11:19:42 +0000 UTC Reason: Message:}])
Jun 13 11:19:47.894: INFO: Trying to dial the pod
Jun 13 11:19:52.966: INFO: Controller my-hostname-basic-94406374-eb83-43d1-8718-95bf3ab2a970: Got expected result from replica 1 [my-hostname-basic-94406374-eb83-43d1-8718-95bf3ab2a970-tgtvs]: "my-hostname-basic-94406374-eb83-43d1-8718-95bf3ab2a970-tgtvs", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:19:52.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1008" for this suite.
Jun 13 11:19:59.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:19:59.137: INFO: namespace replicaset-1008 deletion completed in 6.150160787s

• [SLOW TEST:16.320 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:19:59.138: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Jun 13 11:19:59.195: INFO: Waiting up to 5m0s for pod "pod-0917d2a3-f5e7-4ca5-9934-2b7ddd3ba824" in namespace "emptydir-9160" to be "success or failure"
Jun 13 11:19:59.199: INFO: Pod "pod-0917d2a3-f5e7-4ca5-9934-2b7ddd3ba824": Phase="Pending", Reason="", readiness=false. Elapsed: 4.081075ms
Jun 13 11:20:01.205: INFO: Pod "pod-0917d2a3-f5e7-4ca5-9934-2b7ddd3ba824": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009440028s
STEP: Saw pod success
Jun 13 11:20:01.205: INFO: Pod "pod-0917d2a3-f5e7-4ca5-9934-2b7ddd3ba824" satisfied condition "success or failure"
Jun 13 11:20:01.209: INFO: Trying to get logs from node 10.0.10.2 pod pod-0917d2a3-f5e7-4ca5-9934-2b7ddd3ba824 container test-container: <nil>
STEP: delete the pod
Jun 13 11:20:01.238: INFO: Waiting for pod pod-0917d2a3-f5e7-4ca5-9934-2b7ddd3ba824 to disappear
Jun 13 11:20:01.243: INFO: Pod pod-0917d2a3-f5e7-4ca5-9934-2b7ddd3ba824 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:20:01.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9160" for this suite.
Jun 13 11:20:07.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:20:07.401: INFO: namespace emptydir-9160 deletion completed in 6.15242588s

• [SLOW TEST:8.263 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:20:07.408: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:20:10.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-234" for this suite.
Jun 13 11:20:38.525: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:20:38.668: INFO: namespace replication-controller-234 deletion completed in 28.162247613s

• [SLOW TEST:31.260 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:20:38.668: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-abf5a158-adff-4999-882b-55629dd7e568
STEP: Creating a pod to test consume configMaps
Jun 13 11:20:38.732: INFO: Waiting up to 5m0s for pod "pod-configmaps-2f2e6148-d41f-411d-af7f-074960bfde5a" in namespace "configmap-2556" to be "success or failure"
Jun 13 11:20:38.736: INFO: Pod "pod-configmaps-2f2e6148-d41f-411d-af7f-074960bfde5a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.215216ms
Jun 13 11:20:40.741: INFO: Pod "pod-configmaps-2f2e6148-d41f-411d-af7f-074960bfde5a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009353991s
Jun 13 11:20:42.746: INFO: Pod "pod-configmaps-2f2e6148-d41f-411d-af7f-074960bfde5a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014369723s
STEP: Saw pod success
Jun 13 11:20:42.747: INFO: Pod "pod-configmaps-2f2e6148-d41f-411d-af7f-074960bfde5a" satisfied condition "success or failure"
Jun 13 11:20:42.750: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-2f2e6148-d41f-411d-af7f-074960bfde5a container configmap-volume-test: <nil>
STEP: delete the pod
Jun 13 11:20:42.779: INFO: Waiting for pod pod-configmaps-2f2e6148-d41f-411d-af7f-074960bfde5a to disappear
Jun 13 11:20:42.783: INFO: Pod pod-configmaps-2f2e6148-d41f-411d-af7f-074960bfde5a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:20:42.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2556" for this suite.
Jun 13 11:20:48.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:20:48.927: INFO: namespace configmap-2556 deletion completed in 6.138932259s

• [SLOW TEST:10.260 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:20:48.928: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Jun 13 11:20:52.999: INFO: &Pod{ObjectMeta:{send-events-4ec5e137-a377-47da-a565-b323acd64bdb  events-9478 /api/v1/namespaces/events-9478/pods/send-events-4ec5e137-a377-47da-a565-b323acd64bdb 04ed6b2c-c524-46ba-b0d2-0f94b372086c 111035 0 2020-06-13 11:20:48 +0000 UTC <nil> <nil> map[name:foo time:967268128] map[] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-v5bzj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-v5bzj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-v5bzj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:20:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:20:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:20:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 11:20:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.1.122,StartTime:2020-06-13 11:20:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-13 11:20:50 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:docker://1e4919a790d0a8aba8127d43cf42f4f4352425e5686de58450140ee3120301f0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.122,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Jun 13 11:20:55.006: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Jun 13 11:20:57.011: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:20:57.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-9478" for this suite.
Jun 13 11:21:41.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:21:41.157: INFO: namespace events-9478 deletion completed in 44.133328698s

• [SLOW TEST:52.229 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:21:41.157: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-jztq
STEP: Creating a pod to test atomic-volume-subpath
Jun 13 11:21:41.225: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-jztq" in namespace "subpath-7183" to be "success or failure"
Jun 13 11:21:41.229: INFO: Pod "pod-subpath-test-configmap-jztq": Phase="Pending", Reason="", readiness=false. Elapsed: 4.437522ms
Jun 13 11:21:43.234: INFO: Pod "pod-subpath-test-configmap-jztq": Phase="Running", Reason="", readiness=true. Elapsed: 2.009113296s
Jun 13 11:21:45.239: INFO: Pod "pod-subpath-test-configmap-jztq": Phase="Running", Reason="", readiness=true. Elapsed: 4.014142867s
Jun 13 11:21:47.243: INFO: Pod "pod-subpath-test-configmap-jztq": Phase="Running", Reason="", readiness=true. Elapsed: 6.018687613s
Jun 13 11:21:49.248: INFO: Pod "pod-subpath-test-configmap-jztq": Phase="Running", Reason="", readiness=true. Elapsed: 8.022920985s
Jun 13 11:21:51.253: INFO: Pod "pod-subpath-test-configmap-jztq": Phase="Running", Reason="", readiness=true. Elapsed: 10.027860537s
Jun 13 11:21:53.257: INFO: Pod "pod-subpath-test-configmap-jztq": Phase="Running", Reason="", readiness=true. Elapsed: 12.032427963s
Jun 13 11:21:55.262: INFO: Pod "pod-subpath-test-configmap-jztq": Phase="Running", Reason="", readiness=true. Elapsed: 14.037697686s
Jun 13 11:21:57.267: INFO: Pod "pod-subpath-test-configmap-jztq": Phase="Running", Reason="", readiness=true. Elapsed: 16.042072053s
Jun 13 11:21:59.271: INFO: Pod "pod-subpath-test-configmap-jztq": Phase="Running", Reason="", readiness=true. Elapsed: 18.046152337s
Jun 13 11:22:01.276: INFO: Pod "pod-subpath-test-configmap-jztq": Phase="Running", Reason="", readiness=true. Elapsed: 20.051111754s
Jun 13 11:22:03.281: INFO: Pod "pod-subpath-test-configmap-jztq": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.055853937s
STEP: Saw pod success
Jun 13 11:22:03.281: INFO: Pod "pod-subpath-test-configmap-jztq" satisfied condition "success or failure"
Jun 13 11:22:03.284: INFO: Trying to get logs from node 10.0.10.2 pod pod-subpath-test-configmap-jztq container test-container-subpath-configmap-jztq: <nil>
STEP: delete the pod
Jun 13 11:22:03.311: INFO: Waiting for pod pod-subpath-test-configmap-jztq to disappear
Jun 13 11:22:03.315: INFO: Pod pod-subpath-test-configmap-jztq no longer exists
STEP: Deleting pod pod-subpath-test-configmap-jztq
Jun 13 11:22:03.315: INFO: Deleting pod "pod-subpath-test-configmap-jztq" in namespace "subpath-7183"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:22:03.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7183" for this suite.
Jun 13 11:22:09.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:22:09.491: INFO: namespace subpath-7183 deletion completed in 6.168339418s

• [SLOW TEST:28.334 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:22:09.493: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 13 11:22:10.086: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 13 11:22:13.111: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:22:13.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7781" for this suite.
Jun 13 11:22:19.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:22:19.277: INFO: namespace webhook-7781 deletion completed in 6.146989935s
STEP: Destroying namespace "webhook-7781-markers" for this suite.
Jun 13 11:22:25.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:22:25.420: INFO: namespace webhook-7781-markers deletion completed in 6.142865953s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.949 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:22:25.442: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 11:22:25.486: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Jun 13 11:22:28.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 --namespace=crd-publish-openapi-9987 create -f -'
Jun 13 11:22:28.939: INFO: stderr: ""
Jun 13 11:22:28.939: INFO: stdout: "e2e-test-crd-publish-openapi-5042-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Jun 13 11:22:28.939: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 --namespace=crd-publish-openapi-9987 delete e2e-test-crd-publish-openapi-5042-crds test-cr'
Jun 13 11:22:29.101: INFO: stderr: ""
Jun 13 11:22:29.101: INFO: stdout: "e2e-test-crd-publish-openapi-5042-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Jun 13 11:22:29.101: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 --namespace=crd-publish-openapi-9987 apply -f -'
Jun 13 11:22:29.418: INFO: stderr: ""
Jun 13 11:22:29.418: INFO: stdout: "e2e-test-crd-publish-openapi-5042-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Jun 13 11:22:29.418: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 --namespace=crd-publish-openapi-9987 delete e2e-test-crd-publish-openapi-5042-crds test-cr'
Jun 13 11:22:29.550: INFO: stderr: ""
Jun 13 11:22:29.550: INFO: stdout: "e2e-test-crd-publish-openapi-5042-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Jun 13 11:22:29.550: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 explain e2e-test-crd-publish-openapi-5042-crds'
Jun 13 11:22:29.802: INFO: stderr: ""
Jun 13 11:22:29.802: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5042-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:22:33.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9987" for this suite.
Jun 13 11:22:39.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:22:39.383: INFO: namespace crd-publish-openapi-9987 deletion completed in 6.144459718s

• [SLOW TEST:13.941 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:22:39.384: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3672
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-3672
STEP: Creating statefulset with conflicting port in namespace statefulset-3672
STEP: Waiting until pod test-pod will start running in namespace statefulset-3672
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-3672
Jun 13 11:22:43.483: INFO: Observed stateful pod in namespace: statefulset-3672, name: ss-0, uid: 619389d3-c1ad-4199-89a6-aebc579588d4, status phase: Pending. Waiting for statefulset controller to delete.
Jun 13 11:22:43.865: INFO: Observed stateful pod in namespace: statefulset-3672, name: ss-0, uid: 619389d3-c1ad-4199-89a6-aebc579588d4, status phase: Failed. Waiting for statefulset controller to delete.
Jun 13 11:22:43.873: INFO: Observed stateful pod in namespace: statefulset-3672, name: ss-0, uid: 619389d3-c1ad-4199-89a6-aebc579588d4, status phase: Failed. Waiting for statefulset controller to delete.
Jun 13 11:22:43.877: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-3672
STEP: Removing pod with conflicting port in namespace statefulset-3672
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-3672 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Jun 13 11:22:47.905: INFO: Deleting all statefulset in ns statefulset-3672
Jun 13 11:22:47.911: INFO: Scaling statefulset ss to 0
Jun 13 11:22:57.936: INFO: Waiting for statefulset status.replicas updated to 0
Jun 13 11:22:57.940: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:22:57.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3672" for this suite.
Jun 13 11:23:04.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:23:04.523: INFO: namespace statefulset-3672 deletion completed in 6.556187755s

• [SLOW TEST:25.139 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:23:04.523: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Jun 13 11:23:06.599: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:23:06.615: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8493" for this suite.
Jun 13 11:23:12.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:23:12.771: INFO: namespace container-runtime-8493 deletion completed in 6.151706261s

• [SLOW TEST:8.248 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:23:12.773: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-2786
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 13 11:23:12.832: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun 13 11:23:34.917: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.1.128 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2786 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 13 11:23:34.917: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 11:23:36.177: INFO: Found all expected endpoints: [netserver-0]
Jun 13 11:23:36.182: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.0.124 8081 | grep -v '^\s*$'] Namespace:pod-network-test-2786 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 13 11:23:36.182: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 11:23:37.406: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:23:37.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-2786" for this suite.
Jun 13 11:23:49.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:23:49.564: INFO: namespace pod-network-test-2786 deletion completed in 12.151846116s

• [SLOW TEST:36.791 seconds]
[sig-network] Networking
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:23:49.564: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-123
I0613 11:23:49.615665      22 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-123, replica count: 1
I0613 11:23:50.666199      22 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0613 11:23:51.666440      22 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Jun 13 11:23:51.780: INFO: Created: latency-svc-mkpgt
Jun 13 11:23:51.788: INFO: Got endpoints: latency-svc-mkpgt [21.893259ms]
Jun 13 11:23:51.799: INFO: Created: latency-svc-jh948
Jun 13 11:23:51.804: INFO: Got endpoints: latency-svc-jh948 [16.069587ms]
Jun 13 11:23:51.805: INFO: Created: latency-svc-ckqtd
Jun 13 11:23:51.810: INFO: Got endpoints: latency-svc-ckqtd [21.27379ms]
Jun 13 11:23:51.811: INFO: Created: latency-svc-9492k
Jun 13 11:23:51.816: INFO: Created: latency-svc-cjsgj
Jun 13 11:23:51.817: INFO: Got endpoints: latency-svc-9492k [28.256258ms]
Jun 13 11:23:51.822: INFO: Created: latency-svc-xw9pl
Jun 13 11:23:51.822: INFO: Got endpoints: latency-svc-cjsgj [33.646397ms]
Jun 13 11:23:51.826: INFO: Got endpoints: latency-svc-xw9pl [36.904822ms]
Jun 13 11:23:51.830: INFO: Created: latency-svc-jr7pw
Jun 13 11:23:51.836: INFO: Created: latency-svc-lh7xh
Jun 13 11:23:51.836: INFO: Got endpoints: latency-svc-jr7pw [48.003279ms]
Jun 13 11:23:51.841: INFO: Got endpoints: latency-svc-lh7xh [52.673854ms]
Jun 13 11:23:51.842: INFO: Created: latency-svc-9jrf6
Jun 13 11:23:51.847: INFO: Got endpoints: latency-svc-9jrf6 [58.471036ms]
Jun 13 11:23:51.848: INFO: Created: latency-svc-5w6lq
Jun 13 11:23:51.856: INFO: Created: latency-svc-gkxsv
Jun 13 11:23:51.856: INFO: Got endpoints: latency-svc-5w6lq [67.630556ms]
Jun 13 11:23:51.860: INFO: Got endpoints: latency-svc-gkxsv [71.372322ms]
Jun 13 11:23:51.863: INFO: Created: latency-svc-jkgmd
Jun 13 11:23:51.868: INFO: Created: latency-svc-5vwwf
Jun 13 11:23:51.868: INFO: Got endpoints: latency-svc-jkgmd [79.448365ms]
Jun 13 11:23:51.872: INFO: Got endpoints: latency-svc-5vwwf [82.937248ms]
Jun 13 11:23:51.876: INFO: Created: latency-svc-zf5c4
Jun 13 11:23:51.878: INFO: Got endpoints: latency-svc-zf5c4 [90.113825ms]
Jun 13 11:23:51.889: INFO: Created: latency-svc-dh72m
Jun 13 11:23:51.890: INFO: Created: latency-svc-9xnl5
Jun 13 11:23:51.892: INFO: Created: latency-svc-snjtn
Jun 13 11:23:51.895: INFO: Got endpoints: latency-svc-9xnl5 [106.411987ms]
Jun 13 11:23:51.896: INFO: Got endpoints: latency-svc-dh72m [107.589096ms]
Jun 13 11:23:51.900: INFO: Created: latency-svc-stlsz
Jun 13 11:23:51.900: INFO: Got endpoints: latency-svc-snjtn [95.355222ms]
Jun 13 11:23:51.903: INFO: Created: latency-svc-c8mjh
Jun 13 11:23:51.903: INFO: Got endpoints: latency-svc-stlsz [92.5896ms]
Jun 13 11:23:51.908: INFO: Got endpoints: latency-svc-c8mjh [91.403962ms]
Jun 13 11:23:51.912: INFO: Created: latency-svc-vskvq
Jun 13 11:23:51.914: INFO: Got endpoints: latency-svc-vskvq [91.462575ms]
Jun 13 11:23:51.917: INFO: Created: latency-svc-9bnf5
Jun 13 11:23:51.920: INFO: Got endpoints: latency-svc-9bnf5 [93.079825ms]
Jun 13 11:23:51.923: INFO: Created: latency-svc-bfgnx
Jun 13 11:23:51.927: INFO: Got endpoints: latency-svc-bfgnx [90.187441ms]
Jun 13 11:23:51.931: INFO: Created: latency-svc-lh8rc
Jun 13 11:23:51.934: INFO: Got endpoints: latency-svc-lh8rc [92.889522ms]
Jun 13 11:23:51.946: INFO: Created: latency-svc-bkfnx
Jun 13 11:23:51.947: INFO: Created: latency-svc-crkfl
Jun 13 11:23:51.949: INFO: Got endpoints: latency-svc-crkfl [92.468481ms]
Jun 13 11:23:51.949: INFO: Got endpoints: latency-svc-bkfnx [101.48882ms]
Jun 13 11:23:51.953: INFO: Created: latency-svc-sd8lv
Jun 13 11:23:51.955: INFO: Got endpoints: latency-svc-sd8lv [94.613577ms]
Jun 13 11:23:51.958: INFO: Created: latency-svc-qbgqp
Jun 13 11:23:51.963: INFO: Got endpoints: latency-svc-qbgqp [94.106712ms]
Jun 13 11:23:51.963: INFO: Created: latency-svc-bh596
Jun 13 11:23:51.968: INFO: Got endpoints: latency-svc-bh596 [96.628218ms]
Jun 13 11:23:51.970: INFO: Created: latency-svc-plt8h
Jun 13 11:23:51.976: INFO: Created: latency-svc-bjrgt
Jun 13 11:23:51.976: INFO: Got endpoints: latency-svc-plt8h [97.680658ms]
Jun 13 11:23:51.982: INFO: Got endpoints: latency-svc-bjrgt [83.501791ms]
Jun 13 11:23:51.983: INFO: Created: latency-svc-ljfj8
Jun 13 11:23:51.988: INFO: Created: latency-svc-twqqt
Jun 13 11:23:51.988: INFO: Got endpoints: latency-svc-ljfj8 [88.024811ms]
Jun 13 11:23:51.992: INFO: Got endpoints: latency-svc-twqqt [93.931043ms]
Jun 13 11:23:51.998: INFO: Created: latency-svc-89k9m
Jun 13 11:23:51.998: INFO: Got endpoints: latency-svc-89k9m [94.767133ms]
Jun 13 11:23:51.999: INFO: Created: latency-svc-ht9zw
Jun 13 11:23:52.007: INFO: Got endpoints: latency-svc-ht9zw [98.854441ms]
Jun 13 11:23:52.008: INFO: Created: latency-svc-dfz6d
Jun 13 11:23:52.015: INFO: Created: latency-svc-fmsvc
Jun 13 11:23:52.018: INFO: Created: latency-svc-ww5q8
Jun 13 11:23:52.024: INFO: Created: latency-svc-ln5xr
Jun 13 11:23:52.029: INFO: Created: latency-svc-8v5xh
Jun 13 11:23:52.036: INFO: Created: latency-svc-zqv6d
Jun 13 11:23:52.037: INFO: Got endpoints: latency-svc-dfz6d [121.857236ms]
Jun 13 11:23:52.041: INFO: Created: latency-svc-zmgwv
Jun 13 11:23:52.048: INFO: Created: latency-svc-8256n
Jun 13 11:23:52.052: INFO: Created: latency-svc-hdz95
Jun 13 11:23:52.058: INFO: Created: latency-svc-jkwbk
Jun 13 11:23:52.063: INFO: Created: latency-svc-rbdxh
Jun 13 11:23:52.070: INFO: Created: latency-svc-qg7vj
Jun 13 11:23:52.077: INFO: Created: latency-svc-qvnf5
Jun 13 11:23:52.082: INFO: Created: latency-svc-4vh97
Jun 13 11:23:52.087: INFO: Got endpoints: latency-svc-fmsvc [165.244395ms]
Jun 13 11:23:52.088: INFO: Created: latency-svc-l7m5c
Jun 13 11:23:52.096: INFO: Created: latency-svc-gkzwk
Jun 13 11:23:52.103: INFO: Created: latency-svc-z4r7x
Jun 13 11:23:52.136: INFO: Got endpoints: latency-svc-ww5q8 [208.519189ms]
Jun 13 11:23:52.147: INFO: Created: latency-svc-5m7bx
Jun 13 11:23:52.185: INFO: Got endpoints: latency-svc-ln5xr [245.479853ms]
Jun 13 11:23:52.196: INFO: Created: latency-svc-mnrkv
Jun 13 11:23:52.236: INFO: Got endpoints: latency-svc-8v5xh [286.116112ms]
Jun 13 11:23:52.250: INFO: Created: latency-svc-8x5nd
Jun 13 11:23:52.286: INFO: Got endpoints: latency-svc-zqv6d [335.35506ms]
Jun 13 11:23:52.298: INFO: Created: latency-svc-pndpq
Jun 13 11:23:52.335: INFO: Got endpoints: latency-svc-zmgwv [379.721653ms]
Jun 13 11:23:52.346: INFO: Created: latency-svc-wgjjc
Jun 13 11:23:52.385: INFO: Got endpoints: latency-svc-8256n [421.425874ms]
Jun 13 11:23:52.397: INFO: Created: latency-svc-ps2x2
Jun 13 11:23:52.435: INFO: Got endpoints: latency-svc-hdz95 [465.060743ms]
Jun 13 11:23:52.447: INFO: Created: latency-svc-z4krw
Jun 13 11:23:52.485: INFO: Got endpoints: latency-svc-jkwbk [508.961241ms]
Jun 13 11:23:52.502: INFO: Created: latency-svc-kd9sp
Jun 13 11:23:52.536: INFO: Got endpoints: latency-svc-rbdxh [552.865512ms]
Jun 13 11:23:52.548: INFO: Created: latency-svc-cmr85
Jun 13 11:23:52.586: INFO: Got endpoints: latency-svc-qg7vj [597.272811ms]
Jun 13 11:23:52.597: INFO: Created: latency-svc-7xltj
Jun 13 11:23:52.636: INFO: Got endpoints: latency-svc-qvnf5 [637.615878ms]
Jun 13 11:23:52.649: INFO: Created: latency-svc-trmn4
Jun 13 11:23:52.685: INFO: Got endpoints: latency-svc-4vh97 [692.950353ms]
Jun 13 11:23:52.701: INFO: Created: latency-svc-b4klq
Jun 13 11:23:52.735: INFO: Got endpoints: latency-svc-l7m5c [726.637ms]
Jun 13 11:23:52.749: INFO: Created: latency-svc-stgth
Jun 13 11:23:52.786: INFO: Got endpoints: latency-svc-gkzwk [748.878991ms]
Jun 13 11:23:52.798: INFO: Created: latency-svc-gfpz7
Jun 13 11:23:52.835: INFO: Got endpoints: latency-svc-z4r7x [748.558023ms]
Jun 13 11:23:52.845: INFO: Created: latency-svc-qmptr
Jun 13 11:23:52.886: INFO: Got endpoints: latency-svc-5m7bx [750.109861ms]
Jun 13 11:23:52.901: INFO: Created: latency-svc-fvtcr
Jun 13 11:23:52.938: INFO: Got endpoints: latency-svc-mnrkv [752.167329ms]
Jun 13 11:23:52.949: INFO: Created: latency-svc-86lgv
Jun 13 11:23:52.985: INFO: Got endpoints: latency-svc-8x5nd [748.459968ms]
Jun 13 11:23:52.997: INFO: Created: latency-svc-cmgsw
Jun 13 11:23:53.037: INFO: Got endpoints: latency-svc-pndpq [751.267582ms]
Jun 13 11:23:53.054: INFO: Created: latency-svc-dqtcl
Jun 13 11:23:53.086: INFO: Got endpoints: latency-svc-wgjjc [750.118963ms]
Jun 13 11:23:53.097: INFO: Created: latency-svc-qfsmm
Jun 13 11:23:53.135: INFO: Got endpoints: latency-svc-ps2x2 [750.079304ms]
Jun 13 11:23:53.147: INFO: Created: latency-svc-9r7qz
Jun 13 11:23:53.189: INFO: Got endpoints: latency-svc-z4krw [752.265947ms]
Jun 13 11:23:53.210: INFO: Created: latency-svc-br4cz
Jun 13 11:23:53.236: INFO: Got endpoints: latency-svc-kd9sp [750.227233ms]
Jun 13 11:23:53.252: INFO: Created: latency-svc-vzdkh
Jun 13 11:23:53.286: INFO: Got endpoints: latency-svc-cmr85 [750.798439ms]
Jun 13 11:23:53.299: INFO: Created: latency-svc-2jvjk
Jun 13 11:23:53.336: INFO: Got endpoints: latency-svc-7xltj [750.330168ms]
Jun 13 11:23:53.350: INFO: Created: latency-svc-zhfzb
Jun 13 11:23:53.386: INFO: Got endpoints: latency-svc-trmn4 [749.323707ms]
Jun 13 11:23:53.398: INFO: Created: latency-svc-bcd6r
Jun 13 11:23:53.436: INFO: Got endpoints: latency-svc-b4klq [750.625939ms]
Jun 13 11:23:53.447: INFO: Created: latency-svc-v6hww
Jun 13 11:23:53.485: INFO: Got endpoints: latency-svc-stgth [748.969291ms]
Jun 13 11:23:53.498: INFO: Created: latency-svc-mqsbc
Jun 13 11:23:53.536: INFO: Got endpoints: latency-svc-gfpz7 [750.23402ms]
Jun 13 11:23:53.549: INFO: Created: latency-svc-h9n9t
Jun 13 11:23:53.586: INFO: Got endpoints: latency-svc-qmptr [750.360483ms]
Jun 13 11:23:53.609: INFO: Created: latency-svc-h7ncb
Jun 13 11:23:53.636: INFO: Got endpoints: latency-svc-fvtcr [748.184995ms]
Jun 13 11:23:53.647: INFO: Created: latency-svc-rhsg4
Jun 13 11:23:53.685: INFO: Got endpoints: latency-svc-86lgv [747.425054ms]
Jun 13 11:23:53.695: INFO: Created: latency-svc-h2ct6
Jun 13 11:23:53.741: INFO: Got endpoints: latency-svc-cmgsw [755.080759ms]
Jun 13 11:23:53.752: INFO: Created: latency-svc-6l28g
Jun 13 11:23:53.786: INFO: Got endpoints: latency-svc-dqtcl [748.417935ms]
Jun 13 11:23:53.800: INFO: Created: latency-svc-2vm9b
Jun 13 11:23:53.836: INFO: Got endpoints: latency-svc-qfsmm [750.67051ms]
Jun 13 11:23:53.851: INFO: Created: latency-svc-dqk4r
Jun 13 11:23:53.886: INFO: Got endpoints: latency-svc-9r7qz [750.38234ms]
Jun 13 11:23:53.902: INFO: Created: latency-svc-ltk4z
Jun 13 11:23:53.936: INFO: Got endpoints: latency-svc-br4cz [747.411308ms]
Jun 13 11:23:53.948: INFO: Created: latency-svc-k4sk7
Jun 13 11:23:53.986: INFO: Got endpoints: latency-svc-vzdkh [749.821449ms]
Jun 13 11:23:54.001: INFO: Created: latency-svc-crkc5
Jun 13 11:23:54.036: INFO: Got endpoints: latency-svc-2jvjk [748.350039ms]
Jun 13 11:23:54.047: INFO: Created: latency-svc-sc9df
Jun 13 11:23:54.085: INFO: Got endpoints: latency-svc-zhfzb [748.456933ms]
Jun 13 11:23:54.099: INFO: Created: latency-svc-qjw8q
Jun 13 11:23:54.135: INFO: Got endpoints: latency-svc-bcd6r [749.663938ms]
Jun 13 11:23:54.148: INFO: Created: latency-svc-k7sdt
Jun 13 11:23:54.185: INFO: Got endpoints: latency-svc-v6hww [749.483643ms]
Jun 13 11:23:54.200: INFO: Created: latency-svc-q4l6s
Jun 13 11:23:54.236: INFO: Got endpoints: latency-svc-mqsbc [749.193974ms]
Jun 13 11:23:54.250: INFO: Created: latency-svc-czkp4
Jun 13 11:23:54.286: INFO: Got endpoints: latency-svc-h9n9t [749.307446ms]
Jun 13 11:23:54.300: INFO: Created: latency-svc-nq9qs
Jun 13 11:23:54.339: INFO: Got endpoints: latency-svc-h7ncb [753.399493ms]
Jun 13 11:23:54.351: INFO: Created: latency-svc-49nvq
Jun 13 11:23:54.386: INFO: Got endpoints: latency-svc-rhsg4 [750.261958ms]
Jun 13 11:23:54.401: INFO: Created: latency-svc-84snt
Jun 13 11:23:54.436: INFO: Got endpoints: latency-svc-h2ct6 [750.758214ms]
Jun 13 11:23:54.452: INFO: Created: latency-svc-m5tnn
Jun 13 11:23:54.487: INFO: Got endpoints: latency-svc-6l28g [745.27819ms]
Jun 13 11:23:54.499: INFO: Created: latency-svc-7vl24
Jun 13 11:23:54.536: INFO: Got endpoints: latency-svc-2vm9b [750.366216ms]
Jun 13 11:23:54.554: INFO: Created: latency-svc-wt7ft
Jun 13 11:23:54.590: INFO: Got endpoints: latency-svc-dqk4r [753.03938ms]
Jun 13 11:23:54.609: INFO: Created: latency-svc-f4wvl
Jun 13 11:23:54.636: INFO: Got endpoints: latency-svc-ltk4z [749.77702ms]
Jun 13 11:23:54.652: INFO: Created: latency-svc-njzcx
Jun 13 11:23:54.686: INFO: Got endpoints: latency-svc-k4sk7 [748.789809ms]
Jun 13 11:23:54.701: INFO: Created: latency-svc-6hxhc
Jun 13 11:23:54.736: INFO: Got endpoints: latency-svc-crkc5 [750.055168ms]
Jun 13 11:23:54.750: INFO: Created: latency-svc-4ff2h
Jun 13 11:23:54.786: INFO: Got endpoints: latency-svc-sc9df [750.097492ms]
Jun 13 11:23:54.801: INFO: Created: latency-svc-8xtvk
Jun 13 11:23:54.836: INFO: Got endpoints: latency-svc-qjw8q [749.813727ms]
Jun 13 11:23:54.855: INFO: Created: latency-svc-sl4zk
Jun 13 11:23:54.886: INFO: Got endpoints: latency-svc-k7sdt [750.585424ms]
Jun 13 11:23:54.904: INFO: Created: latency-svc-t7r6l
Jun 13 11:23:54.935: INFO: Got endpoints: latency-svc-q4l6s [748.611357ms]
Jun 13 11:23:54.954: INFO: Created: latency-svc-hclqf
Jun 13 11:23:54.986: INFO: Got endpoints: latency-svc-czkp4 [749.331875ms]
Jun 13 11:23:55.004: INFO: Created: latency-svc-54tlc
Jun 13 11:23:55.037: INFO: Got endpoints: latency-svc-nq9qs [750.860888ms]
Jun 13 11:23:55.051: INFO: Created: latency-svc-btkvz
Jun 13 11:23:55.087: INFO: Got endpoints: latency-svc-49nvq [747.245217ms]
Jun 13 11:23:55.099: INFO: Created: latency-svc-4mqp4
Jun 13 11:23:55.137: INFO: Got endpoints: latency-svc-84snt [750.651856ms]
Jun 13 11:23:55.149: INFO: Created: latency-svc-8rnm2
Jun 13 11:23:55.186: INFO: Got endpoints: latency-svc-m5tnn [749.467814ms]
Jun 13 11:23:55.206: INFO: Created: latency-svc-nq65m
Jun 13 11:23:55.236: INFO: Got endpoints: latency-svc-7vl24 [748.485651ms]
Jun 13 11:23:55.249: INFO: Created: latency-svc-p5ffl
Jun 13 11:23:55.285: INFO: Got endpoints: latency-svc-wt7ft [748.811579ms]
Jun 13 11:23:55.299: INFO: Created: latency-svc-z8d7h
Jun 13 11:23:55.336: INFO: Got endpoints: latency-svc-f4wvl [745.26141ms]
Jun 13 11:23:55.349: INFO: Created: latency-svc-b5dmc
Jun 13 11:23:55.386: INFO: Got endpoints: latency-svc-njzcx [749.254471ms]
Jun 13 11:23:55.398: INFO: Created: latency-svc-sm5jl
Jun 13 11:23:55.436: INFO: Got endpoints: latency-svc-6hxhc [749.940375ms]
Jun 13 11:23:55.448: INFO: Created: latency-svc-6kcsj
Jun 13 11:23:55.489: INFO: Got endpoints: latency-svc-4ff2h [752.582312ms]
Jun 13 11:23:55.502: INFO: Created: latency-svc-7jzjq
Jun 13 11:23:55.536: INFO: Got endpoints: latency-svc-8xtvk [749.946322ms]
Jun 13 11:23:55.550: INFO: Created: latency-svc-xcxwl
Jun 13 11:23:55.586: INFO: Got endpoints: latency-svc-sl4zk [749.605099ms]
Jun 13 11:23:55.600: INFO: Created: latency-svc-xf6rv
Jun 13 11:23:55.636: INFO: Got endpoints: latency-svc-t7r6l [749.832519ms]
Jun 13 11:23:55.653: INFO: Created: latency-svc-trk8h
Jun 13 11:23:55.686: INFO: Got endpoints: latency-svc-hclqf [748.682168ms]
Jun 13 11:23:55.697: INFO: Created: latency-svc-sjv5t
Jun 13 11:23:55.735: INFO: Got endpoints: latency-svc-54tlc [748.498712ms]
Jun 13 11:23:55.748: INFO: Created: latency-svc-lc2k9
Jun 13 11:23:55.787: INFO: Got endpoints: latency-svc-btkvz [749.550976ms]
Jun 13 11:23:55.798: INFO: Created: latency-svc-d9lbd
Jun 13 11:23:55.836: INFO: Got endpoints: latency-svc-4mqp4 [748.616529ms]
Jun 13 11:23:55.854: INFO: Created: latency-svc-b6tft
Jun 13 11:23:55.885: INFO: Got endpoints: latency-svc-8rnm2 [747.652267ms]
Jun 13 11:23:55.900: INFO: Created: latency-svc-q9v4t
Jun 13 11:23:55.935: INFO: Got endpoints: latency-svc-nq65m [743.465891ms]
Jun 13 11:23:55.952: INFO: Created: latency-svc-95t6v
Jun 13 11:23:55.988: INFO: Got endpoints: latency-svc-p5ffl [749.600054ms]
Jun 13 11:23:56.000: INFO: Created: latency-svc-kpv4k
Jun 13 11:23:56.035: INFO: Got endpoints: latency-svc-z8d7h [749.040894ms]
Jun 13 11:23:56.049: INFO: Created: latency-svc-dzqmj
Jun 13 11:23:56.086: INFO: Got endpoints: latency-svc-b5dmc [748.813458ms]
Jun 13 11:23:56.108: INFO: Created: latency-svc-l6g76
Jun 13 11:23:56.135: INFO: Got endpoints: latency-svc-sm5jl [749.365832ms]
Jun 13 11:23:56.148: INFO: Created: latency-svc-bpxjr
Jun 13 11:23:56.186: INFO: Got endpoints: latency-svc-6kcsj [749.858924ms]
Jun 13 11:23:56.203: INFO: Created: latency-svc-665fj
Jun 13 11:23:56.235: INFO: Got endpoints: latency-svc-7jzjq [746.238386ms]
Jun 13 11:23:56.253: INFO: Created: latency-svc-dtglp
Jun 13 11:23:56.287: INFO: Got endpoints: latency-svc-xcxwl [750.271613ms]
Jun 13 11:23:56.301: INFO: Created: latency-svc-nbxv5
Jun 13 11:23:56.336: INFO: Got endpoints: latency-svc-xf6rv [749.021919ms]
Jun 13 11:23:56.349: INFO: Created: latency-svc-8p7cp
Jun 13 11:23:56.389: INFO: Got endpoints: latency-svc-trk8h [752.358563ms]
Jun 13 11:23:56.401: INFO: Created: latency-svc-58tgf
Jun 13 11:23:56.436: INFO: Got endpoints: latency-svc-sjv5t [749.617004ms]
Jun 13 11:23:56.451: INFO: Created: latency-svc-6wftc
Jun 13 11:23:56.486: INFO: Got endpoints: latency-svc-lc2k9 [750.719223ms]
Jun 13 11:23:56.502: INFO: Created: latency-svc-ld7p9
Jun 13 11:23:56.535: INFO: Got endpoints: latency-svc-d9lbd [748.368348ms]
Jun 13 11:23:56.547: INFO: Created: latency-svc-8qhjr
Jun 13 11:23:56.588: INFO: Got endpoints: latency-svc-b6tft [750.803222ms]
Jun 13 11:23:56.605: INFO: Created: latency-svc-zkbt5
Jun 13 11:23:56.637: INFO: Got endpoints: latency-svc-q9v4t [750.932716ms]
Jun 13 11:23:56.650: INFO: Created: latency-svc-wdgbj
Jun 13 11:23:56.686: INFO: Got endpoints: latency-svc-95t6v [745.639681ms]
Jun 13 11:23:56.699: INFO: Created: latency-svc-5p25t
Jun 13 11:23:56.736: INFO: Got endpoints: latency-svc-kpv4k [747.854757ms]
Jun 13 11:23:56.753: INFO: Created: latency-svc-mzmwp
Jun 13 11:23:56.786: INFO: Got endpoints: latency-svc-dzqmj [750.064282ms]
Jun 13 11:23:56.799: INFO: Created: latency-svc-fklcp
Jun 13 11:23:56.835: INFO: Got endpoints: latency-svc-l6g76 [749.375971ms]
Jun 13 11:23:56.849: INFO: Created: latency-svc-lhkcp
Jun 13 11:23:56.886: INFO: Got endpoints: latency-svc-bpxjr [749.60967ms]
Jun 13 11:23:56.903: INFO: Created: latency-svc-rnm6d
Jun 13 11:23:56.938: INFO: Got endpoints: latency-svc-665fj [750.545717ms]
Jun 13 11:23:56.949: INFO: Created: latency-svc-8kz95
Jun 13 11:23:56.986: INFO: Got endpoints: latency-svc-dtglp [749.711273ms]
Jun 13 11:23:57.002: INFO: Created: latency-svc-8dbdp
Jun 13 11:23:57.038: INFO: Got endpoints: latency-svc-nbxv5 [750.999336ms]
Jun 13 11:23:57.048: INFO: Created: latency-svc-p2pkc
Jun 13 11:23:57.087: INFO: Got endpoints: latency-svc-8p7cp [749.101453ms]
Jun 13 11:23:57.098: INFO: Created: latency-svc-9vvwv
Jun 13 11:23:57.135: INFO: Got endpoints: latency-svc-58tgf [745.668178ms]
Jun 13 11:23:57.147: INFO: Created: latency-svc-zrhz5
Jun 13 11:23:57.185: INFO: Got endpoints: latency-svc-6wftc [748.083592ms]
Jun 13 11:23:57.199: INFO: Created: latency-svc-j7wfw
Jun 13 11:23:57.236: INFO: Got endpoints: latency-svc-ld7p9 [747.514069ms]
Jun 13 11:23:57.247: INFO: Created: latency-svc-8nltk
Jun 13 11:23:57.289: INFO: Got endpoints: latency-svc-8qhjr [753.074169ms]
Jun 13 11:23:57.303: INFO: Created: latency-svc-pkwcb
Jun 13 11:23:57.337: INFO: Got endpoints: latency-svc-zkbt5 [743.666645ms]
Jun 13 11:23:57.352: INFO: Created: latency-svc-qjf7v
Jun 13 11:23:57.386: INFO: Got endpoints: latency-svc-wdgbj [748.594766ms]
Jun 13 11:23:57.400: INFO: Created: latency-svc-chrhv
Jun 13 11:23:57.438: INFO: Got endpoints: latency-svc-5p25t [751.708153ms]
Jun 13 11:23:57.449: INFO: Created: latency-svc-fzlnc
Jun 13 11:23:57.487: INFO: Got endpoints: latency-svc-mzmwp [744.870786ms]
Jun 13 11:23:57.498: INFO: Created: latency-svc-b8kvw
Jun 13 11:23:57.538: INFO: Got endpoints: latency-svc-fklcp [751.396481ms]
Jun 13 11:23:57.549: INFO: Created: latency-svc-kd8xz
Jun 13 11:23:57.586: INFO: Got endpoints: latency-svc-lhkcp [749.38659ms]
Jun 13 11:23:57.598: INFO: Created: latency-svc-r4kkg
Jun 13 11:23:57.636: INFO: Got endpoints: latency-svc-rnm6d [749.894413ms]
Jun 13 11:23:57.649: INFO: Created: latency-svc-6z595
Jun 13 11:23:57.686: INFO: Got endpoints: latency-svc-8kz95 [747.851255ms]
Jun 13 11:23:57.701: INFO: Created: latency-svc-87bdp
Jun 13 11:23:57.736: INFO: Got endpoints: latency-svc-8dbdp [749.286007ms]
Jun 13 11:23:57.751: INFO: Created: latency-svc-f4rcd
Jun 13 11:23:57.786: INFO: Got endpoints: latency-svc-p2pkc [748.246323ms]
Jun 13 11:23:57.805: INFO: Created: latency-svc-5g7tz
Jun 13 11:23:57.836: INFO: Got endpoints: latency-svc-9vvwv [748.601737ms]
Jun 13 11:23:57.848: INFO: Created: latency-svc-4zc6k
Jun 13 11:23:57.892: INFO: Got endpoints: latency-svc-zrhz5 [756.034544ms]
Jun 13 11:23:57.918: INFO: Created: latency-svc-lspgd
Jun 13 11:23:57.935: INFO: Got endpoints: latency-svc-j7wfw [748.20086ms]
Jun 13 11:23:57.957: INFO: Created: latency-svc-x5tjs
Jun 13 11:23:57.986: INFO: Got endpoints: latency-svc-8nltk [750.541887ms]
Jun 13 11:23:58.000: INFO: Created: latency-svc-j64xf
Jun 13 11:23:58.039: INFO: Got endpoints: latency-svc-pkwcb [749.940829ms]
Jun 13 11:23:58.052: INFO: Created: latency-svc-vt4cx
Jun 13 11:23:58.089: INFO: Got endpoints: latency-svc-qjf7v [749.847084ms]
Jun 13 11:23:58.101: INFO: Created: latency-svc-nxvfp
Jun 13 11:23:58.135: INFO: Got endpoints: latency-svc-chrhv [748.292729ms]
Jun 13 11:23:58.147: INFO: Created: latency-svc-65xn7
Jun 13 11:23:58.185: INFO: Got endpoints: latency-svc-fzlnc [747.086597ms]
Jun 13 11:23:58.205: INFO: Created: latency-svc-hnvlf
Jun 13 11:23:58.236: INFO: Got endpoints: latency-svc-b8kvw [748.489809ms]
Jun 13 11:23:58.250: INFO: Created: latency-svc-76dng
Jun 13 11:23:58.286: INFO: Got endpoints: latency-svc-kd8xz [748.292234ms]
Jun 13 11:23:58.300: INFO: Created: latency-svc-mt78k
Jun 13 11:23:58.336: INFO: Got endpoints: latency-svc-r4kkg [750.27722ms]
Jun 13 11:23:58.352: INFO: Created: latency-svc-q2cbl
Jun 13 11:23:58.386: INFO: Got endpoints: latency-svc-6z595 [748.737463ms]
Jun 13 11:23:58.401: INFO: Created: latency-svc-mnpcz
Jun 13 11:23:58.436: INFO: Got endpoints: latency-svc-87bdp [749.931994ms]
Jun 13 11:23:58.449: INFO: Created: latency-svc-jtkc2
Jun 13 11:23:58.486: INFO: Got endpoints: latency-svc-f4rcd [746.441553ms]
Jun 13 11:23:58.498: INFO: Created: latency-svc-s2zwb
Jun 13 11:23:58.536: INFO: Got endpoints: latency-svc-5g7tz [749.82839ms]
Jun 13 11:23:58.549: INFO: Created: latency-svc-8rph2
Jun 13 11:23:58.586: INFO: Got endpoints: latency-svc-4zc6k [748.982102ms]
Jun 13 11:23:58.613: INFO: Created: latency-svc-j7pjp
Jun 13 11:23:58.638: INFO: Got endpoints: latency-svc-lspgd [735.655605ms]
Jun 13 11:23:58.650: INFO: Created: latency-svc-cm9lw
Jun 13 11:23:58.686: INFO: Got endpoints: latency-svc-x5tjs [748.389574ms]
Jun 13 11:23:58.702: INFO: Created: latency-svc-d4ks2
Jun 13 11:23:58.737: INFO: Got endpoints: latency-svc-j64xf [750.379238ms]
Jun 13 11:23:58.753: INFO: Created: latency-svc-zs9vg
Jun 13 11:23:58.787: INFO: Got endpoints: latency-svc-vt4cx [748.001316ms]
Jun 13 11:23:58.800: INFO: Created: latency-svc-k8g7q
Jun 13 11:23:58.836: INFO: Got endpoints: latency-svc-nxvfp [747.093507ms]
Jun 13 11:23:58.850: INFO: Created: latency-svc-z9wc7
Jun 13 11:23:58.888: INFO: Got endpoints: latency-svc-65xn7 [752.294453ms]
Jun 13 11:23:58.900: INFO: Created: latency-svc-psx7x
Jun 13 11:23:58.936: INFO: Got endpoints: latency-svc-hnvlf [744.995801ms]
Jun 13 11:23:58.949: INFO: Created: latency-svc-qj2vf
Jun 13 11:23:58.985: INFO: Got endpoints: latency-svc-76dng [747.92515ms]
Jun 13 11:23:58.996: INFO: Created: latency-svc-4tq7f
Jun 13 11:23:59.037: INFO: Got endpoints: latency-svc-mt78k [748.087532ms]
Jun 13 11:23:59.059: INFO: Created: latency-svc-p44gf
Jun 13 11:23:59.085: INFO: Got endpoints: latency-svc-q2cbl [745.593926ms]
Jun 13 11:23:59.098: INFO: Created: latency-svc-clgqt
Jun 13 11:23:59.136: INFO: Got endpoints: latency-svc-mnpcz [750.23038ms]
Jun 13 11:23:59.150: INFO: Created: latency-svc-tkspp
Jun 13 11:23:59.185: INFO: Got endpoints: latency-svc-jtkc2 [748.125572ms]
Jun 13 11:23:59.201: INFO: Created: latency-svc-d9kw8
Jun 13 11:23:59.236: INFO: Got endpoints: latency-svc-s2zwb [750.059334ms]
Jun 13 11:23:59.251: INFO: Created: latency-svc-sbfzx
Jun 13 11:23:59.286: INFO: Got endpoints: latency-svc-8rph2 [749.777995ms]
Jun 13 11:23:59.298: INFO: Created: latency-svc-pcvht
Jun 13 11:23:59.336: INFO: Got endpoints: latency-svc-j7pjp [750.057347ms]
Jun 13 11:23:59.348: INFO: Created: latency-svc-fcnvf
Jun 13 11:23:59.390: INFO: Got endpoints: latency-svc-cm9lw [751.548739ms]
Jun 13 11:23:59.403: INFO: Created: latency-svc-tqk62
Jun 13 11:23:59.439: INFO: Got endpoints: latency-svc-d4ks2 [752.575687ms]
Jun 13 11:23:59.452: INFO: Created: latency-svc-xhctw
Jun 13 11:23:59.488: INFO: Got endpoints: latency-svc-zs9vg [751.016417ms]
Jun 13 11:23:59.512: INFO: Created: latency-svc-snhf8
Jun 13 11:23:59.537: INFO: Got endpoints: latency-svc-k8g7q [749.687389ms]
Jun 13 11:23:59.549: INFO: Created: latency-svc-kcvlx
Jun 13 11:23:59.586: INFO: Got endpoints: latency-svc-z9wc7 [749.381681ms]
Jun 13 11:23:59.597: INFO: Created: latency-svc-6q5rb
Jun 13 11:23:59.636: INFO: Got endpoints: latency-svc-psx7x [747.999716ms]
Jun 13 11:23:59.685: INFO: Got endpoints: latency-svc-qj2vf [749.321464ms]
Jun 13 11:23:59.737: INFO: Got endpoints: latency-svc-4tq7f [751.433463ms]
Jun 13 11:23:59.786: INFO: Got endpoints: latency-svc-p44gf [741.556784ms]
Jun 13 11:23:59.836: INFO: Got endpoints: latency-svc-clgqt [750.329539ms]
Jun 13 11:23:59.886: INFO: Got endpoints: latency-svc-tkspp [748.947616ms]
Jun 13 11:23:59.936: INFO: Got endpoints: latency-svc-d9kw8 [750.33651ms]
Jun 13 11:23:59.986: INFO: Got endpoints: latency-svc-sbfzx [749.187209ms]
Jun 13 11:24:00.036: INFO: Got endpoints: latency-svc-pcvht [749.902346ms]
Jun 13 11:24:00.086: INFO: Got endpoints: latency-svc-fcnvf [749.90648ms]
Jun 13 11:24:00.139: INFO: Got endpoints: latency-svc-tqk62 [747.18864ms]
Jun 13 11:24:00.187: INFO: Got endpoints: latency-svc-xhctw [747.406649ms]
Jun 13 11:24:00.236: INFO: Got endpoints: latency-svc-snhf8 [747.90784ms]
Jun 13 11:24:00.286: INFO: Got endpoints: latency-svc-kcvlx [749.159674ms]
Jun 13 11:24:00.336: INFO: Got endpoints: latency-svc-6q5rb [750.123837ms]
Jun 13 11:24:00.337: INFO: Latencies: [16.069587ms 21.27379ms 28.256258ms 33.646397ms 36.904822ms 48.003279ms 52.673854ms 58.471036ms 67.630556ms 71.372322ms 79.448365ms 82.937248ms 83.501791ms 88.024811ms 90.113825ms 90.187441ms 91.403962ms 91.462575ms 92.468481ms 92.5896ms 92.889522ms 93.079825ms 93.931043ms 94.106712ms 94.613577ms 94.767133ms 95.355222ms 96.628218ms 97.680658ms 98.854441ms 101.48882ms 106.411987ms 107.589096ms 121.857236ms 165.244395ms 208.519189ms 245.479853ms 286.116112ms 335.35506ms 379.721653ms 421.425874ms 465.060743ms 508.961241ms 552.865512ms 597.272811ms 637.615878ms 692.950353ms 726.637ms 735.655605ms 741.556784ms 743.465891ms 743.666645ms 744.870786ms 744.995801ms 745.26141ms 745.27819ms 745.593926ms 745.639681ms 745.668178ms 746.238386ms 746.441553ms 747.086597ms 747.093507ms 747.18864ms 747.245217ms 747.406649ms 747.411308ms 747.425054ms 747.514069ms 747.652267ms 747.851255ms 747.854757ms 747.90784ms 747.92515ms 747.999716ms 748.001316ms 748.083592ms 748.087532ms 748.125572ms 748.184995ms 748.20086ms 748.246323ms 748.292234ms 748.292729ms 748.350039ms 748.368348ms 748.389574ms 748.417935ms 748.456933ms 748.459968ms 748.485651ms 748.489809ms 748.498712ms 748.558023ms 748.594766ms 748.601737ms 748.611357ms 748.616529ms 748.682168ms 748.737463ms 748.789809ms 748.811579ms 748.813458ms 748.878991ms 748.947616ms 748.969291ms 748.982102ms 749.021919ms 749.040894ms 749.101453ms 749.159674ms 749.187209ms 749.193974ms 749.254471ms 749.286007ms 749.307446ms 749.321464ms 749.323707ms 749.331875ms 749.365832ms 749.375971ms 749.381681ms 749.38659ms 749.467814ms 749.483643ms 749.550976ms 749.600054ms 749.605099ms 749.60967ms 749.617004ms 749.663938ms 749.687389ms 749.711273ms 749.77702ms 749.777995ms 749.813727ms 749.821449ms 749.82839ms 749.832519ms 749.847084ms 749.858924ms 749.894413ms 749.902346ms 749.90648ms 749.931994ms 749.940375ms 749.940829ms 749.946322ms 750.055168ms 750.057347ms 750.059334ms 750.064282ms 750.079304ms 750.097492ms 750.109861ms 750.118963ms 750.123837ms 750.227233ms 750.23038ms 750.23402ms 750.261958ms 750.271613ms 750.27722ms 750.329539ms 750.330168ms 750.33651ms 750.360483ms 750.366216ms 750.379238ms 750.38234ms 750.541887ms 750.545717ms 750.585424ms 750.625939ms 750.651856ms 750.67051ms 750.719223ms 750.758214ms 750.798439ms 750.803222ms 750.860888ms 750.932716ms 750.999336ms 751.016417ms 751.267582ms 751.396481ms 751.433463ms 751.548739ms 751.708153ms 752.167329ms 752.265947ms 752.294453ms 752.358563ms 752.575687ms 752.582312ms 753.03938ms 753.074169ms 753.399493ms 755.080759ms 756.034544ms]
Jun 13 11:24:00.340: INFO: 50 %ile: 748.789809ms
Jun 13 11:24:00.340: INFO: 90 %ile: 750.860888ms
Jun 13 11:24:00.341: INFO: 99 %ile: 755.080759ms
Jun 13 11:24:00.341: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:24:00.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-123" for this suite.
Jun 13 11:24:18.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:24:18.525: INFO: namespace svc-latency-123 deletion completed in 18.169367332s

• [SLOW TEST:28.961 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:24:18.532: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 13 11:24:18.959: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jun 13 11:24:20.971: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727644258, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727644258, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727644258, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727644258, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 13 11:24:23.989: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:24:36.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-294" for this suite.
Jun 13 11:24:42.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:24:42.613: INFO: namespace webhook-294 deletion completed in 6.144431137s
STEP: Destroying namespace "webhook-294-markers" for this suite.
Jun 13 11:24:48.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:24:48.770: INFO: namespace webhook-294-markers deletion completed in 6.157210068s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:30.260 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:24:48.796: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Jun 13 11:24:48.848: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 11:24:51.316: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:25:03.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8845" for this suite.
Jun 13 11:25:09.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:25:09.904: INFO: namespace crd-publish-openapi-8845 deletion completed in 6.14532481s

• [SLOW TEST:21.109 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:25:09.905: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Jun 13 11:25:09.961: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1f60205d-5866-46fe-a4b1-af2cbed3a566" in namespace "downward-api-7155" to be "success or failure"
Jun 13 11:25:09.965: INFO: Pod "downwardapi-volume-1f60205d-5866-46fe-a4b1-af2cbed3a566": Phase="Pending", Reason="", readiness=false. Elapsed: 4.40607ms
Jun 13 11:25:11.970: INFO: Pod "downwardapi-volume-1f60205d-5866-46fe-a4b1-af2cbed3a566": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009089111s
STEP: Saw pod success
Jun 13 11:25:11.970: INFO: Pod "downwardapi-volume-1f60205d-5866-46fe-a4b1-af2cbed3a566" satisfied condition "success or failure"
Jun 13 11:25:11.975: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-1f60205d-5866-46fe-a4b1-af2cbed3a566 container client-container: <nil>
STEP: delete the pod
Jun 13 11:25:12.160: INFO: Waiting for pod downwardapi-volume-1f60205d-5866-46fe-a4b1-af2cbed3a566 to disappear
Jun 13 11:25:12.164: INFO: Pod downwardapi-volume-1f60205d-5866-46fe-a4b1-af2cbed3a566 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:25:12.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7155" for this suite.
Jun 13 11:25:18.182: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:25:18.301: INFO: namespace downward-api-7155 deletion completed in 6.132894312s

• [SLOW TEST:8.396 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:25:18.301: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Jun 13 11:25:18.358: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f890cc2c-2664-4a38-98dc-71cad7a62c01" in namespace "downward-api-5150" to be "success or failure"
Jun 13 11:25:18.363: INFO: Pod "downwardapi-volume-f890cc2c-2664-4a38-98dc-71cad7a62c01": Phase="Pending", Reason="", readiness=false. Elapsed: 4.321676ms
Jun 13 11:25:20.367: INFO: Pod "downwardapi-volume-f890cc2c-2664-4a38-98dc-71cad7a62c01": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00859754s
Jun 13 11:25:22.372: INFO: Pod "downwardapi-volume-f890cc2c-2664-4a38-98dc-71cad7a62c01": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013305886s
STEP: Saw pod success
Jun 13 11:25:22.372: INFO: Pod "downwardapi-volume-f890cc2c-2664-4a38-98dc-71cad7a62c01" satisfied condition "success or failure"
Jun 13 11:25:22.376: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-f890cc2c-2664-4a38-98dc-71cad7a62c01 container client-container: <nil>
STEP: delete the pod
Jun 13 11:25:22.400: INFO: Waiting for pod downwardapi-volume-f890cc2c-2664-4a38-98dc-71cad7a62c01 to disappear
Jun 13 11:25:22.404: INFO: Pod downwardapi-volume-f890cc2c-2664-4a38-98dc-71cad7a62c01 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:25:22.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5150" for this suite.
Jun 13 11:25:28.427: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:25:28.828: INFO: namespace downward-api-5150 deletion completed in 6.418201533s

• [SLOW TEST:10.527 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:25:28.828: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Jun 13 11:25:28.867: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 cluster-info'
Jun 13 11:25:28.959: INFO: stderr: ""
Jun 13 11:25:28.959: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:25:28.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9920" for this suite.
Jun 13 11:25:34.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:25:35.108: INFO: namespace kubectl-9920 deletion completed in 6.142604245s

• [SLOW TEST:6.279 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:25:35.108: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-4f2e7764-f72f-4e68-a3c0-e6307838b38b
STEP: Creating a pod to test consume configMaps
Jun 13 11:25:35.180: INFO: Waiting up to 5m0s for pod "pod-configmaps-ac074a8c-2901-4476-9021-691642c926f0" in namespace "configmap-9595" to be "success or failure"
Jun 13 11:25:35.185: INFO: Pod "pod-configmaps-ac074a8c-2901-4476-9021-691642c926f0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.912296ms
Jun 13 11:25:37.190: INFO: Pod "pod-configmaps-ac074a8c-2901-4476-9021-691642c926f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009278414s
Jun 13 11:25:39.195: INFO: Pod "pod-configmaps-ac074a8c-2901-4476-9021-691642c926f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014734522s
STEP: Saw pod success
Jun 13 11:25:39.195: INFO: Pod "pod-configmaps-ac074a8c-2901-4476-9021-691642c926f0" satisfied condition "success or failure"
Jun 13 11:25:39.199: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-ac074a8c-2901-4476-9021-691642c926f0 container configmap-volume-test: <nil>
STEP: delete the pod
Jun 13 11:25:39.225: INFO: Waiting for pod pod-configmaps-ac074a8c-2901-4476-9021-691642c926f0 to disappear
Jun 13 11:25:39.229: INFO: Pod pod-configmaps-ac074a8c-2901-4476-9021-691642c926f0 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:25:39.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9595" for this suite.
Jun 13 11:25:45.249: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:25:45.383: INFO: namespace configmap-9595 deletion completed in 6.14959351s

• [SLOW TEST:10.275 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:25:45.385: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-8af24c7e-4b8a-4c76-9f33-6fc31a3d5455 in namespace container-probe-1682
Jun 13 11:25:49.454: INFO: Started pod busybox-8af24c7e-4b8a-4c76-9f33-6fc31a3d5455 in namespace container-probe-1682
STEP: checking the pod's current state and verifying that restartCount is present
Jun 13 11:25:49.458: INFO: Initial restart count of pod busybox-8af24c7e-4b8a-4c76-9f33-6fc31a3d5455 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:29:50.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1682" for this suite.
Jun 13 11:29:56.082: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:29:56.478: INFO: namespace container-probe-1682 deletion completed in 6.411692246s

• [SLOW TEST:251.093 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:29:56.479: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Jun 13 11:29:56.520: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-2740'
Jun 13 11:29:56.653: INFO: stderr: ""
Jun 13 11:29:56.653: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Jun 13 11:29:56.660: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 delete pods e2e-test-httpd-pod --namespace=kubectl-2740'
Jun 13 11:30:04.376: INFO: stderr: ""
Jun 13 11:30:04.376: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:30:04.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2740" for this suite.
Jun 13 11:30:10.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:30:10.523: INFO: namespace kubectl-2740 deletion completed in 6.139975101s

• [SLOW TEST:14.045 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:30:10.527: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Jun 13 11:30:13.273: INFO: Successfully updated pod "labelsupdate63f59bf6-5b84-4316-a57c-394765ba142d"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:30:15.346: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3584" for this suite.
Jun 13 11:30:27.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:30:27.502: INFO: namespace downward-api-3584 deletion completed in 12.151238408s

• [SLOW TEST:16.976 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:30:27.503: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:30:49.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7790" for this suite.
Jun 13 11:30:55.805: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:30:55.950: INFO: namespace container-runtime-7790 deletion completed in 6.160790807s

• [SLOW TEST:28.446 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:30:55.950: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Jun 13 11:30:55.992: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-257530218 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:30:56.065: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7014" for this suite.
Jun 13 11:31:02.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:31:02.211: INFO: namespace kubectl-7014 deletion completed in 6.140715637s

• [SLOW TEST:6.261 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:31:02.212: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:31:02.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3096" for this suite.
Jun 13 11:31:30.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:31:30.419: INFO: namespace pods-3096 deletion completed in 28.141041119s

• [SLOW TEST:28.207 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:31:30.420: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Jun 13 11:31:30.462: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:31:35.063: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5475" for this suite.
Jun 13 11:31:47.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:31:47.217: INFO: namespace init-container-5475 deletion completed in 12.149752141s

• [SLOW TEST:16.798 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:31:47.219: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Jun 13 11:31:47.263: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:32:05.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2189" for this suite.
Jun 13 11:32:11.220: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:32:11.346: INFO: namespace crd-publish-openapi-2189 deletion completed in 6.141712201s

• [SLOW TEST:24.127 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:32:11.346: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-7e591042-b56d-4eb3-a672-44d604895159
STEP: Creating a pod to test consume configMaps
Jun 13 11:32:11.412: INFO: Waiting up to 5m0s for pod "pod-configmaps-9c4c5ee9-b33d-4d0c-adf4-81293c9c836f" in namespace "configmap-5168" to be "success or failure"
Jun 13 11:32:11.417: INFO: Pod "pod-configmaps-9c4c5ee9-b33d-4d0c-adf4-81293c9c836f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.374458ms
Jun 13 11:32:13.422: INFO: Pod "pod-configmaps-9c4c5ee9-b33d-4d0c-adf4-81293c9c836f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009945086s
Jun 13 11:32:15.427: INFO: Pod "pod-configmaps-9c4c5ee9-b33d-4d0c-adf4-81293c9c836f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015140192s
STEP: Saw pod success
Jun 13 11:32:15.427: INFO: Pod "pod-configmaps-9c4c5ee9-b33d-4d0c-adf4-81293c9c836f" satisfied condition "success or failure"
Jun 13 11:32:15.431: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-9c4c5ee9-b33d-4d0c-adf4-81293c9c836f container configmap-volume-test: <nil>
STEP: delete the pod
Jun 13 11:32:15.565: INFO: Waiting for pod pod-configmaps-9c4c5ee9-b33d-4d0c-adf4-81293c9c836f to disappear
Jun 13 11:32:15.570: INFO: Pod pod-configmaps-9c4c5ee9-b33d-4d0c-adf4-81293c9c836f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:32:15.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5168" for this suite.
Jun 13 11:32:21.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:32:21.710: INFO: namespace configmap-5168 deletion completed in 6.135853202s

• [SLOW TEST:10.364 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:32:21.710: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Jun 13 11:32:21.750: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Jun 13 11:32:21.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 create -f - --namespace=kubectl-3388'
Jun 13 11:32:22.050: INFO: stderr: ""
Jun 13 11:32:22.050: INFO: stdout: "service/redis-slave created\n"
Jun 13 11:32:22.050: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Jun 13 11:32:22.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 create -f - --namespace=kubectl-3388'
Jun 13 11:32:22.364: INFO: stderr: ""
Jun 13 11:32:22.364: INFO: stdout: "service/redis-master created\n"
Jun 13 11:32:22.364: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Jun 13 11:32:22.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 create -f - --namespace=kubectl-3388'
Jun 13 11:32:22.692: INFO: stderr: ""
Jun 13 11:32:22.692: INFO: stdout: "service/frontend created\n"
Jun 13 11:32:22.692: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Jun 13 11:32:22.692: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 create -f - --namespace=kubectl-3388'
Jun 13 11:32:23.015: INFO: stderr: ""
Jun 13 11:32:23.015: INFO: stdout: "deployment.apps/frontend created\n"
Jun 13 11:32:23.016: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Jun 13 11:32:23.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 create -f - --namespace=kubectl-3388'
Jun 13 11:32:23.360: INFO: stderr: ""
Jun 13 11:32:23.360: INFO: stdout: "deployment.apps/redis-master created\n"
Jun 13 11:32:23.361: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Jun 13 11:32:23.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 create -f - --namespace=kubectl-3388'
Jun 13 11:32:23.664: INFO: stderr: ""
Jun 13 11:32:23.664: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Jun 13 11:32:23.664: INFO: Waiting for all frontend pods to be Running.
Jun 13 11:32:28.715: INFO: Waiting for frontend to serve content.
Jun 13 11:32:28.796: INFO: Trying to add a new entry to the guestbook.
Jun 13 11:32:28.846: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Jun 13 11:32:28.861: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 delete --grace-period=0 --force -f - --namespace=kubectl-3388'
Jun 13 11:32:29.070: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 13 11:32:29.070: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Jun 13 11:32:29.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 delete --grace-period=0 --force -f - --namespace=kubectl-3388'
Jun 13 11:32:29.221: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 13 11:32:29.221: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jun 13 11:32:29.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 delete --grace-period=0 --force -f - --namespace=kubectl-3388'
Jun 13 11:32:29.367: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 13 11:32:29.367: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jun 13 11:32:29.368: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 delete --grace-period=0 --force -f - --namespace=kubectl-3388'
Jun 13 11:32:29.542: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 13 11:32:29.542: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Jun 13 11:32:29.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 delete --grace-period=0 --force -f - --namespace=kubectl-3388'
Jun 13 11:32:29.632: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 13 11:32:29.632: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Jun 13 11:32:29.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 delete --grace-period=0 --force -f - --namespace=kubectl-3388'
Jun 13 11:32:29.725: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Jun 13 11:32:29.725: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:32:29.725: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3388" for this suite.
Jun 13 11:32:35.747: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:32:35.887: INFO: namespace kubectl-3388 deletion completed in 6.156043065s

• [SLOW TEST:14.178 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:32:35.891: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Jun 13 11:32:35.951: INFO: Waiting up to 5m0s for pod "downward-api-4c5f5416-97ff-44a3-a6e2-bfad4a5c07e4" in namespace "downward-api-1047" to be "success or failure"
Jun 13 11:32:35.956: INFO: Pod "downward-api-4c5f5416-97ff-44a3-a6e2-bfad4a5c07e4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.741216ms
Jun 13 11:32:37.961: INFO: Pod "downward-api-4c5f5416-97ff-44a3-a6e2-bfad4a5c07e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009439241s
Jun 13 11:32:40.156: INFO: Pod "downward-api-4c5f5416-97ff-44a3-a6e2-bfad4a5c07e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.204113228s
STEP: Saw pod success
Jun 13 11:32:40.156: INFO: Pod "downward-api-4c5f5416-97ff-44a3-a6e2-bfad4a5c07e4" satisfied condition "success or failure"
Jun 13 11:32:40.160: INFO: Trying to get logs from node 10.0.10.2 pod downward-api-4c5f5416-97ff-44a3-a6e2-bfad4a5c07e4 container dapi-container: <nil>
STEP: delete the pod
Jun 13 11:32:40.186: INFO: Waiting for pod downward-api-4c5f5416-97ff-44a3-a6e2-bfad4a5c07e4 to disappear
Jun 13 11:32:40.191: INFO: Pod downward-api-4c5f5416-97ff-44a3-a6e2-bfad4a5c07e4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:32:40.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1047" for this suite.
Jun 13 11:32:46.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:32:46.329: INFO: namespace downward-api-1047 deletion completed in 6.133121674s

• [SLOW TEST:10.438 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:32:46.331: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Jun 13 11:32:48.923: INFO: Successfully updated pod "annotationupdatee1bffe5e-8e7e-4a36-ada7-644d20d52659"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:32:53.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2525" for this suite.
Jun 13 11:33:05.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:33:05.229: INFO: namespace projected-2525 deletion completed in 12.164867198s

• [SLOW TEST:18.898 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:33:05.230: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:33:07.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-6737" for this suite.
Jun 13 11:33:13.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:33:13.533: INFO: namespace emptydir-wrapper-6737 deletion completed in 6.15702229s

• [SLOW TEST:8.304 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:33:13.533: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Jun 13 11:33:18.110: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3152 pod-service-account-3e898fd5-7e78-44f4-8400-31f9876d5a03 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Jun 13 11:33:18.502: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3152 pod-service-account-3e898fd5-7e78-44f4-8400-31f9876d5a03 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Jun 13 11:33:18.870: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3152 pod-service-account-3e898fd5-7e78-44f4-8400-31f9876d5a03 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:33:19.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3152" for this suite.
Jun 13 11:33:25.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:33:25.436: INFO: namespace svcaccounts-3152 deletion completed in 6.144772636s

• [SLOW TEST:11.903 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:33:25.443: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jun 13 11:33:25.500: INFO: Waiting up to 5m0s for pod "pod-7cc0795c-4434-4208-8cc8-846f0eb3b5a4" in namespace "emptydir-8503" to be "success or failure"
Jun 13 11:33:25.504: INFO: Pod "pod-7cc0795c-4434-4208-8cc8-846f0eb3b5a4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.154727ms
Jun 13 11:33:27.509: INFO: Pod "pod-7cc0795c-4434-4208-8cc8-846f0eb3b5a4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008804941s
Jun 13 11:33:29.513: INFO: Pod "pod-7cc0795c-4434-4208-8cc8-846f0eb3b5a4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013362835s
STEP: Saw pod success
Jun 13 11:33:29.513: INFO: Pod "pod-7cc0795c-4434-4208-8cc8-846f0eb3b5a4" satisfied condition "success or failure"
Jun 13 11:33:29.517: INFO: Trying to get logs from node 10.0.10.2 pod pod-7cc0795c-4434-4208-8cc8-846f0eb3b5a4 container test-container: <nil>
STEP: delete the pod
Jun 13 11:33:29.544: INFO: Waiting for pod pod-7cc0795c-4434-4208-8cc8-846f0eb3b5a4 to disappear
Jun 13 11:33:29.548: INFO: Pod pod-7cc0795c-4434-4208-8cc8-846f0eb3b5a4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:33:29.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8503" for this suite.
Jun 13 11:33:35.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:33:35.705: INFO: namespace emptydir-8503 deletion completed in 6.148850517s

• [SLOW TEST:10.262 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:33:35.706: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-7875
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Jun 13 11:33:35.743: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Jun 13 11:33:55.828: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.155:8080/dial?request=hostName&protocol=udp&host=10.244.0.127&port=8081&tries=1'] Namespace:pod-network-test-7875 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 13 11:33:55.828: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 11:33:56.075: INFO: Waiting for endpoints: map[]
Jun 13 11:33:56.079: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.1.155:8080/dial?request=hostName&protocol=udp&host=10.244.1.154&port=8081&tries=1'] Namespace:pod-network-test-7875 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Jun 13 11:33:56.079: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 11:33:56.389: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:33:56.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7875" for this suite.
Jun 13 11:34:08.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:34:08.536: INFO: namespace pod-network-test-7875 deletion completed in 12.141810931s

• [SLOW TEST:32.830 seconds]
[sig-network] Networking
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:34:08.538: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 11:34:08.604: INFO: Create a RollingUpdate DaemonSet
Jun 13 11:34:08.614: INFO: Check that daemon pods launch on every node of the cluster
Jun 13 11:34:08.622: INFO: Number of nodes with available pods: 0
Jun 13 11:34:08.622: INFO: Node 10.0.10.2 is running more than one daemon pod
Jun 13 11:34:09.637: INFO: Number of nodes with available pods: 0
Jun 13 11:34:09.637: INFO: Node 10.0.10.2 is running more than one daemon pod
Jun 13 11:34:10.631: INFO: Number of nodes with available pods: 1
Jun 13 11:34:10.631: INFO: Node 10.0.10.3 is running more than one daemon pod
Jun 13 11:34:11.632: INFO: Number of nodes with available pods: 2
Jun 13 11:34:11.632: INFO: Number of running nodes: 2, number of available pods: 2
Jun 13 11:34:11.632: INFO: Update the DaemonSet to trigger a rollout
Jun 13 11:34:11.645: INFO: Updating DaemonSet daemon-set
Jun 13 11:34:24.664: INFO: Roll back the DaemonSet before rollout is complete
Jun 13 11:34:24.674: INFO: Updating DaemonSet daemon-set
Jun 13 11:34:24.674: INFO: Make sure DaemonSet rollback is complete
Jun 13 11:34:24.678: INFO: Wrong image for pod: daemon-set-x6z4f. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Jun 13 11:34:24.678: INFO: Pod daemon-set-x6z4f is not available
Jun 13 11:34:25.687: INFO: Wrong image for pod: daemon-set-x6z4f. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Jun 13 11:34:25.687: INFO: Pod daemon-set-x6z4f is not available
Jun 13 11:34:26.688: INFO: Wrong image for pod: daemon-set-x6z4f. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Jun 13 11:34:26.688: INFO: Pod daemon-set-x6z4f is not available
Jun 13 11:34:27.687: INFO: Pod daemon-set-7nc5x is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7227, will wait for the garbage collector to delete the pods
Jun 13 11:34:27.775: INFO: Deleting DaemonSet.extensions daemon-set took: 11.693318ms
Jun 13 11:34:28.075: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.244283ms
Jun 13 11:34:34.380: INFO: Number of nodes with available pods: 0
Jun 13 11:34:34.380: INFO: Number of running nodes: 0, number of available pods: 0
Jun 13 11:34:34.384: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7227/daemonsets","resourceVersion":"115959"},"items":null}

Jun 13 11:34:34.387: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7227/pods","resourceVersion":"115959"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:34:34.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7227" for this suite.
Jun 13 11:34:40.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:34:40.800: INFO: namespace daemonsets-7227 deletion completed in 6.39607172s

• [SLOW TEST:32.262 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:34:40.800: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-721d5d9a-e6fb-4719-b614-c996523b1e8d
STEP: Creating a pod to test consume configMaps
Jun 13 11:34:40.862: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-38b273e0-95f2-48a2-8770-8e4d93b54519" in namespace "projected-4699" to be "success or failure"
Jun 13 11:34:40.867: INFO: Pod "pod-projected-configmaps-38b273e0-95f2-48a2-8770-8e4d93b54519": Phase="Pending", Reason="", readiness=false. Elapsed: 4.717095ms
Jun 13 11:34:42.872: INFO: Pod "pod-projected-configmaps-38b273e0-95f2-48a2-8770-8e4d93b54519": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009879397s
STEP: Saw pod success
Jun 13 11:34:42.872: INFO: Pod "pod-projected-configmaps-38b273e0-95f2-48a2-8770-8e4d93b54519" satisfied condition "success or failure"
Jun 13 11:34:42.876: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-configmaps-38b273e0-95f2-48a2-8770-8e4d93b54519 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 13 11:34:42.959: INFO: Waiting for pod pod-projected-configmaps-38b273e0-95f2-48a2-8770-8e4d93b54519 to disappear
Jun 13 11:34:42.964: INFO: Pod pod-projected-configmaps-38b273e0-95f2-48a2-8770-8e4d93b54519 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:34:42.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4699" for this suite.
Jun 13 11:34:48.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:34:49.111: INFO: namespace projected-4699 deletion completed in 6.140903189s

• [SLOW TEST:8.311 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:34:49.114: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Jun 13 11:34:49.154: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-5587'
Jun 13 11:34:49.258: INFO: stderr: ""
Jun 13 11:34:49.258: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Jun 13 11:34:54.309: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 get pod e2e-test-httpd-pod --namespace=kubectl-5587 -o json'
Jun 13 11:34:54.396: INFO: stderr: ""
Jun 13 11:34:54.396: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2020-06-13T11:34:49Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-5587\",\n        \"resourceVersion\": \"116074\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-5587/pods/e2e-test-httpd-pod\",\n        \"uid\": \"1e24fe0d-daf9-459f-8578-38e40e7cea7a\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-4nt6g\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.0.10.2\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-4nt6g\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-4nt6g\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-06-13T11:34:49Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-06-13T11:34:51Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-06-13T11:34:51Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-06-13T11:34:49Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://3b63bcd1e187e0b107ca6eff81b3fee89e50c7945dce01aba178405a28f7d378\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-06-13T11:34:50Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.10.2\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.1.160\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.244.1.160\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-06-13T11:34:49Z\"\n    }\n}\n"
STEP: replace the image in the pod
Jun 13 11:34:54.396: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 replace -f - --namespace=kubectl-5587'
Jun 13 11:34:54.657: INFO: stderr: ""
Jun 13 11:34:54.657: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Jun 13 11:34:54.661: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 delete pods e2e-test-httpd-pod --namespace=kubectl-5587'
Jun 13 11:34:56.668: INFO: stderr: ""
Jun 13 11:34:56.668: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:34:56.668: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5587" for this suite.
Jun 13 11:35:02.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:35:03.072: INFO: namespace kubectl-5587 deletion completed in 6.39827609s

• [SLOW TEST:13.958 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:35:03.072: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-bab4564a-0069-40b3-ad5c-5abde4dedc26
STEP: Creating a pod to test consume secrets
Jun 13 11:35:03.136: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-462b27f1-fc11-4bd6-b782-681332a7ba55" in namespace "projected-334" to be "success or failure"
Jun 13 11:35:03.141: INFO: Pod "pod-projected-secrets-462b27f1-fc11-4bd6-b782-681332a7ba55": Phase="Pending", Reason="", readiness=false. Elapsed: 4.826875ms
Jun 13 11:35:05.146: INFO: Pod "pod-projected-secrets-462b27f1-fc11-4bd6-b782-681332a7ba55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009984348s
STEP: Saw pod success
Jun 13 11:35:05.146: INFO: Pod "pod-projected-secrets-462b27f1-fc11-4bd6-b782-681332a7ba55" satisfied condition "success or failure"
Jun 13 11:35:05.150: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-secrets-462b27f1-fc11-4bd6-b782-681332a7ba55 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 13 11:35:05.175: INFO: Waiting for pod pod-projected-secrets-462b27f1-fc11-4bd6-b782-681332a7ba55 to disappear
Jun 13 11:35:05.180: INFO: Pod pod-projected-secrets-462b27f1-fc11-4bd6-b782-681332a7ba55 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:35:05.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-334" for this suite.
Jun 13 11:35:11.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:35:11.325: INFO: namespace projected-334 deletion completed in 6.138949806s

• [SLOW TEST:8.253 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:35:11.336: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Jun 13 11:35:11.390: INFO: Waiting up to 5m0s for pod "pod-eb1fba62-f560-4c10-9310-38cdb9e03230" in namespace "emptydir-2790" to be "success or failure"
Jun 13 11:35:11.395: INFO: Pod "pod-eb1fba62-f560-4c10-9310-38cdb9e03230": Phase="Pending", Reason="", readiness=false. Elapsed: 4.112952ms
Jun 13 11:35:13.399: INFO: Pod "pod-eb1fba62-f560-4c10-9310-38cdb9e03230": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008866286s
STEP: Saw pod success
Jun 13 11:35:13.399: INFO: Pod "pod-eb1fba62-f560-4c10-9310-38cdb9e03230" satisfied condition "success or failure"
Jun 13 11:35:13.403: INFO: Trying to get logs from node 10.0.10.2 pod pod-eb1fba62-f560-4c10-9310-38cdb9e03230 container test-container: <nil>
STEP: delete the pod
Jun 13 11:35:13.430: INFO: Waiting for pod pod-eb1fba62-f560-4c10-9310-38cdb9e03230 to disappear
Jun 13 11:35:13.434: INFO: Pod pod-eb1fba62-f560-4c10-9310-38cdb9e03230 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:35:13.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2790" for this suite.
Jun 13 11:35:19.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:35:19.576: INFO: namespace emptydir-2790 deletion completed in 6.137924518s

• [SLOW TEST:8.241 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:35:19.577: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 13 11:35:20.279: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 13 11:35:23.305: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:35:23.531: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1716" for this suite.
Jun 13 11:35:29.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:35:29.682: INFO: namespace webhook-1716 deletion completed in 6.146599574s
STEP: Destroying namespace "webhook-1716-markers" for this suite.
Jun 13 11:35:35.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:35:35.827: INFO: namespace webhook-1716-markers deletion completed in 6.145002756s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.274 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:35:35.851: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-37230e58-121a-4f9c-b810-b4f2278f3b53
STEP: Creating a pod to test consume secrets
Jun 13 11:35:35.916: INFO: Waiting up to 5m0s for pod "pod-secrets-0e6cb7ca-0368-4ad5-8a25-f7c007ff0f79" in namespace "secrets-4570" to be "success or failure"
Jun 13 11:35:35.921: INFO: Pod "pod-secrets-0e6cb7ca-0368-4ad5-8a25-f7c007ff0f79": Phase="Pending", Reason="", readiness=false. Elapsed: 4.791745ms
Jun 13 11:35:37.926: INFO: Pod "pod-secrets-0e6cb7ca-0368-4ad5-8a25-f7c007ff0f79": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009685901s
STEP: Saw pod success
Jun 13 11:35:37.926: INFO: Pod "pod-secrets-0e6cb7ca-0368-4ad5-8a25-f7c007ff0f79" satisfied condition "success or failure"
Jun 13 11:35:37.930: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-0e6cb7ca-0368-4ad5-8a25-f7c007ff0f79 container secret-volume-test: <nil>
STEP: delete the pod
Jun 13 11:35:37.957: INFO: Waiting for pod pod-secrets-0e6cb7ca-0368-4ad5-8a25-f7c007ff0f79 to disappear
Jun 13 11:35:37.962: INFO: Pod pod-secrets-0e6cb7ca-0368-4ad5-8a25-f7c007ff0f79 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:35:37.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4570" for this suite.
Jun 13 11:35:43.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:35:44.117: INFO: namespace secrets-4570 deletion completed in 6.149616501s

• [SLOW TEST:8.266 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:35:44.117: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
Jun 13 11:35:45.214: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0613 11:35:45.214657      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:35:45.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5573" for this suite.
Jun 13 11:35:51.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:35:51.369: INFO: namespace gc-5573 deletion completed in 6.149928213s

• [SLOW TEST:7.251 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:35:51.371: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Jun 13 11:35:51.427: INFO: Waiting up to 5m0s for pod "downwardapi-volume-355cc906-c273-432c-87d5-6b87fdfe081d" in namespace "downward-api-1238" to be "success or failure"
Jun 13 11:35:51.431: INFO: Pod "downwardapi-volume-355cc906-c273-432c-87d5-6b87fdfe081d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.179287ms
Jun 13 11:35:53.436: INFO: Pod "downwardapi-volume-355cc906-c273-432c-87d5-6b87fdfe081d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008820906s
Jun 13 11:35:55.441: INFO: Pod "downwardapi-volume-355cc906-c273-432c-87d5-6b87fdfe081d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013428819s
STEP: Saw pod success
Jun 13 11:35:55.441: INFO: Pod "downwardapi-volume-355cc906-c273-432c-87d5-6b87fdfe081d" satisfied condition "success or failure"
Jun 13 11:35:55.445: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-355cc906-c273-432c-87d5-6b87fdfe081d container client-container: <nil>
STEP: delete the pod
Jun 13 11:35:55.470: INFO: Waiting for pod downwardapi-volume-355cc906-c273-432c-87d5-6b87fdfe081d to disappear
Jun 13 11:35:55.474: INFO: Pod downwardapi-volume-355cc906-c273-432c-87d5-6b87fdfe081d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:35:55.474: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1238" for this suite.
Jun 13 11:36:01.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:36:01.629: INFO: namespace downward-api-1238 deletion completed in 6.150670325s

• [SLOW TEST:10.258 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:36:01.634: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-07004f26-240c-4e8b-a611-46c2f85f13c9
STEP: Creating a pod to test consume configMaps
Jun 13 11:36:01.699: INFO: Waiting up to 5m0s for pod "pod-configmaps-3691481b-fc8e-41f8-8501-4dca2ed46d36" in namespace "configmap-8062" to be "success or failure"
Jun 13 11:36:01.703: INFO: Pod "pod-configmaps-3691481b-fc8e-41f8-8501-4dca2ed46d36": Phase="Pending", Reason="", readiness=false. Elapsed: 4.042752ms
Jun 13 11:36:03.708: INFO: Pod "pod-configmaps-3691481b-fc8e-41f8-8501-4dca2ed46d36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009096908s
STEP: Saw pod success
Jun 13 11:36:03.708: INFO: Pod "pod-configmaps-3691481b-fc8e-41f8-8501-4dca2ed46d36" satisfied condition "success or failure"
Jun 13 11:36:03.712: INFO: Trying to get logs from node 10.0.10.2 pod pod-configmaps-3691481b-fc8e-41f8-8501-4dca2ed46d36 container configmap-volume-test: <nil>
STEP: delete the pod
Jun 13 11:36:03.738: INFO: Waiting for pod pod-configmaps-3691481b-fc8e-41f8-8501-4dca2ed46d36 to disappear
Jun 13 11:36:03.743: INFO: Pod pod-configmaps-3691481b-fc8e-41f8-8501-4dca2ed46d36 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:36:03.743: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8062" for this suite.
Jun 13 11:36:09.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:36:09.889: INFO: namespace configmap-8062 deletion completed in 6.14121067s

• [SLOW TEST:8.255 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:36:09.889: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Jun 13 11:36:09.945: INFO: Waiting up to 5m0s for pod "pod-824698df-c8a1-4ed5-95e5-a2f6bc0fc2cf" in namespace "emptydir-3548" to be "success or failure"
Jun 13 11:36:09.949: INFO: Pod "pod-824698df-c8a1-4ed5-95e5-a2f6bc0fc2cf": Phase="Pending", Reason="", readiness=false. Elapsed: 3.860556ms
Jun 13 11:36:11.954: INFO: Pod "pod-824698df-c8a1-4ed5-95e5-a2f6bc0fc2cf": Phase="Running", Reason="", readiness=true. Elapsed: 2.008332968s
Jun 13 11:36:13.958: INFO: Pod "pod-824698df-c8a1-4ed5-95e5-a2f6bc0fc2cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012849931s
STEP: Saw pod success
Jun 13 11:36:13.958: INFO: Pod "pod-824698df-c8a1-4ed5-95e5-a2f6bc0fc2cf" satisfied condition "success or failure"
Jun 13 11:36:13.962: INFO: Trying to get logs from node 10.0.10.2 pod pod-824698df-c8a1-4ed5-95e5-a2f6bc0fc2cf container test-container: <nil>
STEP: delete the pod
Jun 13 11:36:13.986: INFO: Waiting for pod pod-824698df-c8a1-4ed5-95e5-a2f6bc0fc2cf to disappear
Jun 13 11:36:13.990: INFO: Pod pod-824698df-c8a1-4ed5-95e5-a2f6bc0fc2cf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:36:13.990: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3548" for this suite.
Jun 13 11:36:20.009: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:36:20.133: INFO: namespace emptydir-3548 deletion completed in 6.139204839s

• [SLOW TEST:10.245 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:36:20.134: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Jun 13 11:36:24.722: INFO: Successfully updated pod "pod-update-activedeadlineseconds-2a8572f7-affb-44a3-abfa-c4570a5ade09"
Jun 13 11:36:24.722: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-2a8572f7-affb-44a3-abfa-c4570a5ade09" in namespace "pods-5336" to be "terminated due to deadline exceeded"
Jun 13 11:36:24.727: INFO: Pod "pod-update-activedeadlineseconds-2a8572f7-affb-44a3-abfa-c4570a5ade09": Phase="Running", Reason="", readiness=true. Elapsed: 4.207198ms
Jun 13 11:36:26.731: INFO: Pod "pod-update-activedeadlineseconds-2a8572f7-affb-44a3-abfa-c4570a5ade09": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.00885349s
Jun 13 11:36:26.731: INFO: Pod "pod-update-activedeadlineseconds-2a8572f7-affb-44a3-abfa-c4570a5ade09" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:36:26.731: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5336" for this suite.
Jun 13 11:36:32.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:36:32.872: INFO: namespace pods-5336 deletion completed in 6.136602005s

• [SLOW TEST:12.739 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:36:32.873: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Jun 13 11:36:32.929: INFO: Waiting up to 5m0s for pod "downwardapi-volume-fbe932b6-cb1b-4a2d-8374-38943c2945bb" in namespace "downward-api-7594" to be "success or failure"
Jun 13 11:36:32.934: INFO: Pod "downwardapi-volume-fbe932b6-cb1b-4a2d-8374-38943c2945bb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.56752ms
Jun 13 11:36:34.943: INFO: Pod "downwardapi-volume-fbe932b6-cb1b-4a2d-8374-38943c2945bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.013950998s
STEP: Saw pod success
Jun 13 11:36:34.943: INFO: Pod "downwardapi-volume-fbe932b6-cb1b-4a2d-8374-38943c2945bb" satisfied condition "success or failure"
Jun 13 11:36:34.948: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-fbe932b6-cb1b-4a2d-8374-38943c2945bb container client-container: <nil>
STEP: delete the pod
Jun 13 11:36:34.982: INFO: Waiting for pod downwardapi-volume-fbe932b6-cb1b-4a2d-8374-38943c2945bb to disappear
Jun 13 11:36:34.987: INFO: Pod downwardapi-volume-fbe932b6-cb1b-4a2d-8374-38943c2945bb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:36:34.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7594" for this suite.
Jun 13 11:36:41.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:36:41.133: INFO: namespace downward-api-7594 deletion completed in 6.141246367s

• [SLOW TEST:8.260 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:36:41.133: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Jun 13 11:36:42.103: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Jun 13 11:36:44.114: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727645002, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727645002, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727645002, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727645002, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Jun 13 11:36:47.133: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:36:47.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5303" for this suite.
Jun 13 11:36:59.314: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:36:59.454: INFO: namespace webhook-5303 deletion completed in 12.154352503s
STEP: Destroying namespace "webhook-5303-markers" for this suite.
Jun 13 11:37:05.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:37:05.619: INFO: namespace webhook-5303-markers deletion completed in 6.164264747s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.506 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:37:05.640: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-7c7d3560-8876-440f-8147-ea53e60bc460 in namespace container-probe-6713
Jun 13 11:37:07.707: INFO: Started pod test-webserver-7c7d3560-8876-440f-8147-ea53e60bc460 in namespace container-probe-6713
STEP: checking the pod's current state and verifying that restartCount is present
Jun 13 11:37:07.711: INFO: Initial restart count of pod test-webserver-7c7d3560-8876-440f-8147-ea53e60bc460 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:41:08.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6713" for this suite.
Jun 13 11:41:14.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:41:14.756: INFO: namespace container-probe-6713 deletion completed in 6.438090541s

• [SLOW TEST:249.117 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:41:14.757: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8310.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-8310.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8310.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8310.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8310.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-8310.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8310.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-8310.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8310.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8310.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-8310.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8310.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-8310.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8310.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-8310.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8310.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-8310.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8310.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Jun 13 11:41:18.915: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8310.svc.cluster.local from pod dns-8310/dns-test-11c0a635-5918-4816-aef3-46e9fa5da4f7: the server could not find the requested resource (get pods dns-test-11c0a635-5918-4816-aef3-46e9fa5da4f7)
Jun 13 11:41:18.947: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8310.svc.cluster.local from pod dns-8310/dns-test-11c0a635-5918-4816-aef3-46e9fa5da4f7: the server could not find the requested resource (get pods dns-test-11c0a635-5918-4816-aef3-46e9fa5da4f7)
Jun 13 11:41:18.952: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8310.svc.cluster.local from pod dns-8310/dns-test-11c0a635-5918-4816-aef3-46e9fa5da4f7: the server could not find the requested resource (get pods dns-test-11c0a635-5918-4816-aef3-46e9fa5da4f7)
Jun 13 11:41:18.958: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8310.svc.cluster.local from pod dns-8310/dns-test-11c0a635-5918-4816-aef3-46e9fa5da4f7: the server could not find the requested resource (get pods dns-test-11c0a635-5918-4816-aef3-46e9fa5da4f7)
Jun 13 11:41:18.974: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8310.svc.cluster.local from pod dns-8310/dns-test-11c0a635-5918-4816-aef3-46e9fa5da4f7: the server could not find the requested resource (get pods dns-test-11c0a635-5918-4816-aef3-46e9fa5da4f7)
Jun 13 11:41:18.979: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8310.svc.cluster.local from pod dns-8310/dns-test-11c0a635-5918-4816-aef3-46e9fa5da4f7: the server could not find the requested resource (get pods dns-test-11c0a635-5918-4816-aef3-46e9fa5da4f7)
Jun 13 11:41:18.984: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8310.svc.cluster.local from pod dns-8310/dns-test-11c0a635-5918-4816-aef3-46e9fa5da4f7: the server could not find the requested resource (get pods dns-test-11c0a635-5918-4816-aef3-46e9fa5da4f7)
Jun 13 11:41:18.989: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8310.svc.cluster.local from pod dns-8310/dns-test-11c0a635-5918-4816-aef3-46e9fa5da4f7: the server could not find the requested resource (get pods dns-test-11c0a635-5918-4816-aef3-46e9fa5da4f7)
Jun 13 11:41:19.000: INFO: Lookups using dns-8310/dns-test-11c0a635-5918-4816-aef3-46e9fa5da4f7 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8310.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8310.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8310.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8310.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8310.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8310.svc.cluster.local jessie_udp@dns-test-service-2.dns-8310.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8310.svc.cluster.local]

Jun 13 11:41:24.094: INFO: DNS probes using dns-8310/dns-test-11c0a635-5918-4816-aef3-46e9fa5da4f7 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:41:24.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8310" for this suite.
Jun 13 11:41:30.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:41:30.276: INFO: namespace dns-8310 deletion completed in 6.14107318s

• [SLOW TEST:15.519 seconds]
[sig-network] DNS
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:41:30.276: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Jun 13 11:41:32.360: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec pod-sharedvolume-56dec865-ef05-446e-a854-a8a80e264b8c -c busybox-main-container --namespace=emptydir-6064 -- cat /usr/share/volumeshare/shareddata.txt'
Jun 13 11:41:32.678: INFO: stderr: ""
Jun 13 11:41:32.678: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:41:32.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6064" for this suite.
Jun 13 11:41:38.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:41:38.820: INFO: namespace emptydir-6064 deletion completed in 6.137056653s

• [SLOW TEST:8.543 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:41:38.820: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Jun 13 11:41:38.859: INFO: PodSpec: initContainers in spec.initContainers
Jun 13 11:42:24.353: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-3312307c-c11e-48f2-a9d9-2b9667491e39", GenerateName:"", Namespace:"init-container-8978", SelfLink:"/api/v1/namespaces/init-container-8978/pods/pod-init-3312307c-c11e-48f2-a9d9-2b9667491e39", UID:"12a99a0c-2a87-4eb2-b9c1-f5f8dcc60099", ResourceVersion:"117944", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63727645298, loc:(*time.Location)(0x789e8e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"858978802"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-gpvvx", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0029ea000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gpvvx", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gpvvx", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gpvvx", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc004844088), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.0.10.2", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0027a6720), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004844110)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc004844130)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc004844138), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00484413c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727645298, loc:(*time.Location)(0x789e8e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727645298, loc:(*time.Location)(0x789e8e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727645298, loc:(*time.Location)(0x789e8e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727645298, loc:(*time.Location)(0x789e8e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.10.2", PodIP:"10.244.1.177", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.244.1.177"}}, StartTime:(*v1.Time)(0xc00270e100), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00065a070)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc00065a1c0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://c60547b78eda3b3eab67bee26305ddfe77c043b63b313b0c41a6e1cb77f43741", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00270e160), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00270e120), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0048441bf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:42:24.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8978" for this suite.
Jun 13 11:42:36.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:42:36.501: INFO: namespace init-container-8978 deletion completed in 12.141181066s

• [SLOW TEST:57.681 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:42:36.501: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-32faecfa-772b-4eda-ba5b-ce9a0fb4a2c9
STEP: Creating a pod to test consume secrets
Jun 13 11:42:36.611: INFO: Waiting up to 5m0s for pod "pod-secrets-069d6511-8fa4-49b7-8f15-11ab86e45955" in namespace "secrets-5196" to be "success or failure"
Jun 13 11:42:36.615: INFO: Pod "pod-secrets-069d6511-8fa4-49b7-8f15-11ab86e45955": Phase="Pending", Reason="", readiness=false. Elapsed: 4.468471ms
Jun 13 11:42:38.620: INFO: Pod "pod-secrets-069d6511-8fa4-49b7-8f15-11ab86e45955": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008713436s
STEP: Saw pod success
Jun 13 11:42:38.620: INFO: Pod "pod-secrets-069d6511-8fa4-49b7-8f15-11ab86e45955" satisfied condition "success or failure"
Jun 13 11:42:38.623: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-069d6511-8fa4-49b7-8f15-11ab86e45955 container secret-volume-test: <nil>
STEP: delete the pod
Jun 13 11:42:38.775: INFO: Waiting for pod pod-secrets-069d6511-8fa4-49b7-8f15-11ab86e45955 to disappear
Jun 13 11:42:38.779: INFO: Pod pod-secrets-069d6511-8fa4-49b7-8f15-11ab86e45955 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:42:38.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5196" for this suite.
Jun 13 11:42:44.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:42:44.922: INFO: namespace secrets-5196 deletion completed in 6.138089284s
STEP: Destroying namespace "secret-namespace-142" for this suite.
Jun 13 11:42:50.936: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:42:51.059: INFO: namespace secret-namespace-142 deletion completed in 6.13688859s

• [SLOW TEST:14.558 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:42:51.060: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3899
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Jun 13 11:42:51.122: INFO: Found 0 stateful pods, waiting for 3
Jun 13 11:43:01.128: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 13 11:43:01.128: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 13 11:43:01.128: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Jun 13 11:43:01.141: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-3899 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jun 13 11:43:01.660: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jun 13 11:43:01.660: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jun 13 11:43:01.660: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Jun 13 11:43:11.701: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Jun 13 11:43:21.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-3899 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 11:43:22.073: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jun 13 11:43:22.073: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jun 13 11:43:22.073: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Jun 13 11:43:32.101: INFO: Waiting for StatefulSet statefulset-3899/ss2 to complete update
Jun 13 11:43:32.101: INFO: Waiting for Pod statefulset-3899/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Jun 13 11:43:32.101: INFO: Waiting for Pod statefulset-3899/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Jun 13 11:43:32.101: INFO: Waiting for Pod statefulset-3899/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Jun 13 11:43:42.111: INFO: Waiting for StatefulSet statefulset-3899/ss2 to complete update
Jun 13 11:43:42.111: INFO: Waiting for Pod statefulset-3899/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Jun 13 11:43:42.111: INFO: Waiting for Pod statefulset-3899/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Jun 13 11:43:52.112: INFO: Waiting for StatefulSet statefulset-3899/ss2 to complete update
Jun 13 11:43:52.112: INFO: Waiting for Pod statefulset-3899/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Jun 13 11:44:02.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-3899 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Jun 13 11:44:02.478: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Jun 13 11:44:02.478: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Jun 13 11:44:02.478: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Jun 13 11:44:12.523: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Jun 13 11:44:22.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 exec --namespace=statefulset-3899 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Jun 13 11:44:22.882: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Jun 13 11:44:22.882: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Jun 13 11:44:22.882: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Jun 13 11:44:42.908: INFO: Deleting all statefulset in ns statefulset-3899
Jun 13 11:44:42.913: INFO: Scaling statefulset ss2 to 0
Jun 13 11:45:22.931: INFO: Waiting for statefulset status.replicas updated to 0
Jun 13 11:45:22.936: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:45:22.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3899" for this suite.
Jun 13 11:45:28.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:45:29.111: INFO: namespace statefulset-3899 deletion completed in 6.151116058s

• [SLOW TEST:158.051 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:45:29.111: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 11:45:29.152: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:45:30.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6971" for this suite.
Jun 13 11:45:36.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:45:36.344: INFO: namespace custom-resource-definition-6971 deletion completed in 6.153332672s

• [SLOW TEST:7.233 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:45:36.345: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-189fb322-c0e7-462c-b5f2-bbfa2071f39a
STEP: Creating a pod to test consume secrets
Jun 13 11:45:36.411: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-93e73d97-8def-4604-8157-ac6329dc9f51" in namespace "projected-3951" to be "success or failure"
Jun 13 11:45:36.416: INFO: Pod "pod-projected-secrets-93e73d97-8def-4604-8157-ac6329dc9f51": Phase="Pending", Reason="", readiness=false. Elapsed: 4.751748ms
Jun 13 11:45:38.420: INFO: Pod "pod-projected-secrets-93e73d97-8def-4604-8157-ac6329dc9f51": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009128005s
STEP: Saw pod success
Jun 13 11:45:38.420: INFO: Pod "pod-projected-secrets-93e73d97-8def-4604-8157-ac6329dc9f51" satisfied condition "success or failure"
Jun 13 11:45:38.424: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-secrets-93e73d97-8def-4604-8157-ac6329dc9f51 container projected-secret-volume-test: <nil>
STEP: delete the pod
Jun 13 11:45:38.571: INFO: Waiting for pod pod-projected-secrets-93e73d97-8def-4604-8157-ac6329dc9f51 to disappear
Jun 13 11:45:38.576: INFO: Pod pod-projected-secrets-93e73d97-8def-4604-8157-ac6329dc9f51 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:45:38.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3951" for this suite.
Jun 13 11:45:44.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:45:44.724: INFO: namespace projected-3951 deletion completed in 6.143357099s

• [SLOW TEST:8.379 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:45:44.725: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Jun 13 11:45:44.768: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Jun 13 11:45:45.577: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Jun 13 11:45:48.666: INFO: Waited 1.031226702s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:45:49.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-8161" for this suite.
Jun 13 11:45:55.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:45:55.468: INFO: namespace aggregator-8161 deletion completed in 6.236378648s

• [SLOW TEST:10.743 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:45:55.472: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Jun 13 11:46:05.609: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:46:05.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0613 11:46:05.609278      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-273" for this suite.
Jun 13 11:46:11.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:46:11.753: INFO: namespace gc-273 deletion completed in 6.139883759s

• [SLOW TEST:16.282 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:46:11.754: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Jun 13 11:46:11.797: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-1528'
Jun 13 11:46:11.901: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Jun 13 11:46:11.901: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Jun 13 11:46:13.913: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 delete deployment e2e-test-httpd-deployment --namespace=kubectl-1528'
Jun 13 11:46:14.016: INFO: stderr: ""
Jun 13 11:46:14.016: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:46:14.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1528" for this suite.
Jun 13 11:47:42.044: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:47:42.476: INFO: namespace kubectl-1528 deletion completed in 1m28.447629261s

• [SLOW TEST:90.722 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:47:42.477: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1329
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Jun 13 11:47:42.550: INFO: Found 0 stateful pods, waiting for 3
Jun 13 11:47:52.556: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 13 11:47:52.556: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 13 11:47:52.556: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Jun 13 11:47:52.594: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Jun 13 11:48:02.632: INFO: Updating stateful set ss2
Jun 13 11:48:02.641: INFO: Waiting for Pod statefulset-1329/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Jun 13 11:48:12.651: INFO: Waiting for Pod statefulset-1329/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Jun 13 11:48:22.688: INFO: Found 2 stateful pods, waiting for 3
Jun 13 11:48:32.695: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Jun 13 11:48:32.695: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Jun 13 11:48:32.695: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Jun 13 11:48:32.724: INFO: Updating stateful set ss2
Jun 13 11:48:32.732: INFO: Waiting for Pod statefulset-1329/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Jun 13 11:48:42.742: INFO: Waiting for Pod statefulset-1329/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Jun 13 11:48:52.765: INFO: Updating stateful set ss2
Jun 13 11:48:52.774: INFO: Waiting for StatefulSet statefulset-1329/ss2 to complete update
Jun 13 11:48:52.774: INFO: Waiting for Pod statefulset-1329/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Jun 13 11:49:02.784: INFO: Deleting all statefulset in ns statefulset-1329
Jun 13 11:49:02.789: INFO: Scaling statefulset ss2 to 0
Jun 13 11:49:42.808: INFO: Waiting for statefulset status.replicas updated to 0
Jun 13 11:49:42.813: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:49:42.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1329" for this suite.
Jun 13 11:49:48.852: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:49:48.976: INFO: namespace statefulset-1329 deletion completed in 6.139567895s

• [SLOW TEST:126.499 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:49:48.976: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 11:49:49.151: INFO: (0) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 129.701032ms)
Jun 13 11:49:49.157: INFO: (1) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.378195ms)
Jun 13 11:49:49.163: INFO: (2) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.892128ms)
Jun 13 11:49:49.169: INFO: (3) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.522474ms)
Jun 13 11:49:49.175: INFO: (4) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.90472ms)
Jun 13 11:49:49.180: INFO: (5) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.766677ms)
Jun 13 11:49:49.186: INFO: (6) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.819702ms)
Jun 13 11:49:49.192: INFO: (7) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.895932ms)
Jun 13 11:49:49.198: INFO: (8) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.541752ms)
Jun 13 11:49:49.204: INFO: (9) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.689128ms)
Jun 13 11:49:49.209: INFO: (10) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.760972ms)
Jun 13 11:49:49.215: INFO: (11) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.743694ms)
Jun 13 11:49:49.221: INFO: (12) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.631204ms)
Jun 13 11:49:49.226: INFO: (13) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.292311ms)
Jun 13 11:49:49.231: INFO: (14) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.207074ms)
Jun 13 11:49:49.237: INFO: (15) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.24843ms)
Jun 13 11:49:49.246: INFO: (16) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 8.879882ms)
Jun 13 11:49:49.251: INFO: (17) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.663547ms)
Jun 13 11:49:49.257: INFO: (18) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 5.356999ms)
Jun 13 11:49:49.263: INFO: (19) /api/v1/nodes/10.0.10.2:10250/proxy/logs/: <pre>
<a href="audit/">audit/</a>
<a href="boot.log">boot.log</a>
<a href="btmp">btmp</a>
<a href... (200; 6.13779ms)
[AfterEach] version v1
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:49:49.263: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8111" for this suite.
Jun 13 11:49:55.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:49:55.403: INFO: namespace proxy-8111 deletion completed in 6.135112731s

• [SLOW TEST:6.426 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:49:55.403: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-f799ed1e-e1ac-451a-861c-50f64a494761
STEP: Creating a pod to test consume secrets
Jun 13 11:49:55.467: INFO: Waiting up to 5m0s for pod "pod-secrets-bcca9dce-256b-481e-8a25-1168f1b4c0c8" in namespace "secrets-1736" to be "success or failure"
Jun 13 11:49:55.472: INFO: Pod "pod-secrets-bcca9dce-256b-481e-8a25-1168f1b4c0c8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.208161ms
Jun 13 11:49:57.476: INFO: Pod "pod-secrets-bcca9dce-256b-481e-8a25-1168f1b4c0c8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008405855s
Jun 13 11:49:59.480: INFO: Pod "pod-secrets-bcca9dce-256b-481e-8a25-1168f1b4c0c8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012346202s
STEP: Saw pod success
Jun 13 11:49:59.480: INFO: Pod "pod-secrets-bcca9dce-256b-481e-8a25-1168f1b4c0c8" satisfied condition "success or failure"
Jun 13 11:49:59.484: INFO: Trying to get logs from node 10.0.10.2 pod pod-secrets-bcca9dce-256b-481e-8a25-1168f1b4c0c8 container secret-volume-test: <nil>
STEP: delete the pod
Jun 13 11:49:59.560: INFO: Waiting for pod pod-secrets-bcca9dce-256b-481e-8a25-1168f1b4c0c8 to disappear
Jun 13 11:49:59.564: INFO: Pod pod-secrets-bcca9dce-256b-481e-8a25-1168f1b4c0c8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:49:59.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1736" for this suite.
Jun 13 11:50:05.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:50:05.718: INFO: namespace secrets-1736 deletion completed in 6.149029538s

• [SLOW TEST:10.315 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:50:05.718: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 11:50:05.793: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"64fbfbed-2448-4260-961e-7951fe24eb4d", Controller:(*bool)(0xc003f42cf2), BlockOwnerDeletion:(*bool)(0xc003f42cf3)}}
Jun 13 11:50:05.799: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"00ca7e5d-17e8-4913-b613-5db5096b2058", Controller:(*bool)(0xc00417f7da), BlockOwnerDeletion:(*bool)(0xc00417f7db)}}
Jun 13 11:50:05.806: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"fece67c1-1742-45cb-9ca0-934131a9bba0", Controller:(*bool)(0xc003f42ec2), BlockOwnerDeletion:(*bool)(0xc003f42ec3)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:50:10.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1464" for this suite.
Jun 13 11:50:16.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:50:16.959: INFO: namespace gc-1464 deletion completed in 6.134848221s

• [SLOW TEST:11.241 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:50:16.960: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Jun 13 11:50:17.014: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a0843ad9-a543-4eaa-9b85-e70a8a175dfe" in namespace "projected-4761" to be "success or failure"
Jun 13 11:50:17.019: INFO: Pod "downwardapi-volume-a0843ad9-a543-4eaa-9b85-e70a8a175dfe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.497323ms
Jun 13 11:50:19.024: INFO: Pod "downwardapi-volume-a0843ad9-a543-4eaa-9b85-e70a8a175dfe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009361838s
Jun 13 11:50:21.036: INFO: Pod "downwardapi-volume-a0843ad9-a543-4eaa-9b85-e70a8a175dfe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.021263791s
STEP: Saw pod success
Jun 13 11:50:21.036: INFO: Pod "downwardapi-volume-a0843ad9-a543-4eaa-9b85-e70a8a175dfe" satisfied condition "success or failure"
Jun 13 11:50:21.040: INFO: Trying to get logs from node 10.0.10.2 pod downwardapi-volume-a0843ad9-a543-4eaa-9b85-e70a8a175dfe container client-container: <nil>
STEP: delete the pod
Jun 13 11:50:21.063: INFO: Waiting for pod downwardapi-volume-a0843ad9-a543-4eaa-9b85-e70a8a175dfe to disappear
Jun 13 11:50:21.068: INFO: Pod downwardapi-volume-a0843ad9-a543-4eaa-9b85-e70a8a175dfe no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:50:21.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4761" for this suite.
Jun 13 11:50:27.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:50:27.211: INFO: namespace projected-4761 deletion completed in 6.137869108s

• [SLOW TEST:10.251 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:50:27.212: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-95d3e71c-35bb-47f9-a098-c6311d2ab888
Jun 13 11:50:27.267: INFO: Pod name my-hostname-basic-95d3e71c-35bb-47f9-a098-c6311d2ab888: Found 0 pods out of 1
Jun 13 11:50:32.273: INFO: Pod name my-hostname-basic-95d3e71c-35bb-47f9-a098-c6311d2ab888: Found 1 pods out of 1
Jun 13 11:50:32.273: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-95d3e71c-35bb-47f9-a098-c6311d2ab888" are running
Jun 13 11:50:32.278: INFO: Pod "my-hostname-basic-95d3e71c-35bb-47f9-a098-c6311d2ab888-t4d9f" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-06-13 11:50:27 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-06-13 11:50:29 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-06-13 11:50:29 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-06-13 11:50:27 +0000 UTC Reason: Message:}])
Jun 13 11:50:32.278: INFO: Trying to dial the pod
Jun 13 11:50:37.436: INFO: Controller my-hostname-basic-95d3e71c-35bb-47f9-a098-c6311d2ab888: Got expected result from replica 1 [my-hostname-basic-95d3e71c-35bb-47f9-a098-c6311d2ab888-t4d9f]: "my-hostname-basic-95d3e71c-35bb-47f9-a098-c6311d2ab888-t4d9f", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:50:37.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-4180" for this suite.
Jun 13 11:50:43.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:50:43.591: INFO: namespace replication-controller-4180 deletion completed in 6.150174692s

• [SLOW TEST:16.379 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:50:43.592: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Jun 13 11:50:49.701: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 13 11:50:49.706: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 13 11:50:51.706: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 13 11:50:51.710: INFO: Pod pod-with-poststart-exec-hook still exists
Jun 13 11:50:53.706: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Jun 13 11:50:53.711: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:50:53.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6703" for this suite.
Jun 13 11:51:21.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:51:21.849: INFO: namespace container-lifecycle-hook-6703 deletion completed in 28.13406272s

• [SLOW TEST:38.257 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:51:21.849: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-e5b28d0b-d6a0-410d-8c40-6195b1d0ebcf
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:51:21.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9636" for this suite.
Jun 13 11:51:27.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:51:28.046: INFO: namespace secrets-9636 deletion completed in 6.141986127s

• [SLOW TEST:6.197 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:51:28.048: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W0613 11:52:08.137106      22 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Jun 13 11:52:08.137: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:52:08.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5666" for this suite.
Jun 13 11:52:14.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:52:14.568: INFO: namespace gc-5666 deletion completed in 6.426460551s

• [SLOW TEST:46.520 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:52:14.568: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Jun 13 11:52:17.649: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:52:17.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8936" for this suite.
Jun 13 11:52:23.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:52:23.813: INFO: namespace container-runtime-8936 deletion completed in 6.143382128s

• [SLOW TEST:9.245 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:52:23.815: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Jun 13 11:52:25.893: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-257530218 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Jun 13 11:52:35.987: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:52:35.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8038" for this suite.
Jun 13 11:52:42.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:52:42.140: INFO: namespace pods-8038 deletion completed in 6.142285523s

• [SLOW TEST:18.326 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:52:42.141: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-7bfd98cb-855f-41d2-b3f5-7f7678dfe016
STEP: Creating secret with name s-test-opt-upd-18239070-7c01-430e-8564-889209927fae
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-7bfd98cb-855f-41d2-b3f5-7f7678dfe016
STEP: Updating secret s-test-opt-upd-18239070-7c01-430e-8564-889209927fae
STEP: Creating secret with name s-test-opt-create-c2326949-73ea-407c-b585-2a679b1d89d4
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:52:46.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5234" for this suite.
Jun 13 11:52:58.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:52:58.782: INFO: namespace projected-5234 deletion completed in 12.418259202s

• [SLOW TEST:16.642 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:52:58.782: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Jun 13 11:52:58.824: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Jun 13 11:52:58.841: INFO: Waiting for terminating namespaces to be deleted...
Jun 13 11:52:58.846: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.2 before test
Jun 13 11:52:58.948: INFO: sonobuoy-systemd-logs-daemon-set-89d5b422bcff4ee4-jptvl from sonobuoy started at 2020-06-13 09:55:07 +0000 UTC (2 container statuses recorded)
Jun 13 11:52:58.948: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jun 13 11:52:58.949: INFO: 	Container systemd-logs ready: true, restart count 0
Jun 13 11:52:58.949: INFO: kube-proxy-mbpxz from kube-system started at 2020-06-13 03:16:34 +0000 UTC (1 container statuses recorded)
Jun 13 11:52:58.949: INFO: 	Container kube-proxy ready: true, restart count 0
Jun 13 11:52:58.949: INFO: kube-flannel-ds-mddmt from kube-system started at 2020-06-13 03:16:34 +0000 UTC (1 container statuses recorded)
Jun 13 11:52:58.949: INFO: 	Container kube-flannel ready: true, restart count 1
Jun 13 11:52:58.949: INFO: proxymux-client-bvtcs from kube-system started at 2020-06-13 11:10:21 +0000 UTC (1 container statuses recorded)
Jun 13 11:52:58.949: INFO: 	Container proxymux-client ready: true, restart count 0
Jun 13 11:52:58.949: INFO: csi-oci-node-dnwhj from kube-system started at 2020-06-13 11:10:24 +0000 UTC (1 container statuses recorded)
Jun 13 11:52:58.949: INFO: 	Container csi-node-driver ready: true, restart count 0
Jun 13 11:52:58.949: INFO: 
Logging pods the kubelet thinks is on node 10.0.10.3 before test
Jun 13 11:52:59.042: INFO: kube-dns-autoscaler-75565f7896-hm82m from kube-system started at 2020-06-13 03:17:03 +0000 UTC (1 container statuses recorded)
Jun 13 11:52:59.043: INFO: 	Container autoscaler ready: true, restart count 0
Jun 13 11:52:59.043: INFO: sonobuoy-e2e-job-eae45311abd24acb from sonobuoy started at 2020-06-13 09:55:07 +0000 UTC (2 container statuses recorded)
Jun 13 11:52:59.043: INFO: 	Container e2e ready: true, restart count 0
Jun 13 11:52:59.043: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Jun 13 11:52:59.043: INFO: coredns-6f9ff9bd47-kp5rh from kube-system started at 2020-06-13 10:43:57 +0000 UTC (1 container statuses recorded)
Jun 13 11:52:59.043: INFO: 	Container coredns ready: true, restart count 0
Jun 13 11:52:59.043: INFO: kube-flannel-ds-6cxw2 from kube-system started at 2020-06-13 03:16:34 +0000 UTC (1 container statuses recorded)
Jun 13 11:52:59.043: INFO: 	Container kube-flannel ready: true, restart count 1
Jun 13 11:52:59.043: INFO: proxymux-client-mshct from kube-system started at 2020-06-13 03:16:54 +0000 UTC (1 container statuses recorded)
Jun 13 11:52:59.043: INFO: 	Container proxymux-client ready: true, restart count 0
Jun 13 11:52:59.043: INFO: kubernetes-dashboard-56b6bf4bf-65jz6 from kube-system started at 2020-06-13 03:16:53 +0000 UTC (1 container statuses recorded)
Jun 13 11:52:59.043: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Jun 13 11:52:59.043: INFO: sonobuoy from sonobuoy started at 2020-06-13 09:55:05 +0000 UTC (1 container statuses recorded)
Jun 13 11:52:59.043: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Jun 13 11:52:59.043: INFO: sonobuoy-systemd-logs-daemon-set-89d5b422bcff4ee4-z5xtf from sonobuoy started at 2020-06-13 09:55:07 +0000 UTC (2 container statuses recorded)
Jun 13 11:52:59.043: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Jun 13 11:52:59.043: INFO: 	Container systemd-logs ready: true, restart count 0
Jun 13 11:52:59.043: INFO: kube-proxy-6vf8c from kube-system started at 2020-06-13 03:16:34 +0000 UTC (1 container statuses recorded)
Jun 13 11:52:59.043: INFO: 	Container kube-proxy ready: true, restart count 0
Jun 13 11:52:59.043: INFO: csi-oci-node-hhfs6 from kube-system started at 2020-06-13 03:16:54 +0000 UTC (1 container statuses recorded)
Jun 13 11:52:59.043: INFO: 	Container csi-node-driver ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-aab74de4-c876-43b3-bad7-e6e5996a6938 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-aab74de4-c876-43b3-bad7-e6e5996a6938 off the node 10.0.10.2
STEP: verifying the node doesn't have the label kubernetes.io/e2e-aab74de4-c876-43b3-bad7-e6e5996a6938
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:58:05.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1939" for this suite.
Jun 13 11:58:13.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:58:13.577: INFO: namespace sched-pred-1939 deletion completed in 8.414411591s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:314.795 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:58:13.578: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-5739
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5739 to expose endpoints map[]
Jun 13 11:58:13.667: INFO: Get endpoints failed (5.796555ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Jun 13 11:58:14.674: INFO: successfully validated that service multi-endpoint-test in namespace services-5739 exposes endpoints map[] (1.012515744s elapsed)
STEP: Creating pod pod1 in namespace services-5739
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5739 to expose endpoints map[pod1:[100]]
Jun 13 11:58:16.880: INFO: successfully validated that service multi-endpoint-test in namespace services-5739 exposes endpoints map[pod1:[100]] (2.188249454s elapsed)
STEP: Creating pod pod2 in namespace services-5739
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5739 to expose endpoints map[pod1:[100] pod2:[101]]
Jun 13 11:58:18.940: INFO: successfully validated that service multi-endpoint-test in namespace services-5739 exposes endpoints map[pod1:[100] pod2:[101]] (2.053042207s elapsed)
STEP: Deleting pod pod1 in namespace services-5739
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5739 to expose endpoints map[pod2:[101]]
Jun 13 11:58:19.967: INFO: successfully validated that service multi-endpoint-test in namespace services-5739 exposes endpoints map[pod2:[101]] (1.019244166s elapsed)
STEP: Deleting pod pod2 in namespace services-5739
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-5739 to expose endpoints map[]
Jun 13 11:58:20.983: INFO: successfully validated that service multi-endpoint-test in namespace services-5739 exposes endpoints map[] (1.008361082s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:58:21.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5739" for this suite.
Jun 13 11:58:27.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:58:27.156: INFO: namespace services-5739 deletion completed in 6.143036436s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.578 seconds]
[sig-network] Services
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:58:27.156: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Jun 13 11:58:27.194: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-257530218 --namespace=kubectl-3415 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Jun 13 11:58:29.394: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Jun 13 11:58:29.394: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:58:31.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3415" for this suite.
Jun 13 11:58:37.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:58:37.556: INFO: namespace kubectl-3415 deletion completed in 6.146949103s

• [SLOW TEST:10.400 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:58:37.557: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:58:53.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5439" for this suite.
Jun 13 11:58:59.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:59:00.092: INFO: namespace resourcequota-5439 deletion completed in 6.136065144s

• [SLOW TEST:22.535 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:59:00.093: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-a575d9f6-a321-4b44-be55-34d6b63fde81
STEP: Creating a pod to test consume configMaps
Jun 13 11:59:00.152: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e982f402-c5d7-42b4-9950-1d91bc8a0632" in namespace "projected-372" to be "success or failure"
Jun 13 11:59:00.156: INFO: Pod "pod-projected-configmaps-e982f402-c5d7-42b4-9950-1d91bc8a0632": Phase="Pending", Reason="", readiness=false. Elapsed: 4.203337ms
Jun 13 11:59:02.161: INFO: Pod "pod-projected-configmaps-e982f402-c5d7-42b4-9950-1d91bc8a0632": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009098077s
STEP: Saw pod success
Jun 13 11:59:02.161: INFO: Pod "pod-projected-configmaps-e982f402-c5d7-42b4-9950-1d91bc8a0632" satisfied condition "success or failure"
Jun 13 11:59:02.165: INFO: Trying to get logs from node 10.0.10.2 pod pod-projected-configmaps-e982f402-c5d7-42b4-9950-1d91bc8a0632 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Jun 13 11:59:02.272: INFO: Waiting for pod pod-projected-configmaps-e982f402-c5d7-42b4-9950-1d91bc8a0632 to disappear
Jun 13 11:59:02.276: INFO: Pod pod-projected-configmaps-e982f402-c5d7-42b4-9950-1d91bc8a0632 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:59:02.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-372" for this suite.
Jun 13 11:59:08.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:59:08.416: INFO: namespace projected-372 deletion completed in 6.13546511s

• [SLOW TEST:8.324 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:59:08.417: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:59:24.577: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7214" for this suite.
Jun 13 11:59:30.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:59:30.727: INFO: namespace resourcequota-7214 deletion completed in 6.145277547s

• [SLOW TEST:22.310 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:59:30.728: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Jun 13 11:59:30.770: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
Jun 13 11:59:32.752: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:59:45.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9149" for this suite.
Jun 13 11:59:51.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 11:59:51.333: INFO: namespace crd-publish-openapi-9149 deletion completed in 6.14176643s

• [SLOW TEST:20.606 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 11:59:51.338: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 11:59:51.382: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 11:59:57.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8411" for this suite.
Jun 13 12:00:03.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 12:00:03.852: INFO: namespace custom-resource-definition-8411 deletion completed in 6.166540037s

• [SLOW TEST:12.515 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 12:00:03.853: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Jun 13 12:00:03.912: INFO: Pod name rollover-pod: Found 0 pods out of 1
Jun 13 12:00:08.918: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Jun 13 12:00:08.918: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Jun 13 12:00:10.924: INFO: Creating deployment "test-rollover-deployment"
Jun 13 12:00:10.935: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Jun 13 12:00:12.944: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Jun 13 12:00:12.954: INFO: Ensure that both replica sets have 1 created replica
Jun 13 12:00:12.963: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Jun 13 12:00:12.981: INFO: Updating deployment test-rollover-deployment
Jun 13 12:00:12.981: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Jun 13 12:00:14.989: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Jun 13 12:00:14.998: INFO: Make sure deployment "test-rollover-deployment" is complete
Jun 13 12:00:15.007: INFO: all replica sets need to contain the pod-template-hash label
Jun 13 12:00:15.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646410, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646410, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646413, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646410, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 13 12:00:17.019: INFO: all replica sets need to contain the pod-template-hash label
Jun 13 12:00:17.019: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646410, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646410, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646415, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646410, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 13 12:00:19.018: INFO: all replica sets need to contain the pod-template-hash label
Jun 13 12:00:19.019: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646410, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646410, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646415, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646410, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 13 12:00:21.019: INFO: all replica sets need to contain the pod-template-hash label
Jun 13 12:00:21.019: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646410, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646410, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646415, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646410, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 13 12:00:23.019: INFO: all replica sets need to contain the pod-template-hash label
Jun 13 12:00:23.019: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646410, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646410, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646415, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646410, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 13 12:00:25.018: INFO: all replica sets need to contain the pod-template-hash label
Jun 13 12:00:25.018: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646410, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646410, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646415, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63727646410, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Jun 13 12:00:27.020: INFO: 
Jun 13 12:00:27.020: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Jun 13 12:00:27.033: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-3925 /apis/apps/v1/namespaces/deployment-3925/deployments/test-rollover-deployment 949f2d86-8508-4d57-9b26-9165b5379108 123061 2 2020-06-13 12:00:10 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0048018a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-06-13 12:00:10 +0000 UTC,LastTransitionTime:2020-06-13 12:00:10 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2020-06-13 12:00:25 +0000 UTC,LastTransitionTime:2020-06-13 12:00:10 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Jun 13 12:00:27.039: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-3925 /apis/apps/v1/namespaces/deployment-3925/replicasets/test-rollover-deployment-7d7dc6548c 42d32588-f217-4963-8a5b-295d641f626f 123050 2 2020-06-13 12:00:12 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 949f2d86-8508-4d57-9b26-9165b5379108 0xc0047d7a07 0xc0047d7a08}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0047d7a68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Jun 13 12:00:27.039: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Jun 13 12:00:27.039: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-3925 /apis/apps/v1/namespaces/deployment-3925/replicasets/test-rollover-controller 0446a369-bad8-47d1-8ddb-51290833d132 123059 2 2020-06-13 12:00:03 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 949f2d86-8508-4d57-9b26-9165b5379108 0xc0047d7907 0xc0047d7908}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0047d7978 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jun 13 12:00:27.040: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-3925 /apis/apps/v1/namespaces/deployment-3925/replicasets/test-rollover-deployment-f6c94f66c fa605908-cedd-4d32-ba0e-f43354c3a5fe 122996 2 2020-06-13 12:00:10 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 949f2d86-8508-4d57-9b26-9165b5379108 0xc0047d7ad0 0xc0047d7ad1}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0047d7b48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Jun 13 12:00:27.046: INFO: Pod "test-rollover-deployment-7d7dc6548c-dnbt2" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-dnbt2 test-rollover-deployment-7d7dc6548c- deployment-3925 /api/v1/namespaces/deployment-3925/pods/test-rollover-deployment-7d7dc6548c-dnbt2 8852483c-fe76-4eba-a8a5-524a14129864 123017 0 2020-06-13 12:00:13 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c 42d32588-f217-4963-8a5b-295d641f626f 0xc0048380e7 0xc0048380e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-5n466,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-5n466,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-5n466,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.10.2,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 12:00:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 12:00:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 12:00:15 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-06-13 12:00:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.10.2,PodIP:10.244.1.225,StartTime:2020-06-13 12:00:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-06-13 12:00:14 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://46afa0322894432096ec5af56c173477b2aeeba2a14c9b5460f261e06808bf37,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.1.225,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 12:00:27.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3925" for this suite.
Jun 13 12:00:33.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 12:00:33.442: INFO: namespace deployment-3925 deletion completed in 6.389357483s

• [SLOW TEST:29.589 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 12:00:33.444: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-4373
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4373 to expose endpoints map[]
Jun 13 12:00:33.506: INFO: Get endpoints failed (7.54689ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Jun 13 12:00:34.511: INFO: successfully validated that service endpoint-test2 in namespace services-4373 exposes endpoints map[] (1.012285244s elapsed)
STEP: Creating pod pod1 in namespace services-4373
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4373 to expose endpoints map[pod1:[80]]
Jun 13 12:00:36.548: INFO: successfully validated that service endpoint-test2 in namespace services-4373 exposes endpoints map[pod1:[80]] (2.024047125s elapsed)
STEP: Creating pod pod2 in namespace services-4373
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4373 to expose endpoints map[pod1:[80] pod2:[80]]
Jun 13 12:00:38.591: INFO: successfully validated that service endpoint-test2 in namespace services-4373 exposes endpoints map[pod1:[80] pod2:[80]] (2.036539978s elapsed)
STEP: Deleting pod pod1 in namespace services-4373
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4373 to expose endpoints map[pod2:[80]]
Jun 13 12:00:39.616: INFO: successfully validated that service endpoint-test2 in namespace services-4373 exposes endpoints map[pod2:[80]] (1.016433274s elapsed)
STEP: Deleting pod pod2 in namespace services-4373
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4373 to expose endpoints map[]
Jun 13 12:00:40.634: INFO: successfully validated that service endpoint-test2 in namespace services-4373 exposes endpoints map[] (1.008870382s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 12:00:40.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4373" for this suite.
Jun 13 12:01:08.682: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 12:01:08.812: INFO: namespace services-4373 deletion completed in 28.1474779s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:35.369 seconds]
[sig-network] Services
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 12:01:08.813: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Jun 13 12:01:08.868: INFO: Waiting up to 5m0s for pod "client-containers-797baae8-23fe-4858-afcc-7af21f1c5f0f" in namespace "containers-7070" to be "success or failure"
Jun 13 12:01:08.872: INFO: Pod "client-containers-797baae8-23fe-4858-afcc-7af21f1c5f0f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010223ms
Jun 13 12:01:10.876: INFO: Pod "client-containers-797baae8-23fe-4858-afcc-7af21f1c5f0f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008869342s
Jun 13 12:01:12.881: INFO: Pod "client-containers-797baae8-23fe-4858-afcc-7af21f1c5f0f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013193321s
STEP: Saw pod success
Jun 13 12:01:12.881: INFO: Pod "client-containers-797baae8-23fe-4858-afcc-7af21f1c5f0f" satisfied condition "success or failure"
Jun 13 12:01:12.884: INFO: Trying to get logs from node 10.0.10.2 pod client-containers-797baae8-23fe-4858-afcc-7af21f1c5f0f container test-container: <nil>
STEP: delete the pod
Jun 13 12:01:13.073: INFO: Waiting for pod client-containers-797baae8-23fe-4858-afcc-7af21f1c5f0f to disappear
Jun 13 12:01:13.077: INFO: Pod client-containers-797baae8-23fe-4858-afcc-7af21f1c5f0f no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 12:01:13.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7070" for this suite.
Jun 13 12:01:19.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 12:01:19.221: INFO: namespace containers-7070 deletion completed in 6.139487681s

• [SLOW TEST:10.408 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Jun 13 12:01:19.222: INFO: >>> kubeConfig: /tmp/kubeconfig-257530218
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Jun 13 12:01:30.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4676" for this suite.
Jun 13 12:01:36.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Jun 13 12:01:36.501: INFO: namespace resourcequota-4676 deletion completed in 6.16901133s

• [SLOW TEST:17.280 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSJun 13 12:01:36.502: INFO: Running AfterSuite actions on all nodes
Jun 13 12:01:36.502: INFO: Running AfterSuite actions on node 1
Jun 13 12:01:36.502: INFO: Skipping dumping logs from cluster

Ran 276 of 4731 Specs in 7582.313 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4455 Skipped
PASS

Ginkgo ran 1 suite in 2h6m25.041736628s
Test Suite Passed
