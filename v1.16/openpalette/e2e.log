I1213 17:43:46.251182      25 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-064082504
I1213 17:43:46.251344      25 e2e.go:92] Starting e2e run "3f0ae178-3bbe-4ce4-9327-26be0029b2ca" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1576259023 - Will randomize all specs
Will run 276 of 4897 specs

Dec 13 17:43:46.268: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 17:43:46.271: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec 13 17:43:46.285: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec 13 17:43:46.312: INFO: 2 / 2 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec 13 17:43:46.312: INFO: expected 1 pod replicas in namespace 'kube-system', 1 are Running and Ready.
Dec 13 17:43:46.312: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec 13 17:43:46.319: INFO: e2e test version: v1.16.1
Dec 13 17:43:46.320: INFO: kube-apiserver version: v1.16.1
Dec 13 17:43:46.320: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 17:43:46.324: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:43:46.324: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename crd-watch
Dec 13 17:43:46.348: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 17:43:46.349: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Creating first CR 
Dec 13 17:43:46.946: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-13T17:43:46Z generation:1 name:name1 resourceVersion:116603 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:39417f49-777c-468f-91ec-1e2870d7c08d] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Dec 13 17:43:56.950: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-13T17:43:56Z generation:1 name:name2 resourceVersion:116611 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:7ac2eb40-4abe-422c-8121-b946cee67347] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Dec 13 17:44:06.954: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-13T17:43:46Z generation:2 name:name1 resourceVersion:116619 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:39417f49-777c-468f-91ec-1e2870d7c08d] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Dec 13 17:44:16.958: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-13T17:43:56Z generation:2 name:name2 resourceVersion:116628 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:7ac2eb40-4abe-422c-8121-b946cee67347] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Dec 13 17:44:26.962: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-13T17:43:46Z generation:2 name:name1 resourceVersion:116637 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:39417f49-777c-468f-91ec-1e2870d7c08d] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Dec 13 17:44:36.967: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-13T17:43:56Z generation:2 name:name2 resourceVersion:116645 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:7ac2eb40-4abe-422c-8121-b946cee67347] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:44:47.473: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-5044" for this suite.
Dec 13 17:44:53.481: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:44:53.522: INFO: namespace crd-watch-5044 deletion completed in 6.046771807s

• [SLOW TEST:67.197 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:44:53.522: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec 13 17:44:53.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 create -f - --namespace=kubectl-1851'
Dec 13 17:44:54.190: INFO: stderr: ""
Dec 13 17:44:54.190: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 13 17:44:55.194: INFO: Selector matched 1 pods for map[app:redis]
Dec 13 17:44:55.194: INFO: Found 0 / 1
Dec 13 17:44:56.193: INFO: Selector matched 1 pods for map[app:redis]
Dec 13 17:44:56.193: INFO: Found 0 / 1
Dec 13 17:44:57.193: INFO: Selector matched 1 pods for map[app:redis]
Dec 13 17:44:57.193: INFO: Found 0 / 1
Dec 13 17:44:58.193: INFO: Selector matched 1 pods for map[app:redis]
Dec 13 17:44:58.193: INFO: Found 0 / 1
Dec 13 17:44:59.193: INFO: Selector matched 1 pods for map[app:redis]
Dec 13 17:44:59.193: INFO: Found 1 / 1
Dec 13 17:44:59.193: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec 13 17:44:59.195: INFO: Selector matched 1 pods for map[app:redis]
Dec 13 17:44:59.195: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 13 17:44:59.195: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 patch pod redis-master-x75jz --namespace=kubectl-1851 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec 13 17:44:59.311: INFO: stderr: ""
Dec 13 17:44:59.311: INFO: stdout: "pod/redis-master-x75jz patched\n"
STEP: checking annotations
Dec 13 17:44:59.313: INFO: Selector matched 1 pods for map[app:redis]
Dec 13 17:44:59.313: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:44:59.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1851" for this suite.
Dec 13 17:45:11.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:45:11.360: INFO: namespace kubectl-1851 deletion completed in 12.045277441s

• [SLOW TEST:17.838 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:45:11.362: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 13 17:45:11.387: INFO: Waiting up to 5m0s for pod "downward-api-43ed528d-d2a5-4f22-8f7d-558320fabdf9" in namespace "downward-api-89" to be "success or failure"
Dec 13 17:45:11.389: INFO: Pod "downward-api-43ed528d-d2a5-4f22-8f7d-558320fabdf9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.482846ms
Dec 13 17:45:13.391: INFO: Pod "downward-api-43ed528d-d2a5-4f22-8f7d-558320fabdf9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003516682s
Dec 13 17:45:15.393: INFO: Pod "downward-api-43ed528d-d2a5-4f22-8f7d-558320fabdf9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006019266s
Dec 13 17:45:17.396: INFO: Pod "downward-api-43ed528d-d2a5-4f22-8f7d-558320fabdf9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008354539s
Dec 13 17:45:19.690: INFO: Pod "downward-api-43ed528d-d2a5-4f22-8f7d-558320fabdf9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.302436026s
STEP: Saw pod success
Dec 13 17:45:19.690: INFO: Pod "downward-api-43ed528d-d2a5-4f22-8f7d-558320fabdf9" satisfied condition "success or failure"
Dec 13 17:45:19.692: INFO: Trying to get logs from node 172.160.134.165 pod downward-api-43ed528d-d2a5-4f22-8f7d-558320fabdf9 container dapi-container: <nil>
STEP: delete the pod
Dec 13 17:45:19.725: INFO: Waiting for pod downward-api-43ed528d-d2a5-4f22-8f7d-558320fabdf9 to disappear
Dec 13 17:45:19.733: INFO: Pod downward-api-43ed528d-d2a5-4f22-8f7d-558320fabdf9 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:45:19.733: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-89" for this suite.
Dec 13 17:45:25.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:45:25.780: INFO: namespace downward-api-89 deletion completed in 6.044391919s

• [SLOW TEST:14.418 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:45:25.780: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Dec 13 17:45:25.807: INFO: Waiting up to 5m0s for pod "client-containers-5a38d2b1-5a5d-43d2-897a-8d9ba6f978f0" in namespace "containers-8519" to be "success or failure"
Dec 13 17:45:25.810: INFO: Pod "client-containers-5a38d2b1-5a5d-43d2-897a-8d9ba6f978f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.14802ms
Dec 13 17:45:27.812: INFO: Pod "client-containers-5a38d2b1-5a5d-43d2-897a-8d9ba6f978f0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004384937s
Dec 13 17:45:29.814: INFO: Pod "client-containers-5a38d2b1-5a5d-43d2-897a-8d9ba6f978f0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006604343s
Dec 13 17:45:31.816: INFO: Pod "client-containers-5a38d2b1-5a5d-43d2-897a-8d9ba6f978f0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008773442s
Dec 13 17:45:33.818: INFO: Pod "client-containers-5a38d2b1-5a5d-43d2-897a-8d9ba6f978f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.010889113s
STEP: Saw pod success
Dec 13 17:45:33.818: INFO: Pod "client-containers-5a38d2b1-5a5d-43d2-897a-8d9ba6f978f0" satisfied condition "success or failure"
Dec 13 17:45:33.820: INFO: Trying to get logs from node 172.160.134.166 pod client-containers-5a38d2b1-5a5d-43d2-897a-8d9ba6f978f0 container test-container: <nil>
STEP: delete the pod
Dec 13 17:45:33.861: INFO: Waiting for pod client-containers-5a38d2b1-5a5d-43d2-897a-8d9ba6f978f0 to disappear
Dec 13 17:45:33.863: INFO: Pod client-containers-5a38d2b1-5a5d-43d2-897a-8d9ba6f978f0 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:45:33.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8519" for this suite.
Dec 13 17:45:39.875: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:45:39.917: INFO: namespace containers-8519 deletion completed in 6.052340935s

• [SLOW TEST:14.136 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:45:39.917: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:46:39.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1526" for this suite.
Dec 13 17:46:51.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:46:52.003: INFO: namespace container-probe-1526 deletion completed in 12.050671058s

• [SLOW TEST:72.086 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:46:52.004: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-6956/configmap-test-c15343e1-cd00-4ce9-b2e8-d704fcbe9fe7
STEP: Creating a pod to test consume configMaps
Dec 13 17:46:52.035: INFO: Waiting up to 5m0s for pod "pod-configmaps-8a186d3b-c916-409f-8c9c-89bd710be6ff" in namespace "configmap-6956" to be "success or failure"
Dec 13 17:46:52.038: INFO: Pod "pod-configmaps-8a186d3b-c916-409f-8c9c-89bd710be6ff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.495956ms
Dec 13 17:46:54.040: INFO: Pod "pod-configmaps-8a186d3b-c916-409f-8c9c-89bd710be6ff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004738921s
Dec 13 17:46:56.043: INFO: Pod "pod-configmaps-8a186d3b-c916-409f-8c9c-89bd710be6ff": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00699081s
Dec 13 17:46:58.045: INFO: Pod "pod-configmaps-8a186d3b-c916-409f-8c9c-89bd710be6ff": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009329683s
Dec 13 17:47:00.047: INFO: Pod "pod-configmaps-8a186d3b-c916-409f-8c9c-89bd710be6ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.011688029s
STEP: Saw pod success
Dec 13 17:47:00.047: INFO: Pod "pod-configmaps-8a186d3b-c916-409f-8c9c-89bd710be6ff" satisfied condition "success or failure"
Dec 13 17:47:00.049: INFO: Trying to get logs from node 172.160.134.166 pod pod-configmaps-8a186d3b-c916-409f-8c9c-89bd710be6ff container env-test: <nil>
STEP: delete the pod
Dec 13 17:47:00.065: INFO: Waiting for pod pod-configmaps-8a186d3b-c916-409f-8c9c-89bd710be6ff to disappear
Dec 13 17:47:00.069: INFO: Pod pod-configmaps-8a186d3b-c916-409f-8c9c-89bd710be6ff no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:47:00.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6956" for this suite.
Dec 13 17:47:06.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:47:06.124: INFO: namespace configmap-6956 deletion completed in 6.052759457s

• [SLOW TEST:14.121 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:47:06.124: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 13 17:47:06.152: INFO: Waiting up to 5m0s for pod "downwardapi-volume-970a9dca-1ce8-4f84-9e21-896f90716a98" in namespace "projected-8970" to be "success or failure"
Dec 13 17:47:06.166: INFO: Pod "downwardapi-volume-970a9dca-1ce8-4f84-9e21-896f90716a98": Phase="Pending", Reason="", readiness=false. Elapsed: 14.659033ms
Dec 13 17:47:08.168: INFO: Pod "downwardapi-volume-970a9dca-1ce8-4f84-9e21-896f90716a98": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016759936s
Dec 13 17:47:10.171: INFO: Pod "downwardapi-volume-970a9dca-1ce8-4f84-9e21-896f90716a98": Phase="Pending", Reason="", readiness=false. Elapsed: 4.019105233s
Dec 13 17:47:12.176: INFO: Pod "downwardapi-volume-970a9dca-1ce8-4f84-9e21-896f90716a98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.02392986s
STEP: Saw pod success
Dec 13 17:47:12.176: INFO: Pod "downwardapi-volume-970a9dca-1ce8-4f84-9e21-896f90716a98" satisfied condition "success or failure"
Dec 13 17:47:12.177: INFO: Trying to get logs from node 172.160.134.165 pod downwardapi-volume-970a9dca-1ce8-4f84-9e21-896f90716a98 container client-container: <nil>
STEP: delete the pod
Dec 13 17:47:12.203: INFO: Waiting for pod downwardapi-volume-970a9dca-1ce8-4f84-9e21-896f90716a98 to disappear
Dec 13 17:47:12.204: INFO: Pod downwardapi-volume-970a9dca-1ce8-4f84-9e21-896f90716a98 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:47:12.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8970" for this suite.
Dec 13 17:47:18.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:47:18.259: INFO: namespace projected-8970 deletion completed in 6.052683832s

• [SLOW TEST:12.135 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:47:18.262: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 13 17:47:18.291: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-1896'
Dec 13 17:47:18.407: INFO: stderr: ""
Dec 13 17:47:18.407: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Dec 13 17:47:18.423: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 delete pods e2e-test-httpd-pod --namespace=kubectl-1896'
Dec 13 17:47:18.554: INFO: stderr: ""
Dec 13 17:47:18.554: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:47:18.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1896" for this suite.
Dec 13 17:47:24.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:47:24.603: INFO: namespace kubectl-1896 deletion completed in 6.046922669s

• [SLOW TEST:6.341 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:47:24.603: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 17:47:32.651: INFO: Waiting up to 5m0s for pod "client-envvars-92706ff5-c2a4-4521-9696-a8427591da8d" in namespace "pods-9625" to be "success or failure"
Dec 13 17:47:32.653: INFO: Pod "client-envvars-92706ff5-c2a4-4521-9696-a8427591da8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.11023ms
Dec 13 17:47:34.656: INFO: Pod "client-envvars-92706ff5-c2a4-4521-9696-a8427591da8d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004490163s
Dec 13 17:47:36.658: INFO: Pod "client-envvars-92706ff5-c2a4-4521-9696-a8427591da8d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006873219s
Dec 13 17:47:38.661: INFO: Pod "client-envvars-92706ff5-c2a4-4521-9696-a8427591da8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009294944s
STEP: Saw pod success
Dec 13 17:47:38.661: INFO: Pod "client-envvars-92706ff5-c2a4-4521-9696-a8427591da8d" satisfied condition "success or failure"
Dec 13 17:47:38.662: INFO: Trying to get logs from node 172.160.134.165 pod client-envvars-92706ff5-c2a4-4521-9696-a8427591da8d container env3cont: <nil>
STEP: delete the pod
Dec 13 17:47:38.681: INFO: Waiting for pod client-envvars-92706ff5-c2a4-4521-9696-a8427591da8d to disappear
Dec 13 17:47:38.688: INFO: Pod client-envvars-92706ff5-c2a4-4521-9696-a8427591da8d no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:47:38.688: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9625" for this suite.
Dec 13 17:47:50.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:47:50.742: INFO: namespace pods-9625 deletion completed in 12.052258294s

• [SLOW TEST:26.138 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:47:50.744: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec 13 17:47:50.791: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5290 /api/v1/namespaces/watch-5290/configmaps/e2e-watch-test-resource-version 6bf4a90d-7c4e-49af-ad56-1180e8d16686 117031 0 2019-12-13 17:47:50 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 13 17:47:50.791: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-5290 /api/v1/namespaces/watch-5290/configmaps/e2e-watch-test-resource-version 6bf4a90d-7c4e-49af-ad56-1180e8d16686 117032 0 2019-12-13 17:47:50 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:47:50.791: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5290" for this suite.
Dec 13 17:47:56.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:47:56.840: INFO: namespace watch-5290 deletion completed in 6.047424575s

• [SLOW TEST:6.096 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:47:56.841: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 17:47:56.863: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:48:04.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9153" for this suite.
Dec 13 17:48:48.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:48:48.937: INFO: namespace pods-9153 deletion completed in 44.047400768s

• [SLOW TEST:52.096 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:48:48.937: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 13 17:48:48.967: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b350e098-b53c-485f-9817-fbc303cb7e54" in namespace "projected-3711" to be "success or failure"
Dec 13 17:48:48.969: INFO: Pod "downwardapi-volume-b350e098-b53c-485f-9817-fbc303cb7e54": Phase="Pending", Reason="", readiness=false. Elapsed: 2.350564ms
Dec 13 17:48:50.971: INFO: Pod "downwardapi-volume-b350e098-b53c-485f-9817-fbc303cb7e54": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004563676s
Dec 13 17:48:52.973: INFO: Pod "downwardapi-volume-b350e098-b53c-485f-9817-fbc303cb7e54": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006875417s
Dec 13 17:48:54.976: INFO: Pod "downwardapi-volume-b350e098-b53c-485f-9817-fbc303cb7e54": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.00953401s
STEP: Saw pod success
Dec 13 17:48:54.976: INFO: Pod "downwardapi-volume-b350e098-b53c-485f-9817-fbc303cb7e54" satisfied condition "success or failure"
Dec 13 17:48:54.979: INFO: Trying to get logs from node 172.160.134.165 pod downwardapi-volume-b350e098-b53c-485f-9817-fbc303cb7e54 container client-container: <nil>
STEP: delete the pod
Dec 13 17:48:54.992: INFO: Waiting for pod downwardapi-volume-b350e098-b53c-485f-9817-fbc303cb7e54 to disappear
Dec 13 17:48:54.996: INFO: Pod downwardapi-volume-b350e098-b53c-485f-9817-fbc303cb7e54 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:48:54.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3711" for this suite.
Dec 13 17:49:01.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:49:01.045: INFO: namespace projected-3711 deletion completed in 6.047156992s

• [SLOW TEST:12.108 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:49:01.045: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Dec 13 17:49:01.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-7365 -- logs-generator --log-lines-total 100 --run-duration 20s'
Dec 13 17:49:01.187: INFO: stderr: ""
Dec 13 17:49:01.187: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Dec 13 17:49:01.187: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Dec 13 17:49:01.187: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-7365" to be "running and ready, or succeeded"
Dec 13 17:49:01.188: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 1.419884ms
Dec 13 17:49:03.191: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004329286s
Dec 13 17:49:05.193: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006516827s
Dec 13 17:49:07.196: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 6.00894279s
Dec 13 17:49:09.198: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 8.010829641s
Dec 13 17:49:09.198: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Dec 13 17:49:09.198: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Dec 13 17:49:09.198: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 logs logs-generator logs-generator --namespace=kubectl-7365'
Dec 13 17:49:09.365: INFO: stderr: ""
Dec 13 17:49:09.365: INFO: stdout: "I1213 17:49:06.922630       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/s4qz 339\nI1213 17:49:07.122763       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/zh5z 235\nI1213 17:49:07.322764       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/d57s 452\nI1213 17:49:07.523856       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/jdh4 571\nI1213 17:49:07.722849       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/f92 343\nI1213 17:49:07.922804       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/m7l 564\nI1213 17:49:08.122768       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/q4t 521\nI1213 17:49:08.322737       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/trs 414\nI1213 17:49:08.522753       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/xw2 529\nI1213 17:49:08.723357       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/kube-system/pods/pdtx 267\nI1213 17:49:08.923470       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/svr 374\nI1213 17:49:09.122782       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/992 579\nI1213 17:49:09.348335       1 logs_generator.go:76] 12 POST /api/v1/namespaces/ns/pods/wqr 541\n"
STEP: limiting log lines
Dec 13 17:49:09.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 logs logs-generator logs-generator --namespace=kubectl-7365 --tail=1'
Dec 13 17:49:09.491: INFO: stderr: ""
Dec 13 17:49:09.491: INFO: stdout: "I1213 17:49:09.348335       1 logs_generator.go:76] 12 POST /api/v1/namespaces/ns/pods/wqr 541\n"
STEP: limiting log bytes
Dec 13 17:49:09.491: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 logs logs-generator logs-generator --namespace=kubectl-7365 --limit-bytes=1'
Dec 13 17:49:09.601: INFO: stderr: ""
Dec 13 17:49:09.602: INFO: stdout: "I"
STEP: exposing timestamps
Dec 13 17:49:09.602: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 logs logs-generator logs-generator --namespace=kubectl-7365 --tail=1 --timestamps'
Dec 13 17:49:09.715: INFO: stderr: ""
Dec 13 17:49:09.715: INFO: stdout: "2019-12-13T17:49:09.522952768Z I1213 17:49:09.522756       1 logs_generator.go:76] 13 GET /api/v1/namespaces/ns/pods/99g 325\n"
STEP: restricting to a time range
Dec 13 17:49:12.215: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 logs logs-generator logs-generator --namespace=kubectl-7365 --since=1s'
Dec 13 17:49:12.326: INFO: stderr: ""
Dec 13 17:49:12.326: INFO: stdout: "I1213 17:49:11.522766       1 logs_generator.go:76] 23 GET /api/v1/namespaces/kube-system/pods/pnzw 210\nI1213 17:49:11.722775       1 logs_generator.go:76] 24 GET /api/v1/namespaces/kube-system/pods/6xm 551\nI1213 17:49:11.922769       1 logs_generator.go:76] 25 POST /api/v1/namespaces/kube-system/pods/c7p 597\nI1213 17:49:12.122977       1 logs_generator.go:76] 26 POST /api/v1/namespaces/ns/pods/j5c 303\nI1213 17:49:12.322788       1 logs_generator.go:76] 27 GET /api/v1/namespaces/ns/pods/bdr9 254\n"
Dec 13 17:49:12.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 logs logs-generator logs-generator --namespace=kubectl-7365 --since=24h'
Dec 13 17:49:12.437: INFO: stderr: ""
Dec 13 17:49:12.437: INFO: stdout: "I1213 17:49:06.922630       1 logs_generator.go:76] 0 GET /api/v1/namespaces/default/pods/s4qz 339\nI1213 17:49:07.122763       1 logs_generator.go:76] 1 POST /api/v1/namespaces/default/pods/zh5z 235\nI1213 17:49:07.322764       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/d57s 452\nI1213 17:49:07.523856       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/jdh4 571\nI1213 17:49:07.722849       1 logs_generator.go:76] 4 POST /api/v1/namespaces/kube-system/pods/f92 343\nI1213 17:49:07.922804       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/m7l 564\nI1213 17:49:08.122768       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/q4t 521\nI1213 17:49:08.322737       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/trs 414\nI1213 17:49:08.522753       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/xw2 529\nI1213 17:49:08.723357       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/kube-system/pods/pdtx 267\nI1213 17:49:08.923470       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/svr 374\nI1213 17:49:09.122782       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/default/pods/992 579\nI1213 17:49:09.348335       1 logs_generator.go:76] 12 POST /api/v1/namespaces/ns/pods/wqr 541\nI1213 17:49:09.522756       1 logs_generator.go:76] 13 GET /api/v1/namespaces/ns/pods/99g 325\nI1213 17:49:09.722759       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/wq8 297\nI1213 17:49:09.922768       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/kube-system/pods/nk5 456\nI1213 17:49:10.124559       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/cx5 363\nI1213 17:49:10.322768       1 logs_generator.go:76] 17 POST /api/v1/namespaces/kube-system/pods/lllv 404\nI1213 17:49:10.522753       1 logs_generator.go:76] 18 POST /api/v1/namespaces/kube-system/pods/q4v 487\nI1213 17:49:10.722741       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/chbq 297\nI1213 17:49:10.922770       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/g6w 394\nI1213 17:49:11.124765       1 logs_generator.go:76] 21 POST /api/v1/namespaces/ns/pods/ljt 363\nI1213 17:49:11.322779       1 logs_generator.go:76] 22 POST /api/v1/namespaces/default/pods/j95 515\nI1213 17:49:11.522766       1 logs_generator.go:76] 23 GET /api/v1/namespaces/kube-system/pods/pnzw 210\nI1213 17:49:11.722775       1 logs_generator.go:76] 24 GET /api/v1/namespaces/kube-system/pods/6xm 551\nI1213 17:49:11.922769       1 logs_generator.go:76] 25 POST /api/v1/namespaces/kube-system/pods/c7p 597\nI1213 17:49:12.122977       1 logs_generator.go:76] 26 POST /api/v1/namespaces/ns/pods/j5c 303\nI1213 17:49:12.322788       1 logs_generator.go:76] 27 GET /api/v1/namespaces/ns/pods/bdr9 254\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Dec 13 17:49:12.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 delete pod logs-generator --namespace=kubectl-7365'
Dec 13 17:49:15.551: INFO: stderr: ""
Dec 13 17:49:15.551: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:49:15.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7365" for this suite.
Dec 13 17:49:21.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:49:21.600: INFO: namespace kubectl-7365 deletion completed in 6.047054623s

• [SLOW TEST:20.555 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:49:21.600: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 13 17:49:37.641: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 13 17:49:37.646: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 13 17:49:39.646: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 13 17:49:39.649: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 13 17:49:41.646: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 13 17:49:41.649: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:49:41.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9109" for this suite.
Dec 13 17:49:53.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:49:53.708: INFO: namespace container-lifecycle-hook-9109 deletion completed in 12.049488444s

• [SLOW TEST:32.107 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:49:53.708: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 13 17:50:00.261: INFO: Successfully updated pod "labelsupdate5efa81dd-48c3-48c5-b551-d421582037be"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:50:02.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-978" for this suite.
Dec 13 17:50:14.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:50:14.323: INFO: namespace downward-api-978 deletion completed in 12.046141748s

• [SLOW TEST:20.615 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:50:14.325: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-93458cec-d205-46b5-a47d-f14f3d1229d8
STEP: Creating configMap with name cm-test-opt-upd-785de84e-a532-4d31-a933-8bca8698a91c
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-93458cec-d205-46b5-a47d-f14f3d1229d8
STEP: Updating configmap cm-test-opt-upd-785de84e-a532-4d31-a933-8bca8698a91c
STEP: Creating configMap with name cm-test-opt-create-9e58194a-e3d1-4073-ba64-92616f3b7cff
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:51:26.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3698" for this suite.
Dec 13 17:51:38.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:51:38.728: INFO: namespace configmap-3698 deletion completed in 12.048095823s

• [SLOW TEST:84.403 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:51:38.728: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 13 17:51:38.761: INFO: Waiting up to 5m0s for pod "downwardapi-volume-130bcac5-e523-4dbf-8ab8-5c9cce189a42" in namespace "projected-474" to be "success or failure"
Dec 13 17:51:38.773: INFO: Pod "downwardapi-volume-130bcac5-e523-4dbf-8ab8-5c9cce189a42": Phase="Pending", Reason="", readiness=false. Elapsed: 12.148144ms
Dec 13 17:51:40.775: INFO: Pod "downwardapi-volume-130bcac5-e523-4dbf-8ab8-5c9cce189a42": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014436186s
Dec 13 17:51:42.778: INFO: Pod "downwardapi-volume-130bcac5-e523-4dbf-8ab8-5c9cce189a42": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016790037s
Dec 13 17:51:44.780: INFO: Pod "downwardapi-volume-130bcac5-e523-4dbf-8ab8-5c9cce189a42": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.01917394s
STEP: Saw pod success
Dec 13 17:51:44.780: INFO: Pod "downwardapi-volume-130bcac5-e523-4dbf-8ab8-5c9cce189a42" satisfied condition "success or failure"
Dec 13 17:51:44.782: INFO: Trying to get logs from node 172.160.134.165 pod downwardapi-volume-130bcac5-e523-4dbf-8ab8-5c9cce189a42 container client-container: <nil>
STEP: delete the pod
Dec 13 17:51:44.805: INFO: Waiting for pod downwardapi-volume-130bcac5-e523-4dbf-8ab8-5c9cce189a42 to disappear
Dec 13 17:51:44.809: INFO: Pod downwardapi-volume-130bcac5-e523-4dbf-8ab8-5c9cce189a42 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:51:44.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-474" for this suite.
Dec 13 17:51:50.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:51:50.864: INFO: namespace projected-474 deletion completed in 6.053028254s

• [SLOW TEST:12.136 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:51:50.864: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-1889
STEP: creating replication controller nodeport-test in namespace services-1889
I1213 17:51:50.908241      25 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-1889, replica count: 2
I1213 17:51:53.958647      25 runners.go:184] nodeport-test Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1213 17:51:56.958884      25 runners.go:184] nodeport-test Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1213 17:51:59.959140      25 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 13 17:51:59.959: INFO: Creating new exec pod
Dec 13 17:52:08.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=services-1889 execpodxjzkc -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Dec 13 17:52:09.600: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec 13 17:52:09.600: INFO: stdout: ""
Dec 13 17:52:09.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=services-1889 execpodxjzkc -- /bin/sh -x -c nc -zv -t -w 2 10.254.70.183 80'
Dec 13 17:52:10.006: INFO: stderr: "+ nc -zv -t -w 2 10.254.70.183 80\nConnection to 10.254.70.183 80 port [tcp/http] succeeded!\n"
Dec 13 17:52:10.006: INFO: stdout: ""
Dec 13 17:52:10.006: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=services-1889 execpodxjzkc -- /bin/sh -x -c nc -zv -t -w 2 172.160.134.165 30391'
Dec 13 17:52:10.379: INFO: stderr: "+ nc -zv -t -w 2 172.160.134.165 30391\nConnection to 172.160.134.165 30391 port [tcp/30391] succeeded!\n"
Dec 13 17:52:10.379: INFO: stdout: ""
Dec 13 17:52:10.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=services-1889 execpodxjzkc -- /bin/sh -x -c nc -zv -t -w 2 172.160.134.166 30391'
Dec 13 17:52:10.755: INFO: stderr: "+ nc -zv -t -w 2 172.160.134.166 30391\nConnection to 172.160.134.166 30391 port [tcp/30391] succeeded!\n"
Dec 13 17:52:10.755: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:52:10.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1889" for this suite.
Dec 13 17:52:16.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:52:16.806: INFO: namespace services-1889 deletion completed in 6.048383358s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:25.941 seconds]
[sig-network] Services
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:52:16.806: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:52:32.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2233" for this suite.
Dec 13 17:52:38.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:52:38.943: INFO: namespace resourcequota-2233 deletion completed in 6.050620839s

• [SLOW TEST:22.137 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:52:38.943: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:52:54.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7041" for this suite.
Dec 13 17:53:01.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:53:01.046: INFO: namespace resourcequota-7041 deletion completed in 6.045661052s

• [SLOW TEST:22.103 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:53:01.046: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2934
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-2934
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2934
Dec 13 17:53:01.078: INFO: Found 0 stateful pods, waiting for 1
Dec 13 17:53:11.082: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec 13 17:53:11.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=statefulset-2934 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 13 17:53:11.260: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 13 17:53:11.260: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 13 17:53:11.260: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 13 17:53:11.262: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 13 17:53:21.265: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 13 17:53:21.265: INFO: Waiting for statefulset status.replicas updated to 0
Dec 13 17:53:21.274: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Dec 13 17:53:21.274: INFO: ss-0  172.160.134.165  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:11 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:11 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:01 +0000 UTC  }]
Dec 13 17:53:21.274: INFO: 
Dec 13 17:53:21.274: INFO: StatefulSet ss has not reached scale 3, at 1
Dec 13 17:53:22.277: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.996903568s
Dec 13 17:53:23.279: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.994031089s
Dec 13 17:53:24.282: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.991409448s
Dec 13 17:53:25.285: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.988569878s
Dec 13 17:53:26.288: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.985716774s
Dec 13 17:53:27.290: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.98294287s
Dec 13 17:53:28.293: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.980388569s
Dec 13 17:53:29.296: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.977626714s
Dec 13 17:53:30.298: INFO: Verifying statefulset ss doesn't scale past 3 for another 975.013653ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2934
Dec 13 17:53:31.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=statefulset-2934 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 13 17:53:31.473: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 13 17:53:31.473: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 13 17:53:31.473: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 13 17:53:31.473: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=statefulset-2934 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 13 17:53:31.831: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 13 17:53:31.832: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 13 17:53:31.832: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 13 17:53:31.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=statefulset-2934 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 13 17:53:32.567: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 13 17:53:32.567: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 13 17:53:32.567: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 13 17:53:32.570: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 13 17:53:32.570: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 13 17:53:32.570: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec 13 17:53:32.572: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=statefulset-2934 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 13 17:53:32.750: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 13 17:53:32.751: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 13 17:53:32.751: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 13 17:53:32.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=statefulset-2934 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 13 17:53:33.269: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 13 17:53:33.270: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 13 17:53:33.270: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 13 17:53:33.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=statefulset-2934 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 13 17:53:33.654: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 13 17:53:33.654: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 13 17:53:33.654: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 13 17:53:33.654: INFO: Waiting for statefulset status.replicas updated to 0
Dec 13 17:53:33.656: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec 13 17:53:43.660: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 13 17:53:43.660: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 13 17:53:43.660: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 13 17:53:43.668: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Dec 13 17:53:43.668: INFO: ss-0  172.160.134.165  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:01 +0000 UTC  }]
Dec 13 17:53:43.668: INFO: ss-1  172.160.134.166  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  }]
Dec 13 17:53:43.668: INFO: ss-2  172.160.134.166  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  }]
Dec 13 17:53:43.668: INFO: 
Dec 13 17:53:43.668: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 13 17:53:44.671: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Dec 13 17:53:44.671: INFO: ss-0  172.160.134.165  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:01 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:33 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:01 +0000 UTC  }]
Dec 13 17:53:44.671: INFO: ss-1  172.160.134.166  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  }]
Dec 13 17:53:44.671: INFO: ss-2  172.160.134.166  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  }]
Dec 13 17:53:44.671: INFO: 
Dec 13 17:53:44.671: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 13 17:53:45.673: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Dec 13 17:53:45.673: INFO: ss-1  172.160.134.166  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  }]
Dec 13 17:53:45.674: INFO: ss-2  172.160.134.166  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  }]
Dec 13 17:53:45.674: INFO: 
Dec 13 17:53:45.674: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 13 17:53:46.676: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Dec 13 17:53:46.676: INFO: ss-1  172.160.134.166  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  }]
Dec 13 17:53:46.676: INFO: ss-2  172.160.134.166  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  }]
Dec 13 17:53:46.676: INFO: 
Dec 13 17:53:46.676: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 13 17:53:47.678: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Dec 13 17:53:47.678: INFO: ss-1  172.160.134.166  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  }]
Dec 13 17:53:47.678: INFO: ss-2  172.160.134.166  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  }]
Dec 13 17:53:47.679: INFO: 
Dec 13 17:53:47.679: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 13 17:53:48.681: INFO: POD   NODE             PHASE    GRACE  CONDITIONS
Dec 13 17:53:48.681: INFO: ss-1  172.160.134.166  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  }]
Dec 13 17:53:48.681: INFO: ss-2  172.160.134.166  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-13 17:53:21 +0000 UTC  }]
Dec 13 17:53:48.681: INFO: 
Dec 13 17:53:48.681: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 13 17:53:49.683: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.982577717s
Dec 13 17:53:50.685: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.980627921s
Dec 13 17:53:51.687: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.978539249s
Dec 13 17:53:52.690: INFO: Verifying statefulset ss doesn't scale past 0 for another 976.380039ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2934
Dec 13 17:53:53.692: INFO: Scaling statefulset ss to 0
Dec 13 17:53:53.697: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 13 17:53:53.698: INFO: Deleting all statefulset in ns statefulset-2934
Dec 13 17:53:53.700: INFO: Scaling statefulset ss to 0
Dec 13 17:53:53.704: INFO: Waiting for statefulset status.replicas updated to 0
Dec 13 17:53:53.705: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:53:53.712: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2934" for this suite.
Dec 13 17:53:59.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:53:59.761: INFO: namespace statefulset-2934 deletion completed in 6.047749468s

• [SLOW TEST:58.715 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:53:59.763: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Dec 13 17:53:59.791: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 --namespace=kubectl-9354 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec 13 17:54:06.801: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec 13 17:54:06.801: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:54:08.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9354" for this suite.
Dec 13 17:54:14.812: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:54:14.853: INFO: namespace kubectl-9354 deletion completed in 6.047496568s

• [SLOW TEST:15.091 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:54:14.854: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 13 17:54:28.898: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 13 17:54:28.903: INFO: Pod pod-with-prestop-http-hook still exists
Dec 13 17:54:30.903: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 13 17:54:30.905: INFO: Pod pod-with-prestop-http-hook still exists
Dec 13 17:54:32.903: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 13 17:54:32.905: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:54:32.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2137" for this suite.
Dec 13 17:54:44.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:54:44.971: INFO: namespace container-lifecycle-hook-2137 deletion completed in 12.044659824s

• [SLOW TEST:30.118 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:54:44.971: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-b743ca98-3c13-488b-b222-96148020e71b
STEP: Creating a pod to test consume secrets
Dec 13 17:54:45.002: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5f3ba601-37d5-44ed-a799-7f5bcb751d6c" in namespace "projected-126" to be "success or failure"
Dec 13 17:54:45.004: INFO: Pod "pod-projected-secrets-5f3ba601-37d5-44ed-a799-7f5bcb751d6c": Phase="Pending", Reason="", readiness=false. Elapsed: 1.615812ms
Dec 13 17:54:47.006: INFO: Pod "pod-projected-secrets-5f3ba601-37d5-44ed-a799-7f5bcb751d6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003784982s
Dec 13 17:54:49.008: INFO: Pod "pod-projected-secrets-5f3ba601-37d5-44ed-a799-7f5bcb751d6c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006058513s
Dec 13 17:54:51.010: INFO: Pod "pod-projected-secrets-5f3ba601-37d5-44ed-a799-7f5bcb751d6c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008385858s
Dec 13 17:54:53.013: INFO: Pod "pod-projected-secrets-5f3ba601-37d5-44ed-a799-7f5bcb751d6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.010592845s
STEP: Saw pod success
Dec 13 17:54:53.013: INFO: Pod "pod-projected-secrets-5f3ba601-37d5-44ed-a799-7f5bcb751d6c" satisfied condition "success or failure"
Dec 13 17:54:53.014: INFO: Trying to get logs from node 172.160.134.166 pod pod-projected-secrets-5f3ba601-37d5-44ed-a799-7f5bcb751d6c container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 13 17:54:53.030: INFO: Waiting for pod pod-projected-secrets-5f3ba601-37d5-44ed-a799-7f5bcb751d6c to disappear
Dec 13 17:54:53.034: INFO: Pod pod-projected-secrets-5f3ba601-37d5-44ed-a799-7f5bcb751d6c no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:54:53.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-126" for this suite.
Dec 13 17:54:59.043: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:54:59.084: INFO: namespace projected-126 deletion completed in 6.048856472s

• [SLOW TEST:14.113 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:54:59.085: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-ab9affa8-33e3-4326-bf0a-51fcda4ebb1e
STEP: Creating a pod to test consume secrets
Dec 13 17:54:59.119: INFO: Waiting up to 5m0s for pod "pod-secrets-b1bd9840-8a28-4d6b-8d33-623c49453a89" in namespace "secrets-8692" to be "success or failure"
Dec 13 17:54:59.124: INFO: Pod "pod-secrets-b1bd9840-8a28-4d6b-8d33-623c49453a89": Phase="Pending", Reason="", readiness=false. Elapsed: 4.970678ms
Dec 13 17:55:01.126: INFO: Pod "pod-secrets-b1bd9840-8a28-4d6b-8d33-623c49453a89": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007258467s
Dec 13 17:55:03.128: INFO: Pod "pod-secrets-b1bd9840-8a28-4d6b-8d33-623c49453a89": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009574264s
Dec 13 17:55:05.131: INFO: Pod "pod-secrets-b1bd9840-8a28-4d6b-8d33-623c49453a89": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011999288s
STEP: Saw pod success
Dec 13 17:55:05.131: INFO: Pod "pod-secrets-b1bd9840-8a28-4d6b-8d33-623c49453a89" satisfied condition "success or failure"
Dec 13 17:55:05.132: INFO: Trying to get logs from node 172.160.134.165 pod pod-secrets-b1bd9840-8a28-4d6b-8d33-623c49453a89 container secret-volume-test: <nil>
STEP: delete the pod
Dec 13 17:55:05.171: INFO: Waiting for pod pod-secrets-b1bd9840-8a28-4d6b-8d33-623c49453a89 to disappear
Dec 13 17:55:05.179: INFO: Pod pod-secrets-b1bd9840-8a28-4d6b-8d33-623c49453a89 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:55:05.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8692" for this suite.
Dec 13 17:55:11.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:55:11.229: INFO: namespace secrets-8692 deletion completed in 6.048691625s

• [SLOW TEST:12.145 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:55:11.229: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-4d391169-52da-4ef7-be57-8376aa0c29ec
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-4d391169-52da-4ef7-be57-8376aa0c29ec
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:56:21.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8098" for this suite.
Dec 13 17:56:33.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:56:33.537: INFO: namespace projected-8098 deletion completed in 12.044392107s

• [SLOW TEST:82.307 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:56:33.537: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-7bf76953-2f26-458e-8ab3-7391d3b9c0dd
STEP: Creating configMap with name cm-test-opt-upd-ed72524f-2969-4019-af0f-214fb16754d3
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-7bf76953-2f26-458e-8ab3-7391d3b9c0dd
STEP: Updating configmap cm-test-opt-upd-ed72524f-2969-4019-af0f-214fb16754d3
STEP: Creating configMap with name cm-test-opt-create-d5be7422-96b4-4bec-bc5e-714913248b44
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:56:45.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2959" for this suite.
Dec 13 17:56:57.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:56:57.735: INFO: namespace projected-2959 deletion completed in 12.052600551s

• [SLOW TEST:24.198 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:56:57.736: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 13 17:56:57.776: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8cd63a4c-b16b-4af6-9647-b8b2452eaba3" in namespace "downward-api-4850" to be "success or failure"
Dec 13 17:56:57.778: INFO: Pod "downwardapi-volume-8cd63a4c-b16b-4af6-9647-b8b2452eaba3": Phase="Pending", Reason="", readiness=false. Elapsed: 1.64756ms
Dec 13 17:56:59.780: INFO: Pod "downwardapi-volume-8cd63a4c-b16b-4af6-9647-b8b2452eaba3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004075726s
Dec 13 17:57:01.782: INFO: Pod "downwardapi-volume-8cd63a4c-b16b-4af6-9647-b8b2452eaba3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00643614s
Dec 13 17:57:03.784: INFO: Pod "downwardapi-volume-8cd63a4c-b16b-4af6-9647-b8b2452eaba3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008326072s
STEP: Saw pod success
Dec 13 17:57:03.785: INFO: Pod "downwardapi-volume-8cd63a4c-b16b-4af6-9647-b8b2452eaba3" satisfied condition "success or failure"
Dec 13 17:57:03.786: INFO: Trying to get logs from node 172.160.134.165 pod downwardapi-volume-8cd63a4c-b16b-4af6-9647-b8b2452eaba3 container client-container: <nil>
STEP: delete the pod
Dec 13 17:57:03.798: INFO: Waiting for pod downwardapi-volume-8cd63a4c-b16b-4af6-9647-b8b2452eaba3 to disappear
Dec 13 17:57:03.800: INFO: Pod downwardapi-volume-8cd63a4c-b16b-4af6-9647-b8b2452eaba3 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:57:03.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4850" for this suite.
Dec 13 17:57:09.807: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:57:09.848: INFO: namespace downward-api-4850 deletion completed in 6.046619425s

• [SLOW TEST:12.113 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:57:09.849: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Dec 13 17:57:09.919: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-064082504 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:57:10.009: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8744" for this suite.
Dec 13 17:57:16.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:57:16.064: INFO: namespace kubectl-8744 deletion completed in 6.053511759s

• [SLOW TEST:6.215 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:57:16.064: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 13 17:57:16.087: INFO: Waiting up to 5m0s for pod "pod-33c07c43-aaa7-4cd4-88f5-6544d38a4173" in namespace "emptydir-8444" to be "success or failure"
Dec 13 17:57:16.089: INFO: Pod "pod-33c07c43-aaa7-4cd4-88f5-6544d38a4173": Phase="Pending", Reason="", readiness=false. Elapsed: 1.878736ms
Dec 13 17:57:18.091: INFO: Pod "pod-33c07c43-aaa7-4cd4-88f5-6544d38a4173": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003993408s
Dec 13 17:57:20.093: INFO: Pod "pod-33c07c43-aaa7-4cd4-88f5-6544d38a4173": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006123546s
Dec 13 17:57:22.095: INFO: Pod "pod-33c07c43-aaa7-4cd4-88f5-6544d38a4173": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007959299s
Dec 13 17:57:24.097: INFO: Pod "pod-33c07c43-aaa7-4cd4-88f5-6544d38a4173": Phase="Pending", Reason="", readiness=false. Elapsed: 8.010083882s
Dec 13 17:57:26.100: INFO: Pod "pod-33c07c43-aaa7-4cd4-88f5-6544d38a4173": Phase="Pending", Reason="", readiness=false. Elapsed: 10.012386984s
Dec 13 17:57:28.102: INFO: Pod "pod-33c07c43-aaa7-4cd4-88f5-6544d38a4173": Phase="Pending", Reason="", readiness=false. Elapsed: 12.014504871s
Dec 13 17:57:30.104: INFO: Pod "pod-33c07c43-aaa7-4cd4-88f5-6544d38a4173": Phase="Pending", Reason="", readiness=false. Elapsed: 14.016740467s
Dec 13 17:57:32.106: INFO: Pod "pod-33c07c43-aaa7-4cd4-88f5-6544d38a4173": Phase="Pending", Reason="", readiness=false. Elapsed: 16.018898217s
Dec 13 17:57:34.108: INFO: Pod "pod-33c07c43-aaa7-4cd4-88f5-6544d38a4173": Phase="Pending", Reason="", readiness=false. Elapsed: 18.020998676s
Dec 13 17:57:36.111: INFO: Pod "pod-33c07c43-aaa7-4cd4-88f5-6544d38a4173": Phase="Pending", Reason="", readiness=false. Elapsed: 20.023230788s
Dec 13 17:57:38.113: INFO: Pod "pod-33c07c43-aaa7-4cd4-88f5-6544d38a4173": Phase="Pending", Reason="", readiness=false. Elapsed: 22.025413826s
Dec 13 17:57:40.115: INFO: Pod "pod-33c07c43-aaa7-4cd4-88f5-6544d38a4173": Phase="Pending", Reason="", readiness=false. Elapsed: 24.027521107s
Dec 13 17:57:42.117: INFO: Pod "pod-33c07c43-aaa7-4cd4-88f5-6544d38a4173": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.029712125s
STEP: Saw pod success
Dec 13 17:57:42.117: INFO: Pod "pod-33c07c43-aaa7-4cd4-88f5-6544d38a4173" satisfied condition "success or failure"
Dec 13 17:57:42.118: INFO: Trying to get logs from node 172.160.134.165 pod pod-33c07c43-aaa7-4cd4-88f5-6544d38a4173 container test-container: <nil>
STEP: delete the pod
Dec 13 17:57:42.131: INFO: Waiting for pod pod-33c07c43-aaa7-4cd4-88f5-6544d38a4173 to disappear
Dec 13 17:57:42.134: INFO: Pod pod-33c07c43-aaa7-4cd4-88f5-6544d38a4173 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:57:42.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8444" for this suite.
Dec 13 17:57:48.144: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:57:48.185: INFO: namespace emptydir-8444 deletion completed in 6.048706332s

• [SLOW TEST:32.121 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:57:48.185: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-2ebcba59-9722-467b-95ae-579a99c6d7dc
STEP: Creating a pod to test consume secrets
Dec 13 17:57:48.213: INFO: Waiting up to 5m0s for pod "pod-secrets-7dffee48-046e-4dbb-a9ee-26cb4ac06e1f" in namespace "secrets-476" to be "success or failure"
Dec 13 17:57:48.221: INFO: Pod "pod-secrets-7dffee48-046e-4dbb-a9ee-26cb4ac06e1f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.864201ms
Dec 13 17:57:50.223: INFO: Pod "pod-secrets-7dffee48-046e-4dbb-a9ee-26cb4ac06e1f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010212952s
Dec 13 17:57:52.225: INFO: Pod "pod-secrets-7dffee48-046e-4dbb-a9ee-26cb4ac06e1f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012437054s
Dec 13 17:57:54.227: INFO: Pod "pod-secrets-7dffee48-046e-4dbb-a9ee-26cb4ac06e1f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014524365s
STEP: Saw pod success
Dec 13 17:57:54.227: INFO: Pod "pod-secrets-7dffee48-046e-4dbb-a9ee-26cb4ac06e1f" satisfied condition "success or failure"
Dec 13 17:57:54.229: INFO: Trying to get logs from node 172.160.134.165 pod pod-secrets-7dffee48-046e-4dbb-a9ee-26cb4ac06e1f container secret-volume-test: <nil>
STEP: delete the pod
Dec 13 17:57:54.242: INFO: Waiting for pod pod-secrets-7dffee48-046e-4dbb-a9ee-26cb4ac06e1f to disappear
Dec 13 17:57:54.243: INFO: Pod pod-secrets-7dffee48-046e-4dbb-a9ee-26cb4ac06e1f no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:57:54.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-476" for this suite.
Dec 13 17:58:00.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:58:00.292: INFO: namespace secrets-476 deletion completed in 6.046825884s

• [SLOW TEST:12.107 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:58:00.292: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:58:11.334: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9020" for this suite.
Dec 13 17:58:17.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:58:17.383: INFO: namespace resourcequota-9020 deletion completed in 6.047381625s

• [SLOW TEST:17.091 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:58:17.383: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:58:23.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-817" for this suite.
Dec 13 17:59:07.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:59:07.480: INFO: namespace kubelet-test-817 deletion completed in 44.045525153s

• [SLOW TEST:50.097 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:59:07.480: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 13 17:59:07.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-6215'
Dec 13 17:59:07.944: INFO: stderr: ""
Dec 13 17:59:07.944: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Dec 13 17:59:17.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pod e2e-test-httpd-pod --namespace=kubectl-6215 -o json'
Dec 13 17:59:18.097: INFO: stderr: ""
Dec 13 17:59:18.097: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2019-12-13T17:59:07Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-6215\",\n        \"resourceVersion\": \"118387\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-6215/pods/e2e-test-httpd-pod\",\n        \"uid\": \"03bf5633-2fb7-41d9-bf39-99a100bb669d\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-zjzz9\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"172.160.134.165\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-zjzz9\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-zjzz9\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-13T17:59:07Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-13T17:59:15Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-13T17:59:15Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-13T17:59:07Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://f7f3076e423c305a861f2b326a493561c33d35c3bb923074df71656520265925\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-12-13T17:59:14Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"172.160.134.165\",\n        \"phase\": \"Running\",\n        \"podIP\": \"172.160.134.202\",\n        \"podIPs\": [\n            {\n                \"ip\": \"172.160.134.202\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-12-13T17:59:07Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec 13 17:59:18.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 replace -f - --namespace=kubectl-6215'
Dec 13 17:59:18.343: INFO: stderr: ""
Dec 13 17:59:18.343: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Dec 13 17:59:18.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 delete pods e2e-test-httpd-pod --namespace=kubectl-6215'
Dec 13 17:59:21.310: INFO: stderr: ""
Dec 13 17:59:21.310: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:59:21.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6215" for this suite.
Dec 13 17:59:27.321: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:59:27.360: INFO: namespace kubectl-6215 deletion completed in 6.047514277s

• [SLOW TEST:19.879 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:59:27.360: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 13 17:59:27.387: INFO: Waiting up to 5m0s for pod "pod-d6718814-ee44-45eb-a41a-5e813b00d9ee" in namespace "emptydir-4843" to be "success or failure"
Dec 13 17:59:27.390: INFO: Pod "pod-d6718814-ee44-45eb-a41a-5e813b00d9ee": Phase="Pending", Reason="", readiness=false. Elapsed: 3.615326ms
Dec 13 17:59:29.393: INFO: Pod "pod-d6718814-ee44-45eb-a41a-5e813b00d9ee": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005963151s
Dec 13 17:59:31.395: INFO: Pod "pod-d6718814-ee44-45eb-a41a-5e813b00d9ee": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008070177s
Dec 13 17:59:33.397: INFO: Pod "pod-d6718814-ee44-45eb-a41a-5e813b00d9ee": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010139638s
Dec 13 17:59:35.399: INFO: Pod "pod-d6718814-ee44-45eb-a41a-5e813b00d9ee": Phase="Pending", Reason="", readiness=false. Elapsed: 8.01231743s
Dec 13 17:59:37.401: INFO: Pod "pod-d6718814-ee44-45eb-a41a-5e813b00d9ee": Phase="Pending", Reason="", readiness=false. Elapsed: 10.014434031s
Dec 13 17:59:39.403: INFO: Pod "pod-d6718814-ee44-45eb-a41a-5e813b00d9ee": Phase="Pending", Reason="", readiness=false. Elapsed: 12.016598539s
Dec 13 17:59:41.405: INFO: Pod "pod-d6718814-ee44-45eb-a41a-5e813b00d9ee": Phase="Pending", Reason="", readiness=false. Elapsed: 14.018668836s
Dec 13 17:59:43.407: INFO: Pod "pod-d6718814-ee44-45eb-a41a-5e813b00d9ee": Phase="Pending", Reason="", readiness=false. Elapsed: 16.020568738s
Dec 13 17:59:45.409: INFO: Pod "pod-d6718814-ee44-45eb-a41a-5e813b00d9ee": Phase="Pending", Reason="", readiness=false. Elapsed: 18.022816101s
Dec 13 17:59:47.411: INFO: Pod "pod-d6718814-ee44-45eb-a41a-5e813b00d9ee": Phase="Pending", Reason="", readiness=false. Elapsed: 20.02491061s
Dec 13 17:59:49.414: INFO: Pod "pod-d6718814-ee44-45eb-a41a-5e813b00d9ee": Phase="Pending", Reason="", readiness=false. Elapsed: 22.027228712s
Dec 13 17:59:51.416: INFO: Pod "pod-d6718814-ee44-45eb-a41a-5e813b00d9ee": Phase="Pending", Reason="", readiness=false. Elapsed: 24.029346021s
Dec 13 17:59:53.418: INFO: Pod "pod-d6718814-ee44-45eb-a41a-5e813b00d9ee": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.031445884s
STEP: Saw pod success
Dec 13 17:59:53.418: INFO: Pod "pod-d6718814-ee44-45eb-a41a-5e813b00d9ee" satisfied condition "success or failure"
Dec 13 17:59:53.419: INFO: Trying to get logs from node 172.160.134.165 pod pod-d6718814-ee44-45eb-a41a-5e813b00d9ee container test-container: <nil>
STEP: delete the pod
Dec 13 17:59:53.432: INFO: Waiting for pod pod-d6718814-ee44-45eb-a41a-5e813b00d9ee to disappear
Dec 13 17:59:53.435: INFO: Pod pod-d6718814-ee44-45eb-a41a-5e813b00d9ee no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 17:59:53.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4843" for this suite.
Dec 13 17:59:59.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 17:59:59.490: INFO: namespace emptydir-4843 deletion completed in 6.053649309s

• [SLOW TEST:32.130 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 17:59:59.490: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-9686
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 13 17:59:59.516: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 13 18:00:33.555: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.160.134.207:8080/dial?request=hostName&protocol=udp&host=172.160.134.206&port=8081&tries=1'] Namespace:pod-network-test-9686 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 13 18:00:33.555: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 18:00:33.996: INFO: Waiting for endpoints: map[]
Dec 13 18:00:34.003: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.160.134.207:8080/dial?request=hostName&protocol=udp&host=172.160.134.205&port=8081&tries=1'] Namespace:pod-network-test-9686 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 13 18:00:34.003: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 18:00:34.268: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:00:34.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9686" for this suite.
Dec 13 18:00:46.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:00:46.317: INFO: namespace pod-network-test-9686 deletion completed in 12.046432725s

• [SLOW TEST:46.827 seconds]
[sig-network] Networking
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:00:46.317: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-214
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 13 18:00:46.338: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 13 18:01:14.377: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.160.134.22:8080/dial?request=hostName&protocol=http&host=172.160.134.209&port=8080&tries=1'] Namespace:pod-network-test-214 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 13 18:01:14.377: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 18:01:14.531: INFO: Waiting for endpoints: map[]
Dec 13 18:01:14.533: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://172.160.134.22:8080/dial?request=hostName&protocol=http&host=172.160.134.219&port=8080&tries=1'] Namespace:pod-network-test-214 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 13 18:01:14.533: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 18:01:14.781: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:01:14.781: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-214" for this suite.
Dec 13 18:01:26.791: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:01:26.831: INFO: namespace pod-network-test-214 deletion completed in 12.047344702s

• [SLOW TEST:40.513 seconds]
[sig-network] Networking
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:01:26.831: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 13 18:01:26.854: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:01:33.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5065" for this suite.
Dec 13 18:01:39.283: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:01:39.322: INFO: namespace init-container-5065 deletion completed in 6.046251203s

• [SLOW TEST:12.491 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:01:39.324: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-cf8d8813-026f-4f4b-9007-fa2e453b5aa3
STEP: Creating a pod to test consume secrets
Dec 13 18:01:39.366: INFO: Waiting up to 5m0s for pod "pod-secrets-f4b8bb7f-95ff-4505-b4af-bdad1e933132" in namespace "secrets-5284" to be "success or failure"
Dec 13 18:01:39.377: INFO: Pod "pod-secrets-f4b8bb7f-95ff-4505-b4af-bdad1e933132": Phase="Pending", Reason="", readiness=false. Elapsed: 10.960031ms
Dec 13 18:01:41.379: INFO: Pod "pod-secrets-f4b8bb7f-95ff-4505-b4af-bdad1e933132": Phase="Pending", Reason="", readiness=false. Elapsed: 2.013562401s
Dec 13 18:01:43.381: INFO: Pod "pod-secrets-f4b8bb7f-95ff-4505-b4af-bdad1e933132": Phase="Pending", Reason="", readiness=false. Elapsed: 4.015418121s
Dec 13 18:01:45.384: INFO: Pod "pod-secrets-f4b8bb7f-95ff-4505-b4af-bdad1e933132": Phase="Pending", Reason="", readiness=false. Elapsed: 6.017797635s
Dec 13 18:01:47.386: INFO: Pod "pod-secrets-f4b8bb7f-95ff-4505-b4af-bdad1e933132": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.020048855s
STEP: Saw pod success
Dec 13 18:01:47.386: INFO: Pod "pod-secrets-f4b8bb7f-95ff-4505-b4af-bdad1e933132" satisfied condition "success or failure"
Dec 13 18:01:47.387: INFO: Trying to get logs from node 172.160.134.166 pod pod-secrets-f4b8bb7f-95ff-4505-b4af-bdad1e933132 container secret-volume-test: <nil>
STEP: delete the pod
Dec 13 18:01:47.425: INFO: Waiting for pod pod-secrets-f4b8bb7f-95ff-4505-b4af-bdad1e933132 to disappear
Dec 13 18:01:47.428: INFO: Pod pod-secrets-f4b8bb7f-95ff-4505-b4af-bdad1e933132 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:01:47.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5284" for this suite.
Dec 13 18:01:53.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:01:53.480: INFO: namespace secrets-5284 deletion completed in 6.049720104s

• [SLOW TEST:14.155 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:01:53.480: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Dec 13 18:01:53.508: INFO: Waiting up to 5m0s for pod "pod-83c02f5d-1551-4305-9a50-022e54b11e65" in namespace "emptydir-5116" to be "success or failure"
Dec 13 18:01:53.510: INFO: Pod "pod-83c02f5d-1551-4305-9a50-022e54b11e65": Phase="Pending", Reason="", readiness=false. Elapsed: 1.89966ms
Dec 13 18:01:55.512: INFO: Pod "pod-83c02f5d-1551-4305-9a50-022e54b11e65": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004150998s
Dec 13 18:01:57.518: INFO: Pod "pod-83c02f5d-1551-4305-9a50-022e54b11e65": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010023964s
Dec 13 18:01:59.520: INFO: Pod "pod-83c02f5d-1551-4305-9a50-022e54b11e65": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012258571s
Dec 13 18:02:01.522: INFO: Pod "pod-83c02f5d-1551-4305-9a50-022e54b11e65": Phase="Pending", Reason="", readiness=false. Elapsed: 8.014498522s
Dec 13 18:02:03.525: INFO: Pod "pod-83c02f5d-1551-4305-9a50-022e54b11e65": Phase="Pending", Reason="", readiness=false. Elapsed: 10.016789587s
Dec 13 18:02:05.527: INFO: Pod "pod-83c02f5d-1551-4305-9a50-022e54b11e65": Phase="Pending", Reason="", readiness=false. Elapsed: 12.019139976s
Dec 13 18:02:07.529: INFO: Pod "pod-83c02f5d-1551-4305-9a50-022e54b11e65": Phase="Pending", Reason="", readiness=false. Elapsed: 14.021282312s
Dec 13 18:02:09.531: INFO: Pod "pod-83c02f5d-1551-4305-9a50-022e54b11e65": Phase="Pending", Reason="", readiness=false. Elapsed: 16.023694374s
Dec 13 18:02:11.534: INFO: Pod "pod-83c02f5d-1551-4305-9a50-022e54b11e65": Phase="Pending", Reason="", readiness=false. Elapsed: 18.02603879s
Dec 13 18:02:13.536: INFO: Pod "pod-83c02f5d-1551-4305-9a50-022e54b11e65": Phase="Pending", Reason="", readiness=false. Elapsed: 20.027841199s
Dec 13 18:02:15.538: INFO: Pod "pod-83c02f5d-1551-4305-9a50-022e54b11e65": Phase="Pending", Reason="", readiness=false. Elapsed: 22.030171394s
Dec 13 18:02:17.540: INFO: Pod "pod-83c02f5d-1551-4305-9a50-022e54b11e65": Phase="Pending", Reason="", readiness=false. Elapsed: 24.032553005s
Dec 13 18:02:19.543: INFO: Pod "pod-83c02f5d-1551-4305-9a50-022e54b11e65": Phase="Pending", Reason="", readiness=false. Elapsed: 26.034862036s
Dec 13 18:02:21.545: INFO: Pod "pod-83c02f5d-1551-4305-9a50-022e54b11e65": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.037164409s
STEP: Saw pod success
Dec 13 18:02:21.545: INFO: Pod "pod-83c02f5d-1551-4305-9a50-022e54b11e65" satisfied condition "success or failure"
Dec 13 18:02:21.546: INFO: Trying to get logs from node 172.160.134.166 pod pod-83c02f5d-1551-4305-9a50-022e54b11e65 container test-container: <nil>
STEP: delete the pod
Dec 13 18:02:21.562: INFO: Waiting for pod pod-83c02f5d-1551-4305-9a50-022e54b11e65 to disappear
Dec 13 18:02:21.585: INFO: Pod pod-83c02f5d-1551-4305-9a50-022e54b11e65 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:02:21.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5116" for this suite.
Dec 13 18:02:27.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:02:27.635: INFO: namespace emptydir-5116 deletion completed in 6.047089821s

• [SLOW TEST:34.155 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:02:27.636: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 13 18:02:41.709: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 13 18:02:41.711: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 13 18:02:43.711: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 13 18:02:43.714: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 13 18:02:45.711: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 13 18:02:45.713: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:02:45.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2855" for this suite.
Dec 13 18:02:57.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:02:57.775: INFO: namespace container-lifecycle-hook-2855 deletion completed in 12.060135651s

• [SLOW TEST:30.140 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:02:57.775: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 13 18:02:58.790: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 13 18:03:00.796: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711856978, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711856978, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711856978, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711856978, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 18:03:02.799: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711856978, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711856978, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711856978, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711856978, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 13 18:03:05.803: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
Dec 13 18:03:05.817: INFO: Waiting for webhook configuration to be ready...
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:03:05.964: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1010" for this suite.
Dec 13 18:03:17.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:03:18.014: INFO: namespace webhook-1010 deletion completed in 12.047821369s
STEP: Destroying namespace "webhook-1010-markers" for this suite.
Dec 13 18:03:24.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:03:24.071: INFO: namespace webhook-1010-markers deletion completed in 6.05657932s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:26.307 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:03:24.083: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-4036, will wait for the garbage collector to delete the pods
Dec 13 18:03:52.169: INFO: Deleting Job.batch foo took: 3.820314ms
Dec 13 18:03:52.469: INFO: Terminating Job.batch foo pods took: 300.209184ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:04:25.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4036" for this suite.
Dec 13 18:04:31.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:04:31.318: INFO: namespace job-4036 deletion completed in 6.045660283s

• [SLOW TEST:67.235 seconds]
[sig-apps] Job
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:04:31.318: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-sdcd
STEP: Creating a pod to test atomic-volume-subpath
Dec 13 18:04:31.349: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-sdcd" in namespace "subpath-3637" to be "success or failure"
Dec 13 18:04:31.353: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.106378ms
Dec 13 18:04:33.355: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006316478s
Dec 13 18:04:35.357: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008580909s
Dec 13 18:04:37.363: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Pending", Reason="", readiness=false. Elapsed: 6.014099719s
Dec 13 18:04:39.365: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016300213s
Dec 13 18:04:41.367: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.018441156s
Dec 13 18:04:43.369: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Pending", Reason="", readiness=false. Elapsed: 12.020650884s
Dec 13 18:04:45.372: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Pending", Reason="", readiness=false. Elapsed: 14.022844019s
Dec 13 18:04:47.374: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Pending", Reason="", readiness=false. Elapsed: 16.024871822s
Dec 13 18:04:49.376: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Pending", Reason="", readiness=false. Elapsed: 18.02723647s
Dec 13 18:04:51.378: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Pending", Reason="", readiness=false. Elapsed: 20.029590949s
Dec 13 18:04:53.380: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Pending", Reason="", readiness=false. Elapsed: 22.031520326s
Dec 13 18:04:55.382: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Pending", Reason="", readiness=false. Elapsed: 24.033587446s
Dec 13 18:04:57.385: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Pending", Reason="", readiness=false. Elapsed: 26.035877516s
Dec 13 18:04:59.387: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Running", Reason="", readiness=true. Elapsed: 28.037909206s
Dec 13 18:05:01.389: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Running", Reason="", readiness=true. Elapsed: 30.040012262s
Dec 13 18:05:03.391: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Running", Reason="", readiness=true. Elapsed: 32.041913604s
Dec 13 18:05:05.393: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Running", Reason="", readiness=true. Elapsed: 34.044303935s
Dec 13 18:05:07.395: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Running", Reason="", readiness=true. Elapsed: 36.046467945s
Dec 13 18:05:09.397: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Running", Reason="", readiness=true. Elapsed: 38.048733081s
Dec 13 18:05:11.400: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Running", Reason="", readiness=true. Elapsed: 40.051005372s
Dec 13 18:05:13.402: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Running", Reason="", readiness=true. Elapsed: 42.053347518s
Dec 13 18:05:15.404: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Running", Reason="", readiness=true. Elapsed: 44.055558704s
Dec 13 18:05:17.406: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Running", Reason="", readiness=true. Elapsed: 46.057797503s
Dec 13 18:05:19.409: INFO: Pod "pod-subpath-test-configmap-sdcd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 48.060043164s
STEP: Saw pod success
Dec 13 18:05:19.409: INFO: Pod "pod-subpath-test-configmap-sdcd" satisfied condition "success or failure"
Dec 13 18:05:19.410: INFO: Trying to get logs from node 172.160.134.166 pod pod-subpath-test-configmap-sdcd container test-container-subpath-configmap-sdcd: <nil>
STEP: delete the pod
Dec 13 18:05:19.434: INFO: Waiting for pod pod-subpath-test-configmap-sdcd to disappear
Dec 13 18:05:19.442: INFO: Pod pod-subpath-test-configmap-sdcd no longer exists
STEP: Deleting pod pod-subpath-test-configmap-sdcd
Dec 13 18:05:19.442: INFO: Deleting pod "pod-subpath-test-configmap-sdcd" in namespace "subpath-3637"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:05:19.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3637" for this suite.
Dec 13 18:05:25.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:05:25.491: INFO: namespace subpath-3637 deletion completed in 6.045933119s

• [SLOW TEST:54.172 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:05:25.491: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 13 18:05:26.127: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 13 18:05:28.132: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711857126, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711857126, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711857126, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711857126, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 18:05:30.135: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711857126, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711857126, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711857126, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711857126, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 18:05:32.135: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711857126, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711857126, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711857126, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711857126, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 13 18:05:35.142: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
Dec 13 18:05:35.157: INFO: Waiting for webhook configuration to be ready...
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Dec 13 18:05:43.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 attach --namespace=webhook-114 to-be-attached-pod -i -c=container1'
Dec 13 18:05:43.403: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:05:43.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-114" for this suite.
Dec 13 18:05:55.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:05:55.457: INFO: namespace webhook-114 deletion completed in 12.048015875s
STEP: Destroying namespace "webhook-114-markers" for this suite.
Dec 13 18:06:01.463: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:06:01.501: INFO: namespace webhook-114-markers deletion completed in 6.04443239s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:36.016 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:06:01.509: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 13 18:06:01.544: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a9c9b425-252e-4973-beb5-355d4bd26272" in namespace "projected-1107" to be "success or failure"
Dec 13 18:06:01.551: INFO: Pod "downwardapi-volume-a9c9b425-252e-4973-beb5-355d4bd26272": Phase="Pending", Reason="", readiness=false. Elapsed: 6.418235ms
Dec 13 18:06:03.553: INFO: Pod "downwardapi-volume-a9c9b425-252e-4973-beb5-355d4bd26272": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008712631s
Dec 13 18:06:05.555: INFO: Pod "downwardapi-volume-a9c9b425-252e-4973-beb5-355d4bd26272": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011105255s
Dec 13 18:06:07.558: INFO: Pod "downwardapi-volume-a9c9b425-252e-4973-beb5-355d4bd26272": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013376576s
Dec 13 18:06:09.561: INFO: Pod "downwardapi-volume-a9c9b425-252e-4973-beb5-355d4bd26272": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.016590405s
STEP: Saw pod success
Dec 13 18:06:09.561: INFO: Pod "downwardapi-volume-a9c9b425-252e-4973-beb5-355d4bd26272" satisfied condition "success or failure"
Dec 13 18:06:09.563: INFO: Trying to get logs from node 172.160.134.166 pod downwardapi-volume-a9c9b425-252e-4973-beb5-355d4bd26272 container client-container: <nil>
STEP: delete the pod
Dec 13 18:06:09.577: INFO: Waiting for pod downwardapi-volume-a9c9b425-252e-4973-beb5-355d4bd26272 to disappear
Dec 13 18:06:09.584: INFO: Pod downwardapi-volume-a9c9b425-252e-4973-beb5-355d4bd26272 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:06:09.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1107" for this suite.
Dec 13 18:06:15.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:06:15.641: INFO: namespace projected-1107 deletion completed in 6.054680223s

• [SLOW TEST:14.132 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:06:15.641: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-bb0634e5-a00e-4a8f-8e1b-e59b1eb8fd2a
STEP: Creating a pod to test consume configMaps
Dec 13 18:06:15.672: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-211bf149-b378-46d0-98f0-432cd462d839" in namespace "projected-8117" to be "success or failure"
Dec 13 18:06:15.674: INFO: Pod "pod-projected-configmaps-211bf149-b378-46d0-98f0-432cd462d839": Phase="Pending", Reason="", readiness=false. Elapsed: 2.45339ms
Dec 13 18:06:17.676: INFO: Pod "pod-projected-configmaps-211bf149-b378-46d0-98f0-432cd462d839": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004707485s
Dec 13 18:06:19.679: INFO: Pod "pod-projected-configmaps-211bf149-b378-46d0-98f0-432cd462d839": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006924558s
Dec 13 18:06:21.681: INFO: Pod "pod-projected-configmaps-211bf149-b378-46d0-98f0-432cd462d839": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009028135s
Dec 13 18:06:23.683: INFO: Pod "pod-projected-configmaps-211bf149-b378-46d0-98f0-432cd462d839": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.011489393s
STEP: Saw pod success
Dec 13 18:06:23.683: INFO: Pod "pod-projected-configmaps-211bf149-b378-46d0-98f0-432cd462d839" satisfied condition "success or failure"
Dec 13 18:06:23.685: INFO: Trying to get logs from node 172.160.134.166 pod pod-projected-configmaps-211bf149-b378-46d0-98f0-432cd462d839 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 13 18:06:23.717: INFO: Waiting for pod pod-projected-configmaps-211bf149-b378-46d0-98f0-432cd462d839 to disappear
Dec 13 18:06:23.719: INFO: Pod pod-projected-configmaps-211bf149-b378-46d0-98f0-432cd462d839 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:06:23.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8117" for this suite.
Dec 13 18:06:29.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:06:29.768: INFO: namespace projected-8117 deletion completed in 6.047281669s

• [SLOW TEST:14.127 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:06:29.769: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Dec 13 18:06:29.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 cluster-info'
Dec 13 18:06:29.895: INFO: stderr: ""
Dec 13 18:06:29.895: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.254.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:06:29.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2609" for this suite.
Dec 13 18:06:35.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:06:35.943: INFO: namespace kubectl-2609 deletion completed in 6.045915648s

• [SLOW TEST:6.174 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:06:35.943: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 13 18:06:35.971: INFO: Waiting up to 5m0s for pod "downward-api-93724b74-87ce-4a7f-91e7-aff4e1204c39" in namespace "downward-api-4168" to be "success or failure"
Dec 13 18:06:35.973: INFO: Pod "downward-api-93724b74-87ce-4a7f-91e7-aff4e1204c39": Phase="Pending", Reason="", readiness=false. Elapsed: 1.248092ms
Dec 13 18:06:37.975: INFO: Pod "downward-api-93724b74-87ce-4a7f-91e7-aff4e1204c39": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00344469s
Dec 13 18:06:39.977: INFO: Pod "downward-api-93724b74-87ce-4a7f-91e7-aff4e1204c39": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00583318s
Dec 13 18:06:41.980: INFO: Pod "downward-api-93724b74-87ce-4a7f-91e7-aff4e1204c39": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008488971s
STEP: Saw pod success
Dec 13 18:06:41.980: INFO: Pod "downward-api-93724b74-87ce-4a7f-91e7-aff4e1204c39" satisfied condition "success or failure"
Dec 13 18:06:41.981: INFO: Trying to get logs from node 172.160.134.165 pod downward-api-93724b74-87ce-4a7f-91e7-aff4e1204c39 container dapi-container: <nil>
STEP: delete the pod
Dec 13 18:06:42.002: INFO: Waiting for pod downward-api-93724b74-87ce-4a7f-91e7-aff4e1204c39 to disappear
Dec 13 18:06:42.006: INFO: Pod downward-api-93724b74-87ce-4a7f-91e7-aff4e1204c39 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:06:42.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4168" for this suite.
Dec 13 18:06:48.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:06:48.058: INFO: namespace downward-api-4168 deletion completed in 6.05014569s

• [SLOW TEST:12.115 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:06:48.058: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 18:06:48.085: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-cf18882e-e796-4daa-931f-2baad25348bc" in namespace "security-context-test-2971" to be "success or failure"
Dec 13 18:06:48.088: INFO: Pod "busybox-privileged-false-cf18882e-e796-4daa-931f-2baad25348bc": Phase="Pending", Reason="", readiness=false. Elapsed: 3.200944ms
Dec 13 18:06:50.091: INFO: Pod "busybox-privileged-false-cf18882e-e796-4daa-931f-2baad25348bc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005578537s
Dec 13 18:06:52.093: INFO: Pod "busybox-privileged-false-cf18882e-e796-4daa-931f-2baad25348bc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007982943s
Dec 13 18:06:54.095: INFO: Pod "busybox-privileged-false-cf18882e-e796-4daa-931f-2baad25348bc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010265798s
Dec 13 18:06:54.096: INFO: Pod "busybox-privileged-false-cf18882e-e796-4daa-931f-2baad25348bc" satisfied condition "success or failure"
Dec 13 18:06:54.101: INFO: Got logs for pod "busybox-privileged-false-cf18882e-e796-4daa-931f-2baad25348bc": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:06:54.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2971" for this suite.
Dec 13 18:07:00.129: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:07:00.169: INFO: namespace security-context-test-2971 deletion completed in 6.066087645s

• [SLOW TEST:12.110 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:07:00.169: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-4c0b041c-143f-485f-af12-f420ae91930d
STEP: Creating a pod to test consume configMaps
Dec 13 18:07:00.202: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f2e8c6c9-7fdd-48f4-83a3-b4145a2b3511" in namespace "projected-7537" to be "success or failure"
Dec 13 18:07:00.205: INFO: Pod "pod-projected-configmaps-f2e8c6c9-7fdd-48f4-83a3-b4145a2b3511": Phase="Pending", Reason="", readiness=false. Elapsed: 2.569994ms
Dec 13 18:07:02.207: INFO: Pod "pod-projected-configmaps-f2e8c6c9-7fdd-48f4-83a3-b4145a2b3511": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004914222s
Dec 13 18:07:04.209: INFO: Pod "pod-projected-configmaps-f2e8c6c9-7fdd-48f4-83a3-b4145a2b3511": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00695744s
Dec 13 18:07:06.212: INFO: Pod "pod-projected-configmaps-f2e8c6c9-7fdd-48f4-83a3-b4145a2b3511": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009242651s
STEP: Saw pod success
Dec 13 18:07:06.212: INFO: Pod "pod-projected-configmaps-f2e8c6c9-7fdd-48f4-83a3-b4145a2b3511" satisfied condition "success or failure"
Dec 13 18:07:06.213: INFO: Trying to get logs from node 172.160.134.165 pod pod-projected-configmaps-f2e8c6c9-7fdd-48f4-83a3-b4145a2b3511 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 13 18:07:06.231: INFO: Waiting for pod pod-projected-configmaps-f2e8c6c9-7fdd-48f4-83a3-b4145a2b3511 to disappear
Dec 13 18:07:06.235: INFO: Pod pod-projected-configmaps-f2e8c6c9-7fdd-48f4-83a3-b4145a2b3511 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:07:06.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7537" for this suite.
Dec 13 18:07:12.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:07:12.288: INFO: namespace projected-7537 deletion completed in 6.050309862s

• [SLOW TEST:12.119 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:07:12.288: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 13 18:07:12.311: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 13 18:07:12.316: INFO: Waiting for terminating namespaces to be deleted...
Dec 13 18:07:12.317: INFO: 
Logging pods the kubelet thinks is on node 172.160.134.165 before test
Dec 13 18:07:12.320: INFO: iag-172.160.134.165 from kube-system started at 2019-12-12 13:53:36 +0000 UTC (1 container statuses recorded)
Dec 13 18:07:12.320: INFO: 	Container iag ready: true, restart count 0
Dec 13 18:07:12.320: INFO: sonobuoy-e2e-job-acb159fe38ea4959 from sonobuoy started at 2019-12-13 17:43:15 +0000 UTC (2 container statuses recorded)
Dec 13 18:07:12.320: INFO: 	Container e2e ready: true, restart count 0
Dec 13 18:07:12.320: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 13 18:07:12.320: INFO: sonobuoy-systemd-logs-daemon-set-5a2f946422e448af-pq5l8 from sonobuoy started at 2019-12-13 17:43:15 +0000 UTC (2 container statuses recorded)
Dec 13 18:07:12.320: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 13 18:07:12.320: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 13 18:07:12.320: INFO: 
Logging pods the kubelet thinks is on node 172.160.134.166 before test
Dec 13 18:07:12.328: INFO: coredns-6cf786c879-zgnqd from kube-system started at 2019-12-12 19:44:20 +0000 UTC (1 container statuses recorded)
Dec 13 18:07:12.328: INFO: 	Container coredns ready: true, restart count 0
Dec 13 18:07:12.328: INFO: sonobuoy from sonobuoy started at 2019-12-13 17:42:49 +0000 UTC (1 container statuses recorded)
Dec 13 18:07:12.328: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 13 18:07:12.328: INFO: sonobuoy-systemd-logs-daemon-set-5a2f946422e448af-cjc42 from sonobuoy started at 2019-12-13 17:43:15 +0000 UTC (2 container statuses recorded)
Dec 13 18:07:12.328: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 13 18:07:12.328: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-12e78e19-fc97-47cb-8499-80eed2de8d2e 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-12e78e19-fc97-47cb-8499-80eed2de8d2e off the node 172.160.134.166
STEP: verifying the node doesn't have the label kubernetes.io/e2e-12e78e19-fc97-47cb-8499-80eed2de8d2e
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:12:28.406: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9945" for this suite.
Dec 13 18:12:38.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:12:38.460: INFO: namespace sched-pred-9945 deletion completed in 10.051680518s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:326.172 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:12:38.460: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 13 18:12:43.505: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:12:43.533: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-846" for this suite.
Dec 13 18:12:49.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:12:49.583: INFO: namespace container-runtime-846 deletion completed in 6.048027435s

• [SLOW TEST:11.123 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:12:49.583: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:13:06.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9450" for this suite.
Dec 13 18:13:12.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:13:12.678: INFO: namespace resourcequota-9450 deletion completed in 6.048953875s

• [SLOW TEST:23.095 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:13:12.678: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-7909
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-7909
Dec 13 18:13:12.714: INFO: Found 0 stateful pods, waiting for 1
Dec 13 18:13:22.717: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 13 18:13:22.727: INFO: Deleting all statefulset in ns statefulset-7909
Dec 13 18:13:22.735: INFO: Scaling statefulset ss to 0
Dec 13 18:13:32.756: INFO: Waiting for statefulset status.replicas updated to 0
Dec 13 18:13:32.757: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:13:32.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7909" for this suite.
Dec 13 18:13:38.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:13:38.823: INFO: namespace statefulset-7909 deletion completed in 6.057120645s

• [SLOW TEST:26.145 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:13:38.824: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec 13 18:13:38.849: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:14:02.364: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9213" for this suite.
Dec 13 18:14:08.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:14:08.414: INFO: namespace crd-publish-openapi-9213 deletion completed in 6.047903245s

• [SLOW TEST:29.589 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:14:08.414: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:15:04.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3500" for this suite.
Dec 13 18:15:10.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:15:10.488: INFO: namespace job-3500 deletion completed in 6.047416372s

• [SLOW TEST:62.074 seconds]
[sig-apps] Job
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:15:10.488: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-5466/secret-test-37d858a3-eb65-4d5c-bf1f-c732d2d55496
STEP: Creating a pod to test consume secrets
Dec 13 18:15:10.516: INFO: Waiting up to 5m0s for pod "pod-configmaps-605dff68-8942-4647-bed9-810eb1b7b9dd" in namespace "secrets-5466" to be "success or failure"
Dec 13 18:15:10.518: INFO: Pod "pod-configmaps-605dff68-8942-4647-bed9-810eb1b7b9dd": Phase="Pending", Reason="", readiness=false. Elapsed: 1.752661ms
Dec 13 18:15:12.520: INFO: Pod "pod-configmaps-605dff68-8942-4647-bed9-810eb1b7b9dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004017384s
Dec 13 18:15:14.522: INFO: Pod "pod-configmaps-605dff68-8942-4647-bed9-810eb1b7b9dd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006379462s
Dec 13 18:15:16.524: INFO: Pod "pod-configmaps-605dff68-8942-4647-bed9-810eb1b7b9dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008730868s
STEP: Saw pod success
Dec 13 18:15:16.525: INFO: Pod "pod-configmaps-605dff68-8942-4647-bed9-810eb1b7b9dd" satisfied condition "success or failure"
Dec 13 18:15:16.526: INFO: Trying to get logs from node 172.160.134.165 pod pod-configmaps-605dff68-8942-4647-bed9-810eb1b7b9dd container env-test: <nil>
STEP: delete the pod
Dec 13 18:15:16.547: INFO: Waiting for pod pod-configmaps-605dff68-8942-4647-bed9-810eb1b7b9dd to disappear
Dec 13 18:15:16.556: INFO: Pod pod-configmaps-605dff68-8942-4647-bed9-810eb1b7b9dd no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:15:16.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5466" for this suite.
Dec 13 18:15:22.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:15:22.605: INFO: namespace secrets-5466 deletion completed in 6.046787192s

• [SLOW TEST:12.117 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:15:22.605: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-5986
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5986 to expose endpoints map[]
Dec 13 18:15:22.637: INFO: Get endpoints failed (1.787831ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec 13 18:15:23.639: INFO: successfully validated that service endpoint-test2 in namespace services-5986 exposes endpoints map[] (1.0037647s elapsed)
STEP: Creating pod pod1 in namespace services-5986
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5986 to expose endpoints map[pod1:[80]]
Dec 13 18:15:27.679: INFO: Unexpected endpoints: found map[], expected map[pod1:[80]] (4.03432847s elapsed, will retry)
Dec 13 18:15:28.683: INFO: successfully validated that service endpoint-test2 in namespace services-5986 exposes endpoints map[pod1:[80]] (5.038142851s elapsed)
STEP: Creating pod pod2 in namespace services-5986
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5986 to expose endpoints map[pod1:[80] pod2:[80]]
Dec 13 18:15:32.715: INFO: Unexpected endpoints: found map[ba937a88-8822-4027-987b-d93038444e5a:[80]], expected map[pod1:[80] pod2:[80]] (4.028782326s elapsed, will retry)
Dec 13 18:15:35.730: INFO: successfully validated that service endpoint-test2 in namespace services-5986 exposes endpoints map[pod1:[80] pod2:[80]] (7.043080956s elapsed)
STEP: Deleting pod pod1 in namespace services-5986
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5986 to expose endpoints map[pod2:[80]]
Dec 13 18:15:35.741: INFO: successfully validated that service endpoint-test2 in namespace services-5986 exposes endpoints map[pod2:[80]] (6.410287ms elapsed)
STEP: Deleting pod pod2 in namespace services-5986
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-5986 to expose endpoints map[]
Dec 13 18:15:35.748: INFO: successfully validated that service endpoint-test2 in namespace services-5986 exposes endpoints map[] (3.289181ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:15:35.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5986" for this suite.
Dec 13 18:15:41.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:15:41.807: INFO: namespace services-5986 deletion completed in 6.045806984s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:19.202 seconds]
[sig-network] Services
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:15:41.807: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 18:15:41.835: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec 13 18:15:46.838: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 13 18:15:48.842: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 13 18:15:48.859: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-2513 /apis/apps/v1/namespaces/deployment-2513/deployments/test-cleanup-deployment 521f9430-20e6-49dd-b91b-1d45532a1f9e 120188 1 2019-12-13 18:15:48 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0030b3d08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Dec 13 18:15:48.864: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-2513 /apis/apps/v1/namespaces/deployment-2513/replicasets/test-cleanup-deployment-65db99849b 67a32777-280a-40ce-852d-0e7afabcd9b7 120190 1 2019-12-13 18:15:48 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 521f9430-20e6-49dd-b91b-1d45532a1f9e 0xc0048e36a7 0xc0048e36a8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0048e3748 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 13 18:15:48.864: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Dec 13 18:15:48.864: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-2513 /apis/apps/v1/namespaces/deployment-2513/replicasets/test-cleanup-controller 69cbbbc4-8484-4e78-8f46-321c4d630bcb 120189 1 2019-12-13 18:15:41 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 521f9430-20e6-49dd-b91b-1d45532a1f9e 0xc0048e3577 0xc0048e3578}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0048e35e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 13 18:15:48.866: INFO: Pod "test-cleanup-controller-m2wmm" is available:
&Pod{ObjectMeta:{test-cleanup-controller-m2wmm test-cleanup-controller- deployment-2513 /api/v1/namespaces/deployment-2513/pods/test-cleanup-controller-m2wmm b62a513b-d82a-408f-ba21-344dd5c205d5 120185 0 2019-12-13 18:15:41 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller 69cbbbc4-8484-4e78-8f46-321c4d630bcb 0xc0032c6187 0xc0032c6188}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-d4vxh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-d4vxh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-d4vxh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:15:41 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:15:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:15:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:15:41 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.160.134.166,PodIP:172.160.134.57,StartTime:2019-12-13 18:15:41 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-13 18:15:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://3e7d8e1a7da1575f45eac96e8ae2b018f7cc7a9ecc8e066d4f6f6d752093f92e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.160.134.57,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:15:48.867: INFO: Pod "test-cleanup-deployment-65db99849b-xxb8z" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-65db99849b-xxb8z test-cleanup-deployment-65db99849b- deployment-2513 /api/v1/namespaces/deployment-2513/pods/test-cleanup-deployment-65db99849b-xxb8z 40ab29b5-a977-4616-b1a7-bc3b85b04fa1 120191 0 2019-12-13 18:15:48 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-65db99849b 67a32777-280a-40ce-852d-0e7afabcd9b7 0xc0032c6317 0xc0032c6318}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-d4vxh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-d4vxh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-d4vxh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:15:48.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2513" for this suite.
Dec 13 18:15:54.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:15:54.934: INFO: namespace deployment-2513 deletion completed in 6.052940212s

• [SLOW TEST:13.127 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:15:54.934: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 13 18:15:54.971: INFO: Number of nodes with available pods: 0
Dec 13 18:15:54.971: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 18:15:55.975: INFO: Number of nodes with available pods: 0
Dec 13 18:15:55.975: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 18:15:56.975: INFO: Number of nodes with available pods: 0
Dec 13 18:15:56.975: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 18:15:57.975: INFO: Number of nodes with available pods: 0
Dec 13 18:15:57.975: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 18:15:58.975: INFO: Number of nodes with available pods: 0
Dec 13 18:15:58.975: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 18:15:59.975: INFO: Number of nodes with available pods: 1
Dec 13 18:15:59.975: INFO: Node 172.160.134.166 is running more than one daemon pod
Dec 13 18:16:00.975: INFO: Number of nodes with available pods: 1
Dec 13 18:16:00.975: INFO: Node 172.160.134.166 is running more than one daemon pod
Dec 13 18:16:01.975: INFO: Number of nodes with available pods: 2
Dec 13 18:16:01.975: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec 13 18:16:01.985: INFO: Number of nodes with available pods: 1
Dec 13 18:16:01.985: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 18:16:02.990: INFO: Number of nodes with available pods: 1
Dec 13 18:16:02.990: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 18:16:03.989: INFO: Number of nodes with available pods: 1
Dec 13 18:16:03.989: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 18:16:04.989: INFO: Number of nodes with available pods: 1
Dec 13 18:16:04.989: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 18:16:05.989: INFO: Number of nodes with available pods: 1
Dec 13 18:16:05.989: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 18:16:06.989: INFO: Number of nodes with available pods: 1
Dec 13 18:16:06.989: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 18:16:07.991: INFO: Number of nodes with available pods: 1
Dec 13 18:16:07.991: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 18:16:08.989: INFO: Number of nodes with available pods: 2
Dec 13 18:16:08.989: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6285, will wait for the garbage collector to delete the pods
Dec 13 18:16:09.046: INFO: Deleting DaemonSet.extensions daemon-set took: 3.266459ms
Dec 13 18:16:09.346: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.212842ms
Dec 13 18:16:13.948: INFO: Number of nodes with available pods: 0
Dec 13 18:16:13.948: INFO: Number of running nodes: 0, number of available pods: 0
Dec 13 18:16:13.952: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6285/daemonsets","resourceVersion":"120302"},"items":null}

Dec 13 18:16:13.953: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6285/pods","resourceVersion":"120302"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:16:13.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6285" for this suite.
Dec 13 18:16:19.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:16:20.009: INFO: namespace daemonsets-6285 deletion completed in 6.049543182s

• [SLOW TEST:25.075 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:16:20.011: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2970.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-2970.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2970.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2970.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-2970.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2970.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 13 18:16:48.062: INFO: DNS probes using dns-2970/dns-test-58cad6ab-9001-4532-ab23-c7e8656631d8 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:16:48.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2970" for this suite.
Dec 13 18:16:54.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:16:54.124: INFO: namespace dns-2970 deletion completed in 6.050018627s

• [SLOW TEST:34.114 seconds]
[sig-network] DNS
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:16:54.126: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 13 18:16:54.151: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 13 18:16:54.155: INFO: Waiting for terminating namespaces to be deleted...
Dec 13 18:16:54.157: INFO: 
Logging pods the kubelet thinks is on node 172.160.134.165 before test
Dec 13 18:16:54.169: INFO: sonobuoy-e2e-job-acb159fe38ea4959 from sonobuoy started at 2019-12-13 17:43:15 +0000 UTC (2 container statuses recorded)
Dec 13 18:16:54.169: INFO: 	Container e2e ready: true, restart count 0
Dec 13 18:16:54.169: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 13 18:16:54.169: INFO: sonobuoy-systemd-logs-daemon-set-5a2f946422e448af-pq5l8 from sonobuoy started at 2019-12-13 17:43:15 +0000 UTC (2 container statuses recorded)
Dec 13 18:16:54.169: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 13 18:16:54.169: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 13 18:16:54.169: INFO: iag-172.160.134.165 from kube-system started at 2019-12-12 13:53:36 +0000 UTC (1 container statuses recorded)
Dec 13 18:16:54.169: INFO: 	Container iag ready: true, restart count 0
Dec 13 18:16:54.169: INFO: 
Logging pods the kubelet thinks is on node 172.160.134.166 before test
Dec 13 18:16:54.185: INFO: coredns-6cf786c879-zgnqd from kube-system started at 2019-12-12 19:44:20 +0000 UTC (1 container statuses recorded)
Dec 13 18:16:54.185: INFO: 	Container coredns ready: true, restart count 0
Dec 13 18:16:54.185: INFO: sonobuoy from sonobuoy started at 2019-12-13 17:42:49 +0000 UTC (1 container statuses recorded)
Dec 13 18:16:54.185: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 13 18:16:54.185: INFO: sonobuoy-systemd-logs-daemon-set-5a2f946422e448af-cjc42 from sonobuoy started at 2019-12-13 17:43:15 +0000 UTC (2 container statuses recorded)
Dec 13 18:16:54.185: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 13 18:16:54.185: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-64a23f72-838c-460e-bc9b-3732d4a6c484 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-64a23f72-838c-460e-bc9b-3732d4a6c484 off the node 172.160.134.166
STEP: verifying the node doesn't have the label kubernetes.io/e2e-64a23f72-838c-460e-bc9b-3732d4a6c484
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:17:10.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1370" for this suite.
Dec 13 18:17:22.240: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:17:22.284: INFO: namespace sched-pred-1370 deletion completed in 12.050374163s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:28.158 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:17:22.284: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Dec 13 18:17:28.321: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-064082504 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec 13 18:17:33.418: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:17:33.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5284" for this suite.
Dec 13 18:17:39.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:17:39.471: INFO: namespace pods-5284 deletion completed in 6.049801397s

• [SLOW TEST:17.187 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:17:39.472: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 13 18:17:39.530: INFO: Number of nodes with available pods: 0
Dec 13 18:17:39.530: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 18:17:40.534: INFO: Number of nodes with available pods: 0
Dec 13 18:17:40.534: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 18:17:41.534: INFO: Number of nodes with available pods: 0
Dec 13 18:17:41.534: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 18:17:42.534: INFO: Number of nodes with available pods: 0
Dec 13 18:17:42.534: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 18:17:43.534: INFO: Number of nodes with available pods: 0
Dec 13 18:17:43.534: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 18:17:44.534: INFO: Number of nodes with available pods: 1
Dec 13 18:17:44.534: INFO: Node 172.160.134.166 is running more than one daemon pod
Dec 13 18:17:45.534: INFO: Number of nodes with available pods: 1
Dec 13 18:17:45.534: INFO: Node 172.160.134.166 is running more than one daemon pod
Dec 13 18:17:46.534: INFO: Number of nodes with available pods: 2
Dec 13 18:17:46.534: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec 13 18:17:46.545: INFO: Number of nodes with available pods: 2
Dec 13 18:17:46.545: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5121, will wait for the garbage collector to delete the pods
Dec 13 18:17:47.608: INFO: Deleting DaemonSet.extensions daemon-set took: 3.176066ms
Dec 13 18:17:47.909: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.171558ms
Dec 13 18:17:51.611: INFO: Number of nodes with available pods: 0
Dec 13 18:17:51.611: INFO: Number of running nodes: 0, number of available pods: 0
Dec 13 18:17:51.612: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5121/daemonsets","resourceVersion":"120562"},"items":null}

Dec 13 18:17:51.613: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5121/pods","resourceVersion":"120562"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:17:51.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5121" for this suite.
Dec 13 18:17:57.629: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:17:57.668: INFO: namespace daemonsets-5121 deletion completed in 6.048623932s

• [SLOW TEST:18.196 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:17:57.668: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 18:17:57.704: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 13 18:18:02.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 --namespace=crd-publish-openapi-9401 create -f -'
Dec 13 18:18:02.965: INFO: stderr: ""
Dec 13 18:18:02.965: INFO: stdout: "e2e-test-crd-publish-openapi-3710-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 13 18:18:02.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 --namespace=crd-publish-openapi-9401 delete e2e-test-crd-publish-openapi-3710-crds test-cr'
Dec 13 18:18:03.073: INFO: stderr: ""
Dec 13 18:18:03.073: INFO: stdout: "e2e-test-crd-publish-openapi-3710-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Dec 13 18:18:03.073: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 --namespace=crd-publish-openapi-9401 apply -f -'
Dec 13 18:18:03.320: INFO: stderr: ""
Dec 13 18:18:03.320: INFO: stdout: "e2e-test-crd-publish-openapi-3710-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 13 18:18:03.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 --namespace=crd-publish-openapi-9401 delete e2e-test-crd-publish-openapi-3710-crds test-cr'
Dec 13 18:18:03.431: INFO: stderr: ""
Dec 13 18:18:03.431: INFO: stdout: "e2e-test-crd-publish-openapi-3710-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Dec 13 18:18:03.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 explain e2e-test-crd-publish-openapi-3710-crds'
Dec 13 18:18:03.657: INFO: stderr: ""
Dec 13 18:18:03.657: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3710-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:18:08.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9401" for this suite.
Dec 13 18:18:14.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:18:14.267: INFO: namespace crd-publish-openapi-9401 deletion completed in 6.049716827s

• [SLOW TEST:16.599 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:18:14.267: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec 13 18:18:24.315: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-721 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 13 18:18:24.315: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 18:18:24.644: INFO: Exec stderr: ""
Dec 13 18:18:24.644: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-721 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 13 18:18:24.644: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 18:18:24.859: INFO: Exec stderr: ""
Dec 13 18:18:24.859: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-721 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 13 18:18:24.859: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 18:18:25.103: INFO: Exec stderr: ""
Dec 13 18:18:25.103: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-721 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 13 18:18:25.103: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 18:18:25.283: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec 13 18:18:25.283: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-721 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 13 18:18:25.283: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 18:18:25.599: INFO: Exec stderr: ""
Dec 13 18:18:25.599: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-721 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 13 18:18:25.599: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 18:18:25.921: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec 13 18:18:25.921: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-721 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 13 18:18:25.921: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 18:18:25.984: INFO: Exec stderr: ""
Dec 13 18:18:25.984: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-721 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 13 18:18:25.984: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 18:18:26.049: INFO: Exec stderr: ""
Dec 13 18:18:26.049: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-721 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 13 18:18:26.049: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 18:18:26.115: INFO: Exec stderr: ""
Dec 13 18:18:26.115: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-721 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 13 18:18:26.115: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 18:18:26.179: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:18:26.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-721" for this suite.
Dec 13 18:19:10.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:19:10.228: INFO: namespace e2e-kubelet-etc-hosts-721 deletion completed in 44.047280622s

• [SLOW TEST:55.961 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:19:10.229: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1213 18:19:20.298905      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 13 18:19:20.298: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:19:20.298: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9132" for this suite.
Dec 13 18:19:26.306: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:19:26.347: INFO: namespace gc-9132 deletion completed in 6.046722296s

• [SLOW TEST:16.119 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:19:26.348: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-00faa833-c50d-475f-a813-f67931e85adb
STEP: Creating a pod to test consume configMaps
Dec 13 18:19:26.379: INFO: Waiting up to 5m0s for pod "pod-configmaps-8c1ca223-c2d0-4239-9b2d-6c9868de8133" in namespace "configmap-102" to be "success or failure"
Dec 13 18:19:26.384: INFO: Pod "pod-configmaps-8c1ca223-c2d0-4239-9b2d-6c9868de8133": Phase="Pending", Reason="", readiness=false. Elapsed: 4.780232ms
Dec 13 18:19:28.386: INFO: Pod "pod-configmaps-8c1ca223-c2d0-4239-9b2d-6c9868de8133": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00688908s
Dec 13 18:19:30.388: INFO: Pod "pod-configmaps-8c1ca223-c2d0-4239-9b2d-6c9868de8133": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008861421s
Dec 13 18:19:32.390: INFO: Pod "pod-configmaps-8c1ca223-c2d0-4239-9b2d-6c9868de8133": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011006469s
Dec 13 18:19:34.392: INFO: Pod "pod-configmaps-8c1ca223-c2d0-4239-9b2d-6c9868de8133": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.013266735s
STEP: Saw pod success
Dec 13 18:19:34.392: INFO: Pod "pod-configmaps-8c1ca223-c2d0-4239-9b2d-6c9868de8133" satisfied condition "success or failure"
Dec 13 18:19:34.394: INFO: Trying to get logs from node 172.160.134.166 pod pod-configmaps-8c1ca223-c2d0-4239-9b2d-6c9868de8133 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 13 18:19:34.424: INFO: Waiting for pod pod-configmaps-8c1ca223-c2d0-4239-9b2d-6c9868de8133 to disappear
Dec 13 18:19:34.427: INFO: Pod pod-configmaps-8c1ca223-c2d0-4239-9b2d-6c9868de8133 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:19:34.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-102" for this suite.
Dec 13 18:19:40.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:19:40.479: INFO: namespace configmap-102 deletion completed in 6.049576481s

• [SLOW TEST:14.130 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:19:40.480: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec 13 18:19:46.512: INFO: &Pod{ObjectMeta:{send-events-cccf7cb3-ad56-4762-9af4-6a68c7d1b492  events-8686 /api/v1/namespaces/events-8686/pods/send-events-cccf7cb3-ad56-4762-9af4-6a68c7d1b492 9892379c-d6b2-4ca7-b0d1-474277db315d 120942 0 2019-12-13 18:19:40 +0000 UTC <nil> <nil> map[name:foo time:501913099] map[] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-wj9s7,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-wj9s7,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-wj9s7,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:19:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:19:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:19:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:19:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.160.134.165,PodIP:172.160.134.82,StartTime:2019-12-13 18:19:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-13 18:19:44 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:docker://fda367d2270bdf0125b7e41a1c6e8e319cadc25f21d18a6165c8883e62a0413b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.160.134.82,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Dec 13 18:19:48.515: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec 13 18:19:50.517: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:19:50.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-8686" for this suite.
Dec 13 18:20:34.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:20:34.580: INFO: namespace events-8686 deletion completed in 44.056665486s

• [SLOW TEST:54.101 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:20:34.580: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 13 18:20:34.612: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c0dd9bcf-f12c-46c9-a724-664a0670d4e6" in namespace "projected-174" to be "success or failure"
Dec 13 18:20:34.617: INFO: Pod "downwardapi-volume-c0dd9bcf-f12c-46c9-a724-664a0670d4e6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.699994ms
Dec 13 18:20:36.620: INFO: Pod "downwardapi-volume-c0dd9bcf-f12c-46c9-a724-664a0670d4e6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0080817s
Dec 13 18:20:38.622: INFO: Pod "downwardapi-volume-c0dd9bcf-f12c-46c9-a724-664a0670d4e6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010672475s
Dec 13 18:20:40.625: INFO: Pod "downwardapi-volume-c0dd9bcf-f12c-46c9-a724-664a0670d4e6": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01303065s
Dec 13 18:20:42.627: INFO: Pod "downwardapi-volume-c0dd9bcf-f12c-46c9-a724-664a0670d4e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.015421648s
STEP: Saw pod success
Dec 13 18:20:42.627: INFO: Pod "downwardapi-volume-c0dd9bcf-f12c-46c9-a724-664a0670d4e6" satisfied condition "success or failure"
Dec 13 18:20:42.629: INFO: Trying to get logs from node 172.160.134.166 pod downwardapi-volume-c0dd9bcf-f12c-46c9-a724-664a0670d4e6 container client-container: <nil>
STEP: delete the pod
Dec 13 18:20:42.687: INFO: Waiting for pod downwardapi-volume-c0dd9bcf-f12c-46c9-a724-664a0670d4e6 to disappear
Dec 13 18:20:42.690: INFO: Pod downwardapi-volume-c0dd9bcf-f12c-46c9-a724-664a0670d4e6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:20:42.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-174" for this suite.
Dec 13 18:20:48.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:20:48.742: INFO: namespace projected-174 deletion completed in 6.051227728s

• [SLOW TEST:14.162 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:20:48.743: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec 13 18:20:48.770: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:21:14.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8761" for this suite.
Dec 13 18:21:20.333: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:21:20.375: INFO: namespace crd-publish-openapi-8761 deletion completed in 6.048399072s

• [SLOW TEST:31.632 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:21:20.376: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-9b181cfa-761b-48a6-b607-694231ad083b
STEP: Creating a pod to test consume configMaps
Dec 13 18:21:20.404: INFO: Waiting up to 5m0s for pod "pod-configmaps-d13d9a75-0036-47c4-b8d5-6a70dd52f8df" in namespace "configmap-8049" to be "success or failure"
Dec 13 18:21:20.405: INFO: Pod "pod-configmaps-d13d9a75-0036-47c4-b8d5-6a70dd52f8df": Phase="Pending", Reason="", readiness=false. Elapsed: 1.328635ms
Dec 13 18:21:22.408: INFO: Pod "pod-configmaps-d13d9a75-0036-47c4-b8d5-6a70dd52f8df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003608691s
Dec 13 18:21:24.410: INFO: Pod "pod-configmaps-d13d9a75-0036-47c4-b8d5-6a70dd52f8df": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005946253s
Dec 13 18:21:26.412: INFO: Pod "pod-configmaps-d13d9a75-0036-47c4-b8d5-6a70dd52f8df": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008149321s
Dec 13 18:21:28.414: INFO: Pod "pod-configmaps-d13d9a75-0036-47c4-b8d5-6a70dd52f8df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.010362446s
STEP: Saw pod success
Dec 13 18:21:28.414: INFO: Pod "pod-configmaps-d13d9a75-0036-47c4-b8d5-6a70dd52f8df" satisfied condition "success or failure"
Dec 13 18:21:28.416: INFO: Trying to get logs from node 172.160.134.166 pod pod-configmaps-d13d9a75-0036-47c4-b8d5-6a70dd52f8df container configmap-volume-test: <nil>
STEP: delete the pod
Dec 13 18:21:28.432: INFO: Waiting for pod pod-configmaps-d13d9a75-0036-47c4-b8d5-6a70dd52f8df to disappear
Dec 13 18:21:28.436: INFO: Pod pod-configmaps-d13d9a75-0036-47c4-b8d5-6a70dd52f8df no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:21:28.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8049" for this suite.
Dec 13 18:21:34.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:21:34.493: INFO: namespace configmap-8049 deletion completed in 6.055600714s

• [SLOW TEST:14.117 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:21:34.494: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-837f7579-45ba-4e38-9946-2473433be259
STEP: Creating a pod to test consume configMaps
Dec 13 18:21:34.521: INFO: Waiting up to 5m0s for pod "pod-configmaps-a89e193c-8027-42ff-a8e5-240abace4f36" in namespace "configmap-2380" to be "success or failure"
Dec 13 18:21:34.525: INFO: Pod "pod-configmaps-a89e193c-8027-42ff-a8e5-240abace4f36": Phase="Pending", Reason="", readiness=false. Elapsed: 3.691055ms
Dec 13 18:21:36.527: INFO: Pod "pod-configmaps-a89e193c-8027-42ff-a8e5-240abace4f36": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005853898s
Dec 13 18:21:38.529: INFO: Pod "pod-configmaps-a89e193c-8027-42ff-a8e5-240abace4f36": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008012662s
Dec 13 18:21:40.532: INFO: Pod "pod-configmaps-a89e193c-8027-42ff-a8e5-240abace4f36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010443052s
STEP: Saw pod success
Dec 13 18:21:40.532: INFO: Pod "pod-configmaps-a89e193c-8027-42ff-a8e5-240abace4f36" satisfied condition "success or failure"
Dec 13 18:21:40.533: INFO: Trying to get logs from node 172.160.134.165 pod pod-configmaps-a89e193c-8027-42ff-a8e5-240abace4f36 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 13 18:21:40.562: INFO: Waiting for pod pod-configmaps-a89e193c-8027-42ff-a8e5-240abace4f36 to disappear
Dec 13 18:21:40.572: INFO: Pod pod-configmaps-a89e193c-8027-42ff-a8e5-240abace4f36 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:21:40.572: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2380" for this suite.
Dec 13 18:21:46.580: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:21:46.635: INFO: namespace configmap-2380 deletion completed in 6.060667914s

• [SLOW TEST:12.140 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:21:46.635: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Dec 13 18:21:46.658: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-064082504 proxy --unix-socket=/tmp/kubectl-proxy-unix342479247/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:21:46.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9735" for this suite.
Dec 13 18:21:52.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:21:52.785: INFO: namespace kubectl-9735 deletion completed in 6.04408089s

• [SLOW TEST:6.151 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:21:52.785: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 13 18:22:01.336: INFO: Successfully updated pod "labelsupdate5fe89bd3-08ec-4225-b7d9-40e63eda7a68"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:22:03.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7499" for this suite.
Dec 13 18:22:15.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:22:15.400: INFO: namespace projected-7499 deletion completed in 12.048240797s

• [SLOW TEST:22.614 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:22:15.400: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec 13 18:22:16.368: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Dec 13 18:22:18.376: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858136, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858136, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858136, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858136, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 18:22:20.381: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858136, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858136, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858136, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858136, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 18:22:22.379: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858136, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858136, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858136, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858136, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 13 18:22:25.392: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 18:22:25.394: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:22:26.498: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-5944" for this suite.
Dec 13 18:22:32.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:22:32.546: INFO: namespace crd-webhook-5944 deletion completed in 6.046668207s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:17.155 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:22:32.555: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-744df34c-3c3a-4314-84ba-d208375ffe16
STEP: Creating secret with name s-test-opt-upd-1cacd5e4-0b45-430d-9e2e-98f11a786103
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-744df34c-3c3a-4314-84ba-d208375ffe16
STEP: Updating secret s-test-opt-upd-1cacd5e4-0b45-430d-9e2e-98f11a786103
STEP: Creating secret with name s-test-opt-create-7cda7beb-7c45-40f6-b55b-4af6f012a975
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:23:45.002: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8958" for this suite.
Dec 13 18:23:57.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:23:57.054: INFO: namespace secrets-8958 deletion completed in 12.050156567s

• [SLOW TEST:84.499 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:23:57.054: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 13 18:23:57.082: INFO: PodSpec: initContainers in spec.initContainers
Dec 13 18:24:41.136: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-97e619da-5f5b-49af-9962-14a7e3dfa778", GenerateName:"", Namespace:"init-container-789", SelfLink:"/api/v1/namespaces/init-container-789/pods/pod-init-97e619da-5f5b-49af-9962-14a7e3dfa778", UID:"b9957863-a73d-4a9a-bf3e-8c00f91efb7f", ResourceVersion:"121452", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63711858237, loc:(*time.Location)(0x84c12c0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"82538798"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-h87qw", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc0034f1080), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-h87qw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-h87qw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-h87qw", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003d9a518), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"172.160.134.165", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc003113080), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003d9a5a0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003d9a5c0)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003d9a5c8), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc003d9a5cc), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858237, loc:(*time.Location)(0x84c12c0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858237, loc:(*time.Location)(0x84c12c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858237, loc:(*time.Location)(0x84c12c0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858237, loc:(*time.Location)(0x84c12c0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"172.160.134.165", PodIP:"172.160.134.89", PodIPs:[]v1.PodIP{v1.PodIP{IP:"172.160.134.89"}}, StartTime:(*v1.Time)(0xc003036600), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000333a40)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000333ab0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://ebfb0e560585870c5288fd8b712b4a26f56f50304a1db5305ed55b1aca23f43d", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003036640), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc003036620), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc003d9a644)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:24:41.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-789" for this suite.
Dec 13 18:25:09.146: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:25:09.187: INFO: namespace init-container-789 deletion completed in 28.048245974s

• [SLOW TEST:72.134 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:25:09.188: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 13 18:25:09.687: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 13 18:25:11.692: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858309, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858309, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858309, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858309, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 18:25:13.694: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858309, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858309, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858309, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858309, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 13 18:25:16.701: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:25:16.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1631" for this suite.
Dec 13 18:25:22.751: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:25:22.792: INFO: namespace webhook-1631 deletion completed in 6.046670378s
STEP: Destroying namespace "webhook-1631-markers" for this suite.
Dec 13 18:25:28.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:25:28.839: INFO: namespace webhook-1631-markers deletion completed in 6.04714159s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.657 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:25:28.846: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:25:34.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-9244" for this suite.
Dec 13 18:25:42.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:25:42.942: INFO: namespace containers-9244 deletion completed in 8.045754228s

• [SLOW TEST:14.096 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:25:42.944: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:25:43.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1151" for this suite.
Dec 13 18:25:49.016: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:25:49.058: INFO: namespace kubelet-test-1151 deletion completed in 6.048178768s

• [SLOW TEST:6.114 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:25:49.059: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-9693
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9693 to expose endpoints map[]
Dec 13 18:25:49.094: INFO: Get endpoints failed (2.702488ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec 13 18:25:50.100: INFO: successfully validated that service multi-endpoint-test in namespace services-9693 exposes endpoints map[] (1.009442503s elapsed)
STEP: Creating pod pod1 in namespace services-9693
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9693 to expose endpoints map[pod1:[100]]
Dec 13 18:25:54.153: INFO: Unexpected endpoints: found map[], expected map[pod1:[100]] (4.039290006s elapsed, will retry)
Dec 13 18:25:57.163: INFO: successfully validated that service multi-endpoint-test in namespace services-9693 exposes endpoints map[pod1:[100]] (7.049019717s elapsed)
STEP: Creating pod pod2 in namespace services-9693
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9693 to expose endpoints map[pod1:[100] pod2:[101]]
Dec 13 18:26:01.193: INFO: Unexpected endpoints: found map[c1532425-4a82-44b5-a562-f4f6c9d10d65:[100]], expected map[pod1:[100] pod2:[101]] (4.027585641s elapsed, will retry)
Dec 13 18:26:04.207: INFO: successfully validated that service multi-endpoint-test in namespace services-9693 exposes endpoints map[pod1:[100] pod2:[101]] (7.041754329s elapsed)
STEP: Deleting pod pod1 in namespace services-9693
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9693 to expose endpoints map[pod2:[101]]
Dec 13 18:26:05.224: INFO: successfully validated that service multi-endpoint-test in namespace services-9693 exposes endpoints map[pod2:[101]] (1.014271659s elapsed)
STEP: Deleting pod pod2 in namespace services-9693
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9693 to expose endpoints map[]
Dec 13 18:26:06.231: INFO: successfully validated that service multi-endpoint-test in namespace services-9693 exposes endpoints map[] (1.004538111s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:26:06.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9693" for this suite.
Dec 13 18:26:12.251: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:26:12.293: INFO: namespace services-9693 deletion completed in 6.047182952s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:23.234 seconds]
[sig-network] Services
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:26:12.293: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-4342
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec 13 18:26:12.332: INFO: Found 0 stateful pods, waiting for 3
Dec 13 18:26:22.335: INFO: Found 2 stateful pods, waiting for 3
Dec 13 18:26:32.336: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 13 18:26:32.336: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 13 18:26:32.336: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec 13 18:26:32.342: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=statefulset-4342 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 13 18:26:32.662: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 13 18:26:32.662: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 13 18:26:32.662: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec 13 18:26:42.685: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec 13 18:26:52.695: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=statefulset-4342 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 13 18:26:53.049: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 13 18:26:53.049: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 13 18:26:53.049: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 13 18:27:03.061: INFO: Waiting for StatefulSet statefulset-4342/ss2 to complete update
Dec 13 18:27:03.061: INFO: Waiting for Pod statefulset-4342/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 13 18:27:03.061: INFO: Waiting for Pod statefulset-4342/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 13 18:27:13.066: INFO: Waiting for StatefulSet statefulset-4342/ss2 to complete update
Dec 13 18:27:13.066: INFO: Waiting for Pod statefulset-4342/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Dec 13 18:27:23.066: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=statefulset-4342 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 13 18:27:23.713: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 13 18:27:23.713: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 13 18:27:23.713: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 13 18:27:33.736: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec 13 18:27:43.751: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=statefulset-4342 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 13 18:27:44.121: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 13 18:27:44.121: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 13 18:27:44.121: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 13 18:27:54.132: INFO: Waiting for StatefulSet statefulset-4342/ss2 to complete update
Dec 13 18:27:54.132: INFO: Waiting for Pod statefulset-4342/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Dec 13 18:27:54.132: INFO: Waiting for Pod statefulset-4342/ss2-1 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
Dec 13 18:28:04.136: INFO: Waiting for StatefulSet statefulset-4342/ss2 to complete update
Dec 13 18:28:04.136: INFO: Waiting for Pod statefulset-4342/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 13 18:28:14.136: INFO: Deleting all statefulset in ns statefulset-4342
Dec 13 18:28:14.138: INFO: Scaling statefulset ss2 to 0
Dec 13 18:28:24.146: INFO: Waiting for statefulset status.replicas updated to 0
Dec 13 18:28:24.148: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:28:24.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4342" for this suite.
Dec 13 18:28:30.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:28:30.208: INFO: namespace statefulset-4342 deletion completed in 6.052499855s

• [SLOW TEST:137.915 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:28:30.208: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1213 18:28:40.246619      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 13 18:28:40.246: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:28:40.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5555" for this suite.
Dec 13 18:28:46.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:28:46.293: INFO: namespace gc-5555 deletion completed in 6.044876681s

• [SLOW TEST:16.084 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:28:46.293: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 18:28:46.333: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"cdb79c76-90a5-4861-b14a-46068adb6bdd", Controller:(*bool)(0xc004619f0a), BlockOwnerDeletion:(*bool)(0xc004619f0b)}}
Dec 13 18:28:46.339: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"23bf989a-e92a-4c70-a66b-814968bfb3f2", Controller:(*bool)(0xc004cac47a), BlockOwnerDeletion:(*bool)(0xc004cac47b)}}
Dec 13 18:28:46.343: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"752440aa-5dbe-41f9-942a-58721ade75b2", Controller:(*bool)(0xc003d9bd4a), BlockOwnerDeletion:(*bool)(0xc003d9bd4b)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:28:51.353: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6237" for this suite.
Dec 13 18:28:57.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:28:57.398: INFO: namespace gc-6237 deletion completed in 6.043167091s

• [SLOW TEST:11.105 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:28:57.399: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Dec 13 18:28:57.421: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec 13 18:29:10.463: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:29:10.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-771" for this suite.
Dec 13 18:29:16.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:29:16.519: INFO: namespace pods-771 deletion completed in 6.052251145s

• [SLOW TEST:19.120 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:29:16.519: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Dec 13 18:29:16.545: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 13 18:30:16.555: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 18:30:16.556: INFO: Starting informer...
STEP: Starting pods...
Dec 13 18:30:16.767: INFO: Pod1 is running on 172.160.134.165. Tainting Node
Dec 13 18:30:22.977: INFO: Pod2 is running on 172.160.134.165. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Dec 13 18:30:29.358: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Dec 13 18:30:49.447: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:30:49.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-8272" for this suite.
Dec 13 18:30:55.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:30:55.510: INFO: namespace taint-multiple-pods-8272 deletion completed in 6.048489144s

• [SLOW TEST:98.991 seconds]
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:30:55.511: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 18:30:55.550: INFO: (0) /api/v1/nodes/172.160.134.165:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 11.074625ms)
Dec 13 18:30:55.552: INFO: (1) /api/v1/nodes/172.160.134.165:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 2.13893ms)
Dec 13 18:30:55.554: INFO: (2) /api/v1/nodes/172.160.134.165:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 2.012095ms)
Dec 13 18:30:55.556: INFO: (3) /api/v1/nodes/172.160.134.165:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 1.945771ms)
Dec 13 18:30:55.558: INFO: (4) /api/v1/nodes/172.160.134.165:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 1.792617ms)
Dec 13 18:30:55.560: INFO: (5) /api/v1/nodes/172.160.134.165:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 1.874332ms)
Dec 13 18:30:55.562: INFO: (6) /api/v1/nodes/172.160.134.165:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 1.905464ms)
Dec 13 18:30:55.564: INFO: (7) /api/v1/nodes/172.160.134.165:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 1.83577ms)
Dec 13 18:30:55.565: INFO: (8) /api/v1/nodes/172.160.134.165:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 1.809361ms)
Dec 13 18:30:55.567: INFO: (9) /api/v1/nodes/172.160.134.165:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 1.805905ms)
Dec 13 18:30:55.569: INFO: (10) /api/v1/nodes/172.160.134.165:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 1.839075ms)
Dec 13 18:30:55.571: INFO: (11) /api/v1/nodes/172.160.134.165:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 1.875447ms)
Dec 13 18:30:55.573: INFO: (12) /api/v1/nodes/172.160.134.165:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 2.044577ms)
Dec 13 18:30:55.575: INFO: (13) /api/v1/nodes/172.160.134.165:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 1.939978ms)
Dec 13 18:30:55.577: INFO: (14) /api/v1/nodes/172.160.134.165:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 1.94708ms)
Dec 13 18:30:55.579: INFO: (15) /api/v1/nodes/172.160.134.165:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 1.835944ms)
Dec 13 18:30:55.581: INFO: (16) /api/v1/nodes/172.160.134.165:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 1.939039ms)
Dec 13 18:30:55.583: INFO: (17) /api/v1/nodes/172.160.134.165:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 1.965641ms)
Dec 13 18:30:55.585: INFO: (18) /api/v1/nodes/172.160.134.165:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 1.965182ms)
Dec 13 18:30:55.588: INFO: (19) /api/v1/nodes/172.160.134.165:10250/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 2.288842ms)
[AfterEach] version v1
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:30:55.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5332" for this suite.
Dec 13 18:31:01.596: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:31:01.641: INFO: namespace proxy-5332 deletion completed in 6.051387768s

• [SLOW TEST:6.130 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:31:01.643: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 13 18:31:01.667: INFO: Waiting up to 5m0s for pod "pod-dd4d7a9f-58d5-4a65-9a98-9e6b6c823386" in namespace "emptydir-2797" to be "success or failure"
Dec 13 18:31:01.691: INFO: Pod "pod-dd4d7a9f-58d5-4a65-9a98-9e6b6c823386": Phase="Pending", Reason="", readiness=false. Elapsed: 23.544873ms
Dec 13 18:31:03.693: INFO: Pod "pod-dd4d7a9f-58d5-4a65-9a98-9e6b6c823386": Phase="Pending", Reason="", readiness=false. Elapsed: 2.025854247s
Dec 13 18:31:05.695: INFO: Pod "pod-dd4d7a9f-58d5-4a65-9a98-9e6b6c823386": Phase="Pending", Reason="", readiness=false. Elapsed: 4.028139748s
Dec 13 18:31:07.698: INFO: Pod "pod-dd4d7a9f-58d5-4a65-9a98-9e6b6c823386": Phase="Pending", Reason="", readiness=false. Elapsed: 6.030478969s
Dec 13 18:31:09.700: INFO: Pod "pod-dd4d7a9f-58d5-4a65-9a98-9e6b6c823386": Phase="Pending", Reason="", readiness=false. Elapsed: 8.032856626s
Dec 13 18:31:11.702: INFO: Pod "pod-dd4d7a9f-58d5-4a65-9a98-9e6b6c823386": Phase="Pending", Reason="", readiness=false. Elapsed: 10.035202393s
Dec 13 18:31:13.705: INFO: Pod "pod-dd4d7a9f-58d5-4a65-9a98-9e6b6c823386": Phase="Pending", Reason="", readiness=false. Elapsed: 12.037493459s
Dec 13 18:31:15.707: INFO: Pod "pod-dd4d7a9f-58d5-4a65-9a98-9e6b6c823386": Phase="Pending", Reason="", readiness=false. Elapsed: 14.039726528s
Dec 13 18:31:17.709: INFO: Pod "pod-dd4d7a9f-58d5-4a65-9a98-9e6b6c823386": Phase="Pending", Reason="", readiness=false. Elapsed: 16.041856538s
Dec 13 18:31:19.711: INFO: Pod "pod-dd4d7a9f-58d5-4a65-9a98-9e6b6c823386": Phase="Pending", Reason="", readiness=false. Elapsed: 18.044180982s
Dec 13 18:31:21.714: INFO: Pod "pod-dd4d7a9f-58d5-4a65-9a98-9e6b6c823386": Phase="Pending", Reason="", readiness=false. Elapsed: 20.046456668s
Dec 13 18:31:23.716: INFO: Pod "pod-dd4d7a9f-58d5-4a65-9a98-9e6b6c823386": Phase="Pending", Reason="", readiness=false. Elapsed: 22.048749452s
Dec 13 18:31:25.718: INFO: Pod "pod-dd4d7a9f-58d5-4a65-9a98-9e6b6c823386": Phase="Pending", Reason="", readiness=false. Elapsed: 24.050932072s
Dec 13 18:31:27.720: INFO: Pod "pod-dd4d7a9f-58d5-4a65-9a98-9e6b6c823386": Phase="Running", Reason="", readiness=true. Elapsed: 26.053093244s
Dec 13 18:31:29.722: INFO: Pod "pod-dd4d7a9f-58d5-4a65-9a98-9e6b6c823386": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.055327691s
STEP: Saw pod success
Dec 13 18:31:29.723: INFO: Pod "pod-dd4d7a9f-58d5-4a65-9a98-9e6b6c823386" satisfied condition "success or failure"
Dec 13 18:31:29.729: INFO: Trying to get logs from node 172.160.134.166 pod pod-dd4d7a9f-58d5-4a65-9a98-9e6b6c823386 container test-container: <nil>
STEP: delete the pod
Dec 13 18:31:29.756: INFO: Waiting for pod pod-dd4d7a9f-58d5-4a65-9a98-9e6b6c823386 to disappear
Dec 13 18:31:29.761: INFO: Pod pod-dd4d7a9f-58d5-4a65-9a98-9e6b6c823386 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:31:29.761: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2797" for this suite.
Dec 13 18:31:35.788: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:31:35.830: INFO: namespace emptydir-2797 deletion completed in 6.067222447s

• [SLOW TEST:34.187 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:31:35.830: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 13 18:31:40.883: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:31:40.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-532" for this suite.
Dec 13 18:31:46.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:31:46.963: INFO: namespace container-runtime-532 deletion completed in 6.055533167s

• [SLOW TEST:11.132 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:31:46.963: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 13 18:31:52.010: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:31:52.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1846" for this suite.
Dec 13 18:31:58.032: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:31:58.072: INFO: namespace container-runtime-1846 deletion completed in 6.047208705s

• [SLOW TEST:11.109 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:31:58.073: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-8gdn
STEP: Creating a pod to test atomic-volume-subpath
Dec 13 18:31:58.101: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-8gdn" in namespace "subpath-9721" to be "success or failure"
Dec 13 18:31:58.103: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Pending", Reason="", readiness=false. Elapsed: 1.89532ms
Dec 13 18:32:00.105: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003902617s
Dec 13 18:32:02.107: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006287247s
Dec 13 18:32:04.110: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008806233s
Dec 13 18:32:06.112: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Pending", Reason="", readiness=false. Elapsed: 8.011299733s
Dec 13 18:32:08.115: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Pending", Reason="", readiness=false. Elapsed: 10.01352533s
Dec 13 18:32:10.116: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Pending", Reason="", readiness=false. Elapsed: 12.015302479s
Dec 13 18:32:12.118: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Pending", Reason="", readiness=false. Elapsed: 14.017462353s
Dec 13 18:32:14.121: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Pending", Reason="", readiness=false. Elapsed: 16.01991227s
Dec 13 18:32:16.123: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Pending", Reason="", readiness=false. Elapsed: 18.022189936s
Dec 13 18:32:18.125: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Pending", Reason="", readiness=false. Elapsed: 20.023966143s
Dec 13 18:32:20.127: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Pending", Reason="", readiness=false. Elapsed: 22.026335018s
Dec 13 18:32:22.129: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Pending", Reason="", readiness=false. Elapsed: 24.028267062s
Dec 13 18:32:24.132: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Running", Reason="", readiness=true. Elapsed: 26.030617576s
Dec 13 18:32:26.134: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Running", Reason="", readiness=true. Elapsed: 28.033003357s
Dec 13 18:32:28.136: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Running", Reason="", readiness=true. Elapsed: 30.034945336s
Dec 13 18:32:30.141: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Running", Reason="", readiness=true. Elapsed: 32.040435947s
Dec 13 18:32:32.144: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Running", Reason="", readiness=true. Elapsed: 34.042684005s
Dec 13 18:32:34.146: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Running", Reason="", readiness=true. Elapsed: 36.045012158s
Dec 13 18:32:36.148: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Running", Reason="", readiness=true. Elapsed: 38.047337862s
Dec 13 18:32:38.151: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Running", Reason="", readiness=true. Elapsed: 40.049535328s
Dec 13 18:32:40.153: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Running", Reason="", readiness=true. Elapsed: 42.05168558s
Dec 13 18:32:42.155: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Running", Reason="", readiness=true. Elapsed: 44.053925469s
Dec 13 18:32:44.157: INFO: Pod "pod-subpath-test-configmap-8gdn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 46.056218686s
STEP: Saw pod success
Dec 13 18:32:44.157: INFO: Pod "pod-subpath-test-configmap-8gdn" satisfied condition "success or failure"
Dec 13 18:32:44.159: INFO: Trying to get logs from node 172.160.134.165 pod pod-subpath-test-configmap-8gdn container test-container-subpath-configmap-8gdn: <nil>
STEP: delete the pod
Dec 13 18:32:44.182: INFO: Waiting for pod pod-subpath-test-configmap-8gdn to disappear
Dec 13 18:32:44.187: INFO: Pod pod-subpath-test-configmap-8gdn no longer exists
STEP: Deleting pod pod-subpath-test-configmap-8gdn
Dec 13 18:32:44.187: INFO: Deleting pod "pod-subpath-test-configmap-8gdn" in namespace "subpath-9721"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:32:44.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-9721" for this suite.
Dec 13 18:32:50.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:32:50.239: INFO: namespace subpath-9721 deletion completed in 6.049058221s

• [SLOW TEST:52.166 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:32:50.239: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 13 18:32:50.271: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d3939c0a-2838-42de-a7d7-197321a447f9" in namespace "downward-api-650" to be "success or failure"
Dec 13 18:32:50.272: INFO: Pod "downwardapi-volume-d3939c0a-2838-42de-a7d7-197321a447f9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.616093ms
Dec 13 18:32:52.275: INFO: Pod "downwardapi-volume-d3939c0a-2838-42de-a7d7-197321a447f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004180077s
Dec 13 18:32:54.277: INFO: Pod "downwardapi-volume-d3939c0a-2838-42de-a7d7-197321a447f9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006589908s
Dec 13 18:32:56.280: INFO: Pod "downwardapi-volume-d3939c0a-2838-42de-a7d7-197321a447f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009085922s
STEP: Saw pod success
Dec 13 18:32:56.280: INFO: Pod "downwardapi-volume-d3939c0a-2838-42de-a7d7-197321a447f9" satisfied condition "success or failure"
Dec 13 18:32:56.281: INFO: Trying to get logs from node 172.160.134.165 pod downwardapi-volume-d3939c0a-2838-42de-a7d7-197321a447f9 container client-container: <nil>
STEP: delete the pod
Dec 13 18:32:56.292: INFO: Waiting for pod downwardapi-volume-d3939c0a-2838-42de-a7d7-197321a447f9 to disappear
Dec 13 18:32:56.293: INFO: Pod downwardapi-volume-d3939c0a-2838-42de-a7d7-197321a447f9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:32:56.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-650" for this suite.
Dec 13 18:33:02.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:33:02.345: INFO: namespace downward-api-650 deletion completed in 6.048814449s

• [SLOW TEST:12.105 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:33:02.345: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-ce3798f3-69cc-4325-a71a-fae4a5438a21
STEP: Creating a pod to test consume secrets
Dec 13 18:33:02.414: INFO: Waiting up to 5m0s for pod "pod-secrets-830edc5c-c79e-48f2-8d72-63eafa1f1871" in namespace "secrets-8503" to be "success or failure"
Dec 13 18:33:02.416: INFO: Pod "pod-secrets-830edc5c-c79e-48f2-8d72-63eafa1f1871": Phase="Pending", Reason="", readiness=false. Elapsed: 1.273306ms
Dec 13 18:33:04.418: INFO: Pod "pod-secrets-830edc5c-c79e-48f2-8d72-63eafa1f1871": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00343141s
Dec 13 18:33:06.420: INFO: Pod "pod-secrets-830edc5c-c79e-48f2-8d72-63eafa1f1871": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005756442s
Dec 13 18:33:08.422: INFO: Pod "pod-secrets-830edc5c-c79e-48f2-8d72-63eafa1f1871": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007842092s
Dec 13 18:33:10.424: INFO: Pod "pod-secrets-830edc5c-c79e-48f2-8d72-63eafa1f1871": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.010052025s
STEP: Saw pod success
Dec 13 18:33:10.424: INFO: Pod "pod-secrets-830edc5c-c79e-48f2-8d72-63eafa1f1871" satisfied condition "success or failure"
Dec 13 18:33:10.426: INFO: Trying to get logs from node 172.160.134.166 pod pod-secrets-830edc5c-c79e-48f2-8d72-63eafa1f1871 container secret-env-test: <nil>
STEP: delete the pod
Dec 13 18:33:10.450: INFO: Waiting for pod pod-secrets-830edc5c-c79e-48f2-8d72-63eafa1f1871 to disappear
Dec 13 18:33:10.452: INFO: Pod pod-secrets-830edc5c-c79e-48f2-8d72-63eafa1f1871 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:33:10.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8503" for this suite.
Dec 13 18:33:16.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:33:16.501: INFO: namespace secrets-8503 deletion completed in 6.04758483s

• [SLOW TEST:14.157 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:33:16.502: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:33:33.589: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5906" for this suite.
Dec 13 18:33:39.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:33:39.638: INFO: namespace namespaces-5906 deletion completed in 6.047359189s
STEP: Destroying namespace "nsdeletetest-8043" for this suite.
Dec 13 18:33:39.639: INFO: Namespace nsdeletetest-8043 was already deleted
STEP: Destroying namespace "nsdeletetest-4245" for this suite.
Dec 13 18:33:45.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:33:45.688: INFO: namespace nsdeletetest-4245 deletion completed in 6.04888524s

• [SLOW TEST:29.186 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:33:45.690: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-e53bf03d-df1d-40e5-a0b7-86eb9565ec8f in namespace container-probe-2467
Dec 13 18:33:51.725: INFO: Started pod liveness-e53bf03d-df1d-40e5-a0b7-86eb9565ec8f in namespace container-probe-2467
STEP: checking the pod's current state and verifying that restartCount is present
Dec 13 18:33:51.727: INFO: Initial restart count of pod liveness-e53bf03d-df1d-40e5-a0b7-86eb9565ec8f is 0
Dec 13 18:34:05.744: INFO: Restart count of pod container-probe-2467/liveness-e53bf03d-df1d-40e5-a0b7-86eb9565ec8f is now 1 (14.016598189s elapsed)
Dec 13 18:34:25.767: INFO: Restart count of pod container-probe-2467/liveness-e53bf03d-df1d-40e5-a0b7-86eb9565ec8f is now 2 (34.039806335s elapsed)
Dec 13 18:34:45.789: INFO: Restart count of pod container-probe-2467/liveness-e53bf03d-df1d-40e5-a0b7-86eb9565ec8f is now 3 (54.061632402s elapsed)
Dec 13 18:35:05.811: INFO: Restart count of pod container-probe-2467/liveness-e53bf03d-df1d-40e5-a0b7-86eb9565ec8f is now 4 (1m14.08374474s elapsed)
Dec 13 18:36:17.900: INFO: Restart count of pod container-probe-2467/liveness-e53bf03d-df1d-40e5-a0b7-86eb9565ec8f is now 5 (2m26.1727987s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:36:17.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2467" for this suite.
Dec 13 18:36:23.916: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:36:23.959: INFO: namespace container-probe-2467 deletion completed in 6.049168778s

• [SLOW TEST:158.269 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:36:23.959: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 13 18:36:24.747: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 13 18:36:26.753: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858984, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858984, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858984, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858984, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 18:36:28.755: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858984, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858984, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858984, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711858984, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 13 18:36:31.764: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 18:36:31.766: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5398-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:36:32.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9569" for this suite.
Dec 13 18:36:38.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:36:38.928: INFO: namespace webhook-9569 deletion completed in 6.050167742s
STEP: Destroying namespace "webhook-9569-markers" for this suite.
Dec 13 18:36:44.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:36:44.971: INFO: namespace webhook-9569-markers deletion completed in 6.042372495s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.018 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:36:44.977: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:36:58.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2516" for this suite.
Dec 13 18:37:04.041: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:37:04.081: INFO: namespace resourcequota-2516 deletion completed in 6.045420883s

• [SLOW TEST:19.104 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:37:04.082: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:37:15.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3512" for this suite.
Dec 13 18:37:21.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:37:21.197: INFO: namespace resourcequota-3512 deletion completed in 6.055966873s

• [SLOW TEST:17.116 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:37:21.199: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 13 18:37:21.221: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-157'
Dec 13 18:37:21.670: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 13 18:37:21.670: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Dec 13 18:37:21.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 delete jobs e2e-test-httpd-job --namespace=kubectl-157'
Dec 13 18:37:21.787: INFO: stderr: ""
Dec 13 18:37:21.787: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:37:21.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-157" for this suite.
Dec 13 18:37:27.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:37:27.837: INFO: namespace kubectl-157 deletion completed in 6.048380351s

• [SLOW TEST:6.639 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:37:27.838: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-f4c1d7e1-ff91-46c2-921c-32603f122d1e
STEP: Creating a pod to test consume secrets
Dec 13 18:37:27.870: INFO: Waiting up to 5m0s for pod "pod-secrets-3a7c3d85-9b86-40d6-9609-c27c3e1ed302" in namespace "secrets-6867" to be "success or failure"
Dec 13 18:37:27.876: INFO: Pod "pod-secrets-3a7c3d85-9b86-40d6-9609-c27c3e1ed302": Phase="Pending", Reason="", readiness=false. Elapsed: 6.436738ms
Dec 13 18:37:29.878: INFO: Pod "pod-secrets-3a7c3d85-9b86-40d6-9609-c27c3e1ed302": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008652532s
Dec 13 18:37:31.881: INFO: Pod "pod-secrets-3a7c3d85-9b86-40d6-9609-c27c3e1ed302": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011034982s
Dec 13 18:37:33.883: INFO: Pod "pod-secrets-3a7c3d85-9b86-40d6-9609-c27c3e1ed302": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.013155703s
STEP: Saw pod success
Dec 13 18:37:33.883: INFO: Pod "pod-secrets-3a7c3d85-9b86-40d6-9609-c27c3e1ed302" satisfied condition "success or failure"
Dec 13 18:37:33.884: INFO: Trying to get logs from node 172.160.134.165 pod pod-secrets-3a7c3d85-9b86-40d6-9609-c27c3e1ed302 container secret-volume-test: <nil>
STEP: delete the pod
Dec 13 18:37:33.904: INFO: Waiting for pod pod-secrets-3a7c3d85-9b86-40d6-9609-c27c3e1ed302 to disappear
Dec 13 18:37:33.908: INFO: Pod pod-secrets-3a7c3d85-9b86-40d6-9609-c27c3e1ed302 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:37:33.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6867" for this suite.
Dec 13 18:37:39.918: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:37:39.963: INFO: namespace secrets-6867 deletion completed in 6.052808056s

• [SLOW TEST:12.125 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:37:39.963: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Dec 13 18:37:39.987: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Dec 13 18:37:57.397: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 18:38:01.979: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:38:19.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8871" for this suite.
Dec 13 18:38:25.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:38:25.791: INFO: namespace crd-publish-openapi-8871 deletion completed in 6.051839829s

• [SLOW TEST:45.828 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:38:25.791: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-cfb85805-aa9a-4f5f-adbb-bac07127dc66
STEP: Creating a pod to test consume configMaps
Dec 13 18:38:25.820: INFO: Waiting up to 5m0s for pod "pod-configmaps-3df4bad5-a4e2-4a53-a1a9-3b4eb098af4e" in namespace "configmap-5633" to be "success or failure"
Dec 13 18:38:25.823: INFO: Pod "pod-configmaps-3df4bad5-a4e2-4a53-a1a9-3b4eb098af4e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.324384ms
Dec 13 18:38:27.825: INFO: Pod "pod-configmaps-3df4bad5-a4e2-4a53-a1a9-3b4eb098af4e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005448923s
Dec 13 18:38:29.828: INFO: Pod "pod-configmaps-3df4bad5-a4e2-4a53-a1a9-3b4eb098af4e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007830055s
Dec 13 18:38:31.830: INFO: Pod "pod-configmaps-3df4bad5-a4e2-4a53-a1a9-3b4eb098af4e": Phase="Pending", Reason="", readiness=false. Elapsed: 6.0103239s
Dec 13 18:38:33.832: INFO: Pod "pod-configmaps-3df4bad5-a4e2-4a53-a1a9-3b4eb098af4e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.012781576s
STEP: Saw pod success
Dec 13 18:38:33.833: INFO: Pod "pod-configmaps-3df4bad5-a4e2-4a53-a1a9-3b4eb098af4e" satisfied condition "success or failure"
Dec 13 18:38:33.834: INFO: Trying to get logs from node 172.160.134.166 pod pod-configmaps-3df4bad5-a4e2-4a53-a1a9-3b4eb098af4e container configmap-volume-test: <nil>
STEP: delete the pod
Dec 13 18:38:33.863: INFO: Waiting for pod pod-configmaps-3df4bad5-a4e2-4a53-a1a9-3b4eb098af4e to disappear
Dec 13 18:38:33.867: INFO: Pod pod-configmaps-3df4bad5-a4e2-4a53-a1a9-3b4eb098af4e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:38:33.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5633" for this suite.
Dec 13 18:38:39.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:38:39.928: INFO: namespace configmap-5633 deletion completed in 6.059646536s

• [SLOW TEST:14.137 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:38:39.929: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 18:38:39.950: INFO: Creating ReplicaSet my-hostname-basic-55302f0b-632c-4e7b-af6b-2770bc547cb3
Dec 13 18:38:39.954: INFO: Pod name my-hostname-basic-55302f0b-632c-4e7b-af6b-2770bc547cb3: Found 0 pods out of 1
Dec 13 18:38:44.957: INFO: Pod name my-hostname-basic-55302f0b-632c-4e7b-af6b-2770bc547cb3: Found 1 pods out of 1
Dec 13 18:38:44.957: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-55302f0b-632c-4e7b-af6b-2770bc547cb3" is running
Dec 13 18:38:46.960: INFO: Pod "my-hostname-basic-55302f0b-632c-4e7b-af6b-2770bc547cb3-rns8l" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-13 18:38:39 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-13 18:38:39 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-55302f0b-632c-4e7b-af6b-2770bc547cb3]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-13 18:38:39 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-55302f0b-632c-4e7b-af6b-2770bc547cb3]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-13 18:38:39 +0000 UTC Reason: Message:}])
Dec 13 18:38:46.961: INFO: Trying to dial the pod
Dec 13 18:38:51.970: INFO: Controller my-hostname-basic-55302f0b-632c-4e7b-af6b-2770bc547cb3: Got expected result from replica 1 [my-hostname-basic-55302f0b-632c-4e7b-af6b-2770bc547cb3-rns8l]: "my-hostname-basic-55302f0b-632c-4e7b-af6b-2770bc547cb3-rns8l", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:38:51.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-1987" for this suite.
Dec 13 18:38:57.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:38:58.024: INFO: namespace replicaset-1987 deletion completed in 6.051991087s

• [SLOW TEST:18.095 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:38:58.025: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 13 18:38:58.052: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 13 18:38:58.057: INFO: Waiting for terminating namespaces to be deleted...
Dec 13 18:38:58.058: INFO: 
Logging pods the kubelet thinks is on node 172.160.134.165 before test
Dec 13 18:38:58.062: INFO: iag-172.160.134.165 from kube-system started at 2019-12-12 13:53:36 +0000 UTC (1 container statuses recorded)
Dec 13 18:38:58.062: INFO: 	Container iag ready: true, restart count 0
Dec 13 18:38:58.062: INFO: sonobuoy-e2e-job-acb159fe38ea4959 from sonobuoy started at 2019-12-13 17:43:15 +0000 UTC (2 container statuses recorded)
Dec 13 18:38:58.062: INFO: 	Container e2e ready: true, restart count 0
Dec 13 18:38:58.062: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 13 18:38:58.062: INFO: sonobuoy-systemd-logs-daemon-set-5a2f946422e448af-pq5l8 from sonobuoy started at 2019-12-13 17:43:15 +0000 UTC (2 container statuses recorded)
Dec 13 18:38:58.062: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 13 18:38:58.062: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 13 18:38:58.062: INFO: 
Logging pods the kubelet thinks is on node 172.160.134.166 before test
Dec 13 18:38:58.068: INFO: coredns-6cf786c879-zgnqd from kube-system started at 2019-12-12 19:44:20 +0000 UTC (1 container statuses recorded)
Dec 13 18:38:58.068: INFO: 	Container coredns ready: true, restart count 0
Dec 13 18:38:58.068: INFO: sonobuoy from sonobuoy started at 2019-12-13 17:42:49 +0000 UTC (1 container statuses recorded)
Dec 13 18:38:58.068: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 13 18:38:58.068: INFO: sonobuoy-systemd-logs-daemon-set-5a2f946422e448af-cjc42 from sonobuoy started at 2019-12-13 17:43:15 +0000 UTC (2 container statuses recorded)
Dec 13 18:38:58.068: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 13 18:38:58.068: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node 172.160.134.165
STEP: verifying the node has the label node 172.160.134.166
Dec 13 18:38:58.087: INFO: Pod coredns-6cf786c879-zgnqd requesting resource cpu=100m on Node 172.160.134.166
Dec 13 18:38:58.087: INFO: Pod iag-172.160.134.165 requesting resource cpu=0m on Node 172.160.134.165
Dec 13 18:38:58.087: INFO: Pod sonobuoy requesting resource cpu=0m on Node 172.160.134.166
Dec 13 18:38:58.087: INFO: Pod sonobuoy-e2e-job-acb159fe38ea4959 requesting resource cpu=0m on Node 172.160.134.165
Dec 13 18:38:58.087: INFO: Pod sonobuoy-systemd-logs-daemon-set-5a2f946422e448af-cjc42 requesting resource cpu=0m on Node 172.160.134.166
Dec 13 18:38:58.087: INFO: Pod sonobuoy-systemd-logs-daemon-set-5a2f946422e448af-pq5l8 requesting resource cpu=0m on Node 172.160.134.165
STEP: Starting Pods to consume most of the cluster CPU.
Dec 13 18:38:58.087: INFO: Creating a pod which consumes cpu=4900m on Node 172.160.134.165
Dec 13 18:38:58.090: INFO: Creating a pod which consumes cpu=4830m on Node 172.160.134.166
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-628b767b-f75e-42f4-93f8-2928159ca39f.15e0023ebf95d18a], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1528/filler-pod-628b767b-f75e-42f4-93f8-2928159ca39f to 172.160.134.166]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-628b767b-f75e-42f4-93f8-2928159ca39f.15e00240190f1422], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-628b767b-f75e-42f4-93f8-2928159ca39f.15e002401bd1b85a], Reason = [Created], Message = [Created container filler-pod-628b767b-f75e-42f4-93f8-2928159ca39f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-628b767b-f75e-42f4-93f8-2928159ca39f.15e002402b1fa353], Reason = [Started], Message = [Started container filler-pod-628b767b-f75e-42f4-93f8-2928159ca39f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9def18e1-b629-4097-9613-b5c572e318a0.15e0023ebeed1742], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1528/filler-pod-9def18e1-b629-4097-9613-b5c572e318a0 to 172.160.134.165]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9def18e1-b629-4097-9613-b5c572e318a0.15e0023fc007b239], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9def18e1-b629-4097-9613-b5c572e318a0.15e0023fc2dc4059], Reason = [Created], Message = [Created container filler-pod-9def18e1-b629-4097-9613-b5c572e318a0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-9def18e1-b629-4097-9613-b5c572e318a0.15e0023fc990c172], Reason = [Started], Message = [Started container filler-pod-9def18e1-b629-4097-9613-b5c572e318a0]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15e002409d16e8bb], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node 172.160.134.165
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 172.160.134.166
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:39:07.134: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1528" for this suite.
Dec 13 18:39:13.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:39:13.183: INFO: namespace sched-pred-1528 deletion completed in 6.048188049s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:15.158 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:39:13.184: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-4657
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-4657
STEP: Deleting pre-stop pod
Dec 13 18:39:32.227: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:39:32.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-4657" for this suite.
Dec 13 18:40:16.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:40:16.289: INFO: namespace prestop-4657 deletion completed in 44.056353707s

• [SLOW TEST:63.105 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:40:16.289: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 13 18:40:22.836: INFO: Successfully updated pod "annotationupdate837c48b7-2661-490c-b3f9-60887c521038"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:40:24.853: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3968" for this suite.
Dec 13 18:40:36.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:40:36.903: INFO: namespace downward-api-3968 deletion completed in 12.047847697s

• [SLOW TEST:20.614 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:40:36.903: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6992.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6992.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 13 18:41:06.966: INFO: DNS probes using dns-6992/dns-test-6b4f7d0c-f3d1-4d38-b705-6fb15fb11f9a succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:41:06.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6992" for this suite.
Dec 13 18:41:12.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:41:13.040: INFO: namespace dns-6992 deletion completed in 6.051328944s

• [SLOW TEST:36.137 seconds]
[sig-network] DNS
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:41:13.041: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:41:21.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1158" for this suite.
Dec 13 18:42:05.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:42:05.149: INFO: namespace kubelet-test-1158 deletion completed in 44.049232363s

• [SLOW TEST:52.108 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:42:05.149: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 18:42:27.183: INFO: Container started at 2019-12-13 18:42:09 +0000 UTC, pod became ready at 2019-12-13 18:42:26 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:42:27.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3998" for this suite.
Dec 13 18:42:39.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:42:39.237: INFO: namespace container-probe-3998 deletion completed in 12.051660095s

• [SLOW TEST:34.088 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:42:39.237: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 18:42:39.267: INFO: Creating deployment "webserver-deployment"
Dec 13 18:42:39.269: INFO: Waiting for observed generation 1
Dec 13 18:42:41.276: INFO: Waiting for all required pods to come up
Dec 13 18:42:41.278: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec 13 18:42:51.282: INFO: Waiting for deployment "webserver-deployment" to complete
Dec 13 18:42:51.286: INFO: Updating deployment "webserver-deployment" with a non-existent image
Dec 13 18:42:51.290: INFO: Updating deployment webserver-deployment
Dec 13 18:42:51.290: INFO: Waiting for observed generation 2
Dec 13 18:42:53.294: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec 13 18:42:53.296: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec 13 18:42:53.297: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 13 18:42:53.301: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec 13 18:42:53.301: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec 13 18:42:53.302: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 13 18:42:53.305: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Dec 13 18:42:53.305: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Dec 13 18:42:53.308: INFO: Updating deployment webserver-deployment
Dec 13 18:42:53.308: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Dec 13 18:42:53.312: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec 13 18:42:53.315: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 13 18:42:53.341: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-3173 /apis/apps/v1/namespaces/deployment-3173/deployments/webserver-deployment 2127c13c-3208-4917-bea6-1dc120a6bc64 123882 3 2019-12-13 18:42:39 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002d06a98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2019-12-13 18:42:51 +0000 UTC,LastTransitionTime:2019-12-13 18:42:39 +0000 UTC,},DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-12-13 18:42:53 +0000 UTC,LastTransitionTime:2019-12-13 18:42:53 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Dec 13 18:42:53.362: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-3173 /apis/apps/v1/namespaces/deployment-3173/replicasets/webserver-deployment-c7997dcc8 37f7ff87-40fd-47f5-bde4-7053c53b5dd5 123863 3 2019-12-13 18:42:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 2127c13c-3208-4917-bea6-1dc120a6bc64 0xc004c828d7 0xc004c828d8}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004c82978 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 13 18:42:53.362: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Dec 13 18:42:53.362: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-3173 /apis/apps/v1/namespaces/deployment-3173/replicasets/webserver-deployment-595b5b9587 30450f4c-2686-4c5c-a2fe-d7b5b7e939ee 123861 3 2019-12-13 18:42:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 2127c13c-3208-4917-bea6-1dc120a6bc64 0xc004c82817 0xc004c82818}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004c82878 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Dec 13 18:42:53.373: INFO: Pod "webserver-deployment-595b5b9587-4dtl7" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-4dtl7 webserver-deployment-595b5b9587- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-595b5b9587-4dtl7 f4eebbc7-752a-4e7e-9d95-aa52131cd3cd 123872 0 2019-12-13 18:42:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 30450f4c-2686-4c5c-a2fe-d7b5b7e939ee 0xc003d9b297 0xc003d9b298}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.373: INFO: Pod "webserver-deployment-595b5b9587-5w7m9" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-5w7m9 webserver-deployment-595b5b9587- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-595b5b9587-5w7m9 ac1b1bd2-56e2-4848-9edc-646fa5e0a2c6 123887 0 2019-12-13 18:42:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 30450f4c-2686-4c5c-a2fe-d7b5b7e939ee 0xc003d9b3b0 0xc003d9b3b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.373: INFO: Pod "webserver-deployment-595b5b9587-6lqds" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6lqds webserver-deployment-595b5b9587- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-595b5b9587-6lqds 8e61637d-0ed0-4156-a558-67015fb38e25 123910 0 2019-12-13 18:42:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 30450f4c-2686-4c5c-a2fe-d7b5b7e939ee 0xc003d9b4d0 0xc003d9b4d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.373: INFO: Pod "webserver-deployment-595b5b9587-7tv2m" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-7tv2m webserver-deployment-595b5b9587- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-595b5b9587-7tv2m 0aa09c51-5488-4ac5-997d-b4a5e4777005 123793 0 2019-12-13 18:42:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 30450f4c-2686-4c5c-a2fe-d7b5b7e939ee 0xc003d9b5f0 0xc003d9b5f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.160.134.166,PodIP:172.160.134.148,StartTime:2019-12-13 18:42:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-13 18:42:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://73723a16b48c25048f8292f78476f41582a9bed0b6d882348c474172aa03f21b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.160.134.148,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.373: INFO: Pod "webserver-deployment-595b5b9587-8zcv6" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-8zcv6 webserver-deployment-595b5b9587- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-595b5b9587-8zcv6 65b23981-8d21-4e3f-add0-3388c6b9eb3c 123914 0 2019-12-13 18:42:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 30450f4c-2686-4c5c-a2fe-d7b5b7e939ee 0xc003d9b787 0xc003d9b788}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.374: INFO: Pod "webserver-deployment-595b5b9587-ctbg4" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-ctbg4 webserver-deployment-595b5b9587- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-595b5b9587-ctbg4 925217f3-ef51-48f2-82ee-ff3f38ac16a9 123779 0 2019-12-13 18:42:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 30450f4c-2686-4c5c-a2fe-d7b5b7e939ee 0xc003d9b8a0 0xc003d9b8a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.160.134.166,PodIP:172.160.134.142,StartTime:2019-12-13 18:42:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-13 18:42:46 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://fab0bd49b9dded0a7187a4868bcbeb27aac9f2dd68ec942d749606be984e1618,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.160.134.142,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.374: INFO: Pod "webserver-deployment-595b5b9587-dcd8s" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-dcd8s webserver-deployment-595b5b9587- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-595b5b9587-dcd8s ac6976a9-75f3-439f-8d01-abe7489c4252 123866 0 2019-12-13 18:42:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 30450f4c-2686-4c5c-a2fe-d7b5b7e939ee 0xc003d9ba57 0xc003d9ba58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.374: INFO: Pod "webserver-deployment-595b5b9587-dqggk" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-dqggk webserver-deployment-595b5b9587- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-595b5b9587-dqggk eb22d4fa-fbcf-4b76-b931-55b9814ea5b0 123745 0 2019-12-13 18:42:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 30450f4c-2686-4c5c-a2fe-d7b5b7e939ee 0xc003d9bb70 0xc003d9bb71}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.160.134.166,PodIP:172.160.134.138,StartTime:2019-12-13 18:42:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-13 18:42:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://b5070644da9bd57deaf1373212b64a55d6c91dc32d3db02edcdb983b0b0a6932,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.160.134.138,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.374: INFO: Pod "webserver-deployment-595b5b9587-gjdzk" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gjdzk webserver-deployment-595b5b9587- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-595b5b9587-gjdzk 06dd7a0d-23fa-4b1a-93e5-f024c078ea4e 123770 0 2019-12-13 18:42:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 30450f4c-2686-4c5c-a2fe-d7b5b7e939ee 0xc003d9bd07 0xc003d9bd08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.160.134.165,PodIP:172.160.134.143,StartTime:2019-12-13 18:42:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-13 18:42:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://857ee5685b73310715cb0b372acacb382b6a8b322bd38537c865544c3b3d081f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.160.134.143,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.375: INFO: Pod "webserver-deployment-595b5b9587-gm7r4" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gm7r4 webserver-deployment-595b5b9587- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-595b5b9587-gm7r4 b0e3de07-a1e2-4c3b-b206-7ffdf12cc57c 123874 0 2019-12-13 18:42:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 30450f4c-2686-4c5c-a2fe-d7b5b7e939ee 0xc003d9be87 0xc003d9be88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.376: INFO: Pod "webserver-deployment-595b5b9587-gxl8g" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gxl8g webserver-deployment-595b5b9587- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-595b5b9587-gxl8g ce5f0212-412d-4294-850c-8233b164defe 123908 0 2019-12-13 18:42:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 30450f4c-2686-4c5c-a2fe-d7b5b7e939ee 0xc003d9bfa0 0xc003d9bfa1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.376: INFO: Pod "webserver-deployment-595b5b9587-jc6vv" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-jc6vv webserver-deployment-595b5b9587- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-595b5b9587-jc6vv 2d2c51d4-0ede-4751-84f2-13669fab6972 123900 0 2019-12-13 18:42:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 30450f4c-2686-4c5c-a2fe-d7b5b7e939ee 0xc003222160 0xc003222161}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.376: INFO: Pod "webserver-deployment-595b5b9587-k8cgg" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-k8cgg webserver-deployment-595b5b9587- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-595b5b9587-k8cgg 3a8a0488-d980-481a-bde3-776c9b90e741 123768 0 2019-12-13 18:42:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 30450f4c-2686-4c5c-a2fe-d7b5b7e939ee 0xc003222320 0xc003222321}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.160.134.165,PodIP:172.160.134.139,StartTime:2019-12-13 18:42:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-13 18:42:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://1db8291c99a5766f316d615ae410fa7a71ab4523c3c7a32619d1f6d05f9d8315,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.160.134.139,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.376: INFO: Pod "webserver-deployment-595b5b9587-mhl5b" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mhl5b webserver-deployment-595b5b9587- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-595b5b9587-mhl5b 52054915-3180-43ec-9eea-35b3a6684dc7 123909 0 2019-12-13 18:42:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 30450f4c-2686-4c5c-a2fe-d7b5b7e939ee 0xc003222547 0xc003222548}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.376: INFO: Pod "webserver-deployment-595b5b9587-nrgvw" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-nrgvw webserver-deployment-595b5b9587- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-595b5b9587-nrgvw 72221a90-fc06-4344-8074-efe09829b86d 123915 0 2019-12-13 18:42:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 30450f4c-2686-4c5c-a2fe-d7b5b7e939ee 0xc003222800 0xc003222801}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.377: INFO: Pod "webserver-deployment-595b5b9587-rpk9l" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-rpk9l webserver-deployment-595b5b9587- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-595b5b9587-rpk9l 100f9da5-4010-4d95-8254-d1dc0e2818dc 123888 0 2019-12-13 18:42:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 30450f4c-2686-4c5c-a2fe-d7b5b7e939ee 0xc003222950 0xc003222951}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.377: INFO: Pod "webserver-deployment-595b5b9587-twx7j" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-twx7j webserver-deployment-595b5b9587- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-595b5b9587-twx7j 162a8e67-8f4e-4dc6-b823-e2aa2f2f26a1 123782 0 2019-12-13 18:42:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 30450f4c-2686-4c5c-a2fe-d7b5b7e939ee 0xc003222be0 0xc003222be1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.160.134.166,PodIP:172.160.134.140,StartTime:2019-12-13 18:42:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-13 18:42:46 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://5360dff0d12118042d22e30a3c1d8362aec3df02ba06805f633bcdb88a6ab623,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.160.134.140,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.377: INFO: Pod "webserver-deployment-595b5b9587-x8zrc" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-x8zrc webserver-deployment-595b5b9587- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-595b5b9587-x8zrc 557b53c8-23e4-47b5-96e3-72ef8bb78721 123765 0 2019-12-13 18:42:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 30450f4c-2686-4c5c-a2fe-d7b5b7e939ee 0xc003222d57 0xc003222d58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.160.134.165,PodIP:172.160.134.141,StartTime:2019-12-13 18:42:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-13 18:42:46 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://1a9626f3c384193da2e157389777540ae35b4744d1e54a772599b56fa3844336,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.160.134.141,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.377: INFO: Pod "webserver-deployment-595b5b9587-xhwp9" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-xhwp9 webserver-deployment-595b5b9587- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-595b5b9587-xhwp9 f38cea1c-302a-4c42-a15f-1146a3b95424 123890 0 2019-12-13 18:42:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 30450f4c-2686-4c5c-a2fe-d7b5b7e939ee 0xc003222ee7 0xc003222ee8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.377: INFO: Pod "webserver-deployment-595b5b9587-zpflr" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zpflr webserver-deployment-595b5b9587- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-595b5b9587-zpflr 7d975654-f48a-4f97-a898-0d09c08e8a94 123775 0 2019-12-13 18:42:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 30450f4c-2686-4c5c-a2fe-d7b5b7e939ee 0xc003223000 0xc003223001}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.160.134.165,PodIP:172.160.134.144,StartTime:2019-12-13 18:42:39 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-13 18:42:46 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://4cf03cd4b6ebaf5ebe61fdea70f09071af07ef153014b97f7afbed58023c143c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.160.134.144,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.378: INFO: Pod "webserver-deployment-c7997dcc8-5jtzh" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-5jtzh webserver-deployment-c7997dcc8- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-c7997dcc8-5jtzh ca72489d-0ff6-4b57-a047-7579f3747289 123889 0 2019-12-13 18:42:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 37f7ff87-40fd-47f5-bde4-7053c53b5dd5 0xc003223177 0xc003223178}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.381: INFO: Pod "webserver-deployment-c7997dcc8-6f98x" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-6f98x webserver-deployment-c7997dcc8- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-c7997dcc8-6f98x a89c9c0d-d104-4561-9081-b074dea54d1f 123906 0 2019-12-13 18:42:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 37f7ff87-40fd-47f5-bde4-7053c53b5dd5 0xc0032234b0 0xc0032234b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.381: INFO: Pod "webserver-deployment-c7997dcc8-7qxnh" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-7qxnh webserver-deployment-c7997dcc8- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-c7997dcc8-7qxnh 13a64f71-9afd-48ca-9846-7fd9e299dc80 123911 0 2019-12-13 18:42:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 37f7ff87-40fd-47f5-bde4-7053c53b5dd5 0xc0032236a0 0xc0032236a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.381: INFO: Pod "webserver-deployment-c7997dcc8-bxvhs" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-bxvhs webserver-deployment-c7997dcc8- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-c7997dcc8-bxvhs 90397bf6-bd53-43db-b636-7359acce2a18 123846 0 2019-12-13 18:42:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 37f7ff87-40fd-47f5-bde4-7053c53b5dd5 0xc0032238d0 0xc0032238d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.160.134.165,PodIP:,StartTime:2019-12-13 18:42:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.381: INFO: Pod "webserver-deployment-c7997dcc8-cb78h" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-cb78h webserver-deployment-c7997dcc8- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-c7997dcc8-cb78h ee18cacb-56ec-4e09-84d5-723d68610c2b 123875 0 2019-12-13 18:42:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 37f7ff87-40fd-47f5-bde4-7053c53b5dd5 0xc003223af7 0xc003223af8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.381: INFO: Pod "webserver-deployment-c7997dcc8-gp299" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-gp299 webserver-deployment-c7997dcc8- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-c7997dcc8-gp299 6267b93c-f429-4ad5-a61a-a13bf430808d 123837 0 2019-12-13 18:42:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 37f7ff87-40fd-47f5-bde4-7053c53b5dd5 0xc003223cb0 0xc003223cb1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.160.134.166,PodIP:,StartTime:2019-12-13 18:42:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.382: INFO: Pod "webserver-deployment-c7997dcc8-j6jm8" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-j6jm8 webserver-deployment-c7997dcc8- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-c7997dcc8-j6jm8 8c0818a0-7793-4aa2-908a-88cc521f9061 123918 0 2019-12-13 18:42:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 37f7ff87-40fd-47f5-bde4-7053c53b5dd5 0xc003223f77 0xc003223f78}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.382: INFO: Pod "webserver-deployment-c7997dcc8-nsfth" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-nsfth webserver-deployment-c7997dcc8- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-c7997dcc8-nsfth 5b83e686-0fd6-4988-b7ec-8b1a4c230721 123838 0 2019-12-13 18:42:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 37f7ff87-40fd-47f5-bde4-7053c53b5dd5 0xc0039d80a0 0xc0039d80a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.160.134.165,PodIP:,StartTime:2019-12-13 18:42:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.382: INFO: Pod "webserver-deployment-c7997dcc8-sfqxx" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-sfqxx webserver-deployment-c7997dcc8- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-c7997dcc8-sfqxx ff019370-c21d-4d84-8677-bc03aeb95a86 123907 0 2019-12-13 18:42:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 37f7ff87-40fd-47f5-bde4-7053c53b5dd5 0xc0039d8217 0xc0039d8218}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.382: INFO: Pod "webserver-deployment-c7997dcc8-tdt44" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-tdt44 webserver-deployment-c7997dcc8- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-c7997dcc8-tdt44 d04bb185-4e79-45b9-91b6-36a7a4d88f1b 123885 0 2019-12-13 18:42:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 37f7ff87-40fd-47f5-bde4-7053c53b5dd5 0xc0039d8340 0xc0039d8341}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.382: INFO: Pod "webserver-deployment-c7997dcc8-tn7wn" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-tn7wn webserver-deployment-c7997dcc8- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-c7997dcc8-tn7wn a7ad326f-5216-421b-81a9-2ea45a8f0e05 123858 0 2019-12-13 18:42:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 37f7ff87-40fd-47f5-bde4-7053c53b5dd5 0xc0039d8460 0xc0039d8461}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.160.134.166,PodIP:,StartTime:2019-12-13 18:42:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.382: INFO: Pod "webserver-deployment-c7997dcc8-vxcmt" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-vxcmt webserver-deployment-c7997dcc8- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-c7997dcc8-vxcmt a19c489b-bfe6-4b35-a788-b16dbb6185cc 123859 0 2019-12-13 18:42:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 37f7ff87-40fd-47f5-bde4-7053c53b5dd5 0xc0039d85d7 0xc0039d85d8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.166,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:42:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.160.134.166,PodIP:,StartTime:2019-12-13 18:42:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 13 18:42:53.383: INFO: Pod "webserver-deployment-c7997dcc8-wj5cm" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-wj5cm webserver-deployment-c7997dcc8- deployment-3173 /api/v1/namespaces/deployment-3173/pods/webserver-deployment-c7997dcc8-wj5cm fa4805b2-fd69-4ad9-9606-bdfaee773d82 123913 0 2019-12-13 18:42:53 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 37f7ff87-40fd-47f5-bde4-7053c53b5dd5 0xc0039d8757 0xc0039d8758}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q847z,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q847z,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q847z,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:42:53.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3173" for this suite.
Dec 13 18:43:01.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:43:01.477: INFO: namespace deployment-3173 deletion completed in 8.071234113s

• [SLOW TEST:22.240 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:43:01.478: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-f5f1ee32-e3ee-4e80-aea5-d156ea9cc667
STEP: Creating a pod to test consume configMaps
Dec 13 18:43:01.509: INFO: Waiting up to 5m0s for pod "pod-configmaps-d2c30972-6a9e-441e-9522-1975a1c08bab" in namespace "configmap-8335" to be "success or failure"
Dec 13 18:43:01.512: INFO: Pod "pod-configmaps-d2c30972-6a9e-441e-9522-1975a1c08bab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.510679ms
Dec 13 18:43:03.513: INFO: Pod "pod-configmaps-d2c30972-6a9e-441e-9522-1975a1c08bab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0042835s
Dec 13 18:43:05.516: INFO: Pod "pod-configmaps-d2c30972-6a9e-441e-9522-1975a1c08bab": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00660988s
Dec 13 18:43:07.518: INFO: Pod "pod-configmaps-d2c30972-6a9e-441e-9522-1975a1c08bab": Phase="Pending", Reason="", readiness=false. Elapsed: 6.00882651s
Dec 13 18:43:09.520: INFO: Pod "pod-configmaps-d2c30972-6a9e-441e-9522-1975a1c08bab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.011046951s
STEP: Saw pod success
Dec 13 18:43:09.520: INFO: Pod "pod-configmaps-d2c30972-6a9e-441e-9522-1975a1c08bab" satisfied condition "success or failure"
Dec 13 18:43:09.522: INFO: Trying to get logs from node 172.160.134.165 pod pod-configmaps-d2c30972-6a9e-441e-9522-1975a1c08bab container configmap-volume-test: <nil>
STEP: delete the pod
Dec 13 18:43:09.543: INFO: Waiting for pod pod-configmaps-d2c30972-6a9e-441e-9522-1975a1c08bab to disappear
Dec 13 18:43:09.546: INFO: Pod pod-configmaps-d2c30972-6a9e-441e-9522-1975a1c08bab no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:43:09.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8335" for this suite.
Dec 13 18:43:15.554: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:43:15.596: INFO: namespace configmap-8335 deletion completed in 6.04822626s

• [SLOW TEST:14.118 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:43:15.598: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Dec 13 18:43:46.142: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1213 18:43:46.142027      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:43:46.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4465" for this suite.
Dec 13 18:43:52.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:43:52.194: INFO: namespace gc-4465 deletion completed in 6.048443306s

• [SLOW TEST:36.596 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:43:52.194: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 13 18:43:52.228: INFO: Waiting up to 5m0s for pod "pod-e5b1d100-2fba-401e-a3f4-b3d3c4c79c80" in namespace "emptydir-1411" to be "success or failure"
Dec 13 18:43:52.234: INFO: Pod "pod-e5b1d100-2fba-401e-a3f4-b3d3c4c79c80": Phase="Pending", Reason="", readiness=false. Elapsed: 5.21869ms
Dec 13 18:43:54.236: INFO: Pod "pod-e5b1d100-2fba-401e-a3f4-b3d3c4c79c80": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007417994s
Dec 13 18:43:56.238: INFO: Pod "pod-e5b1d100-2fba-401e-a3f4-b3d3c4c79c80": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009772218s
Dec 13 18:43:58.241: INFO: Pod "pod-e5b1d100-2fba-401e-a3f4-b3d3c4c79c80": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012199205s
Dec 13 18:44:00.243: INFO: Pod "pod-e5b1d100-2fba-401e-a3f4-b3d3c4c79c80": Phase="Pending", Reason="", readiness=false. Elapsed: 8.01432903s
Dec 13 18:44:02.245: INFO: Pod "pod-e5b1d100-2fba-401e-a3f4-b3d3c4c79c80": Phase="Pending", Reason="", readiness=false. Elapsed: 10.016442441s
Dec 13 18:44:04.247: INFO: Pod "pod-e5b1d100-2fba-401e-a3f4-b3d3c4c79c80": Phase="Pending", Reason="", readiness=false. Elapsed: 12.018645787s
Dec 13 18:44:06.249: INFO: Pod "pod-e5b1d100-2fba-401e-a3f4-b3d3c4c79c80": Phase="Pending", Reason="", readiness=false. Elapsed: 14.020999115s
Dec 13 18:44:08.252: INFO: Pod "pod-e5b1d100-2fba-401e-a3f4-b3d3c4c79c80": Phase="Pending", Reason="", readiness=false. Elapsed: 16.023128077s
Dec 13 18:44:10.254: INFO: Pod "pod-e5b1d100-2fba-401e-a3f4-b3d3c4c79c80": Phase="Pending", Reason="", readiness=false. Elapsed: 18.025384033s
Dec 13 18:44:12.256: INFO: Pod "pod-e5b1d100-2fba-401e-a3f4-b3d3c4c79c80": Phase="Pending", Reason="", readiness=false. Elapsed: 20.027555517s
Dec 13 18:44:14.258: INFO: Pod "pod-e5b1d100-2fba-401e-a3f4-b3d3c4c79c80": Phase="Pending", Reason="", readiness=false. Elapsed: 22.029965601s
Dec 13 18:44:16.261: INFO: Pod "pod-e5b1d100-2fba-401e-a3f4-b3d3c4c79c80": Phase="Pending", Reason="", readiness=false. Elapsed: 24.032187899s
Dec 13 18:44:18.263: INFO: Pod "pod-e5b1d100-2fba-401e-a3f4-b3d3c4c79c80": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.034887467s
STEP: Saw pod success
Dec 13 18:44:18.263: INFO: Pod "pod-e5b1d100-2fba-401e-a3f4-b3d3c4c79c80" satisfied condition "success or failure"
Dec 13 18:44:18.265: INFO: Trying to get logs from node 172.160.134.165 pod pod-e5b1d100-2fba-401e-a3f4-b3d3c4c79c80 container test-container: <nil>
STEP: delete the pod
Dec 13 18:44:18.280: INFO: Waiting for pod pod-e5b1d100-2fba-401e-a3f4-b3d3c4c79c80 to disappear
Dec 13 18:44:18.283: INFO: Pod pod-e5b1d100-2fba-401e-a3f4-b3d3c4c79c80 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:44:18.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1411" for this suite.
Dec 13 18:44:24.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:44:24.334: INFO: namespace emptydir-1411 deletion completed in 6.049575316s

• [SLOW TEST:32.140 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:44:24.335: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-8a0ebd1f-2af9-4c4c-b835-7eca5a600530
STEP: Creating secret with name secret-projected-all-test-volume-a12fd4d8-74f0-4efa-b053-a29127b6a7fc
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec 13 18:44:24.363: INFO: Waiting up to 5m0s for pod "projected-volume-f3baaf31-9442-4230-b26f-07d215ba8bf4" in namespace "projected-335" to be "success or failure"
Dec 13 18:44:24.369: INFO: Pod "projected-volume-f3baaf31-9442-4230-b26f-07d215ba8bf4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.910298ms
Dec 13 18:44:26.371: INFO: Pod "projected-volume-f3baaf31-9442-4230-b26f-07d215ba8bf4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008250665s
Dec 13 18:44:28.373: INFO: Pod "projected-volume-f3baaf31-9442-4230-b26f-07d215ba8bf4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010336741s
Dec 13 18:44:30.375: INFO: Pod "projected-volume-f3baaf31-9442-4230-b26f-07d215ba8bf4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.012590474s
STEP: Saw pod success
Dec 13 18:44:30.375: INFO: Pod "projected-volume-f3baaf31-9442-4230-b26f-07d215ba8bf4" satisfied condition "success or failure"
Dec 13 18:44:30.377: INFO: Trying to get logs from node 172.160.134.165 pod projected-volume-f3baaf31-9442-4230-b26f-07d215ba8bf4 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec 13 18:44:30.391: INFO: Waiting for pod projected-volume-f3baaf31-9442-4230-b26f-07d215ba8bf4 to disappear
Dec 13 18:44:30.395: INFO: Pod projected-volume-f3baaf31-9442-4230-b26f-07d215ba8bf4 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:44:30.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-335" for this suite.
Dec 13 18:44:36.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:44:36.447: INFO: namespace projected-335 deletion completed in 6.049841876s

• [SLOW TEST:12.113 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:44:36.448: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 13 18:44:36.472: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-49'
Dec 13 18:44:36.584: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 13 18:44:36.584: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Dec 13 18:44:38.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 delete deployment e2e-test-httpd-deployment --namespace=kubectl-49'
Dec 13 18:44:38.710: INFO: stderr: ""
Dec 13 18:44:38.710: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:44:38.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-49" for this suite.
Dec 13 18:44:44.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:44:44.761: INFO: namespace kubectl-49 deletion completed in 6.048926648s

• [SLOW TEST:8.313 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:44:44.764: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 18:44:44.787: INFO: Creating deployment "test-recreate-deployment"
Dec 13 18:44:44.796: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec 13 18:44:44.801: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Dec 13 18:44:46.805: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec 13 18:44:46.806: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711859484, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711859484, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711859484, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711859484, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 18:44:48.808: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711859484, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711859484, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711859484, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711859484, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 18:44:50.808: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711859484, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711859484, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711859484, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711859484, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 18:44:52.808: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec 13 18:44:52.811: INFO: Updating deployment test-recreate-deployment
Dec 13 18:44:52.811: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 13 18:44:52.884: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-2617 /apis/apps/v1/namespaces/deployment-2617/deployments/test-recreate-deployment 91d2bec0-910d-48dd-8345-8214876acabe 124446 2 2019-12-13 18:44:44 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0033130a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-12-13 18:44:52 +0000 UTC,LastTransitionTime:2019-12-13 18:44:52 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2019-12-13 18:44:52 +0000 UTC,LastTransitionTime:2019-12-13 18:44:44 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Dec 13 18:44:52.888: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-2617 /apis/apps/v1/namespaces/deployment-2617/replicasets/test-recreate-deployment-5f94c574ff 666511fb-a032-4142-a546-14ca3570ccd1 124445 1 2019-12-13 18:44:52 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 91d2bec0-910d-48dd-8345-8214876acabe 0xc003313897 0xc003313898}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0033139a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 13 18:44:52.888: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec 13 18:44:52.888: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-2617 /apis/apps/v1/namespaces/deployment-2617/replicasets/test-recreate-deployment-68fc85c7bb ea2c5dcd-366e-428b-a95d-a37f2d3033a3 124434 2 2019-12-13 18:44:44 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 91d2bec0-910d-48dd-8345-8214876acabe 0xc003313a87 0xc003313a88}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003313ae8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 13 18:44:52.890: INFO: Pod "test-recreate-deployment-5f94c574ff-d8rc6" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-d8rc6 test-recreate-deployment-5f94c574ff- deployment-2617 /api/v1/namespaces/deployment-2617/pods/test-recreate-deployment-5f94c574ff-d8rc6 042b78e1-cdb6-4384-b9b0-a345632952a0 124447 0 2019-12-13 18:44:52 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 666511fb-a032-4142-a546-14ca3570ccd1 0xc002be18f7 0xc002be18f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-t6694,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-t6694,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-t6694,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:44:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:44:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:44:52 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 18:44:52 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.160.134.165,PodIP:,StartTime:2019-12-13 18:44:52 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:44:52.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2617" for this suite.
Dec 13 18:44:58.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:44:58.947: INFO: namespace deployment-2617 deletion completed in 6.055244067s

• [SLOW TEST:14.183 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:44:58.948: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 13 18:44:58.974: INFO: Waiting up to 5m0s for pod "downward-api-55fd2046-7edb-4d21-97de-55ab678484c0" in namespace "downward-api-6213" to be "success or failure"
Dec 13 18:44:58.977: INFO: Pod "downward-api-55fd2046-7edb-4d21-97de-55ab678484c0": Phase="Pending", Reason="", readiness=false. Elapsed: 3.075037ms
Dec 13 18:45:00.980: INFO: Pod "downward-api-55fd2046-7edb-4d21-97de-55ab678484c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005401398s
Dec 13 18:45:02.982: INFO: Pod "downward-api-55fd2046-7edb-4d21-97de-55ab678484c0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007559729s
Dec 13 18:45:04.984: INFO: Pod "downward-api-55fd2046-7edb-4d21-97de-55ab678484c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009890474s
STEP: Saw pod success
Dec 13 18:45:04.984: INFO: Pod "downward-api-55fd2046-7edb-4d21-97de-55ab678484c0" satisfied condition "success or failure"
Dec 13 18:45:04.986: INFO: Trying to get logs from node 172.160.134.165 pod downward-api-55fd2046-7edb-4d21-97de-55ab678484c0 container dapi-container: <nil>
STEP: delete the pod
Dec 13 18:45:04.998: INFO: Waiting for pod downward-api-55fd2046-7edb-4d21-97de-55ab678484c0 to disappear
Dec 13 18:45:05.004: INFO: Pod downward-api-55fd2046-7edb-4d21-97de-55ab678484c0 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:45:05.005: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6213" for this suite.
Dec 13 18:45:11.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:45:11.052: INFO: namespace downward-api-6213 deletion completed in 6.045954713s

• [SLOW TEST:12.105 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:45:11.053: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 18:45:11.076: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 13 18:45:15.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 --namespace=crd-publish-openapi-8044 create -f -'
Dec 13 18:45:16.349: INFO: stderr: ""
Dec 13 18:45:16.349: INFO: stdout: "e2e-test-crd-publish-openapi-2345-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 13 18:45:16.349: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 --namespace=crd-publish-openapi-8044 delete e2e-test-crd-publish-openapi-2345-crds test-cr'
Dec 13 18:45:16.465: INFO: stderr: ""
Dec 13 18:45:16.465: INFO: stdout: "e2e-test-crd-publish-openapi-2345-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Dec 13 18:45:16.465: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 --namespace=crd-publish-openapi-8044 apply -f -'
Dec 13 18:45:16.699: INFO: stderr: ""
Dec 13 18:45:16.700: INFO: stdout: "e2e-test-crd-publish-openapi-2345-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 13 18:45:16.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 --namespace=crd-publish-openapi-8044 delete e2e-test-crd-publish-openapi-2345-crds test-cr'
Dec 13 18:45:16.803: INFO: stderr: ""
Dec 13 18:45:16.803: INFO: stdout: "e2e-test-crd-publish-openapi-2345-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec 13 18:45:16.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 explain e2e-test-crd-publish-openapi-2345-crds'
Dec 13 18:45:17.020: INFO: stderr: ""
Dec 13 18:45:17.020: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2345-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:45:21.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8044" for this suite.
Dec 13 18:45:27.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:45:27.624: INFO: namespace crd-publish-openapi-8044 deletion completed in 6.053906196s

• [SLOW TEST:16.572 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:45:27.625: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Dec 13 18:45:56.156: INFO: Successfully updated pod "adopt-release-gk4ck"
STEP: Checking that the Job readopts the Pod
Dec 13 18:45:56.157: INFO: Waiting up to 15m0s for pod "adopt-release-gk4ck" in namespace "job-7168" to be "adopted"
Dec 13 18:45:56.158: INFO: Pod "adopt-release-gk4ck": Phase="Running", Reason="", readiness=true. Elapsed: 1.808848ms
Dec 13 18:45:58.161: INFO: Pod "adopt-release-gk4ck": Phase="Running", Reason="", readiness=true. Elapsed: 2.004174438s
Dec 13 18:45:58.161: INFO: Pod "adopt-release-gk4ck" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Dec 13 18:45:58.665: INFO: Successfully updated pod "adopt-release-gk4ck"
STEP: Checking that the Job releases the Pod
Dec 13 18:45:58.666: INFO: Waiting up to 15m0s for pod "adopt-release-gk4ck" in namespace "job-7168" to be "released"
Dec 13 18:45:58.667: INFO: Pod "adopt-release-gk4ck": Phase="Running", Reason="", readiness=true. Elapsed: 1.344862ms
Dec 13 18:46:00.669: INFO: Pod "adopt-release-gk4ck": Phase="Running", Reason="", readiness=true. Elapsed: 2.003547323s
Dec 13 18:46:00.669: INFO: Pod "adopt-release-gk4ck" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:46:00.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7168" for this suite.
Dec 13 18:46:44.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:46:44.719: INFO: namespace job-7168 deletion completed in 44.047653267s

• [SLOW TEST:77.094 seconds]
[sig-apps] Job
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:46:44.720: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec 13 18:46:45.000: INFO: Pod name wrapped-volume-race-ca050425-e02a-4c96-905c-8170096c6f98: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-ca050425-e02a-4c96-905c-8170096c6f98 in namespace emptydir-wrapper-1655, will wait for the garbage collector to delete the pods
Dec 13 18:46:53.097: INFO: Deleting ReplicationController wrapped-volume-race-ca050425-e02a-4c96-905c-8170096c6f98 took: 4.021832ms
Dec 13 18:46:53.397: INFO: Terminating ReplicationController wrapped-volume-race-ca050425-e02a-4c96-905c-8170096c6f98 pods took: 300.223885ms
STEP: Creating RC which spawns configmap-volume pods
Dec 13 18:47:34.311: INFO: Pod name wrapped-volume-race-71e5d051-7aff-4f79-b2ec-08fabdfcd9da: Found 0 pods out of 5
Dec 13 18:47:39.316: INFO: Pod name wrapped-volume-race-71e5d051-7aff-4f79-b2ec-08fabdfcd9da: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-71e5d051-7aff-4f79-b2ec-08fabdfcd9da in namespace emptydir-wrapper-1655, will wait for the garbage collector to delete the pods
Dec 13 18:47:43.393: INFO: Deleting ReplicationController wrapped-volume-race-71e5d051-7aff-4f79-b2ec-08fabdfcd9da took: 3.909421ms
Dec 13 18:47:43.693: INFO: Terminating ReplicationController wrapped-volume-race-71e5d051-7aff-4f79-b2ec-08fabdfcd9da pods took: 300.579902ms
STEP: Creating RC which spawns configmap-volume pods
Dec 13 18:48:24.203: INFO: Pod name wrapped-volume-race-f3b73f81-7908-48c9-9645-1a0c3c18fc06: Found 0 pods out of 5
Dec 13 18:48:29.208: INFO: Pod name wrapped-volume-race-f3b73f81-7908-48c9-9645-1a0c3c18fc06: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-f3b73f81-7908-48c9-9645-1a0c3c18fc06 in namespace emptydir-wrapper-1655, will wait for the garbage collector to delete the pods
Dec 13 18:48:37.278: INFO: Deleting ReplicationController wrapped-volume-race-f3b73f81-7908-48c9-9645-1a0c3c18fc06 took: 3.579991ms
Dec 13 18:48:37.578: INFO: Terminating ReplicationController wrapped-volume-race-f3b73f81-7908-48c9-9645-1a0c3c18fc06 pods took: 300.203864ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:49:14.455: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1655" for this suite.
Dec 13 18:49:20.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:49:20.504: INFO: namespace emptydir-wrapper-1655 deletion completed in 6.046404291s

• [SLOW TEST:155.784 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:49:20.504: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec 13 18:49:20.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 create -f - --namespace=kubectl-172'
Dec 13 18:49:20.817: INFO: stderr: ""
Dec 13 18:49:20.817: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 13 18:49:20.817: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-172'
Dec 13 18:49:20.924: INFO: stderr: ""
Dec 13 18:49:20.924: INFO: stdout: "update-demo-nautilus-2ssg6 update-demo-nautilus-9qb9t "
Dec 13 18:49:20.924: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-2ssg6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-172'
Dec 13 18:49:21.028: INFO: stderr: ""
Dec 13 18:49:21.028: INFO: stdout: ""
Dec 13 18:49:21.028: INFO: update-demo-nautilus-2ssg6 is created but not running
Dec 13 18:49:26.028: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-172'
Dec 13 18:49:26.135: INFO: stderr: ""
Dec 13 18:49:26.135: INFO: stdout: "update-demo-nautilus-2ssg6 update-demo-nautilus-9qb9t "
Dec 13 18:49:26.135: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-2ssg6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-172'
Dec 13 18:49:26.245: INFO: stderr: ""
Dec 13 18:49:26.245: INFO: stdout: ""
Dec 13 18:49:26.245: INFO: update-demo-nautilus-2ssg6 is created but not running
Dec 13 18:49:31.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-172'
Dec 13 18:49:31.352: INFO: stderr: ""
Dec 13 18:49:31.352: INFO: stdout: "update-demo-nautilus-2ssg6 update-demo-nautilus-9qb9t "
Dec 13 18:49:31.352: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-2ssg6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-172'
Dec 13 18:49:31.461: INFO: stderr: ""
Dec 13 18:49:31.461: INFO: stdout: "true"
Dec 13 18:49:31.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-2ssg6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-172'
Dec 13 18:49:31.563: INFO: stderr: ""
Dec 13 18:49:31.563: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 13 18:49:31.563: INFO: validating pod update-demo-nautilus-2ssg6
Dec 13 18:49:31.571: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 13 18:49:31.571: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 13 18:49:31.571: INFO: update-demo-nautilus-2ssg6 is verified up and running
Dec 13 18:49:31.571: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-9qb9t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-172'
Dec 13 18:49:31.674: INFO: stderr: ""
Dec 13 18:49:31.674: INFO: stdout: "true"
Dec 13 18:49:31.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-9qb9t -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-172'
Dec 13 18:49:31.779: INFO: stderr: ""
Dec 13 18:49:31.779: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 13 18:49:31.779: INFO: validating pod update-demo-nautilus-9qb9t
Dec 13 18:49:31.784: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 13 18:49:31.784: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 13 18:49:31.784: INFO: update-demo-nautilus-9qb9t is verified up and running
STEP: using delete to clean up resources
Dec 13 18:49:31.784: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 delete --grace-period=0 --force -f - --namespace=kubectl-172'
Dec 13 18:49:31.894: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 13 18:49:31.894: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 13 18:49:31.894: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-172'
Dec 13 18:49:32.010: INFO: stderr: "No resources found in kubectl-172 namespace.\n"
Dec 13 18:49:32.010: INFO: stdout: ""
Dec 13 18:49:32.010: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods -l name=update-demo --namespace=kubectl-172 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 13 18:49:32.114: INFO: stderr: ""
Dec 13 18:49:32.114: INFO: stdout: "update-demo-nautilus-2ssg6\nupdate-demo-nautilus-9qb9t\n"
Dec 13 18:49:32.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-172'
Dec 13 18:49:32.721: INFO: stderr: "No resources found in kubectl-172 namespace.\n"
Dec 13 18:49:32.721: INFO: stdout: ""
Dec 13 18:49:32.721: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods -l name=update-demo --namespace=kubectl-172 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 13 18:49:32.835: INFO: stderr: ""
Dec 13 18:49:32.835: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:49:32.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-172" for this suite.
Dec 13 18:49:38.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:49:38.888: INFO: namespace kubectl-172 deletion completed in 6.051511708s

• [SLOW TEST:18.384 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:49:38.888: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-372e3cc7-425b-4b03-b321-81abb2cf8f96
STEP: Creating a pod to test consume secrets
Dec 13 18:49:38.914: INFO: Waiting up to 5m0s for pod "pod-secrets-7b7b5990-97be-4845-94bb-a9667df6ad96" in namespace "secrets-8783" to be "success or failure"
Dec 13 18:49:38.916: INFO: Pod "pod-secrets-7b7b5990-97be-4845-94bb-a9667df6ad96": Phase="Pending", Reason="", readiness=false. Elapsed: 1.339625ms
Dec 13 18:49:40.918: INFO: Pod "pod-secrets-7b7b5990-97be-4845-94bb-a9667df6ad96": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00360018s
Dec 13 18:49:42.920: INFO: Pod "pod-secrets-7b7b5990-97be-4845-94bb-a9667df6ad96": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005572348s
Dec 13 18:49:44.922: INFO: Pod "pod-secrets-7b7b5990-97be-4845-94bb-a9667df6ad96": Phase="Pending", Reason="", readiness=false. Elapsed: 6.00791488s
Dec 13 18:49:46.924: INFO: Pod "pod-secrets-7b7b5990-97be-4845-94bb-a9667df6ad96": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.010097877s
STEP: Saw pod success
Dec 13 18:49:46.925: INFO: Pod "pod-secrets-7b7b5990-97be-4845-94bb-a9667df6ad96" satisfied condition "success or failure"
Dec 13 18:49:46.926: INFO: Trying to get logs from node 172.160.134.165 pod pod-secrets-7b7b5990-97be-4845-94bb-a9667df6ad96 container secret-volume-test: <nil>
STEP: delete the pod
Dec 13 18:49:46.946: INFO: Waiting for pod pod-secrets-7b7b5990-97be-4845-94bb-a9667df6ad96 to disappear
Dec 13 18:49:46.950: INFO: Pod pod-secrets-7b7b5990-97be-4845-94bb-a9667df6ad96 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:49:46.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8783" for this suite.
Dec 13 18:49:52.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:49:52.998: INFO: namespace secrets-8783 deletion completed in 6.046224701s

• [SLOW TEST:14.110 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:49:52.998: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:50:00.027: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5238" for this suite.
Dec 13 18:50:06.037: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:50:06.080: INFO: namespace resourcequota-5238 deletion completed in 6.051090345s

• [SLOW TEST:13.082 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:50:06.080: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-d71d339f-0c5c-4b75-b6c5-563bae1e373f
STEP: Creating a pod to test consume secrets
Dec 13 18:50:06.106: INFO: Waiting up to 5m0s for pod "pod-secrets-74734d24-9076-40bd-9297-445dec5c8fa0" in namespace "secrets-683" to be "success or failure"
Dec 13 18:50:06.108: INFO: Pod "pod-secrets-74734d24-9076-40bd-9297-445dec5c8fa0": Phase="Pending", Reason="", readiness=false. Elapsed: 1.950279ms
Dec 13 18:50:08.110: INFO: Pod "pod-secrets-74734d24-9076-40bd-9297-445dec5c8fa0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004286814s
Dec 13 18:50:10.112: INFO: Pod "pod-secrets-74734d24-9076-40bd-9297-445dec5c8fa0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006361324s
Dec 13 18:50:12.114: INFO: Pod "pod-secrets-74734d24-9076-40bd-9297-445dec5c8fa0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008428942s
Dec 13 18:50:14.117: INFO: Pod "pod-secrets-74734d24-9076-40bd-9297-445dec5c8fa0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.01072347s
STEP: Saw pod success
Dec 13 18:50:14.117: INFO: Pod "pod-secrets-74734d24-9076-40bd-9297-445dec5c8fa0" satisfied condition "success or failure"
Dec 13 18:50:14.118: INFO: Trying to get logs from node 172.160.134.166 pod pod-secrets-74734d24-9076-40bd-9297-445dec5c8fa0 container secret-volume-test: <nil>
STEP: delete the pod
Dec 13 18:50:14.144: INFO: Waiting for pod pod-secrets-74734d24-9076-40bd-9297-445dec5c8fa0 to disappear
Dec 13 18:50:14.148: INFO: Pod pod-secrets-74734d24-9076-40bd-9297-445dec5c8fa0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:50:14.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-683" for this suite.
Dec 13 18:50:20.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:50:20.200: INFO: namespace secrets-683 deletion completed in 6.049642457s

• [SLOW TEST:14.119 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:50:20.200: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 13 18:50:20.223: INFO: Waiting up to 5m0s for pod "pod-8fd59515-4638-4c20-a6f0-ef74c797f1cb" in namespace "emptydir-2170" to be "success or failure"
Dec 13 18:50:20.228: INFO: Pod "pod-8fd59515-4638-4c20-a6f0-ef74c797f1cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.884187ms
Dec 13 18:50:22.230: INFO: Pod "pod-8fd59515-4638-4c20-a6f0-ef74c797f1cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0072772s
Dec 13 18:50:24.232: INFO: Pod "pod-8fd59515-4638-4c20-a6f0-ef74c797f1cb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009460022s
Dec 13 18:50:26.235: INFO: Pod "pod-8fd59515-4638-4c20-a6f0-ef74c797f1cb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011716159s
Dec 13 18:50:28.237: INFO: Pod "pod-8fd59515-4638-4c20-a6f0-ef74c797f1cb": Phase="Pending", Reason="", readiness=false. Elapsed: 8.013967395s
Dec 13 18:50:30.239: INFO: Pod "pod-8fd59515-4638-4c20-a6f0-ef74c797f1cb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.016173189s
Dec 13 18:50:32.241: INFO: Pod "pod-8fd59515-4638-4c20-a6f0-ef74c797f1cb": Phase="Pending", Reason="", readiness=false. Elapsed: 12.018565258s
Dec 13 18:50:34.244: INFO: Pod "pod-8fd59515-4638-4c20-a6f0-ef74c797f1cb": Phase="Pending", Reason="", readiness=false. Elapsed: 14.021006554s
Dec 13 18:50:36.246: INFO: Pod "pod-8fd59515-4638-4c20-a6f0-ef74c797f1cb": Phase="Pending", Reason="", readiness=false. Elapsed: 16.023491263s
Dec 13 18:50:38.249: INFO: Pod "pod-8fd59515-4638-4c20-a6f0-ef74c797f1cb": Phase="Pending", Reason="", readiness=false. Elapsed: 18.025765106s
Dec 13 18:50:40.251: INFO: Pod "pod-8fd59515-4638-4c20-a6f0-ef74c797f1cb": Phase="Pending", Reason="", readiness=false. Elapsed: 20.028144328s
Dec 13 18:50:42.253: INFO: Pod "pod-8fd59515-4638-4c20-a6f0-ef74c797f1cb": Phase="Pending", Reason="", readiness=false. Elapsed: 22.030421746s
Dec 13 18:50:44.256: INFO: Pod "pod-8fd59515-4638-4c20-a6f0-ef74c797f1cb": Phase="Pending", Reason="", readiness=false. Elapsed: 24.032771214s
Dec 13 18:50:46.258: INFO: Pod "pod-8fd59515-4638-4c20-a6f0-ef74c797f1cb": Phase="Pending", Reason="", readiness=false. Elapsed: 26.03495593s
Dec 13 18:50:48.260: INFO: Pod "pod-8fd59515-4638-4c20-a6f0-ef74c797f1cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.037403359s
STEP: Saw pod success
Dec 13 18:50:48.260: INFO: Pod "pod-8fd59515-4638-4c20-a6f0-ef74c797f1cb" satisfied condition "success or failure"
Dec 13 18:50:48.262: INFO: Trying to get logs from node 172.160.134.166 pod pod-8fd59515-4638-4c20-a6f0-ef74c797f1cb container test-container: <nil>
STEP: delete the pod
Dec 13 18:50:48.281: INFO: Waiting for pod pod-8fd59515-4638-4c20-a6f0-ef74c797f1cb to disappear
Dec 13 18:50:48.283: INFO: Pod pod-8fd59515-4638-4c20-a6f0-ef74c797f1cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:50:48.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2170" for this suite.
Dec 13 18:50:54.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:50:54.333: INFO: namespace emptydir-2170 deletion completed in 6.047633422s

• [SLOW TEST:34.133 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:50:54.333: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:50:54.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3499" for this suite.
Dec 13 18:51:06.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:51:06.421: INFO: namespace pods-3499 deletion completed in 12.053798426s

• [SLOW TEST:12.089 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:51:06.422: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-87610b34-d0b0-4116-aca3-6f438be21b1c
Dec 13 18:51:06.456: INFO: Pod name my-hostname-basic-87610b34-d0b0-4116-aca3-6f438be21b1c: Found 0 pods out of 1
Dec 13 18:51:11.458: INFO: Pod name my-hostname-basic-87610b34-d0b0-4116-aca3-6f438be21b1c: Found 1 pods out of 1
Dec 13 18:51:11.459: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-87610b34-d0b0-4116-aca3-6f438be21b1c" are running
Dec 13 18:51:13.462: INFO: Pod "my-hostname-basic-87610b34-d0b0-4116-aca3-6f438be21b1c-j56cj" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-13 18:51:06 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-13 18:51:06 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-87610b34-d0b0-4116-aca3-6f438be21b1c]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-13 18:51:06 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-87610b34-d0b0-4116-aca3-6f438be21b1c]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-13 18:51:06 +0000 UTC Reason: Message:}])
Dec 13 18:51:13.462: INFO: Trying to dial the pod
Dec 13 18:51:18.471: INFO: Controller my-hostname-basic-87610b34-d0b0-4116-aca3-6f438be21b1c: Got expected result from replica 1 [my-hostname-basic-87610b34-d0b0-4116-aca3-6f438be21b1c-j56cj]: "my-hostname-basic-87610b34-d0b0-4116-aca3-6f438be21b1c-j56cj", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:51:18.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-122" for this suite.
Dec 13 18:51:24.480: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:51:24.521: INFO: namespace replication-controller-122 deletion completed in 6.048460018s

• [SLOW TEST:18.100 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:51:24.523: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-4813
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec 13 18:51:24.590: INFO: Found 0 stateful pods, waiting for 3
Dec 13 18:51:34.593: INFO: Found 2 stateful pods, waiting for 3
Dec 13 18:51:44.593: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 13 18:51:44.593: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 13 18:51:44.593: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec 13 18:51:44.613: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec 13 18:51:54.639: INFO: Updating stateful set ss2
Dec 13 18:51:54.658: INFO: Waiting for Pod statefulset-4813/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Dec 13 18:52:04.698: INFO: Found 2 stateful pods, waiting for 3
Dec 13 18:52:14.702: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 13 18:52:14.702: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 13 18:52:14.702: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Dec 13 18:52:24.706: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 13 18:52:24.706: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 13 18:52:24.706: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec 13 18:52:24.723: INFO: Updating stateful set ss2
Dec 13 18:52:24.732: INFO: Waiting for Pod statefulset-4813/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 13 18:52:34.752: INFO: Updating stateful set ss2
Dec 13 18:52:34.761: INFO: Waiting for StatefulSet statefulset-4813/ss2 to complete update
Dec 13 18:52:34.761: INFO: Waiting for Pod statefulset-4813/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 13 18:52:44.769: INFO: Waiting for StatefulSet statefulset-4813/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 13 18:52:54.766: INFO: Deleting all statefulset in ns statefulset-4813
Dec 13 18:52:54.767: INFO: Scaling statefulset ss2 to 0
Dec 13 18:53:04.776: INFO: Waiting for statefulset status.replicas updated to 0
Dec 13 18:53:04.777: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:53:04.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4813" for this suite.
Dec 13 18:53:10.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:53:10.839: INFO: namespace statefulset-4813 deletion completed in 6.05087637s

• [SLOW TEST:106.317 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:53:10.840: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 13 18:53:10.867: INFO: Waiting up to 5m0s for pod "pod-c76f40d5-27be-4a0a-95c6-e037466bc90f" in namespace "emptydir-5194" to be "success or failure"
Dec 13 18:53:10.874: INFO: Pod "pod-c76f40d5-27be-4a0a-95c6-e037466bc90f": Phase="Pending", Reason="", readiness=false. Elapsed: 7.320326ms
Dec 13 18:53:12.876: INFO: Pod "pod-c76f40d5-27be-4a0a-95c6-e037466bc90f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009436828s
Dec 13 18:53:14.878: INFO: Pod "pod-c76f40d5-27be-4a0a-95c6-e037466bc90f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011879912s
Dec 13 18:53:16.880: INFO: Pod "pod-c76f40d5-27be-4a0a-95c6-e037466bc90f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013908559s
Dec 13 18:53:18.883: INFO: Pod "pod-c76f40d5-27be-4a0a-95c6-e037466bc90f": Phase="Pending", Reason="", readiness=false. Elapsed: 8.016183506s
Dec 13 18:53:20.885: INFO: Pod "pod-c76f40d5-27be-4a0a-95c6-e037466bc90f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.018430673s
Dec 13 18:53:22.893: INFO: Pod "pod-c76f40d5-27be-4a0a-95c6-e037466bc90f": Phase="Pending", Reason="", readiness=false. Elapsed: 12.026537867s
Dec 13 18:53:24.895: INFO: Pod "pod-c76f40d5-27be-4a0a-95c6-e037466bc90f": Phase="Pending", Reason="", readiness=false. Elapsed: 14.028760304s
Dec 13 18:53:26.898: INFO: Pod "pod-c76f40d5-27be-4a0a-95c6-e037466bc90f": Phase="Pending", Reason="", readiness=false. Elapsed: 16.030978381s
Dec 13 18:53:28.900: INFO: Pod "pod-c76f40d5-27be-4a0a-95c6-e037466bc90f": Phase="Pending", Reason="", readiness=false. Elapsed: 18.033181937s
Dec 13 18:53:30.902: INFO: Pod "pod-c76f40d5-27be-4a0a-95c6-e037466bc90f": Phase="Pending", Reason="", readiness=false. Elapsed: 20.035215042s
Dec 13 18:53:32.904: INFO: Pod "pod-c76f40d5-27be-4a0a-95c6-e037466bc90f": Phase="Pending", Reason="", readiness=false. Elapsed: 22.037293066s
Dec 13 18:53:34.906: INFO: Pod "pod-c76f40d5-27be-4a0a-95c6-e037466bc90f": Phase="Pending", Reason="", readiness=false. Elapsed: 24.039544874s
Dec 13 18:53:36.908: INFO: Pod "pod-c76f40d5-27be-4a0a-95c6-e037466bc90f": Phase="Pending", Reason="", readiness=false. Elapsed: 26.041791832s
Dec 13 18:53:38.911: INFO: Pod "pod-c76f40d5-27be-4a0a-95c6-e037466bc90f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.044077505s
STEP: Saw pod success
Dec 13 18:53:38.911: INFO: Pod "pod-c76f40d5-27be-4a0a-95c6-e037466bc90f" satisfied condition "success or failure"
Dec 13 18:53:38.912: INFO: Trying to get logs from node 172.160.134.166 pod pod-c76f40d5-27be-4a0a-95c6-e037466bc90f container test-container: <nil>
STEP: delete the pod
Dec 13 18:53:38.941: INFO: Waiting for pod pod-c76f40d5-27be-4a0a-95c6-e037466bc90f to disappear
Dec 13 18:53:38.944: INFO: Pod pod-c76f40d5-27be-4a0a-95c6-e037466bc90f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:53:38.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5194" for this suite.
Dec 13 18:53:44.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:53:44.992: INFO: namespace emptydir-5194 deletion completed in 6.045869878s

• [SLOW TEST:34.152 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:53:44.992: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 18:53:45.011: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Dec 13 18:53:47.028: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:53:48.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8660" for this suite.
Dec 13 18:53:54.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:53:54.091: INFO: namespace replication-controller-8660 deletion completed in 6.056716694s

• [SLOW TEST:9.099 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:53:54.092: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 18:53:54.131: INFO: (0) /api/v1/nodes/172.160.134.165/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 14.871311ms)
Dec 13 18:53:54.133: INFO: (1) /api/v1/nodes/172.160.134.165/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 2.647268ms)
Dec 13 18:53:54.135: INFO: (2) /api/v1/nodes/172.160.134.165/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 2.000664ms)
Dec 13 18:53:54.137: INFO: (3) /api/v1/nodes/172.160.134.165/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 2.125839ms)
Dec 13 18:53:54.140: INFO: (4) /api/v1/nodes/172.160.134.165/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 2.095188ms)
Dec 13 18:53:54.141: INFO: (5) /api/v1/nodes/172.160.134.165/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 1.918382ms)
Dec 13 18:53:54.144: INFO: (6) /api/v1/nodes/172.160.134.165/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 2.135852ms)
Dec 13 18:53:54.146: INFO: (7) /api/v1/nodes/172.160.134.165/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 2.073174ms)
Dec 13 18:53:54.150: INFO: (8) /api/v1/nodes/172.160.134.165/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 4.419591ms)
Dec 13 18:53:54.152: INFO: (9) /api/v1/nodes/172.160.134.165/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 2.052684ms)
Dec 13 18:53:54.154: INFO: (10) /api/v1/nodes/172.160.134.165/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 2.157416ms)
Dec 13 18:53:54.157: INFO: (11) /api/v1/nodes/172.160.134.165/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 2.051598ms)
Dec 13 18:53:54.159: INFO: (12) /api/v1/nodes/172.160.134.165/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 1.978919ms)
Dec 13 18:53:54.161: INFO: (13) /api/v1/nodes/172.160.134.165/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 2.036934ms)
Dec 13 18:53:54.163: INFO: (14) /api/v1/nodes/172.160.134.165/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 1.975229ms)
Dec 13 18:53:54.165: INFO: (15) /api/v1/nodes/172.160.134.165/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 1.933692ms)
Dec 13 18:53:54.167: INFO: (16) /api/v1/nodes/172.160.134.165/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 2.155278ms)
Dec 13 18:53:54.169: INFO: (17) /api/v1/nodes/172.160.134.165/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 1.946579ms)
Dec 13 18:53:54.171: INFO: (18) /api/v1/nodes/172.160.134.165/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 2.132778ms)
Dec 13 18:53:54.178: INFO: (19) /api/v1/nodes/172.160.134.165/proxy/logs/: <pre>
<a href="CGSL/">CGSL/</a>
<a href="ansible.log">ansible.log</a>
<a href="audit/">audit/</a>... (200; 7.12412ms)
[AfterEach] version v1
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:53:54.178: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7455" for this suite.
Dec 13 18:54:00.187: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:54:00.227: INFO: namespace proxy-7455 deletion completed in 6.047390473s

• [SLOW TEST:6.136 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:54:00.228: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 18:54:00.248: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:54:08.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5792" for this suite.
Dec 13 18:54:46.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:54:46.519: INFO: namespace pods-5792 deletion completed in 38.050645795s

• [SLOW TEST:46.291 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:54:46.519: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-618
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-618
STEP: creating replication controller externalsvc in namespace services-618
I1213 18:54:46.582512      25 runners.go:184] Created replication controller with name: externalsvc, namespace: services-618, replica count: 2
I1213 18:54:49.632896      25 runners.go:184] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1213 18:54:52.633239      25 runners.go:184] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1213 18:54:55.633555      25 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Dec 13 18:54:55.643: INFO: Creating new exec pod
Dec 13 18:55:03.653: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=services-618 execpodlhs57 -- /bin/sh -x -c nslookup clusterip-service'
Dec 13 18:55:04.113: INFO: stderr: "+ nslookup clusterip-service\n"
Dec 13 18:55:04.113: INFO: stdout: "Server:\t\t10.254.0.10\nAddress:\t10.254.0.10#53\n\nclusterip-service.services-618.svc.cluster.local\tcanonical name = externalsvc.services-618.svc.cluster.local.\nName:\texternalsvc.services-618.svc.cluster.local\nAddress: 10.254.2.172\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-618, will wait for the garbage collector to delete the pods
Dec 13 18:55:04.170: INFO: Deleting ReplicationController externalsvc took: 4.070088ms
Dec 13 18:55:04.470: INFO: Terminating ReplicationController externalsvc pods took: 300.200316ms
Dec 13 18:55:08.879: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:55:08.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-618" for this suite.
Dec 13 18:55:14.903: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:55:14.942: INFO: namespace services-618 deletion completed in 6.050515505s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:28.423 seconds]
[sig-network] Services
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:55:14.942: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 18:55:14.966: INFO: Waiting up to 5m0s for pod "busybox-user-65534-a2d94bc3-5b08-4a7a-98a9-d5f3dc5ee1c4" in namespace "security-context-test-9421" to be "success or failure"
Dec 13 18:55:14.969: INFO: Pod "busybox-user-65534-a2d94bc3-5b08-4a7a-98a9-d5f3dc5ee1c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.462863ms
Dec 13 18:55:16.971: INFO: Pod "busybox-user-65534-a2d94bc3-5b08-4a7a-98a9-d5f3dc5ee1c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004691202s
Dec 13 18:55:18.973: INFO: Pod "busybox-user-65534-a2d94bc3-5b08-4a7a-98a9-d5f3dc5ee1c4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.00659068s
Dec 13 18:55:20.975: INFO: Pod "busybox-user-65534-a2d94bc3-5b08-4a7a-98a9-d5f3dc5ee1c4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008933897s
Dec 13 18:55:22.985: INFO: Pod "busybox-user-65534-a2d94bc3-5b08-4a7a-98a9-d5f3dc5ee1c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.018096269s
Dec 13 18:55:22.985: INFO: Pod "busybox-user-65534-a2d94bc3-5b08-4a7a-98a9-d5f3dc5ee1c4" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:55:22.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9421" for this suite.
Dec 13 18:55:28.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:55:29.032: INFO: namespace security-context-test-9421 deletion completed in 6.045301851s

• [SLOW TEST:14.090 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:55:29.033: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:55:33.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1401" for this suite.
Dec 13 18:55:39.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:55:39.630: INFO: namespace watch-1401 deletion completed in 6.141718042s

• [SLOW TEST:10.597 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:55:39.630: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-8637
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-8637
I1213 18:55:39.670786      25 runners.go:184] Created replication controller with name: externalname-service, namespace: services-8637, replica count: 2
I1213 18:55:42.721256      25 runners.go:184] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1213 18:55:45.721414      25 runners.go:184] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 13 18:55:48.721: INFO: Creating new exec pod
I1213 18:55:48.721567      25 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 13 18:55:57.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=services-8637 execpodpdtkm -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec 13 18:55:58.437: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 13 18:55:58.437: INFO: stdout: ""
Dec 13 18:55:58.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=services-8637 execpodpdtkm -- /bin/sh -x -c nc -zv -t -w 2 10.254.137.126 80'
Dec 13 18:55:58.874: INFO: stderr: "+ nc -zv -t -w 2 10.254.137.126 80\nConnection to 10.254.137.126 80 port [tcp/http] succeeded!\n"
Dec 13 18:55:58.874: INFO: stdout: ""
Dec 13 18:55:58.874: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:55:58.885: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8637" for this suite.
Dec 13 18:56:04.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:56:04.939: INFO: namespace services-8637 deletion completed in 6.045358105s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:25.308 seconds]
[sig-network] Services
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:56:04.939: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:56:04.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2582" for this suite.
Dec 13 18:56:10.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:56:11.017: INFO: namespace services-2582 deletion completed in 6.047939894s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.078 seconds]
[sig-network] Services
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:56:11.017: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 13 18:56:11.042: INFO: Waiting up to 5m0s for pod "downwardapi-volume-79c6c5dc-b6ef-44e5-a469-6f6c78c6cd96" in namespace "projected-1703" to be "success or failure"
Dec 13 18:56:11.044: INFO: Pod "downwardapi-volume-79c6c5dc-b6ef-44e5-a469-6f6c78c6cd96": Phase="Pending", Reason="", readiness=false. Elapsed: 1.562124ms
Dec 13 18:56:13.046: INFO: Pod "downwardapi-volume-79c6c5dc-b6ef-44e5-a469-6f6c78c6cd96": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003925969s
Dec 13 18:56:15.048: INFO: Pod "downwardapi-volume-79c6c5dc-b6ef-44e5-a469-6f6c78c6cd96": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006352698s
Dec 13 18:56:17.051: INFO: Pod "downwardapi-volume-79c6c5dc-b6ef-44e5-a469-6f6c78c6cd96": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008638652s
Dec 13 18:56:19.053: INFO: Pod "downwardapi-volume-79c6c5dc-b6ef-44e5-a469-6f6c78c6cd96": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.010565148s
STEP: Saw pod success
Dec 13 18:56:19.053: INFO: Pod "downwardapi-volume-79c6c5dc-b6ef-44e5-a469-6f6c78c6cd96" satisfied condition "success or failure"
Dec 13 18:56:19.054: INFO: Trying to get logs from node 172.160.134.166 pod downwardapi-volume-79c6c5dc-b6ef-44e5-a469-6f6c78c6cd96 container client-container: <nil>
STEP: delete the pod
Dec 13 18:56:19.079: INFO: Waiting for pod downwardapi-volume-79c6c5dc-b6ef-44e5-a469-6f6c78c6cd96 to disappear
Dec 13 18:56:19.082: INFO: Pod downwardapi-volume-79c6c5dc-b6ef-44e5-a469-6f6c78c6cd96 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:56:19.082: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1703" for this suite.
Dec 13 18:56:25.089: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:56:25.134: INFO: namespace projected-1703 deletion completed in 6.050607188s

• [SLOW TEST:14.117 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:56:25.136: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Dec 13 18:56:25.161: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 18:56:29.775: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:56:47.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5539" for this suite.
Dec 13 18:56:53.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:56:53.714: INFO: namespace crd-publish-openapi-5539 deletion completed in 6.054453271s

• [SLOW TEST:28.578 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:56:53.714: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-abec723b-846c-40a2-b2f3-010d8cd55126
STEP: Creating a pod to test consume configMaps
Dec 13 18:56:53.747: INFO: Waiting up to 5m0s for pod "pod-configmaps-b479c6f0-8979-4970-8a4f-268c3caf9fba" in namespace "configmap-6000" to be "success or failure"
Dec 13 18:56:53.748: INFO: Pod "pod-configmaps-b479c6f0-8979-4970-8a4f-268c3caf9fba": Phase="Pending", Reason="", readiness=false. Elapsed: 1.637574ms
Dec 13 18:56:55.750: INFO: Pod "pod-configmaps-b479c6f0-8979-4970-8a4f-268c3caf9fba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003760285s
Dec 13 18:56:57.753: INFO: Pod "pod-configmaps-b479c6f0-8979-4970-8a4f-268c3caf9fba": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006070625s
Dec 13 18:56:59.758: INFO: Pod "pod-configmaps-b479c6f0-8979-4970-8a4f-268c3caf9fba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011080661s
STEP: Saw pod success
Dec 13 18:56:59.758: INFO: Pod "pod-configmaps-b479c6f0-8979-4970-8a4f-268c3caf9fba" satisfied condition "success or failure"
Dec 13 18:56:59.759: INFO: Trying to get logs from node 172.160.134.165 pod pod-configmaps-b479c6f0-8979-4970-8a4f-268c3caf9fba container configmap-volume-test: <nil>
STEP: delete the pod
Dec 13 18:56:59.780: INFO: Waiting for pod pod-configmaps-b479c6f0-8979-4970-8a4f-268c3caf9fba to disappear
Dec 13 18:56:59.785: INFO: Pod pod-configmaps-b479c6f0-8979-4970-8a4f-268c3caf9fba no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:56:59.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6000" for this suite.
Dec 13 18:57:05.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:57:05.835: INFO: namespace configmap-6000 deletion completed in 6.048274731s

• [SLOW TEST:12.121 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:57:05.837: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-rrnw
STEP: Creating a pod to test atomic-volume-subpath
Dec 13 18:57:05.875: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-rrnw" in namespace "subpath-7944" to be "success or failure"
Dec 13 18:57:05.881: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Pending", Reason="", readiness=false. Elapsed: 6.026718ms
Dec 13 18:57:07.883: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008577904s
Dec 13 18:57:09.886: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011125463s
Dec 13 18:57:11.888: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013485118s
Dec 13 18:57:13.891: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Pending", Reason="", readiness=false. Elapsed: 8.015890779s
Dec 13 18:57:15.893: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Pending", Reason="", readiness=false. Elapsed: 10.01831446s
Dec 13 18:57:17.896: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Pending", Reason="", readiness=false. Elapsed: 12.020686819s
Dec 13 18:57:19.898: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Pending", Reason="", readiness=false. Elapsed: 14.023057217s
Dec 13 18:57:21.900: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Pending", Reason="", readiness=false. Elapsed: 16.025449136s
Dec 13 18:57:23.903: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Pending", Reason="", readiness=false. Elapsed: 18.027842352s
Dec 13 18:57:25.905: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Pending", Reason="", readiness=false. Elapsed: 20.030159313s
Dec 13 18:57:27.907: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Pending", Reason="", readiness=false. Elapsed: 22.032439288s
Dec 13 18:57:29.910: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Pending", Reason="", readiness=false. Elapsed: 24.034735158s
Dec 13 18:57:31.912: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Pending", Reason="", readiness=false. Elapsed: 26.037035575s
Dec 13 18:57:33.914: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Running", Reason="", readiness=true. Elapsed: 28.03919827s
Dec 13 18:57:35.916: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Running", Reason="", readiness=true. Elapsed: 30.041311754s
Dec 13 18:57:37.918: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Running", Reason="", readiness=true. Elapsed: 32.043589674s
Dec 13 18:57:39.921: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Running", Reason="", readiness=true. Elapsed: 34.045798181s
Dec 13 18:57:41.923: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Running", Reason="", readiness=true. Elapsed: 36.048206991s
Dec 13 18:57:43.925: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Running", Reason="", readiness=true. Elapsed: 38.050512645s
Dec 13 18:57:45.928: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Running", Reason="", readiness=true. Elapsed: 40.052790445s
Dec 13 18:57:47.930: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Running", Reason="", readiness=true. Elapsed: 42.055192248s
Dec 13 18:57:49.932: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Running", Reason="", readiness=true. Elapsed: 44.057605757s
Dec 13 18:57:51.935: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Running", Reason="", readiness=true. Elapsed: 46.059744985s
Dec 13 18:57:53.937: INFO: Pod "pod-subpath-test-projected-rrnw": Phase="Succeeded", Reason="", readiness=false. Elapsed: 48.062198956s
STEP: Saw pod success
Dec 13 18:57:53.937: INFO: Pod "pod-subpath-test-projected-rrnw" satisfied condition "success or failure"
Dec 13 18:57:53.939: INFO: Trying to get logs from node 172.160.134.166 pod pod-subpath-test-projected-rrnw container test-container-subpath-projected-rrnw: <nil>
STEP: delete the pod
Dec 13 18:57:53.962: INFO: Waiting for pod pod-subpath-test-projected-rrnw to disappear
Dec 13 18:57:53.966: INFO: Pod pod-subpath-test-projected-rrnw no longer exists
STEP: Deleting pod pod-subpath-test-projected-rrnw
Dec 13 18:57:53.966: INFO: Deleting pod "pod-subpath-test-projected-rrnw" in namespace "subpath-7944"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:57:53.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7944" for this suite.
Dec 13 18:57:59.976: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:58:00.017: INFO: namespace subpath-7944 deletion completed in 6.048118252s

• [SLOW TEST:54.180 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:58:00.017: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 13 18:58:00.058: INFO: Waiting up to 5m0s for pod "downwardapi-volume-44e5fad9-28dd-46ff-9aa1-f681d0793bcf" in namespace "projected-9516" to be "success or failure"
Dec 13 18:58:00.060: INFO: Pod "downwardapi-volume-44e5fad9-28dd-46ff-9aa1-f681d0793bcf": Phase="Pending", Reason="", readiness=false. Elapsed: 1.756977ms
Dec 13 18:58:02.062: INFO: Pod "downwardapi-volume-44e5fad9-28dd-46ff-9aa1-f681d0793bcf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004065726s
Dec 13 18:58:04.064: INFO: Pod "downwardapi-volume-44e5fad9-28dd-46ff-9aa1-f681d0793bcf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006525419s
Dec 13 18:58:06.067: INFO: Pod "downwardapi-volume-44e5fad9-28dd-46ff-9aa1-f681d0793bcf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009142937s
Dec 13 18:58:08.069: INFO: Pod "downwardapi-volume-44e5fad9-28dd-46ff-9aa1-f681d0793bcf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.011410314s
STEP: Saw pod success
Dec 13 18:58:08.069: INFO: Pod "downwardapi-volume-44e5fad9-28dd-46ff-9aa1-f681d0793bcf" satisfied condition "success or failure"
Dec 13 18:58:08.071: INFO: Trying to get logs from node 172.160.134.166 pod downwardapi-volume-44e5fad9-28dd-46ff-9aa1-f681d0793bcf container client-container: <nil>
STEP: delete the pod
Dec 13 18:58:08.083: INFO: Waiting for pod downwardapi-volume-44e5fad9-28dd-46ff-9aa1-f681d0793bcf to disappear
Dec 13 18:58:08.087: INFO: Pod downwardapi-volume-44e5fad9-28dd-46ff-9aa1-f681d0793bcf no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:58:08.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9516" for this suite.
Dec 13 18:58:14.097: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:58:14.147: INFO: namespace projected-9516 deletion completed in 6.058088335s

• [SLOW TEST:14.129 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:58:14.147: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7540.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7540.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7540.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7540.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 13 18:58:42.208: INFO: File wheezy_udp@dns-test-service-3.dns-7540.svc.cluster.local from pod  dns-7540/dns-test-34be38dc-71f8-431e-936f-95b1f9001743 contains '' instead of 'foo.example.com.'
Dec 13 18:58:42.226: INFO: Lookups using dns-7540/dns-test-34be38dc-71f8-431e-936f-95b1f9001743 failed for: [wheezy_udp@dns-test-service-3.dns-7540.svc.cluster.local]

Dec 13 18:58:47.233: INFO: DNS probes using dns-test-34be38dc-71f8-431e-936f-95b1f9001743 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7540.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7540.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7540.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7540.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 13 18:59:17.291: INFO: DNS probes using dns-test-58a08a07-fb06-4d46-a015-7c4f1fcb8269 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7540.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7540.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7540.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7540.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 13 18:59:47.331: INFO: DNS probes using dns-test-1a49cb51-ce85-4ec4-8e4e-89cca298e2e8 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 18:59:47.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7540" for this suite.
Dec 13 18:59:53.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 18:59:53.396: INFO: namespace dns-7540 deletion completed in 6.05035355s

• [SLOW TEST:99.249 seconds]
[sig-network] DNS
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 18:59:53.397: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-7c77ee56-83b9-4c27-a316-32f94c30c856 in namespace container-probe-646
Dec 13 18:59:59.425: INFO: Started pod busybox-7c77ee56-83b9-4c27-a316-32f94c30c856 in namespace container-probe-646
STEP: checking the pod's current state and verifying that restartCount is present
Dec 13 18:59:59.426: INFO: Initial restart count of pod busybox-7c77ee56-83b9-4c27-a316-32f94c30c856 is 0
Dec 13 19:00:47.481: INFO: Restart count of pod container-probe-646/busybox-7c77ee56-83b9-4c27-a316-32f94c30c856 is now 1 (48.054418958s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:00:47.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-646" for this suite.
Dec 13 19:00:53.500: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:00:53.540: INFO: namespace container-probe-646 deletion completed in 6.049936854s

• [SLOW TEST:60.144 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:00:53.541: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Dec 13 19:00:54.075: INFO: created pod pod-service-account-defaultsa
Dec 13 19:00:54.075: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec 13 19:00:54.077: INFO: created pod pod-service-account-mountsa
Dec 13 19:00:54.077: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec 13 19:00:54.082: INFO: created pod pod-service-account-nomountsa
Dec 13 19:00:54.082: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec 13 19:00:54.095: INFO: created pod pod-service-account-defaultsa-mountspec
Dec 13 19:00:54.095: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec 13 19:00:54.100: INFO: created pod pod-service-account-mountsa-mountspec
Dec 13 19:00:54.100: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec 13 19:00:54.110: INFO: created pod pod-service-account-nomountsa-mountspec
Dec 13 19:00:54.110: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec 13 19:00:54.121: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec 13 19:00:54.122: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec 13 19:00:54.135: INFO: created pod pod-service-account-mountsa-nomountspec
Dec 13 19:00:54.135: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec 13 19:00:54.145: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec 13 19:00:54.145: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:00:54.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8037" for this suite.
Dec 13 19:01:06.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:01:06.213: INFO: namespace svcaccounts-8037 deletion completed in 12.061551921s

• [SLOW TEST:12.673 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:01:06.214: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 19:01:06.240: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec 13 19:01:06.243: INFO: Number of nodes with available pods: 0
Dec 13 19:01:06.244: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec 13 19:01:06.254: INFO: Number of nodes with available pods: 0
Dec 13 19:01:06.254: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:07.256: INFO: Number of nodes with available pods: 0
Dec 13 19:01:07.256: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:08.256: INFO: Number of nodes with available pods: 0
Dec 13 19:01:08.257: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:09.256: INFO: Number of nodes with available pods: 0
Dec 13 19:01:09.256: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:10.256: INFO: Number of nodes with available pods: 0
Dec 13 19:01:10.256: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:11.256: INFO: Number of nodes with available pods: 1
Dec 13 19:01:11.256: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec 13 19:01:11.264: INFO: Number of nodes with available pods: 1
Dec 13 19:01:11.264: INFO: Number of running nodes: 0, number of available pods: 1
Dec 13 19:01:12.266: INFO: Number of nodes with available pods: 0
Dec 13 19:01:12.266: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec 13 19:01:12.276: INFO: Number of nodes with available pods: 0
Dec 13 19:01:12.276: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:13.278: INFO: Number of nodes with available pods: 0
Dec 13 19:01:13.278: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:14.278: INFO: Number of nodes with available pods: 0
Dec 13 19:01:14.278: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:15.278: INFO: Number of nodes with available pods: 0
Dec 13 19:01:15.278: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:16.278: INFO: Number of nodes with available pods: 0
Dec 13 19:01:16.278: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:17.278: INFO: Number of nodes with available pods: 0
Dec 13 19:01:17.278: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:18.278: INFO: Number of nodes with available pods: 0
Dec 13 19:01:18.278: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:19.278: INFO: Number of nodes with available pods: 0
Dec 13 19:01:19.278: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:20.278: INFO: Number of nodes with available pods: 0
Dec 13 19:01:20.278: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:21.278: INFO: Number of nodes with available pods: 0
Dec 13 19:01:21.278: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:22.278: INFO: Number of nodes with available pods: 0
Dec 13 19:01:22.278: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:23.278: INFO: Number of nodes with available pods: 0
Dec 13 19:01:23.278: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:24.278: INFO: Number of nodes with available pods: 0
Dec 13 19:01:24.278: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:25.278: INFO: Number of nodes with available pods: 0
Dec 13 19:01:25.278: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:26.278: INFO: Number of nodes with available pods: 0
Dec 13 19:01:26.278: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:27.278: INFO: Number of nodes with available pods: 0
Dec 13 19:01:27.278: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:28.278: INFO: Number of nodes with available pods: 0
Dec 13 19:01:28.278: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:01:29.278: INFO: Number of nodes with available pods: 1
Dec 13 19:01:29.278: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2539, will wait for the garbage collector to delete the pods
Dec 13 19:01:29.336: INFO: Deleting DaemonSet.extensions daemon-set took: 3.632911ms
Dec 13 19:01:29.636: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.175529ms
Dec 13 19:01:33.138: INFO: Number of nodes with available pods: 0
Dec 13 19:01:33.138: INFO: Number of running nodes: 0, number of available pods: 0
Dec 13 19:01:33.140: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2539/daemonsets","resourceVersion":"127085"},"items":null}

Dec 13 19:01:33.141: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2539/pods","resourceVersion":"127085"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:01:33.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2539" for this suite.
Dec 13 19:01:39.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:01:39.196: INFO: namespace daemonsets-2539 deletion completed in 6.044976423s

• [SLOW TEST:32.983 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:01:39.197: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-767be11d-6cf1-4a1c-a03b-6a9aef8222b2
STEP: Creating a pod to test consume configMaps
Dec 13 19:01:39.246: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-007d0851-8088-4760-a692-440fff472dcc" in namespace "projected-4852" to be "success or failure"
Dec 13 19:01:39.249: INFO: Pod "pod-projected-configmaps-007d0851-8088-4760-a692-440fff472dcc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.223643ms
Dec 13 19:01:41.251: INFO: Pod "pod-projected-configmaps-007d0851-8088-4760-a692-440fff472dcc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00455587s
Dec 13 19:01:43.254: INFO: Pod "pod-projected-configmaps-007d0851-8088-4760-a692-440fff472dcc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007139515s
Dec 13 19:01:45.256: INFO: Pod "pod-projected-configmaps-007d0851-8088-4760-a692-440fff472dcc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009501317s
STEP: Saw pod success
Dec 13 19:01:45.256: INFO: Pod "pod-projected-configmaps-007d0851-8088-4760-a692-440fff472dcc" satisfied condition "success or failure"
Dec 13 19:01:45.258: INFO: Trying to get logs from node 172.160.134.165 pod pod-projected-configmaps-007d0851-8088-4760-a692-440fff472dcc container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 13 19:01:45.278: INFO: Waiting for pod pod-projected-configmaps-007d0851-8088-4760-a692-440fff472dcc to disappear
Dec 13 19:01:45.281: INFO: Pod pod-projected-configmaps-007d0851-8088-4760-a692-440fff472dcc no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:01:45.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4852" for this suite.
Dec 13 19:01:51.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:01:51.331: INFO: namespace projected-4852 deletion completed in 6.048028938s

• [SLOW TEST:12.134 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:01:51.332: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Dec 13 19:01:59.869: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3565 pod-service-account-503f9a8c-1eae-4e78-a97c-86fbed615a08 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Dec 13 19:02:00.173: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3565 pod-service-account-503f9a8c-1eae-4e78-a97c-86fbed615a08 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Dec 13 19:02:00.452: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-3565 pod-service-account-503f9a8c-1eae-4e78-a97c-86fbed615a08 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:02:00.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3565" for this suite.
Dec 13 19:02:06.946: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:02:06.993: INFO: namespace svcaccounts-3565 deletion completed in 6.053074915s

• [SLOW TEST:15.662 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:02:06.993: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 19:02:07.017: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Dec 13 19:02:11.585: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 --namespace=crd-publish-openapi-7997 create -f -'
Dec 13 19:02:12.263: INFO: stderr: ""
Dec 13 19:02:12.263: INFO: stdout: "e2e-test-crd-publish-openapi-5340-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 13 19:02:12.263: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 --namespace=crd-publish-openapi-7997 delete e2e-test-crd-publish-openapi-5340-crds test-foo'
Dec 13 19:02:12.375: INFO: stderr: ""
Dec 13 19:02:12.375: INFO: stdout: "e2e-test-crd-publish-openapi-5340-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Dec 13 19:02:12.375: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 --namespace=crd-publish-openapi-7997 apply -f -'
Dec 13 19:02:12.656: INFO: stderr: ""
Dec 13 19:02:12.656: INFO: stdout: "e2e-test-crd-publish-openapi-5340-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 13 19:02:12.656: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 --namespace=crd-publish-openapi-7997 delete e2e-test-crd-publish-openapi-5340-crds test-foo'
Dec 13 19:02:12.775: INFO: stderr: ""
Dec 13 19:02:12.775: INFO: stdout: "e2e-test-crd-publish-openapi-5340-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Dec 13 19:02:12.775: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 --namespace=crd-publish-openapi-7997 create -f -'
Dec 13 19:02:12.986: INFO: rc: 1
Dec 13 19:02:12.986: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 --namespace=crd-publish-openapi-7997 apply -f -'
Dec 13 19:02:13.220: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Dec 13 19:02:13.220: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 --namespace=crd-publish-openapi-7997 create -f -'
Dec 13 19:02:13.445: INFO: rc: 1
Dec 13 19:02:13.445: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 --namespace=crd-publish-openapi-7997 apply -f -'
Dec 13 19:02:13.650: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Dec 13 19:02:13.650: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 explain e2e-test-crd-publish-openapi-5340-crds'
Dec 13 19:02:13.869: INFO: stderr: ""
Dec 13 19:02:13.869: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5340-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Dec 13 19:02:13.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 explain e2e-test-crd-publish-openapi-5340-crds.metadata'
Dec 13 19:02:14.097: INFO: stderr: ""
Dec 13 19:02:14.097: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5340-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Dec 13 19:02:14.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 explain e2e-test-crd-publish-openapi-5340-crds.spec'
Dec 13 19:02:14.328: INFO: stderr: ""
Dec 13 19:02:14.328: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5340-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Dec 13 19:02:14.328: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 explain e2e-test-crd-publish-openapi-5340-crds.spec.bars'
Dec 13 19:02:14.550: INFO: stderr: ""
Dec 13 19:02:14.550: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5340-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Dec 13 19:02:14.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 explain e2e-test-crd-publish-openapi-5340-crds.spec.bars2'
Dec 13 19:02:14.786: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:02:19.332: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7997" for this suite.
Dec 13 19:02:25.340: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:02:25.381: INFO: namespace crd-publish-openapi-7997 deletion completed in 6.048027047s

• [SLOW TEST:18.388 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:02:25.382: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 13 19:02:25.410: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-9172'
Dec 13 19:02:25.530: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 13 19:02:25.531: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Dec 13 19:02:27.537: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 delete deployment e2e-test-httpd-deployment --namespace=kubectl-9172'
Dec 13 19:02:27.646: INFO: stderr: ""
Dec 13 19:02:27.646: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:02:27.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9172" for this suite.
Dec 13 19:02:33.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:02:33.696: INFO: namespace kubectl-9172 deletion completed in 6.048523774s

• [SLOW TEST:8.315 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:02:33.699: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec 13 19:02:33.742: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6321 /api/v1/namespaces/watch-6321/configmaps/e2e-watch-test-watch-closed ae5a58f5-7f90-4514-b7f5-47d98372e200 127258 0 2019-12-13 19:02:33 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 13 19:02:33.742: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6321 /api/v1/namespaces/watch-6321/configmaps/e2e-watch-test-watch-closed ae5a58f5-7f90-4514-b7f5-47d98372e200 127259 0 2019-12-13 19:02:33 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec 13 19:02:33.750: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6321 /api/v1/namespaces/watch-6321/configmaps/e2e-watch-test-watch-closed ae5a58f5-7f90-4514-b7f5-47d98372e200 127260 0 2019-12-13 19:02:33 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 13 19:02:33.750: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-6321 /api/v1/namespaces/watch-6321/configmaps/e2e-watch-test-watch-closed ae5a58f5-7f90-4514-b7f5-47d98372e200 127261 0 2019-12-13 19:02:33 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:02:33.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6321" for this suite.
Dec 13 19:02:39.757: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:02:39.801: INFO: namespace watch-6321 deletion completed in 6.049874999s

• [SLOW TEST:6.102 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:02:39.802: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-724
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 13 19:02:39.822: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 13 19:03:11.865: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.160.134.87:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-724 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 13 19:03:11.865: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 19:03:12.254: INFO: Found all expected endpoints: [netserver-0]
Dec 13 19:03:12.257: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://172.160.134.88:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-724 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 13 19:03:12.257: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 19:03:12.503: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:03:12.503: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-724" for this suite.
Dec 13 19:03:24.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:03:24.552: INFO: namespace pod-network-test-724 deletion completed in 12.046943471s

• [SLOW TEST:44.750 seconds]
[sig-network] Networking
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:03:24.552: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Dec 13 19:03:24.583: INFO: Waiting up to 5m0s for pod "var-expansion-66fccf26-b2ec-43be-b295-c617580cc845" in namespace "var-expansion-6456" to be "success or failure"
Dec 13 19:03:24.588: INFO: Pod "var-expansion-66fccf26-b2ec-43be-b295-c617580cc845": Phase="Pending", Reason="", readiness=false. Elapsed: 4.468974ms
Dec 13 19:03:26.590: INFO: Pod "var-expansion-66fccf26-b2ec-43be-b295-c617580cc845": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006550864s
Dec 13 19:03:28.592: INFO: Pod "var-expansion-66fccf26-b2ec-43be-b295-c617580cc845": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008829167s
Dec 13 19:03:30.595: INFO: Pod "var-expansion-66fccf26-b2ec-43be-b295-c617580cc845": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.011237767s
STEP: Saw pod success
Dec 13 19:03:30.595: INFO: Pod "var-expansion-66fccf26-b2ec-43be-b295-c617580cc845" satisfied condition "success or failure"
Dec 13 19:03:30.596: INFO: Trying to get logs from node 172.160.134.165 pod var-expansion-66fccf26-b2ec-43be-b295-c617580cc845 container dapi-container: <nil>
STEP: delete the pod
Dec 13 19:03:30.621: INFO: Waiting for pod var-expansion-66fccf26-b2ec-43be-b295-c617580cc845 to disappear
Dec 13 19:03:30.623: INFO: Pod var-expansion-66fccf26-b2ec-43be-b295-c617580cc845 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:03:30.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6456" for this suite.
Dec 13 19:03:36.632: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:03:36.675: INFO: namespace var-expansion-6456 deletion completed in 6.049478049s

• [SLOW TEST:12.122 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:03:36.675: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-5273accd-abb6-4c6a-948f-ee5e2bf5d92f
STEP: Creating a pod to test consume secrets
Dec 13 19:03:36.705: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-c0d57a79-4cb3-47e2-b125-ac028c33dd0a" in namespace "projected-9831" to be "success or failure"
Dec 13 19:03:36.708: INFO: Pod "pod-projected-secrets-c0d57a79-4cb3-47e2-b125-ac028c33dd0a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.380071ms
Dec 13 19:03:38.710: INFO: Pod "pod-projected-secrets-c0d57a79-4cb3-47e2-b125-ac028c33dd0a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004564829s
Dec 13 19:03:40.712: INFO: Pod "pod-projected-secrets-c0d57a79-4cb3-47e2-b125-ac028c33dd0a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006847248s
Dec 13 19:03:42.714: INFO: Pod "pod-projected-secrets-c0d57a79-4cb3-47e2-b125-ac028c33dd0a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009072028s
STEP: Saw pod success
Dec 13 19:03:42.714: INFO: Pod "pod-projected-secrets-c0d57a79-4cb3-47e2-b125-ac028c33dd0a" satisfied condition "success or failure"
Dec 13 19:03:42.716: INFO: Trying to get logs from node 172.160.134.165 pod pod-projected-secrets-c0d57a79-4cb3-47e2-b125-ac028c33dd0a container secret-volume-test: <nil>
STEP: delete the pod
Dec 13 19:03:42.730: INFO: Waiting for pod pod-projected-secrets-c0d57a79-4cb3-47e2-b125-ac028c33dd0a to disappear
Dec 13 19:03:42.734: INFO: Pod pod-projected-secrets-c0d57a79-4cb3-47e2-b125-ac028c33dd0a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:03:42.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9831" for this suite.
Dec 13 19:03:48.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:03:48.782: INFO: namespace projected-9831 deletion completed in 6.046496377s

• [SLOW TEST:12.107 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:03:48.782: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Dec 13 19:03:48.809: INFO: Waiting up to 5m0s for pod "client-containers-f5fbc7e0-9620-43c4-b016-b9105131955b" in namespace "containers-751" to be "success or failure"
Dec 13 19:03:48.811: INFO: Pod "client-containers-f5fbc7e0-9620-43c4-b016-b9105131955b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.547133ms
Dec 13 19:03:50.813: INFO: Pod "client-containers-f5fbc7e0-9620-43c4-b016-b9105131955b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003618977s
Dec 13 19:03:52.815: INFO: Pod "client-containers-f5fbc7e0-9620-43c4-b016-b9105131955b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005828894s
Dec 13 19:03:54.817: INFO: Pod "client-containers-f5fbc7e0-9620-43c4-b016-b9105131955b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008165733s
STEP: Saw pod success
Dec 13 19:03:54.817: INFO: Pod "client-containers-f5fbc7e0-9620-43c4-b016-b9105131955b" satisfied condition "success or failure"
Dec 13 19:03:54.819: INFO: Trying to get logs from node 172.160.134.165 pod client-containers-f5fbc7e0-9620-43c4-b016-b9105131955b container test-container: <nil>
STEP: delete the pod
Dec 13 19:03:54.833: INFO: Waiting for pod client-containers-f5fbc7e0-9620-43c4-b016-b9105131955b to disappear
Dec 13 19:03:54.835: INFO: Pod client-containers-f5fbc7e0-9620-43c4-b016-b9105131955b no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:03:54.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-751" for this suite.
Dec 13 19:04:00.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:04:00.887: INFO: namespace containers-751 deletion completed in 6.050079288s

• [SLOW TEST:12.105 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:04:00.887: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:04:06.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8377" for this suite.
Dec 13 19:04:12.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:04:13.013: INFO: namespace namespaces-8377 deletion completed in 6.04597407s
STEP: Destroying namespace "nsdeletetest-3087" for this suite.
Dec 13 19:04:13.014: INFO: Namespace nsdeletetest-3087 was already deleted
STEP: Destroying namespace "nsdeletetest-7270" for this suite.
Dec 13 19:04:19.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:04:19.059: INFO: namespace nsdeletetest-7270 deletion completed in 6.044391035s

• [SLOW TEST:18.171 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:04:19.059: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 19:04:19.094: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec 13 19:04:19.101: INFO: Number of nodes with available pods: 0
Dec 13 19:04:19.101: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:04:20.119: INFO: Number of nodes with available pods: 0
Dec 13 19:04:20.119: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:04:21.105: INFO: Number of nodes with available pods: 0
Dec 13 19:04:21.105: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:04:22.104: INFO: Number of nodes with available pods: 0
Dec 13 19:04:22.104: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:04:23.105: INFO: Number of nodes with available pods: 0
Dec 13 19:04:23.105: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:04:24.105: INFO: Number of nodes with available pods: 1
Dec 13 19:04:24.105: INFO: Node 172.160.134.166 is running more than one daemon pod
Dec 13 19:04:25.105: INFO: Number of nodes with available pods: 1
Dec 13 19:04:25.105: INFO: Node 172.160.134.166 is running more than one daemon pod
Dec 13 19:04:26.105: INFO: Number of nodes with available pods: 2
Dec 13 19:04:26.105: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec 13 19:04:26.122: INFO: Wrong image for pod: daemon-set-4fsc4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 13 19:04:26.122: INFO: Wrong image for pod: daemon-set-sg788. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 13 19:04:27.130: INFO: Wrong image for pod: daemon-set-4fsc4. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 13 19:04:27.130: INFO: Pod daemon-set-4fsc4 is not available
Dec 13 19:04:27.130: INFO: Wrong image for pod: daemon-set-sg788. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 13 19:04:28.130: INFO: Pod daemon-set-2v4wp is not available
Dec 13 19:04:28.130: INFO: Wrong image for pod: daemon-set-sg788. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 13 19:04:29.130: INFO: Pod daemon-set-2v4wp is not available
Dec 13 19:04:29.130: INFO: Wrong image for pod: daemon-set-sg788. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 13 19:04:30.130: INFO: Pod daemon-set-2v4wp is not available
Dec 13 19:04:30.130: INFO: Wrong image for pod: daemon-set-sg788. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 13 19:04:31.130: INFO: Pod daemon-set-2v4wp is not available
Dec 13 19:04:31.130: INFO: Wrong image for pod: daemon-set-sg788. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 13 19:04:32.130: INFO: Pod daemon-set-2v4wp is not available
Dec 13 19:04:32.130: INFO: Wrong image for pod: daemon-set-sg788. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 13 19:04:33.130: INFO: Wrong image for pod: daemon-set-sg788. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 13 19:04:34.130: INFO: Wrong image for pod: daemon-set-sg788. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 13 19:04:35.129: INFO: Wrong image for pod: daemon-set-sg788. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 13 19:04:36.130: INFO: Wrong image for pod: daemon-set-sg788. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 13 19:04:36.130: INFO: Pod daemon-set-sg788 is not available
Dec 13 19:04:37.129: INFO: Pod daemon-set-jtv42 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Dec 13 19:04:37.134: INFO: Number of nodes with available pods: 1
Dec 13 19:04:37.134: INFO: Node 172.160.134.166 is running more than one daemon pod
Dec 13 19:04:38.138: INFO: Number of nodes with available pods: 1
Dec 13 19:04:38.138: INFO: Node 172.160.134.166 is running more than one daemon pod
Dec 13 19:04:39.138: INFO: Number of nodes with available pods: 1
Dec 13 19:04:39.138: INFO: Node 172.160.134.166 is running more than one daemon pod
Dec 13 19:04:40.138: INFO: Number of nodes with available pods: 1
Dec 13 19:04:40.138: INFO: Node 172.160.134.166 is running more than one daemon pod
Dec 13 19:04:41.138: INFO: Number of nodes with available pods: 1
Dec 13 19:04:41.138: INFO: Node 172.160.134.166 is running more than one daemon pod
Dec 13 19:04:42.138: INFO: Number of nodes with available pods: 1
Dec 13 19:04:42.138: INFO: Node 172.160.134.166 is running more than one daemon pod
Dec 13 19:04:43.138: INFO: Number of nodes with available pods: 2
Dec 13 19:04:43.138: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8267, will wait for the garbage collector to delete the pods
Dec 13 19:04:43.200: INFO: Deleting DaemonSet.extensions daemon-set took: 3.410777ms
Dec 13 19:04:43.501: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.206582ms
Dec 13 19:04:48.102: INFO: Number of nodes with available pods: 0
Dec 13 19:04:48.102: INFO: Number of running nodes: 0, number of available pods: 0
Dec 13 19:04:48.104: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8267/daemonsets","resourceVersion":"127630"},"items":null}

Dec 13 19:04:48.105: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8267/pods","resourceVersion":"127630"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:04:48.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8267" for this suite.
Dec 13 19:04:54.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:04:54.160: INFO: namespace daemonsets-8267 deletion completed in 6.049382166s

• [SLOW TEST:35.101 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:04:54.160: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 13 19:04:54.184: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-9907'
Dec 13 19:04:54.301: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 13 19:04:54.301: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: rolling-update to same image controller
Dec 13 19:04:54.311: INFO: scanned /root for discovery docs: <nil>
Dec 13 19:04:54.311: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-9907'
Dec 13 19:05:13.097: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 13 19:05:13.097: INFO: stdout: "Created e2e-test-httpd-rc-1fda6e92212215a45ce62dcfd89f6b11\nScaling up e2e-test-httpd-rc-1fda6e92212215a45ce62dcfd89f6b11 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-1fda6e92212215a45ce62dcfd89f6b11 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-1fda6e92212215a45ce62dcfd89f6b11 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Dec 13 19:05:13.097: INFO: stdout: "Created e2e-test-httpd-rc-1fda6e92212215a45ce62dcfd89f6b11\nScaling up e2e-test-httpd-rc-1fda6e92212215a45ce62dcfd89f6b11 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-1fda6e92212215a45ce62dcfd89f6b11 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-1fda6e92212215a45ce62dcfd89f6b11 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Dec 13 19:05:13.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-9907'
Dec 13 19:05:13.205: INFO: stderr: ""
Dec 13 19:05:13.205: INFO: stdout: "e2e-test-httpd-rc-1fda6e92212215a45ce62dcfd89f6b11-6gbfh "
Dec 13 19:05:13.206: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods e2e-test-httpd-rc-1fda6e92212215a45ce62dcfd89f6b11-6gbfh -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-9907'
Dec 13 19:05:13.308: INFO: stderr: ""
Dec 13 19:05:13.308: INFO: stdout: "true"
Dec 13 19:05:13.308: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods e2e-test-httpd-rc-1fda6e92212215a45ce62dcfd89f6b11-6gbfh -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-9907'
Dec 13 19:05:13.415: INFO: stderr: ""
Dec 13 19:05:13.415: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Dec 13 19:05:13.415: INFO: e2e-test-httpd-rc-1fda6e92212215a45ce62dcfd89f6b11-6gbfh is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Dec 13 19:05:13.415: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 delete rc e2e-test-httpd-rc --namespace=kubectl-9907'
Dec 13 19:05:13.523: INFO: stderr: ""
Dec 13 19:05:13.523: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:05:13.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9907" for this suite.
Dec 13 19:05:19.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:05:19.582: INFO: namespace kubectl-9907 deletion completed in 6.053232638s

• [SLOW TEST:25.422 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:05:19.582: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4082.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-4082.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4082.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4082.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4082.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-4082.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4082.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-4082.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4082.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4082.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-4082.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-4082.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-4082.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-4082.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-4082.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-4082.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-4082.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4082.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 13 19:05:47.642: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-4082.svc.cluster.local from pod dns-4082/dns-test-e84bbe75-3108-4ac3-a49c-09efcbd56612: the server could not find the requested resource (get pods dns-test-e84bbe75-3108-4ac3-a49c-09efcbd56612)
Dec 13 19:05:47.655: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4082.svc.cluster.local from pod dns-4082/dns-test-e84bbe75-3108-4ac3-a49c-09efcbd56612: the server could not find the requested resource (get pods dns-test-e84bbe75-3108-4ac3-a49c-09efcbd56612)
Dec 13 19:05:47.662: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-4082.svc.cluster.local from pod dns-4082/dns-test-e84bbe75-3108-4ac3-a49c-09efcbd56612: the server could not find the requested resource (get pods dns-test-e84bbe75-3108-4ac3-a49c-09efcbd56612)
Dec 13 19:05:47.677: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-4082.svc.cluster.local from pod dns-4082/dns-test-e84bbe75-3108-4ac3-a49c-09efcbd56612: the server could not find the requested resource (get pods dns-test-e84bbe75-3108-4ac3-a49c-09efcbd56612)
Dec 13 19:05:47.699: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-4082.svc.cluster.local from pod dns-4082/dns-test-e84bbe75-3108-4ac3-a49c-09efcbd56612: the server could not find the requested resource (get pods dns-test-e84bbe75-3108-4ac3-a49c-09efcbd56612)
Dec 13 19:05:47.701: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-4082.svc.cluster.local from pod dns-4082/dns-test-e84bbe75-3108-4ac3-a49c-09efcbd56612: the server could not find the requested resource (get pods dns-test-e84bbe75-3108-4ac3-a49c-09efcbd56612)
Dec 13 19:05:47.703: INFO: Unable to read jessie_udp@dns-test-service-2.dns-4082.svc.cluster.local from pod dns-4082/dns-test-e84bbe75-3108-4ac3-a49c-09efcbd56612: the server could not find the requested resource (get pods dns-test-e84bbe75-3108-4ac3-a49c-09efcbd56612)
Dec 13 19:05:47.707: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-4082.svc.cluster.local from pod dns-4082/dns-test-e84bbe75-3108-4ac3-a49c-09efcbd56612: the server could not find the requested resource (get pods dns-test-e84bbe75-3108-4ac3-a49c-09efcbd56612)
Dec 13 19:05:47.711: INFO: Lookups using dns-4082/dns-test-e84bbe75-3108-4ac3-a49c-09efcbd56612 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-4082.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-4082.svc.cluster.local wheezy_udp@dns-test-service-2.dns-4082.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-4082.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-4082.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-4082.svc.cluster.local jessie_udp@dns-test-service-2.dns-4082.svc.cluster.local jessie_tcp@dns-test-service-2.dns-4082.svc.cluster.local]

Dec 13 19:05:52.732: INFO: DNS probes using dns-4082/dns-test-e84bbe75-3108-4ac3-a49c-09efcbd56612 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:05:52.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4082" for this suite.
Dec 13 19:05:58.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:05:58.821: INFO: namespace dns-4082 deletion completed in 6.050204795s

• [SLOW TEST:39.239 seconds]
[sig-network] DNS
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:05:58.821: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-ed3597c2-083f-4884-8ad2-588fc0d7e671 in namespace container-probe-3159
Dec 13 19:06:04.860: INFO: Started pod busybox-ed3597c2-083f-4884-8ad2-588fc0d7e671 in namespace container-probe-3159
STEP: checking the pod's current state and verifying that restartCount is present
Dec 13 19:06:04.862: INFO: Initial restart count of pod busybox-ed3597c2-083f-4884-8ad2-588fc0d7e671 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:10:05.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3159" for this suite.
Dec 13 19:10:11.161: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:10:11.202: INFO: namespace container-probe-3159 deletion completed in 6.050275821s

• [SLOW TEST:252.381 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:10:11.202: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 13 19:10:11.221: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 13 19:10:11.227: INFO: Waiting for terminating namespaces to be deleted...
Dec 13 19:10:11.229: INFO: 
Logging pods the kubelet thinks is on node 172.160.134.165 before test
Dec 13 19:10:11.241: INFO: iag-172.160.134.165 from kube-system started at 2019-12-12 13:53:36 +0000 UTC (1 container statuses recorded)
Dec 13 19:10:11.241: INFO: 	Container iag ready: true, restart count 0
Dec 13 19:10:11.241: INFO: sonobuoy-e2e-job-acb159fe38ea4959 from sonobuoy started at 2019-12-13 17:43:15 +0000 UTC (2 container statuses recorded)
Dec 13 19:10:11.241: INFO: 	Container e2e ready: true, restart count 0
Dec 13 19:10:11.241: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 13 19:10:11.241: INFO: sonobuoy-systemd-logs-daemon-set-5a2f946422e448af-pq5l8 from sonobuoy started at 2019-12-13 17:43:15 +0000 UTC (2 container statuses recorded)
Dec 13 19:10:11.241: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 13 19:10:11.241: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 13 19:10:11.241: INFO: 
Logging pods the kubelet thinks is on node 172.160.134.166 before test
Dec 13 19:10:11.255: INFO: sonobuoy from sonobuoy started at 2019-12-13 17:42:49 +0000 UTC (1 container statuses recorded)
Dec 13 19:10:11.255: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 13 19:10:11.255: INFO: coredns-6cf786c879-zgnqd from kube-system started at 2019-12-12 19:44:20 +0000 UTC (1 container statuses recorded)
Dec 13 19:10:11.255: INFO: 	Container coredns ready: true, restart count 0
Dec 13 19:10:11.255: INFO: sonobuoy-systemd-logs-daemon-set-5a2f946422e448af-cjc42 from sonobuoy started at 2019-12-13 17:43:15 +0000 UTC (2 container statuses recorded)
Dec 13 19:10:11.255: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 13 19:10:11.255: INFO: 	Container systemd-logs ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15e003f2e09ea090], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15e003f2e1602b72], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:10:12.267: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6496" for this suite.
Dec 13 19:10:18.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:10:18.320: INFO: namespace sched-pred-6496 deletion completed in 6.051362931s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.118 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:10:18.321: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-c071a7d6-6707-4f7b-a28f-078d2ae82e97
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:10:18.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7425" for this suite.
Dec 13 19:10:24.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:10:24.400: INFO: namespace secrets-7425 deletion completed in 6.050204465s

• [SLOW TEST:6.079 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:10:24.401: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1993
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-1993
STEP: Creating statefulset with conflicting port in namespace statefulset-1993
STEP: Waiting until pod test-pod will start running in namespace statefulset-1993
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-1993
Dec 13 19:10:32.445: INFO: Observed stateful pod in namespace: statefulset-1993, name: ss-0, uid: 6f7f4b58-c018-49fa-a8ee-a3ddbd6d308c, status phase: Pending. Waiting for statefulset controller to delete.
Dec 13 19:10:34.166: INFO: Observed stateful pod in namespace: statefulset-1993, name: ss-0, uid: 6f7f4b58-c018-49fa-a8ee-a3ddbd6d308c, status phase: Failed. Waiting for statefulset controller to delete.
Dec 13 19:10:34.174: INFO: Observed stateful pod in namespace: statefulset-1993, name: ss-0, uid: 6f7f4b58-c018-49fa-a8ee-a3ddbd6d308c, status phase: Failed. Waiting for statefulset controller to delete.
Dec 13 19:10:34.178: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-1993
STEP: Removing pod with conflicting port in namespace statefulset-1993
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-1993 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 13 19:10:40.212: INFO: Deleting all statefulset in ns statefulset-1993
Dec 13 19:10:40.213: INFO: Scaling statefulset ss to 0
Dec 13 19:10:50.222: INFO: Waiting for statefulset status.replicas updated to 0
Dec 13 19:10:50.223: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:10:50.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1993" for this suite.
Dec 13 19:10:56.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:10:56.280: INFO: namespace statefulset-1993 deletion completed in 6.047609629s

• [SLOW TEST:31.879 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:10:56.280: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Dec 13 19:10:56.305: INFO: Waiting up to 5m0s for pod "var-expansion-afa8df7e-5fd3-4c7e-b1aa-ef60aa12229d" in namespace "var-expansion-3279" to be "success or failure"
Dec 13 19:10:56.308: INFO: Pod "var-expansion-afa8df7e-5fd3-4c7e-b1aa-ef60aa12229d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.601371ms
Dec 13 19:10:58.310: INFO: Pod "var-expansion-afa8df7e-5fd3-4c7e-b1aa-ef60aa12229d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00491743s
Dec 13 19:11:00.312: INFO: Pod "var-expansion-afa8df7e-5fd3-4c7e-b1aa-ef60aa12229d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007308009s
Dec 13 19:11:02.315: INFO: Pod "var-expansion-afa8df7e-5fd3-4c7e-b1aa-ef60aa12229d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009550054s
Dec 13 19:11:04.317: INFO: Pod "var-expansion-afa8df7e-5fd3-4c7e-b1aa-ef60aa12229d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.011938989s
STEP: Saw pod success
Dec 13 19:11:04.317: INFO: Pod "var-expansion-afa8df7e-5fd3-4c7e-b1aa-ef60aa12229d" satisfied condition "success or failure"
Dec 13 19:11:04.319: INFO: Trying to get logs from node 172.160.134.166 pod var-expansion-afa8df7e-5fd3-4c7e-b1aa-ef60aa12229d container dapi-container: <nil>
STEP: delete the pod
Dec 13 19:11:04.332: INFO: Waiting for pod var-expansion-afa8df7e-5fd3-4c7e-b1aa-ef60aa12229d to disappear
Dec 13 19:11:04.336: INFO: Pod var-expansion-afa8df7e-5fd3-4c7e-b1aa-ef60aa12229d no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:11:04.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3279" for this suite.
Dec 13 19:11:10.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:11:10.386: INFO: namespace var-expansion-3279 deletion completed in 6.048743056s

• [SLOW TEST:14.106 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:11:10.386: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec 13 19:11:11.229: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Dec 13 19:11:13.234: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861071, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861071, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861071, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861071, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:11:15.237: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861071, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861071, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861071, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861071, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:11:17.237: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861071, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861071, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861071, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861071, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 13 19:11:20.247: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 19:11:20.249: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:11:21.426: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-98" for this suite.
Dec 13 19:11:27.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:11:27.478: INFO: namespace crd-webhook-98 deletion completed in 6.050489191s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:17.099 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:11:27.486: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Dec 13 19:11:27.519: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 create -f - --namespace=kubectl-1325'
Dec 13 19:11:27.799: INFO: stderr: ""
Dec 13 19:11:27.799: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 13 19:11:27.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1325'
Dec 13 19:11:27.909: INFO: stderr: ""
Dec 13 19:11:27.909: INFO: stdout: "update-demo-nautilus-62x6b update-demo-nautilus-ppxw4 "
Dec 13 19:11:27.909: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-62x6b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1325'
Dec 13 19:11:28.016: INFO: stderr: ""
Dec 13 19:11:28.016: INFO: stdout: ""
Dec 13 19:11:28.016: INFO: update-demo-nautilus-62x6b is created but not running
Dec 13 19:11:33.016: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1325'
Dec 13 19:11:33.127: INFO: stderr: ""
Dec 13 19:11:33.127: INFO: stdout: "update-demo-nautilus-62x6b update-demo-nautilus-ppxw4 "
Dec 13 19:11:33.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-62x6b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1325'
Dec 13 19:11:33.235: INFO: stderr: ""
Dec 13 19:11:33.235: INFO: stdout: ""
Dec 13 19:11:33.235: INFO: update-demo-nautilus-62x6b is created but not running
Dec 13 19:11:38.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1325'
Dec 13 19:11:38.340: INFO: stderr: ""
Dec 13 19:11:38.340: INFO: stdout: "update-demo-nautilus-62x6b update-demo-nautilus-ppxw4 "
Dec 13 19:11:38.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-62x6b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1325'
Dec 13 19:11:38.438: INFO: stderr: ""
Dec 13 19:11:38.438: INFO: stdout: "true"
Dec 13 19:11:38.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-62x6b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1325'
Dec 13 19:11:38.541: INFO: stderr: ""
Dec 13 19:11:38.541: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 13 19:11:38.541: INFO: validating pod update-demo-nautilus-62x6b
Dec 13 19:11:38.551: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 13 19:11:38.551: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 13 19:11:38.551: INFO: update-demo-nautilus-62x6b is verified up and running
Dec 13 19:11:38.551: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-ppxw4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1325'
Dec 13 19:11:38.655: INFO: stderr: ""
Dec 13 19:11:38.655: INFO: stdout: "true"
Dec 13 19:11:38.655: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-ppxw4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1325'
Dec 13 19:11:38.758: INFO: stderr: ""
Dec 13 19:11:38.758: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 13 19:11:38.758: INFO: validating pod update-demo-nautilus-ppxw4
Dec 13 19:11:38.762: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 13 19:11:38.762: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 13 19:11:38.762: INFO: update-demo-nautilus-ppxw4 is verified up and running
STEP: rolling-update to new replication controller
Dec 13 19:11:38.765: INFO: scanned /root for discovery docs: <nil>
Dec 13 19:11:38.765: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-1325'
Dec 13 19:12:06.199: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 13 19:12:06.199: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 13 19:12:06.199: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1325'
Dec 13 19:12:06.307: INFO: stderr: ""
Dec 13 19:12:06.307: INFO: stdout: "update-demo-kitten-2859x update-demo-kitten-76gk6 "
Dec 13 19:12:06.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-kitten-2859x -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1325'
Dec 13 19:12:06.412: INFO: stderr: ""
Dec 13 19:12:06.412: INFO: stdout: "true"
Dec 13 19:12:06.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-kitten-2859x -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1325'
Dec 13 19:12:06.515: INFO: stderr: ""
Dec 13 19:12:06.515: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 13 19:12:06.515: INFO: validating pod update-demo-kitten-2859x
Dec 13 19:12:06.521: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 13 19:12:06.521: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 13 19:12:06.521: INFO: update-demo-kitten-2859x is verified up and running
Dec 13 19:12:06.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-kitten-76gk6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1325'
Dec 13 19:12:06.627: INFO: stderr: ""
Dec 13 19:12:06.627: INFO: stdout: "true"
Dec 13 19:12:06.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-kitten-76gk6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1325'
Dec 13 19:12:06.729: INFO: stderr: ""
Dec 13 19:12:06.729: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 13 19:12:06.729: INFO: validating pod update-demo-kitten-76gk6
Dec 13 19:12:06.742: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 13 19:12:06.742: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 13 19:12:06.742: INFO: update-demo-kitten-76gk6 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:12:06.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1325" for this suite.
Dec 13 19:12:18.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:12:18.790: INFO: namespace kubectl-1325 deletion completed in 12.046878508s

• [SLOW TEST:51.305 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:12:18.791: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-96bc8922-1f37-42d9-b2a3-e43fa15a961a
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-96bc8922-1f37-42d9-b2a3-e43fa15a961a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:13:45.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7391" for this suite.
Dec 13 19:13:57.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:13:57.309: INFO: namespace configmap-7391 deletion completed in 12.046624981s

• [SLOW TEST:98.519 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:13:57.310: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec 13 19:13:57.338: INFO: Waiting up to 5m0s for pod "pod-23525c68-c08d-48a0-8c28-6381e62845e4" in namespace "emptydir-1103" to be "success or failure"
Dec 13 19:13:57.341: INFO: Pod "pod-23525c68-c08d-48a0-8c28-6381e62845e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.55365ms
Dec 13 19:13:59.343: INFO: Pod "pod-23525c68-c08d-48a0-8c28-6381e62845e4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005019643s
Dec 13 19:14:01.346: INFO: Pod "pod-23525c68-c08d-48a0-8c28-6381e62845e4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007484495s
Dec 13 19:14:03.348: INFO: Pod "pod-23525c68-c08d-48a0-8c28-6381e62845e4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009482712s
Dec 13 19:14:05.350: INFO: Pod "pod-23525c68-c08d-48a0-8c28-6381e62845e4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012049534s
Dec 13 19:14:07.353: INFO: Pod "pod-23525c68-c08d-48a0-8c28-6381e62845e4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.014271463s
Dec 13 19:14:09.355: INFO: Pod "pod-23525c68-c08d-48a0-8c28-6381e62845e4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.016667467s
Dec 13 19:14:11.357: INFO: Pod "pod-23525c68-c08d-48a0-8c28-6381e62845e4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.018931487s
Dec 13 19:14:13.359: INFO: Pod "pod-23525c68-c08d-48a0-8c28-6381e62845e4": Phase="Pending", Reason="", readiness=false. Elapsed: 16.020971949s
Dec 13 19:14:15.362: INFO: Pod "pod-23525c68-c08d-48a0-8c28-6381e62845e4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.023324154s
Dec 13 19:14:17.364: INFO: Pod "pod-23525c68-c08d-48a0-8c28-6381e62845e4": Phase="Pending", Reason="", readiness=false. Elapsed: 20.025499251s
Dec 13 19:14:19.366: INFO: Pod "pod-23525c68-c08d-48a0-8c28-6381e62845e4": Phase="Pending", Reason="", readiness=false. Elapsed: 22.027710427s
Dec 13 19:14:21.368: INFO: Pod "pod-23525c68-c08d-48a0-8c28-6381e62845e4": Phase="Pending", Reason="", readiness=false. Elapsed: 24.029797192s
Dec 13 19:14:23.372: INFO: Pod "pod-23525c68-c08d-48a0-8c28-6381e62845e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.034200696s
STEP: Saw pod success
Dec 13 19:14:23.373: INFO: Pod "pod-23525c68-c08d-48a0-8c28-6381e62845e4" satisfied condition "success or failure"
Dec 13 19:14:23.378: INFO: Trying to get logs from node 172.160.134.165 pod pod-23525c68-c08d-48a0-8c28-6381e62845e4 container test-container: <nil>
STEP: delete the pod
Dec 13 19:14:23.397: INFO: Waiting for pod pod-23525c68-c08d-48a0-8c28-6381e62845e4 to disappear
Dec 13 19:14:23.401: INFO: Pod pod-23525c68-c08d-48a0-8c28-6381e62845e4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:14:23.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1103" for this suite.
Dec 13 19:14:29.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:14:29.447: INFO: namespace emptydir-1103 deletion completed in 6.043705602s

• [SLOW TEST:32.137 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:14:29.447: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
W1213 19:14:35.485405      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 13 19:14:35.485: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:14:35.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6097" for this suite.
Dec 13 19:14:41.492: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:14:41.533: INFO: namespace gc-6097 deletion completed in 6.046832576s

• [SLOW TEST:12.087 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:14:41.534: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 13 19:14:41.558: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b07ae11a-ccff-4b2e-9b34-188883bb1523" in namespace "downward-api-6266" to be "success or failure"
Dec 13 19:14:41.560: INFO: Pod "downwardapi-volume-b07ae11a-ccff-4b2e-9b34-188883bb1523": Phase="Pending", Reason="", readiness=false. Elapsed: 1.326709ms
Dec 13 19:14:43.562: INFO: Pod "downwardapi-volume-b07ae11a-ccff-4b2e-9b34-188883bb1523": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003515167s
Dec 13 19:14:45.564: INFO: Pod "downwardapi-volume-b07ae11a-ccff-4b2e-9b34-188883bb1523": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005727554s
Dec 13 19:14:47.566: INFO: Pod "downwardapi-volume-b07ae11a-ccff-4b2e-9b34-188883bb1523": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.00810565s
STEP: Saw pod success
Dec 13 19:14:47.566: INFO: Pod "downwardapi-volume-b07ae11a-ccff-4b2e-9b34-188883bb1523" satisfied condition "success or failure"
Dec 13 19:14:47.568: INFO: Trying to get logs from node 172.160.134.165 pod downwardapi-volume-b07ae11a-ccff-4b2e-9b34-188883bb1523 container client-container: <nil>
STEP: delete the pod
Dec 13 19:14:47.579: INFO: Waiting for pod downwardapi-volume-b07ae11a-ccff-4b2e-9b34-188883bb1523 to disappear
Dec 13 19:14:47.581: INFO: Pod downwardapi-volume-b07ae11a-ccff-4b2e-9b34-188883bb1523 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:14:47.581: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6266" for this suite.
Dec 13 19:14:53.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:14:53.627: INFO: namespace downward-api-6266 deletion completed in 6.043974499s

• [SLOW TEST:12.093 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:14:53.627: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 13 19:14:54.522: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 13 19:14:56.527: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861294, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861294, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861294, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861294, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:14:58.530: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861294, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861294, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861294, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861294, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:15:00.530: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861294, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861294, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861294, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861294, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 13 19:15:03.538: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:15:03.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3275" for this suite.
Dec 13 19:15:09.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:15:09.589: INFO: namespace webhook-3275 deletion completed in 6.045158275s
STEP: Destroying namespace "webhook-3275-markers" for this suite.
Dec 13 19:15:15.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:15:15.637: INFO: namespace webhook-3275-markers deletion completed in 6.047094619s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.015 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:15:15.643: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 19:15:15.669: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 create -f - --namespace=kubectl-4118'
Dec 13 19:15:16.246: INFO: stderr: ""
Dec 13 19:15:16.246: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec 13 19:15:16.246: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 create -f - --namespace=kubectl-4118'
Dec 13 19:15:16.480: INFO: stderr: ""
Dec 13 19:15:16.480: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 13 19:15:17.483: INFO: Selector matched 1 pods for map[app:redis]
Dec 13 19:15:17.483: INFO: Found 0 / 1
Dec 13 19:15:18.483: INFO: Selector matched 1 pods for map[app:redis]
Dec 13 19:15:18.483: INFO: Found 0 / 1
Dec 13 19:15:19.483: INFO: Selector matched 1 pods for map[app:redis]
Dec 13 19:15:19.483: INFO: Found 0 / 1
Dec 13 19:15:20.482: INFO: Selector matched 1 pods for map[app:redis]
Dec 13 19:15:20.482: INFO: Found 0 / 1
Dec 13 19:15:21.483: INFO: Selector matched 1 pods for map[app:redis]
Dec 13 19:15:21.483: INFO: Found 0 / 1
Dec 13 19:15:22.483: INFO: Selector matched 1 pods for map[app:redis]
Dec 13 19:15:22.483: INFO: Found 1 / 1
Dec 13 19:15:22.483: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 13 19:15:22.485: INFO: Selector matched 1 pods for map[app:redis]
Dec 13 19:15:22.485: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 13 19:15:22.485: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 describe pod redis-master-tkpl5 --namespace=kubectl-4118'
Dec 13 19:15:22.616: INFO: stderr: ""
Dec 13 19:15:22.616: INFO: stdout: "Name:         redis-master-tkpl5\nNamespace:    kubectl-4118\nPriority:     0\nNode:         172.160.134.165/172.160.134.165\nStart Time:   Fri, 13 Dec 2019 19:15:16 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nStatus:       Running\nIP:           172.160.134.133\nIPs:\n  IP:           172.160.134.133\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://e4fb06391ced2056bbf06a4d62741039f91f1c10cc70f86c3c04f58fb79cf73e\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 13 Dec 2019 19:15:20 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-vkfbg (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-vkfbg:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-vkfbg\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                      Message\n  ----    ------     ----       ----                      -------\n  Normal  Scheduled  <unknown>  default-scheduler         Successfully assigned kubectl-4118/redis-master-tkpl5 to 172.160.134.165\n  Normal  Pulled     2s         kubelet, 172.160.134.165  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    2s         kubelet, 172.160.134.165  Created container redis-master\n  Normal  Started    2s         kubelet, 172.160.134.165  Started container redis-master\n"
Dec 13 19:15:22.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 describe rc redis-master --namespace=kubectl-4118'
Dec 13 19:15:22.753: INFO: stderr: ""
Dec 13 19:15:22.753: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-4118\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  6s    replication-controller  Created pod: redis-master-tkpl5\n"
Dec 13 19:15:22.753: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 describe service redis-master --namespace=kubectl-4118'
Dec 13 19:15:22.863: INFO: stderr: ""
Dec 13 19:15:22.863: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-4118\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.254.153.58\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         172.160.134.133:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec 13 19:15:22.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 describe node 172.160.134.165'
Dec 13 19:15:22.997: INFO: stderr: ""
Dec 13 19:15:22.997: INFO: stdout: "Name:               172.160.134.165\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=172.160.134.165\n                    kubernetes.io/os=linux\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 12 Dec 2019 13:53:30 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Fri, 13 Dec 2019 19:15:10 +0000   Thu, 12 Dec 2019 13:53:30 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Fri, 13 Dec 2019 19:15:10 +0000   Thu, 12 Dec 2019 13:53:30 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Fri, 13 Dec 2019 19:15:10 +0000   Thu, 12 Dec 2019 13:53:30 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Fri, 13 Dec 2019 19:15:10 +0000   Fri, 13 Dec 2019 13:52:04 +0000   KubeletReady                 kubelet is posting ready status\nAddresses:\n  InternalIP:  172.160.134.165\n  Hostname:    172.160.134.165\nCapacity:\n cpu:                8\n ephemeral-storage:  20466Mi\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             7992640Ki\n pods:               180\nAllocatable:\n cpu:                7\n ephemeral-storage:  19314140743\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             6866240Ki\n pods:               180\nSystem Info:\n Machine ID:                 4c978e458d6141fda808365c48b29c33\n System UUID:                C10C0B92-1F91-4294-AED7-C816899B1853\n Boot ID:                    57c1d3ab-9ba9-4970-8647-341d20abba5b\n Kernel Version:             3.10.0-693.21.1.el7.x86_64\n OS Image:                   NewStart Carrier Grade Server Linux Core 5.04\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://17.3.3\n Kubelet Version:            v1.16.1\n Kube-Proxy Version:         v1.16.1\nNon-terminated Pods:         (4 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                iag-172.160.134.165                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         29h\n  kubectl-4118               redis-master-tkpl5                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         6s\n  sonobuoy                   sonobuoy-e2e-job-acb159fe38ea4959                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         92m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-5a2f946422e448af-pq5l8    0 (0%)        0 (0%)      0 (0%)           0 (0%)         92m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests  Limits\n  --------           --------  ------\n  cpu                0 (0%)    0 (0%)\n  memory             0 (0%)    0 (0%)\n  ephemeral-storage  0 (0%)    0 (0%)\nEvents:              <none>\n"
Dec 13 19:15:22.997: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 describe namespace kubectl-4118'
Dec 13 19:15:23.113: INFO: stderr: ""
Dec 13 19:15:23.113: INFO: stdout: "Name:         kubectl-4118\nLabels:       e2e-framework=kubectl\n              e2e-run=3f0ae178-3bbe-4ce4-9327-26be0029b2ca\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:15:23.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4118" for this suite.
Dec 13 19:15:35.120: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:15:35.162: INFO: namespace kubectl-4118 deletion completed in 12.047022888s

• [SLOW TEST:19.519 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:15:35.162: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Dec 13 19:15:35.186: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 19:15:39.744: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:15:57.475: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9833" for this suite.
Dec 13 19:16:03.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:16:03.527: INFO: namespace crd-publish-openapi-9833 deletion completed in 6.050156658s

• [SLOW TEST:28.365 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:16:03.528: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-1605
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-1605
STEP: creating replication controller externalsvc in namespace services-1605
I1213 19:16:03.578279      25 runners.go:184] Created replication controller with name: externalsvc, namespace: services-1605, replica count: 2
I1213 19:16:06.628662      25 runners.go:184] externalsvc Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1213 19:16:09.629024      25 runners.go:184] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1213 19:16:12.629334      25 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Dec 13 19:16:12.639: INFO: Creating new exec pod
Dec 13 19:16:20.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=services-1605 execpodp24bd -- /bin/sh -x -c nslookup nodeport-service'
Dec 13 19:16:21.502: INFO: stderr: "+ nslookup nodeport-service\n"
Dec 13 19:16:21.502: INFO: stdout: "Server:\t\t10.254.0.10\nAddress:\t10.254.0.10#53\n\nnodeport-service.services-1605.svc.cluster.local\tcanonical name = externalsvc.services-1605.svc.cluster.local.\nName:\texternalsvc.services-1605.svc.cluster.local\nAddress: 10.254.60.173\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-1605, will wait for the garbage collector to delete the pods
Dec 13 19:16:21.559: INFO: Deleting ReplicationController externalsvc took: 3.106714ms
Dec 13 19:16:21.859: INFO: Terminating ReplicationController externalsvc pods took: 300.214814ms
Dec 13 19:16:28.175: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:16:28.182: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1605" for this suite.
Dec 13 19:16:34.191: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:16:34.233: INFO: namespace services-1605 deletion completed in 6.048059348s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:30.705 seconds]
[sig-network] Services
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:16:34.233: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-d77s9 in namespace proxy-1267
I1213 19:16:34.265719      25 runners.go:184] Created replication controller with name: proxy-service-d77s9, namespace: proxy-1267, replica count: 1
I1213 19:16:35.316048      25 runners.go:184] proxy-service-d77s9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1213 19:16:36.316354      25 runners.go:184] proxy-service-d77s9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1213 19:16:37.316712      25 runners.go:184] proxy-service-d77s9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1213 19:16:38.317042      25 runners.go:184] proxy-service-d77s9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1213 19:16:39.317361      25 runners.go:184] proxy-service-d77s9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1213 19:16:40.317697      25 runners.go:184] proxy-service-d77s9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1213 19:16:41.318021      25 runners.go:184] proxy-service-d77s9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1213 19:16:42.318181      25 runners.go:184] proxy-service-d77s9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1213 19:16:43.318351      25 runners.go:184] proxy-service-d77s9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1213 19:16:44.318534      25 runners.go:184] proxy-service-d77s9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1213 19:16:45.318697      25 runners.go:184] proxy-service-d77s9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1213 19:16:46.318846      25 runners.go:184] proxy-service-d77s9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1213 19:16:47.319011      25 runners.go:184] proxy-service-d77s9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1213 19:16:48.319289      25 runners.go:184] proxy-service-d77s9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1213 19:16:49.319553      25 runners.go:184] proxy-service-d77s9 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 13 19:16:49.321: INFO: setup took 15.068084752s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec 13 19:16:49.330: INFO: (0) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">test<... (200; 8.842315ms)
Dec 13 19:16:49.330: INFO: (0) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 9.117598ms)
Dec 13 19:16:49.331: INFO: (0) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname1/proxy/: foo (200; 9.07449ms)
Dec 13 19:16:49.337: INFO: (0) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 15.892548ms)
Dec 13 19:16:49.338: INFO: (0) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/rewriteme">test</a> (200; 16.190345ms)
Dec 13 19:16:49.338: INFO: (0) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 16.368627ms)
Dec 13 19:16:49.338: INFO: (0) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">... (200; 16.510625ms)
Dec 13 19:16:49.338: INFO: (0) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname1/proxy/: foo (200; 16.16789ms)
Dec 13 19:16:49.338: INFO: (0) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname2/proxy/: bar (200; 16.654308ms)
Dec 13 19:16:49.338: INFO: (0) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname2/proxy/: bar (200; 16.413278ms)
Dec 13 19:16:49.353: INFO: (0) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 31.376812ms)
Dec 13 19:16:49.365: INFO: (0) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:462/proxy/: tls qux (200; 43.302341ms)
Dec 13 19:16:49.365: INFO: (0) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:460/proxy/: tls baz (200; 43.930341ms)
Dec 13 19:16:49.365: INFO: (0) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname1/proxy/: tls baz (200; 44.378487ms)
Dec 13 19:16:49.366: INFO: (0) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname2/proxy/: tls qux (200; 44.004317ms)
Dec 13 19:16:49.366: INFO: (0) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/tlsrewritem... (200; 44.092343ms)
Dec 13 19:16:49.370: INFO: (1) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">test<... (200; 4.153269ms)
Dec 13 19:16:49.371: INFO: (1) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/tlsrewritem... (200; 4.416802ms)
Dec 13 19:16:49.371: INFO: (1) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:460/proxy/: tls baz (200; 4.386773ms)
Dec 13 19:16:49.371: INFO: (1) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 4.656261ms)
Dec 13 19:16:49.371: INFO: (1) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 4.635807ms)
Dec 13 19:16:49.371: INFO: (1) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname1/proxy/: tls baz (200; 5.240005ms)
Dec 13 19:16:49.371: INFO: (1) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">... (200; 5.068264ms)
Dec 13 19:16:49.371: INFO: (1) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 4.788773ms)
Dec 13 19:16:49.372: INFO: (1) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname2/proxy/: bar (200; 5.527365ms)
Dec 13 19:16:49.372: INFO: (1) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname1/proxy/: foo (200; 5.314114ms)
Dec 13 19:16:49.372: INFO: (1) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 5.640756ms)
Dec 13 19:16:49.372: INFO: (1) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname1/proxy/: foo (200; 5.315398ms)
Dec 13 19:16:49.372: INFO: (1) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname2/proxy/: tls qux (200; 5.252013ms)
Dec 13 19:16:49.372: INFO: (1) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname2/proxy/: bar (200; 5.885232ms)
Dec 13 19:16:49.372: INFO: (1) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:462/proxy/: tls qux (200; 6.179603ms)
Dec 13 19:16:49.372: INFO: (1) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/rewriteme">test</a> (200; 5.407357ms)
Dec 13 19:16:49.374: INFO: (2) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 2.135135ms)
Dec 13 19:16:49.375: INFO: (2) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">... (200; 2.498042ms)
Dec 13 19:16:49.375: INFO: (2) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/rewriteme">test</a> (200; 1.981544ms)
Dec 13 19:16:49.375: INFO: (2) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:460/proxy/: tls baz (200; 2.260629ms)
Dec 13 19:16:49.375: INFO: (2) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 3.018499ms)
Dec 13 19:16:49.375: INFO: (2) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 3.456922ms)
Dec 13 19:16:49.375: INFO: (2) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">test<... (200; 2.616118ms)
Dec 13 19:16:49.375: INFO: (2) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 3.237619ms)
Dec 13 19:16:49.376: INFO: (2) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/tlsrewritem... (200; 2.638533ms)
Dec 13 19:16:49.376: INFO: (2) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname2/proxy/: bar (200; 4.133063ms)
Dec 13 19:16:49.376: INFO: (2) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname1/proxy/: foo (200; 3.979912ms)
Dec 13 19:16:49.377: INFO: (2) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname2/proxy/: bar (200; 3.81036ms)
Dec 13 19:16:49.377: INFO: (2) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:462/proxy/: tls qux (200; 3.935608ms)
Dec 13 19:16:49.377: INFO: (2) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname2/proxy/: tls qux (200; 4.017302ms)
Dec 13 19:16:49.377: INFO: (2) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname1/proxy/: foo (200; 4.381551ms)
Dec 13 19:16:49.377: INFO: (2) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname1/proxy/: tls baz (200; 5.179633ms)
Dec 13 19:16:49.379: INFO: (3) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 2.089786ms)
Dec 13 19:16:49.379: INFO: (3) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 2.09963ms)
Dec 13 19:16:49.380: INFO: (3) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 2.291061ms)
Dec 13 19:16:49.380: INFO: (3) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname1/proxy/: tls baz (200; 2.93026ms)
Dec 13 19:16:49.380: INFO: (3) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">... (200; 2.869224ms)
Dec 13 19:16:49.381: INFO: (3) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 3.147666ms)
Dec 13 19:16:49.381: INFO: (3) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:460/proxy/: tls baz (200; 2.924491ms)
Dec 13 19:16:49.381: INFO: (3) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname2/proxy/: tls qux (200; 3.045958ms)
Dec 13 19:16:49.382: INFO: (3) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/rewriteme">test</a> (200; 2.969902ms)
Dec 13 19:16:49.382: INFO: (3) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/tlsrewritem... (200; 3.636821ms)
Dec 13 19:16:49.382: INFO: (3) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">test<... (200; 3.757577ms)
Dec 13 19:16:49.382: INFO: (3) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname2/proxy/: bar (200; 3.889911ms)
Dec 13 19:16:49.382: INFO: (3) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:462/proxy/: tls qux (200; 3.358112ms)
Dec 13 19:16:49.383: INFO: (3) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname2/proxy/: bar (200; 5.852516ms)
Dec 13 19:16:49.383: INFO: (3) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname1/proxy/: foo (200; 5.288961ms)
Dec 13 19:16:49.383: INFO: (3) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname1/proxy/: foo (200; 5.402181ms)
Dec 13 19:16:49.385: INFO: (4) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">test<... (200; 1.935047ms)
Dec 13 19:16:49.388: INFO: (4) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:462/proxy/: tls qux (200; 4.63237ms)
Dec 13 19:16:49.388: INFO: (4) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname2/proxy/: tls qux (200; 4.908068ms)
Dec 13 19:16:49.388: INFO: (4) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname1/proxy/: foo (200; 4.050059ms)
Dec 13 19:16:49.389: INFO: (4) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 4.117756ms)
Dec 13 19:16:49.389: INFO: (4) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/rewriteme">test</a> (200; 5.38346ms)
Dec 13 19:16:49.389: INFO: (4) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname1/proxy/: tls baz (200; 5.177164ms)
Dec 13 19:16:49.389: INFO: (4) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 4.970782ms)
Dec 13 19:16:49.389: INFO: (4) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:460/proxy/: tls baz (200; 5.368096ms)
Dec 13 19:16:49.389: INFO: (4) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">... (200; 4.818881ms)
Dec 13 19:16:49.389: INFO: (4) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 5.121048ms)
Dec 13 19:16:49.390: INFO: (4) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/tlsrewritem... (200; 5.386185ms)
Dec 13 19:16:49.390: INFO: (4) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname1/proxy/: foo (200; 5.549723ms)
Dec 13 19:16:49.390: INFO: (4) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 5.685825ms)
Dec 13 19:16:49.390: INFO: (4) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname2/proxy/: bar (200; 5.760465ms)
Dec 13 19:16:49.390: INFO: (4) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname2/proxy/: bar (200; 6.09864ms)
Dec 13 19:16:49.398: INFO: (5) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">test<... (200; 6.297463ms)
Dec 13 19:16:49.398: INFO: (5) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">... (200; 7.11298ms)
Dec 13 19:16:49.398: INFO: (5) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/rewriteme">test</a> (200; 6.394679ms)
Dec 13 19:16:49.398: INFO: (5) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:460/proxy/: tls baz (200; 7.930359ms)
Dec 13 19:16:49.398: INFO: (5) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 7.484519ms)
Dec 13 19:16:49.398: INFO: (5) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname1/proxy/: tls baz (200; 7.838928ms)
Dec 13 19:16:49.398: INFO: (5) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname2/proxy/: tls qux (200; 6.533737ms)
Dec 13 19:16:49.398: INFO: (5) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:462/proxy/: tls qux (200; 6.629659ms)
Dec 13 19:16:49.398: INFO: (5) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname1/proxy/: foo (200; 6.815727ms)
Dec 13 19:16:49.398: INFO: (5) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname2/proxy/: bar (200; 7.442807ms)
Dec 13 19:16:49.398: INFO: (5) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname2/proxy/: bar (200; 6.811506ms)
Dec 13 19:16:49.398: INFO: (5) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 7.278102ms)
Dec 13 19:16:49.398: INFO: (5) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 7.879416ms)
Dec 13 19:16:49.398: INFO: (5) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname1/proxy/: foo (200; 7.027455ms)
Dec 13 19:16:49.398: INFO: (5) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 7.788389ms)
Dec 13 19:16:49.399: INFO: (5) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/tlsrewritem... (200; 7.517636ms)
Dec 13 19:16:49.408: INFO: (6) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname2/proxy/: bar (200; 8.634421ms)
Dec 13 19:16:49.408: INFO: (6) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 9.017456ms)
Dec 13 19:16:49.408: INFO: (6) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/tlsrewritem... (200; 8.975001ms)
Dec 13 19:16:49.408: INFO: (6) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname2/proxy/: bar (200; 9.031219ms)
Dec 13 19:16:49.408: INFO: (6) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 9.068347ms)
Dec 13 19:16:49.408: INFO: (6) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">test<... (200; 9.2065ms)
Dec 13 19:16:49.408: INFO: (6) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:462/proxy/: tls qux (200; 9.160399ms)
Dec 13 19:16:49.408: INFO: (6) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/rewriteme">test</a> (200; 9.152519ms)
Dec 13 19:16:49.408: INFO: (6) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname2/proxy/: tls qux (200; 9.376136ms)
Dec 13 19:16:49.408: INFO: (6) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname1/proxy/: tls baz (200; 9.524761ms)
Dec 13 19:16:49.408: INFO: (6) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">... (200; 9.368807ms)
Dec 13 19:16:49.409: INFO: (6) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 9.381169ms)
Dec 13 19:16:49.409: INFO: (6) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:460/proxy/: tls baz (200; 9.368309ms)
Dec 13 19:16:49.409: INFO: (6) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname1/proxy/: foo (200; 9.514512ms)
Dec 13 19:16:49.409: INFO: (6) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 9.686818ms)
Dec 13 19:16:49.409: INFO: (6) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname1/proxy/: foo (200; 10.034239ms)
Dec 13 19:16:49.412: INFO: (7) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/tlsrewritem... (200; 3.039572ms)
Dec 13 19:16:49.412: INFO: (7) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:462/proxy/: tls qux (200; 2.75192ms)
Dec 13 19:16:49.412: INFO: (7) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:460/proxy/: tls baz (200; 2.858577ms)
Dec 13 19:16:49.412: INFO: (7) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 2.382743ms)
Dec 13 19:16:49.412: INFO: (7) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/rewriteme">test</a> (200; 2.971587ms)
Dec 13 19:16:49.413: INFO: (7) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname1/proxy/: foo (200; 3.659537ms)
Dec 13 19:16:49.414: INFO: (7) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname2/proxy/: bar (200; 4.793105ms)
Dec 13 19:16:49.414: INFO: (7) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 4.095731ms)
Dec 13 19:16:49.414: INFO: (7) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 4.21545ms)
Dec 13 19:16:49.414: INFO: (7) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname2/proxy/: tls qux (200; 4.659148ms)
Dec 13 19:16:49.414: INFO: (7) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">test<... (200; 5.177705ms)
Dec 13 19:16:49.415: INFO: (7) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname1/proxy/: foo (200; 5.099354ms)
Dec 13 19:16:49.415: INFO: (7) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname1/proxy/: tls baz (200; 4.721851ms)
Dec 13 19:16:49.415: INFO: (7) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">... (200; 4.668597ms)
Dec 13 19:16:49.422: INFO: (7) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 11.963443ms)
Dec 13 19:16:49.422: INFO: (7) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname2/proxy/: bar (200; 13.194705ms)
Dec 13 19:16:49.427: INFO: (8) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 4.426705ms)
Dec 13 19:16:49.427: INFO: (8) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:460/proxy/: tls baz (200; 4.711599ms)
Dec 13 19:16:49.427: INFO: (8) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">test<... (200; 5.01296ms)
Dec 13 19:16:49.428: INFO: (8) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname2/proxy/: bar (200; 5.441802ms)
Dec 13 19:16:49.428: INFO: (8) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 5.717357ms)
Dec 13 19:16:49.428: INFO: (8) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">... (200; 5.706481ms)
Dec 13 19:16:49.428: INFO: (8) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname2/proxy/: tls qux (200; 5.702331ms)
Dec 13 19:16:49.428: INFO: (8) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 5.648162ms)
Dec 13 19:16:49.428: INFO: (8) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:462/proxy/: tls qux (200; 5.937619ms)
Dec 13 19:16:49.429: INFO: (8) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/tlsrewritem... (200; 6.183823ms)
Dec 13 19:16:49.433: INFO: (8) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname1/proxy/: foo (200; 10.75461ms)
Dec 13 19:16:49.433: INFO: (8) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname2/proxy/: bar (200; 11.003143ms)
Dec 13 19:16:49.434: INFO: (8) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname1/proxy/: foo (200; 11.180125ms)
Dec 13 19:16:49.434: INFO: (8) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/rewriteme">test</a> (200; 11.254047ms)
Dec 13 19:16:49.434: INFO: (8) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 11.293898ms)
Dec 13 19:16:49.434: INFO: (8) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname1/proxy/: tls baz (200; 11.419079ms)
Dec 13 19:16:49.439: INFO: (9) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/rewriteme">test</a> (200; 4.16677ms)
Dec 13 19:16:49.439: INFO: (9) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">... (200; 5.026894ms)
Dec 13 19:16:49.440: INFO: (9) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/tlsrewritem... (200; 4.885126ms)
Dec 13 19:16:49.440: INFO: (9) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:460/proxy/: tls baz (200; 4.313354ms)
Dec 13 19:16:49.440: INFO: (9) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:462/proxy/: tls qux (200; 4.286313ms)
Dec 13 19:16:49.440: INFO: (9) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">test<... (200; 4.627985ms)
Dec 13 19:16:49.440: INFO: (9) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 5.375382ms)
Dec 13 19:16:49.440: INFO: (9) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 5.200381ms)
Dec 13 19:16:49.440: INFO: (9) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 5.638193ms)
Dec 13 19:16:49.440: INFO: (9) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 5.345172ms)
Dec 13 19:16:49.442: INFO: (9) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname1/proxy/: foo (200; 7.582904ms)
Dec 13 19:16:49.442: INFO: (9) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname1/proxy/: tls baz (200; 8.388459ms)
Dec 13 19:16:49.442: INFO: (9) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname2/proxy/: tls qux (200; 7.336736ms)
Dec 13 19:16:49.443: INFO: (9) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname1/proxy/: foo (200; 7.876559ms)
Dec 13 19:16:49.443: INFO: (9) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname2/proxy/: bar (200; 8.550326ms)
Dec 13 19:16:49.443: INFO: (9) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname2/proxy/: bar (200; 8.119886ms)
Dec 13 19:16:49.446: INFO: (10) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">... (200; 2.932412ms)
Dec 13 19:16:49.450: INFO: (10) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/tlsrewritem... (200; 6.18862ms)
Dec 13 19:16:49.450: INFO: (10) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">test<... (200; 6.335894ms)
Dec 13 19:16:49.450: INFO: (10) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 6.770542ms)
Dec 13 19:16:49.451: INFO: (10) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 7.957186ms)
Dec 13 19:16:49.451: INFO: (10) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:462/proxy/: tls qux (200; 6.989208ms)
Dec 13 19:16:49.451: INFO: (10) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname1/proxy/: foo (200; 7.250477ms)
Dec 13 19:16:49.452: INFO: (10) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname2/proxy/: bar (200; 7.784824ms)
Dec 13 19:16:49.452: INFO: (10) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname1/proxy/: tls baz (200; 8.500836ms)
Dec 13 19:16:49.452: INFO: (10) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/rewriteme">test</a> (200; 7.521118ms)
Dec 13 19:16:49.452: INFO: (10) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:460/proxy/: tls baz (200; 7.455888ms)
Dec 13 19:16:49.452: INFO: (10) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname1/proxy/: foo (200; 7.987588ms)
Dec 13 19:16:49.452: INFO: (10) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 8.321263ms)
Dec 13 19:16:49.452: INFO: (10) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname2/proxy/: bar (200; 8.099027ms)
Dec 13 19:16:49.452: INFO: (10) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 8.201687ms)
Dec 13 19:16:49.452: INFO: (10) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname2/proxy/: tls qux (200; 8.733394ms)
Dec 13 19:16:49.455: INFO: (11) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 2.958774ms)
Dec 13 19:16:49.455: INFO: (11) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 2.719906ms)
Dec 13 19:16:49.456: INFO: (11) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">test<... (200; 2.570892ms)
Dec 13 19:16:49.456: INFO: (11) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/rewriteme">test</a> (200; 2.576884ms)
Dec 13 19:16:49.456: INFO: (11) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 3.197611ms)
Dec 13 19:16:49.456: INFO: (11) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/tlsrewritem... (200; 3.089539ms)
Dec 13 19:16:49.456: INFO: (11) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">... (200; 3.370795ms)
Dec 13 19:16:49.456: INFO: (11) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:462/proxy/: tls qux (200; 2.597026ms)
Dec 13 19:16:49.456: INFO: (11) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:460/proxy/: tls baz (200; 2.708467ms)
Dec 13 19:16:49.456: INFO: (11) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname1/proxy/: tls baz (200; 3.788521ms)
Dec 13 19:16:49.456: INFO: (11) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 3.705086ms)
Dec 13 19:16:49.457: INFO: (11) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname1/proxy/: foo (200; 3.765327ms)
Dec 13 19:16:49.457: INFO: (11) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname2/proxy/: tls qux (200; 3.713568ms)
Dec 13 19:16:49.457: INFO: (11) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname2/proxy/: bar (200; 4.498965ms)
Dec 13 19:16:49.457: INFO: (11) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname2/proxy/: bar (200; 4.188497ms)
Dec 13 19:16:49.457: INFO: (11) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname1/proxy/: foo (200; 4.283028ms)
Dec 13 19:16:49.459: INFO: (12) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:460/proxy/: tls baz (200; 1.879837ms)
Dec 13 19:16:49.459: INFO: (12) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 2.009076ms)
Dec 13 19:16:49.460: INFO: (12) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/tlsrewritem... (200; 2.303913ms)
Dec 13 19:16:49.460: INFO: (12) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname1/proxy/: tls baz (200; 3.120848ms)
Dec 13 19:16:49.461: INFO: (12) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">... (200; 2.993186ms)
Dec 13 19:16:49.461: INFO: (12) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/rewriteme">test</a> (200; 2.685135ms)
Dec 13 19:16:49.461: INFO: (12) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">test<... (200; 3.497087ms)
Dec 13 19:16:49.461: INFO: (12) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 3.843248ms)
Dec 13 19:16:49.461: INFO: (12) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname2/proxy/: bar (200; 3.742159ms)
Dec 13 19:16:49.461: INFO: (12) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 3.701123ms)
Dec 13 19:16:49.462: INFO: (12) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:462/proxy/: tls qux (200; 3.696671ms)
Dec 13 19:16:49.462: INFO: (12) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname1/proxy/: foo (200; 4.221336ms)
Dec 13 19:16:49.462: INFO: (12) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 4.709852ms)
Dec 13 19:16:49.462: INFO: (12) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname2/proxy/: tls qux (200; 4.015928ms)
Dec 13 19:16:49.463: INFO: (12) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname1/proxy/: foo (200; 4.71676ms)
Dec 13 19:16:49.463: INFO: (12) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname2/proxy/: bar (200; 4.730768ms)
Dec 13 19:16:49.466: INFO: (13) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:462/proxy/: tls qux (200; 2.531085ms)
Dec 13 19:16:49.466: INFO: (13) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname2/proxy/: bar (200; 3.370871ms)
Dec 13 19:16:49.467: INFO: (13) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:460/proxy/: tls baz (200; 3.326295ms)
Dec 13 19:16:49.467: INFO: (13) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 3.124086ms)
Dec 13 19:16:49.467: INFO: (13) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 3.028512ms)
Dec 13 19:16:49.467: INFO: (13) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 3.353114ms)
Dec 13 19:16:49.467: INFO: (13) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">... (200; 3.901885ms)
Dec 13 19:16:49.468: INFO: (13) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">test<... (200; 4.431408ms)
Dec 13 19:16:49.468: INFO: (13) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 3.88439ms)
Dec 13 19:16:49.468: INFO: (13) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname1/proxy/: foo (200; 4.634516ms)
Dec 13 19:16:49.468: INFO: (13) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname2/proxy/: tls qux (200; 4.100218ms)
Dec 13 19:16:49.468: INFO: (13) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/rewriteme">test</a> (200; 4.302604ms)
Dec 13 19:16:49.468: INFO: (13) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname1/proxy/: tls baz (200; 4.074336ms)
Dec 13 19:16:49.468: INFO: (13) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname1/proxy/: foo (200; 4.925269ms)
Dec 13 19:16:49.468: INFO: (13) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname2/proxy/: bar (200; 5.408354ms)
Dec 13 19:16:49.468: INFO: (13) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/tlsrewritem... (200; 5.286983ms)
Dec 13 19:16:49.472: INFO: (14) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 3.769043ms)
Dec 13 19:16:49.473: INFO: (14) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 3.914099ms)
Dec 13 19:16:49.474: INFO: (14) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname1/proxy/: foo (200; 5.557039ms)
Dec 13 19:16:49.474: INFO: (14) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 4.909622ms)
Dec 13 19:16:49.474: INFO: (14) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">test<... (200; 5.736776ms)
Dec 13 19:16:49.474: INFO: (14) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 4.965967ms)
Dec 13 19:16:49.474: INFO: (14) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/tlsrewritem... (200; 5.728442ms)
Dec 13 19:16:49.474: INFO: (14) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:460/proxy/: tls baz (200; 5.193593ms)
Dec 13 19:16:49.474: INFO: (14) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname2/proxy/: tls qux (200; 5.349844ms)
Dec 13 19:16:49.474: INFO: (14) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname1/proxy/: tls baz (200; 5.140868ms)
Dec 13 19:16:49.474: INFO: (14) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">... (200; 4.762472ms)
Dec 13 19:16:49.475: INFO: (14) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:462/proxy/: tls qux (200; 5.587748ms)
Dec 13 19:16:49.475: INFO: (14) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname2/proxy/: bar (200; 6.003931ms)
Dec 13 19:16:49.475: INFO: (14) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/rewriteme">test</a> (200; 5.765067ms)
Dec 13 19:16:49.475: INFO: (14) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname2/proxy/: bar (200; 5.727ms)
Dec 13 19:16:49.475: INFO: (14) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname1/proxy/: foo (200; 6.58554ms)
Dec 13 19:16:49.478: INFO: (15) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/tlsrewritem... (200; 2.159396ms)
Dec 13 19:16:49.478: INFO: (15) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:460/proxy/: tls baz (200; 1.90055ms)
Dec 13 19:16:49.478: INFO: (15) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:462/proxy/: tls qux (200; 1.881198ms)
Dec 13 19:16:49.478: INFO: (15) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname2/proxy/: tls qux (200; 2.807156ms)
Dec 13 19:16:49.479: INFO: (15) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/rewriteme">test</a> (200; 3.490101ms)
Dec 13 19:16:49.479: INFO: (15) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname1/proxy/: tls baz (200; 3.413095ms)
Dec 13 19:16:49.479: INFO: (15) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 3.296797ms)
Dec 13 19:16:49.479: INFO: (15) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 3.333976ms)
Dec 13 19:16:49.480: INFO: (15) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname1/proxy/: foo (200; 3.979785ms)
Dec 13 19:16:49.480: INFO: (15) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 4.059798ms)
Dec 13 19:16:49.480: INFO: (15) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">test<... (200; 4.124746ms)
Dec 13 19:16:49.481: INFO: (15) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 4.402409ms)
Dec 13 19:16:49.481: INFO: (15) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname2/proxy/: bar (200; 4.477788ms)
Dec 13 19:16:49.481: INFO: (15) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">... (200; 4.46118ms)
Dec 13 19:16:49.481: INFO: (15) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname1/proxy/: foo (200; 5.122889ms)
Dec 13 19:16:49.481: INFO: (15) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname2/proxy/: bar (200; 5.175819ms)
Dec 13 19:16:49.484: INFO: (16) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">test<... (200; 2.302632ms)
Dec 13 19:16:49.484: INFO: (16) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 2.440557ms)
Dec 13 19:16:49.484: INFO: (16) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 1.607915ms)
Dec 13 19:16:49.484: INFO: (16) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:460/proxy/: tls baz (200; 1.94018ms)
Dec 13 19:16:49.484: INFO: (16) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/tlsrewritem... (200; 2.832656ms)
Dec 13 19:16:49.484: INFO: (16) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 2.087661ms)
Dec 13 19:16:49.485: INFO: (16) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:462/proxy/: tls qux (200; 2.754602ms)
Dec 13 19:16:49.485: INFO: (16) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 2.321661ms)
Dec 13 19:16:49.485: INFO: (16) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">... (200; 2.536821ms)
Dec 13 19:16:49.485: INFO: (16) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/rewriteme">test</a> (200; 3.245846ms)
Dec 13 19:16:49.486: INFO: (16) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname2/proxy/: bar (200; 4.512745ms)
Dec 13 19:16:49.486: INFO: (16) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname1/proxy/: tls baz (200; 4.140096ms)
Dec 13 19:16:49.487: INFO: (16) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname1/proxy/: foo (200; 5.052947ms)
Dec 13 19:16:49.487: INFO: (16) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname1/proxy/: foo (200; 5.038288ms)
Dec 13 19:16:49.487: INFO: (16) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname2/proxy/: tls qux (200; 4.891235ms)
Dec 13 19:16:49.487: INFO: (16) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname2/proxy/: bar (200; 4.504755ms)
Dec 13 19:16:49.490: INFO: (17) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname1/proxy/: tls baz (200; 2.947014ms)
Dec 13 19:16:49.490: INFO: (17) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 2.939676ms)
Dec 13 19:16:49.491: INFO: (17) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">... (200; 3.092292ms)
Dec 13 19:16:49.491: INFO: (17) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 3.218348ms)
Dec 13 19:16:49.491: INFO: (17) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 3.558163ms)
Dec 13 19:16:49.491: INFO: (17) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname2/proxy/: bar (200; 3.89632ms)
Dec 13 19:16:49.492: INFO: (17) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 4.032326ms)
Dec 13 19:16:49.493: INFO: (17) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/tlsrewritem... (200; 4.872486ms)
Dec 13 19:16:49.493: INFO: (17) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:460/proxy/: tls baz (200; 5.14707ms)
Dec 13 19:16:49.493: INFO: (17) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname2/proxy/: bar (200; 5.582313ms)
Dec 13 19:16:49.493: INFO: (17) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/rewriteme">test</a> (200; 5.316165ms)
Dec 13 19:16:49.493: INFO: (17) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname2/proxy/: tls qux (200; 5.330403ms)
Dec 13 19:16:49.494: INFO: (17) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:462/proxy/: tls qux (200; 6.696879ms)
Dec 13 19:16:49.494: INFO: (17) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">test<... (200; 5.988896ms)
Dec 13 19:16:49.494: INFO: (17) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname1/proxy/: foo (200; 6.474562ms)
Dec 13 19:16:49.494: INFO: (17) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname1/proxy/: foo (200; 6.552847ms)
Dec 13 19:16:49.498: INFO: (18) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:460/proxy/: tls baz (200; 3.590543ms)
Dec 13 19:16:49.498: INFO: (18) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:462/proxy/: tls qux (200; 3.784656ms)
Dec 13 19:16:49.499: INFO: (18) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 3.919371ms)
Dec 13 19:16:49.499: INFO: (18) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 3.898384ms)
Dec 13 19:16:49.499: INFO: (18) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">test<... (200; 4.016969ms)
Dec 13 19:16:49.499: INFO: (18) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/rewriteme">test</a> (200; 4.451426ms)
Dec 13 19:16:49.500: INFO: (18) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 4.554936ms)
Dec 13 19:16:49.500: INFO: (18) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/tlsrewritem... (200; 4.375625ms)
Dec 13 19:16:49.500: INFO: (18) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 4.74113ms)
Dec 13 19:16:49.500: INFO: (18) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname2/proxy/: bar (200; 5.14519ms)
Dec 13 19:16:49.501: INFO: (18) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname2/proxy/: tls qux (200; 5.949093ms)
Dec 13 19:16:49.501: INFO: (18) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">... (200; 5.538332ms)
Dec 13 19:16:49.501: INFO: (18) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname1/proxy/: foo (200; 6.290654ms)
Dec 13 19:16:49.501: INFO: (18) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname2/proxy/: bar (200; 5.587761ms)
Dec 13 19:16:49.501: INFO: (18) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname1/proxy/: foo (200; 5.51987ms)
Dec 13 19:16:49.501: INFO: (18) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname1/proxy/: tls baz (200; 6.083043ms)
Dec 13 19:16:49.505: INFO: (19) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:443/proxy/tlsrewritem... (200; 3.967973ms)
Dec 13 19:16:49.505: INFO: (19) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 3.852385ms)
Dec 13 19:16:49.505: INFO: (19) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 3.840062ms)
Dec 13 19:16:49.505: INFO: (19) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2/proxy/rewriteme">test</a> (200; 4.249775ms)
Dec 13 19:16:49.505: INFO: (19) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:460/proxy/: tls baz (200; 4.227179ms)
Dec 13 19:16:49.505: INFO: (19) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">test<... (200; 4.111053ms)
Dec 13 19:16:49.505: INFO: (19) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/: <a href="/api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:1080/proxy/rewriteme">... (200; 3.948889ms)
Dec 13 19:16:49.505: INFO: (19) /api/v1/namespaces/proxy-1267/pods/proxy-service-d77s9-6vqw2:160/proxy/: foo (200; 4.091186ms)
Dec 13 19:16:49.506: INFO: (19) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname1/proxy/: foo (200; 5.383653ms)
Dec 13 19:16:49.506: INFO: (19) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname2/proxy/: bar (200; 5.248944ms)
Dec 13 19:16:49.506: INFO: (19) /api/v1/namespaces/proxy-1267/services/proxy-service-d77s9:portname2/proxy/: bar (200; 5.510701ms)
Dec 13 19:16:49.507: INFO: (19) /api/v1/namespaces/proxy-1267/services/http:proxy-service-d77s9:portname1/proxy/: foo (200; 5.328584ms)
Dec 13 19:16:49.507: INFO: (19) /api/v1/namespaces/proxy-1267/pods/http:proxy-service-d77s9-6vqw2:162/proxy/: bar (200; 5.066965ms)
Dec 13 19:16:49.507: INFO: (19) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname1/proxy/: tls baz (200; 5.140023ms)
Dec 13 19:16:49.507: INFO: (19) /api/v1/namespaces/proxy-1267/services/https:proxy-service-d77s9:tlsportname2/proxy/: tls qux (200; 5.215012ms)
Dec 13 19:16:49.507: INFO: (19) /api/v1/namespaces/proxy-1267/pods/https:proxy-service-d77s9-6vqw2:462/proxy/: tls qux (200; 5.769652ms)
STEP: deleting ReplicationController proxy-service-d77s9 in namespace proxy-1267, will wait for the garbage collector to delete the pods
Dec 13 19:16:49.562: INFO: Deleting ReplicationController proxy-service-d77s9 took: 3.225733ms
Dec 13 19:16:49.862: INFO: Terminating ReplicationController proxy-service-d77s9 pods took: 300.287758ms
[AfterEach] version v1
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:16:53.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1267" for this suite.
Dec 13 19:16:59.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:16:59.411: INFO: namespace proxy-1267 deletion completed in 6.047016713s

• [SLOW TEST:25.178 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:16:59.411: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 13 19:16:59.434: INFO: Waiting up to 5m0s for pod "pod-21b37759-9f50-4001-865c-2e82a4b17aa7" in namespace "emptydir-6500" to be "success or failure"
Dec 13 19:16:59.435: INFO: Pod "pod-21b37759-9f50-4001-865c-2e82a4b17aa7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.522518ms
Dec 13 19:17:01.437: INFO: Pod "pod-21b37759-9f50-4001-865c-2e82a4b17aa7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003611896s
Dec 13 19:17:03.440: INFO: Pod "pod-21b37759-9f50-4001-865c-2e82a4b17aa7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005690771s
Dec 13 19:17:05.442: INFO: Pod "pod-21b37759-9f50-4001-865c-2e82a4b17aa7": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007966167s
Dec 13 19:17:07.444: INFO: Pod "pod-21b37759-9f50-4001-865c-2e82a4b17aa7": Phase="Pending", Reason="", readiness=false. Elapsed: 8.010085092s
Dec 13 19:17:09.446: INFO: Pod "pod-21b37759-9f50-4001-865c-2e82a4b17aa7": Phase="Pending", Reason="", readiness=false. Elapsed: 10.012137508s
Dec 13 19:17:11.448: INFO: Pod "pod-21b37759-9f50-4001-865c-2e82a4b17aa7": Phase="Pending", Reason="", readiness=false. Elapsed: 12.014322193s
Dec 13 19:17:13.451: INFO: Pod "pod-21b37759-9f50-4001-865c-2e82a4b17aa7": Phase="Pending", Reason="", readiness=false. Elapsed: 14.016636338s
Dec 13 19:17:15.453: INFO: Pod "pod-21b37759-9f50-4001-865c-2e82a4b17aa7": Phase="Pending", Reason="", readiness=false. Elapsed: 16.018634996s
Dec 13 19:17:17.455: INFO: Pod "pod-21b37759-9f50-4001-865c-2e82a4b17aa7": Phase="Pending", Reason="", readiness=false. Elapsed: 18.020729995s
Dec 13 19:17:19.457: INFO: Pod "pod-21b37759-9f50-4001-865c-2e82a4b17aa7": Phase="Pending", Reason="", readiness=false. Elapsed: 20.023159591s
Dec 13 19:17:21.459: INFO: Pod "pod-21b37759-9f50-4001-865c-2e82a4b17aa7": Phase="Pending", Reason="", readiness=false. Elapsed: 22.02553014s
Dec 13 19:17:23.461: INFO: Pod "pod-21b37759-9f50-4001-865c-2e82a4b17aa7": Phase="Pending", Reason="", readiness=false. Elapsed: 24.027552256s
Dec 13 19:17:25.463: INFO: Pod "pod-21b37759-9f50-4001-865c-2e82a4b17aa7": Phase="Pending", Reason="", readiness=false. Elapsed: 26.029554474s
Dec 13 19:17:27.466: INFO: Pod "pod-21b37759-9f50-4001-865c-2e82a4b17aa7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.031630707s
STEP: Saw pod success
Dec 13 19:17:27.466: INFO: Pod "pod-21b37759-9f50-4001-865c-2e82a4b17aa7" satisfied condition "success or failure"
Dec 13 19:17:27.467: INFO: Trying to get logs from node 172.160.134.166 pod pod-21b37759-9f50-4001-865c-2e82a4b17aa7 container test-container: <nil>
STEP: delete the pod
Dec 13 19:17:27.492: INFO: Waiting for pod pod-21b37759-9f50-4001-865c-2e82a4b17aa7 to disappear
Dec 13 19:17:27.497: INFO: Pod pod-21b37759-9f50-4001-865c-2e82a4b17aa7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:17:27.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6500" for this suite.
Dec 13 19:17:33.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:17:33.550: INFO: namespace emptydir-6500 deletion completed in 6.051655623s

• [SLOW TEST:34.138 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:17:33.551: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 13 19:17:33.576: INFO: Waiting up to 5m0s for pod "pod-ed78af3d-f829-4f38-a71f-5403ce1c0ca4" in namespace "emptydir-319" to be "success or failure"
Dec 13 19:17:33.577: INFO: Pod "pod-ed78af3d-f829-4f38-a71f-5403ce1c0ca4": Phase="Pending", Reason="", readiness=false. Elapsed: 1.408968ms
Dec 13 19:17:35.580: INFO: Pod "pod-ed78af3d-f829-4f38-a71f-5403ce1c0ca4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003541779s
Dec 13 19:17:37.582: INFO: Pod "pod-ed78af3d-f829-4f38-a71f-5403ce1c0ca4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005890299s
Dec 13 19:17:39.584: INFO: Pod "pod-ed78af3d-f829-4f38-a71f-5403ce1c0ca4": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007856616s
Dec 13 19:17:41.586: INFO: Pod "pod-ed78af3d-f829-4f38-a71f-5403ce1c0ca4": Phase="Pending", Reason="", readiness=false. Elapsed: 8.010053261s
Dec 13 19:17:43.588: INFO: Pod "pod-ed78af3d-f829-4f38-a71f-5403ce1c0ca4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.012175349s
Dec 13 19:17:45.590: INFO: Pod "pod-ed78af3d-f829-4f38-a71f-5403ce1c0ca4": Phase="Pending", Reason="", readiness=false. Elapsed: 12.014334666s
Dec 13 19:17:47.592: INFO: Pod "pod-ed78af3d-f829-4f38-a71f-5403ce1c0ca4": Phase="Pending", Reason="", readiness=false. Elapsed: 14.016428968s
Dec 13 19:17:49.595: INFO: Pod "pod-ed78af3d-f829-4f38-a71f-5403ce1c0ca4": Phase="Pending", Reason="", readiness=false. Elapsed: 16.018538857s
Dec 13 19:17:51.597: INFO: Pod "pod-ed78af3d-f829-4f38-a71f-5403ce1c0ca4": Phase="Pending", Reason="", readiness=false. Elapsed: 18.0207616s
Dec 13 19:17:53.599: INFO: Pod "pod-ed78af3d-f829-4f38-a71f-5403ce1c0ca4": Phase="Pending", Reason="", readiness=false. Elapsed: 20.023060924s
Dec 13 19:17:55.601: INFO: Pod "pod-ed78af3d-f829-4f38-a71f-5403ce1c0ca4": Phase="Pending", Reason="", readiness=false. Elapsed: 22.025258292s
Dec 13 19:17:57.603: INFO: Pod "pod-ed78af3d-f829-4f38-a71f-5403ce1c0ca4": Phase="Pending", Reason="", readiness=false. Elapsed: 24.027319381s
Dec 13 19:17:59.606: INFO: Pod "pod-ed78af3d-f829-4f38-a71f-5403ce1c0ca4": Phase="Pending", Reason="", readiness=false. Elapsed: 26.029677804s
Dec 13 19:18:01.608: INFO: Pod "pod-ed78af3d-f829-4f38-a71f-5403ce1c0ca4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.032168352s
STEP: Saw pod success
Dec 13 19:18:01.608: INFO: Pod "pod-ed78af3d-f829-4f38-a71f-5403ce1c0ca4" satisfied condition "success or failure"
Dec 13 19:18:01.610: INFO: Trying to get logs from node 172.160.134.166 pod pod-ed78af3d-f829-4f38-a71f-5403ce1c0ca4 container test-container: <nil>
STEP: delete the pod
Dec 13 19:18:01.628: INFO: Waiting for pod pod-ed78af3d-f829-4f38-a71f-5403ce1c0ca4 to disappear
Dec 13 19:18:01.629: INFO: Pod pod-ed78af3d-f829-4f38-a71f-5403ce1c0ca4 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:18:01.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-319" for this suite.
Dec 13 19:18:07.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:18:07.678: INFO: namespace emptydir-319 deletion completed in 6.046848615s

• [SLOW TEST:34.127 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:18:07.678: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 13 19:18:07.701: INFO: Waiting up to 5m0s for pod "pod-346c7f01-afbb-40f2-a176-1ec9044ffadf" in namespace "emptydir-3530" to be "success or failure"
Dec 13 19:18:07.703: INFO: Pod "pod-346c7f01-afbb-40f2-a176-1ec9044ffadf": Phase="Pending", Reason="", readiness=false. Elapsed: 1.5264ms
Dec 13 19:18:09.705: INFO: Pod "pod-346c7f01-afbb-40f2-a176-1ec9044ffadf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003684686s
Dec 13 19:18:11.707: INFO: Pod "pod-346c7f01-afbb-40f2-a176-1ec9044ffadf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005975946s
Dec 13 19:18:13.710: INFO: Pod "pod-346c7f01-afbb-40f2-a176-1ec9044ffadf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008125287s
Dec 13 19:18:15.712: INFO: Pod "pod-346c7f01-afbb-40f2-a176-1ec9044ffadf": Phase="Pending", Reason="", readiness=false. Elapsed: 8.010458287s
Dec 13 19:18:17.714: INFO: Pod "pod-346c7f01-afbb-40f2-a176-1ec9044ffadf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.012530058s
Dec 13 19:18:19.716: INFO: Pod "pod-346c7f01-afbb-40f2-a176-1ec9044ffadf": Phase="Pending", Reason="", readiness=false. Elapsed: 12.014619112s
Dec 13 19:18:21.718: INFO: Pod "pod-346c7f01-afbb-40f2-a176-1ec9044ffadf": Phase="Pending", Reason="", readiness=false. Elapsed: 14.016845821s
Dec 13 19:18:23.720: INFO: Pod "pod-346c7f01-afbb-40f2-a176-1ec9044ffadf": Phase="Pending", Reason="", readiness=false. Elapsed: 16.019094463s
Dec 13 19:18:25.722: INFO: Pod "pod-346c7f01-afbb-40f2-a176-1ec9044ffadf": Phase="Pending", Reason="", readiness=false. Elapsed: 18.020919248s
Dec 13 19:18:27.725: INFO: Pod "pod-346c7f01-afbb-40f2-a176-1ec9044ffadf": Phase="Pending", Reason="", readiness=false. Elapsed: 20.023136202s
Dec 13 19:18:29.727: INFO: Pod "pod-346c7f01-afbb-40f2-a176-1ec9044ffadf": Phase="Pending", Reason="", readiness=false. Elapsed: 22.025213861s
Dec 13 19:18:31.728: INFO: Pod "pod-346c7f01-afbb-40f2-a176-1ec9044ffadf": Phase="Pending", Reason="", readiness=false. Elapsed: 24.027059822s
Dec 13 19:18:33.731: INFO: Pod "pod-346c7f01-afbb-40f2-a176-1ec9044ffadf": Phase="Running", Reason="", readiness=true. Elapsed: 26.029320972s
Dec 13 19:18:35.733: INFO: Pod "pod-346c7f01-afbb-40f2-a176-1ec9044ffadf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.03137909s
STEP: Saw pod success
Dec 13 19:18:35.733: INFO: Pod "pod-346c7f01-afbb-40f2-a176-1ec9044ffadf" satisfied condition "success or failure"
Dec 13 19:18:35.734: INFO: Trying to get logs from node 172.160.134.166 pod pod-346c7f01-afbb-40f2-a176-1ec9044ffadf container test-container: <nil>
STEP: delete the pod
Dec 13 19:18:35.748: INFO: Waiting for pod pod-346c7f01-afbb-40f2-a176-1ec9044ffadf to disappear
Dec 13 19:18:35.762: INFO: Pod pod-346c7f01-afbb-40f2-a176-1ec9044ffadf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:18:35.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3530" for this suite.
Dec 13 19:18:41.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:18:41.811: INFO: namespace emptydir-3530 deletion completed in 6.048026127s

• [SLOW TEST:34.133 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:18:41.813: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 19:18:41.841: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-e220b235-ad7e-4cbd-8fad-a8cb33b27984" in namespace "security-context-test-397" to be "success or failure"
Dec 13 19:18:41.843: INFO: Pod "alpine-nnp-false-e220b235-ad7e-4cbd-8fad-a8cb33b27984": Phase="Pending", Reason="", readiness=false. Elapsed: 1.462706ms
Dec 13 19:18:43.845: INFO: Pod "alpine-nnp-false-e220b235-ad7e-4cbd-8fad-a8cb33b27984": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003682205s
Dec 13 19:18:45.847: INFO: Pod "alpine-nnp-false-e220b235-ad7e-4cbd-8fad-a8cb33b27984": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005861715s
Dec 13 19:18:47.849: INFO: Pod "alpine-nnp-false-e220b235-ad7e-4cbd-8fad-a8cb33b27984": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007918473s
Dec 13 19:18:49.852: INFO: Pod "alpine-nnp-false-e220b235-ad7e-4cbd-8fad-a8cb33b27984": Phase="Pending", Reason="", readiness=false. Elapsed: 8.010247741s
Dec 13 19:18:51.854: INFO: Pod "alpine-nnp-false-e220b235-ad7e-4cbd-8fad-a8cb33b27984": Phase="Pending", Reason="", readiness=false. Elapsed: 10.012550721s
Dec 13 19:18:53.867: INFO: Pod "alpine-nnp-false-e220b235-ad7e-4cbd-8fad-a8cb33b27984": Phase="Succeeded", Reason="", readiness=false. Elapsed: 12.025786597s
Dec 13 19:18:53.867: INFO: Pod "alpine-nnp-false-e220b235-ad7e-4cbd-8fad-a8cb33b27984" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:18:53.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-397" for this suite.
Dec 13 19:18:59.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:18:59.938: INFO: namespace security-context-test-397 deletion completed in 6.04960264s

• [SLOW TEST:18.125 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:18:59.938: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Dec 13 19:18:59.961: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec 13 19:18:59.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 create -f - --namespace=kubectl-2718'
Dec 13 19:19:00.264: INFO: stderr: ""
Dec 13 19:19:00.264: INFO: stdout: "service/redis-slave created\n"
Dec 13 19:19:00.264: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec 13 19:19:00.264: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 create -f - --namespace=kubectl-2718'
Dec 13 19:19:00.506: INFO: stderr: ""
Dec 13 19:19:00.506: INFO: stdout: "service/redis-master created\n"
Dec 13 19:19:00.506: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec 13 19:19:00.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 create -f - --namespace=kubectl-2718'
Dec 13 19:19:00.736: INFO: stderr: ""
Dec 13 19:19:00.736: INFO: stdout: "service/frontend created\n"
Dec 13 19:19:00.736: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec 13 19:19:00.736: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 create -f - --namespace=kubectl-2718'
Dec 13 19:19:00.961: INFO: stderr: ""
Dec 13 19:19:00.961: INFO: stdout: "deployment.apps/frontend created\n"
Dec 13 19:19:00.961: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 13 19:19:00.961: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 create -f - --namespace=kubectl-2718'
Dec 13 19:19:01.186: INFO: stderr: ""
Dec 13 19:19:01.186: INFO: stdout: "deployment.apps/redis-master created\n"
Dec 13 19:19:01.186: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec 13 19:19:01.186: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 create -f - --namespace=kubectl-2718'
Dec 13 19:19:01.424: INFO: stderr: ""
Dec 13 19:19:01.424: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Dec 13 19:19:01.424: INFO: Waiting for all frontend pods to be Running.
Dec 13 19:19:11.475: INFO: Waiting for frontend to serve content.
Dec 13 19:19:11.494: INFO: Trying to add a new entry to the guestbook.
Dec 13 19:19:11.506: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec 13 19:19:11.531: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 delete --grace-period=0 --force -f - --namespace=kubectl-2718'
Dec 13 19:19:11.647: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 13 19:19:11.647: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec 13 19:19:11.647: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 delete --grace-period=0 --force -f - --namespace=kubectl-2718'
Dec 13 19:19:11.764: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 13 19:19:11.764: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 13 19:19:11.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 delete --grace-period=0 --force -f - --namespace=kubectl-2718'
Dec 13 19:19:11.891: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 13 19:19:11.891: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 13 19:19:11.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 delete --grace-period=0 --force -f - --namespace=kubectl-2718'
Dec 13 19:19:11.996: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 13 19:19:11.996: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 13 19:19:11.996: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 delete --grace-period=0 --force -f - --namespace=kubectl-2718'
Dec 13 19:19:12.096: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 13 19:19:12.096: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 13 19:19:12.096: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 delete --grace-period=0 --force -f - --namespace=kubectl-2718'
Dec 13 19:19:12.201: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 13 19:19:12.201: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:19:12.201: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2718" for this suite.
Dec 13 19:19:40.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:19:40.250: INFO: namespace kubectl-2718 deletion completed in 28.046414073s

• [SLOW TEST:40.312 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:19:40.250: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4692.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4692.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4692.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4692.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4692.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4692.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4692.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4692.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4692.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4692.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4692.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4692.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4692.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 112.32.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.32.112_udp@PTR;check="$$(dig +tcp +noall +answer +search 112.32.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.32.112_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4692.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4692.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4692.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4692.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4692.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4692.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4692.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4692.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4692.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4692.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4692.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4692.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4692.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 112.32.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.32.112_udp@PTR;check="$$(dig +tcp +noall +answer +search 112.32.254.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.254.32.112_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 13 19:20:10.302: INFO: Unable to read wheezy_udp@dns-test-service.dns-4692.svc.cluster.local from pod dns-4692/dns-test-d3c3c4df-a5e7-45cf-9b34-5f7adccaee12: the server could not find the requested resource (get pods dns-test-d3c3c4df-a5e7-45cf-9b34-5f7adccaee12)
Dec 13 19:20:10.307: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4692.svc.cluster.local from pod dns-4692/dns-test-d3c3c4df-a5e7-45cf-9b34-5f7adccaee12: the server could not find the requested resource (get pods dns-test-d3c3c4df-a5e7-45cf-9b34-5f7adccaee12)
Dec 13 19:20:10.319: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4692.svc.cluster.local from pod dns-4692/dns-test-d3c3c4df-a5e7-45cf-9b34-5f7adccaee12: the server could not find the requested resource (get pods dns-test-d3c3c4df-a5e7-45cf-9b34-5f7adccaee12)
Dec 13 19:20:10.321: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4692.svc.cluster.local from pod dns-4692/dns-test-d3c3c4df-a5e7-45cf-9b34-5f7adccaee12: the server could not find the requested resource (get pods dns-test-d3c3c4df-a5e7-45cf-9b34-5f7adccaee12)
Dec 13 19:20:10.357: INFO: Unable to read jessie_udp@dns-test-service.dns-4692.svc.cluster.local from pod dns-4692/dns-test-d3c3c4df-a5e7-45cf-9b34-5f7adccaee12: the server could not find the requested resource (get pods dns-test-d3c3c4df-a5e7-45cf-9b34-5f7adccaee12)
Dec 13 19:20:10.361: INFO: Unable to read jessie_tcp@dns-test-service.dns-4692.svc.cluster.local from pod dns-4692/dns-test-d3c3c4df-a5e7-45cf-9b34-5f7adccaee12: the server could not find the requested resource (get pods dns-test-d3c3c4df-a5e7-45cf-9b34-5f7adccaee12)
Dec 13 19:20:10.363: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4692.svc.cluster.local from pod dns-4692/dns-test-d3c3c4df-a5e7-45cf-9b34-5f7adccaee12: the server could not find the requested resource (get pods dns-test-d3c3c4df-a5e7-45cf-9b34-5f7adccaee12)
Dec 13 19:20:10.368: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4692.svc.cluster.local from pod dns-4692/dns-test-d3c3c4df-a5e7-45cf-9b34-5f7adccaee12: the server could not find the requested resource (get pods dns-test-d3c3c4df-a5e7-45cf-9b34-5f7adccaee12)
Dec 13 19:20:10.398: INFO: Lookups using dns-4692/dns-test-d3c3c4df-a5e7-45cf-9b34-5f7adccaee12 failed for: [wheezy_udp@dns-test-service.dns-4692.svc.cluster.local wheezy_tcp@dns-test-service.dns-4692.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4692.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4692.svc.cluster.local jessie_udp@dns-test-service.dns-4692.svc.cluster.local jessie_tcp@dns-test-service.dns-4692.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4692.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4692.svc.cluster.local]

Dec 13 19:20:15.453: INFO: DNS probes using dns-4692/dns-test-d3c3c4df-a5e7-45cf-9b34-5f7adccaee12 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:20:15.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4692" for this suite.
Dec 13 19:20:21.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:20:21.560: INFO: namespace dns-4692 deletion completed in 6.048390669s

• [SLOW TEST:41.310 seconds]
[sig-network] DNS
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:20:21.560: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 13 19:20:22.176: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 13 19:20:24.182: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861622, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861622, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861622, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861622, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:20:26.184: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861622, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861622, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861622, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861622, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:20:28.184: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861622, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861622, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861622, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861622, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 13 19:20:31.191: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:20:31.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6135" for this suite.
Dec 13 19:20:37.360: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:20:37.400: INFO: namespace webhook-6135 deletion completed in 6.04528981s
STEP: Destroying namespace "webhook-6135-markers" for this suite.
Dec 13 19:20:43.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:20:43.450: INFO: namespace webhook-6135-markers deletion completed in 6.050327467s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.897 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:20:43.458: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Dec 13 19:21:11.497: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec pod-sharedvolume-9123bc1b-2bec-4774-907b-c9867ddb2d47 -c busybox-main-container --namespace=emptydir-6766 -- cat /usr/share/volumeshare/shareddata.txt'
Dec 13 19:21:11.763: INFO: stderr: ""
Dec 13 19:21:11.763: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:21:11.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6766" for this suite.
Dec 13 19:21:17.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:21:17.811: INFO: namespace emptydir-6766 deletion completed in 6.045904815s

• [SLOW TEST:34.354 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:21:17.812: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 13 19:21:17.836: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f54387f2-086c-4931-a146-a1655f7b45e7" in namespace "downward-api-5009" to be "success or failure"
Dec 13 19:21:17.838: INFO: Pod "downwardapi-volume-f54387f2-086c-4931-a146-a1655f7b45e7": Phase="Pending", Reason="", readiness=false. Elapsed: 1.988902ms
Dec 13 19:21:19.840: INFO: Pod "downwardapi-volume-f54387f2-086c-4931-a146-a1655f7b45e7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004198586s
Dec 13 19:21:21.843: INFO: Pod "downwardapi-volume-f54387f2-086c-4931-a146-a1655f7b45e7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006606653s
Dec 13 19:21:23.845: INFO: Pod "downwardapi-volume-f54387f2-086c-4931-a146-a1655f7b45e7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008742083s
STEP: Saw pod success
Dec 13 19:21:23.845: INFO: Pod "downwardapi-volume-f54387f2-086c-4931-a146-a1655f7b45e7" satisfied condition "success or failure"
Dec 13 19:21:23.846: INFO: Trying to get logs from node 172.160.134.165 pod downwardapi-volume-f54387f2-086c-4931-a146-a1655f7b45e7 container client-container: <nil>
STEP: delete the pod
Dec 13 19:21:23.870: INFO: Waiting for pod downwardapi-volume-f54387f2-086c-4931-a146-a1655f7b45e7 to disappear
Dec 13 19:21:23.873: INFO: Pod downwardapi-volume-f54387f2-086c-4931-a146-a1655f7b45e7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:21:23.873: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5009" for this suite.
Dec 13 19:21:29.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:21:29.926: INFO: namespace downward-api-5009 deletion completed in 6.05139118s

• [SLOW TEST:12.115 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:21:29.927: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 13 19:21:29.950: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:21:38.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4120" for this suite.
Dec 13 19:21:44.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:21:44.591: INFO: namespace init-container-4120 deletion completed in 6.047511236s

• [SLOW TEST:14.665 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:21:44.591: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 19:21:44.612: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec 13 19:21:44.618: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 13 19:21:49.620: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 13 19:21:51.626: INFO: Creating deployment "test-rolling-update-deployment"
Dec 13 19:21:51.629: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec 13 19:21:51.633: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec 13 19:21:53.637: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec 13 19:21:53.638: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861711, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861711, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861711, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861711, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:21:55.641: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861711, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861711, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861711, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861711, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:21:57.640: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 13 19:21:57.645: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-4653 /apis/apps/v1/namespaces/deployment-4653/deployments/test-rolling-update-deployment 1b6231eb-f3f6-40a3-9417-aea63036c883 129964 1 2019-12-13 19:21:51 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0059851c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-13 19:21:51 +0000 UTC,LastTransitionTime:2019-12-13 19:21:51 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2019-12-13 19:21:56 +0000 UTC,LastTransitionTime:2019-12-13 19:21:51 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 13 19:21:57.648: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-4653 /apis/apps/v1/namespaces/deployment-4653/replicasets/test-rolling-update-deployment-55d946486 aa344f7e-f358-4843-bb27-d6dd24fcefd3 129953 1 2019-12-13 19:21:51 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 1b6231eb-f3f6-40a3-9417-aea63036c883 0xc005985720 0xc005985721}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005985788 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 13 19:21:57.648: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec 13 19:21:57.648: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-4653 /apis/apps/v1/namespaces/deployment-4653/replicasets/test-rolling-update-controller d7f53afd-0688-4c4e-b21d-9e170fef21f8 129962 2 2019-12-13 19:21:44 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 1b6231eb-f3f6-40a3-9417-aea63036c883 0xc005985627 0xc005985628}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc005985688 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 13 19:21:57.650: INFO: Pod "test-rolling-update-deployment-55d946486-4cjfb" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-4cjfb test-rolling-update-deployment-55d946486- deployment-4653 /api/v1/namespaces/deployment-4653/pods/test-rolling-update-deployment-55d946486-4cjfb 4593bfae-9093-4f39-ba25-f3295f7724c3 129952 0 2019-12-13 19:21:51 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 aa344f7e-f358-4843-bb27-d6dd24fcefd3 0xc007dc54d0 0xc007dc54d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-ljc5x,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-ljc5x,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-ljc5x,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 19:21:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 19:21:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 19:21:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 19:21:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.160.134.165,PodIP:172.160.134.158,StartTime:2019-12-13 19:21:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-13 19:21:56 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://b3210dfadb11d72d2daabc3c4c14853a6111ce7149cd00683d38bf00078b6d30,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.160.134.158,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:21:57.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4653" for this suite.
Dec 13 19:22:03.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:22:03.703: INFO: namespace deployment-4653 deletion completed in 6.051111251s

• [SLOW TEST:19.111 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:22:03.703: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 13 19:22:03.727: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cf8e25fc-cdc7-4556-bccc-af619568a3d8" in namespace "downward-api-5854" to be "success or failure"
Dec 13 19:22:03.730: INFO: Pod "downwardapi-volume-cf8e25fc-cdc7-4556-bccc-af619568a3d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.269007ms
Dec 13 19:22:05.732: INFO: Pod "downwardapi-volume-cf8e25fc-cdc7-4556-bccc-af619568a3d8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004494485s
Dec 13 19:22:07.734: INFO: Pod "downwardapi-volume-cf8e25fc-cdc7-4556-bccc-af619568a3d8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006726063s
Dec 13 19:22:09.737: INFO: Pod "downwardapi-volume-cf8e25fc-cdc7-4556-bccc-af619568a3d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009157646s
STEP: Saw pod success
Dec 13 19:22:09.737: INFO: Pod "downwardapi-volume-cf8e25fc-cdc7-4556-bccc-af619568a3d8" satisfied condition "success or failure"
Dec 13 19:22:09.738: INFO: Trying to get logs from node 172.160.134.165 pod downwardapi-volume-cf8e25fc-cdc7-4556-bccc-af619568a3d8 container client-container: <nil>
STEP: delete the pod
Dec 13 19:22:09.752: INFO: Waiting for pod downwardapi-volume-cf8e25fc-cdc7-4556-bccc-af619568a3d8 to disappear
Dec 13 19:22:09.755: INFO: Pod downwardapi-volume-cf8e25fc-cdc7-4556-bccc-af619568a3d8 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:22:09.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5854" for this suite.
Dec 13 19:22:15.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:22:15.808: INFO: namespace downward-api-5854 deletion completed in 6.050530013s

• [SLOW TEST:12.105 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:22:15.808: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 13 19:22:16.777: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Dec 13 19:22:18.782: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861736, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861736, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861736, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861736, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:22:20.784: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861736, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861736, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861736, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861736, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:22:22.784: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861736, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861736, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861736, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861736, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 13 19:22:25.792: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 19:22:25.795: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6032-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:22:26.906: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9250" for this suite.
Dec 13 19:22:32.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:22:32.956: INFO: namespace webhook-9250 deletion completed in 6.04767472s
STEP: Destroying namespace "webhook-9250-markers" for this suite.
Dec 13 19:22:38.963: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:22:39.001: INFO: namespace webhook-9250-markers deletion completed in 6.044924109s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:23.199 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:22:39.007: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-df6e1cee-f78a-4d07-b23b-3e019823b007
STEP: Creating a pod to test consume secrets
Dec 13 19:22:39.054: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e92c5ee2-343d-4aa0-bea6-9a4a82ca3e92" in namespace "projected-7488" to be "success or failure"
Dec 13 19:22:39.056: INFO: Pod "pod-projected-secrets-e92c5ee2-343d-4aa0-bea6-9a4a82ca3e92": Phase="Pending", Reason="", readiness=false. Elapsed: 1.476217ms
Dec 13 19:22:41.058: INFO: Pod "pod-projected-secrets-e92c5ee2-343d-4aa0-bea6-9a4a82ca3e92": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003635239s
Dec 13 19:22:43.060: INFO: Pod "pod-projected-secrets-e92c5ee2-343d-4aa0-bea6-9a4a82ca3e92": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006023786s
Dec 13 19:22:45.062: INFO: Pod "pod-projected-secrets-e92c5ee2-343d-4aa0-bea6-9a4a82ca3e92": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008315477s
STEP: Saw pod success
Dec 13 19:22:45.062: INFO: Pod "pod-projected-secrets-e92c5ee2-343d-4aa0-bea6-9a4a82ca3e92" satisfied condition "success or failure"
Dec 13 19:22:45.064: INFO: Trying to get logs from node 172.160.134.165 pod pod-projected-secrets-e92c5ee2-343d-4aa0-bea6-9a4a82ca3e92 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 13 19:22:45.078: INFO: Waiting for pod pod-projected-secrets-e92c5ee2-343d-4aa0-bea6-9a4a82ca3e92 to disappear
Dec 13 19:22:45.082: INFO: Pod pod-projected-secrets-e92c5ee2-343d-4aa0-bea6-9a4a82ca3e92 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:22:45.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7488" for this suite.
Dec 13 19:22:51.090: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:22:51.134: INFO: namespace projected-7488 deletion completed in 6.049322804s

• [SLOW TEST:12.127 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:22:51.134: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 13 19:22:51.843: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 13 19:22:53.849: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861771, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861771, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861771, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861771, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:22:55.851: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861771, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861771, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861771, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861771, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 13 19:22:58.856: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:22:58.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4277" for this suite.
Dec 13 19:23:04.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:23:04.982: INFO: namespace webhook-4277 deletion completed in 6.048884408s
STEP: Destroying namespace "webhook-4277-markers" for this suite.
Dec 13 19:23:10.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:23:11.026: INFO: namespace webhook-4277-markers deletion completed in 6.044581464s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.898 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:23:11.032: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 13 19:23:11.805: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 13 19:23:13.810: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861791, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861791, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861791, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861791, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:23:15.812: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861791, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861791, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861791, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861791, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:23:17.812: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861791, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861791, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861791, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711861791, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 13 19:23:20.818: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:23:30.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4380" for this suite.
Dec 13 19:23:36.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:23:36.987: INFO: namespace webhook-4380 deletion completed in 6.048237767s
STEP: Destroying namespace "webhook-4380-markers" for this suite.
Dec 13 19:23:42.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:23:43.035: INFO: namespace webhook-4380-markers deletion completed in 6.047573763s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:32.008 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:23:43.041: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec 13 19:23:43.069: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 create -f - --namespace=kubectl-2185'
Dec 13 19:23:43.294: INFO: stderr: ""
Dec 13 19:23:43.294: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 13 19:23:43.294: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2185'
Dec 13 19:23:43.404: INFO: stderr: ""
Dec 13 19:23:43.404: INFO: stdout: "update-demo-nautilus-46cp6 update-demo-nautilus-m9tzg "
Dec 13 19:23:43.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-46cp6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2185'
Dec 13 19:23:43.510: INFO: stderr: ""
Dec 13 19:23:43.510: INFO: stdout: ""
Dec 13 19:23:43.510: INFO: update-demo-nautilus-46cp6 is created but not running
Dec 13 19:23:48.510: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2185'
Dec 13 19:23:48.619: INFO: stderr: ""
Dec 13 19:23:48.619: INFO: stdout: "update-demo-nautilus-46cp6 update-demo-nautilus-m9tzg "
Dec 13 19:23:48.619: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-46cp6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2185'
Dec 13 19:23:48.723: INFO: stderr: ""
Dec 13 19:23:48.723: INFO: stdout: ""
Dec 13 19:23:48.723: INFO: update-demo-nautilus-46cp6 is created but not running
Dec 13 19:23:53.723: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2185'
Dec 13 19:23:53.838: INFO: stderr: ""
Dec 13 19:23:53.838: INFO: stdout: "update-demo-nautilus-46cp6 update-demo-nautilus-m9tzg "
Dec 13 19:23:53.838: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-46cp6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2185'
Dec 13 19:23:53.944: INFO: stderr: ""
Dec 13 19:23:53.944: INFO: stdout: "true"
Dec 13 19:23:53.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-46cp6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2185'
Dec 13 19:23:54.056: INFO: stderr: ""
Dec 13 19:23:54.056: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 13 19:23:54.056: INFO: validating pod update-demo-nautilus-46cp6
Dec 13 19:23:54.130: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 13 19:23:54.130: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 13 19:23:54.130: INFO: update-demo-nautilus-46cp6 is verified up and running
Dec 13 19:23:54.130: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-m9tzg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2185'
Dec 13 19:23:54.247: INFO: stderr: ""
Dec 13 19:23:54.247: INFO: stdout: "true"
Dec 13 19:23:54.247: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-m9tzg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2185'
Dec 13 19:23:54.354: INFO: stderr: ""
Dec 13 19:23:54.354: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 13 19:23:54.354: INFO: validating pod update-demo-nautilus-m9tzg
Dec 13 19:23:54.358: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 13 19:23:54.358: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 13 19:23:54.358: INFO: update-demo-nautilus-m9tzg is verified up and running
STEP: scaling down the replication controller
Dec 13 19:23:54.361: INFO: scanned /root for discovery docs: <nil>
Dec 13 19:23:54.361: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-2185'
Dec 13 19:23:55.492: INFO: stderr: ""
Dec 13 19:23:55.492: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 13 19:23:55.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2185'
Dec 13 19:23:55.600: INFO: stderr: ""
Dec 13 19:23:55.600: INFO: stdout: "update-demo-nautilus-46cp6 update-demo-nautilus-m9tzg "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 13 19:24:00.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2185'
Dec 13 19:24:00.708: INFO: stderr: ""
Dec 13 19:24:00.708: INFO: stdout: "update-demo-nautilus-m9tzg "
Dec 13 19:24:00.708: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-m9tzg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2185'
Dec 13 19:24:00.816: INFO: stderr: ""
Dec 13 19:24:00.816: INFO: stdout: "true"
Dec 13 19:24:00.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-m9tzg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2185'
Dec 13 19:24:00.921: INFO: stderr: ""
Dec 13 19:24:00.921: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 13 19:24:00.921: INFO: validating pod update-demo-nautilus-m9tzg
Dec 13 19:24:00.923: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 13 19:24:00.923: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 13 19:24:00.923: INFO: update-demo-nautilus-m9tzg is verified up and running
STEP: scaling up the replication controller
Dec 13 19:24:00.925: INFO: scanned /root for discovery docs: <nil>
Dec 13 19:24:00.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-2185'
Dec 13 19:24:02.051: INFO: stderr: ""
Dec 13 19:24:02.051: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 13 19:24:02.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2185'
Dec 13 19:24:02.161: INFO: stderr: ""
Dec 13 19:24:02.161: INFO: stdout: "update-demo-nautilus-m9tzg update-demo-nautilus-xmn24 "
Dec 13 19:24:02.161: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-m9tzg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2185'
Dec 13 19:24:02.266: INFO: stderr: ""
Dec 13 19:24:02.267: INFO: stdout: "true"
Dec 13 19:24:02.267: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-m9tzg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2185'
Dec 13 19:24:02.374: INFO: stderr: ""
Dec 13 19:24:02.374: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 13 19:24:02.374: INFO: validating pod update-demo-nautilus-m9tzg
Dec 13 19:24:02.376: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 13 19:24:02.376: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 13 19:24:02.376: INFO: update-demo-nautilus-m9tzg is verified up and running
Dec 13 19:24:02.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-xmn24 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2185'
Dec 13 19:24:02.483: INFO: stderr: ""
Dec 13 19:24:02.483: INFO: stdout: ""
Dec 13 19:24:02.483: INFO: update-demo-nautilus-xmn24 is created but not running
Dec 13 19:24:07.483: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-2185'
Dec 13 19:24:07.594: INFO: stderr: ""
Dec 13 19:24:07.594: INFO: stdout: "update-demo-nautilus-m9tzg update-demo-nautilus-xmn24 "
Dec 13 19:24:07.594: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-m9tzg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2185'
Dec 13 19:24:07.696: INFO: stderr: ""
Dec 13 19:24:07.696: INFO: stdout: "true"
Dec 13 19:24:07.696: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-m9tzg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2185'
Dec 13 19:24:07.798: INFO: stderr: ""
Dec 13 19:24:07.798: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 13 19:24:07.798: INFO: validating pod update-demo-nautilus-m9tzg
Dec 13 19:24:07.800: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 13 19:24:07.800: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 13 19:24:07.800: INFO: update-demo-nautilus-m9tzg is verified up and running
Dec 13 19:24:07.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-xmn24 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-2185'
Dec 13 19:24:07.902: INFO: stderr: ""
Dec 13 19:24:07.902: INFO: stdout: "true"
Dec 13 19:24:07.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods update-demo-nautilus-xmn24 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-2185'
Dec 13 19:24:08.014: INFO: stderr: ""
Dec 13 19:24:08.014: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 13 19:24:08.014: INFO: validating pod update-demo-nautilus-xmn24
Dec 13 19:24:08.020: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 13 19:24:08.020: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 13 19:24:08.020: INFO: update-demo-nautilus-xmn24 is verified up and running
STEP: using delete to clean up resources
Dec 13 19:24:08.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 delete --grace-period=0 --force -f - --namespace=kubectl-2185'
Dec 13 19:24:08.126: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 13 19:24:08.126: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 13 19:24:08.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2185'
Dec 13 19:24:08.235: INFO: stderr: "No resources found in kubectl-2185 namespace.\n"
Dec 13 19:24:08.235: INFO: stdout: ""
Dec 13 19:24:08.235: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods -l name=update-demo --namespace=kubectl-2185 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 13 19:24:08.346: INFO: stderr: ""
Dec 13 19:24:08.346: INFO: stdout: "update-demo-nautilus-m9tzg\nupdate-demo-nautilus-xmn24\n"
Dec 13 19:24:08.846: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-2185'
Dec 13 19:24:08.956: INFO: stderr: "No resources found in kubectl-2185 namespace.\n"
Dec 13 19:24:08.956: INFO: stdout: ""
Dec 13 19:24:08.956: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods -l name=update-demo --namespace=kubectl-2185 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 13 19:24:09.064: INFO: stderr: ""
Dec 13 19:24:09.064: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:24:09.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2185" for this suite.
Dec 13 19:24:15.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:24:15.117: INFO: namespace kubectl-2185 deletion completed in 6.050377883s

• [SLOW TEST:32.076 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:24:15.117: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-792f052a-4183-49be-a3b7-071738d2d126 in namespace container-probe-2256
Dec 13 19:24:21.168: INFO: Started pod liveness-792f052a-4183-49be-a3b7-071738d2d126 in namespace container-probe-2256
STEP: checking the pod's current state and verifying that restartCount is present
Dec 13 19:24:21.170: INFO: Initial restart count of pod liveness-792f052a-4183-49be-a3b7-071738d2d126 is 0
Dec 13 19:24:45.198: INFO: Restart count of pod container-probe-2256/liveness-792f052a-4183-49be-a3b7-071738d2d126 is now 1 (24.028233887s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:24:45.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2256" for this suite.
Dec 13 19:24:51.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:24:51.255: INFO: namespace container-probe-2256 deletion completed in 6.045591534s

• [SLOW TEST:36.139 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:24:51.256: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 13 19:24:51.280: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1fbb8ece-daa9-4ce6-bd55-18283877ee6b" in namespace "downward-api-6521" to be "success or failure"
Dec 13 19:24:51.282: INFO: Pod "downwardapi-volume-1fbb8ece-daa9-4ce6-bd55-18283877ee6b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.533285ms
Dec 13 19:24:53.285: INFO: Pod "downwardapi-volume-1fbb8ece-daa9-4ce6-bd55-18283877ee6b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004790555s
Dec 13 19:24:55.287: INFO: Pod "downwardapi-volume-1fbb8ece-daa9-4ce6-bd55-18283877ee6b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007200672s
Dec 13 19:24:57.290: INFO: Pod "downwardapi-volume-1fbb8ece-daa9-4ce6-bd55-18283877ee6b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010565988s
STEP: Saw pod success
Dec 13 19:24:57.290: INFO: Pod "downwardapi-volume-1fbb8ece-daa9-4ce6-bd55-18283877ee6b" satisfied condition "success or failure"
Dec 13 19:24:57.292: INFO: Trying to get logs from node 172.160.134.165 pod downwardapi-volume-1fbb8ece-daa9-4ce6-bd55-18283877ee6b container client-container: <nil>
STEP: delete the pod
Dec 13 19:24:57.314: INFO: Waiting for pod downwardapi-volume-1fbb8ece-daa9-4ce6-bd55-18283877ee6b to disappear
Dec 13 19:24:57.317: INFO: Pod downwardapi-volume-1fbb8ece-daa9-4ce6-bd55-18283877ee6b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:24:57.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6521" for this suite.
Dec 13 19:25:03.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:25:03.368: INFO: namespace downward-api-6521 deletion completed in 6.04883658s

• [SLOW TEST:12.113 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:25:03.369: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-5755
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-5755
I1213 19:25:03.410339      25 runners.go:184] Created replication controller with name: externalname-service, namespace: services-5755, replica count: 2
I1213 19:25:06.460697      25 runners.go:184] externalname-service Pods: 2 out of 2 created, 0 running, 2 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1213 19:25:09.461011      25 runners.go:184] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 13 19:25:12.461: INFO: Creating new exec pod
I1213 19:25:12.461334      25 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 13 19:25:21.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=services-5755 execpodv95tp -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec 13 19:25:22.222: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 13 19:25:22.222: INFO: stdout: ""
Dec 13 19:25:22.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=services-5755 execpodv95tp -- /bin/sh -x -c nc -zv -t -w 2 10.254.31.210 80'
Dec 13 19:25:22.710: INFO: stderr: "+ nc -zv -t -w 2 10.254.31.210 80\nConnection to 10.254.31.210 80 port [tcp/http] succeeded!\n"
Dec 13 19:25:22.710: INFO: stdout: ""
Dec 13 19:25:22.710: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=services-5755 execpodv95tp -- /bin/sh -x -c nc -zv -t -w 2 172.160.134.165 30366'
Dec 13 19:25:23.282: INFO: stderr: "+ nc -zv -t -w 2 172.160.134.165 30366\nConnection to 172.160.134.165 30366 port [tcp/30366] succeeded!\n"
Dec 13 19:25:23.282: INFO: stdout: ""
Dec 13 19:25:23.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=services-5755 execpodv95tp -- /bin/sh -x -c nc -zv -t -w 2 172.160.134.166 30366'
Dec 13 19:25:23.699: INFO: stderr: "+ nc -zv -t -w 2 172.160.134.166 30366\nConnection to 172.160.134.166 30366 port [tcp/30366] succeeded!\n"
Dec 13 19:25:23.699: INFO: stdout: ""
Dec 13 19:25:23.699: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:25:23.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5755" for this suite.
Dec 13 19:25:29.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:25:29.761: INFO: namespace services-5755 deletion completed in 6.045846981s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:26.392 seconds]
[sig-network] Services
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:25:29.761: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 13 19:25:29.787: INFO: Waiting up to 5m0s for pod "pod-41f22310-84c4-43a1-9435-1d708f3c91f9" in namespace "emptydir-9784" to be "success or failure"
Dec 13 19:25:29.789: INFO: Pod "pod-41f22310-84c4-43a1-9435-1d708f3c91f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.334014ms
Dec 13 19:25:31.791: INFO: Pod "pod-41f22310-84c4-43a1-9435-1d708f3c91f9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004478329s
Dec 13 19:25:33.794: INFO: Pod "pod-41f22310-84c4-43a1-9435-1d708f3c91f9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006729174s
Dec 13 19:25:35.796: INFO: Pod "pod-41f22310-84c4-43a1-9435-1d708f3c91f9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008867867s
Dec 13 19:25:37.798: INFO: Pod "pod-41f22310-84c4-43a1-9435-1d708f3c91f9": Phase="Pending", Reason="", readiness=false. Elapsed: 8.010739907s
Dec 13 19:25:39.800: INFO: Pod "pod-41f22310-84c4-43a1-9435-1d708f3c91f9": Phase="Pending", Reason="", readiness=false. Elapsed: 10.012757432s
Dec 13 19:25:41.802: INFO: Pod "pod-41f22310-84c4-43a1-9435-1d708f3c91f9": Phase="Pending", Reason="", readiness=false. Elapsed: 12.014675992s
Dec 13 19:25:43.804: INFO: Pod "pod-41f22310-84c4-43a1-9435-1d708f3c91f9": Phase="Pending", Reason="", readiness=false. Elapsed: 14.016891955s
Dec 13 19:25:45.806: INFO: Pod "pod-41f22310-84c4-43a1-9435-1d708f3c91f9": Phase="Pending", Reason="", readiness=false. Elapsed: 16.018991686s
Dec 13 19:25:47.808: INFO: Pod "pod-41f22310-84c4-43a1-9435-1d708f3c91f9": Phase="Pending", Reason="", readiness=false. Elapsed: 18.020798213s
Dec 13 19:25:49.810: INFO: Pod "pod-41f22310-84c4-43a1-9435-1d708f3c91f9": Phase="Pending", Reason="", readiness=false. Elapsed: 20.022900664s
Dec 13 19:25:51.812: INFO: Pod "pod-41f22310-84c4-43a1-9435-1d708f3c91f9": Phase="Pending", Reason="", readiness=false. Elapsed: 22.025001925s
Dec 13 19:25:53.814: INFO: Pod "pod-41f22310-84c4-43a1-9435-1d708f3c91f9": Phase="Pending", Reason="", readiness=false. Elapsed: 24.026852996s
Dec 13 19:25:55.816: INFO: Pod "pod-41f22310-84c4-43a1-9435-1d708f3c91f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.029040788s
STEP: Saw pod success
Dec 13 19:25:55.816: INFO: Pod "pod-41f22310-84c4-43a1-9435-1d708f3c91f9" satisfied condition "success or failure"
Dec 13 19:25:55.817: INFO: Trying to get logs from node 172.160.134.165 pod pod-41f22310-84c4-43a1-9435-1d708f3c91f9 container test-container: <nil>
STEP: delete the pod
Dec 13 19:25:55.828: INFO: Waiting for pod pod-41f22310-84c4-43a1-9435-1d708f3c91f9 to disappear
Dec 13 19:25:55.831: INFO: Pod pod-41f22310-84c4-43a1-9435-1d708f3c91f9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:25:55.831: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9784" for this suite.
Dec 13 19:26:01.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:26:01.883: INFO: namespace emptydir-9784 deletion completed in 6.050227162s

• [SLOW TEST:32.122 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:26:01.883: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 13 19:26:08.430: INFO: Successfully updated pod "pod-update-activedeadlineseconds-b038575e-7553-46f4-9338-8c11d39aeaac"
Dec 13 19:26:08.430: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-b038575e-7553-46f4-9338-8c11d39aeaac" in namespace "pods-9063" to be "terminated due to deadline exceeded"
Dec 13 19:26:08.432: INFO: Pod "pod-update-activedeadlineseconds-b038575e-7553-46f4-9338-8c11d39aeaac": Phase="Running", Reason="", readiness=true. Elapsed: 1.535276ms
Dec 13 19:26:10.434: INFO: Pod "pod-update-activedeadlineseconds-b038575e-7553-46f4-9338-8c11d39aeaac": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.003793907s
Dec 13 19:26:10.434: INFO: Pod "pod-update-activedeadlineseconds-b038575e-7553-46f4-9338-8c11d39aeaac" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:26:10.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9063" for this suite.
Dec 13 19:26:16.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:26:16.485: INFO: namespace pods-9063 deletion completed in 6.049260796s

• [SLOW TEST:14.602 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:26:16.485: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 19:26:16.515: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-ee11d392-fe03-44c7-878c-444bdf5a6fbb" in namespace "security-context-test-282" to be "success or failure"
Dec 13 19:26:16.521: INFO: Pod "busybox-readonly-false-ee11d392-fe03-44c7-878c-444bdf5a6fbb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.936123ms
Dec 13 19:26:18.523: INFO: Pod "busybox-readonly-false-ee11d392-fe03-44c7-878c-444bdf5a6fbb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00813053s
Dec 13 19:26:20.526: INFO: Pod "busybox-readonly-false-ee11d392-fe03-44c7-878c-444bdf5a6fbb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010290823s
Dec 13 19:26:22.528: INFO: Pod "busybox-readonly-false-ee11d392-fe03-44c7-878c-444bdf5a6fbb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01227064s
Dec 13 19:26:24.530: INFO: Pod "busybox-readonly-false-ee11d392-fe03-44c7-878c-444bdf5a6fbb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.014581674s
Dec 13 19:26:24.530: INFO: Pod "busybox-readonly-false-ee11d392-fe03-44c7-878c-444bdf5a6fbb" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:26:24.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-282" for this suite.
Dec 13 19:26:30.539: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:26:30.579: INFO: namespace security-context-test-282 deletion completed in 6.046848722s

• [SLOW TEST:14.093 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:26:30.579: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Dec 13 19:26:38.610: INFO: Pod pod-hostip-debcc9ba-37c4-43dc-9be6-9a1f33d8e23a has hostIP: 172.160.134.166
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:26:38.610: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9529" for this suite.
Dec 13 19:26:50.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:26:50.659: INFO: namespace pods-9529 deletion completed in 12.047465463s

• [SLOW TEST:20.080 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:26:50.659: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec 13 19:26:50.697: INFO: Pod name pod-release: Found 0 pods out of 1
Dec 13 19:26:55.713: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:26:56.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2804" for this suite.
Dec 13 19:27:02.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:27:02.773: INFO: namespace replication-controller-2804 deletion completed in 6.048410397s

• [SLOW TEST:12.113 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:27:02.773: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 13 19:27:02.801: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:27:12.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4214" for this suite.
Dec 13 19:27:24.275: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:27:24.314: INFO: namespace init-container-4214 deletion completed in 12.045051687s

• [SLOW TEST:21.541 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:27:24.314: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 13 19:27:25.221: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 13 19:27:27.227: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862045, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862045, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862045, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862045, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:27:29.229: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862045, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862045, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862045, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862045, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:27:31.229: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862045, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862045, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862045, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862045, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 13 19:27:34.245: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 19:27:34.247: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7876-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:27:35.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8439" for this suite.
Dec 13 19:27:41.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:27:41.521: INFO: namespace webhook-8439 deletion completed in 6.048312042s
STEP: Destroying namespace "webhook-8439-markers" for this suite.
Dec 13 19:27:47.527: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:27:47.570: INFO: namespace webhook-8439-markers deletion completed in 6.049338576s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:23.263 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:27:47.577: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:27:47.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-291" for this suite.
Dec 13 19:27:53.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:27:53.650: INFO: namespace custom-resource-definition-291 deletion completed in 6.045805018s

• [SLOW TEST:6.073 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:27:53.650: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Dec 13 19:27:53.677: INFO: Waiting up to 5m0s for pod "var-expansion-11aebbe1-53c3-4e05-a803-0954047691b8" in namespace "var-expansion-1342" to be "success or failure"
Dec 13 19:27:53.679: INFO: Pod "var-expansion-11aebbe1-53c3-4e05-a803-0954047691b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.727447ms
Dec 13 19:27:55.681: INFO: Pod "var-expansion-11aebbe1-53c3-4e05-a803-0954047691b8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004708371s
Dec 13 19:27:57.684: INFO: Pod "var-expansion-11aebbe1-53c3-4e05-a803-0954047691b8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007300896s
Dec 13 19:27:59.686: INFO: Pod "var-expansion-11aebbe1-53c3-4e05-a803-0954047691b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009609497s
STEP: Saw pod success
Dec 13 19:27:59.686: INFO: Pod "var-expansion-11aebbe1-53c3-4e05-a803-0954047691b8" satisfied condition "success or failure"
Dec 13 19:27:59.688: INFO: Trying to get logs from node 172.160.134.165 pod var-expansion-11aebbe1-53c3-4e05-a803-0954047691b8 container dapi-container: <nil>
STEP: delete the pod
Dec 13 19:27:59.715: INFO: Waiting for pod var-expansion-11aebbe1-53c3-4e05-a803-0954047691b8 to disappear
Dec 13 19:27:59.717: INFO: Pod var-expansion-11aebbe1-53c3-4e05-a803-0954047691b8 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:27:59.717: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1342" for this suite.
Dec 13 19:28:05.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:28:05.768: INFO: namespace var-expansion-1342 deletion completed in 6.049388127s

• [SLOW TEST:12.118 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:28:05.768: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec 13 19:28:05.792: INFO: namespace kubectl-1890
Dec 13 19:28:05.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 create -f - --namespace=kubectl-1890'
Dec 13 19:28:06.079: INFO: stderr: ""
Dec 13 19:28:06.079: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 13 19:28:07.082: INFO: Selector matched 1 pods for map[app:redis]
Dec 13 19:28:07.082: INFO: Found 0 / 1
Dec 13 19:28:08.082: INFO: Selector matched 1 pods for map[app:redis]
Dec 13 19:28:08.082: INFO: Found 0 / 1
Dec 13 19:28:09.082: INFO: Selector matched 1 pods for map[app:redis]
Dec 13 19:28:09.082: INFO: Found 0 / 1
Dec 13 19:28:10.081: INFO: Selector matched 1 pods for map[app:redis]
Dec 13 19:28:10.081: INFO: Found 0 / 1
Dec 13 19:28:11.082: INFO: Selector matched 1 pods for map[app:redis]
Dec 13 19:28:11.082: INFO: Found 0 / 1
Dec 13 19:28:12.082: INFO: Selector matched 1 pods for map[app:redis]
Dec 13 19:28:12.082: INFO: Found 1 / 1
Dec 13 19:28:12.082: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 13 19:28:12.083: INFO: Selector matched 1 pods for map[app:redis]
Dec 13 19:28:12.083: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 13 19:28:12.083: INFO: wait on redis-master startup in kubectl-1890 
Dec 13 19:28:12.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 logs redis-master-zpkp6 redis-master --namespace=kubectl-1890'
Dec 13 19:28:12.216: INFO: stderr: ""
Dec 13 19:28:12.216: INFO: stdout: "1:C 13 Dec 2019 19:28:11.514 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 13 Dec 2019 19:28:11.514 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 13 Dec 2019 19:28:11.514 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 13 Dec 2019 19:28:11.516 * Running mode=standalone, port=6379.\n1:M 13 Dec 2019 19:28:11.516 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 13 Dec 2019 19:28:11.516 # Server initialized\n1:M 13 Dec 2019 19:28:11.516 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 13 Dec 2019 19:28:11.516 * Ready to accept connections\n"
STEP: exposing RC
Dec 13 19:28:12.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-1890'
Dec 13 19:28:12.342: INFO: stderr: ""
Dec 13 19:28:12.342: INFO: stdout: "service/rm2 exposed\n"
Dec 13 19:28:12.344: INFO: Service rm2 in namespace kubectl-1890 found.
STEP: exposing service
Dec 13 19:28:14.347: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-1890'
Dec 13 19:28:14.460: INFO: stderr: ""
Dec 13 19:28:14.460: INFO: stdout: "service/rm3 exposed\n"
Dec 13 19:28:14.463: INFO: Service rm3 in namespace kubectl-1890 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:28:16.466: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1890" for this suite.
Dec 13 19:28:28.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:28:28.517: INFO: namespace kubectl-1890 deletion completed in 12.04896948s

• [SLOW TEST:22.748 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:28:28.517: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-dv2z
STEP: Creating a pod to test atomic-volume-subpath
Dec 13 19:28:28.546: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-dv2z" in namespace "subpath-1317" to be "success or failure"
Dec 13 19:28:28.550: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Pending", Reason="", readiness=false. Elapsed: 3.726024ms
Dec 13 19:28:30.552: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005853765s
Dec 13 19:28:32.554: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008028947s
Dec 13 19:28:34.556: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Pending", Reason="", readiness=false. Elapsed: 6.010129728s
Dec 13 19:28:36.559: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012456531s
Dec 13 19:28:38.561: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Pending", Reason="", readiness=false. Elapsed: 10.014847744s
Dec 13 19:28:40.563: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Pending", Reason="", readiness=false. Elapsed: 12.017294589s
Dec 13 19:28:42.566: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Pending", Reason="", readiness=false. Elapsed: 14.019533753s
Dec 13 19:28:44.568: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Pending", Reason="", readiness=false. Elapsed: 16.021639375s
Dec 13 19:28:46.570: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Pending", Reason="", readiness=false. Elapsed: 18.023765353s
Dec 13 19:28:48.572: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Pending", Reason="", readiness=false. Elapsed: 20.025982274s
Dec 13 19:28:50.574: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Pending", Reason="", readiness=false. Elapsed: 22.02817973s
Dec 13 19:28:52.577: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Pending", Reason="", readiness=false. Elapsed: 24.030427802s
Dec 13 19:28:54.579: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Pending", Reason="", readiness=false. Elapsed: 26.03242317s
Dec 13 19:28:56.581: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Running", Reason="", readiness=true. Elapsed: 28.034461593s
Dec 13 19:28:58.583: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Running", Reason="", readiness=true. Elapsed: 30.036518241s
Dec 13 19:29:00.585: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Running", Reason="", readiness=true. Elapsed: 32.038656241s
Dec 13 19:29:02.587: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Running", Reason="", readiness=true. Elapsed: 34.040847144s
Dec 13 19:29:04.589: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Running", Reason="", readiness=true. Elapsed: 36.043040387s
Dec 13 19:29:06.591: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Running", Reason="", readiness=true. Elapsed: 38.04515458s
Dec 13 19:29:08.594: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Running", Reason="", readiness=true. Elapsed: 40.04739948s
Dec 13 19:29:10.596: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Running", Reason="", readiness=true. Elapsed: 42.049687708s
Dec 13 19:29:12.598: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Running", Reason="", readiness=true. Elapsed: 44.051852305s
Dec 13 19:29:14.600: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Running", Reason="", readiness=true. Elapsed: 46.054234296s
Dec 13 19:29:16.603: INFO: Pod "pod-subpath-test-downwardapi-dv2z": Phase="Succeeded", Reason="", readiness=false. Elapsed: 48.056456336s
STEP: Saw pod success
Dec 13 19:29:16.603: INFO: Pod "pod-subpath-test-downwardapi-dv2z" satisfied condition "success or failure"
Dec 13 19:29:16.604: INFO: Trying to get logs from node 172.160.134.166 pod pod-subpath-test-downwardapi-dv2z container test-container-subpath-downwardapi-dv2z: <nil>
STEP: delete the pod
Dec 13 19:29:16.628: INFO: Waiting for pod pod-subpath-test-downwardapi-dv2z to disappear
Dec 13 19:29:16.634: INFO: Pod pod-subpath-test-downwardapi-dv2z no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-dv2z
Dec 13 19:29:16.634: INFO: Deleting pod "pod-subpath-test-downwardapi-dv2z" in namespace "subpath-1317"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:29:16.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1317" for this suite.
Dec 13 19:29:22.642: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:29:22.683: INFO: namespace subpath-1317 deletion completed in 6.046205871s

• [SLOW TEST:54.166 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:29:22.683: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 13 19:29:22.712: INFO: Waiting up to 5m0s for pod "downwardapi-volume-16c0b0af-e502-45c4-96ba-fb5ca09ebacb" in namespace "projected-2904" to be "success or failure"
Dec 13 19:29:22.718: INFO: Pod "downwardapi-volume-16c0b0af-e502-45c4-96ba-fb5ca09ebacb": Phase="Pending", Reason="", readiness=false. Elapsed: 5.821263ms
Dec 13 19:29:24.720: INFO: Pod "downwardapi-volume-16c0b0af-e502-45c4-96ba-fb5ca09ebacb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008015275s
Dec 13 19:29:26.723: INFO: Pod "downwardapi-volume-16c0b0af-e502-45c4-96ba-fb5ca09ebacb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010261424s
Dec 13 19:29:28.725: INFO: Pod "downwardapi-volume-16c0b0af-e502-45c4-96ba-fb5ca09ebacb": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012532947s
Dec 13 19:29:30.727: INFO: Pod "downwardapi-volume-16c0b0af-e502-45c4-96ba-fb5ca09ebacb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.014816535s
STEP: Saw pod success
Dec 13 19:29:30.727: INFO: Pod "downwardapi-volume-16c0b0af-e502-45c4-96ba-fb5ca09ebacb" satisfied condition "success or failure"
Dec 13 19:29:30.729: INFO: Trying to get logs from node 172.160.134.166 pod downwardapi-volume-16c0b0af-e502-45c4-96ba-fb5ca09ebacb container client-container: <nil>
STEP: delete the pod
Dec 13 19:29:30.747: INFO: Waiting for pod downwardapi-volume-16c0b0af-e502-45c4-96ba-fb5ca09ebacb to disappear
Dec 13 19:29:30.758: INFO: Pod downwardapi-volume-16c0b0af-e502-45c4-96ba-fb5ca09ebacb no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:29:30.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2904" for this suite.
Dec 13 19:29:36.766: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:29:36.804: INFO: namespace projected-2904 deletion completed in 6.044133442s

• [SLOW TEST:14.121 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:29:36.805: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-1254
I1213 19:29:36.828808      25 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1254, replica count: 1
I1213 19:29:37.879264      25 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1213 19:29:38.879562      25 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1213 19:29:39.879724      25 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1213 19:29:40.879961      25 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1213 19:29:41.880292      25 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1213 19:29:42.880561      25 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1213 19:29:43.880909      25 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 13 19:29:43.987: INFO: Created: latency-svc-jhtmm
Dec 13 19:29:43.990: INFO: Got endpoints: latency-svc-jhtmm [9.114688ms]
Dec 13 19:29:43.997: INFO: Created: latency-svc-nkfhp
Dec 13 19:29:44.005: INFO: Got endpoints: latency-svc-nkfhp [15.411406ms]
Dec 13 19:29:44.006: INFO: Created: latency-svc-k5kvd
Dec 13 19:29:44.011: INFO: Got endpoints: latency-svc-k5kvd [20.174006ms]
Dec 13 19:29:44.016: INFO: Created: latency-svc-b6v9r
Dec 13 19:29:44.019: INFO: Got endpoints: latency-svc-b6v9r [29.082158ms]
Dec 13 19:29:44.024: INFO: Created: latency-svc-84lk2
Dec 13 19:29:44.027: INFO: Got endpoints: latency-svc-84lk2 [36.719281ms]
Dec 13 19:29:44.036: INFO: Created: latency-svc-tm82v
Dec 13 19:29:44.041: INFO: Got endpoints: latency-svc-tm82v [51.096718ms]
Dec 13 19:29:44.042: INFO: Created: latency-svc-lq9p6
Dec 13 19:29:44.046: INFO: Got endpoints: latency-svc-lq9p6 [56.185155ms]
Dec 13 19:29:44.047: INFO: Created: latency-svc-brcgb
Dec 13 19:29:44.060: INFO: Created: latency-svc-glv2b
Dec 13 19:29:44.061: INFO: Got endpoints: latency-svc-brcgb [70.914485ms]
Dec 13 19:29:44.066: INFO: Got endpoints: latency-svc-glv2b [76.171965ms]
Dec 13 19:29:44.066: INFO: Created: latency-svc-gdd5b
Dec 13 19:29:44.074: INFO: Got endpoints: latency-svc-gdd5b [83.616006ms]
Dec 13 19:29:44.075: INFO: Created: latency-svc-rgnzb
Dec 13 19:29:44.076: INFO: Got endpoints: latency-svc-rgnzb [85.925558ms]
Dec 13 19:29:44.084: INFO: Created: latency-svc-sgmct
Dec 13 19:29:44.087: INFO: Got endpoints: latency-svc-sgmct [96.192216ms]
Dec 13 19:29:44.092: INFO: Created: latency-svc-n8pmn
Dec 13 19:29:44.101: INFO: Got endpoints: latency-svc-n8pmn [110.723769ms]
Dec 13 19:29:44.102: INFO: Created: latency-svc-r26dm
Dec 13 19:29:44.107: INFO: Created: latency-svc-hpw56
Dec 13 19:29:44.107: INFO: Got endpoints: latency-svc-r26dm [116.723675ms]
Dec 13 19:29:44.114: INFO: Created: latency-svc-j9qqc
Dec 13 19:29:44.114: INFO: Got endpoints: latency-svc-hpw56 [123.761049ms]
Dec 13 19:29:44.116: INFO: Got endpoints: latency-svc-j9qqc [125.81202ms]
Dec 13 19:29:44.122: INFO: Created: latency-svc-5tvdk
Dec 13 19:29:44.125: INFO: Got endpoints: latency-svc-5tvdk [119.184871ms]
Dec 13 19:29:44.130: INFO: Created: latency-svc-dzrfr
Dec 13 19:29:44.133: INFO: Got endpoints: latency-svc-dzrfr [121.878451ms]
Dec 13 19:29:44.138: INFO: Created: latency-svc-2tz26
Dec 13 19:29:44.141: INFO: Got endpoints: latency-svc-2tz26 [122.107996ms]
Dec 13 19:29:44.146: INFO: Created: latency-svc-9n4mx
Dec 13 19:29:44.149: INFO: Got endpoints: latency-svc-9n4mx [122.138012ms]
Dec 13 19:29:44.153: INFO: Created: latency-svc-2dv5h
Dec 13 19:29:44.169: INFO: Created: latency-svc-4wgg7
Dec 13 19:29:44.169: INFO: Got endpoints: latency-svc-2dv5h [127.537678ms]
Dec 13 19:29:44.176: INFO: Created: latency-svc-xccft
Dec 13 19:29:44.176: INFO: Got endpoints: latency-svc-4wgg7 [129.548734ms]
Dec 13 19:29:44.185: INFO: Created: latency-svc-dgvtm
Dec 13 19:29:44.185: INFO: Got endpoints: latency-svc-xccft [123.85129ms]
Dec 13 19:29:44.187: INFO: Got endpoints: latency-svc-dgvtm [121.075616ms]
Dec 13 19:29:44.193: INFO: Created: latency-svc-swqpx
Dec 13 19:29:44.204: INFO: Created: latency-svc-bxvkw
Dec 13 19:29:44.204: INFO: Got endpoints: latency-svc-swqpx [130.1183ms]
Dec 13 19:29:44.209: INFO: Got endpoints: latency-svc-bxvkw [132.74587ms]
Dec 13 19:29:44.209: INFO: Created: latency-svc-wnwxf
Dec 13 19:29:44.214: INFO: Created: latency-svc-b6xc7
Dec 13 19:29:44.214: INFO: Got endpoints: latency-svc-wnwxf [127.498064ms]
Dec 13 19:29:44.220: INFO: Created: latency-svc-9hllc
Dec 13 19:29:44.220: INFO: Got endpoints: latency-svc-b6xc7 [119.16973ms]
Dec 13 19:29:44.230: INFO: Created: latency-svc-bg754
Dec 13 19:29:44.230: INFO: Got endpoints: latency-svc-9hllc [122.947865ms]
Dec 13 19:29:44.232: INFO: Got endpoints: latency-svc-bg754 [118.010096ms]
Dec 13 19:29:44.238: INFO: Created: latency-svc-jcj96
Dec 13 19:29:44.241: INFO: Got endpoints: latency-svc-jcj96 [125.018911ms]
Dec 13 19:29:44.247: INFO: Created: latency-svc-8jn4m
Dec 13 19:29:44.249: INFO: Got endpoints: latency-svc-8jn4m [124.504023ms]
Dec 13 19:29:44.255: INFO: Created: latency-svc-6z8md
Dec 13 19:29:44.257: INFO: Got endpoints: latency-svc-6z8md [124.556166ms]
Dec 13 19:29:44.263: INFO: Created: latency-svc-bw5x9
Dec 13 19:29:44.268: INFO: Got endpoints: latency-svc-bw5x9 [126.445964ms]
Dec 13 19:29:44.311: INFO: Created: latency-svc-nnrqc
Dec 13 19:29:44.317: INFO: Created: latency-svc-mz424
Dec 13 19:29:44.317: INFO: Got endpoints: latency-svc-nnrqc [168.022134ms]
Dec 13 19:29:44.321: INFO: Got endpoints: latency-svc-mz424 [151.899657ms]
Dec 13 19:29:44.324: INFO: Created: latency-svc-dqgdl
Dec 13 19:29:44.338: INFO: Created: latency-svc-kmffq
Dec 13 19:29:44.351: INFO: Got endpoints: latency-svc-dqgdl [174.286541ms]
Dec 13 19:29:44.351: INFO: Created: latency-svc-7dwkv
Dec 13 19:29:44.357: INFO: Created: latency-svc-4ff6l
Dec 13 19:29:44.364: INFO: Created: latency-svc-mnqhw
Dec 13 19:29:44.373: INFO: Created: latency-svc-hwn2f
Dec 13 19:29:44.380: INFO: Created: latency-svc-2q5zb
Dec 13 19:29:44.387: INFO: Created: latency-svc-2tlbv
Dec 13 19:29:44.390: INFO: Got endpoints: latency-svc-kmffq [205.002708ms]
Dec 13 19:29:44.395: INFO: Created: latency-svc-r7j79
Dec 13 19:29:44.407: INFO: Created: latency-svc-w2772
Dec 13 19:29:44.418: INFO: Created: latency-svc-jmr5q
Dec 13 19:29:44.425: INFO: Created: latency-svc-g8bjg
Dec 13 19:29:44.435: INFO: Created: latency-svc-nqj7m
Dec 13 19:29:44.443: INFO: Got endpoints: latency-svc-7dwkv [255.939939ms]
Dec 13 19:29:44.444: INFO: Created: latency-svc-z9x7m
Dec 13 19:29:44.452: INFO: Created: latency-svc-5qhv5
Dec 13 19:29:44.459: INFO: Created: latency-svc-w7c2k
Dec 13 19:29:44.468: INFO: Created: latency-svc-7vhbv
Dec 13 19:29:44.473: INFO: Created: latency-svc-bcdbt
Dec 13 19:29:44.490: INFO: Got endpoints: latency-svc-4ff6l [285.407253ms]
Dec 13 19:29:44.499: INFO: Created: latency-svc-6qxkn
Dec 13 19:29:44.540: INFO: Got endpoints: latency-svc-mnqhw [331.229073ms]
Dec 13 19:29:44.549: INFO: Created: latency-svc-m99wj
Dec 13 19:29:44.590: INFO: Got endpoints: latency-svc-hwn2f [375.594265ms]
Dec 13 19:29:44.597: INFO: Created: latency-svc-w56kd
Dec 13 19:29:44.640: INFO: Got endpoints: latency-svc-2q5zb [419.600595ms]
Dec 13 19:29:44.650: INFO: Created: latency-svc-9tpcp
Dec 13 19:29:44.691: INFO: Got endpoints: latency-svc-2tlbv [460.413555ms]
Dec 13 19:29:44.699: INFO: Created: latency-svc-2wb5l
Dec 13 19:29:44.740: INFO: Got endpoints: latency-svc-r7j79 [507.428502ms]
Dec 13 19:29:44.752: INFO: Created: latency-svc-2zfz4
Dec 13 19:29:44.790: INFO: Got endpoints: latency-svc-w2772 [548.407754ms]
Dec 13 19:29:44.796: INFO: Created: latency-svc-nwjwr
Dec 13 19:29:44.842: INFO: Got endpoints: latency-svc-jmr5q [592.77911ms]
Dec 13 19:29:44.853: INFO: Created: latency-svc-99x8c
Dec 13 19:29:44.890: INFO: Got endpoints: latency-svc-g8bjg [632.757297ms]
Dec 13 19:29:44.898: INFO: Created: latency-svc-n47tr
Dec 13 19:29:44.940: INFO: Got endpoints: latency-svc-nqj7m [672.002964ms]
Dec 13 19:29:44.952: INFO: Created: latency-svc-cv7ph
Dec 13 19:29:44.990: INFO: Got endpoints: latency-svc-z9x7m [672.862136ms]
Dec 13 19:29:44.997: INFO: Created: latency-svc-9mwcb
Dec 13 19:29:45.040: INFO: Got endpoints: latency-svc-5qhv5 [719.008954ms]
Dec 13 19:29:45.047: INFO: Created: latency-svc-zvs2j
Dec 13 19:29:45.090: INFO: Got endpoints: latency-svc-w7c2k [739.579614ms]
Dec 13 19:29:45.104: INFO: Created: latency-svc-mkp6m
Dec 13 19:29:45.141: INFO: Got endpoints: latency-svc-7vhbv [750.303631ms]
Dec 13 19:29:45.147: INFO: Created: latency-svc-flplb
Dec 13 19:29:45.191: INFO: Got endpoints: latency-svc-bcdbt [747.06241ms]
Dec 13 19:29:45.198: INFO: Created: latency-svc-t2z6l
Dec 13 19:29:45.240: INFO: Got endpoints: latency-svc-6qxkn [750.648387ms]
Dec 13 19:29:45.255: INFO: Created: latency-svc-bpqbj
Dec 13 19:29:45.290: INFO: Got endpoints: latency-svc-m99wj [749.629643ms]
Dec 13 19:29:45.299: INFO: Created: latency-svc-8wsbc
Dec 13 19:29:45.340: INFO: Got endpoints: latency-svc-w56kd [750.179275ms]
Dec 13 19:29:45.346: INFO: Created: latency-svc-v7wdc
Dec 13 19:29:45.390: INFO: Got endpoints: latency-svc-9tpcp [749.702136ms]
Dec 13 19:29:45.396: INFO: Created: latency-svc-9q9xs
Dec 13 19:29:45.440: INFO: Got endpoints: latency-svc-2wb5l [749.400031ms]
Dec 13 19:29:45.456: INFO: Created: latency-svc-rxjtv
Dec 13 19:29:45.490: INFO: Got endpoints: latency-svc-2zfz4 [749.929929ms]
Dec 13 19:29:45.496: INFO: Created: latency-svc-9bs47
Dec 13 19:29:45.541: INFO: Got endpoints: latency-svc-nwjwr [750.502992ms]
Dec 13 19:29:45.548: INFO: Created: latency-svc-zkwx8
Dec 13 19:29:45.590: INFO: Got endpoints: latency-svc-99x8c [748.148737ms]
Dec 13 19:29:45.597: INFO: Created: latency-svc-r7m76
Dec 13 19:29:45.641: INFO: Got endpoints: latency-svc-n47tr [750.567998ms]
Dec 13 19:29:45.651: INFO: Created: latency-svc-2wzfz
Dec 13 19:29:45.691: INFO: Got endpoints: latency-svc-cv7ph [751.324574ms]
Dec 13 19:29:45.714: INFO: Created: latency-svc-d5p8v
Dec 13 19:29:45.740: INFO: Got endpoints: latency-svc-9mwcb [749.295879ms]
Dec 13 19:29:45.746: INFO: Created: latency-svc-xfspl
Dec 13 19:29:45.790: INFO: Got endpoints: latency-svc-zvs2j [749.848168ms]
Dec 13 19:29:45.806: INFO: Created: latency-svc-d5mvj
Dec 13 19:29:45.840: INFO: Got endpoints: latency-svc-mkp6m [749.886236ms]
Dec 13 19:29:45.849: INFO: Created: latency-svc-9wzld
Dec 13 19:29:45.890: INFO: Got endpoints: latency-svc-flplb [749.453007ms]
Dec 13 19:29:45.901: INFO: Created: latency-svc-px95b
Dec 13 19:29:45.940: INFO: Got endpoints: latency-svc-t2z6l [749.479355ms]
Dec 13 19:29:45.948: INFO: Created: latency-svc-brlch
Dec 13 19:29:45.991: INFO: Got endpoints: latency-svc-bpqbj [750.304694ms]
Dec 13 19:29:45.998: INFO: Created: latency-svc-bxrxj
Dec 13 19:29:46.040: INFO: Got endpoints: latency-svc-8wsbc [750.284845ms]
Dec 13 19:29:46.051: INFO: Created: latency-svc-l879x
Dec 13 19:29:46.090: INFO: Got endpoints: latency-svc-v7wdc [749.919028ms]
Dec 13 19:29:46.099: INFO: Created: latency-svc-j8djs
Dec 13 19:29:46.140: INFO: Got endpoints: latency-svc-9q9xs [750.07567ms]
Dec 13 19:29:46.151: INFO: Created: latency-svc-zqxtb
Dec 13 19:29:46.190: INFO: Got endpoints: latency-svc-rxjtv [749.883203ms]
Dec 13 19:29:46.198: INFO: Created: latency-svc-85r46
Dec 13 19:29:46.240: INFO: Got endpoints: latency-svc-9bs47 [750.256912ms]
Dec 13 19:29:46.249: INFO: Created: latency-svc-7tjvh
Dec 13 19:29:46.291: INFO: Got endpoints: latency-svc-zkwx8 [750.363121ms]
Dec 13 19:29:46.302: INFO: Created: latency-svc-2k6t7
Dec 13 19:29:46.341: INFO: Got endpoints: latency-svc-r7m76 [750.270157ms]
Dec 13 19:29:46.348: INFO: Created: latency-svc-8lmfn
Dec 13 19:29:46.390: INFO: Got endpoints: latency-svc-2wzfz [749.458817ms]
Dec 13 19:29:46.396: INFO: Created: latency-svc-pk689
Dec 13 19:29:46.440: INFO: Got endpoints: latency-svc-d5p8v [749.090655ms]
Dec 13 19:29:46.449: INFO: Created: latency-svc-tgv6c
Dec 13 19:29:46.490: INFO: Got endpoints: latency-svc-xfspl [750.451964ms]
Dec 13 19:29:46.507: INFO: Created: latency-svc-p4bbh
Dec 13 19:29:46.540: INFO: Got endpoints: latency-svc-d5mvj [750.294608ms]
Dec 13 19:29:46.546: INFO: Created: latency-svc-xvrzb
Dec 13 19:29:46.590: INFO: Got endpoints: latency-svc-9wzld [749.949204ms]
Dec 13 19:29:46.597: INFO: Created: latency-svc-rpc22
Dec 13 19:29:46.642: INFO: Got endpoints: latency-svc-px95b [751.44151ms]
Dec 13 19:29:46.651: INFO: Created: latency-svc-kqzm5
Dec 13 19:29:46.690: INFO: Got endpoints: latency-svc-brlch [749.780897ms]
Dec 13 19:29:46.703: INFO: Created: latency-svc-29pn7
Dec 13 19:29:46.740: INFO: Got endpoints: latency-svc-bxrxj [749.222609ms]
Dec 13 19:29:46.751: INFO: Created: latency-svc-4r89v
Dec 13 19:29:46.790: INFO: Got endpoints: latency-svc-l879x [749.993224ms]
Dec 13 19:29:46.797: INFO: Created: latency-svc-zmb9h
Dec 13 19:29:46.840: INFO: Got endpoints: latency-svc-j8djs [749.92515ms]
Dec 13 19:29:46.860: INFO: Created: latency-svc-j68vp
Dec 13 19:29:46.890: INFO: Got endpoints: latency-svc-zqxtb [750.241672ms]
Dec 13 19:29:46.901: INFO: Created: latency-svc-l8f2d
Dec 13 19:29:46.940: INFO: Got endpoints: latency-svc-85r46 [750.13759ms]
Dec 13 19:29:46.947: INFO: Created: latency-svc-rlx65
Dec 13 19:29:46.991: INFO: Got endpoints: latency-svc-7tjvh [750.875868ms]
Dec 13 19:29:46.997: INFO: Created: latency-svc-4jj2t
Dec 13 19:29:47.040: INFO: Got endpoints: latency-svc-2k6t7 [748.555051ms]
Dec 13 19:29:47.049: INFO: Created: latency-svc-rlf45
Dec 13 19:29:47.090: INFO: Got endpoints: latency-svc-8lmfn [749.08934ms]
Dec 13 19:29:47.098: INFO: Created: latency-svc-4dw7j
Dec 13 19:29:47.141: INFO: Got endpoints: latency-svc-pk689 [750.389846ms]
Dec 13 19:29:47.149: INFO: Created: latency-svc-v26gf
Dec 13 19:29:47.191: INFO: Got endpoints: latency-svc-tgv6c [750.078931ms]
Dec 13 19:29:47.202: INFO: Created: latency-svc-xb75r
Dec 13 19:29:47.240: INFO: Got endpoints: latency-svc-p4bbh [749.884169ms]
Dec 13 19:29:47.249: INFO: Created: latency-svc-p2mrb
Dec 13 19:29:47.290: INFO: Got endpoints: latency-svc-xvrzb [749.85986ms]
Dec 13 19:29:47.299: INFO: Created: latency-svc-vqnvl
Dec 13 19:29:47.340: INFO: Got endpoints: latency-svc-rpc22 [749.274855ms]
Dec 13 19:29:47.350: INFO: Created: latency-svc-wkxp2
Dec 13 19:29:47.391: INFO: Got endpoints: latency-svc-kqzm5 [749.30936ms]
Dec 13 19:29:47.398: INFO: Created: latency-svc-qvg2g
Dec 13 19:29:47.440: INFO: Got endpoints: latency-svc-29pn7 [750.051645ms]
Dec 13 19:29:47.447: INFO: Created: latency-svc-w7f6m
Dec 13 19:29:47.490: INFO: Got endpoints: latency-svc-4r89v [749.704213ms]
Dec 13 19:29:47.505: INFO: Created: latency-svc-xkcqk
Dec 13 19:29:47.540: INFO: Got endpoints: latency-svc-zmb9h [749.721163ms]
Dec 13 19:29:47.552: INFO: Created: latency-svc-s4s6z
Dec 13 19:29:47.592: INFO: Got endpoints: latency-svc-j68vp [751.99286ms]
Dec 13 19:29:47.599: INFO: Created: latency-svc-r5dbf
Dec 13 19:29:47.640: INFO: Got endpoints: latency-svc-l8f2d [749.871554ms]
Dec 13 19:29:47.648: INFO: Created: latency-svc-zdg4t
Dec 13 19:29:47.690: INFO: Got endpoints: latency-svc-rlx65 [749.762134ms]
Dec 13 19:29:47.705: INFO: Created: latency-svc-rnjxp
Dec 13 19:29:47.740: INFO: Got endpoints: latency-svc-4jj2t [748.98681ms]
Dec 13 19:29:47.747: INFO: Created: latency-svc-g8fcz
Dec 13 19:29:47.792: INFO: Got endpoints: latency-svc-rlf45 [751.972724ms]
Dec 13 19:29:47.802: INFO: Created: latency-svc-bfmlz
Dec 13 19:29:47.840: INFO: Got endpoints: latency-svc-4dw7j [750.232314ms]
Dec 13 19:29:47.849: INFO: Created: latency-svc-ccwhn
Dec 13 19:29:47.891: INFO: Got endpoints: latency-svc-v26gf [749.923093ms]
Dec 13 19:29:47.910: INFO: Created: latency-svc-lxrfm
Dec 13 19:29:47.940: INFO: Got endpoints: latency-svc-xb75r [749.590516ms]
Dec 13 19:29:47.946: INFO: Created: latency-svc-ztsns
Dec 13 19:29:47.991: INFO: Got endpoints: latency-svc-p2mrb [750.392505ms]
Dec 13 19:29:47.997: INFO: Created: latency-svc-9wzcj
Dec 13 19:29:48.040: INFO: Got endpoints: latency-svc-vqnvl [749.545215ms]
Dec 13 19:29:48.049: INFO: Created: latency-svc-794mv
Dec 13 19:29:48.090: INFO: Got endpoints: latency-svc-wkxp2 [750.385059ms]
Dec 13 19:29:48.099: INFO: Created: latency-svc-l2x5p
Dec 13 19:29:48.140: INFO: Got endpoints: latency-svc-qvg2g [748.669235ms]
Dec 13 19:29:48.148: INFO: Created: latency-svc-cwvwv
Dec 13 19:29:48.190: INFO: Got endpoints: latency-svc-w7f6m [749.730489ms]
Dec 13 19:29:48.197: INFO: Created: latency-svc-f548s
Dec 13 19:29:48.240: INFO: Got endpoints: latency-svc-xkcqk [749.866903ms]
Dec 13 19:29:48.257: INFO: Created: latency-svc-sprkw
Dec 13 19:29:48.290: INFO: Got endpoints: latency-svc-s4s6z [750.048454ms]
Dec 13 19:29:48.299: INFO: Created: latency-svc-gnn8q
Dec 13 19:29:48.340: INFO: Got endpoints: latency-svc-r5dbf [747.447174ms]
Dec 13 19:29:48.349: INFO: Created: latency-svc-fr42s
Dec 13 19:29:48.390: INFO: Got endpoints: latency-svc-zdg4t [750.062371ms]
Dec 13 19:29:48.399: INFO: Created: latency-svc-km5tf
Dec 13 19:29:48.444: INFO: Got endpoints: latency-svc-rnjxp [754.285947ms]
Dec 13 19:29:48.452: INFO: Created: latency-svc-kqs46
Dec 13 19:29:48.490: INFO: Got endpoints: latency-svc-g8fcz [749.704713ms]
Dec 13 19:29:48.498: INFO: Created: latency-svc-g4c28
Dec 13 19:29:48.540: INFO: Got endpoints: latency-svc-bfmlz [748.306157ms]
Dec 13 19:29:48.554: INFO: Created: latency-svc-pkxwv
Dec 13 19:29:48.590: INFO: Got endpoints: latency-svc-ccwhn [749.923022ms]
Dec 13 19:29:48.603: INFO: Created: latency-svc-q9dql
Dec 13 19:29:48.640: INFO: Got endpoints: latency-svc-lxrfm [749.04866ms]
Dec 13 19:29:48.650: INFO: Created: latency-svc-68tbz
Dec 13 19:29:48.690: INFO: Got endpoints: latency-svc-ztsns [749.550856ms]
Dec 13 19:29:48.698: INFO: Created: latency-svc-x2wp9
Dec 13 19:29:48.740: INFO: Got endpoints: latency-svc-9wzcj [749.678657ms]
Dec 13 19:29:48.750: INFO: Created: latency-svc-mmjqb
Dec 13 19:29:48.790: INFO: Got endpoints: latency-svc-794mv [750.278702ms]
Dec 13 19:29:48.800: INFO: Created: latency-svc-m4npb
Dec 13 19:29:48.840: INFO: Got endpoints: latency-svc-l2x5p [749.401743ms]
Dec 13 19:29:48.850: INFO: Created: latency-svc-nmf8v
Dec 13 19:29:48.890: INFO: Got endpoints: latency-svc-cwvwv [749.868688ms]
Dec 13 19:29:48.907: INFO: Created: latency-svc-w2n6j
Dec 13 19:29:48.940: INFO: Got endpoints: latency-svc-f548s [750.212805ms]
Dec 13 19:29:48.951: INFO: Created: latency-svc-qxbjl
Dec 13 19:29:48.990: INFO: Got endpoints: latency-svc-sprkw [750.435515ms]
Dec 13 19:29:48.998: INFO: Created: latency-svc-d49rk
Dec 13 19:29:49.040: INFO: Got endpoints: latency-svc-gnn8q [749.883611ms]
Dec 13 19:29:49.047: INFO: Created: latency-svc-8nncf
Dec 13 19:29:49.090: INFO: Got endpoints: latency-svc-fr42s [749.816136ms]
Dec 13 19:29:49.098: INFO: Created: latency-svc-pw7gm
Dec 13 19:29:49.140: INFO: Got endpoints: latency-svc-km5tf [749.415879ms]
Dec 13 19:29:49.149: INFO: Created: latency-svc-znf2r
Dec 13 19:29:49.192: INFO: Got endpoints: latency-svc-kqs46 [747.409097ms]
Dec 13 19:29:49.202: INFO: Created: latency-svc-vwlcs
Dec 13 19:29:49.240: INFO: Got endpoints: latency-svc-g4c28 [749.938056ms]
Dec 13 19:29:49.251: INFO: Created: latency-svc-4zvfk
Dec 13 19:29:49.290: INFO: Got endpoints: latency-svc-pkxwv [750.233604ms]
Dec 13 19:29:49.305: INFO: Created: latency-svc-2zpvn
Dec 13 19:29:49.340: INFO: Got endpoints: latency-svc-q9dql [749.648985ms]
Dec 13 19:29:49.349: INFO: Created: latency-svc-v26hj
Dec 13 19:29:49.391: INFO: Got endpoints: latency-svc-68tbz [751.253562ms]
Dec 13 19:29:49.406: INFO: Created: latency-svc-f8gkh
Dec 13 19:29:49.440: INFO: Got endpoints: latency-svc-x2wp9 [750.404219ms]
Dec 13 19:29:49.447: INFO: Created: latency-svc-w28hr
Dec 13 19:29:49.491: INFO: Got endpoints: latency-svc-mmjqb [750.209496ms]
Dec 13 19:29:49.502: INFO: Created: latency-svc-zvtcp
Dec 13 19:29:49.540: INFO: Got endpoints: latency-svc-m4npb [749.445537ms]
Dec 13 19:29:49.555: INFO: Created: latency-svc-zql24
Dec 13 19:29:49.590: INFO: Got endpoints: latency-svc-nmf8v [750.172613ms]
Dec 13 19:29:49.603: INFO: Created: latency-svc-m27gq
Dec 13 19:29:49.640: INFO: Got endpoints: latency-svc-w2n6j [750.19742ms]
Dec 13 19:29:49.648: INFO: Created: latency-svc-wsrh4
Dec 13 19:29:49.690: INFO: Got endpoints: latency-svc-qxbjl [749.308192ms]
Dec 13 19:29:49.698: INFO: Created: latency-svc-fg57n
Dec 13 19:29:49.740: INFO: Got endpoints: latency-svc-d49rk [749.423002ms]
Dec 13 19:29:49.748: INFO: Created: latency-svc-qmskx
Dec 13 19:29:49.790: INFO: Got endpoints: latency-svc-8nncf [749.677565ms]
Dec 13 19:29:49.798: INFO: Created: latency-svc-n8bfp
Dec 13 19:29:49.840: INFO: Got endpoints: latency-svc-pw7gm [750.026402ms]
Dec 13 19:29:49.847: INFO: Created: latency-svc-84fxr
Dec 13 19:29:49.890: INFO: Got endpoints: latency-svc-znf2r [749.837793ms]
Dec 13 19:29:49.901: INFO: Created: latency-svc-mn7wg
Dec 13 19:29:49.943: INFO: Got endpoints: latency-svc-vwlcs [750.971482ms]
Dec 13 19:29:49.956: INFO: Created: latency-svc-7v5x9
Dec 13 19:29:49.990: INFO: Got endpoints: latency-svc-4zvfk [749.735848ms]
Dec 13 19:29:49.996: INFO: Created: latency-svc-2phlp
Dec 13 19:29:50.040: INFO: Got endpoints: latency-svc-2zpvn [749.691006ms]
Dec 13 19:29:50.060: INFO: Created: latency-svc-468g6
Dec 13 19:29:50.090: INFO: Got endpoints: latency-svc-v26hj [750.034885ms]
Dec 13 19:29:50.098: INFO: Created: latency-svc-qzm85
Dec 13 19:29:50.141: INFO: Got endpoints: latency-svc-f8gkh [749.218479ms]
Dec 13 19:29:50.147: INFO: Created: latency-svc-zz7zj
Dec 13 19:29:50.190: INFO: Got endpoints: latency-svc-w28hr [749.684425ms]
Dec 13 19:29:50.202: INFO: Created: latency-svc-tzhqd
Dec 13 19:29:50.241: INFO: Got endpoints: latency-svc-zvtcp [749.870839ms]
Dec 13 19:29:50.249: INFO: Created: latency-svc-khgfc
Dec 13 19:29:50.290: INFO: Got endpoints: latency-svc-zql24 [750.023303ms]
Dec 13 19:29:50.300: INFO: Created: latency-svc-2dss5
Dec 13 19:29:50.340: INFO: Got endpoints: latency-svc-m27gq [749.919115ms]
Dec 13 19:29:50.348: INFO: Created: latency-svc-gnn2s
Dec 13 19:29:50.390: INFO: Got endpoints: latency-svc-wsrh4 [749.892698ms]
Dec 13 19:29:50.398: INFO: Created: latency-svc-ddrjx
Dec 13 19:29:50.440: INFO: Got endpoints: latency-svc-fg57n [749.934475ms]
Dec 13 19:29:50.449: INFO: Created: latency-svc-fgl7p
Dec 13 19:29:50.490: INFO: Got endpoints: latency-svc-qmskx [750.20348ms]
Dec 13 19:29:50.497: INFO: Created: latency-svc-7zrvv
Dec 13 19:29:50.540: INFO: Got endpoints: latency-svc-n8bfp [749.494029ms]
Dec 13 19:29:50.546: INFO: Created: latency-svc-b2zm2
Dec 13 19:29:50.590: INFO: Got endpoints: latency-svc-84fxr [749.707025ms]
Dec 13 19:29:50.597: INFO: Created: latency-svc-fwb9r
Dec 13 19:29:50.640: INFO: Got endpoints: latency-svc-mn7wg [750.064954ms]
Dec 13 19:29:50.654: INFO: Created: latency-svc-fqrs4
Dec 13 19:29:50.690: INFO: Got endpoints: latency-svc-7v5x9 [746.685841ms]
Dec 13 19:29:50.698: INFO: Created: latency-svc-cknkc
Dec 13 19:29:50.740: INFO: Got endpoints: latency-svc-2phlp [749.748226ms]
Dec 13 19:29:50.747: INFO: Created: latency-svc-l4kgf
Dec 13 19:29:50.792: INFO: Got endpoints: latency-svc-468g6 [751.568452ms]
Dec 13 19:29:50.798: INFO: Created: latency-svc-lh76p
Dec 13 19:29:50.843: INFO: Got endpoints: latency-svc-qzm85 [752.922356ms]
Dec 13 19:29:50.851: INFO: Created: latency-svc-296nn
Dec 13 19:29:50.890: INFO: Got endpoints: latency-svc-zz7zj [749.090073ms]
Dec 13 19:29:50.905: INFO: Created: latency-svc-qwphb
Dec 13 19:29:50.940: INFO: Got endpoints: latency-svc-tzhqd [749.912438ms]
Dec 13 19:29:50.947: INFO: Created: latency-svc-hdwj5
Dec 13 19:29:50.990: INFO: Got endpoints: latency-svc-khgfc [749.355758ms]
Dec 13 19:29:51.012: INFO: Created: latency-svc-bpwjg
Dec 13 19:29:51.040: INFO: Got endpoints: latency-svc-2dss5 [750.085874ms]
Dec 13 19:29:51.048: INFO: Created: latency-svc-b5kwd
Dec 13 19:29:51.090: INFO: Got endpoints: latency-svc-gnn2s [750.303278ms]
Dec 13 19:29:51.099: INFO: Created: latency-svc-6pnnn
Dec 13 19:29:51.140: INFO: Got endpoints: latency-svc-ddrjx [750.117728ms]
Dec 13 19:29:51.155: INFO: Created: latency-svc-6qwjj
Dec 13 19:29:51.190: INFO: Got endpoints: latency-svc-fgl7p [750.052554ms]
Dec 13 19:29:51.197: INFO: Created: latency-svc-lp9bt
Dec 13 19:29:51.242: INFO: Got endpoints: latency-svc-7zrvv [751.592555ms]
Dec 13 19:29:51.253: INFO: Created: latency-svc-9dwzv
Dec 13 19:29:51.291: INFO: Got endpoints: latency-svc-b2zm2 [750.901323ms]
Dec 13 19:29:51.299: INFO: Created: latency-svc-b6lzk
Dec 13 19:29:51.341: INFO: Got endpoints: latency-svc-fwb9r [750.804944ms]
Dec 13 19:29:51.351: INFO: Created: latency-svc-knz7t
Dec 13 19:29:51.390: INFO: Got endpoints: latency-svc-fqrs4 [749.858464ms]
Dec 13 19:29:51.397: INFO: Created: latency-svc-pp7km
Dec 13 19:29:51.440: INFO: Got endpoints: latency-svc-cknkc [750.364696ms]
Dec 13 19:29:51.449: INFO: Created: latency-svc-htfz2
Dec 13 19:29:51.490: INFO: Got endpoints: latency-svc-l4kgf [749.987856ms]
Dec 13 19:29:51.498: INFO: Created: latency-svc-9v42t
Dec 13 19:29:51.542: INFO: Got endpoints: latency-svc-lh76p [749.831931ms]
Dec 13 19:29:51.548: INFO: Created: latency-svc-68bwk
Dec 13 19:29:51.590: INFO: Got endpoints: latency-svc-296nn [747.117413ms]
Dec 13 19:29:51.597: INFO: Created: latency-svc-2qn9z
Dec 13 19:29:51.640: INFO: Got endpoints: latency-svc-qwphb [750.105097ms]
Dec 13 19:29:51.652: INFO: Created: latency-svc-jhtsl
Dec 13 19:29:51.690: INFO: Got endpoints: latency-svc-hdwj5 [750.008064ms]
Dec 13 19:29:51.704: INFO: Created: latency-svc-6gg2x
Dec 13 19:29:51.740: INFO: Got endpoints: latency-svc-bpwjg [749.78877ms]
Dec 13 19:29:51.752: INFO: Created: latency-svc-vfblx
Dec 13 19:29:51.790: INFO: Got endpoints: latency-svc-b5kwd [749.962159ms]
Dec 13 19:29:51.798: INFO: Created: latency-svc-2bbvs
Dec 13 19:29:51.840: INFO: Got endpoints: latency-svc-6pnnn [749.447019ms]
Dec 13 19:29:51.890: INFO: Got endpoints: latency-svc-6qwjj [750.029916ms]
Dec 13 19:29:51.940: INFO: Got endpoints: latency-svc-lp9bt [749.982749ms]
Dec 13 19:29:51.991: INFO: Got endpoints: latency-svc-9dwzv [748.373981ms]
Dec 13 19:29:52.040: INFO: Got endpoints: latency-svc-b6lzk [749.182843ms]
Dec 13 19:29:52.089: INFO: Got endpoints: latency-svc-knz7t [748.818241ms]
Dec 13 19:29:52.141: INFO: Got endpoints: latency-svc-pp7km [750.665978ms]
Dec 13 19:29:52.190: INFO: Got endpoints: latency-svc-htfz2 [749.837567ms]
Dec 13 19:29:52.240: INFO: Got endpoints: latency-svc-9v42t [750.050639ms]
Dec 13 19:29:52.291: INFO: Got endpoints: latency-svc-68bwk [748.676627ms]
Dec 13 19:29:52.340: INFO: Got endpoints: latency-svc-2qn9z [749.68074ms]
Dec 13 19:29:52.391: INFO: Got endpoints: latency-svc-jhtsl [750.601079ms]
Dec 13 19:29:52.441: INFO: Got endpoints: latency-svc-6gg2x [750.254469ms]
Dec 13 19:29:52.490: INFO: Got endpoints: latency-svc-vfblx [749.631425ms]
Dec 13 19:29:52.540: INFO: Got endpoints: latency-svc-2bbvs [749.667278ms]
Dec 13 19:29:52.540: INFO: Latencies: [15.411406ms 20.174006ms 29.082158ms 36.719281ms 51.096718ms 56.185155ms 70.914485ms 76.171965ms 83.616006ms 85.925558ms 96.192216ms 110.723769ms 116.723675ms 118.010096ms 119.16973ms 119.184871ms 121.075616ms 121.878451ms 122.107996ms 122.138012ms 122.947865ms 123.761049ms 123.85129ms 124.504023ms 124.556166ms 125.018911ms 125.81202ms 126.445964ms 127.498064ms 127.537678ms 129.548734ms 130.1183ms 132.74587ms 151.899657ms 168.022134ms 174.286541ms 205.002708ms 255.939939ms 285.407253ms 331.229073ms 375.594265ms 419.600595ms 460.413555ms 507.428502ms 548.407754ms 592.77911ms 632.757297ms 672.002964ms 672.862136ms 719.008954ms 739.579614ms 746.685841ms 747.06241ms 747.117413ms 747.409097ms 747.447174ms 748.148737ms 748.306157ms 748.373981ms 748.555051ms 748.669235ms 748.676627ms 748.818241ms 748.98681ms 749.04866ms 749.08934ms 749.090073ms 749.090655ms 749.182843ms 749.218479ms 749.222609ms 749.274855ms 749.295879ms 749.308192ms 749.30936ms 749.355758ms 749.400031ms 749.401743ms 749.415879ms 749.423002ms 749.445537ms 749.447019ms 749.453007ms 749.458817ms 749.479355ms 749.494029ms 749.545215ms 749.550856ms 749.590516ms 749.629643ms 749.631425ms 749.648985ms 749.667278ms 749.677565ms 749.678657ms 749.68074ms 749.684425ms 749.691006ms 749.702136ms 749.704213ms 749.704713ms 749.707025ms 749.721163ms 749.730489ms 749.735848ms 749.748226ms 749.762134ms 749.780897ms 749.78877ms 749.816136ms 749.831931ms 749.837567ms 749.837793ms 749.848168ms 749.858464ms 749.85986ms 749.866903ms 749.868688ms 749.870839ms 749.871554ms 749.883203ms 749.883611ms 749.884169ms 749.886236ms 749.892698ms 749.912438ms 749.919028ms 749.919115ms 749.923022ms 749.923093ms 749.92515ms 749.929929ms 749.934475ms 749.938056ms 749.949204ms 749.962159ms 749.982749ms 749.987856ms 749.993224ms 750.008064ms 750.023303ms 750.026402ms 750.029916ms 750.034885ms 750.048454ms 750.050639ms 750.051645ms 750.052554ms 750.062371ms 750.064954ms 750.07567ms 750.078931ms 750.085874ms 750.105097ms 750.117728ms 750.13759ms 750.172613ms 750.179275ms 750.19742ms 750.20348ms 750.209496ms 750.212805ms 750.232314ms 750.233604ms 750.241672ms 750.254469ms 750.256912ms 750.270157ms 750.278702ms 750.284845ms 750.294608ms 750.303278ms 750.303631ms 750.304694ms 750.363121ms 750.364696ms 750.385059ms 750.389846ms 750.392505ms 750.404219ms 750.435515ms 750.451964ms 750.502992ms 750.567998ms 750.601079ms 750.648387ms 750.665978ms 750.804944ms 750.875868ms 750.901323ms 750.971482ms 751.253562ms 751.324574ms 751.44151ms 751.568452ms 751.592555ms 751.972724ms 751.99286ms 752.922356ms 754.285947ms]
Dec 13 19:29:52.540: INFO: 50 %ile: 749.704713ms
Dec 13 19:29:52.540: INFO: 90 %ile: 750.435515ms
Dec 13 19:29:52.540: INFO: 99 %ile: 752.922356ms
Dec 13 19:29:52.540: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:29:52.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-1254" for this suite.
Dec 13 19:30:02.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:30:02.591: INFO: namespace svc-latency-1254 deletion completed in 10.047970609s

• [SLOW TEST:25.786 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:30:02.592: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 19:30:02.628: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec 13 19:30:07.630: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 13 19:30:09.634: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec 13 19:30:11.636: INFO: Creating deployment "test-rollover-deployment"
Dec 13 19:30:11.641: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec 13 19:30:13.645: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec 13 19:30:13.648: INFO: Ensure that both replica sets have 1 created replica
Dec 13 19:30:13.652: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec 13 19:30:13.656: INFO: Updating deployment test-rollover-deployment
Dec 13 19:30:13.656: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec 13 19:30:15.659: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec 13 19:30:15.663: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec 13 19:30:15.666: INFO: all replica sets need to contain the pod-template-hash label
Dec 13 19:30:15.666: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862211, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862211, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862213, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862211, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:30:17.670: INFO: all replica sets need to contain the pod-template-hash label
Dec 13 19:30:17.671: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862211, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862211, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862213, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862211, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:30:19.671: INFO: all replica sets need to contain the pod-template-hash label
Dec 13 19:30:19.671: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862211, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862211, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862218, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862211, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:30:21.670: INFO: all replica sets need to contain the pod-template-hash label
Dec 13 19:30:21.670: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862211, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862211, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862218, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862211, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:30:23.672: INFO: all replica sets need to contain the pod-template-hash label
Dec 13 19:30:23.672: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862211, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862211, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862218, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862211, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:30:25.671: INFO: all replica sets need to contain the pod-template-hash label
Dec 13 19:30:25.671: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862211, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862211, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862218, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862211, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:30:27.670: INFO: all replica sets need to contain the pod-template-hash label
Dec 13 19:30:27.670: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862211, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862211, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862218, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862211, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:30:30.309: INFO: 
Dec 13 19:30:30.309: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 13 19:30:30.313: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-8181 /apis/apps/v1/namespaces/deployment-8181/deployments/test-rollover-deployment 7347c988-e275-4139-9ea7-865b34a49a7d 132619 2 2019-12-13 19:30:11 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004224668 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-13 19:30:11 +0000 UTC,LastTransitionTime:2019-12-13 19:30:11 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2019-12-13 19:30:28 +0000 UTC,LastTransitionTime:2019-12-13 19:30:11 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 13 19:30:30.315: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-8181 /apis/apps/v1/namespaces/deployment-8181/replicasets/test-rollover-deployment-7d7dc6548c 6c54224a-357a-4783-a90e-908bf8e28cf6 132608 2 2019-12-13 19:30:13 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 7347c988-e275-4139-9ea7-865b34a49a7d 0xc004b1da77 0xc004b1da78}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004b1dad8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 13 19:30:30.315: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec 13 19:30:30.315: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-8181 /apis/apps/v1/namespaces/deployment-8181/replicasets/test-rollover-controller 8d1abdaa-cd8b-43f8-a933-fff2ed6b901a 132618 2 2019-12-13 19:30:02 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 7347c988-e275-4139-9ea7-865b34a49a7d 0xc004b1d9a7 0xc004b1d9a8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc004b1da08 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 13 19:30:30.315: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-8181 /apis/apps/v1/namespaces/deployment-8181/replicasets/test-rollover-deployment-f6c94f66c 18cb92a7-3102-47d1-af50-466373382308 132589 2 2019-12-13 19:30:11 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 7347c988-e275-4139-9ea7-865b34a49a7d 0xc004b1db40 0xc004b1db41}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004b1dbb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 13 19:30:30.317: INFO: Pod "test-rollover-deployment-7d7dc6548c-kbst5" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-kbst5 test-rollover-deployment-7d7dc6548c- deployment-8181 /api/v1/namespaces/deployment-8181/pods/test-rollover-deployment-7d7dc6548c-kbst5 7670254a-674d-4a48-829a-6874faf54de6 132598 0 2019-12-13 19:30:13 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c 6c54224a-357a-4783-a90e-908bf8e28cf6 0xc003cac107 0xc003cac108}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fhvmg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fhvmg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fhvmg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:172.160.134.165,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 19:30:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 19:30:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 19:30:18 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-13 19:30:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:172.160.134.165,PodIP:172.160.134.200,StartTime:2019-12-13 19:30:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-13 19:30:18 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://36ba499c0a04f7755c5886f37775eb02c44d336a870cad6fa65cb7893a42875f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:172.160.134.200,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:30:30.317: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8181" for this suite.
Dec 13 19:30:36.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:30:36.365: INFO: namespace deployment-8181 deletion completed in 6.046469587s

• [SLOW TEST:33.774 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:30:36.366: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-8043f9d2-b5fa-40f6-b5a9-23a91cfb7098
STEP: Creating a pod to test consume secrets
Dec 13 19:30:36.395: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-04e23d7e-3ecc-4eab-83ef-193d25d72d3b" in namespace "projected-7652" to be "success or failure"
Dec 13 19:30:36.402: INFO: Pod "pod-projected-secrets-04e23d7e-3ecc-4eab-83ef-193d25d72d3b": Phase="Pending", Reason="", readiness=false. Elapsed: 7.229081ms
Dec 13 19:30:38.404: INFO: Pod "pod-projected-secrets-04e23d7e-3ecc-4eab-83ef-193d25d72d3b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009415286s
Dec 13 19:30:40.407: INFO: Pod "pod-projected-secrets-04e23d7e-3ecc-4eab-83ef-193d25d72d3b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012154085s
Dec 13 19:30:42.409: INFO: Pod "pod-projected-secrets-04e23d7e-3ecc-4eab-83ef-193d25d72d3b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.014502119s
STEP: Saw pod success
Dec 13 19:30:42.409: INFO: Pod "pod-projected-secrets-04e23d7e-3ecc-4eab-83ef-193d25d72d3b" satisfied condition "success or failure"
Dec 13 19:30:42.411: INFO: Trying to get logs from node 172.160.134.165 pod pod-projected-secrets-04e23d7e-3ecc-4eab-83ef-193d25d72d3b container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 13 19:30:42.434: INFO: Waiting for pod pod-projected-secrets-04e23d7e-3ecc-4eab-83ef-193d25d72d3b to disappear
Dec 13 19:30:42.437: INFO: Pod pod-projected-secrets-04e23d7e-3ecc-4eab-83ef-193d25d72d3b no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:30:42.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7652" for this suite.
Dec 13 19:30:48.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:30:48.487: INFO: namespace projected-7652 deletion completed in 6.048939777s

• [SLOW TEST:12.122 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:30:48.487: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 13 19:30:48.514: INFO: Waiting up to 5m0s for pod "pod-095112d7-d32f-4715-8e0e-770b25f34bf1" in namespace "emptydir-7150" to be "success or failure"
Dec 13 19:30:48.515: INFO: Pod "pod-095112d7-d32f-4715-8e0e-770b25f34bf1": Phase="Pending", Reason="", readiness=false. Elapsed: 1.414424ms
Dec 13 19:30:50.517: INFO: Pod "pod-095112d7-d32f-4715-8e0e-770b25f34bf1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003456542s
Dec 13 19:30:52.519: INFO: Pod "pod-095112d7-d32f-4715-8e0e-770b25f34bf1": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005556547s
Dec 13 19:30:54.522: INFO: Pod "pod-095112d7-d32f-4715-8e0e-770b25f34bf1": Phase="Pending", Reason="", readiness=false. Elapsed: 6.007901772s
Dec 13 19:30:56.524: INFO: Pod "pod-095112d7-d32f-4715-8e0e-770b25f34bf1": Phase="Pending", Reason="", readiness=false. Elapsed: 8.010036951s
Dec 13 19:30:58.526: INFO: Pod "pod-095112d7-d32f-4715-8e0e-770b25f34bf1": Phase="Pending", Reason="", readiness=false. Elapsed: 10.012306061s
Dec 13 19:31:00.528: INFO: Pod "pod-095112d7-d32f-4715-8e0e-770b25f34bf1": Phase="Pending", Reason="", readiness=false. Elapsed: 12.014569813s
Dec 13 19:31:02.530: INFO: Pod "pod-095112d7-d32f-4715-8e0e-770b25f34bf1": Phase="Pending", Reason="", readiness=false. Elapsed: 14.016852254s
Dec 13 19:31:04.533: INFO: Pod "pod-095112d7-d32f-4715-8e0e-770b25f34bf1": Phase="Pending", Reason="", readiness=false. Elapsed: 16.019054935s
Dec 13 19:31:06.535: INFO: Pod "pod-095112d7-d32f-4715-8e0e-770b25f34bf1": Phase="Pending", Reason="", readiness=false. Elapsed: 18.021060144s
Dec 13 19:31:08.537: INFO: Pod "pod-095112d7-d32f-4715-8e0e-770b25f34bf1": Phase="Pending", Reason="", readiness=false. Elapsed: 20.023190851s
Dec 13 19:31:10.539: INFO: Pod "pod-095112d7-d32f-4715-8e0e-770b25f34bf1": Phase="Pending", Reason="", readiness=false. Elapsed: 22.025507263s
Dec 13 19:31:12.541: INFO: Pod "pod-095112d7-d32f-4715-8e0e-770b25f34bf1": Phase="Pending", Reason="", readiness=false. Elapsed: 24.027503241s
Dec 13 19:31:14.548: INFO: Pod "pod-095112d7-d32f-4715-8e0e-770b25f34bf1": Phase="Pending", Reason="", readiness=false. Elapsed: 26.034286244s
Dec 13 19:31:16.550: INFO: Pod "pod-095112d7-d32f-4715-8e0e-770b25f34bf1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 28.036374696s
STEP: Saw pod success
Dec 13 19:31:16.550: INFO: Pod "pod-095112d7-d32f-4715-8e0e-770b25f34bf1" satisfied condition "success or failure"
Dec 13 19:31:16.551: INFO: Trying to get logs from node 172.160.134.166 pod pod-095112d7-d32f-4715-8e0e-770b25f34bf1 container test-container: <nil>
STEP: delete the pod
Dec 13 19:31:16.572: INFO: Waiting for pod pod-095112d7-d32f-4715-8e0e-770b25f34bf1 to disappear
Dec 13 19:31:16.576: INFO: Pod pod-095112d7-d32f-4715-8e0e-770b25f34bf1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:31:16.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7150" for this suite.
Dec 13 19:31:22.585: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:31:22.631: INFO: namespace emptydir-7150 deletion completed in 6.052349897s

• [SLOW TEST:34.143 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:31:22.631: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 19:31:22.657: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:31:23.671: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8720" for this suite.
Dec 13 19:31:29.679: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:31:29.723: INFO: namespace custom-resource-definition-8720 deletion completed in 6.049278198s

• [SLOW TEST:7.092 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:31:29.723: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:31:29.754: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-5567" for this suite.
Dec 13 19:31:35.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:31:35.799: INFO: namespace tables-5567 deletion completed in 6.043390665s

• [SLOW TEST:6.076 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:31:35.799: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 13 19:31:37.180: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 13 19:31:39.186: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862297, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862297, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862297, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862297, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:31:41.188: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862297, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862297, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862297, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862297, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:31:43.188: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862297, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862297, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862297, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862297, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 13 19:31:46.202: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:31:46.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5718" for this suite.
Dec 13 19:31:52.287: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:31:52.334: INFO: namespace webhook-5718 deletion completed in 6.053657767s
STEP: Destroying namespace "webhook-5718-markers" for this suite.
Dec 13 19:31:58.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:31:58.386: INFO: namespace webhook-5718-markers deletion completed in 6.051468094s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:22.593 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:31:58.392: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-78a9801c-8672-4b86-bb83-8799140da6d9
STEP: Creating a pod to test consume configMaps
Dec 13 19:31:58.418: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-aa70277d-fd78-4602-8f42-0ad623e826e9" in namespace "projected-7333" to be "success or failure"
Dec 13 19:31:58.420: INFO: Pod "pod-projected-configmaps-aa70277d-fd78-4602-8f42-0ad623e826e9": Phase="Pending", Reason="", readiness=false. Elapsed: 1.851956ms
Dec 13 19:32:00.422: INFO: Pod "pod-projected-configmaps-aa70277d-fd78-4602-8f42-0ad623e826e9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003711177s
Dec 13 19:32:02.424: INFO: Pod "pod-projected-configmaps-aa70277d-fd78-4602-8f42-0ad623e826e9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006249171s
Dec 13 19:32:04.427: INFO: Pod "pod-projected-configmaps-aa70277d-fd78-4602-8f42-0ad623e826e9": Phase="Pending", Reason="", readiness=false. Elapsed: 6.008602732s
Dec 13 19:32:06.429: INFO: Pod "pod-projected-configmaps-aa70277d-fd78-4602-8f42-0ad623e826e9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.011008896s
STEP: Saw pod success
Dec 13 19:32:06.429: INFO: Pod "pod-projected-configmaps-aa70277d-fd78-4602-8f42-0ad623e826e9" satisfied condition "success or failure"
Dec 13 19:32:06.431: INFO: Trying to get logs from node 172.160.134.166 pod pod-projected-configmaps-aa70277d-fd78-4602-8f42-0ad623e826e9 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 13 19:32:06.444: INFO: Waiting for pod pod-projected-configmaps-aa70277d-fd78-4602-8f42-0ad623e826e9 to disappear
Dec 13 19:32:06.447: INFO: Pod pod-projected-configmaps-aa70277d-fd78-4602-8f42-0ad623e826e9 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:32:06.447: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7333" for this suite.
Dec 13 19:32:12.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:32:12.499: INFO: namespace projected-7333 deletion completed in 6.050360892s

• [SLOW TEST:14.107 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:32:12.499: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:33:47.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5838" for this suite.
Dec 13 19:33:53.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:33:53.878: INFO: namespace container-runtime-5838 deletion completed in 6.052227092s

• [SLOW TEST:101.379 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:33:53.879: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-3649
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 13 19:33:53.902: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 13 19:34:23.956: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.160.134.209 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3649 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 13 19:34:23.956: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 19:34:25.253: INFO: Found all expected endpoints: [netserver-0]
Dec 13 19:34:25.255: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 172.160.134.219 8081 | grep -v '^\s*$'] Namespace:pod-network-test-3649 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 13 19:34:25.255: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
Dec 13 19:34:26.616: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:34:26.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3649" for this suite.
Dec 13 19:34:38.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:34:38.664: INFO: namespace pod-network-test-3649 deletion completed in 12.045407709s

• [SLOW TEST:44.785 seconds]
[sig-network] Networking
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:34:38.664: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Dec 13 19:34:38.698: INFO: Waiting up to 5m0s for pod "client-containers-44be0ce1-6b16-4ce5-8bdc-f335c0b45781" in namespace "containers-3855" to be "success or failure"
Dec 13 19:34:38.701: INFO: Pod "client-containers-44be0ce1-6b16-4ce5-8bdc-f335c0b45781": Phase="Pending", Reason="", readiness=false. Elapsed: 2.373139ms
Dec 13 19:34:40.703: INFO: Pod "client-containers-44be0ce1-6b16-4ce5-8bdc-f335c0b45781": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004616143s
Dec 13 19:34:42.705: INFO: Pod "client-containers-44be0ce1-6b16-4ce5-8bdc-f335c0b45781": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006784112s
Dec 13 19:34:44.707: INFO: Pod "client-containers-44be0ce1-6b16-4ce5-8bdc-f335c0b45781": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009023106s
STEP: Saw pod success
Dec 13 19:34:44.707: INFO: Pod "client-containers-44be0ce1-6b16-4ce5-8bdc-f335c0b45781" satisfied condition "success or failure"
Dec 13 19:34:44.709: INFO: Trying to get logs from node 172.160.134.165 pod client-containers-44be0ce1-6b16-4ce5-8bdc-f335c0b45781 container test-container: <nil>
STEP: delete the pod
Dec 13 19:34:44.734: INFO: Waiting for pod client-containers-44be0ce1-6b16-4ce5-8bdc-f335c0b45781 to disappear
Dec 13 19:34:44.737: INFO: Pod client-containers-44be0ce1-6b16-4ce5-8bdc-f335c0b45781 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:34:44.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3855" for this suite.
Dec 13 19:34:50.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:34:50.792: INFO: namespace containers-3855 deletion completed in 6.053908933s

• [SLOW TEST:12.128 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:34:50.792: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 19:34:50.823: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:34:51.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2522" for this suite.
Dec 13 19:34:57.376: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:34:57.416: INFO: namespace custom-resource-definition-2522 deletion completed in 6.062858207s

• [SLOW TEST:6.624 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:34:57.418: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Dec 13 19:34:57.439: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Dec 13 19:34:57.921: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Dec 13 19:34:59.948: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862497, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862497, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862497, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862497, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:35:01.951: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862497, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862497, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862497, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862497, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:35:03.951: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862497, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862497, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862497, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862497, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:35:06.880: INFO: Waited 925.722125ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:35:07.309: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1550" for this suite.
Dec 13 19:35:13.461: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:35:13.504: INFO: namespace aggregator-1550 deletion completed in 6.144217683s

• [SLOW TEST:16.086 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:35:13.504: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:35:21.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7430" for this suite.
Dec 13 19:35:27.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:35:27.585: INFO: namespace kubelet-test-7430 deletion completed in 6.049959671s

• [SLOW TEST:14.081 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:35:27.586: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec 13 19:35:27.613: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9367 /api/v1/namespaces/watch-9367/configmaps/e2e-watch-test-configmap-a 29338a51-9a91-45f9-9813-168c20cba040 133334 0 2019-12-13 19:35:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 13 19:35:27.614: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9367 /api/v1/namespaces/watch-9367/configmaps/e2e-watch-test-configmap-a 29338a51-9a91-45f9-9813-168c20cba040 133334 0 2019-12-13 19:35:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec 13 19:35:37.619: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9367 /api/v1/namespaces/watch-9367/configmaps/e2e-watch-test-configmap-a 29338a51-9a91-45f9-9813-168c20cba040 133343 0 2019-12-13 19:35:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 13 19:35:37.619: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9367 /api/v1/namespaces/watch-9367/configmaps/e2e-watch-test-configmap-a 29338a51-9a91-45f9-9813-168c20cba040 133343 0 2019-12-13 19:35:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec 13 19:35:47.624: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9367 /api/v1/namespaces/watch-9367/configmaps/e2e-watch-test-configmap-a 29338a51-9a91-45f9-9813-168c20cba040 133351 0 2019-12-13 19:35:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 13 19:35:47.624: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9367 /api/v1/namespaces/watch-9367/configmaps/e2e-watch-test-configmap-a 29338a51-9a91-45f9-9813-168c20cba040 133351 0 2019-12-13 19:35:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec 13 19:35:57.629: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9367 /api/v1/namespaces/watch-9367/configmaps/e2e-watch-test-configmap-a 29338a51-9a91-45f9-9813-168c20cba040 133359 0 2019-12-13 19:35:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 13 19:35:57.629: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9367 /api/v1/namespaces/watch-9367/configmaps/e2e-watch-test-configmap-a 29338a51-9a91-45f9-9813-168c20cba040 133359 0 2019-12-13 19:35:27 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec 13 19:36:07.633: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9367 /api/v1/namespaces/watch-9367/configmaps/e2e-watch-test-configmap-b 5a39672b-6054-4808-9f43-c87732e874bd 133367 0 2019-12-13 19:36:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 13 19:36:07.633: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9367 /api/v1/namespaces/watch-9367/configmaps/e2e-watch-test-configmap-b 5a39672b-6054-4808-9f43-c87732e874bd 133367 0 2019-12-13 19:36:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec 13 19:36:17.637: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9367 /api/v1/namespaces/watch-9367/configmaps/e2e-watch-test-configmap-b 5a39672b-6054-4808-9f43-c87732e874bd 133376 0 2019-12-13 19:36:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 13 19:36:17.638: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9367 /api/v1/namespaces/watch-9367/configmaps/e2e-watch-test-configmap-b 5a39672b-6054-4808-9f43-c87732e874bd 133376 0 2019-12-13 19:36:07 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:36:27.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9367" for this suite.
Dec 13 19:36:33.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:36:33.693: INFO: namespace watch-9367 deletion completed in 6.052107371s

• [SLOW TEST:66.107 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:36:33.693: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:36:33.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2965" for this suite.
Dec 13 19:36:39.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:36:39.790: INFO: namespace resourcequota-2965 deletion completed in 6.050064522s

• [SLOW TEST:6.097 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:36:39.791: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-9f54dda2-f33a-4633-a5cf-a8f817daca9d
STEP: Creating a pod to test consume configMaps
Dec 13 19:36:39.817: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4d175caa-c199-4a8f-bd98-e439f5b56347" in namespace "projected-7822" to be "success or failure"
Dec 13 19:36:39.819: INFO: Pod "pod-projected-configmaps-4d175caa-c199-4a8f-bd98-e439f5b56347": Phase="Pending", Reason="", readiness=false. Elapsed: 1.995844ms
Dec 13 19:36:41.822: INFO: Pod "pod-projected-configmaps-4d175caa-c199-4a8f-bd98-e439f5b56347": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004458553s
Dec 13 19:36:43.824: INFO: Pod "pod-projected-configmaps-4d175caa-c199-4a8f-bd98-e439f5b56347": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006795642s
Dec 13 19:36:45.826: INFO: Pod "pod-projected-configmaps-4d175caa-c199-4a8f-bd98-e439f5b56347": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009246915s
STEP: Saw pod success
Dec 13 19:36:45.826: INFO: Pod "pod-projected-configmaps-4d175caa-c199-4a8f-bd98-e439f5b56347" satisfied condition "success or failure"
Dec 13 19:36:45.828: INFO: Trying to get logs from node 172.160.134.165 pod pod-projected-configmaps-4d175caa-c199-4a8f-bd98-e439f5b56347 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 13 19:36:45.852: INFO: Waiting for pod pod-projected-configmaps-4d175caa-c199-4a8f-bd98-e439f5b56347 to disappear
Dec 13 19:36:45.855: INFO: Pod pod-projected-configmaps-4d175caa-c199-4a8f-bd98-e439f5b56347 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:36:45.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7822" for this suite.
Dec 13 19:36:51.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:36:51.906: INFO: namespace projected-7822 deletion completed in 6.048858354s

• [SLOW TEST:12.115 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:36:51.906: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:37:02.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8767" for this suite.
Dec 13 19:37:08.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:37:08.999: INFO: namespace resourcequota-8767 deletion completed in 6.049076434s

• [SLOW TEST:17.093 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:37:09.000: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-60a8d98a-6c8b-4719-b77f-381b05fc8daa
STEP: Creating a pod to test consume secrets
Dec 13 19:37:09.032: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-507aa686-40b7-4461-a8d5-9a47f08223b5" in namespace "projected-4320" to be "success or failure"
Dec 13 19:37:09.039: INFO: Pod "pod-projected-secrets-507aa686-40b7-4461-a8d5-9a47f08223b5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.860013ms
Dec 13 19:37:11.041: INFO: Pod "pod-projected-secrets-507aa686-40b7-4461-a8d5-9a47f08223b5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00914777s
Dec 13 19:37:13.043: INFO: Pod "pod-projected-secrets-507aa686-40b7-4461-a8d5-9a47f08223b5": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01138989s
Dec 13 19:37:15.046: INFO: Pod "pod-projected-secrets-507aa686-40b7-4461-a8d5-9a47f08223b5": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013774497s
Dec 13 19:37:17.048: INFO: Pod "pod-projected-secrets-507aa686-40b7-4461-a8d5-9a47f08223b5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.016038838s
STEP: Saw pod success
Dec 13 19:37:17.048: INFO: Pod "pod-projected-secrets-507aa686-40b7-4461-a8d5-9a47f08223b5" satisfied condition "success or failure"
Dec 13 19:37:17.050: INFO: Trying to get logs from node 172.160.134.166 pod pod-projected-secrets-507aa686-40b7-4461-a8d5-9a47f08223b5 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 13 19:37:17.074: INFO: Waiting for pod pod-projected-secrets-507aa686-40b7-4461-a8d5-9a47f08223b5 to disappear
Dec 13 19:37:17.078: INFO: Pod pod-projected-secrets-507aa686-40b7-4461-a8d5-9a47f08223b5 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:37:17.078: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4320" for this suite.
Dec 13 19:37:23.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:37:23.132: INFO: namespace projected-4320 deletion completed in 6.051861589s

• [SLOW TEST:14.132 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:37:23.132: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-f8c50841-3918-4ead-b87e-03d1ff4a3df8
STEP: Creating a pod to test consume configMaps
Dec 13 19:37:23.162: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f82f384f-adbe-4def-8d82-8c084e9557ef" in namespace "projected-2081" to be "success or failure"
Dec 13 19:37:23.167: INFO: Pod "pod-projected-configmaps-f82f384f-adbe-4def-8d82-8c084e9557ef": Phase="Pending", Reason="", readiness=false. Elapsed: 4.962569ms
Dec 13 19:37:25.169: INFO: Pod "pod-projected-configmaps-f82f384f-adbe-4def-8d82-8c084e9557ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007177504s
Dec 13 19:37:27.171: INFO: Pod "pod-projected-configmaps-f82f384f-adbe-4def-8d82-8c084e9557ef": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009491134s
Dec 13 19:37:29.173: INFO: Pod "pod-projected-configmaps-f82f384f-adbe-4def-8d82-8c084e9557ef": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011861105s
Dec 13 19:37:31.176: INFO: Pod "pod-projected-configmaps-f82f384f-adbe-4def-8d82-8c084e9557ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.0143143s
STEP: Saw pod success
Dec 13 19:37:31.176: INFO: Pod "pod-projected-configmaps-f82f384f-adbe-4def-8d82-8c084e9557ef" satisfied condition "success or failure"
Dec 13 19:37:31.177: INFO: Trying to get logs from node 172.160.134.166 pod pod-projected-configmaps-f82f384f-adbe-4def-8d82-8c084e9557ef container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 13 19:37:31.224: INFO: Waiting for pod pod-projected-configmaps-f82f384f-adbe-4def-8d82-8c084e9557ef to disappear
Dec 13 19:37:31.227: INFO: Pod pod-projected-configmaps-f82f384f-adbe-4def-8d82-8c084e9557ef no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:37:31.227: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2081" for this suite.
Dec 13 19:37:37.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:37:37.283: INFO: namespace projected-2081 deletion completed in 6.053850202s

• [SLOW TEST:14.151 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:37:37.284: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 13 19:37:37.308: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 13 19:37:37.313: INFO: Waiting for terminating namespaces to be deleted...
Dec 13 19:37:37.315: INFO: 
Logging pods the kubelet thinks is on node 172.160.134.165 before test
Dec 13 19:37:37.318: INFO: sonobuoy-systemd-logs-daemon-set-5a2f946422e448af-pq5l8 from sonobuoy started at 2019-12-13 17:43:15 +0000 UTC (2 container statuses recorded)
Dec 13 19:37:37.318: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 13 19:37:37.318: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 13 19:37:37.318: INFO: iag-172.160.134.165 from kube-system started at 2019-12-12 13:53:36 +0000 UTC (1 container statuses recorded)
Dec 13 19:37:37.318: INFO: 	Container iag ready: true, restart count 0
Dec 13 19:37:37.318: INFO: sonobuoy-e2e-job-acb159fe38ea4959 from sonobuoy started at 2019-12-13 17:43:15 +0000 UTC (2 container statuses recorded)
Dec 13 19:37:37.318: INFO: 	Container e2e ready: true, restart count 0
Dec 13 19:37:37.318: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Dec 13 19:37:37.318: INFO: 
Logging pods the kubelet thinks is on node 172.160.134.166 before test
Dec 13 19:37:37.322: INFO: sonobuoy-systemd-logs-daemon-set-5a2f946422e448af-cjc42 from sonobuoy started at 2019-12-13 17:43:15 +0000 UTC (2 container statuses recorded)
Dec 13 19:37:37.322: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Dec 13 19:37:37.322: INFO: 	Container systemd-logs ready: true, restart count 0
Dec 13 19:37:37.322: INFO: sonobuoy from sonobuoy started at 2019-12-13 17:42:49 +0000 UTC (1 container statuses recorded)
Dec 13 19:37:37.322: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 13 19:37:37.322: INFO: coredns-6cf786c879-zgnqd from kube-system started at 2019-12-12 19:44:20 +0000 UTC (1 container statuses recorded)
Dec 13 19:37:37.322: INFO: 	Container coredns ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-3f70532e-b77b-4e62-aab9-b243d7e02e87 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-3f70532e-b77b-4e62-aab9-b243d7e02e87 off the node 172.160.134.165
STEP: verifying the node doesn't have the label kubernetes.io/e2e-3f70532e-b77b-4e62-aab9-b243d7e02e87
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:38:01.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4776" for this suite.
Dec 13 19:38:09.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:38:09.435: INFO: namespace sched-pred-4776 deletion completed in 8.046202866s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:32.151 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:38:09.435: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-62f3c910-3335-4969-b08d-06e0a3fc8746
STEP: Creating secret with name s-test-opt-upd-fec0e71c-bb64-46b1-b0d2-28692558153e
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-62f3c910-3335-4969-b08d-06e0a3fc8746
STEP: Updating secret s-test-opt-upd-fec0e71c-bb64-46b1-b0d2-28692558153e
STEP: Creating secret with name s-test-opt-create-7a427549-5481-4ade-8b46-ceb35b123dd1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:38:19.526: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1188" for this suite.
Dec 13 19:38:31.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:38:31.577: INFO: namespace projected-1188 deletion completed in 12.048648063s

• [SLOW TEST:22.142 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:38:31.577: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 13 19:38:31.606: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8b72cc8e-6809-4a8e-8b19-86b0d76530f2" in namespace "projected-2265" to be "success or failure"
Dec 13 19:38:31.607: INFO: Pod "downwardapi-volume-8b72cc8e-6809-4a8e-8b19-86b0d76530f2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.349074ms
Dec 13 19:38:33.610: INFO: Pod "downwardapi-volume-8b72cc8e-6809-4a8e-8b19-86b0d76530f2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003724129s
Dec 13 19:38:35.612: INFO: Pod "downwardapi-volume-8b72cc8e-6809-4a8e-8b19-86b0d76530f2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006195625s
Dec 13 19:38:37.615: INFO: Pod "downwardapi-volume-8b72cc8e-6809-4a8e-8b19-86b0d76530f2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008475118s
STEP: Saw pod success
Dec 13 19:38:37.615: INFO: Pod "downwardapi-volume-8b72cc8e-6809-4a8e-8b19-86b0d76530f2" satisfied condition "success or failure"
Dec 13 19:38:37.616: INFO: Trying to get logs from node 172.160.134.165 pod downwardapi-volume-8b72cc8e-6809-4a8e-8b19-86b0d76530f2 container client-container: <nil>
STEP: delete the pod
Dec 13 19:38:37.628: INFO: Waiting for pod downwardapi-volume-8b72cc8e-6809-4a8e-8b19-86b0d76530f2 to disappear
Dec 13 19:38:37.633: INFO: Pod downwardapi-volume-8b72cc8e-6809-4a8e-8b19-86b0d76530f2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:38:37.633: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2265" for this suite.
Dec 13 19:38:43.640: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:38:43.686: INFO: namespace projected-2265 deletion completed in 6.051306406s

• [SLOW TEST:12.108 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:38:43.686: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 13 19:38:44.999: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 13 19:38:47.005: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862725, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862725, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862725, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862724, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:38:49.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862725, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862725, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862725, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862724, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:38:51.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862725, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862725, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862725, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862724, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:38:53.007: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862725, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862725, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862725, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862724, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 13 19:38:56.014: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:38:56.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9946" for this suite.
Dec 13 19:39:02.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:39:02.221: INFO: namespace webhook-9946 deletion completed in 6.063156768s
STEP: Destroying namespace "webhook-9946-markers" for this suite.
Dec 13 19:39:08.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:39:08.269: INFO: namespace webhook-9946-markers deletion completed in 6.048063876s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.589 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:39:08.275: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 13 19:39:16.821: INFO: Successfully updated pod "annotationupdatefd641120-a73f-4579-9f70-fa69b0a42a26"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:39:18.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2846" for this suite.
Dec 13 19:39:30.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:39:30.915: INFO: namespace projected-2846 deletion completed in 12.046449633s

• [SLOW TEST:22.641 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:39:30.916: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 13 19:39:31.855: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 13 19:39:33.864: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862771, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862771, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862771, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862771, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:39:35.866: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862771, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862771, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862771, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862771, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 13 19:39:38.880: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 19:39:38.882: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:39:39.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2729" for this suite.
Dec 13 19:39:45.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:39:46.027: INFO: namespace webhook-2729 deletion completed in 6.045424921s
STEP: Destroying namespace "webhook-2729-markers" for this suite.
Dec 13 19:39:52.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:39:52.076: INFO: namespace webhook-2729-markers deletion completed in 6.048559232s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:21.167 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:39:52.083: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 13 19:39:57.122: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:39:57.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7897" for this suite.
Dec 13 19:40:03.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:40:03.186: INFO: namespace container-runtime-7897 deletion completed in 6.051995646s

• [SLOW TEST:11.103 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:40:03.188: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename taint-single-pod
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Dec 13 19:40:03.226: INFO: Waiting up to 1m0s for all nodes to be ready
Dec 13 19:41:03.236: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 19:41:03.238: INFO: Starting informer...
STEP: Starting pod...
Dec 13 19:41:03.446: INFO: Pod is running on 172.160.134.165. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Dec 13 19:41:03.453: INFO: Pod wasn't evicted. Proceeding
Dec 13 19:41:03.453: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Dec 13 19:42:18.461: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:42:18.461: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-7030" for this suite.
Dec 13 19:42:30.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:42:30.512: INFO: namespace taint-single-pod-7030 deletion completed in 12.047051641s

• [SLOW TEST:147.323 seconds]
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:42:30.512: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-bbc5d3dd-1a91-410f-bfcf-bdbdb6b39b0a
STEP: Creating a pod to test consume secrets
Dec 13 19:42:30.563: INFO: Waiting up to 5m0s for pod "pod-secrets-a7e58f3b-f196-4a4b-9382-194804623bbe" in namespace "secrets-7933" to be "success or failure"
Dec 13 19:42:30.566: INFO: Pod "pod-secrets-a7e58f3b-f196-4a4b-9382-194804623bbe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.311394ms
Dec 13 19:42:32.568: INFO: Pod "pod-secrets-a7e58f3b-f196-4a4b-9382-194804623bbe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0046902s
Dec 13 19:42:34.570: INFO: Pod "pod-secrets-a7e58f3b-f196-4a4b-9382-194804623bbe": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007136175s
Dec 13 19:42:36.573: INFO: Pod "pod-secrets-a7e58f3b-f196-4a4b-9382-194804623bbe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.009695815s
STEP: Saw pod success
Dec 13 19:42:36.573: INFO: Pod "pod-secrets-a7e58f3b-f196-4a4b-9382-194804623bbe" satisfied condition "success or failure"
Dec 13 19:42:36.575: INFO: Trying to get logs from node 172.160.134.165 pod pod-secrets-a7e58f3b-f196-4a4b-9382-194804623bbe container secret-volume-test: <nil>
STEP: delete the pod
Dec 13 19:42:36.598: INFO: Waiting for pod pod-secrets-a7e58f3b-f196-4a4b-9382-194804623bbe to disappear
Dec 13 19:42:36.599: INFO: Pod pod-secrets-a7e58f3b-f196-4a4b-9382-194804623bbe no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:42:36.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7933" for this suite.
Dec 13 19:42:42.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:42:42.653: INFO: namespace secrets-7933 deletion completed in 6.05109911s
STEP: Destroying namespace "secret-namespace-4783" for this suite.
Dec 13 19:42:48.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:42:48.702: INFO: namespace secret-namespace-4783 deletion completed in 6.049369847s

• [SLOW TEST:18.191 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:42:48.703: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Dec 13 19:42:48.732: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 create -f - --namespace=kubectl-7794'
Dec 13 19:42:49.477: INFO: stderr: ""
Dec 13 19:42:49.477: INFO: stdout: "pod/pause created\n"
Dec 13 19:42:49.478: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec 13 19:42:49.478: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-7794" to be "running and ready"
Dec 13 19:42:49.484: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 5.80326ms
Dec 13 19:42:51.486: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007861759s
Dec 13 19:42:53.488: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010044692s
Dec 13 19:42:55.490: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012342343s
Dec 13 19:42:57.492: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 8.014423626s
Dec 13 19:42:57.492: INFO: Pod "pause" satisfied condition "running and ready"
Dec 13 19:42:57.492: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Dec 13 19:42:57.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 label pods pause testing-label=testing-label-value --namespace=kubectl-7794'
Dec 13 19:42:57.597: INFO: stderr: ""
Dec 13 19:42:57.597: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec 13 19:42:57.597: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pod pause -L testing-label --namespace=kubectl-7794'
Dec 13 19:42:57.699: INFO: stderr: ""
Dec 13 19:42:57.699: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          8s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec 13 19:42:57.699: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 label pods pause testing-label- --namespace=kubectl-7794'
Dec 13 19:42:57.804: INFO: stderr: ""
Dec 13 19:42:57.804: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec 13 19:42:57.804: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pod pause -L testing-label --namespace=kubectl-7794'
Dec 13 19:42:57.910: INFO: stderr: ""
Dec 13 19:42:57.910: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          8s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Dec 13 19:42:57.910: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 delete --grace-period=0 --force -f - --namespace=kubectl-7794'
Dec 13 19:42:58.019: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 13 19:42:58.019: INFO: stdout: "pod \"pause\" force deleted\n"
Dec 13 19:42:58.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get rc,svc -l name=pause --no-headers --namespace=kubectl-7794'
Dec 13 19:42:58.126: INFO: stderr: "No resources found in kubectl-7794 namespace.\n"
Dec 13 19:42:58.126: INFO: stdout: ""
Dec 13 19:42:58.126: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 get pods -l name=pause --namespace=kubectl-7794 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 13 19:42:58.226: INFO: stderr: ""
Dec 13 19:42:58.226: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:42:58.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7794" for this suite.
Dec 13 19:43:04.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:43:04.274: INFO: namespace kubectl-7794 deletion completed in 6.046547949s

• [SLOW TEST:15.572 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:43:04.275: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 13 19:43:04.301: INFO: Waiting up to 5m0s for pod "downward-api-4080f08f-e19b-4f78-9b35-277d8bc63edf" in namespace "downward-api-4667" to be "success or failure"
Dec 13 19:43:04.313: INFO: Pod "downward-api-4080f08f-e19b-4f78-9b35-277d8bc63edf": Phase="Pending", Reason="", readiness=false. Elapsed: 12.231013ms
Dec 13 19:43:06.316: INFO: Pod "downward-api-4080f08f-e19b-4f78-9b35-277d8bc63edf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014570891s
Dec 13 19:43:08.318: INFO: Pod "downward-api-4080f08f-e19b-4f78-9b35-277d8bc63edf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.016915996s
Dec 13 19:43:10.320: INFO: Pod "downward-api-4080f08f-e19b-4f78-9b35-277d8bc63edf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.018825272s
STEP: Saw pod success
Dec 13 19:43:10.320: INFO: Pod "downward-api-4080f08f-e19b-4f78-9b35-277d8bc63edf" satisfied condition "success or failure"
Dec 13 19:43:10.321: INFO: Trying to get logs from node 172.160.134.165 pod downward-api-4080f08f-e19b-4f78-9b35-277d8bc63edf container dapi-container: <nil>
STEP: delete the pod
Dec 13 19:43:10.337: INFO: Waiting for pod downward-api-4080f08f-e19b-4f78-9b35-277d8bc63edf to disappear
Dec 13 19:43:10.338: INFO: Pod downward-api-4080f08f-e19b-4f78-9b35-277d8bc63edf no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:43:10.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4667" for this suite.
Dec 13 19:43:16.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:43:16.388: INFO: namespace downward-api-4667 deletion completed in 6.047877629s

• [SLOW TEST:12.113 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:43:16.388: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 13 19:43:16.905: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 13 19:43:18.911: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862996, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862996, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862996, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862996, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:43:20.913: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862996, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862996, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862996, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711862996, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 13 19:43:23.920: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Dec 13 19:43:23.939: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:43:23.950: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7213" for this suite.
Dec 13 19:43:29.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:43:30.000: INFO: namespace webhook-7213 deletion completed in 6.047157256s
STEP: Destroying namespace "webhook-7213-markers" for this suite.
Dec 13 19:43:36.007: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:43:36.045: INFO: namespace webhook-7213-markers deletion completed in 6.044925381s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.663 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:43:36.051: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 13 19:43:36.074: INFO: Waiting up to 5m0s for pod "downwardapi-volume-cdc2dc31-0829-4025-b4d5-9bb180be34dd" in namespace "downward-api-9561" to be "success or failure"
Dec 13 19:43:36.077: INFO: Pod "downwardapi-volume-cdc2dc31-0829-4025-b4d5-9bb180be34dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.668565ms
Dec 13 19:43:38.079: INFO: Pod "downwardapi-volume-cdc2dc31-0829-4025-b4d5-9bb180be34dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004995634s
Dec 13 19:43:40.083: INFO: Pod "downwardapi-volume-cdc2dc31-0829-4025-b4d5-9bb180be34dd": Phase="Pending", Reason="", readiness=false. Elapsed: 4.008251723s
Dec 13 19:43:42.085: INFO: Pod "downwardapi-volume-cdc2dc31-0829-4025-b4d5-9bb180be34dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.010311115s
STEP: Saw pod success
Dec 13 19:43:42.085: INFO: Pod "downwardapi-volume-cdc2dc31-0829-4025-b4d5-9bb180be34dd" satisfied condition "success or failure"
Dec 13 19:43:42.086: INFO: Trying to get logs from node 172.160.134.165 pod downwardapi-volume-cdc2dc31-0829-4025-b4d5-9bb180be34dd container client-container: <nil>
STEP: delete the pod
Dec 13 19:43:42.099: INFO: Waiting for pod downwardapi-volume-cdc2dc31-0829-4025-b4d5-9bb180be34dd to disappear
Dec 13 19:43:42.105: INFO: Pod downwardapi-volume-cdc2dc31-0829-4025-b4d5-9bb180be34dd no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:43:42.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9561" for this suite.
Dec 13 19:43:48.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:43:48.157: INFO: namespace downward-api-9561 deletion completed in 6.050372379s

• [SLOW TEST:12.105 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:43:48.157: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:43:56.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1004" for this suite.
Dec 13 19:44:40.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:44:40.267: INFO: namespace kubelet-test-1004 deletion completed in 44.052527792s

• [SLOW TEST:52.111 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:44:40.268: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Dec 13 19:44:40.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 api-versions'
Dec 13 19:44:40.400: INFO: stderr: ""
Dec 13 19:44:40.400: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1alpha1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:44:40.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5919" for this suite.
Dec 13 19:44:46.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:44:46.451: INFO: namespace kubectl-5919 deletion completed in 6.048407665s

• [SLOW TEST:6.184 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:44:46.452: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 13 19:44:46.479: INFO: Waiting up to 5m0s for pod "downwardapi-volume-998da441-4ec3-477c-9944-d83fed6f703d" in namespace "downward-api-9970" to be "success or failure"
Dec 13 19:44:46.480: INFO: Pod "downwardapi-volume-998da441-4ec3-477c-9944-d83fed6f703d": Phase="Pending", Reason="", readiness=false. Elapsed: 1.423246ms
Dec 13 19:44:48.483: INFO: Pod "downwardapi-volume-998da441-4ec3-477c-9944-d83fed6f703d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003673037s
Dec 13 19:44:50.485: INFO: Pod "downwardapi-volume-998da441-4ec3-477c-9944-d83fed6f703d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006154304s
Dec 13 19:44:52.487: INFO: Pod "downwardapi-volume-998da441-4ec3-477c-9944-d83fed6f703d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008427763s
STEP: Saw pod success
Dec 13 19:44:52.487: INFO: Pod "downwardapi-volume-998da441-4ec3-477c-9944-d83fed6f703d" satisfied condition "success or failure"
Dec 13 19:44:52.489: INFO: Trying to get logs from node 172.160.134.165 pod downwardapi-volume-998da441-4ec3-477c-9944-d83fed6f703d container client-container: <nil>
STEP: delete the pod
Dec 13 19:44:52.511: INFO: Waiting for pod downwardapi-volume-998da441-4ec3-477c-9944-d83fed6f703d to disappear
Dec 13 19:44:52.515: INFO: Pod downwardapi-volume-998da441-4ec3-477c-9944-d83fed6f703d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:44:52.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9970" for this suite.
Dec 13 19:44:58.524: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:44:58.567: INFO: namespace downward-api-9970 deletion completed in 6.05042644s

• [SLOW TEST:12.115 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:44:58.568: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec 13 19:45:07.609: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:45:08.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9991" for this suite.
Dec 13 19:45:20.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:45:20.664: INFO: namespace replicaset-9991 deletion completed in 12.045961433s

• [SLOW TEST:22.097 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:45:20.665: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 19:45:20.693: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 13 19:45:25.289: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 --namespace=crd-publish-openapi-687 create -f -'
Dec 13 19:45:25.945: INFO: stderr: ""
Dec 13 19:45:25.945: INFO: stdout: "e2e-test-crd-publish-openapi-5168-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 13 19:45:25.945: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 --namespace=crd-publish-openapi-687 delete e2e-test-crd-publish-openapi-5168-crds test-cr'
Dec 13 19:45:26.059: INFO: stderr: ""
Dec 13 19:45:26.059: INFO: stdout: "e2e-test-crd-publish-openapi-5168-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Dec 13 19:45:26.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 --namespace=crd-publish-openapi-687 apply -f -'
Dec 13 19:45:26.297: INFO: stderr: ""
Dec 13 19:45:26.297: INFO: stdout: "e2e-test-crd-publish-openapi-5168-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 13 19:45:26.297: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 --namespace=crd-publish-openapi-687 delete e2e-test-crd-publish-openapi-5168-crds test-cr'
Dec 13 19:45:26.407: INFO: stderr: ""
Dec 13 19:45:26.407: INFO: stdout: "e2e-test-crd-publish-openapi-5168-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec 13 19:45:26.407: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 explain e2e-test-crd-publish-openapi-5168-crds'
Dec 13 19:45:26.630: INFO: stderr: ""
Dec 13 19:45:26.630: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5168-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:45:31.167: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-687" for this suite.
Dec 13 19:45:37.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:45:37.214: INFO: namespace crd-publish-openapi-687 deletion completed in 6.044832359s

• [SLOW TEST:16.549 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:45:37.214: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 19:45:37.248: INFO: Create a RollingUpdate DaemonSet
Dec 13 19:45:37.250: INFO: Check that daemon pods launch on every node of the cluster
Dec 13 19:45:37.256: INFO: Number of nodes with available pods: 0
Dec 13 19:45:37.256: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:45:38.260: INFO: Number of nodes with available pods: 0
Dec 13 19:45:38.260: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:45:39.260: INFO: Number of nodes with available pods: 0
Dec 13 19:45:39.260: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:45:40.260: INFO: Number of nodes with available pods: 0
Dec 13 19:45:40.260: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:45:41.260: INFO: Number of nodes with available pods: 0
Dec 13 19:45:41.260: INFO: Node 172.160.134.165 is running more than one daemon pod
Dec 13 19:45:42.260: INFO: Number of nodes with available pods: 1
Dec 13 19:45:42.260: INFO: Node 172.160.134.166 is running more than one daemon pod
Dec 13 19:45:43.260: INFO: Number of nodes with available pods: 1
Dec 13 19:45:43.260: INFO: Node 172.160.134.166 is running more than one daemon pod
Dec 13 19:45:44.437: INFO: Number of nodes with available pods: 2
Dec 13 19:45:44.437: INFO: Number of running nodes: 2, number of available pods: 2
Dec 13 19:45:44.437: INFO: Update the DaemonSet to trigger a rollout
Dec 13 19:45:44.442: INFO: Updating DaemonSet daemon-set
Dec 13 19:45:49.455: INFO: Roll back the DaemonSet before rollout is complete
Dec 13 19:45:49.459: INFO: Updating DaemonSet daemon-set
Dec 13 19:45:49.459: INFO: Make sure DaemonSet rollback is complete
Dec 13 19:45:49.471: INFO: Wrong image for pod: daemon-set-6zpwl. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 13 19:45:49.471: INFO: Pod daemon-set-6zpwl is not available
Dec 13 19:45:50.479: INFO: Pod daemon-set-nxgp5 is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3767, will wait for the garbage collector to delete the pods
Dec 13 19:45:50.539: INFO: Deleting DaemonSet.extensions daemon-set took: 3.192449ms
Dec 13 19:45:50.839: INFO: Terminating DaemonSet.extensions daemon-set pods took: 300.171235ms
Dec 13 19:45:53.141: INFO: Number of nodes with available pods: 0
Dec 13 19:45:53.141: INFO: Number of running nodes: 0, number of available pods: 0
Dec 13 19:45:53.142: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3767/daemonsets","resourceVersion":"134695"},"items":null}

Dec 13 19:45:53.143: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3767/pods","resourceVersion":"134695"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:45:53.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3767" for this suite.
Dec 13 19:45:59.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:45:59.193: INFO: namespace daemonsets-3767 deletion completed in 6.044386155s

• [SLOW TEST:21.978 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:45:59.193: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec 13 19:45:59.230: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6926 /api/v1/namespaces/watch-6926/configmaps/e2e-watch-test-label-changed 9bd91723-cfd2-4299-8e37-a5001408cb61 134726 0 2019-12-13 19:45:59 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 13 19:45:59.230: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6926 /api/v1/namespaces/watch-6926/configmaps/e2e-watch-test-label-changed 9bd91723-cfd2-4299-8e37-a5001408cb61 134727 0 2019-12-13 19:45:59 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 13 19:45:59.230: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6926 /api/v1/namespaces/watch-6926/configmaps/e2e-watch-test-label-changed 9bd91723-cfd2-4299-8e37-a5001408cb61 134728 0 2019-12-13 19:45:59 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec 13 19:46:09.247: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6926 /api/v1/namespaces/watch-6926/configmaps/e2e-watch-test-label-changed 9bd91723-cfd2-4299-8e37-a5001408cb61 134737 0 2019-12-13 19:45:59 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 13 19:46:09.247: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6926 /api/v1/namespaces/watch-6926/configmaps/e2e-watch-test-label-changed 9bd91723-cfd2-4299-8e37-a5001408cb61 134738 0 2019-12-13 19:45:59 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec 13 19:46:09.247: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6926 /api/v1/namespaces/watch-6926/configmaps/e2e-watch-test-label-changed 9bd91723-cfd2-4299-8e37-a5001408cb61 134739 0 2019-12-13 19:45:59 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:46:09.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6926" for this suite.
Dec 13 19:46:15.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:46:15.300: INFO: namespace watch-6926 deletion completed in 6.049427437s

• [SLOW TEST:16.107 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:46:15.300: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 19:46:15.330: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:46:21.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3348" for this suite.
Dec 13 19:46:27.501: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:46:27.545: INFO: namespace custom-resource-definition-3348 deletion completed in 6.051961905s

• [SLOW TEST:12.245 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:46:27.547: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 13 19:46:27.576: INFO: Waiting up to 5m0s for pod "pod-84f6c885-3faf-498e-8f72-47f06a19eaab" in namespace "emptydir-6108" to be "success or failure"
Dec 13 19:46:27.579: INFO: Pod "pod-84f6c885-3faf-498e-8f72-47f06a19eaab": Phase="Pending", Reason="", readiness=false. Elapsed: 3.280735ms
Dec 13 19:46:29.582: INFO: Pod "pod-84f6c885-3faf-498e-8f72-47f06a19eaab": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005620642s
Dec 13 19:46:31.584: INFO: Pod "pod-84f6c885-3faf-498e-8f72-47f06a19eaab": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007668159s
Dec 13 19:46:33.586: INFO: Pod "pod-84f6c885-3faf-498e-8f72-47f06a19eaab": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009638431s
Dec 13 19:46:35.588: INFO: Pod "pod-84f6c885-3faf-498e-8f72-47f06a19eaab": Phase="Pending", Reason="", readiness=false. Elapsed: 8.012250443s
Dec 13 19:46:37.591: INFO: Pod "pod-84f6c885-3faf-498e-8f72-47f06a19eaab": Phase="Pending", Reason="", readiness=false. Elapsed: 10.014573074s
Dec 13 19:46:39.593: INFO: Pod "pod-84f6c885-3faf-498e-8f72-47f06a19eaab": Phase="Pending", Reason="", readiness=false. Elapsed: 12.016993843s
Dec 13 19:46:41.595: INFO: Pod "pod-84f6c885-3faf-498e-8f72-47f06a19eaab": Phase="Pending", Reason="", readiness=false. Elapsed: 14.018847317s
Dec 13 19:46:43.597: INFO: Pod "pod-84f6c885-3faf-498e-8f72-47f06a19eaab": Phase="Pending", Reason="", readiness=false. Elapsed: 16.021013177s
Dec 13 19:46:45.599: INFO: Pod "pod-84f6c885-3faf-498e-8f72-47f06a19eaab": Phase="Pending", Reason="", readiness=false. Elapsed: 18.0233529s
Dec 13 19:46:47.602: INFO: Pod "pod-84f6c885-3faf-498e-8f72-47f06a19eaab": Phase="Pending", Reason="", readiness=false. Elapsed: 20.02561041s
Dec 13 19:46:49.604: INFO: Pod "pod-84f6c885-3faf-498e-8f72-47f06a19eaab": Phase="Pending", Reason="", readiness=false. Elapsed: 22.028001622s
Dec 13 19:46:51.606: INFO: Pod "pod-84f6c885-3faf-498e-8f72-47f06a19eaab": Phase="Pending", Reason="", readiness=false. Elapsed: 24.030212368s
Dec 13 19:46:53.609: INFO: Pod "pod-84f6c885-3faf-498e-8f72-47f06a19eaab": Phase="Succeeded", Reason="", readiness=false. Elapsed: 26.032411287s
STEP: Saw pod success
Dec 13 19:46:53.609: INFO: Pod "pod-84f6c885-3faf-498e-8f72-47f06a19eaab" satisfied condition "success or failure"
Dec 13 19:46:53.610: INFO: Trying to get logs from node 172.160.134.165 pod pod-84f6c885-3faf-498e-8f72-47f06a19eaab container test-container: <nil>
STEP: delete the pod
Dec 13 19:46:53.629: INFO: Waiting for pod pod-84f6c885-3faf-498e-8f72-47f06a19eaab to disappear
Dec 13 19:46:53.634: INFO: Pod pod-84f6c885-3faf-498e-8f72-47f06a19eaab no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:46:53.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6108" for this suite.
Dec 13 19:46:59.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:46:59.684: INFO: namespace emptydir-6108 deletion completed in 6.049336104s

• [SLOW TEST:32.138 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:46:59.685: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-65f44ce0-3a88-4985-90c2-49e1e21bffde
STEP: Creating a pod to test consume configMaps
Dec 13 19:46:59.722: INFO: Waiting up to 5m0s for pod "pod-configmaps-ba088241-e54c-498d-9626-eaec1d4b571f" in namespace "configmap-5451" to be "success or failure"
Dec 13 19:46:59.727: INFO: Pod "pod-configmaps-ba088241-e54c-498d-9626-eaec1d4b571f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.886079ms
Dec 13 19:47:01.730: INFO: Pod "pod-configmaps-ba088241-e54c-498d-9626-eaec1d4b571f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007398977s
Dec 13 19:47:03.732: INFO: Pod "pod-configmaps-ba088241-e54c-498d-9626-eaec1d4b571f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009433658s
Dec 13 19:47:05.734: INFO: Pod "pod-configmaps-ba088241-e54c-498d-9626-eaec1d4b571f": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011638828s
Dec 13 19:47:07.736: INFO: Pod "pod-configmaps-ba088241-e54c-498d-9626-eaec1d4b571f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.013788319s
STEP: Saw pod success
Dec 13 19:47:07.736: INFO: Pod "pod-configmaps-ba088241-e54c-498d-9626-eaec1d4b571f" satisfied condition "success or failure"
Dec 13 19:47:07.738: INFO: Trying to get logs from node 172.160.134.166 pod pod-configmaps-ba088241-e54c-498d-9626-eaec1d4b571f container configmap-volume-test: <nil>
STEP: delete the pod
Dec 13 19:47:07.760: INFO: Waiting for pod pod-configmaps-ba088241-e54c-498d-9626-eaec1d4b571f to disappear
Dec 13 19:47:07.773: INFO: Pod pod-configmaps-ba088241-e54c-498d-9626-eaec1d4b571f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:47:07.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5451" for this suite.
Dec 13 19:47:13.787: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:47:13.828: INFO: namespace configmap-5451 deletion completed in 6.049134815s

• [SLOW TEST:14.143 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:47:13.828: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 13 19:47:13.856: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 version'
Dec 13 19:47:13.954: INFO: stderr: ""
Dec 13 19:47:13.955: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.1\", GitCommit:\"d647ddbd755faf07169599a625faf302ffc34458\", GitTreeState:\"clean\", BuildDate:\"2019-10-02T17:01:15Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.1\", GitCommit:\"57112d2a7d58d1d48204f5096a22babae8403646\", GitTreeState:\"archive\", BuildDate:\"2019-12-05T07:06:30Z\", GoVersion:\"go1.12.13\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:47:13.955: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-67" for this suite.
Dec 13 19:47:19.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:47:20.000: INFO: namespace kubectl-67 deletion completed in 6.043488405s

• [SLOW TEST:6.172 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:47:20.000: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 13 19:47:20.024: INFO: Waiting up to 5m0s for pod "downwardapi-volume-022ba969-0aac-432a-a23b-4fc794f50369" in namespace "downward-api-3422" to be "success or failure"
Dec 13 19:47:20.026: INFO: Pod "downwardapi-volume-022ba969-0aac-432a-a23b-4fc794f50369": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035879ms
Dec 13 19:47:22.029: INFO: Pod "downwardapi-volume-022ba969-0aac-432a-a23b-4fc794f50369": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004479005s
Dec 13 19:47:24.031: INFO: Pod "downwardapi-volume-022ba969-0aac-432a-a23b-4fc794f50369": Phase="Pending", Reason="", readiness=false. Elapsed: 4.007206088s
Dec 13 19:47:26.034: INFO: Pod "downwardapi-volume-022ba969-0aac-432a-a23b-4fc794f50369": Phase="Pending", Reason="", readiness=false. Elapsed: 6.009490958s
Dec 13 19:47:28.036: INFO: Pod "downwardapi-volume-022ba969-0aac-432a-a23b-4fc794f50369": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.011721657s
STEP: Saw pod success
Dec 13 19:47:28.036: INFO: Pod "downwardapi-volume-022ba969-0aac-432a-a23b-4fc794f50369" satisfied condition "success or failure"
Dec 13 19:47:28.037: INFO: Trying to get logs from node 172.160.134.166 pod downwardapi-volume-022ba969-0aac-432a-a23b-4fc794f50369 container client-container: <nil>
STEP: delete the pod
Dec 13 19:47:28.048: INFO: Waiting for pod downwardapi-volume-022ba969-0aac-432a-a23b-4fc794f50369 to disappear
Dec 13 19:47:28.052: INFO: Pod downwardapi-volume-022ba969-0aac-432a-a23b-4fc794f50369 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:47:28.052: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3422" for this suite.
Dec 13 19:47:34.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:47:34.106: INFO: namespace downward-api-3422 deletion completed in 6.052174371s

• [SLOW TEST:14.106 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:47:34.106: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:47:43.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2667" for this suite.
Dec 13 19:47:55.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:47:55.198: INFO: namespace replication-controller-2667 deletion completed in 12.048651942s

• [SLOW TEST:21.091 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:47:55.199: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Dec 13 19:47:55.228: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-2559" to be "success or failure"
Dec 13 19:47:55.234: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.471765ms
Dec 13 19:47:57.237: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008545352s
Dec 13 19:47:59.239: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010701419s
Dec 13 19:48:01.241: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012898929s
Dec 13 19:48:03.243: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.015166592s
STEP: Saw pod success
Dec 13 19:48:03.243: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec 13 19:48:03.245: INFO: Trying to get logs from node 172.160.134.166 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec 13 19:48:03.267: INFO: Waiting for pod pod-host-path-test to disappear
Dec 13 19:48:03.271: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:48:03.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-2559" for this suite.
Dec 13 19:48:09.285: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:48:09.328: INFO: namespace hostpath-2559 deletion completed in 6.055304199s

• [SLOW TEST:14.129 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:48:09.328: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
W1213 19:48:10.374219      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 13 19:48:10.374: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:48:10.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5709" for this suite.
Dec 13 19:48:16.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:48:16.426: INFO: namespace gc-5709 deletion completed in 6.05012774s

• [SLOW TEST:7.098 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:48:16.426: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 13 19:48:17.122: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 13 19:48:19.128: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863297, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863297, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863297, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863297, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:48:21.130: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863297, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863297, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863297, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863297, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 13 19:48:24.136: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:48:36.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3898" for this suite.
Dec 13 19:48:42.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:48:42.272: INFO: namespace webhook-3898 deletion completed in 6.046641171s
STEP: Destroying namespace "webhook-3898-markers" for this suite.
Dec 13 19:48:48.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:48:48.323: INFO: namespace webhook-3898-markers deletion completed in 6.050379797s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:31.903 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:48:48.330: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 13 19:49:02.388: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 13 19:49:02.390: INFO: Pod pod-with-poststart-http-hook still exists
Dec 13 19:49:04.390: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 13 19:49:04.393: INFO: Pod pod-with-poststart-http-hook still exists
Dec 13 19:49:06.390: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 13 19:49:06.393: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:49:06.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-96" for this suite.
Dec 13 19:49:18.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:49:18.443: INFO: namespace container-lifecycle-hook-96 deletion completed in 12.048063949s

• [SLOW TEST:30.113 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:49:18.443: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1156
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-1156
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-1156
Dec 13 19:49:18.471: INFO: Found 0 stateful pods, waiting for 1
Dec 13 19:49:28.474: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec 13 19:49:28.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=statefulset-1156 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 13 19:49:28.654: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 13 19:49:28.654: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 13 19:49:28.654: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 13 19:49:28.656: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 13 19:49:38.659: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 13 19:49:38.659: INFO: Waiting for statefulset status.replicas updated to 0
Dec 13 19:49:38.667: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999509s
Dec 13 19:49:39.669: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996605515s
Dec 13 19:49:40.672: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.994454783s
Dec 13 19:49:41.675: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.991900824s
Dec 13 19:49:42.677: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.989333823s
Dec 13 19:49:43.680: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.986793947s
Dec 13 19:49:44.684: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.98422694s
Dec 13 19:49:45.686: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.9803647s
Dec 13 19:49:46.689: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.977578195s
Dec 13 19:49:47.691: INFO: Verifying statefulset ss doesn't scale past 1 for another 975.33679ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-1156
Dec 13 19:49:48.694: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=statefulset-1156 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 13 19:49:48.864: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 13 19:49:48.864: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 13 19:49:48.864: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 13 19:49:48.866: INFO: Found 1 stateful pods, waiting for 3
Dec 13 19:49:58.869: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 13 19:49:58.869: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 13 19:49:58.869: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Pending - Ready=false
Dec 13 19:50:08.869: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 13 19:50:08.869: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 13 19:50:08.869: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec 13 19:50:08.872: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=statefulset-1156 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 13 19:50:09.052: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 13 19:50:09.052: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 13 19:50:09.052: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 13 19:50:09.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=statefulset-1156 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 13 19:50:09.310: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 13 19:50:09.310: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 13 19:50:09.310: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 13 19:50:09.310: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=statefulset-1156 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 13 19:50:09.808: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 13 19:50:09.808: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 13 19:50:09.808: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 13 19:50:09.808: INFO: Waiting for statefulset status.replicas updated to 0
Dec 13 19:50:09.810: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec 13 19:50:19.815: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 13 19:50:19.815: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 13 19:50:19.815: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 13 19:50:19.821: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999584s
Dec 13 19:50:20.823: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997823727s
Dec 13 19:50:21.826: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.995201521s
Dec 13 19:50:22.828: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.992486834s
Dec 13 19:50:23.831: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.98998517s
Dec 13 19:50:24.834: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.987285644s
Dec 13 19:50:25.836: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.984607335s
Dec 13 19:50:26.839: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.981855705s
Dec 13 19:50:27.842: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.978984056s
Dec 13 19:50:28.844: INFO: Verifying statefulset ss doesn't scale past 3 for another 976.350557ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-1156
Dec 13 19:50:29.847: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=statefulset-1156 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 13 19:50:30.017: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 13 19:50:30.017: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 13 19:50:30.017: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 13 19:50:30.018: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=statefulset-1156 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 13 19:50:30.402: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 13 19:50:30.402: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 13 19:50:30.402: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 13 19:50:30.402: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 exec --namespace=statefulset-1156 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 13 19:50:30.756: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 13 19:50:30.756: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 13 19:50:30.756: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 13 19:50:30.756: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 13 19:50:40.766: INFO: Deleting all statefulset in ns statefulset-1156
Dec 13 19:50:40.767: INFO: Scaling statefulset ss to 0
Dec 13 19:50:40.771: INFO: Waiting for statefulset status.replicas updated to 0
Dec 13 19:50:40.773: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:50:40.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1156" for this suite.
Dec 13 19:50:46.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:50:46.824: INFO: namespace statefulset-1156 deletion completed in 6.043856825s

• [SLOW TEST:88.380 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:50:46.825: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-55f45604-7931-4405-8c40-1d1128d039aa
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:50:46.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1944" for this suite.
Dec 13 19:50:52.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:50:52.897: INFO: namespace configmap-1944 deletion completed in 6.046565525s

• [SLOW TEST:6.072 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:50:52.897: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3020.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-3020.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3020.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-3020.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-3020.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3020.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 13 19:51:24.951: INFO: DNS probes using dns-3020/dns-test-82b57124-533f-445d-a1dc-b920c7eec8b7 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:51:24.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3020" for this suite.
Dec 13 19:51:30.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:51:31.023: INFO: namespace dns-3020 deletion completed in 6.051065756s

• [SLOW TEST:38.126 seconds]
[sig-network] DNS
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:51:31.023: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 13 19:51:37.561: INFO: Successfully updated pod "pod-update-21ba1f3d-dee8-44ba-9caa-b74bbca33aa9"
STEP: verifying the updated pod is in kubernetes
Dec 13 19:51:37.567: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:51:37.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1025" for this suite.
Dec 13 19:51:49.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:51:49.616: INFO: namespace pods-1025 deletion completed in 12.047947099s

• [SLOW TEST:18.594 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:51:49.617: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-875ecbc6-f3f8-40d1-bf6e-a0bf05017b0d
STEP: Creating a pod to test consume configMaps
Dec 13 19:51:49.648: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-55670200-9ab2-4d02-a6d7-86d80f3f127b" in namespace "projected-7638" to be "success or failure"
Dec 13 19:51:49.650: INFO: Pod "pod-projected-configmaps-55670200-9ab2-4d02-a6d7-86d80f3f127b": Phase="Pending", Reason="", readiness=false. Elapsed: 1.826334ms
Dec 13 19:51:51.652: INFO: Pod "pod-projected-configmaps-55670200-9ab2-4d02-a6d7-86d80f3f127b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004291668s
Dec 13 19:51:53.655: INFO: Pod "pod-projected-configmaps-55670200-9ab2-4d02-a6d7-86d80f3f127b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006706592s
Dec 13 19:51:55.657: INFO: Pod "pod-projected-configmaps-55670200-9ab2-4d02-a6d7-86d80f3f127b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.00904405s
STEP: Saw pod success
Dec 13 19:51:55.657: INFO: Pod "pod-projected-configmaps-55670200-9ab2-4d02-a6d7-86d80f3f127b" satisfied condition "success or failure"
Dec 13 19:51:55.659: INFO: Trying to get logs from node 172.160.134.165 pod pod-projected-configmaps-55670200-9ab2-4d02-a6d7-86d80f3f127b container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 13 19:51:55.681: INFO: Waiting for pod pod-projected-configmaps-55670200-9ab2-4d02-a6d7-86d80f3f127b to disappear
Dec 13 19:51:55.683: INFO: Pod pod-projected-configmaps-55670200-9ab2-4d02-a6d7-86d80f3f127b no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:51:55.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7638" for this suite.
Dec 13 19:52:01.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:52:01.744: INFO: namespace projected-7638 deletion completed in 6.057490683s

• [SLOW TEST:12.127 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:52:01.744: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
W1213 19:52:41.792111      25 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 13 19:52:41.792: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:52:41.792: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5742" for this suite.
Dec 13 19:52:47.800: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:52:47.839: INFO: namespace gc-5742 deletion completed in 6.04549916s

• [SLOW TEST:46.095 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:52:47.841: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-4dbbf6b5-36d5-451b-b7af-f71a01adfb51 in namespace container-probe-9316
Dec 13 19:52:59.872: INFO: Started pod test-webserver-4dbbf6b5-36d5-451b-b7af-f71a01adfb51 in namespace container-probe-9316
STEP: checking the pod's current state and verifying that restartCount is present
Dec 13 19:52:59.873: INFO: Initial restart count of pod test-webserver-4dbbf6b5-36d5-451b-b7af-f71a01adfb51 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:57:00.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9316" for this suite.
Dec 13 19:57:06.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:57:06.219: INFO: namespace container-probe-9316 deletion completed in 6.056130154s

• [SLOW TEST:258.379 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:57:06.220: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-2ccc4a6e-3dda-4556-827e-7851a0c8c7b9
STEP: Creating a pod to test consume secrets
Dec 13 19:57:06.252: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-68a81474-92d3-4111-aec8-81aa9c1ec00d" in namespace "projected-7099" to be "success or failure"
Dec 13 19:57:06.257: INFO: Pod "pod-projected-secrets-68a81474-92d3-4111-aec8-81aa9c1ec00d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.429552ms
Dec 13 19:57:08.259: INFO: Pod "pod-projected-secrets-68a81474-92d3-4111-aec8-81aa9c1ec00d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007727661s
Dec 13 19:57:10.262: INFO: Pod "pod-projected-secrets-68a81474-92d3-4111-aec8-81aa9c1ec00d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.010093174s
Dec 13 19:57:12.264: INFO: Pod "pod-projected-secrets-68a81474-92d3-4111-aec8-81aa9c1ec00d": Phase="Pending", Reason="", readiness=false. Elapsed: 6.01247166s
Dec 13 19:57:14.266: INFO: Pod "pod-projected-secrets-68a81474-92d3-4111-aec8-81aa9c1ec00d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.014675467s
STEP: Saw pod success
Dec 13 19:57:14.267: INFO: Pod "pod-projected-secrets-68a81474-92d3-4111-aec8-81aa9c1ec00d" satisfied condition "success or failure"
Dec 13 19:57:14.268: INFO: Trying to get logs from node 172.160.134.166 pod pod-projected-secrets-68a81474-92d3-4111-aec8-81aa9c1ec00d container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 13 19:57:14.314: INFO: Waiting for pod pod-projected-secrets-68a81474-92d3-4111-aec8-81aa9c1ec00d to disappear
Dec 13 19:57:14.318: INFO: Pod pod-projected-secrets-68a81474-92d3-4111-aec8-81aa9c1ec00d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:57:14.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7099" for this suite.
Dec 13 19:57:20.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:57:20.369: INFO: namespace projected-7099 deletion completed in 6.048973067s

• [SLOW TEST:14.149 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:57:20.370: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 13 19:57:20.398: INFO: Waiting up to 5m0s for pod "downward-api-6a0a2fed-2381-4774-b26f-2015d0c5ab72" in namespace "downward-api-9183" to be "success or failure"
Dec 13 19:57:20.403: INFO: Pod "downward-api-6a0a2fed-2381-4774-b26f-2015d0c5ab72": Phase="Pending", Reason="", readiness=false. Elapsed: 5.029793ms
Dec 13 19:57:22.406: INFO: Pod "downward-api-6a0a2fed-2381-4774-b26f-2015d0c5ab72": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007614531s
Dec 13 19:57:24.408: INFO: Pod "downward-api-6a0a2fed-2381-4774-b26f-2015d0c5ab72": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009958405s
Dec 13 19:57:26.410: INFO: Pod "downward-api-6a0a2fed-2381-4774-b26f-2015d0c5ab72": Phase="Pending", Reason="", readiness=false. Elapsed: 6.011850516s
Dec 13 19:57:28.412: INFO: Pod "downward-api-6a0a2fed-2381-4774-b26f-2015d0c5ab72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.014048769s
STEP: Saw pod success
Dec 13 19:57:28.412: INFO: Pod "downward-api-6a0a2fed-2381-4774-b26f-2015d0c5ab72" satisfied condition "success or failure"
Dec 13 19:57:28.414: INFO: Trying to get logs from node 172.160.134.166 pod downward-api-6a0a2fed-2381-4774-b26f-2015d0c5ab72 container dapi-container: <nil>
STEP: delete the pod
Dec 13 19:57:28.435: INFO: Waiting for pod downward-api-6a0a2fed-2381-4774-b26f-2015d0c5ab72 to disappear
Dec 13 19:57:28.438: INFO: Pod downward-api-6a0a2fed-2381-4774-b26f-2015d0c5ab72 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:57:28.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9183" for this suite.
Dec 13 19:57:34.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:57:34.486: INFO: namespace downward-api-9183 deletion completed in 6.046433173s

• [SLOW TEST:14.117 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:57:34.487: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-3c1c1eb0-c73b-4bb6-a5cd-3fd911478e87
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:57:42.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7953" for this suite.
Dec 13 19:57:54.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:57:54.587: INFO: namespace configmap-7953 deletion completed in 12.046348356s

• [SLOW TEST:20.100 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:57:54.587: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 13 19:57:54.609: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-4655'
Dec 13 19:57:55.045: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 13 19:57:55.045: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Dec 13 19:57:55.059: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-h7qc2]
Dec 13 19:57:55.059: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-h7qc2" in namespace "kubectl-4655" to be "running and ready"
Dec 13 19:57:55.061: INFO: Pod "e2e-test-httpd-rc-h7qc2": Phase="Pending", Reason="", readiness=false. Elapsed: 1.512838ms
Dec 13 19:57:57.063: INFO: Pod "e2e-test-httpd-rc-h7qc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.003648644s
Dec 13 19:57:59.065: INFO: Pod "e2e-test-httpd-rc-h7qc2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.005735965s
Dec 13 19:58:01.067: INFO: Pod "e2e-test-httpd-rc-h7qc2": Phase="Running", Reason="", readiness=true. Elapsed: 6.007887773s
Dec 13 19:58:01.067: INFO: Pod "e2e-test-httpd-rc-h7qc2" satisfied condition "running and ready"
Dec 13 19:58:01.067: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-h7qc2]
Dec 13 19:58:01.067: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 logs rc/e2e-test-httpd-rc --namespace=kubectl-4655'
Dec 13 19:58:01.193: INFO: stderr: ""
Dec 13 19:58:01.193: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.160.134.90. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 172.160.134.90. Set the 'ServerName' directive globally to suppress this message\n[Fri Dec 13 19:57:59.554671 2019] [mpm_event:notice] [pid 1:tid 140630845426536] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Fri Dec 13 19:57:59.554727 2019] [core:notice] [pid 1:tid 140630845426536] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Dec 13 19:58:01.193: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-064082504 delete rc e2e-test-httpd-rc --namespace=kubectl-4655'
Dec 13 19:58:01.303: INFO: stderr: ""
Dec 13 19:58:01.303: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:58:01.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4655" for this suite.
Dec 13 19:58:07.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:58:07.351: INFO: namespace kubectl-4655 deletion completed in 6.046023233s

• [SLOW TEST:12.764 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:58:07.351: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-1900/configmap-test-deff6718-bea8-421f-ac88-0538dc6b5ae1
STEP: Creating a pod to test consume configMaps
Dec 13 19:58:07.377: INFO: Waiting up to 5m0s for pod "pod-configmaps-83996fe0-403d-4209-a8b8-e6dbd745c28d" in namespace "configmap-1900" to be "success or failure"
Dec 13 19:58:07.379: INFO: Pod "pod-configmaps-83996fe0-403d-4209-a8b8-e6dbd745c28d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.304864ms
Dec 13 19:58:09.382: INFO: Pod "pod-configmaps-83996fe0-403d-4209-a8b8-e6dbd745c28d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004566316s
Dec 13 19:58:11.384: INFO: Pod "pod-configmaps-83996fe0-403d-4209-a8b8-e6dbd745c28d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006672677s
Dec 13 19:58:13.386: INFO: Pod "pod-configmaps-83996fe0-403d-4209-a8b8-e6dbd745c28d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.008574036s
STEP: Saw pod success
Dec 13 19:58:13.386: INFO: Pod "pod-configmaps-83996fe0-403d-4209-a8b8-e6dbd745c28d" satisfied condition "success or failure"
Dec 13 19:58:13.387: INFO: Trying to get logs from node 172.160.134.165 pod pod-configmaps-83996fe0-403d-4209-a8b8-e6dbd745c28d container env-test: <nil>
STEP: delete the pod
Dec 13 19:58:13.400: INFO: Waiting for pod pod-configmaps-83996fe0-403d-4209-a8b8-e6dbd745c28d to disappear
Dec 13 19:58:13.403: INFO: Pod pod-configmaps-83996fe0-403d-4209-a8b8-e6dbd745c28d no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:58:13.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1900" for this suite.
Dec 13 19:58:19.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:58:19.452: INFO: namespace configmap-1900 deletion completed in 6.04743002s

• [SLOW TEST:12.101 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:58:19.452: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 13 19:58:20.065: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 13 19:58:22.071: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:58:24.074: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:58:26.074: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:58:28.074: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:58:30.073: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:58:32.074: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863900, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 13 19:58:35.080: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:58:35.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5851" for this suite.
Dec 13 19:58:41.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:58:41.198: INFO: namespace webhook-5851 deletion completed in 6.053254755s
STEP: Destroying namespace "webhook-5851-markers" for this suite.
Dec 13 19:58:47.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:58:47.252: INFO: namespace webhook-5851-markers deletion completed in 6.053413988s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:27.806 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:58:47.259: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 13 19:58:47.922: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 13 19:58:49.928: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863927, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863927, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863927, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863927, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 13 19:58:51.930: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863927, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863927, loc:(*time.Location)(0x84c12c0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863927, loc:(*time.Location)(0x84c12c0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63711863927, loc:(*time.Location)(0x84c12c0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 13 19:58:54.935: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:58:54.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3070" for this suite.
Dec 13 19:59:00.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:59:01.012: INFO: namespace webhook-3070 deletion completed in 6.050544725s
STEP: Destroying namespace "webhook-3070-markers" for this suite.
Dec 13 19:59:07.018: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:59:07.059: INFO: namespace webhook-3070-markers deletion completed in 6.046477045s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.806 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:59:07.065: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:59:13.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7994" for this suite.
Dec 13 19:59:19.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:59:19.176: INFO: namespace emptydir-wrapper-7994 deletion completed in 6.05073007s

• [SLOW TEST:12.111 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:59:19.177: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 19:59:35.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4959" for this suite.
Dec 13 19:59:41.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 19:59:41.298: INFO: namespace resourcequota-4959 deletion completed in 6.043389806s

• [SLOW TEST:22.121 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 13 19:59:41.298: INFO: >>> kubeConfig: /tmp/kubeconfig-064082504
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-5cqf
STEP: Creating a pod to test atomic-volume-subpath
Dec 13 19:59:41.329: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-5cqf" in namespace "subpath-2306" to be "success or failure"
Dec 13 19:59:41.344: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Pending", Reason="", readiness=false. Elapsed: 15.60041ms
Dec 13 19:59:43.346: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.017612245s
Dec 13 19:59:46.149: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Pending", Reason="", readiness=false. Elapsed: 4.820446678s
Dec 13 19:59:48.151: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Pending", Reason="", readiness=false. Elapsed: 6.82252813s
Dec 13 19:59:50.153: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Pending", Reason="", readiness=false. Elapsed: 8.824387391s
Dec 13 19:59:52.155: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.826617968s
Dec 13 19:59:54.157: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Pending", Reason="", readiness=false. Elapsed: 12.828885214s
Dec 13 19:59:56.159: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Pending", Reason="", readiness=false. Elapsed: 14.830904542s
Dec 13 19:59:58.162: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Pending", Reason="", readiness=false. Elapsed: 16.833101298s
Dec 13 20:00:00.164: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Pending", Reason="", readiness=false. Elapsed: 18.83534918s
Dec 13 20:00:02.166: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Pending", Reason="", readiness=false. Elapsed: 20.837730544s
Dec 13 20:00:04.168: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Pending", Reason="", readiness=false. Elapsed: 22.839853009s
Dec 13 20:00:06.171: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Pending", Reason="", readiness=false. Elapsed: 24.842876336s
Dec 13 20:00:08.174: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Running", Reason="", readiness=true. Elapsed: 26.845373606s
Dec 13 20:00:10.176: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Running", Reason="", readiness=true. Elapsed: 28.847649994s
Dec 13 20:00:12.178: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Running", Reason="", readiness=true. Elapsed: 30.849925337s
Dec 13 20:00:14.181: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Running", Reason="", readiness=true. Elapsed: 32.852450645s
Dec 13 20:00:16.183: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Running", Reason="", readiness=true. Elapsed: 34.854370165s
Dec 13 20:00:18.185: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Running", Reason="", readiness=true. Elapsed: 36.856650203s
Dec 13 20:00:20.187: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Running", Reason="", readiness=true. Elapsed: 38.858468956s
Dec 13 20:00:22.189: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Running", Reason="", readiness=true. Elapsed: 40.860652615s
Dec 13 20:00:24.191: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Running", Reason="", readiness=true. Elapsed: 42.862929438s
Dec 13 20:00:26.197: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Running", Reason="", readiness=true. Elapsed: 44.868474117s
Dec 13 20:00:28.199: INFO: Pod "pod-subpath-test-secret-5cqf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 46.870686038s
STEP: Saw pod success
Dec 13 20:00:28.199: INFO: Pod "pod-subpath-test-secret-5cqf" satisfied condition "success or failure"
Dec 13 20:00:28.201: INFO: Trying to get logs from node 172.160.134.166 pod pod-subpath-test-secret-5cqf container test-container-subpath-secret-5cqf: <nil>
STEP: delete the pod
Dec 13 20:00:28.247: INFO: Waiting for pod pod-subpath-test-secret-5cqf to disappear
Dec 13 20:00:28.249: INFO: Pod pod-subpath-test-secret-5cqf no longer exists
STEP: Deleting pod pod-subpath-test-secret-5cqf
Dec 13 20:00:28.249: INFO: Deleting pod "pod-subpath-test-secret-5cqf" in namespace "subpath-2306"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 13 20:00:28.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2306" for this suite.
Dec 13 20:00:34.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 13 20:00:34.302: INFO: namespace subpath-2306 deletion completed in 6.05020046s

• [SLOW TEST:53.004 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.1-beta.0.37+d647ddbd755faf/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSDec 13 20:00:34.304: INFO: Running AfterSuite actions on all nodes
Dec 13 20:00:34.305: INFO: Running AfterSuite actions on node 1
Dec 13 20:00:34.305: INFO: Skipping dumping logs from cluster

Ran 276 of 4897 Specs in 8208.044 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Pending | 4621 Skipped
PASS

Ginkgo ran 1 suite in 2h16m50.484192017s
Test Suite Passed
