I0406 21:55:30.873911      23 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-273020805
I0406 21:55:30.874000      23 e2e.go:92] Starting e2e run "c7c60ad1-c2d7-4a44-87a9-c332544d3e88" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1586210129 - Will randomize all specs
Will run 274 of 4731 specs

Apr  6 21:55:30.923: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 21:55:30.924: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Apr  6 21:55:30.939: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Apr  6 21:55:30.967: INFO: 4 / 4 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Apr  6 21:55:30.967: INFO: expected 3 pod replicas in namespace 'kube-system', 3 are Running and Ready.
Apr  6 21:55:30.967: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Apr  6 21:55:30.974: INFO: e2e test version: v1.16.8
Apr  6 21:55:30.975: INFO: kube-apiserver version: v1.16.8
Apr  6 21:55:30.975: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 21:55:30.979: INFO: Cluster IP family: ipv4
SSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 21:55:30.979: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename downward-api
Apr  6 21:55:31.002: INFO: No PodSecurityPolicies found; assuming PodSecurityPolicy is disabled.
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Apr  6 21:55:31.007: INFO: Waiting up to 5m0s for pod "downward-api-3e63e771-6f88-4723-807c-9c785888d6bf" in namespace "downward-api-290" to be "success or failure"
Apr  6 21:55:31.010: INFO: Pod "downward-api-3e63e771-6f88-4723-807c-9c785888d6bf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.817684ms
Apr  6 21:55:33.013: INFO: Pod "downward-api-3e63e771-6f88-4723-807c-9c785888d6bf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005883478s
Apr  6 21:55:35.016: INFO: Pod "downward-api-3e63e771-6f88-4723-807c-9c785888d6bf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008757281s
STEP: Saw pod success
Apr  6 21:55:35.016: INFO: Pod "downward-api-3e63e771-6f88-4723-807c-9c785888d6bf" satisfied condition "success or failure"
Apr  6 21:55:35.018: INFO: Trying to get logs from node 10.0.0.43 pod downward-api-3e63e771-6f88-4723-807c-9c785888d6bf container dapi-container: <nil>
STEP: delete the pod
Apr  6 21:55:35.045: INFO: Waiting for pod downward-api-3e63e771-6f88-4723-807c-9c785888d6bf to disappear
Apr  6 21:55:35.049: INFO: Pod downward-api-3e63e771-6f88-4723-807c-9c785888d6bf no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 21:55:35.049: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-290" for this suite.
Apr  6 21:55:41.060: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 21:55:41.122: INFO: namespace downward-api-290 deletion completed in 6.070314838s

• [SLOW TEST:10.142 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 21:55:41.122: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr  6 21:55:53.187: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  6 21:55:53.190: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  6 21:55:55.190: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  6 21:55:55.193: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  6 21:55:57.190: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  6 21:55:57.193: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  6 21:55:59.190: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  6 21:55:59.193: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  6 21:56:01.190: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  6 21:56:01.193: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  6 21:56:03.190: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  6 21:56:03.193: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  6 21:56:05.190: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  6 21:56:05.193: INFO: Pod pod-with-poststart-exec-hook still exists
Apr  6 21:56:07.190: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Apr  6 21:56:07.193: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 21:56:07.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1172" for this suite.
Apr  6 21:56:19.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 21:56:19.267: INFO: namespace container-lifecycle-hook-1172 deletion completed in 12.07039803s

• [SLOW TEST:38.145 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 21:56:19.267: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr  6 21:56:19.300: INFO: Waiting up to 5m0s for pod "pod-4958411b-8d6b-4fba-8380-d3f910d21ddc" in namespace "emptydir-579" to be "success or failure"
Apr  6 21:56:19.302: INFO: Pod "pod-4958411b-8d6b-4fba-8380-d3f910d21ddc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.128105ms
Apr  6 21:56:21.305: INFO: Pod "pod-4958411b-8d6b-4fba-8380-d3f910d21ddc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005498395s
Apr  6 21:56:23.309: INFO: Pod "pod-4958411b-8d6b-4fba-8380-d3f910d21ddc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009093514s
STEP: Saw pod success
Apr  6 21:56:23.309: INFO: Pod "pod-4958411b-8d6b-4fba-8380-d3f910d21ddc" satisfied condition "success or failure"
Apr  6 21:56:23.311: INFO: Trying to get logs from node 10.0.0.42 pod pod-4958411b-8d6b-4fba-8380-d3f910d21ddc container test-container: <nil>
STEP: delete the pod
Apr  6 21:56:23.337: INFO: Waiting for pod pod-4958411b-8d6b-4fba-8380-d3f910d21ddc to disappear
Apr  6 21:56:23.339: INFO: Pod pod-4958411b-8d6b-4fba-8380-d3f910d21ddc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 21:56:23.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-579" for this suite.
Apr  6 21:56:29.349: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 21:56:29.415: INFO: namespace emptydir-579 deletion completed in 6.07312448s

• [SLOW TEST:10.148 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 21:56:29.415: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-16d5da3f-6090-494b-a661-b89fb8f8e915
STEP: Creating secret with name secret-projected-all-test-volume-c258ec3e-9f17-48e9-8960-07ccd7b2d8d8
STEP: Creating a pod to test Check all projections for projected volume plugin
Apr  6 21:56:29.447: INFO: Waiting up to 5m0s for pod "projected-volume-8853bc28-eaa2-4eba-943b-bbd976f19135" in namespace "projected-3381" to be "success or failure"
Apr  6 21:56:29.451: INFO: Pod "projected-volume-8853bc28-eaa2-4eba-943b-bbd976f19135": Phase="Pending", Reason="", readiness=false. Elapsed: 3.103365ms
Apr  6 21:56:31.454: INFO: Pod "projected-volume-8853bc28-eaa2-4eba-943b-bbd976f19135": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006330565s
STEP: Saw pod success
Apr  6 21:56:31.454: INFO: Pod "projected-volume-8853bc28-eaa2-4eba-943b-bbd976f19135" satisfied condition "success or failure"
Apr  6 21:56:31.456: INFO: Trying to get logs from node 10.0.0.43 pod projected-volume-8853bc28-eaa2-4eba-943b-bbd976f19135 container projected-all-volume-test: <nil>
STEP: delete the pod
Apr  6 21:56:31.470: INFO: Waiting for pod projected-volume-8853bc28-eaa2-4eba-943b-bbd976f19135 to disappear
Apr  6 21:56:31.472: INFO: Pod projected-volume-8853bc28-eaa2-4eba-943b-bbd976f19135 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 21:56:31.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3381" for this suite.
Apr  6 21:56:37.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 21:56:37.541: INFO: namespace projected-3381 deletion completed in 6.065632543s

• [SLOW TEST:8.126 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 21:56:37.541: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-9421/secret-test-fd9b5efc-19f2-477f-bca6-352b48763eb6
STEP: Creating a pod to test consume secrets
Apr  6 21:56:37.574: INFO: Waiting up to 5m0s for pod "pod-configmaps-d4c74255-2960-4c86-8cbe-a57eebf36039" in namespace "secrets-9421" to be "success or failure"
Apr  6 21:56:37.576: INFO: Pod "pod-configmaps-d4c74255-2960-4c86-8cbe-a57eebf36039": Phase="Pending", Reason="", readiness=false. Elapsed: 1.889836ms
Apr  6 21:56:39.580: INFO: Pod "pod-configmaps-d4c74255-2960-4c86-8cbe-a57eebf36039": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00557348s
STEP: Saw pod success
Apr  6 21:56:39.580: INFO: Pod "pod-configmaps-d4c74255-2960-4c86-8cbe-a57eebf36039" satisfied condition "success or failure"
Apr  6 21:56:39.582: INFO: Trying to get logs from node 10.0.0.43 pod pod-configmaps-d4c74255-2960-4c86-8cbe-a57eebf36039 container env-test: <nil>
STEP: delete the pod
Apr  6 21:56:39.598: INFO: Waiting for pod pod-configmaps-d4c74255-2960-4c86-8cbe-a57eebf36039 to disappear
Apr  6 21:56:39.600: INFO: Pod pod-configmaps-d4c74255-2960-4c86-8cbe-a57eebf36039 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 21:56:39.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9421" for this suite.
Apr  6 21:56:45.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 21:56:45.686: INFO: namespace secrets-9421 deletion completed in 6.083630417s

• [SLOW TEST:8.145 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 21:56:45.687: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  6 21:56:46.208: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr  6 21:56:48.216: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721807006, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721807006, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721807006, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721807006, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  6 21:56:50.219: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721807006, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721807006, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721807006, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721807006, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  6 21:56:53.226: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 21:56:53.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8933" for this suite.
Apr  6 21:56:59.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 21:56:59.436: INFO: namespace webhook-8933 deletion completed in 6.067243163s
STEP: Destroying namespace "webhook-8933-markers" for this suite.
Apr  6 21:57:05.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 21:57:05.506: INFO: namespace webhook-8933-markers deletion completed in 6.069315568s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.829 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 21:57:05.516: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-96c5de8f-5d0a-4a11-ba2f-fc7d2ee4fd23
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 21:57:09.570: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9192" for this suite.
Apr  6 21:57:21.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 21:57:21.644: INFO: namespace configmap-9192 deletion completed in 12.070700881s

• [SLOW TEST:16.128 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 21:57:21.644: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 21:57:21.680: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Apr  6 21:57:21.685: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:21.687: INFO: Number of nodes with available pods: 0
Apr  6 21:57:21.688: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 21:57:22.692: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:22.695: INFO: Number of nodes with available pods: 0
Apr  6 21:57:22.695: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 21:57:23.692: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:23.695: INFO: Number of nodes with available pods: 0
Apr  6 21:57:23.695: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 21:57:24.691: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:24.694: INFO: Number of nodes with available pods: 0
Apr  6 21:57:24.694: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 21:57:25.691: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:25.694: INFO: Number of nodes with available pods: 0
Apr  6 21:57:25.694: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 21:57:26.692: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:26.695: INFO: Number of nodes with available pods: 0
Apr  6 21:57:26.695: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 21:57:27.691: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:27.694: INFO: Number of nodes with available pods: 1
Apr  6 21:57:27.694: INFO: Node 10.0.0.43 is running more than one daemon pod
Apr  6 21:57:28.691: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:28.694: INFO: Number of nodes with available pods: 2
Apr  6 21:57:28.695: INFO: Node 10.0.0.44 is running more than one daemon pod
Apr  6 21:57:29.692: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:29.695: INFO: Number of nodes with available pods: 3
Apr  6 21:57:29.695: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Apr  6 21:57:29.724: INFO: Wrong image for pod: daemon-set-qrvgq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:29.724: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:29.724: INFO: Wrong image for pod: daemon-set-wqhbs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:29.730: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:30.733: INFO: Wrong image for pod: daemon-set-qrvgq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:30.733: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:30.733: INFO: Wrong image for pod: daemon-set-wqhbs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:30.736: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:31.733: INFO: Wrong image for pod: daemon-set-qrvgq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:31.733: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:31.733: INFO: Wrong image for pod: daemon-set-wqhbs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:31.737: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:32.733: INFO: Wrong image for pod: daemon-set-qrvgq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:32.733: INFO: Pod daemon-set-qrvgq is not available
Apr  6 21:57:32.733: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:32.733: INFO: Wrong image for pod: daemon-set-wqhbs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:32.737: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:33.733: INFO: Wrong image for pod: daemon-set-qrvgq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:33.733: INFO: Pod daemon-set-qrvgq is not available
Apr  6 21:57:33.733: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:33.733: INFO: Wrong image for pod: daemon-set-wqhbs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:33.737: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:34.734: INFO: Wrong image for pod: daemon-set-qrvgq. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:34.734: INFO: Pod daemon-set-qrvgq is not available
Apr  6 21:57:34.734: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:34.734: INFO: Wrong image for pod: daemon-set-wqhbs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:34.737: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:35.735: INFO: Pod daemon-set-w9dxf is not available
Apr  6 21:57:35.735: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:35.735: INFO: Wrong image for pod: daemon-set-wqhbs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:35.740: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:36.733: INFO: Pod daemon-set-w9dxf is not available
Apr  6 21:57:36.733: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:36.733: INFO: Wrong image for pod: daemon-set-wqhbs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:36.737: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:37.733: INFO: Pod daemon-set-w9dxf is not available
Apr  6 21:57:37.733: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:37.733: INFO: Wrong image for pod: daemon-set-wqhbs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:37.736: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:38.733: INFO: Pod daemon-set-w9dxf is not available
Apr  6 21:57:38.733: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:38.733: INFO: Wrong image for pod: daemon-set-wqhbs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:38.739: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:39.733: INFO: Pod daemon-set-w9dxf is not available
Apr  6 21:57:39.733: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:39.733: INFO: Wrong image for pod: daemon-set-wqhbs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:39.737: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:40.734: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:40.734: INFO: Wrong image for pod: daemon-set-wqhbs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:40.734: INFO: Pod daemon-set-wqhbs is not available
Apr  6 21:57:40.738: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:41.733: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:41.733: INFO: Wrong image for pod: daemon-set-wqhbs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:41.733: INFO: Pod daemon-set-wqhbs is not available
Apr  6 21:57:41.737: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:42.733: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:42.733: INFO: Wrong image for pod: daemon-set-wqhbs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:42.733: INFO: Pod daemon-set-wqhbs is not available
Apr  6 21:57:42.737: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:43.733: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:43.733: INFO: Wrong image for pod: daemon-set-wqhbs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:43.733: INFO: Pod daemon-set-wqhbs is not available
Apr  6 21:57:43.736: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:44.733: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:44.733: INFO: Wrong image for pod: daemon-set-wqhbs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:44.733: INFO: Pod daemon-set-wqhbs is not available
Apr  6 21:57:44.740: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:45.733: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:45.733: INFO: Wrong image for pod: daemon-set-wqhbs. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:45.733: INFO: Pod daemon-set-wqhbs is not available
Apr  6 21:57:45.736: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:46.733: INFO: Pod daemon-set-t52xv is not available
Apr  6 21:57:46.733: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:46.737: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:47.733: INFO: Pod daemon-set-t52xv is not available
Apr  6 21:57:47.733: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:47.736: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:48.733: INFO: Pod daemon-set-t52xv is not available
Apr  6 21:57:48.733: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:48.736: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:49.733: INFO: Pod daemon-set-t52xv is not available
Apr  6 21:57:49.733: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:49.736: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:50.733: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:50.736: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:51.733: INFO: Wrong image for pod: daemon-set-wmbkw. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Apr  6 21:57:51.733: INFO: Pod daemon-set-wmbkw is not available
Apr  6 21:57:51.736: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:52.733: INFO: Pod daemon-set-w8cch is not available
Apr  6 21:57:52.737: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Apr  6 21:57:52.740: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:52.743: INFO: Number of nodes with available pods: 2
Apr  6 21:57:52.743: INFO: Node 10.0.0.43 is running more than one daemon pod
Apr  6 21:57:53.747: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:53.750: INFO: Number of nodes with available pods: 2
Apr  6 21:57:53.750: INFO: Node 10.0.0.43 is running more than one daemon pod
Apr  6 21:57:54.747: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:54.750: INFO: Number of nodes with available pods: 2
Apr  6 21:57:54.750: INFO: Node 10.0.0.43 is running more than one daemon pod
Apr  6 21:57:55.747: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:55.749: INFO: Number of nodes with available pods: 2
Apr  6 21:57:55.749: INFO: Node 10.0.0.43 is running more than one daemon pod
Apr  6 21:57:56.747: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:57:56.753: INFO: Number of nodes with available pods: 3
Apr  6 21:57:56.753: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1560, will wait for the garbage collector to delete the pods
Apr  6 21:57:56.823: INFO: Deleting DaemonSet.extensions daemon-set took: 5.988718ms
Apr  6 21:57:57.423: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.346344ms
Apr  6 21:58:06.426: INFO: Number of nodes with available pods: 0
Apr  6 21:58:06.426: INFO: Number of running nodes: 0, number of available pods: 0
Apr  6 21:58:06.428: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1560/daemonsets","resourceVersion":"2118"},"items":null}

Apr  6 21:58:06.430: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1560/pods","resourceVersion":"2118"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 21:58:06.439: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1560" for this suite.
Apr  6 21:58:12.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 21:58:12.525: INFO: namespace daemonsets-1560 deletion completed in 6.083599675s

• [SLOW TEST:50.881 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 21:58:12.526: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 21:58:18.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-6387" for this suite.
Apr  6 21:58:24.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 21:58:24.685: INFO: namespace namespaces-6387 deletion completed in 6.07653744s
STEP: Destroying namespace "nsdeletetest-1788" for this suite.
Apr  6 21:58:24.687: INFO: Namespace nsdeletetest-1788 was already deleted
STEP: Destroying namespace "nsdeletetest-3291" for this suite.
Apr  6 21:58:30.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 21:58:30.752: INFO: namespace nsdeletetest-3291 deletion completed in 6.065736343s

• [SLOW TEST:18.227 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 21:58:30.753: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Apr  6 21:58:30.781: INFO: Waiting up to 5m0s for pod "downward-api-f1bcd59b-0800-4910-8aed-42ee73706567" in namespace "downward-api-5320" to be "success or failure"
Apr  6 21:58:30.784: INFO: Pod "downward-api-f1bcd59b-0800-4910-8aed-42ee73706567": Phase="Pending", Reason="", readiness=false. Elapsed: 2.319216ms
Apr  6 21:58:32.787: INFO: Pod "downward-api-f1bcd59b-0800-4910-8aed-42ee73706567": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005392308s
STEP: Saw pod success
Apr  6 21:58:32.787: INFO: Pod "downward-api-f1bcd59b-0800-4910-8aed-42ee73706567" satisfied condition "success or failure"
Apr  6 21:58:32.789: INFO: Trying to get logs from node 10.0.0.43 pod downward-api-f1bcd59b-0800-4910-8aed-42ee73706567 container dapi-container: <nil>
STEP: delete the pod
Apr  6 21:58:32.816: INFO: Waiting for pod downward-api-f1bcd59b-0800-4910-8aed-42ee73706567 to disappear
Apr  6 21:58:32.820: INFO: Pod downward-api-f1bcd59b-0800-4910-8aed-42ee73706567 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 21:58:32.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5320" for this suite.
Apr  6 21:58:38.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 21:58:38.902: INFO: namespace downward-api-5320 deletion completed in 6.078686705s

• [SLOW TEST:8.149 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 21:58:38.902: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 21:58:38.955: INFO: Create a RollingUpdate DaemonSet
Apr  6 21:58:38.959: INFO: Check that daemon pods launch on every node of the cluster
Apr  6 21:58:38.963: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:58:38.965: INFO: Number of nodes with available pods: 0
Apr  6 21:58:38.965: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 21:58:39.970: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:58:39.973: INFO: Number of nodes with available pods: 0
Apr  6 21:58:39.974: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 21:58:40.970: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:58:40.973: INFO: Number of nodes with available pods: 3
Apr  6 21:58:40.973: INFO: Number of running nodes: 3, number of available pods: 3
Apr  6 21:58:40.973: INFO: Update the DaemonSet to trigger a rollout
Apr  6 21:58:40.980: INFO: Updating DaemonSet daemon-set
Apr  6 21:58:46.998: INFO: Roll back the DaemonSet before rollout is complete
Apr  6 21:58:47.004: INFO: Updating DaemonSet daemon-set
Apr  6 21:58:47.004: INFO: Make sure DaemonSet rollback is complete
Apr  6 21:58:47.008: INFO: Wrong image for pod: daemon-set-qcmf7. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Apr  6 21:58:47.008: INFO: Pod daemon-set-qcmf7 is not available
Apr  6 21:58:47.013: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:58:48.016: INFO: Wrong image for pod: daemon-set-qcmf7. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Apr  6 21:58:48.016: INFO: Pod daemon-set-qcmf7 is not available
Apr  6 21:58:48.020: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:58:49.016: INFO: Wrong image for pod: daemon-set-qcmf7. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Apr  6 21:58:49.016: INFO: Pod daemon-set-qcmf7 is not available
Apr  6 21:58:49.020: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 21:58:50.016: INFO: Pod daemon-set-rqcj7 is not available
Apr  6 21:58:50.020: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2492, will wait for the garbage collector to delete the pods
Apr  6 21:58:50.084: INFO: Deleting DaemonSet.extensions daemon-set took: 6.975061ms
Apr  6 21:58:50.684: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.302301ms
Apr  6 21:58:56.387: INFO: Number of nodes with available pods: 0
Apr  6 21:58:56.387: INFO: Number of running nodes: 0, number of available pods: 0
Apr  6 21:58:56.389: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2492/daemonsets","resourceVersion":"2401"},"items":null}

Apr  6 21:58:56.391: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2492/pods","resourceVersion":"2401"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 21:58:56.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2492" for this suite.
Apr  6 21:59:02.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 21:59:02.475: INFO: namespace daemonsets-2492 deletion completed in 6.07331243s

• [SLOW TEST:23.573 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 21:59:02.475: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Apr  6 21:59:06.513: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec pod-sharedvolume-f7cabf77-76a1-4758-9787-f0e8707713a8 -c busybox-main-container --namespace=emptydir-8544 -- cat /usr/share/volumeshare/shareddata.txt'
Apr  6 21:59:06.957: INFO: stderr: ""
Apr  6 21:59:06.957: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 21:59:06.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8544" for this suite.
Apr  6 21:59:12.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 21:59:13.030: INFO: namespace emptydir-8544 deletion completed in 6.0687002s

• [SLOW TEST:10.555 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 21:59:13.030: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-93c2ac07-ff0b-4658-9928-85c76f9c8b7e
STEP: Creating a pod to test consume secrets
Apr  6 21:59:13.061: INFO: Waiting up to 5m0s for pod "pod-secrets-6556678f-f90d-4e66-a620-d4a3282d7ed5" in namespace "secrets-5156" to be "success or failure"
Apr  6 21:59:13.064: INFO: Pod "pod-secrets-6556678f-f90d-4e66-a620-d4a3282d7ed5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.613923ms
Apr  6 21:59:15.067: INFO: Pod "pod-secrets-6556678f-f90d-4e66-a620-d4a3282d7ed5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005811673s
STEP: Saw pod success
Apr  6 21:59:15.067: INFO: Pod "pod-secrets-6556678f-f90d-4e66-a620-d4a3282d7ed5" satisfied condition "success or failure"
Apr  6 21:59:15.070: INFO: Trying to get logs from node 10.0.0.43 pod pod-secrets-6556678f-f90d-4e66-a620-d4a3282d7ed5 container secret-volume-test: <nil>
STEP: delete the pod
Apr  6 21:59:15.089: INFO: Waiting for pod pod-secrets-6556678f-f90d-4e66-a620-d4a3282d7ed5 to disappear
Apr  6 21:59:15.091: INFO: Pod pod-secrets-6556678f-f90d-4e66-a620-d4a3282d7ed5 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 21:59:15.091: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5156" for this suite.
Apr  6 21:59:21.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 21:59:21.220: INFO: namespace secrets-5156 deletion completed in 6.125895422s

• [SLOW TEST:8.190 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 21:59:21.220: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Apr  6 21:59:21.244: INFO: Waiting up to 5m0s for pod "client-containers-0dda13d1-7205-496d-a45f-e912a09c79df" in namespace "containers-5667" to be "success or failure"
Apr  6 21:59:21.246: INFO: Pod "client-containers-0dda13d1-7205-496d-a45f-e912a09c79df": Phase="Pending", Reason="", readiness=false. Elapsed: 2.172716ms
Apr  6 21:59:23.250: INFO: Pod "client-containers-0dda13d1-7205-496d-a45f-e912a09c79df": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005392139s
STEP: Saw pod success
Apr  6 21:59:23.250: INFO: Pod "client-containers-0dda13d1-7205-496d-a45f-e912a09c79df" satisfied condition "success or failure"
Apr  6 21:59:23.252: INFO: Trying to get logs from node 10.0.0.42 pod client-containers-0dda13d1-7205-496d-a45f-e912a09c79df container test-container: <nil>
STEP: delete the pod
Apr  6 21:59:23.275: INFO: Waiting for pod client-containers-0dda13d1-7205-496d-a45f-e912a09c79df to disappear
Apr  6 21:59:23.277: INFO: Pod client-containers-0dda13d1-7205-496d-a45f-e912a09c79df no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 21:59:23.277: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5667" for this suite.
Apr  6 21:59:29.288: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 21:59:29.349: INFO: namespace containers-5667 deletion completed in 6.068895671s

• [SLOW TEST:8.129 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 21:59:29.349: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Apr  6 21:59:39.396: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 21:59:39.396: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W0406 21:59:39.396887      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-2535" for this suite.
Apr  6 21:59:45.409: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 21:59:45.471: INFO: namespace gc-2535 deletion completed in 6.071337201s

• [SLOW TEST:16.122 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 21:59:45.471: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  6 21:59:45.944: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr  6 21:59:47.952: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721807185, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721807185, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721807185, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721807185, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  6 21:59:50.962: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:00:01.093: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2661" for this suite.
Apr  6 22:00:07.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:00:07.166: INFO: namespace webhook-2661 deletion completed in 6.069950298s
STEP: Destroying namespace "webhook-2661-markers" for this suite.
Apr  6 22:00:13.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:00:13.238: INFO: namespace webhook-2661-markers deletion completed in 6.07135003s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:27.775 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:00:13.247: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 22:00:13.284: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Apr  6 22:00:13.288: INFO: Number of nodes with available pods: 0
Apr  6 22:00:13.288: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Apr  6 22:00:13.302: INFO: Number of nodes with available pods: 0
Apr  6 22:00:13.302: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:00:14.306: INFO: Number of nodes with available pods: 0
Apr  6 22:00:14.306: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:00:15.305: INFO: Number of nodes with available pods: 0
Apr  6 22:00:15.305: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:00:16.305: INFO: Number of nodes with available pods: 1
Apr  6 22:00:16.305: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Apr  6 22:00:16.316: INFO: Number of nodes with available pods: 1
Apr  6 22:00:16.316: INFO: Number of running nodes: 0, number of available pods: 1
Apr  6 22:00:17.319: INFO: Number of nodes with available pods: 0
Apr  6 22:00:17.319: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Apr  6 22:00:17.329: INFO: Number of nodes with available pods: 0
Apr  6 22:00:17.329: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:00:18.332: INFO: Number of nodes with available pods: 0
Apr  6 22:00:18.332: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:00:19.333: INFO: Number of nodes with available pods: 0
Apr  6 22:00:19.333: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:00:20.332: INFO: Number of nodes with available pods: 0
Apr  6 22:00:20.332: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:00:21.332: INFO: Number of nodes with available pods: 0
Apr  6 22:00:21.332: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:00:22.332: INFO: Number of nodes with available pods: 0
Apr  6 22:00:22.332: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:00:23.332: INFO: Number of nodes with available pods: 0
Apr  6 22:00:23.332: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:00:24.332: INFO: Number of nodes with available pods: 0
Apr  6 22:00:24.332: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:00:25.332: INFO: Number of nodes with available pods: 0
Apr  6 22:00:25.332: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:00:26.332: INFO: Number of nodes with available pods: 0
Apr  6 22:00:26.332: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:00:27.332: INFO: Number of nodes with available pods: 0
Apr  6 22:00:27.332: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:00:28.332: INFO: Number of nodes with available pods: 1
Apr  6 22:00:28.332: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1372, will wait for the garbage collector to delete the pods
Apr  6 22:00:28.398: INFO: Deleting DaemonSet.extensions daemon-set took: 5.652636ms
Apr  6 22:00:28.998: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.293592ms
Apr  6 22:00:36.401: INFO: Number of nodes with available pods: 0
Apr  6 22:00:36.401: INFO: Number of running nodes: 0, number of available pods: 0
Apr  6 22:00:36.402: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1372/daemonsets","resourceVersion":"2868"},"items":null}

Apr  6 22:00:36.404: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1372/pods","resourceVersion":"2868"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:00:36.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1372" for this suite.
Apr  6 22:00:42.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:00:42.521: INFO: namespace daemonsets-1372 deletion completed in 6.098108508s

• [SLOW TEST:29.274 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:00:42.521: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2745
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-2745
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-2745
Apr  6 22:00:42.556: INFO: Found 0 stateful pods, waiting for 1
Apr  6 22:00:52.560: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Apr  6 22:00:52.563: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=statefulset-2745 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr  6 22:00:52.768: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr  6 22:00:52.768: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr  6 22:00:52.768: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr  6 22:00:52.771: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr  6 22:01:02.775: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  6 22:01:02.775: INFO: Waiting for statefulset status.replicas updated to 0
Apr  6 22:01:02.785: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999449s
Apr  6 22:01:03.789: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996468893s
Apr  6 22:01:04.792: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.992904674s
Apr  6 22:01:05.795: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.989700667s
Apr  6 22:01:06.800: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.986020611s
Apr  6 22:01:07.804: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.98128844s
Apr  6 22:01:08.807: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.977465066s
Apr  6 22:01:09.811: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.974122929s
Apr  6 22:01:10.815: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.970588149s
Apr  6 22:01:11.818: INFO: Verifying statefulset ss doesn't scale past 1 for another 966.930203ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-2745
Apr  6 22:01:12.822: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=statefulset-2745 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr  6 22:01:13.039: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr  6 22:01:13.039: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr  6 22:01:13.039: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr  6 22:01:13.042: INFO: Found 1 stateful pods, waiting for 3
Apr  6 22:01:23.045: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  6 22:01:23.045: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  6 22:01:23.045: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Apr  6 22:01:23.050: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=statefulset-2745 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr  6 22:01:23.257: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr  6 22:01:23.257: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr  6 22:01:23.257: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr  6 22:01:23.257: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=statefulset-2745 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr  6 22:01:23.466: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr  6 22:01:23.466: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr  6 22:01:23.466: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr  6 22:01:23.466: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=statefulset-2745 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr  6 22:01:23.680: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr  6 22:01:23.681: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr  6 22:01:23.681: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr  6 22:01:23.681: INFO: Waiting for statefulset status.replicas updated to 0
Apr  6 22:01:23.683: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr  6 22:01:33.689: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  6 22:01:33.689: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr  6 22:01:33.689: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr  6 22:01:33.697: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999559s
Apr  6 22:01:34.701: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997004878s
Apr  6 22:01:35.704: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992994265s
Apr  6 22:01:36.708: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989324758s
Apr  6 22:01:37.712: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.985788827s
Apr  6 22:01:38.715: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.982034358s
Apr  6 22:01:39.719: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.978327965s
Apr  6 22:01:40.723: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.974656697s
Apr  6 22:01:41.727: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.970956529s
Apr  6 22:01:42.731: INFO: Verifying statefulset ss doesn't scale past 3 for another 966.912126ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-2745
Apr  6 22:01:43.734: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=statefulset-2745 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr  6 22:01:43.932: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr  6 22:01:43.932: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr  6 22:01:43.932: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr  6 22:01:43.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=statefulset-2745 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr  6 22:01:44.138: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr  6 22:01:44.138: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr  6 22:01:44.138: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr  6 22:01:44.138: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=statefulset-2745 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr  6 22:01:44.341: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr  6 22:01:44.341: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr  6 22:01:44.341: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr  6 22:01:44.341: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Apr  6 22:01:54.354: INFO: Deleting all statefulset in ns statefulset-2745
Apr  6 22:01:54.356: INFO: Scaling statefulset ss to 0
Apr  6 22:01:54.364: INFO: Waiting for statefulset status.replicas updated to 0
Apr  6 22:01:54.366: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:01:54.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2745" for this suite.
Apr  6 22:02:00.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:02:00.456: INFO: namespace statefulset-2745 deletion completed in 6.078505838s

• [SLOW TEST:77.935 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:02:00.456: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Apr  6 22:02:04.509: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2292 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 22:02:04.509: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 22:02:04.626: INFO: Exec stderr: ""
Apr  6 22:02:04.626: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2292 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 22:02:04.626: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 22:02:04.758: INFO: Exec stderr: ""
Apr  6 22:02:04.758: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2292 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 22:02:04.758: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 22:02:04.895: INFO: Exec stderr: ""
Apr  6 22:02:04.895: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2292 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 22:02:04.895: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 22:02:05.023: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Apr  6 22:02:05.023: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2292 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 22:02:05.023: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 22:02:05.135: INFO: Exec stderr: ""
Apr  6 22:02:05.135: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2292 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 22:02:05.135: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 22:02:05.252: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Apr  6 22:02:05.253: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2292 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 22:02:05.253: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 22:02:05.379: INFO: Exec stderr: ""
Apr  6 22:02:05.379: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2292 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 22:02:05.379: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 22:02:05.491: INFO: Exec stderr: ""
Apr  6 22:02:05.491: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2292 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 22:02:05.491: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 22:02:05.609: INFO: Exec stderr: ""
Apr  6 22:02:05.609: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2292 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 22:02:05.609: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 22:02:05.723: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:02:05.723: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-2292" for this suite.
Apr  6 22:02:49.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:02:49.802: INFO: namespace e2e-kubelet-etc-hosts-2292 deletion completed in 44.07368258s

• [SLOW TEST:49.346 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:02:49.802: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 22:02:49.827: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:02:55.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1343" for this suite.
Apr  6 22:03:39.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:03:40.007: INFO: namespace pods-1343 deletion completed in 44.066675244s

• [SLOW TEST:50.204 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:03:40.007: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 22:03:40.044: INFO: (0) /api/v1/nodes/10.0.0.42/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 10.146018ms)
Apr  6 22:03:40.047: INFO: (1) /api/v1/nodes/10.0.0.42/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.195635ms)
Apr  6 22:03:40.050: INFO: (2) /api/v1/nodes/10.0.0.42/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 2.996032ms)
Apr  6 22:03:40.053: INFO: (3) /api/v1/nodes/10.0.0.42/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.037007ms)
Apr  6 22:03:40.056: INFO: (4) /api/v1/nodes/10.0.0.42/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 2.92096ms)
Apr  6 22:03:40.059: INFO: (5) /api/v1/nodes/10.0.0.42/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.18752ms)
Apr  6 22:03:40.063: INFO: (6) /api/v1/nodes/10.0.0.42/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.462727ms)
Apr  6 22:03:40.066: INFO: (7) /api/v1/nodes/10.0.0.42/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.279945ms)
Apr  6 22:03:40.069: INFO: (8) /api/v1/nodes/10.0.0.42/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.13936ms)
Apr  6 22:03:40.072: INFO: (9) /api/v1/nodes/10.0.0.42/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.031138ms)
Apr  6 22:03:40.075: INFO: (10) /api/v1/nodes/10.0.0.42/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.152946ms)
Apr  6 22:03:40.079: INFO: (11) /api/v1/nodes/10.0.0.42/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.17094ms)
Apr  6 22:03:40.082: INFO: (12) /api/v1/nodes/10.0.0.42/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.28772ms)
Apr  6 22:03:40.085: INFO: (13) /api/v1/nodes/10.0.0.42/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.053159ms)
Apr  6 22:03:40.088: INFO: (14) /api/v1/nodes/10.0.0.42/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.258083ms)
Apr  6 22:03:40.091: INFO: (15) /api/v1/nodes/10.0.0.42/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.068877ms)
Apr  6 22:03:40.095: INFO: (16) /api/v1/nodes/10.0.0.42/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.728578ms)
Apr  6 22:03:40.099: INFO: (17) /api/v1/nodes/10.0.0.42/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.359183ms)
Apr  6 22:03:40.102: INFO: (18) /api/v1/nodes/10.0.0.42/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.454684ms)
Apr  6 22:03:40.106: INFO: (19) /api/v1/nodes/10.0.0.42/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.395071ms)
[AfterEach] version v1
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:03:40.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7673" for this suite.
Apr  6 22:03:46.117: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:03:46.179: INFO: namespace proxy-7673 deletion completed in 6.070017861s

• [SLOW TEST:6.172 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:03:46.179: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr  6 22:03:46.208: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d26d348c-1316-49e1-81e9-faa4d749b1a2" in namespace "projected-1515" to be "success or failure"
Apr  6 22:03:46.211: INFO: Pod "downwardapi-volume-d26d348c-1316-49e1-81e9-faa4d749b1a2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.34149ms
Apr  6 22:03:48.214: INFO: Pod "downwardapi-volume-d26d348c-1316-49e1-81e9-faa4d749b1a2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005809199s
Apr  6 22:03:50.217: INFO: Pod "downwardapi-volume-d26d348c-1316-49e1-81e9-faa4d749b1a2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009204192s
STEP: Saw pod success
Apr  6 22:03:50.217: INFO: Pod "downwardapi-volume-d26d348c-1316-49e1-81e9-faa4d749b1a2" satisfied condition "success or failure"
Apr  6 22:03:50.220: INFO: Trying to get logs from node 10.0.0.43 pod downwardapi-volume-d26d348c-1316-49e1-81e9-faa4d749b1a2 container client-container: <nil>
STEP: delete the pod
Apr  6 22:03:50.245: INFO: Waiting for pod downwardapi-volume-d26d348c-1316-49e1-81e9-faa4d749b1a2 to disappear
Apr  6 22:03:50.246: INFO: Pod downwardapi-volume-d26d348c-1316-49e1-81e9-faa4d749b1a2 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:03:50.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1515" for this suite.
Apr  6 22:03:56.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:03:56.324: INFO: namespace projected-1515 deletion completed in 6.074269982s

• [SLOW TEST:10.145 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:03:56.324: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr  6 22:03:56.369: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:03:56.372: INFO: Number of nodes with available pods: 0
Apr  6 22:03:56.372: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:03:57.376: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:03:57.379: INFO: Number of nodes with available pods: 0
Apr  6 22:03:57.379: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:03:58.376: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:03:58.379: INFO: Number of nodes with available pods: 2
Apr  6 22:03:58.379: INFO: Node 10.0.0.43 is running more than one daemon pod
Apr  6 22:03:59.377: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:03:59.380: INFO: Number of nodes with available pods: 3
Apr  6 22:03:59.380: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Apr  6 22:03:59.392: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:03:59.395: INFO: Number of nodes with available pods: 2
Apr  6 22:03:59.395: INFO: Node 10.0.0.44 is running more than one daemon pod
Apr  6 22:04:00.399: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:04:00.403: INFO: Number of nodes with available pods: 2
Apr  6 22:04:00.403: INFO: Node 10.0.0.44 is running more than one daemon pod
Apr  6 22:04:01.398: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:04:01.401: INFO: Number of nodes with available pods: 3
Apr  6 22:04:01.401: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2808, will wait for the garbage collector to delete the pods
Apr  6 22:04:01.463: INFO: Deleting DaemonSet.extensions daemon-set took: 5.005134ms
Apr  6 22:04:02.063: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.345674ms
Apr  6 22:04:15.766: INFO: Number of nodes with available pods: 0
Apr  6 22:04:15.766: INFO: Number of running nodes: 0, number of available pods: 0
Apr  6 22:04:15.768: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2808/daemonsets","resourceVersion":"3633"},"items":null}

Apr  6 22:04:15.770: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2808/pods","resourceVersion":"3633"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:04:15.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2808" for this suite.
Apr  6 22:04:21.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:04:21.859: INFO: namespace daemonsets-2808 deletion completed in 6.077188128s

• [SLOW TEST:25.535 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:04:21.859: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-1cf49701-281c-42db-983f-79d8b326e785
STEP: Creating a pod to test consume secrets
Apr  6 22:04:21.892: INFO: Waiting up to 5m0s for pod "pod-secrets-22c9b997-e9bf-4273-a103-680995a84a7c" in namespace "secrets-4868" to be "success or failure"
Apr  6 22:04:21.894: INFO: Pod "pod-secrets-22c9b997-e9bf-4273-a103-680995a84a7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.088603ms
Apr  6 22:04:23.897: INFO: Pod "pod-secrets-22c9b997-e9bf-4273-a103-680995a84a7c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004943239s
Apr  6 22:04:25.901: INFO: Pod "pod-secrets-22c9b997-e9bf-4273-a103-680995a84a7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008287351s
STEP: Saw pod success
Apr  6 22:04:25.901: INFO: Pod "pod-secrets-22c9b997-e9bf-4273-a103-680995a84a7c" satisfied condition "success or failure"
Apr  6 22:04:25.903: INFO: Trying to get logs from node 10.0.0.44 pod pod-secrets-22c9b997-e9bf-4273-a103-680995a84a7c container secret-volume-test: <nil>
STEP: delete the pod
Apr  6 22:04:25.926: INFO: Waiting for pod pod-secrets-22c9b997-e9bf-4273-a103-680995a84a7c to disappear
Apr  6 22:04:25.928: INFO: Pod pod-secrets-22c9b997-e9bf-4273-a103-680995a84a7c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:04:25.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4868" for this suite.
Apr  6 22:04:31.939: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:04:32.004: INFO: namespace secrets-4868 deletion completed in 6.073148184s

• [SLOW TEST:10.145 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:04:32.005: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 22:04:32.031: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Apr  6 22:04:37.035: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr  6 22:04:37.035: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Apr  6 22:04:37.053: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-1696 /apis/apps/v1/namespaces/deployment-1696/deployments/test-cleanup-deployment 0e47d14c-c89c-4421-8b14-4f31d947e194 3743 1 2020-04-06 22:04:37 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc001adea98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Apr  6 22:04:37.057: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-1696 /apis/apps/v1/namespaces/deployment-1696/replicasets/test-cleanup-deployment-65db99849b f346779c-1a6f-4da9-8364-cd2e64452988 3746 1 2020-04-06 22:04:37 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 0e47d14c-c89c-4421-8b14-4f31d947e194 0xc001adf317 0xc001adf318}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc001adf3e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:0,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr  6 22:04:37.057: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Apr  6 22:04:37.057: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-1696 /apis/apps/v1/namespaces/deployment-1696/replicasets/test-cleanup-controller f1417e44-3e64-461e-ae9c-aa4419046148 3745 1 2020-04-06 22:04:32 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 0e47d14c-c89c-4421-8b14-4f31d947e194 0xc001adf1b7 0xc001adf1b8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc001adf268 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr  6 22:04:37.064: INFO: Pod "test-cleanup-controller-6v64k" is available:
&Pod{ObjectMeta:{test-cleanup-controller-6v64k test-cleanup-controller- deployment-1696 /api/v1/namespaces/deployment-1696/pods/test-cleanup-controller-6v64k 96801506-a58b-49e9-9bd0-3090b6b3f106 3734 0 2020-04-06 22:04:32 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 ReplicaSet test-cleanup-controller f1417e44-3e64-461e-ae9c-aa4419046148 0xc001adfc7f 0xc001adfc90}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fpsjh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fpsjh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fpsjh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.42,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 22:04:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 22:04:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 22:04:33 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 22:04:32 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.42,PodIP:10.20.14.21,StartTime:2020-04-06 22:04:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-06 22:04:32 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://1ff9958ebbec18b02b07ffe7d5a2f010148bfebf29c96576f2522a997570c0e1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.20.14.21,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 22:04:37.064: INFO: Pod "test-cleanup-deployment-65db99849b-z6qcq" is not available:
&Pod{ObjectMeta:{test-cleanup-deployment-65db99849b-z6qcq test-cleanup-deployment-65db99849b- deployment-1696 /api/v1/namespaces/deployment-1696/pods/test-cleanup-deployment-65db99849b-z6qcq 112fee19-5f19-4b29-b5f9-af376851c0c8 3748 0 2020-04-06 22:04:37 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [{apps/v1 ReplicaSet test-cleanup-deployment-65db99849b f346779c-1a6f-4da9-8364-cd2e64452988 0xc001adfe07 0xc001adfe08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fpsjh,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fpsjh,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fpsjh,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:04:37.064: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1696" for this suite.
Apr  6 22:04:43.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:04:43.138: INFO: namespace deployment-1696 deletion completed in 6.069637891s

• [SLOW TEST:11.134 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:04:43.139: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  6 22:04:43.455: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  6 22:04:46.471: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Apr  6 22:04:46.487: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:04:46.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4265" for this suite.
Apr  6 22:04:52.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:04:52.573: INFO: namespace webhook-4265 deletion completed in 6.068623933s
STEP: Destroying namespace "webhook-4265-markers" for this suite.
Apr  6 22:04:58.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:04:58.638: INFO: namespace webhook-4265-markers deletion completed in 6.064363128s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.509 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:04:58.648: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Apr  6 22:04:58.675: INFO: Waiting up to 5m0s for pod "var-expansion-5c4c6388-745e-4e55-9f57-0427f8898540" in namespace "var-expansion-6982" to be "success or failure"
Apr  6 22:04:58.679: INFO: Pod "var-expansion-5c4c6388-745e-4e55-9f57-0427f8898540": Phase="Pending", Reason="", readiness=false. Elapsed: 3.052501ms
Apr  6 22:05:00.682: INFO: Pod "var-expansion-5c4c6388-745e-4e55-9f57-0427f8898540": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006372769s
STEP: Saw pod success
Apr  6 22:05:00.682: INFO: Pod "var-expansion-5c4c6388-745e-4e55-9f57-0427f8898540" satisfied condition "success or failure"
Apr  6 22:05:00.684: INFO: Trying to get logs from node 10.0.0.43 pod var-expansion-5c4c6388-745e-4e55-9f57-0427f8898540 container dapi-container: <nil>
STEP: delete the pod
Apr  6 22:05:00.699: INFO: Waiting for pod var-expansion-5c4c6388-745e-4e55-9f57-0427f8898540 to disappear
Apr  6 22:05:00.701: INFO: Pod var-expansion-5c4c6388-745e-4e55-9f57-0427f8898540 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:05:00.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6982" for this suite.
Apr  6 22:05:06.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:05:06.780: INFO: namespace var-expansion-6982 deletion completed in 6.074955778s

• [SLOW TEST:8.132 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:05:06.780: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr  6 22:05:10.835: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  6 22:05:10.838: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  6 22:05:12.838: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  6 22:05:12.841: INFO: Pod pod-with-prestop-exec-hook still exists
Apr  6 22:05:14.838: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Apr  6 22:05:14.841: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:05:14.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4373" for this suite.
Apr  6 22:05:42.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:05:42.933: INFO: namespace container-lifecycle-hook-4373 deletion completed in 28.073379708s

• [SLOW TEST:36.153 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:05:42.933: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6632
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Apr  6 22:05:42.966: INFO: Found 0 stateful pods, waiting for 3
Apr  6 22:05:52.969: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  6 22:05:52.969: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  6 22:05:52.969: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Apr  6 22:05:52.994: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Apr  6 22:06:03.023: INFO: Updating stateful set ss2
Apr  6 22:06:03.035: INFO: Waiting for Pod statefulset-6632/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr  6 22:06:13.042: INFO: Waiting for Pod statefulset-6632/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Apr  6 22:06:23.064: INFO: Found 2 stateful pods, waiting for 3
Apr  6 22:06:33.068: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  6 22:06:33.068: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  6 22:06:33.068: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Apr  6 22:06:33.090: INFO: Updating stateful set ss2
Apr  6 22:06:33.095: INFO: Waiting for Pod statefulset-6632/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr  6 22:06:43.101: INFO: Waiting for Pod statefulset-6632/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr  6 22:06:53.117: INFO: Updating stateful set ss2
Apr  6 22:06:53.122: INFO: Waiting for StatefulSet statefulset-6632/ss2 to complete update
Apr  6 22:06:53.122: INFO: Waiting for Pod statefulset-6632/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Apr  6 22:07:03.128: INFO: Waiting for StatefulSet statefulset-6632/ss2 to complete update
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Apr  6 22:07:13.129: INFO: Deleting all statefulset in ns statefulset-6632
Apr  6 22:07:13.131: INFO: Scaling statefulset ss2 to 0
Apr  6 22:07:43.142: INFO: Waiting for statefulset status.replicas updated to 0
Apr  6 22:07:43.144: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:07:43.153: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6632" for this suite.
Apr  6 22:07:49.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:07:49.236: INFO: namespace statefulset-6632 deletion completed in 6.079376165s

• [SLOW TEST:126.303 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:07:49.236: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 22:07:49.271: INFO: (0) /api/v1/nodes/10.0.0.42:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 10.47878ms)
Apr  6 22:07:49.275: INFO: (1) /api/v1/nodes/10.0.0.42:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.742241ms)
Apr  6 22:07:49.279: INFO: (2) /api/v1/nodes/10.0.0.42:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.589819ms)
Apr  6 22:07:49.282: INFO: (3) /api/v1/nodes/10.0.0.42:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.196074ms)
Apr  6 22:07:49.285: INFO: (4) /api/v1/nodes/10.0.0.42:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.405536ms)
Apr  6 22:07:49.289: INFO: (5) /api/v1/nodes/10.0.0.42:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.477352ms)
Apr  6 22:07:49.292: INFO: (6) /api/v1/nodes/10.0.0.42:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 2.951516ms)
Apr  6 22:07:49.295: INFO: (7) /api/v1/nodes/10.0.0.42:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 2.845683ms)
Apr  6 22:07:49.298: INFO: (8) /api/v1/nodes/10.0.0.42:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.287109ms)
Apr  6 22:07:49.301: INFO: (9) /api/v1/nodes/10.0.0.42:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.15723ms)
Apr  6 22:07:49.304: INFO: (10) /api/v1/nodes/10.0.0.42:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.143344ms)
Apr  6 22:07:49.308: INFO: (11) /api/v1/nodes/10.0.0.42:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.254257ms)
Apr  6 22:07:49.311: INFO: (12) /api/v1/nodes/10.0.0.42:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.252934ms)
Apr  6 22:07:49.314: INFO: (13) /api/v1/nodes/10.0.0.42:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.192688ms)
Apr  6 22:07:49.318: INFO: (14) /api/v1/nodes/10.0.0.42:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.593155ms)
Apr  6 22:07:49.321: INFO: (15) /api/v1/nodes/10.0.0.42:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.417229ms)
Apr  6 22:07:49.325: INFO: (16) /api/v1/nodes/10.0.0.42:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.588257ms)
Apr  6 22:07:49.328: INFO: (17) /api/v1/nodes/10.0.0.42:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.369917ms)
Apr  6 22:07:49.332: INFO: (18) /api/v1/nodes/10.0.0.42:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.601251ms)
Apr  6 22:07:49.335: INFO: (19) /api/v1/nodes/10.0.0.42:10250/proxy/logs/: <pre>
<a href="alternatives.log">alternatives.log</a>
<a href="apport.log">apport.log</a>
<a href... (200; 3.380797ms)
[AfterEach] version v1
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:07:49.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4605" for this suite.
Apr  6 22:07:55.348: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:07:55.408: INFO: namespace proxy-4605 deletion completed in 6.069868577s

• [SLOW TEST:6.172 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:07:55.409: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr  6 22:07:55.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-5569'
Apr  6 22:07:55.506: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr  6 22:07:55.506: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Apr  6 22:07:55.513: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-bcv2t]
Apr  6 22:07:55.513: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-bcv2t" in namespace "kubectl-5569" to be "running and ready"
Apr  6 22:07:55.518: INFO: Pod "e2e-test-httpd-rc-bcv2t": Phase="Pending", Reason="", readiness=false. Elapsed: 5.125276ms
Apr  6 22:07:57.521: INFO: Pod "e2e-test-httpd-rc-bcv2t": Phase="Running", Reason="", readiness=true. Elapsed: 2.008074348s
Apr  6 22:07:57.521: INFO: Pod "e2e-test-httpd-rc-bcv2t" satisfied condition "running and ready"
Apr  6 22:07:57.521: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-bcv2t]
Apr  6 22:07:57.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 logs rc/e2e-test-httpd-rc --namespace=kubectl-5569'
Apr  6 22:07:57.630: INFO: stderr: ""
Apr  6 22:07:57.630: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.20.8.26. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.20.8.26. Set the 'ServerName' directive globally to suppress this message\n[Mon Apr 06 22:07:56.490345 2020] [mpm_event:notice] [pid 1:tid 140110052547432] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Mon Apr 06 22:07:56.490377 2020] [core:notice] [pid 1:tid 140110052547432] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Apr  6 22:07:57.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 delete rc e2e-test-httpd-rc --namespace=kubectl-5569'
Apr  6 22:07:57.706: INFO: stderr: ""
Apr  6 22:07:57.706: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:07:57.706: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5569" for this suite.
Apr  6 22:08:25.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:08:25.787: INFO: namespace kubectl-5569 deletion completed in 28.077005775s

• [SLOW TEST:30.378 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:08:25.787: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr  6 22:08:25.815: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d75a4c35-f107-44d9-b9be-88da6d4e5b64" in namespace "projected-8117" to be "success or failure"
Apr  6 22:08:25.818: INFO: Pod "downwardapi-volume-d75a4c35-f107-44d9-b9be-88da6d4e5b64": Phase="Pending", Reason="", readiness=false. Elapsed: 2.764744ms
Apr  6 22:08:27.821: INFO: Pod "downwardapi-volume-d75a4c35-f107-44d9-b9be-88da6d4e5b64": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005889658s
STEP: Saw pod success
Apr  6 22:08:27.821: INFO: Pod "downwardapi-volume-d75a4c35-f107-44d9-b9be-88da6d4e5b64" satisfied condition "success or failure"
Apr  6 22:08:27.827: INFO: Trying to get logs from node 10.0.0.43 pod downwardapi-volume-d75a4c35-f107-44d9-b9be-88da6d4e5b64 container client-container: <nil>
STEP: delete the pod
Apr  6 22:08:27.843: INFO: Waiting for pod downwardapi-volume-d75a4c35-f107-44d9-b9be-88da6d4e5b64 to disappear
Apr  6 22:08:27.845: INFO: Pod downwardapi-volume-d75a4c35-f107-44d9-b9be-88da6d4e5b64 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:08:27.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8117" for this suite.
Apr  6 22:08:33.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:08:33.920: INFO: namespace projected-8117 deletion completed in 6.071891366s

• [SLOW TEST:8.133 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:08:33.920: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr  6 22:08:33.949: INFO: Waiting up to 5m0s for pod "pod-a8eb8d17-0d7b-4e25-a514-2ee237127cd5" in namespace "emptydir-3276" to be "success or failure"
Apr  6 22:08:33.952: INFO: Pod "pod-a8eb8d17-0d7b-4e25-a514-2ee237127cd5": Phase="Pending", Reason="", readiness=false. Elapsed: 3.685419ms
Apr  6 22:08:35.955: INFO: Pod "pod-a8eb8d17-0d7b-4e25-a514-2ee237127cd5": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006452869s
Apr  6 22:08:37.958: INFO: Pod "pod-a8eb8d17-0d7b-4e25-a514-2ee237127cd5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009839167s
STEP: Saw pod success
Apr  6 22:08:37.958: INFO: Pod "pod-a8eb8d17-0d7b-4e25-a514-2ee237127cd5" satisfied condition "success or failure"
Apr  6 22:08:37.961: INFO: Trying to get logs from node 10.0.0.42 pod pod-a8eb8d17-0d7b-4e25-a514-2ee237127cd5 container test-container: <nil>
STEP: delete the pod
Apr  6 22:08:37.978: INFO: Waiting for pod pod-a8eb8d17-0d7b-4e25-a514-2ee237127cd5 to disappear
Apr  6 22:08:37.980: INFO: Pod pod-a8eb8d17-0d7b-4e25-a514-2ee237127cd5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:08:37.980: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3276" for this suite.
Apr  6 22:08:43.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:08:44.069: INFO: namespace emptydir-3276 deletion completed in 6.085643724s

• [SLOW TEST:10.148 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:08:44.069: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-776eb509-ff35-487f-8141-ee2d897eeeec
STEP: Creating configMap with name cm-test-opt-upd-c722d983-3091-442b-af57-6acff1b3b5b1
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-776eb509-ff35-487f-8141-ee2d897eeeec
STEP: Updating configmap cm-test-opt-upd-c722d983-3091-442b-af57-6acff1b3b5b1
STEP: Creating configMap with name cm-test-opt-create-1c5e2a69-f412-4ac2-b0b8-8e37fa9c6b52
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:08:48.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2830" for this suite.
Apr  6 22:09:02.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:09:02.259: INFO: namespace configmap-2830 deletion completed in 14.085188074s

• [SLOW TEST:18.191 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:09:02.260: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr  6 22:09:02.284: INFO: Waiting up to 5m0s for pod "downwardapi-volume-689396da-ccc0-4df5-837b-e53bc718229f" in namespace "projected-9680" to be "success or failure"
Apr  6 22:09:02.287: INFO: Pod "downwardapi-volume-689396da-ccc0-4df5-837b-e53bc718229f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.851045ms
Apr  6 22:09:04.290: INFO: Pod "downwardapi-volume-689396da-ccc0-4df5-837b-e53bc718229f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006445654s
STEP: Saw pod success
Apr  6 22:09:04.290: INFO: Pod "downwardapi-volume-689396da-ccc0-4df5-837b-e53bc718229f" satisfied condition "success or failure"
Apr  6 22:09:04.293: INFO: Trying to get logs from node 10.0.0.42 pod downwardapi-volume-689396da-ccc0-4df5-837b-e53bc718229f container client-container: <nil>
STEP: delete the pod
Apr  6 22:09:04.310: INFO: Waiting for pod downwardapi-volume-689396da-ccc0-4df5-837b-e53bc718229f to disappear
Apr  6 22:09:04.312: INFO: Pod downwardapi-volume-689396da-ccc0-4df5-837b-e53bc718229f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:09:04.312: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9680" for this suite.
Apr  6 22:09:10.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:09:10.397: INFO: namespace projected-9680 deletion completed in 6.081967399s

• [SLOW TEST:8.137 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:09:10.397: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:09:21.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8516" for this suite.
Apr  6 22:09:27.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:09:27.532: INFO: namespace resourcequota-8516 deletion completed in 6.083740024s

• [SLOW TEST:17.135 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:09:27.533: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-8841
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-8841
I0406 22:09:27.583012      23 runners.go:184] Created replication controller with name: externalname-service, namespace: services-8841, replica count: 2
Apr  6 22:09:30.633: INFO: Creating new exec pod
I0406 22:09:30.633579      23 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  6 22:09:33.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=services-8841 execpoddfpg4 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Apr  6 22:09:34.119: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr  6 22:09:34.120: INFO: stdout: ""
Apr  6 22:09:34.120: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=services-8841 execpoddfpg4 -- /bin/sh -x -c nc -zv -t -w 2 10.21.189.213 80'
Apr  6 22:09:34.340: INFO: stderr: "+ nc -zv -t -w 2 10.21.189.213 80\nConnection to 10.21.189.213 80 port [tcp/http] succeeded!\n"
Apr  6 22:09:34.340: INFO: stdout: ""
Apr  6 22:09:34.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=services-8841 execpoddfpg4 -- /bin/sh -x -c nc -zv -t -w 2 10.0.0.42 31906'
Apr  6 22:09:34.546: INFO: stderr: "+ nc -zv -t -w 2 10.0.0.42 31906\nConnection to 10.0.0.42 31906 port [tcp/31906] succeeded!\n"
Apr  6 22:09:34.546: INFO: stdout: ""
Apr  6 22:09:34.546: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=services-8841 execpoddfpg4 -- /bin/sh -x -c nc -zv -t -w 2 10.0.0.43 31906'
Apr  6 22:09:34.763: INFO: stderr: "+ nc -zv -t -w 2 10.0.0.43 31906\nConnection to 10.0.0.43 31906 port [tcp/31906] succeeded!\n"
Apr  6 22:09:34.763: INFO: stdout: ""
Apr  6 22:09:34.763: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:09:34.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8841" for this suite.
Apr  6 22:09:40.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:09:40.872: INFO: namespace services-8841 deletion completed in 6.085377518s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.340 seconds]
[sig-network] Services
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:09:40.873: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-75a94aa3-952a-418a-92a4-90a53abf0890
STEP: Creating a pod to test consume secrets
Apr  6 22:09:40.923: INFO: Waiting up to 5m0s for pod "pod-secrets-588d27f8-a53a-42ea-b9c2-fe17dae21cb0" in namespace "secrets-9065" to be "success or failure"
Apr  6 22:09:40.925: INFO: Pod "pod-secrets-588d27f8-a53a-42ea-b9c2-fe17dae21cb0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.322457ms
Apr  6 22:09:42.928: INFO: Pod "pod-secrets-588d27f8-a53a-42ea-b9c2-fe17dae21cb0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004977993s
Apr  6 22:09:44.932: INFO: Pod "pod-secrets-588d27f8-a53a-42ea-b9c2-fe17dae21cb0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008613681s
STEP: Saw pod success
Apr  6 22:09:44.932: INFO: Pod "pod-secrets-588d27f8-a53a-42ea-b9c2-fe17dae21cb0" satisfied condition "success or failure"
Apr  6 22:09:44.938: INFO: Trying to get logs from node 10.0.0.43 pod pod-secrets-588d27f8-a53a-42ea-b9c2-fe17dae21cb0 container secret-volume-test: <nil>
STEP: delete the pod
Apr  6 22:09:44.959: INFO: Waiting for pod pod-secrets-588d27f8-a53a-42ea-b9c2-fe17dae21cb0 to disappear
Apr  6 22:09:44.961: INFO: Pod pod-secrets-588d27f8-a53a-42ea-b9c2-fe17dae21cb0 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:09:44.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9065" for this suite.
Apr  6 22:09:50.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:09:51.136: INFO: namespace secrets-9065 deletion completed in 6.170376973s
STEP: Destroying namespace "secret-namespace-6152" for this suite.
Apr  6 22:09:57.145: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:09:57.217: INFO: namespace secret-namespace-6152 deletion completed in 6.081250209s

• [SLOW TEST:16.344 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:09:57.217: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr  6 22:09:57.246: INFO: Waiting up to 5m0s for pod "pod-9d5c42d0-7c2f-45ee-b2f9-0f145d656a79" in namespace "emptydir-9124" to be "success or failure"
Apr  6 22:09:57.251: INFO: Pod "pod-9d5c42d0-7c2f-45ee-b2f9-0f145d656a79": Phase="Pending", Reason="", readiness=false. Elapsed: 5.492077ms
Apr  6 22:09:59.255: INFO: Pod "pod-9d5c42d0-7c2f-45ee-b2f9-0f145d656a79": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009040989s
STEP: Saw pod success
Apr  6 22:09:59.255: INFO: Pod "pod-9d5c42d0-7c2f-45ee-b2f9-0f145d656a79" satisfied condition "success or failure"
Apr  6 22:09:59.257: INFO: Trying to get logs from node 10.0.0.44 pod pod-9d5c42d0-7c2f-45ee-b2f9-0f145d656a79 container test-container: <nil>
STEP: delete the pod
Apr  6 22:09:59.279: INFO: Waiting for pod pod-9d5c42d0-7c2f-45ee-b2f9-0f145d656a79 to disappear
Apr  6 22:09:59.281: INFO: Pod pod-9d5c42d0-7c2f-45ee-b2f9-0f145d656a79 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:09:59.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9124" for this suite.
Apr  6 22:10:05.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:10:05.359: INFO: namespace emptydir-9124 deletion completed in 6.074179508s

• [SLOW TEST:8.142 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:10:05.360: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Apr  6 22:10:05.384: INFO: Waiting up to 5m0s for pod "client-containers-a954d515-5cd1-4284-81f8-ad1eae2c830e" in namespace "containers-548" to be "success or failure"
Apr  6 22:10:05.387: INFO: Pod "client-containers-a954d515-5cd1-4284-81f8-ad1eae2c830e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.151949ms
Apr  6 22:10:07.390: INFO: Pod "client-containers-a954d515-5cd1-4284-81f8-ad1eae2c830e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005406435s
STEP: Saw pod success
Apr  6 22:10:07.390: INFO: Pod "client-containers-a954d515-5cd1-4284-81f8-ad1eae2c830e" satisfied condition "success or failure"
Apr  6 22:10:07.392: INFO: Trying to get logs from node 10.0.0.42 pod client-containers-a954d515-5cd1-4284-81f8-ad1eae2c830e container test-container: <nil>
STEP: delete the pod
Apr  6 22:10:07.409: INFO: Waiting for pod client-containers-a954d515-5cd1-4284-81f8-ad1eae2c830e to disappear
Apr  6 22:10:07.412: INFO: Pod client-containers-a954d515-5cd1-4284-81f8-ad1eae2c830e no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:10:07.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-548" for this suite.
Apr  6 22:10:13.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:10:13.532: INFO: namespace containers-548 deletion completed in 6.117075268s

• [SLOW TEST:8.173 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:10:13.533: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Apr  6 22:10:13.555: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:10:17.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5963" for this suite.
Apr  6 22:10:29.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:10:29.523: INFO: namespace init-container-5963 deletion completed in 12.088485122s

• [SLOW TEST:15.991 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:10:29.523: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Apr  6 22:10:29.542: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:10:33.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6716" for this suite.
Apr  6 22:10:39.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:10:39.471: INFO: namespace init-container-6716 deletion completed in 6.090782818s

• [SLOW TEST:9.948 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:10:39.471: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:10:43.530: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5065" for this suite.
Apr  6 22:10:49.541: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:10:49.618: INFO: namespace emptydir-wrapper-5065 deletion completed in 6.084481969s

• [SLOW TEST:10.147 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:10:49.618: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Apr  6 22:10:49.647: INFO: Waiting up to 5m0s for pod "downward-api-fc08e345-acc0-4215-9ea6-9b984febb903" in namespace "downward-api-9623" to be "success or failure"
Apr  6 22:10:49.649: INFO: Pod "downward-api-fc08e345-acc0-4215-9ea6-9b984febb903": Phase="Pending", Reason="", readiness=false. Elapsed: 2.245017ms
Apr  6 22:10:51.652: INFO: Pod "downward-api-fc08e345-acc0-4215-9ea6-9b984febb903": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005192688s
Apr  6 22:10:53.655: INFO: Pod "downward-api-fc08e345-acc0-4215-9ea6-9b984febb903": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007987431s
STEP: Saw pod success
Apr  6 22:10:53.655: INFO: Pod "downward-api-fc08e345-acc0-4215-9ea6-9b984febb903" satisfied condition "success or failure"
Apr  6 22:10:53.659: INFO: Trying to get logs from node 10.0.0.44 pod downward-api-fc08e345-acc0-4215-9ea6-9b984febb903 container dapi-container: <nil>
STEP: delete the pod
Apr  6 22:10:53.674: INFO: Waiting for pod downward-api-fc08e345-acc0-4215-9ea6-9b984febb903 to disappear
Apr  6 22:10:53.676: INFO: Pod downward-api-fc08e345-acc0-4215-9ea6-9b984febb903 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:10:53.676: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9623" for this suite.
Apr  6 22:10:59.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:10:59.752: INFO: namespace downward-api-9623 deletion completed in 6.072335511s

• [SLOW TEST:10.134 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:10:59.752: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr  6 22:10:59.776: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-1854'
Apr  6 22:10:59.858: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr  6 22:10:59.858: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Apr  6 22:11:01.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 delete deployment e2e-test-httpd-deployment --namespace=kubectl-1854'
Apr  6 22:11:01.939: INFO: stderr: ""
Apr  6 22:11:01.940: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:11:01.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1854" for this suite.
Apr  6 22:11:29.951: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:11:30.031: INFO: namespace kubectl-1854 deletion completed in 28.087556436s

• [SLOW TEST:30.279 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:11:30.031: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-ab3c47be-995f-4999-964d-88d28abd65c9
STEP: Creating a pod to test consume configMaps
Apr  6 22:11:30.069: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2c6cfec5-95b7-454d-824d-0d30fea8714a" in namespace "projected-7867" to be "success or failure"
Apr  6 22:11:30.072: INFO: Pod "pod-projected-configmaps-2c6cfec5-95b7-454d-824d-0d30fea8714a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.350698ms
Apr  6 22:11:32.075: INFO: Pod "pod-projected-configmaps-2c6cfec5-95b7-454d-824d-0d30fea8714a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005618687s
STEP: Saw pod success
Apr  6 22:11:32.075: INFO: Pod "pod-projected-configmaps-2c6cfec5-95b7-454d-824d-0d30fea8714a" satisfied condition "success or failure"
Apr  6 22:11:32.078: INFO: Trying to get logs from node 10.0.0.43 pod pod-projected-configmaps-2c6cfec5-95b7-454d-824d-0d30fea8714a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  6 22:11:32.101: INFO: Waiting for pod pod-projected-configmaps-2c6cfec5-95b7-454d-824d-0d30fea8714a to disappear
Apr  6 22:11:32.103: INFO: Pod pod-projected-configmaps-2c6cfec5-95b7-454d-824d-0d30fea8714a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:11:32.103: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7867" for this suite.
Apr  6 22:11:38.114: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:11:38.201: INFO: namespace projected-7867 deletion completed in 6.094204835s

• [SLOW TEST:8.169 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:11:38.201: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 22:11:38.227: INFO: Creating deployment "test-recreate-deployment"
Apr  6 22:11:38.230: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Apr  6 22:11:38.237: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Apr  6 22:11:40.243: INFO: Waiting deployment "test-recreate-deployment" to complete
Apr  6 22:11:40.246: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721807898, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721807898, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721807898, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721807898, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  6 22:11:42.249: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Apr  6 22:11:42.254: INFO: Updating deployment test-recreate-deployment
Apr  6 22:11:42.254: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Apr  6 22:11:42.309: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-2896 /apis/apps/v1/namespaces/deployment-2896/deployments/test-recreate-deployment 08250bf6-fe2e-4eb9-9ecc-9b852565411b 5945 2 2020-04-06 22:11:38 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003a5f688 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-04-06 22:11:42 +0000 UTC,LastTransitionTime:2020-04-06 22:11:42 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2020-04-06 22:11:42 +0000 UTC,LastTransitionTime:2020-04-06 22:11:38 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Apr  6 22:11:42.312: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-2896 /apis/apps/v1/namespaces/deployment-2896/replicasets/test-recreate-deployment-5f94c574ff 30f3624d-3813-4fed-b7ba-645052514a06 5943 1 2020-04-06 22:11:42 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 08250bf6-fe2e-4eb9-9ecc-9b852565411b 0xc003a5fa57 0xc003a5fa58}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003a5fab8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr  6 22:11:42.312: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Apr  6 22:11:42.312: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-2896 /apis/apps/v1/namespaces/deployment-2896/replicasets/test-recreate-deployment-68fc85c7bb 058cbea4-edbe-4926-aa7a-fe9d7e19af55 5932 2 2020-04-06 22:11:38 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 08250bf6-fe2e-4eb9-9ecc-9b852565411b 0xc003a5fb17 0xc003a5fb18}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003a5fb78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr  6 22:11:42.315: INFO: Pod "test-recreate-deployment-5f94c574ff-gvznh" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-gvznh test-recreate-deployment-5f94c574ff- deployment-2896 /api/v1/namespaces/deployment-2896/pods/test-recreate-deployment-5f94c574ff-gvznh bc978835-213b-4e87-ad3e-be06afbef7ed 5944 0 2020-04-06 22:11:42 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 30f3624d-3813-4fed-b7ba-645052514a06 0xc003a5ffe7 0xc003a5ffe8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-7mxnt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-7mxnt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-7mxnt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.42,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 22:11:42 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 22:11:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 22:11:42 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 22:11:42 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.42,PodIP:,StartTime:2020-04-06 22:11:42 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:11:42.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2896" for this suite.
Apr  6 22:11:48.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:11:48.395: INFO: namespace deployment-2896 deletion completed in 6.07671801s

• [SLOW TEST:10.194 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:11:48.395: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-7246f077-f4bf-47d5-93ee-fe4979d17e1b
STEP: Creating a pod to test consume configMaps
Apr  6 22:11:48.424: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3b3e0f2f-fd97-41a6-866d-b801d4caecb4" in namespace "projected-1954" to be "success or failure"
Apr  6 22:11:48.427: INFO: Pod "pod-projected-configmaps-3b3e0f2f-fd97-41a6-866d-b801d4caecb4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.120731ms
Apr  6 22:11:50.429: INFO: Pod "pod-projected-configmaps-3b3e0f2f-fd97-41a6-866d-b801d4caecb4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004779238s
Apr  6 22:11:52.432: INFO: Pod "pod-projected-configmaps-3b3e0f2f-fd97-41a6-866d-b801d4caecb4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007770267s
STEP: Saw pod success
Apr  6 22:11:52.432: INFO: Pod "pod-projected-configmaps-3b3e0f2f-fd97-41a6-866d-b801d4caecb4" satisfied condition "success or failure"
Apr  6 22:11:52.434: INFO: Trying to get logs from node 10.0.0.44 pod pod-projected-configmaps-3b3e0f2f-fd97-41a6-866d-b801d4caecb4 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  6 22:11:52.449: INFO: Waiting for pod pod-projected-configmaps-3b3e0f2f-fd97-41a6-866d-b801d4caecb4 to disappear
Apr  6 22:11:52.451: INFO: Pod pod-projected-configmaps-3b3e0f2f-fd97-41a6-866d-b801d4caecb4 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:11:52.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1954" for this suite.
Apr  6 22:11:58.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:11:58.535: INFO: namespace projected-1954 deletion completed in 6.079694885s

• [SLOW TEST:10.140 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:11:58.535: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Apr  6 22:11:58.557: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  6 22:11:58.566: INFO: Waiting for terminating namespaces to be deleted...
Apr  6 22:11:58.568: INFO: 
Logging pods the kubelet thinks is on node 10.0.0.42 before test
Apr  6 22:11:58.581: INFO: sonobuoy-systemd-logs-daemon-set-3f2ae32d33c24b28-z5vfz from sonobuoy started at 2020-04-06 21:55:15 +0000 UTC (2 container statuses recorded)
Apr  6 22:11:58.581: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  6 22:11:58.581: INFO: 	Container systemd-logs ready: true, restart count 0
Apr  6 22:11:58.581: INFO: prometheus-operator-546b677c-8nsvj from pf9-operators started at 2020-04-06 22:08:44 +0000 UTC (1 container statuses recorded)
Apr  6 22:11:58.581: INFO: 	Container prometheus-operator ready: true, restart count 0
Apr  6 22:11:58.581: INFO: comms-proxy-f9jz2 from pf9-monitoring started at 2020-04-06 22:08:48 +0000 UTC (1 container statuses recorded)
Apr  6 22:11:58.581: INFO: 	Container envoy ready: true, restart count 0
Apr  6 22:11:58.581: INFO: olm-operator-76d446f94c-rhq8h from pf9-olm started at 2020-04-06 21:53:11 +0000 UTC (1 container statuses recorded)
Apr  6 22:11:58.581: INFO: 	Container olm-operator ready: true, restart count 0
Apr  6 22:11:58.581: INFO: kube-state-metrics-595cb5cc-hkr95 from pf9-monitoring started at 2020-04-06 21:53:20 +0000 UTC (1 container statuses recorded)
Apr  6 22:11:58.581: INFO: 	Container kube-state-metrics ready: true, restart count 0
Apr  6 22:11:58.581: INFO: node-exporter-q8z8v from pf9-monitoring started at 2020-04-06 21:53:24 +0000 UTC (1 container statuses recorded)
Apr  6 22:11:58.581: INFO: 	Container node-exporter ready: true, restart count 0
Apr  6 22:11:58.581: INFO: sonobuoy from sonobuoy started at 2020-04-06 21:55:11 +0000 UTC (1 container statuses recorded)
Apr  6 22:11:58.581: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr  6 22:11:58.581: INFO: 
Logging pods the kubelet thinks is on node 10.0.0.43 before test
Apr  6 22:11:58.587: INFO: catalog-operator-5898bbb7d6-86vpd from pf9-olm started at 2020-04-06 21:53:10 +0000 UTC (1 container statuses recorded)
Apr  6 22:11:58.587: INFO: 	Container catalog-operator ready: true, restart count 0
Apr  6 22:11:58.587: INFO: sonobuoy-systemd-logs-daemon-set-3f2ae32d33c24b28-2j6sr from sonobuoy started at 2020-04-06 21:55:15 +0000 UTC (2 container statuses recorded)
Apr  6 22:11:58.587: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  6 22:11:58.587: INFO: 	Container systemd-logs ready: true, restart count 0
Apr  6 22:11:58.587: INFO: node-exporter-xl5fz from pf9-monitoring started at 2020-04-06 21:53:24 +0000 UTC (1 container statuses recorded)
Apr  6 22:11:58.587: INFO: 	Container node-exporter ready: true, restart count 0
Apr  6 22:11:58.587: INFO: packageserver-7799547bfb-ztvbk from pf9-olm started at 2020-04-06 21:53:29 +0000 UTC (1 container statuses recorded)
Apr  6 22:11:58.587: INFO: 	Container packageserver ready: true, restart count 0
Apr  6 22:11:58.587: INFO: comms-proxy-gpw8d from pf9-monitoring started at 2020-04-06 22:08:48 +0000 UTC (1 container statuses recorded)
Apr  6 22:11:58.587: INFO: 	Container envoy ready: true, restart count 0
Apr  6 22:11:58.587: INFO: grafana-86dfdd45b7-78rmr from pf9-monitoring started at 2020-04-06 22:09:29 +0000 UTC (2 container statuses recorded)
Apr  6 22:11:58.587: INFO: 	Container grafana ready: true, restart count 0
Apr  6 22:11:58.587: INFO: 	Container proxy ready: true, restart count 0
Apr  6 22:11:58.587: INFO: prometheus-system-0 from pf9-monitoring started at 2020-04-06 22:09:29 +0000 UTC (3 container statuses recorded)
Apr  6 22:11:58.587: INFO: 	Container prometheus ready: true, restart count 1
Apr  6 22:11:58.587: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Apr  6 22:11:58.587: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Apr  6 22:11:58.587: INFO: 
Logging pods the kubelet thinks is on node 10.0.0.44 before test
Apr  6 22:11:58.594: INFO: sonobuoy-e2e-job-c807e2fec0184d0b from sonobuoy started at 2020-04-06 21:55:15 +0000 UTC (2 container statuses recorded)
Apr  6 22:11:58.594: INFO: 	Container e2e ready: true, restart count 0
Apr  6 22:11:58.594: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  6 22:11:58.594: INFO: packageserver-7799547bfb-5vjt4 from pf9-olm started at 2020-04-06 21:53:20 +0000 UTC (1 container statuses recorded)
Apr  6 22:11:58.594: INFO: 	Container packageserver ready: true, restart count 0
Apr  6 22:11:58.594: INFO: platform9-operators-z62nw from pf9-olm started at 2020-04-06 21:53:38 +0000 UTC (1 container statuses recorded)
Apr  6 22:11:58.594: INFO: 	Container registry-server ready: true, restart count 0
Apr  6 22:11:58.594: INFO: alertmanager-sysalert-0 from pf9-monitoring started at 2020-04-06 22:09:29 +0000 UTC (2 container statuses recorded)
Apr  6 22:11:58.594: INFO: 	Container alertmanager ready: true, restart count 0
Apr  6 22:11:58.594: INFO: 	Container config-reloader ready: true, restart count 0
Apr  6 22:11:58.594: INFO: node-exporter-w7m2g from pf9-monitoring started at 2020-04-06 21:53:24 +0000 UTC (1 container statuses recorded)
Apr  6 22:11:58.594: INFO: 	Container node-exporter ready: true, restart count 0
Apr  6 22:11:58.594: INFO: sonobuoy-systemd-logs-daemon-set-3f2ae32d33c24b28-cst5h from sonobuoy started at 2020-04-06 21:55:15 +0000 UTC (2 container statuses recorded)
Apr  6 22:11:58.594: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  6 22:11:58.594: INFO: 	Container systemd-logs ready: true, restart count 0
Apr  6 22:11:58.594: INFO: monhelper-666465d6b5-8t499 from pf9-operators started at 2020-04-06 22:08:44 +0000 UTC (1 container statuses recorded)
Apr  6 22:11:58.594: INFO: 	Container monhelper ready: true, restart count 0
Apr  6 22:11:58.594: INFO: comms-proxy-28brb from pf9-monitoring started at 2020-04-06 22:08:48 +0000 UTC (1 container statuses recorded)
Apr  6 22:11:58.594: INFO: 	Container envoy ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-640a080b-62de-47a6-a72d-dec6f7baf062 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-640a080b-62de-47a6-a72d-dec6f7baf062 off the node 10.0.0.43
STEP: verifying the node doesn't have the label kubernetes.io/e2e-640a080b-62de-47a6-a72d-dec6f7baf062
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:17:04.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8448" for this suite.
Apr  6 22:17:12.666: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:17:12.824: INFO: namespace sched-pred-8448 deletion completed in 8.168910924s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:314.289 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:17:12.824: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Apr  6 22:17:12.847: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:17:25.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7025" for this suite.
Apr  6 22:17:31.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:17:31.823: INFO: namespace pods-7025 deletion completed in 6.091112702s

• [SLOW TEST:18.998 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:17:31.823: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr  6 22:17:31.850: INFO: Waiting up to 5m0s for pod "pod-b02e694c-bd60-4c2a-9438-e3dff47dc237" in namespace "emptydir-6200" to be "success or failure"
Apr  6 22:17:31.852: INFO: Pod "pod-b02e694c-bd60-4c2a-9438-e3dff47dc237": Phase="Pending", Reason="", readiness=false. Elapsed: 1.977278ms
Apr  6 22:17:33.855: INFO: Pod "pod-b02e694c-bd60-4c2a-9438-e3dff47dc237": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005137348s
Apr  6 22:17:35.858: INFO: Pod "pod-b02e694c-bd60-4c2a-9438-e3dff47dc237": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008160445s
STEP: Saw pod success
Apr  6 22:17:35.858: INFO: Pod "pod-b02e694c-bd60-4c2a-9438-e3dff47dc237" satisfied condition "success or failure"
Apr  6 22:17:35.860: INFO: Trying to get logs from node 10.0.0.44 pod pod-b02e694c-bd60-4c2a-9438-e3dff47dc237 container test-container: <nil>
STEP: delete the pod
Apr  6 22:17:35.873: INFO: Waiting for pod pod-b02e694c-bd60-4c2a-9438-e3dff47dc237 to disappear
Apr  6 22:17:35.875: INFO: Pod pod-b02e694c-bd60-4c2a-9438-e3dff47dc237 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:17:35.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6200" for this suite.
Apr  6 22:17:41.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:17:41.954: INFO: namespace emptydir-6200 deletion completed in 6.07550204s

• [SLOW TEST:10.131 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:17:41.955: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-2f304ddb-0059-4388-b5f2-a641211ceb05
Apr  6 22:17:41.981: INFO: Pod name my-hostname-basic-2f304ddb-0059-4388-b5f2-a641211ceb05: Found 0 pods out of 1
Apr  6 22:17:46.984: INFO: Pod name my-hostname-basic-2f304ddb-0059-4388-b5f2-a641211ceb05: Found 1 pods out of 1
Apr  6 22:17:46.985: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-2f304ddb-0059-4388-b5f2-a641211ceb05" are running
Apr  6 22:17:46.987: INFO: Pod "my-hostname-basic-2f304ddb-0059-4388-b5f2-a641211ceb05-g5tkr" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-06 22:17:41 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-06 22:17:43 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-06 22:17:43 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-06 22:17:41 +0000 UTC Reason: Message:}])
Apr  6 22:17:46.987: INFO: Trying to dial the pod
Apr  6 22:17:51.996: INFO: Controller my-hostname-basic-2f304ddb-0059-4388-b5f2-a641211ceb05: Got expected result from replica 1 [my-hostname-basic-2f304ddb-0059-4388-b5f2-a641211ceb05-g5tkr]: "my-hostname-basic-2f304ddb-0059-4388-b5f2-a641211ceb05-g5tkr", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:17:51.996: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5034" for this suite.
Apr  6 22:17:58.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:17:58.081: INFO: namespace replication-controller-5034 deletion completed in 6.080845942s

• [SLOW TEST:16.126 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:17:58.081: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-fc328db8-7ecf-4c50-b1f6-254e2d21cb28
STEP: Creating a pod to test consume secrets
Apr  6 22:17:58.113: INFO: Waiting up to 5m0s for pod "pod-secrets-efbdf4b4-a4aa-4d52-a61d-e3215c646230" in namespace "secrets-2557" to be "success or failure"
Apr  6 22:17:58.115: INFO: Pod "pod-secrets-efbdf4b4-a4aa-4d52-a61d-e3215c646230": Phase="Pending", Reason="", readiness=false. Elapsed: 2.272443ms
Apr  6 22:18:00.118: INFO: Pod "pod-secrets-efbdf4b4-a4aa-4d52-a61d-e3215c646230": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005378036s
STEP: Saw pod success
Apr  6 22:18:00.118: INFO: Pod "pod-secrets-efbdf4b4-a4aa-4d52-a61d-e3215c646230" satisfied condition "success or failure"
Apr  6 22:18:00.122: INFO: Trying to get logs from node 10.0.0.43 pod pod-secrets-efbdf4b4-a4aa-4d52-a61d-e3215c646230 container secret-volume-test: <nil>
STEP: delete the pod
Apr  6 22:18:00.145: INFO: Waiting for pod pod-secrets-efbdf4b4-a4aa-4d52-a61d-e3215c646230 to disappear
Apr  6 22:18:00.147: INFO: Pod pod-secrets-efbdf4b4-a4aa-4d52-a61d-e3215c646230 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:18:00.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2557" for this suite.
Apr  6 22:18:06.160: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:18:06.230: INFO: namespace secrets-2557 deletion completed in 6.079418153s

• [SLOW TEST:8.149 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:18:06.230: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:18:27.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2663" for this suite.
Apr  6 22:18:33.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:18:33.484: INFO: namespace container-runtime-2663 deletion completed in 6.080278382s

• [SLOW TEST:27.254 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:18:33.484: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  6 22:18:33.850: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  6 22:18:36.900: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:18:36.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7330" for this suite.
Apr  6 22:18:42.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:18:43.043: INFO: namespace webhook-7330 deletion completed in 6.083684579s
STEP: Destroying namespace "webhook-7330-markers" for this suite.
Apr  6 22:18:49.051: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:18:49.121: INFO: namespace webhook-7330-markers deletion completed in 6.078097276s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.645 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:18:49.130: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Apr  6 22:18:53.684: INFO: Successfully updated pod "annotationupdate17f5d208-e8d7-48ab-9444-d70a54675f04"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:18:55.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3335" for this suite.
Apr  6 22:19:07.710: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:19:07.781: INFO: namespace downward-api-3335 deletion completed in 12.079785941s

• [SLOW TEST:18.652 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:19:07.782: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Apr  6 22:19:07.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-1971 -- logs-generator --log-lines-total 100 --run-duration 20s'
Apr  6 22:19:07.886: INFO: stderr: ""
Apr  6 22:19:07.886: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Apr  6 22:19:07.886: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Apr  6 22:19:07.886: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-1971" to be "running and ready, or succeeded"
Apr  6 22:19:07.888: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.198755ms
Apr  6 22:19:09.891: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.005328356s
Apr  6 22:19:09.891: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Apr  6 22:19:09.891: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Apr  6 22:19:09.891: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 logs logs-generator logs-generator --namespace=kubectl-1971'
Apr  6 22:19:09.968: INFO: stderr: ""
Apr  6 22:19:09.968: INFO: stdout: "I0406 22:19:08.808644       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/t5m 353\nI0406 22:19:09.008851       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/phdq 585\nI0406 22:19:09.208921       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/kl6 395\nI0406 22:19:09.408858       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/mmrg 500\nI0406 22:19:09.608845       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/nxvz 500\nI0406 22:19:09.808839       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/xqc 307\n"
STEP: limiting log lines
Apr  6 22:19:09.968: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 logs logs-generator logs-generator --namespace=kubectl-1971 --tail=1'
Apr  6 22:19:10.048: INFO: stderr: ""
Apr  6 22:19:10.048: INFO: stdout: "I0406 22:19:10.008849       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/cmk 407\n"
STEP: limiting log bytes
Apr  6 22:19:10.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 logs logs-generator logs-generator --namespace=kubectl-1971 --limit-bytes=1'
Apr  6 22:19:10.128: INFO: stderr: ""
Apr  6 22:19:10.128: INFO: stdout: "I"
STEP: exposing timestamps
Apr  6 22:19:10.128: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 logs logs-generator logs-generator --namespace=kubectl-1971 --tail=1 --timestamps'
Apr  6 22:19:10.215: INFO: stderr: ""
Apr  6 22:19:10.215: INFO: stdout: "2020-04-06T22:19:10.20902601Z I0406 22:19:10.208848       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/4pj 439\n"
STEP: restricting to a time range
Apr  6 22:19:12.715: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 logs logs-generator logs-generator --namespace=kubectl-1971 --since=1s'
Apr  6 22:19:12.799: INFO: stderr: ""
Apr  6 22:19:12.799: INFO: stdout: "I0406 22:19:11.808855       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/x6t 503\nI0406 22:19:12.008824       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/hz7 202\nI0406 22:19:12.208840       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/2m5 271\nI0406 22:19:12.408844       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/xpm 257\nI0406 22:19:12.608883       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/9zpt 255\n"
Apr  6 22:19:12.800: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 logs logs-generator logs-generator --namespace=kubectl-1971 --since=24h'
Apr  6 22:19:12.887: INFO: stderr: ""
Apr  6 22:19:12.887: INFO: stdout: "I0406 22:19:08.808644       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/ns/pods/t5m 353\nI0406 22:19:09.008851       1 logs_generator.go:76] 1 GET /api/v1/namespaces/ns/pods/phdq 585\nI0406 22:19:09.208921       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/kube-system/pods/kl6 395\nI0406 22:19:09.408858       1 logs_generator.go:76] 3 POST /api/v1/namespaces/default/pods/mmrg 500\nI0406 22:19:09.608845       1 logs_generator.go:76] 4 GET /api/v1/namespaces/ns/pods/nxvz 500\nI0406 22:19:09.808839       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/ns/pods/xqc 307\nI0406 22:19:10.008849       1 logs_generator.go:76] 6 GET /api/v1/namespaces/default/pods/cmk 407\nI0406 22:19:10.208848       1 logs_generator.go:76] 7 POST /api/v1/namespaces/ns/pods/4pj 439\nI0406 22:19:10.409051       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/7r8 332\nI0406 22:19:10.608810       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/default/pods/gpq 552\nI0406 22:19:10.808849       1 logs_generator.go:76] 10 PUT /api/v1/namespaces/default/pods/fkq4 478\nI0406 22:19:11.008906       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/bcz 443\nI0406 22:19:11.208843       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/default/pods/r4j 246\nI0406 22:19:11.408846       1 logs_generator.go:76] 13 GET /api/v1/namespaces/ns/pods/fjg 370\nI0406 22:19:11.608869       1 logs_generator.go:76] 14 GET /api/v1/namespaces/ns/pods/hds 260\nI0406 22:19:11.808855       1 logs_generator.go:76] 15 POST /api/v1/namespaces/default/pods/x6t 503\nI0406 22:19:12.008824       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/default/pods/hz7 202\nI0406 22:19:12.208840       1 logs_generator.go:76] 17 PUT /api/v1/namespaces/default/pods/2m5 271\nI0406 22:19:12.408844       1 logs_generator.go:76] 18 POST /api/v1/namespaces/ns/pods/xpm 257\nI0406 22:19:12.608883       1 logs_generator.go:76] 19 GET /api/v1/namespaces/default/pods/9zpt 255\nI0406 22:19:12.808823       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/m4n 519\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Apr  6 22:19:12.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 delete pod logs-generator --namespace=kubectl-1971'
Apr  6 22:19:19.848: INFO: stderr: ""
Apr  6 22:19:19.848: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:19:19.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1971" for this suite.
Apr  6 22:19:25.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:19:25.938: INFO: namespace kubectl-1971 deletion completed in 6.085729827s

• [SLOW TEST:18.156 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:19:25.938: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr  6 22:19:28.487: INFO: Successfully updated pod "pod-update-f1b84fa4-1706-415a-ab19-319ae80b3e73"
STEP: verifying the updated pod is in kubernetes
Apr  6 22:19:28.493: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:19:28.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5716" for this suite.
Apr  6 22:19:56.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:19:56.576: INFO: namespace pods-5716 deletion completed in 28.078511942s

• [SLOW TEST:30.637 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:19:56.576: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-e04b5e7e-2991-454d-9cf8-cb14d48a5da5
STEP: Creating a pod to test consume configMaps
Apr  6 22:19:56.606: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-8eb5e8fe-a5fc-46c0-8024-6625e040089a" in namespace "projected-715" to be "success or failure"
Apr  6 22:19:56.609: INFO: Pod "pod-projected-configmaps-8eb5e8fe-a5fc-46c0-8024-6625e040089a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.304735ms
Apr  6 22:19:58.612: INFO: Pod "pod-projected-configmaps-8eb5e8fe-a5fc-46c0-8024-6625e040089a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005533586s
STEP: Saw pod success
Apr  6 22:19:58.612: INFO: Pod "pod-projected-configmaps-8eb5e8fe-a5fc-46c0-8024-6625e040089a" satisfied condition "success or failure"
Apr  6 22:19:58.614: INFO: Trying to get logs from node 10.0.0.44 pod pod-projected-configmaps-8eb5e8fe-a5fc-46c0-8024-6625e040089a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  6 22:19:58.629: INFO: Waiting for pod pod-projected-configmaps-8eb5e8fe-a5fc-46c0-8024-6625e040089a to disappear
Apr  6 22:19:58.631: INFO: Pod pod-projected-configmaps-8eb5e8fe-a5fc-46c0-8024-6625e040089a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:19:58.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-715" for this suite.
Apr  6 22:20:04.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:20:04.717: INFO: namespace projected-715 deletion completed in 6.082479324s

• [SLOW TEST:8.142 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:20:04.717: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Apr  6 22:20:07.262: INFO: Successfully updated pod "pod-update-activedeadlineseconds-cced6824-532f-4cb9-9712-7dd7d585b544"
Apr  6 22:20:07.262: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-cced6824-532f-4cb9-9712-7dd7d585b544" in namespace "pods-2048" to be "terminated due to deadline exceeded"
Apr  6 22:20:07.265: INFO: Pod "pod-update-activedeadlineseconds-cced6824-532f-4cb9-9712-7dd7d585b544": Phase="Running", Reason="", readiness=true. Elapsed: 2.96851ms
Apr  6 22:20:09.268: INFO: Pod "pod-update-activedeadlineseconds-cced6824-532f-4cb9-9712-7dd7d585b544": Phase="Running", Reason="", readiness=true. Elapsed: 2.006124844s
Apr  6 22:20:11.271: INFO: Pod "pod-update-activedeadlineseconds-cced6824-532f-4cb9-9712-7dd7d585b544": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.009310621s
Apr  6 22:20:11.271: INFO: Pod "pod-update-activedeadlineseconds-cced6824-532f-4cb9-9712-7dd7d585b544" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:20:11.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2048" for this suite.
Apr  6 22:20:17.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:20:17.352: INFO: namespace pods-2048 deletion completed in 6.077371501s

• [SLOW TEST:12.635 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:20:17.353: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 22:20:17.376: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:20:17.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4105" for this suite.
Apr  6 22:20:23.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:20:23.526: INFO: namespace custom-resource-definition-4105 deletion completed in 6.119690807s

• [SLOW TEST:6.173 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:20:23.526: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-6309d333-964b-4d7c-9c64-80a1247bac87
STEP: Creating a pod to test consume secrets
Apr  6 22:20:23.554: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-82b5fbd5-7b3b-4782-8303-61839bdb687a" in namespace "projected-3489" to be "success or failure"
Apr  6 22:20:23.557: INFO: Pod "pod-projected-secrets-82b5fbd5-7b3b-4782-8303-61839bdb687a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.544551ms
Apr  6 22:20:25.560: INFO: Pod "pod-projected-secrets-82b5fbd5-7b3b-4782-8303-61839bdb687a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006660805s
STEP: Saw pod success
Apr  6 22:20:25.560: INFO: Pod "pod-projected-secrets-82b5fbd5-7b3b-4782-8303-61839bdb687a" satisfied condition "success or failure"
Apr  6 22:20:25.563: INFO: Trying to get logs from node 10.0.0.42 pod pod-projected-secrets-82b5fbd5-7b3b-4782-8303-61839bdb687a container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  6 22:20:25.585: INFO: Waiting for pod pod-projected-secrets-82b5fbd5-7b3b-4782-8303-61839bdb687a to disappear
Apr  6 22:20:25.587: INFO: Pod pod-projected-secrets-82b5fbd5-7b3b-4782-8303-61839bdb687a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:20:25.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3489" for this suite.
Apr  6 22:20:31.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:20:31.663: INFO: namespace projected-3489 deletion completed in 6.072284338s

• [SLOW TEST:8.137 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:20:31.663: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 22:20:31.683: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Apr  6 22:20:31.688: INFO: Pod name sample-pod: Found 0 pods out of 1
Apr  6 22:20:36.692: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr  6 22:20:36.692: INFO: Creating deployment "test-rolling-update-deployment"
Apr  6 22:20:36.695: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Apr  6 22:20:36.703: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Apr  6 22:20:38.713: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Apr  6 22:20:38.716: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Apr  6 22:20:38.723: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-9261 /apis/apps/v1/namespaces/deployment-9261/deployments/test-rolling-update-deployment 9e0ed65e-008c-4f4b-93f7-e8b61fc86e96 7546 1 2020-04-06 22:20:36 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0026bb288 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-04-06 22:20:36 +0000 UTC,LastTransitionTime:2020-04-06 22:20:36 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2020-04-06 22:20:38 +0000 UTC,LastTransitionTime:2020-04-06 22:20:36 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr  6 22:20:38.726: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-9261 /apis/apps/v1/namespaces/deployment-9261/replicasets/test-rolling-update-deployment-55d946486 b4cece39-dff4-462c-8d3e-f2ef8e9ecad7 7536 1 2020-04-06 22:20:36 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 9e0ed65e-008c-4f4b-93f7-e8b61fc86e96 0xc0026bb780 0xc0026bb781}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0026bb7f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr  6 22:20:38.726: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Apr  6 22:20:38.726: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-9261 /apis/apps/v1/namespaces/deployment-9261/replicasets/test-rolling-update-controller 7be6ce58-fbb2-4e80-9ce5-a72dc8280add 7545 2 2020-04-06 22:20:31 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 9e0ed65e-008c-4f4b-93f7-e8b61fc86e96 0xc0026bb6af 0xc0026bb6c0}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0026bb728 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr  6 22:20:38.730: INFO: Pod "test-rolling-update-deployment-55d946486-pj582" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-pj582 test-rolling-update-deployment-55d946486- deployment-9261 /api/v1/namespaces/deployment-9261/pods/test-rolling-update-deployment-55d946486-pj582 ba1cdca5-c32f-4db6-af76-7d445868c51d 7535 0 2020-04-06 22:20:36 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 b4cece39-dff4-462c-8d3e-f2ef8e9ecad7 0xc0026bbc80 0xc0026bbc81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-gswfs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-gswfs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-gswfs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 22:20:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 22:20:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 22:20:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 22:20:36 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.44,PodIP:10.20.16.40,StartTime:2020-04-06 22:20:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-06 22:20:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://f8c5bf26aa1bd600f4f1628173f442b578377ad18b65709e03356aaa7319a598,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.20.16.40,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:20:38.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9261" for this suite.
Apr  6 22:20:44.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:20:44.813: INFO: namespace deployment-9261 deletion completed in 6.07771383s

• [SLOW TEST:13.149 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:20:44.813: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Apr  6 22:20:44.837: INFO: Waiting up to 5m0s for pod "pod-dfb6f8f9-9749-41f2-8906-aada1b0235ff" in namespace "emptydir-4619" to be "success or failure"
Apr  6 22:20:44.839: INFO: Pod "pod-dfb6f8f9-9749-41f2-8906-aada1b0235ff": Phase="Pending", Reason="", readiness=false. Elapsed: 2.177977ms
Apr  6 22:20:46.842: INFO: Pod "pod-dfb6f8f9-9749-41f2-8906-aada1b0235ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005257105s
STEP: Saw pod success
Apr  6 22:20:46.842: INFO: Pod "pod-dfb6f8f9-9749-41f2-8906-aada1b0235ff" satisfied condition "success or failure"
Apr  6 22:20:46.844: INFO: Trying to get logs from node 10.0.0.43 pod pod-dfb6f8f9-9749-41f2-8906-aada1b0235ff container test-container: <nil>
STEP: delete the pod
Apr  6 22:20:46.869: INFO: Waiting for pod pod-dfb6f8f9-9749-41f2-8906-aada1b0235ff to disappear
Apr  6 22:20:46.871: INFO: Pod pod-dfb6f8f9-9749-41f2-8906-aada1b0235ff no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:20:46.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4619" for this suite.
Apr  6 22:20:52.883: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:20:53.019: INFO: namespace emptydir-4619 deletion completed in 6.143919371s

• [SLOW TEST:8.206 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:20:53.019: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename namespaces
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:21:06.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4704" for this suite.
Apr  6 22:21:12.109: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:21:12.180: INFO: namespace namespaces-4704 deletion completed in 6.080165541s
STEP: Destroying namespace "nsdeletetest-3553" for this suite.
Apr  6 22:21:12.182: INFO: Namespace nsdeletetest-3553 was already deleted
STEP: Destroying namespace "nsdeletetest-1931" for this suite.
Apr  6 22:21:18.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:21:18.273: INFO: namespace nsdeletetest-1931 deletion completed in 6.090701491s

• [SLOW TEST:25.254 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:21:18.273: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Apr  6 22:21:18.292: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  6 22:21:18.301: INFO: Waiting for terminating namespaces to be deleted...
Apr  6 22:21:18.304: INFO: 
Logging pods the kubelet thinks is on node 10.0.0.42 before test
Apr  6 22:21:18.309: INFO: sonobuoy from sonobuoy started at 2020-04-06 21:55:11 +0000 UTC (1 container statuses recorded)
Apr  6 22:21:18.309: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr  6 22:21:18.309: INFO: sonobuoy-systemd-logs-daemon-set-3f2ae32d33c24b28-z5vfz from sonobuoy started at 2020-04-06 21:55:15 +0000 UTC (2 container statuses recorded)
Apr  6 22:21:18.309: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  6 22:21:18.309: INFO: 	Container systemd-logs ready: true, restart count 0
Apr  6 22:21:18.309: INFO: prometheus-operator-546b677c-8nsvj from pf9-operators started at 2020-04-06 22:08:44 +0000 UTC (1 container statuses recorded)
Apr  6 22:21:18.309: INFO: 	Container prometheus-operator ready: true, restart count 0
Apr  6 22:21:18.309: INFO: comms-proxy-f9jz2 from pf9-monitoring started at 2020-04-06 22:08:48 +0000 UTC (1 container statuses recorded)
Apr  6 22:21:18.309: INFO: 	Container envoy ready: true, restart count 0
Apr  6 22:21:18.309: INFO: olm-operator-76d446f94c-rhq8h from pf9-olm started at 2020-04-06 21:53:11 +0000 UTC (1 container statuses recorded)
Apr  6 22:21:18.309: INFO: 	Container olm-operator ready: true, restart count 0
Apr  6 22:21:18.309: INFO: kube-state-metrics-595cb5cc-hkr95 from pf9-monitoring started at 2020-04-06 21:53:20 +0000 UTC (1 container statuses recorded)
Apr  6 22:21:18.309: INFO: 	Container kube-state-metrics ready: true, restart count 0
Apr  6 22:21:18.309: INFO: node-exporter-q8z8v from pf9-monitoring started at 2020-04-06 21:53:24 +0000 UTC (1 container statuses recorded)
Apr  6 22:21:18.309: INFO: 	Container node-exporter ready: true, restart count 0
Apr  6 22:21:18.309: INFO: 
Logging pods the kubelet thinks is on node 10.0.0.43 before test
Apr  6 22:21:18.315: INFO: node-exporter-xl5fz from pf9-monitoring started at 2020-04-06 21:53:24 +0000 UTC (1 container statuses recorded)
Apr  6 22:21:18.315: INFO: 	Container node-exporter ready: true, restart count 0
Apr  6 22:21:18.315: INFO: packageserver-7799547bfb-ztvbk from pf9-olm started at 2020-04-06 21:53:29 +0000 UTC (1 container statuses recorded)
Apr  6 22:21:18.315: INFO: 	Container packageserver ready: true, restart count 0
Apr  6 22:21:18.315: INFO: comms-proxy-gpw8d from pf9-monitoring started at 2020-04-06 22:08:48 +0000 UTC (1 container statuses recorded)
Apr  6 22:21:18.315: INFO: 	Container envoy ready: true, restart count 0
Apr  6 22:21:18.315: INFO: grafana-86dfdd45b7-78rmr from pf9-monitoring started at 2020-04-06 22:09:29 +0000 UTC (2 container statuses recorded)
Apr  6 22:21:18.315: INFO: 	Container grafana ready: true, restart count 0
Apr  6 22:21:18.315: INFO: 	Container proxy ready: true, restart count 0
Apr  6 22:21:18.315: INFO: prometheus-system-0 from pf9-monitoring started at 2020-04-06 22:09:29 +0000 UTC (3 container statuses recorded)
Apr  6 22:21:18.315: INFO: 	Container prometheus ready: true, restart count 1
Apr  6 22:21:18.315: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Apr  6 22:21:18.315: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Apr  6 22:21:18.315: INFO: catalog-operator-5898bbb7d6-86vpd from pf9-olm started at 2020-04-06 21:53:10 +0000 UTC (1 container statuses recorded)
Apr  6 22:21:18.315: INFO: 	Container catalog-operator ready: true, restart count 0
Apr  6 22:21:18.315: INFO: sonobuoy-systemd-logs-daemon-set-3f2ae32d33c24b28-2j6sr from sonobuoy started at 2020-04-06 21:55:15 +0000 UTC (2 container statuses recorded)
Apr  6 22:21:18.315: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  6 22:21:18.315: INFO: 	Container systemd-logs ready: true, restart count 0
Apr  6 22:21:18.315: INFO: 
Logging pods the kubelet thinks is on node 10.0.0.44 before test
Apr  6 22:21:18.321: INFO: monhelper-666465d6b5-8t499 from pf9-operators started at 2020-04-06 22:08:44 +0000 UTC (1 container statuses recorded)
Apr  6 22:21:18.321: INFO: 	Container monhelper ready: true, restart count 0
Apr  6 22:21:18.321: INFO: comms-proxy-28brb from pf9-monitoring started at 2020-04-06 22:08:48 +0000 UTC (1 container statuses recorded)
Apr  6 22:21:18.321: INFO: 	Container envoy ready: true, restart count 0
Apr  6 22:21:18.321: INFO: node-exporter-w7m2g from pf9-monitoring started at 2020-04-06 21:53:24 +0000 UTC (1 container statuses recorded)
Apr  6 22:21:18.321: INFO: 	Container node-exporter ready: true, restart count 0
Apr  6 22:21:18.321: INFO: sonobuoy-systemd-logs-daemon-set-3f2ae32d33c24b28-cst5h from sonobuoy started at 2020-04-06 21:55:15 +0000 UTC (2 container statuses recorded)
Apr  6 22:21:18.321: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  6 22:21:18.321: INFO: 	Container systemd-logs ready: true, restart count 0
Apr  6 22:21:18.321: INFO: platform9-operators-z62nw from pf9-olm started at 2020-04-06 21:53:38 +0000 UTC (1 container statuses recorded)
Apr  6 22:21:18.321: INFO: 	Container registry-server ready: true, restart count 0
Apr  6 22:21:18.321: INFO: alertmanager-sysalert-0 from pf9-monitoring started at 2020-04-06 22:09:29 +0000 UTC (2 container statuses recorded)
Apr  6 22:21:18.321: INFO: 	Container alertmanager ready: true, restart count 0
Apr  6 22:21:18.321: INFO: 	Container config-reloader ready: true, restart count 0
Apr  6 22:21:18.321: INFO: sonobuoy-e2e-job-c807e2fec0184d0b from sonobuoy started at 2020-04-06 21:55:15 +0000 UTC (2 container statuses recorded)
Apr  6 22:21:18.321: INFO: 	Container e2e ready: true, restart count 0
Apr  6 22:21:18.321: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  6 22:21:18.321: INFO: packageserver-7799547bfb-5vjt4 from pf9-olm started at 2020-04-06 21:53:20 +0000 UTC (1 container statuses recorded)
Apr  6 22:21:18.321: INFO: 	Container packageserver ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node 10.0.0.42
STEP: verifying the node has the label node 10.0.0.43
STEP: verifying the node has the label node 10.0.0.44
Apr  6 22:21:18.362: INFO: Pod alertmanager-sysalert-0 requesting resource cpu=150m on Node 10.0.0.44
Apr  6 22:21:18.362: INFO: Pod comms-proxy-28brb requesting resource cpu=0m on Node 10.0.0.44
Apr  6 22:21:18.362: INFO: Pod comms-proxy-f9jz2 requesting resource cpu=0m on Node 10.0.0.42
Apr  6 22:21:18.362: INFO: Pod comms-proxy-gpw8d requesting resource cpu=0m on Node 10.0.0.43
Apr  6 22:21:18.362: INFO: Pod grafana-86dfdd45b7-78rmr requesting resource cpu=100m on Node 10.0.0.43
Apr  6 22:21:18.362: INFO: Pod kube-state-metrics-595cb5cc-hkr95 requesting resource cpu=100m on Node 10.0.0.42
Apr  6 22:21:18.362: INFO: Pod node-exporter-q8z8v requesting resource cpu=102m on Node 10.0.0.42
Apr  6 22:21:18.362: INFO: Pod node-exporter-w7m2g requesting resource cpu=102m on Node 10.0.0.44
Apr  6 22:21:18.362: INFO: Pod node-exporter-xl5fz requesting resource cpu=102m on Node 10.0.0.43
Apr  6 22:21:18.362: INFO: Pod prometheus-system-0 requesting resource cpu=500m on Node 10.0.0.43
Apr  6 22:21:18.362: INFO: Pod catalog-operator-5898bbb7d6-86vpd requesting resource cpu=10m on Node 10.0.0.43
Apr  6 22:21:18.362: INFO: Pod olm-operator-76d446f94c-rhq8h requesting resource cpu=10m on Node 10.0.0.42
Apr  6 22:21:18.362: INFO: Pod packageserver-7799547bfb-5vjt4 requesting resource cpu=10m on Node 10.0.0.44
Apr  6 22:21:18.362: INFO: Pod packageserver-7799547bfb-ztvbk requesting resource cpu=10m on Node 10.0.0.43
Apr  6 22:21:18.362: INFO: Pod platform9-operators-z62nw requesting resource cpu=10m on Node 10.0.0.44
Apr  6 22:21:18.362: INFO: Pod monhelper-666465d6b5-8t499 requesting resource cpu=50m on Node 10.0.0.44
Apr  6 22:21:18.362: INFO: Pod prometheus-operator-546b677c-8nsvj requesting resource cpu=100m on Node 10.0.0.42
Apr  6 22:21:18.362: INFO: Pod sonobuoy requesting resource cpu=0m on Node 10.0.0.42
Apr  6 22:21:18.362: INFO: Pod sonobuoy-e2e-job-c807e2fec0184d0b requesting resource cpu=0m on Node 10.0.0.44
Apr  6 22:21:18.362: INFO: Pod sonobuoy-systemd-logs-daemon-set-3f2ae32d33c24b28-2j6sr requesting resource cpu=0m on Node 10.0.0.43
Apr  6 22:21:18.362: INFO: Pod sonobuoy-systemd-logs-daemon-set-3f2ae32d33c24b28-cst5h requesting resource cpu=0m on Node 10.0.0.44
Apr  6 22:21:18.362: INFO: Pod sonobuoy-systemd-logs-daemon-set-3f2ae32d33c24b28-z5vfz requesting resource cpu=0m on Node 10.0.0.42
STEP: Starting Pods to consume most of the cluster CPU.
Apr  6 22:21:18.362: INFO: Creating a pod which consumes cpu=10981m on Node 10.0.0.42
Apr  6 22:21:18.369: INFO: Creating a pod which consumes cpu=10694m on Node 10.0.0.43
Apr  6 22:21:18.374: INFO: Creating a pod which consumes cpu=10974m on Node 10.0.0.44
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-35e6b660-8002-4545-bb2b-9ad436e2d405.16035b1e0d1c4025], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1368/filler-pod-35e6b660-8002-4545-bb2b-9ad436e2d405 to 10.0.0.43]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-35e6b660-8002-4545-bb2b-9ad436e2d405.16035b1e39e1ca73], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-35e6b660-8002-4545-bb2b-9ad436e2d405.16035b1e3ce989a1], Reason = [Created], Message = [Created container filler-pod-35e6b660-8002-4545-bb2b-9ad436e2d405]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-35e6b660-8002-4545-bb2b-9ad436e2d405.16035b1e4738fe62], Reason = [Started], Message = [Started container filler-pod-35e6b660-8002-4545-bb2b-9ad436e2d405]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3d5582f9-0b58-4d0b-8422-978dcb47a770.16035b1e0d41d193], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1368/filler-pod-3d5582f9-0b58-4d0b-8422-978dcb47a770 to 10.0.0.44]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3d5582f9-0b58-4d0b-8422-978dcb47a770.16035b1e3a0e8eab], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3d5582f9-0b58-4d0b-8422-978dcb47a770.16035b1e3e7236ba], Reason = [Created], Message = [Created container filler-pod-3d5582f9-0b58-4d0b-8422-978dcb47a770]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3d5582f9-0b58-4d0b-8422-978dcb47a770.16035b1e4821875b], Reason = [Started], Message = [Started container filler-pod-3d5582f9-0b58-4d0b-8422-978dcb47a770]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-49d0fe77-6d70-4be6-9b4d-ad273f27e423.16035b1e0cabac62], Reason = [Scheduled], Message = [Successfully assigned sched-pred-1368/filler-pod-49d0fe77-6d70-4be6-9b4d-ad273f27e423 to 10.0.0.42]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-49d0fe77-6d70-4be6-9b4d-ad273f27e423.16035b1e3a8d9910], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-49d0fe77-6d70-4be6-9b4d-ad273f27e423.16035b1e3e8053d9], Reason = [Created], Message = [Created container filler-pod-49d0fe77-6d70-4be6-9b4d-ad273f27e423]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-49d0fe77-6d70-4be6-9b4d-ad273f27e423.16035b1e4ca216c2], Reason = [Started], Message = [Started container filler-pod-49d0fe77-6d70-4be6-9b4d-ad273f27e423]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.16035b1e859c98d2], Reason = [FailedScheduling], Message = [0/4 nodes are available: 1 node(s) had taints that the pod didn't tolerate, 3 Insufficient cpu.]
STEP: removing the label node off the node 10.0.0.42
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.0.0.43
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node 10.0.0.44
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:21:21.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1368" for this suite.
Apr  6 22:21:27.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:21:27.534: INFO: namespace sched-pred-1368 deletion completed in 6.098119265s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:9.261 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:21:27.534: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 22:21:27.575: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"336df56b-53ac-4387-bc39-ab0f8b8bf0c8", Controller:(*bool)(0xc003f07cfe), BlockOwnerDeletion:(*bool)(0xc003f07cff)}}
Apr  6 22:21:27.579: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"d31ba14b-6b76-4165-903c-a83077c3aed3", Controller:(*bool)(0xc003db1176), BlockOwnerDeletion:(*bool)(0xc003db1177)}}
Apr  6 22:21:27.583: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"46b86fcb-bc03-42d1-a05b-0f8dc58d8f26", Controller:(*bool)(0xc003cfbdfe), BlockOwnerDeletion:(*bool)(0xc003cfbdff)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:21:32.596: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-404" for this suite.
Apr  6 22:21:38.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:21:38.689: INFO: namespace gc-404 deletion completed in 6.089835973s

• [SLOW TEST:11.155 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:21:38.690: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 22:21:38.721: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-6051fd73-8186-46e4-8509-1fb35a89c9ac" in namespace "security-context-test-1130" to be "success or failure"
Apr  6 22:21:38.724: INFO: Pod "alpine-nnp-false-6051fd73-8186-46e4-8509-1fb35a89c9ac": Phase="Pending", Reason="", readiness=false. Elapsed: 3.003567ms
Apr  6 22:21:40.727: INFO: Pod "alpine-nnp-false-6051fd73-8186-46e4-8509-1fb35a89c9ac": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006247337s
Apr  6 22:21:42.730: INFO: Pod "alpine-nnp-false-6051fd73-8186-46e4-8509-1fb35a89c9ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00951678s
Apr  6 22:21:42.730: INFO: Pod "alpine-nnp-false-6051fd73-8186-46e4-8509-1fb35a89c9ac" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:21:42.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1130" for this suite.
Apr  6 22:21:48.750: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:21:48.823: INFO: namespace security-context-test-1130 deletion completed in 6.080889326s

• [SLOW TEST:10.133 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:21:48.823: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Apr  6 22:21:48.847: INFO: Waiting up to 5m0s for pod "client-containers-bf80b185-583e-4707-9f5f-9f203ec04b66" in namespace "containers-2714" to be "success or failure"
Apr  6 22:21:48.852: INFO: Pod "client-containers-bf80b185-583e-4707-9f5f-9f203ec04b66": Phase="Pending", Reason="", readiness=false. Elapsed: 5.286072ms
Apr  6 22:21:50.855: INFO: Pod "client-containers-bf80b185-583e-4707-9f5f-9f203ec04b66": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008036221s
STEP: Saw pod success
Apr  6 22:21:50.855: INFO: Pod "client-containers-bf80b185-583e-4707-9f5f-9f203ec04b66" satisfied condition "success or failure"
Apr  6 22:21:50.858: INFO: Trying to get logs from node 10.0.0.43 pod client-containers-bf80b185-583e-4707-9f5f-9f203ec04b66 container test-container: <nil>
STEP: delete the pod
Apr  6 22:21:50.880: INFO: Waiting for pod client-containers-bf80b185-583e-4707-9f5f-9f203ec04b66 to disappear
Apr  6 22:21:50.884: INFO: Pod client-containers-bf80b185-583e-4707-9f5f-9f203ec04b66 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:21:50.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2714" for this suite.
Apr  6 22:21:56.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:21:56.971: INFO: namespace containers-2714 deletion completed in 6.083821192s

• [SLOW TEST:8.148 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:21:56.971: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr  6 22:21:57.000: INFO: Waiting up to 5m0s for pod "downwardapi-volume-23667798-b26e-4009-8974-42f5c2a21a4c" in namespace "downward-api-3252" to be "success or failure"
Apr  6 22:21:57.006: INFO: Pod "downwardapi-volume-23667798-b26e-4009-8974-42f5c2a21a4c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.513057ms
Apr  6 22:21:59.009: INFO: Pod "downwardapi-volume-23667798-b26e-4009-8974-42f5c2a21a4c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008761964s
STEP: Saw pod success
Apr  6 22:21:59.009: INFO: Pod "downwardapi-volume-23667798-b26e-4009-8974-42f5c2a21a4c" satisfied condition "success or failure"
Apr  6 22:21:59.012: INFO: Trying to get logs from node 10.0.0.42 pod downwardapi-volume-23667798-b26e-4009-8974-42f5c2a21a4c container client-container: <nil>
STEP: delete the pod
Apr  6 22:21:59.027: INFO: Waiting for pod downwardapi-volume-23667798-b26e-4009-8974-42f5c2a21a4c to disappear
Apr  6 22:21:59.029: INFO: Pod downwardapi-volume-23667798-b26e-4009-8974-42f5c2a21a4c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:21:59.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3252" for this suite.
Apr  6 22:22:05.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:22:05.118: INFO: namespace downward-api-3252 deletion completed in 6.084546015s

• [SLOW TEST:8.146 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:22:05.118: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4609.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-4609.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4609.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-4609.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4609.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4609.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4609.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-4609.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4609.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-4609.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4609.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 11.6.21.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.21.6.11_udp@PTR;check="$$(dig +tcp +noall +answer +search 11.6.21.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.21.6.11_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-4609.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-4609.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-4609.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-4609.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-4609.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-4609.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-4609.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-4609.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-4609.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-4609.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4609.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 11.6.21.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.21.6.11_udp@PTR;check="$$(dig +tcp +noall +answer +search 11.6.21.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.21.6.11_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  6 22:22:17.174: INFO: Unable to read wheezy_udp@dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:17.178: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:17.181: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:17.185: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:17.206: INFO: Unable to read jessie_udp@dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:17.209: INFO: Unable to read jessie_tcp@dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:17.212: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:17.215: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:17.234: INFO: Lookups using dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f failed for: [wheezy_udp@dns-test-service.dns-4609.svc.cluster.local wheezy_tcp@dns-test-service.dns-4609.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local jessie_udp@dns-test-service.dns-4609.svc.cluster.local jessie_tcp@dns-test-service.dns-4609.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local]

Apr  6 22:22:22.238: INFO: Unable to read wheezy_udp@dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:22.242: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:22.245: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:22.247: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:22.272: INFO: Unable to read jessie_udp@dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:22.275: INFO: Unable to read jessie_tcp@dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:22.278: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:22.282: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:22.299: INFO: Lookups using dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f failed for: [wheezy_udp@dns-test-service.dns-4609.svc.cluster.local wheezy_tcp@dns-test-service.dns-4609.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local jessie_udp@dns-test-service.dns-4609.svc.cluster.local jessie_tcp@dns-test-service.dns-4609.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local]

Apr  6 22:22:27.239: INFO: Unable to read wheezy_udp@dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:27.242: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:27.245: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:27.248: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:27.268: INFO: Unable to read jessie_udp@dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:27.271: INFO: Unable to read jessie_tcp@dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:27.274: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:27.277: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:27.300: INFO: Lookups using dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f failed for: [wheezy_udp@dns-test-service.dns-4609.svc.cluster.local wheezy_tcp@dns-test-service.dns-4609.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local jessie_udp@dns-test-service.dns-4609.svc.cluster.local jessie_tcp@dns-test-service.dns-4609.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local]

Apr  6 22:22:32.239: INFO: Unable to read wheezy_udp@dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:32.242: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:32.245: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:32.248: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:32.268: INFO: Unable to read jessie_udp@dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:32.270: INFO: Unable to read jessie_tcp@dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:32.274: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:32.277: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:32.292: INFO: Lookups using dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f failed for: [wheezy_udp@dns-test-service.dns-4609.svc.cluster.local wheezy_tcp@dns-test-service.dns-4609.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local jessie_udp@dns-test-service.dns-4609.svc.cluster.local jessie_tcp@dns-test-service.dns-4609.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local]

Apr  6 22:22:37.239: INFO: Unable to read wheezy_udp@dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:37.242: INFO: Unable to read wheezy_tcp@dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:37.245: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:37.249: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:37.269: INFO: Unable to read jessie_udp@dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:37.272: INFO: Unable to read jessie_tcp@dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:37.276: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:37.279: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local from pod dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f: the server could not find the requested resource (get pods dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f)
Apr  6 22:22:37.297: INFO: Lookups using dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f failed for: [wheezy_udp@dns-test-service.dns-4609.svc.cluster.local wheezy_tcp@dns-test-service.dns-4609.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local jessie_udp@dns-test-service.dns-4609.svc.cluster.local jessie_tcp@dns-test-service.dns-4609.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-4609.svc.cluster.local]

Apr  6 22:22:42.302: INFO: DNS probes using dns-4609/dns-test-0dbe7798-a3b3-4148-8454-7db6ff6bc39f succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:22:42.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4609" for this suite.
Apr  6 22:22:48.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:22:48.456: INFO: namespace dns-4609 deletion completed in 6.101141864s

• [SLOW TEST:43.338 seconds]
[sig-network] DNS
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:22:48.456: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Apr  6 22:22:48.490: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8137 /api/v1/namespaces/watch-8137/configmaps/e2e-watch-test-label-changed 31703932-f91e-4993-b2df-196209559689 8171 0 2020-04-06 22:22:48 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  6 22:22:48.490: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8137 /api/v1/namespaces/watch-8137/configmaps/e2e-watch-test-label-changed 31703932-f91e-4993-b2df-196209559689 8172 0 2020-04-06 22:22:48 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr  6 22:22:48.490: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8137 /api/v1/namespaces/watch-8137/configmaps/e2e-watch-test-label-changed 31703932-f91e-4993-b2df-196209559689 8173 0 2020-04-06 22:22:48 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Apr  6 22:22:58.507: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8137 /api/v1/namespaces/watch-8137/configmaps/e2e-watch-test-label-changed 31703932-f91e-4993-b2df-196209559689 8192 0 2020-04-06 22:22:48 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  6 22:22:58.508: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8137 /api/v1/namespaces/watch-8137/configmaps/e2e-watch-test-label-changed 31703932-f91e-4993-b2df-196209559689 8193 0 2020-04-06 22:22:48 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Apr  6 22:22:58.508: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8137 /api/v1/namespaces/watch-8137/configmaps/e2e-watch-test-label-changed 31703932-f91e-4993-b2df-196209559689 8194 0 2020-04-06 22:22:48 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:22:58.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8137" for this suite.
Apr  6 22:23:04.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:23:04.596: INFO: namespace watch-8137 deletion completed in 6.085370854s

• [SLOW TEST:16.140 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:23:04.597: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Apr  6 22:23:07.147: INFO: Successfully updated pod "labelsupdate03e2eb25-7acd-4068-8f97-cf91373311f7"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:23:09.163: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4292" for this suite.
Apr  6 22:23:21.176: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:23:21.246: INFO: namespace projected-4292 deletion completed in 12.079079628s

• [SLOW TEST:16.649 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:23:21.246: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:23:24.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2749" for this suite.
Apr  6 22:23:52.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:23:52.374: INFO: namespace replication-controller-2749 deletion completed in 28.079603668s

• [SLOW TEST:31.128 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:23:52.374: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr  6 22:23:52.403: INFO: Waiting up to 5m0s for pod "pod-e6989444-0c11-4bac-a1ba-ceb23a226813" in namespace "emptydir-6044" to be "success or failure"
Apr  6 22:23:52.405: INFO: Pod "pod-e6989444-0c11-4bac-a1ba-ceb23a226813": Phase="Pending", Reason="", readiness=false. Elapsed: 2.148684ms
Apr  6 22:23:54.408: INFO: Pod "pod-e6989444-0c11-4bac-a1ba-ceb23a226813": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005124195s
STEP: Saw pod success
Apr  6 22:23:54.408: INFO: Pod "pod-e6989444-0c11-4bac-a1ba-ceb23a226813" satisfied condition "success or failure"
Apr  6 22:23:54.410: INFO: Trying to get logs from node 10.0.0.43 pod pod-e6989444-0c11-4bac-a1ba-ceb23a226813 container test-container: <nil>
STEP: delete the pod
Apr  6 22:23:54.434: INFO: Waiting for pod pod-e6989444-0c11-4bac-a1ba-ceb23a226813 to disappear
Apr  6 22:23:54.436: INFO: Pod pod-e6989444-0c11-4bac-a1ba-ceb23a226813 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:23:54.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6044" for this suite.
Apr  6 22:24:00.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:24:00.521: INFO: namespace emptydir-6044 deletion completed in 6.078263756s

• [SLOW TEST:8.147 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:24:00.521: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:24:11.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7552" for this suite.
Apr  6 22:24:17.581: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:24:17.650: INFO: namespace resourcequota-7552 deletion completed in 6.078372446s

• [SLOW TEST:17.129 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:24:17.651: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 22:24:17.675: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 create -f - --namespace=kubectl-5957'
Apr  6 22:24:18.123: INFO: stderr: ""
Apr  6 22:24:18.123: INFO: stdout: "replicationcontroller/redis-master created\n"
Apr  6 22:24:18.123: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 create -f - --namespace=kubectl-5957'
Apr  6 22:24:18.264: INFO: stderr: ""
Apr  6 22:24:18.264: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr  6 22:24:19.268: INFO: Selector matched 1 pods for map[app:redis]
Apr  6 22:24:19.268: INFO: Found 0 / 1
Apr  6 22:24:20.267: INFO: Selector matched 1 pods for map[app:redis]
Apr  6 22:24:20.267: INFO: Found 1 / 1
Apr  6 22:24:20.267: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr  6 22:24:20.270: INFO: Selector matched 1 pods for map[app:redis]
Apr  6 22:24:20.270: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr  6 22:24:20.270: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 describe pod redis-master-4xsxs --namespace=kubectl-5957'
Apr  6 22:24:20.353: INFO: stderr: ""
Apr  6 22:24:20.353: INFO: stdout: "Name:         redis-master-4xsxs\nNamespace:    kubectl-5957\nPriority:     0\nNode:         10.0.0.44/10.0.0.44\nStart Time:   Mon, 06 Apr 2020 22:24:18 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nStatus:       Running\nIP:           10.20.16.45\nIPs:\n  IP:           10.20.16.45\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://be75163dbc2e8f9e1df1ae7a4946642049f30baa06a543b989743a06dc8d647f\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Mon, 06 Apr 2020 22:24:19 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-pxhlt (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-pxhlt:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-pxhlt\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                Message\n  ----    ------     ----       ----                -------\n  Normal  Scheduled  <unknown>  default-scheduler   Successfully assigned kubectl-5957/redis-master-4xsxs to 10.0.0.44\n  Normal  Pulled     1s         kubelet, 10.0.0.44  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    1s         kubelet, 10.0.0.44  Created container redis-master\n  Normal  Started    1s         kubelet, 10.0.0.44  Started container redis-master\n"
Apr  6 22:24:20.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 describe rc redis-master --namespace=kubectl-5957'
Apr  6 22:24:20.448: INFO: stderr: ""
Apr  6 22:24:20.448: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-5957\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-4xsxs\n"
Apr  6 22:24:20.448: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 describe service redis-master --namespace=kubectl-5957'
Apr  6 22:24:20.523: INFO: stderr: ""
Apr  6 22:24:20.523: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-5957\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.21.198.88\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.20.16.45:6379\nSession Affinity:  None\nEvents:            <none>\n"
Apr  6 22:24:20.527: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 describe node 10.0.0.41'
Apr  6 22:24:20.630: INFO: stderr: ""
Apr  6 22:24:20.630: INFO: stdout: "Name:               10.0.0.41\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=10.0.0.41\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Mon, 06 Apr 2020 21:51:07 +0000\nTaints:             node-role.kubernetes.io/master=true:NoSchedule\nUnschedulable:      false\nConditions:\n  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----             ------  -----------------                 ------------------                ------                       -------\n  MemoryPressure   False   Mon, 06 Apr 2020 22:23:50 +0000   Mon, 06 Apr 2020 21:51:07 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure     False   Mon, 06 Apr 2020 22:23:50 +0000   Mon, 06 Apr 2020 21:51:07 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure      False   Mon, 06 Apr 2020 22:23:50 +0000   Mon, 06 Apr 2020 21:51:07 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready            True    Mon, 06 Apr 2020 22:23:50 +0000   Mon, 06 Apr 2020 21:51:59 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.0.0.41\n  Hostname:    10.0.0.41\nCapacity:\n cpu:                16\n ephemeral-storage:  40593708Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16430628Ki\n pods:               200\nAllocatable:\n cpu:                16\n ephemeral-storage:  37411161231\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             16328228Ki\n pods:               200\nSystem Info:\n Machine ID:                 54175a019b4f4bddb8201b7bd5d9b0b8\n System UUID:                5867CE48-418D-43DF-BE14-5860CE83A9A2\n Boot ID:                    8fac28e9-4fa0-4933-b5cb-6cf292b25604\n Kernel Version:             4.4.0-174-generic\n OS Image:                   Ubuntu 16.04.6 LTS\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.9.9\n Kubelet Version:            v1.16.8\n Kube-Proxy Version:         v1.16.8\nNon-terminated Pods:         (6 in total)\n  Namespace                  Name                                                       CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                       ------------  ----------  ---------------  -------------  ---\n  kube-system                coredns-5dbf897646-4sbtk                                   100m (0%)     0 (0%)      70Mi (0%)        170Mi (1%)     33m\n  kube-system                k8s-master-10.0.0.41                                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         32m\n  kube-system                kubernetes-dashboard-7764bb5d7b-cc95n                      0 (0%)        0 (0%)      0 (0%)           0 (0%)         33m\n  kube-system                metrics-server-v0.3.6-6fcf46458-zq6gd                      53m (0%)      148m (0%)   154Mi (0%)       404Mi (2%)     32m\n  pf9-monitoring             node-exporter-pqsrh                                        102m (0%)     250m (1%)   180Mi (1%)       180Mi (1%)     30m\n  sonobuoy                   sonobuoy-systemd-logs-daemon-set-3f2ae32d33c24b28-2fwh8    0 (0%)        0 (0%)      0 (0%)           0 (0%)         29m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                255m (1%)   398m (2%)\n  memory             404Mi (2%)  754Mi (4%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:\n  Type    Reason                   Age                From                Message\n  ----    ------                   ----               ----                -------\n  Normal  Starting                 33m                kubelet, 10.0.0.41  Starting kubelet.\n  Normal  NodeAllocatableEnforced  33m                kubelet, 10.0.0.41  Updated Node Allocatable limit across pods\n  Normal  NodeHasSufficientMemory  33m (x5 over 33m)  kubelet, 10.0.0.41  Node 10.0.0.41 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    33m (x4 over 33m)  kubelet, 10.0.0.41  Node 10.0.0.41 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     33m (x4 over 33m)  kubelet, 10.0.0.41  Node 10.0.0.41 status is now: NodeHasSufficientPID\n  Normal  KubeletConfigChanged     33m                kubelet, 10.0.0.41  Kubelet restarting to use /api/v1/namespaces/kube-system/configmaps/master-default-kubelet-config, UID: dae379ad-f99d-4b27-b9c3-e6f0787815ac, ResourceVersion: 230, KubeletConfigKey: kubelet\n  Normal  Starting                 32m                kubelet, 10.0.0.41  Starting kubelet.\n  Normal  NodeHasSufficientMemory  32m                kubelet, 10.0.0.41  Node 10.0.0.41 status is now: NodeHasSufficientMemory\n  Normal  NodeHasNoDiskPressure    32m                kubelet, 10.0.0.41  Node 10.0.0.41 status is now: NodeHasNoDiskPressure\n  Normal  NodeHasSufficientPID     32m                kubelet, 10.0.0.41  Node 10.0.0.41 status is now: NodeHasSufficientPID\n  Normal  NodeNotReady             32m                kubelet, 10.0.0.41  Node 10.0.0.41 status is now: NodeNotReady\n  Normal  NodeAllocatableEnforced  32m                kubelet, 10.0.0.41  Updated Node Allocatable limit across pods\n  Normal  NodeReady                32m                kubelet, 10.0.0.41  Node 10.0.0.41 status is now: NodeReady\n"
Apr  6 22:24:20.630: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 describe namespace kubectl-5957'
Apr  6 22:24:20.705: INFO: stderr: ""
Apr  6 22:24:20.705: INFO: stdout: "Name:         kubectl-5957\nLabels:       e2e-framework=kubectl\n              e2e-run=c7c60ad1-c2d7-4a44-87a9-c332544d3e88\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:24:20.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5957" for this suite.
Apr  6 22:24:32.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:24:33.023: INFO: namespace kubectl-5957 deletion completed in 12.310547312s

• [SLOW TEST:15.372 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:24:33.023: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-np89
STEP: Creating a pod to test atomic-volume-subpath
Apr  6 22:24:33.052: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-np89" in namespace "subpath-6643" to be "success or failure"
Apr  6 22:24:33.055: INFO: Pod "pod-subpath-test-downwardapi-np89": Phase="Pending", Reason="", readiness=false. Elapsed: 2.270843ms
Apr  6 22:24:35.058: INFO: Pod "pod-subpath-test-downwardapi-np89": Phase="Running", Reason="", readiness=true. Elapsed: 2.005496142s
Apr  6 22:24:37.062: INFO: Pod "pod-subpath-test-downwardapi-np89": Phase="Running", Reason="", readiness=true. Elapsed: 4.009586713s
Apr  6 22:24:39.065: INFO: Pod "pod-subpath-test-downwardapi-np89": Phase="Running", Reason="", readiness=true. Elapsed: 6.012701397s
Apr  6 22:24:41.068: INFO: Pod "pod-subpath-test-downwardapi-np89": Phase="Running", Reason="", readiness=true. Elapsed: 8.015961823s
Apr  6 22:24:43.071: INFO: Pod "pod-subpath-test-downwardapi-np89": Phase="Running", Reason="", readiness=true. Elapsed: 10.0185889s
Apr  6 22:24:45.074: INFO: Pod "pod-subpath-test-downwardapi-np89": Phase="Running", Reason="", readiness=true. Elapsed: 12.021981828s
Apr  6 22:24:47.077: INFO: Pod "pod-subpath-test-downwardapi-np89": Phase="Running", Reason="", readiness=true. Elapsed: 14.024898562s
Apr  6 22:24:49.080: INFO: Pod "pod-subpath-test-downwardapi-np89": Phase="Running", Reason="", readiness=true. Elapsed: 16.028202834s
Apr  6 22:24:51.083: INFO: Pod "pod-subpath-test-downwardapi-np89": Phase="Running", Reason="", readiness=true. Elapsed: 18.031193597s
Apr  6 22:24:53.087: INFO: Pod "pod-subpath-test-downwardapi-np89": Phase="Running", Reason="", readiness=true. Elapsed: 20.034530291s
Apr  6 22:24:55.090: INFO: Pod "pod-subpath-test-downwardapi-np89": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.037985536s
STEP: Saw pod success
Apr  6 22:24:55.090: INFO: Pod "pod-subpath-test-downwardapi-np89" satisfied condition "success or failure"
Apr  6 22:24:55.093: INFO: Trying to get logs from node 10.0.0.44 pod pod-subpath-test-downwardapi-np89 container test-container-subpath-downwardapi-np89: <nil>
STEP: delete the pod
Apr  6 22:24:55.115: INFO: Waiting for pod pod-subpath-test-downwardapi-np89 to disappear
Apr  6 22:24:55.117: INFO: Pod pod-subpath-test-downwardapi-np89 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-np89
Apr  6 22:24:55.118: INFO: Deleting pod "pod-subpath-test-downwardapi-np89" in namespace "subpath-6643"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:24:55.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6643" for this suite.
Apr  6 22:25:01.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:25:01.196: INFO: namespace subpath-6643 deletion completed in 6.072117505s

• [SLOW TEST:28.173 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:25:01.196: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-d7136dd5-5a53-423c-8d12-ab7447a01cb1
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-d7136dd5-5a53-423c-8d12-ab7447a01cb1
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:26:35.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9165" for this suite.
Apr  6 22:26:47.676: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:26:47.747: INFO: namespace projected-9165 deletion completed in 12.08085146s

• [SLOW TEST:106.551 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:26:47.748: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-3ac99a73-be7a-487c-8461-efd13ea37960
STEP: Creating a pod to test consume secrets
Apr  6 22:26:47.775: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-80a1f7c7-9ac9-4522-8b0a-7fadea202077" in namespace "projected-190" to be "success or failure"
Apr  6 22:26:47.778: INFO: Pod "pod-projected-secrets-80a1f7c7-9ac9-4522-8b0a-7fadea202077": Phase="Pending", Reason="", readiness=false. Elapsed: 2.732501ms
Apr  6 22:26:49.781: INFO: Pod "pod-projected-secrets-80a1f7c7-9ac9-4522-8b0a-7fadea202077": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005677383s
Apr  6 22:26:51.784: INFO: Pod "pod-projected-secrets-80a1f7c7-9ac9-4522-8b0a-7fadea202077": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00906793s
STEP: Saw pod success
Apr  6 22:26:51.784: INFO: Pod "pod-projected-secrets-80a1f7c7-9ac9-4522-8b0a-7fadea202077" satisfied condition "success or failure"
Apr  6 22:26:51.787: INFO: Trying to get logs from node 10.0.0.44 pod pod-projected-secrets-80a1f7c7-9ac9-4522-8b0a-7fadea202077 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  6 22:26:51.811: INFO: Waiting for pod pod-projected-secrets-80a1f7c7-9ac9-4522-8b0a-7fadea202077 to disappear
Apr  6 22:26:51.813: INFO: Pod pod-projected-secrets-80a1f7c7-9ac9-4522-8b0a-7fadea202077 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:26:51.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-190" for this suite.
Apr  6 22:26:57.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:26:57.917: INFO: namespace projected-190 deletion completed in 6.099636825s

• [SLOW TEST:10.169 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:26:57.917: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7677.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-7677.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7677.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-7677.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7677.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7677.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-7677.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7677.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-7677.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7677.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  6 22:26:59.964: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:26:59.968: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:26:59.971: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:26:59.974: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:26:59.985: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:26:59.988: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:26:59.991: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:26:59.994: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:00.000: INFO: Lookups using dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7677.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7677.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local jessie_udp@dns-test-service-2.dns-7677.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7677.svc.cluster.local]

Apr  6 22:27:05.004: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:05.007: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:05.011: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:05.015: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:05.025: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:05.028: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:05.031: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:05.034: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:05.039: INFO: Lookups using dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7677.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7677.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local jessie_udp@dns-test-service-2.dns-7677.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7677.svc.cluster.local]

Apr  6 22:27:10.004: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:10.008: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:10.011: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:10.015: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:10.025: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:10.028: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:10.031: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:10.034: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:10.040: INFO: Lookups using dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7677.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7677.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local jessie_udp@dns-test-service-2.dns-7677.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7677.svc.cluster.local]

Apr  6 22:27:15.004: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:15.008: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:15.011: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:15.017: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:15.026: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:15.029: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:15.032: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:15.035: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:15.041: INFO: Lookups using dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7677.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7677.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local jessie_udp@dns-test-service-2.dns-7677.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7677.svc.cluster.local]

Apr  6 22:27:20.005: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:20.008: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:20.011: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:20.015: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:20.024: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:20.026: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:20.029: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:20.031: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:20.037: INFO: Lookups using dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7677.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7677.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local jessie_udp@dns-test-service-2.dns-7677.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7677.svc.cluster.local]

Apr  6 22:27:25.005: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:25.008: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:25.012: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:25.017: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:25.026: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:25.028: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:25.031: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:25.034: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7677.svc.cluster.local from pod dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166: the server could not find the requested resource (get pods dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166)
Apr  6 22:27:25.039: INFO: Lookups using dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7677.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7677.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7677.svc.cluster.local jessie_udp@dns-test-service-2.dns-7677.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7677.svc.cluster.local]

Apr  6 22:27:30.042: INFO: DNS probes using dns-7677/dns-test-d6c9309c-1440-4688-b2a4-e5eb43637166 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:27:30.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7677" for this suite.
Apr  6 22:27:36.078: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:27:36.149: INFO: namespace dns-7677 deletion completed in 6.082811499s

• [SLOW TEST:38.232 seconds]
[sig-network] DNS
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:27:36.150: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-11132da1-23a3-4c9c-a784-eb03118f3321
STEP: Creating a pod to test consume secrets
Apr  6 22:27:36.181: INFO: Waiting up to 5m0s for pod "pod-secrets-f9b1d6ea-be75-41ad-8d9b-7b91b777701c" in namespace "secrets-1123" to be "success or failure"
Apr  6 22:27:36.183: INFO: Pod "pod-secrets-f9b1d6ea-be75-41ad-8d9b-7b91b777701c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.404576ms
Apr  6 22:27:38.186: INFO: Pod "pod-secrets-f9b1d6ea-be75-41ad-8d9b-7b91b777701c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005471296s
STEP: Saw pod success
Apr  6 22:27:38.186: INFO: Pod "pod-secrets-f9b1d6ea-be75-41ad-8d9b-7b91b777701c" satisfied condition "success or failure"
Apr  6 22:27:38.189: INFO: Trying to get logs from node 10.0.0.43 pod pod-secrets-f9b1d6ea-be75-41ad-8d9b-7b91b777701c container secret-volume-test: <nil>
STEP: delete the pod
Apr  6 22:27:38.210: INFO: Waiting for pod pod-secrets-f9b1d6ea-be75-41ad-8d9b-7b91b777701c to disappear
Apr  6 22:27:38.212: INFO: Pod pod-secrets-f9b1d6ea-be75-41ad-8d9b-7b91b777701c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:27:38.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1123" for this suite.
Apr  6 22:27:44.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:27:44.301: INFO: namespace secrets-1123 deletion completed in 6.086046396s

• [SLOW TEST:8.152 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:27:44.301: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Apr  6 22:27:48.357: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  6 22:27:48.359: INFO: Pod pod-with-poststart-http-hook still exists
Apr  6 22:27:50.360: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  6 22:27:50.362: INFO: Pod pod-with-poststart-http-hook still exists
Apr  6 22:27:52.360: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  6 22:27:52.363: INFO: Pod pod-with-poststart-http-hook still exists
Apr  6 22:27:54.360: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  6 22:27:54.363: INFO: Pod pod-with-poststart-http-hook still exists
Apr  6 22:27:56.360: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Apr  6 22:27:56.362: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:27:56.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-163" for this suite.
Apr  6 22:28:08.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:28:08.465: INFO: namespace container-lifecycle-hook-163 deletion completed in 12.098464061s

• [SLOW TEST:24.164 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:28:08.465: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-rpt8
STEP: Creating a pod to test atomic-volume-subpath
Apr  6 22:28:08.499: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-rpt8" in namespace "subpath-506" to be "success or failure"
Apr  6 22:28:08.501: INFO: Pod "pod-subpath-test-configmap-rpt8": Phase="Pending", Reason="", readiness=false. Elapsed: 1.896414ms
Apr  6 22:28:10.504: INFO: Pod "pod-subpath-test-configmap-rpt8": Phase="Running", Reason="", readiness=true. Elapsed: 2.00528898s
Apr  6 22:28:12.508: INFO: Pod "pod-subpath-test-configmap-rpt8": Phase="Running", Reason="", readiness=true. Elapsed: 4.008535934s
Apr  6 22:28:14.511: INFO: Pod "pod-subpath-test-configmap-rpt8": Phase="Running", Reason="", readiness=true. Elapsed: 6.011532212s
Apr  6 22:28:16.514: INFO: Pod "pod-subpath-test-configmap-rpt8": Phase="Running", Reason="", readiness=true. Elapsed: 8.014955308s
Apr  6 22:28:18.518: INFO: Pod "pod-subpath-test-configmap-rpt8": Phase="Running", Reason="", readiness=true. Elapsed: 10.018388757s
Apr  6 22:28:20.521: INFO: Pod "pod-subpath-test-configmap-rpt8": Phase="Running", Reason="", readiness=true. Elapsed: 12.021786522s
Apr  6 22:28:22.524: INFO: Pod "pod-subpath-test-configmap-rpt8": Phase="Running", Reason="", readiness=true. Elapsed: 14.024528475s
Apr  6 22:28:24.527: INFO: Pod "pod-subpath-test-configmap-rpt8": Phase="Running", Reason="", readiness=true. Elapsed: 16.027862529s
Apr  6 22:28:26.530: INFO: Pod "pod-subpath-test-configmap-rpt8": Phase="Running", Reason="", readiness=true. Elapsed: 18.030978271s
Apr  6 22:28:28.533: INFO: Pod "pod-subpath-test-configmap-rpt8": Phase="Running", Reason="", readiness=true. Elapsed: 20.033981606s
Apr  6 22:28:30.537: INFO: Pod "pod-subpath-test-configmap-rpt8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.037339589s
STEP: Saw pod success
Apr  6 22:28:30.537: INFO: Pod "pod-subpath-test-configmap-rpt8" satisfied condition "success or failure"
Apr  6 22:28:30.539: INFO: Trying to get logs from node 10.0.0.43 pod pod-subpath-test-configmap-rpt8 container test-container-subpath-configmap-rpt8: <nil>
STEP: delete the pod
Apr  6 22:28:30.554: INFO: Waiting for pod pod-subpath-test-configmap-rpt8 to disappear
Apr  6 22:28:30.557: INFO: Pod pod-subpath-test-configmap-rpt8 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-rpt8
Apr  6 22:28:30.557: INFO: Deleting pod "pod-subpath-test-configmap-rpt8" in namespace "subpath-506"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:28:30.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-506" for this suite.
Apr  6 22:28:36.572: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:28:36.725: INFO: namespace subpath-506 deletion completed in 6.162691804s

• [SLOW TEST:28.259 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:28:36.725: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename svc-latency
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-9038
I0406 22:28:36.748269      23 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-9038, replica count: 1
I0406 22:28:37.798784      23 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0406 22:28:38.799000      23 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  6 22:28:38.905: INFO: Created: latency-svc-x26sq
Apr  6 22:28:38.908: INFO: Got endpoints: latency-svc-x26sq [9.761903ms]
Apr  6 22:28:38.916: INFO: Created: latency-svc-z65nh
Apr  6 22:28:38.924: INFO: Created: latency-svc-lq6vw
Apr  6 22:28:38.925: INFO: Got endpoints: latency-svc-z65nh [16.37018ms]
Apr  6 22:28:38.934: INFO: Got endpoints: latency-svc-lq6vw [25.789438ms]
Apr  6 22:28:38.935: INFO: Created: latency-svc-967zg
Apr  6 22:28:38.940: INFO: Got endpoints: latency-svc-967zg [31.002565ms]
Apr  6 22:28:38.940: INFO: Created: latency-svc-gvpfq
Apr  6 22:28:38.944: INFO: Got endpoints: latency-svc-gvpfq [35.387157ms]
Apr  6 22:28:38.945: INFO: Created: latency-svc-swfbl
Apr  6 22:28:38.950: INFO: Created: latency-svc-lwpvd
Apr  6 22:28:38.958: INFO: Got endpoints: latency-svc-lwpvd [49.316064ms]
Apr  6 22:28:38.958: INFO: Got endpoints: latency-svc-swfbl [49.605868ms]
Apr  6 22:28:38.959: INFO: Created: latency-svc-47gkc
Apr  6 22:28:38.961: INFO: Got endpoints: latency-svc-47gkc [52.56926ms]
Apr  6 22:28:38.962: INFO: Created: latency-svc-hp2dh
Apr  6 22:28:38.964: INFO: Got endpoints: latency-svc-hp2dh [55.697476ms]
Apr  6 22:28:38.967: INFO: Created: latency-svc-ljblp
Apr  6 22:28:38.972: INFO: Got endpoints: latency-svc-ljblp [62.728493ms]
Apr  6 22:28:38.972: INFO: Created: latency-svc-ptzld
Apr  6 22:28:38.981: INFO: Got endpoints: latency-svc-ptzld [72.012201ms]
Apr  6 22:28:38.981: INFO: Created: latency-svc-qjx5s
Apr  6 22:28:38.986: INFO: Created: latency-svc-qn8cc
Apr  6 22:28:38.987: INFO: Got endpoints: latency-svc-qjx5s [78.476003ms]
Apr  6 22:28:38.993: INFO: Got endpoints: latency-svc-qn8cc [83.764595ms]
Apr  6 22:28:38.996: INFO: Created: latency-svc-6qfvf
Apr  6 22:28:38.999: INFO: Got endpoints: latency-svc-6qfvf [89.65114ms]
Apr  6 22:28:39.001: INFO: Created: latency-svc-ftl7m
Apr  6 22:28:39.006: INFO: Created: latency-svc-qcb8l
Apr  6 22:28:39.006: INFO: Got endpoints: latency-svc-ftl7m [97.469944ms]
Apr  6 22:28:39.010: INFO: Got endpoints: latency-svc-qcb8l [101.613394ms]
Apr  6 22:28:39.015: INFO: Created: latency-svc-pccds
Apr  6 22:28:39.025: INFO: Created: latency-svc-gnrgt
Apr  6 22:28:39.025: INFO: Got endpoints: latency-svc-pccds [100.137348ms]
Apr  6 22:28:39.030: INFO: Got endpoints: latency-svc-gnrgt [95.528567ms]
Apr  6 22:28:39.030: INFO: Created: latency-svc-497ft
Apr  6 22:28:39.036: INFO: Created: latency-svc-jl6v5
Apr  6 22:28:39.036: INFO: Got endpoints: latency-svc-497ft [95.974741ms]
Apr  6 22:28:39.040: INFO: Got endpoints: latency-svc-jl6v5 [96.26711ms]
Apr  6 22:28:39.040: INFO: Created: latency-svc-sbr44
Apr  6 22:28:39.042: INFO: Got endpoints: latency-svc-sbr44 [84.008629ms]
Apr  6 22:28:39.045: INFO: Created: latency-svc-8h7ws
Apr  6 22:28:39.049: INFO: Created: latency-svc-8x5r7
Apr  6 22:28:39.050: INFO: Got endpoints: latency-svc-8h7ws [91.531105ms]
Apr  6 22:28:39.056: INFO: Got endpoints: latency-svc-8x5r7 [94.986288ms]
Apr  6 22:28:39.056: INFO: Created: latency-svc-jtrxt
Apr  6 22:28:39.062: INFO: Created: latency-svc-jw48x
Apr  6 22:28:39.062: INFO: Got endpoints: latency-svc-jtrxt [97.198491ms]
Apr  6 22:28:39.067: INFO: Got endpoints: latency-svc-jw48x [95.663533ms]
Apr  6 22:28:39.067: INFO: Created: latency-svc-p948x
Apr  6 22:28:39.071: INFO: Got endpoints: latency-svc-p948x [14.927709ms]
Apr  6 22:28:39.071: INFO: Created: latency-svc-jd7dm
Apr  6 22:28:39.077: INFO: Created: latency-svc-qcn2b
Apr  6 22:28:39.077: INFO: Got endpoints: latency-svc-jd7dm [96.03306ms]
Apr  6 22:28:39.086: INFO: Got endpoints: latency-svc-qcn2b [98.135333ms]
Apr  6 22:28:39.086: INFO: Created: latency-svc-q658w
Apr  6 22:28:39.092: INFO: Got endpoints: latency-svc-q658w [99.326111ms]
Apr  6 22:28:39.092: INFO: Created: latency-svc-4ncrs
Apr  6 22:28:39.097: INFO: Created: latency-svc-bpr66
Apr  6 22:28:39.097: INFO: Got endpoints: latency-svc-4ncrs [98.848288ms]
Apr  6 22:28:39.100: INFO: Got endpoints: latency-svc-bpr66 [94.025105ms]
Apr  6 22:28:39.103: INFO: Created: latency-svc-6sm5j
Apr  6 22:28:39.108: INFO: Got endpoints: latency-svc-6sm5j [97.398601ms]
Apr  6 22:28:39.108: INFO: Created: latency-svc-8bvs6
Apr  6 22:28:39.110: INFO: Got endpoints: latency-svc-8bvs6 [85.311448ms]
Apr  6 22:28:39.115: INFO: Created: latency-svc-6z6wz
Apr  6 22:28:39.120: INFO: Got endpoints: latency-svc-6z6wz [89.68559ms]
Apr  6 22:28:39.120: INFO: Created: latency-svc-kgtnz
Apr  6 22:28:39.124: INFO: Created: latency-svc-8p8z8
Apr  6 22:28:39.130: INFO: Created: latency-svc-wpsz8
Apr  6 22:28:39.134: INFO: Created: latency-svc-dpvc7
Apr  6 22:28:39.141: INFO: Created: latency-svc-8vtxr
Apr  6 22:28:39.146: INFO: Created: latency-svc-5hbxm
Apr  6 22:28:39.150: INFO: Created: latency-svc-585kt
Apr  6 22:28:39.155: INFO: Created: latency-svc-lz7xd
Apr  6 22:28:39.159: INFO: Created: latency-svc-wk6kn
Apr  6 22:28:39.159: INFO: Got endpoints: latency-svc-kgtnz [123.382749ms]
Apr  6 22:28:39.164: INFO: Created: latency-svc-mc72b
Apr  6 22:28:39.171: INFO: Created: latency-svc-bxrkn
Apr  6 22:28:39.176: INFO: Created: latency-svc-n9lxn
Apr  6 22:28:39.181: INFO: Created: latency-svc-klhrc
Apr  6 22:28:39.190: INFO: Created: latency-svc-d9jxj
Apr  6 22:28:39.194: INFO: Created: latency-svc-kb6ff
Apr  6 22:28:39.199: INFO: Created: latency-svc-6gggk
Apr  6 22:28:39.208: INFO: Got endpoints: latency-svc-8p8z8 [167.989879ms]
Apr  6 22:28:39.217: INFO: Created: latency-svc-5k5mj
Apr  6 22:28:39.259: INFO: Got endpoints: latency-svc-wpsz8 [216.1937ms]
Apr  6 22:28:39.266: INFO: Created: latency-svc-rqxlh
Apr  6 22:28:39.308: INFO: Got endpoints: latency-svc-dpvc7 [258.814428ms]
Apr  6 22:28:39.317: INFO: Created: latency-svc-jch2k
Apr  6 22:28:39.358: INFO: Got endpoints: latency-svc-8vtxr [296.59361ms]
Apr  6 22:28:39.366: INFO: Created: latency-svc-nn2ct
Apr  6 22:28:39.409: INFO: Got endpoints: latency-svc-5hbxm [341.319947ms]
Apr  6 22:28:39.416: INFO: Created: latency-svc-x8lmq
Apr  6 22:28:39.459: INFO: Got endpoints: latency-svc-585kt [387.231172ms]
Apr  6 22:28:39.469: INFO: Created: latency-svc-7z5mh
Apr  6 22:28:39.509: INFO: Got endpoints: latency-svc-lz7xd [431.865954ms]
Apr  6 22:28:39.516: INFO: Created: latency-svc-xqz4j
Apr  6 22:28:39.559: INFO: Got endpoints: latency-svc-wk6kn [473.2736ms]
Apr  6 22:28:39.566: INFO: Created: latency-svc-mjdff
Apr  6 22:28:39.608: INFO: Got endpoints: latency-svc-mc72b [516.362924ms]
Apr  6 22:28:39.615: INFO: Created: latency-svc-tp6w7
Apr  6 22:28:39.660: INFO: Got endpoints: latency-svc-bxrkn [562.127137ms]
Apr  6 22:28:39.668: INFO: Created: latency-svc-zs6bx
Apr  6 22:28:39.709: INFO: Got endpoints: latency-svc-n9lxn [608.736848ms]
Apr  6 22:28:39.719: INFO: Created: latency-svc-cz6kx
Apr  6 22:28:39.759: INFO: Got endpoints: latency-svc-klhrc [650.903517ms]
Apr  6 22:28:39.767: INFO: Created: latency-svc-5jhj9
Apr  6 22:28:39.809: INFO: Got endpoints: latency-svc-d9jxj [698.059433ms]
Apr  6 22:28:39.815: INFO: Created: latency-svc-x2s7c
Apr  6 22:28:39.858: INFO: Got endpoints: latency-svc-kb6ff [738.769364ms]
Apr  6 22:28:39.866: INFO: Created: latency-svc-lf528
Apr  6 22:28:39.909: INFO: Got endpoints: latency-svc-6gggk [749.924494ms]
Apr  6 22:28:39.916: INFO: Created: latency-svc-h47g9
Apr  6 22:28:39.958: INFO: Got endpoints: latency-svc-5k5mj [749.950282ms]
Apr  6 22:28:39.969: INFO: Created: latency-svc-x7hlh
Apr  6 22:28:40.009: INFO: Got endpoints: latency-svc-rqxlh [749.874226ms]
Apr  6 22:28:40.016: INFO: Created: latency-svc-nl554
Apr  6 22:28:40.058: INFO: Got endpoints: latency-svc-jch2k [749.93029ms]
Apr  6 22:28:40.066: INFO: Created: latency-svc-68s2k
Apr  6 22:28:40.109: INFO: Got endpoints: latency-svc-nn2ct [750.114418ms]
Apr  6 22:28:40.117: INFO: Created: latency-svc-7jrhf
Apr  6 22:28:40.159: INFO: Got endpoints: latency-svc-x8lmq [749.972575ms]
Apr  6 22:28:40.166: INFO: Created: latency-svc-4j6km
Apr  6 22:28:40.208: INFO: Got endpoints: latency-svc-7z5mh [749.729285ms]
Apr  6 22:28:40.222: INFO: Created: latency-svc-znj8w
Apr  6 22:28:40.259: INFO: Got endpoints: latency-svc-xqz4j [749.722279ms]
Apr  6 22:28:40.266: INFO: Created: latency-svc-vpp2l
Apr  6 22:28:40.309: INFO: Got endpoints: latency-svc-mjdff [749.705073ms]
Apr  6 22:28:40.318: INFO: Created: latency-svc-w8dfh
Apr  6 22:28:40.359: INFO: Got endpoints: latency-svc-tp6w7 [750.14949ms]
Apr  6 22:28:40.367: INFO: Created: latency-svc-86hzz
Apr  6 22:28:40.409: INFO: Got endpoints: latency-svc-zs6bx [749.029444ms]
Apr  6 22:28:40.416: INFO: Created: latency-svc-z9vqx
Apr  6 22:28:40.459: INFO: Got endpoints: latency-svc-cz6kx [749.561579ms]
Apr  6 22:28:40.469: INFO: Created: latency-svc-j9mls
Apr  6 22:28:40.509: INFO: Got endpoints: latency-svc-5jhj9 [749.706745ms]
Apr  6 22:28:40.516: INFO: Created: latency-svc-x5xnw
Apr  6 22:28:40.559: INFO: Got endpoints: latency-svc-x2s7c [749.966427ms]
Apr  6 22:28:40.566: INFO: Created: latency-svc-frjg2
Apr  6 22:28:40.608: INFO: Got endpoints: latency-svc-lf528 [749.87028ms]
Apr  6 22:28:40.616: INFO: Created: latency-svc-j7fhc
Apr  6 22:28:40.659: INFO: Got endpoints: latency-svc-h47g9 [749.372645ms]
Apr  6 22:28:40.666: INFO: Created: latency-svc-nd74l
Apr  6 22:28:40.708: INFO: Got endpoints: latency-svc-x7hlh [749.918617ms]
Apr  6 22:28:40.718: INFO: Created: latency-svc-pbzxc
Apr  6 22:28:40.759: INFO: Got endpoints: latency-svc-nl554 [749.912982ms]
Apr  6 22:28:40.767: INFO: Created: latency-svc-bn7fc
Apr  6 22:28:40.809: INFO: Got endpoints: latency-svc-68s2k [750.117264ms]
Apr  6 22:28:40.816: INFO: Created: latency-svc-nb6j4
Apr  6 22:28:40.859: INFO: Got endpoints: latency-svc-7jrhf [749.985002ms]
Apr  6 22:28:40.866: INFO: Created: latency-svc-n8tst
Apr  6 22:28:40.909: INFO: Got endpoints: latency-svc-4j6km [750.350731ms]
Apr  6 22:28:40.917: INFO: Created: latency-svc-p6d27
Apr  6 22:28:40.959: INFO: Got endpoints: latency-svc-znj8w [750.454619ms]
Apr  6 22:28:40.970: INFO: Created: latency-svc-pncdq
Apr  6 22:28:41.009: INFO: Got endpoints: latency-svc-vpp2l [750.082157ms]
Apr  6 22:28:41.028: INFO: Created: latency-svc-m8hzw
Apr  6 22:28:41.059: INFO: Got endpoints: latency-svc-w8dfh [750.03849ms]
Apr  6 22:28:41.067: INFO: Created: latency-svc-p98n7
Apr  6 22:28:41.109: INFO: Got endpoints: latency-svc-86hzz [750.083103ms]
Apr  6 22:28:41.116: INFO: Created: latency-svc-2v8q6
Apr  6 22:28:41.159: INFO: Got endpoints: latency-svc-z9vqx [750.0208ms]
Apr  6 22:28:41.167: INFO: Created: latency-svc-pxjhk
Apr  6 22:28:41.209: INFO: Got endpoints: latency-svc-j9mls [749.947797ms]
Apr  6 22:28:41.219: INFO: Created: latency-svc-h65v8
Apr  6 22:28:41.258: INFO: Got endpoints: latency-svc-x5xnw [749.650034ms]
Apr  6 22:28:41.265: INFO: Created: latency-svc-g6v6v
Apr  6 22:28:41.309: INFO: Got endpoints: latency-svc-frjg2 [750.03092ms]
Apr  6 22:28:41.316: INFO: Created: latency-svc-ppzpd
Apr  6 22:28:41.359: INFO: Got endpoints: latency-svc-j7fhc [750.068799ms]
Apr  6 22:28:41.367: INFO: Created: latency-svc-wn8lc
Apr  6 22:28:41.409: INFO: Got endpoints: latency-svc-nd74l [750.470696ms]
Apr  6 22:28:41.416: INFO: Created: latency-svc-d5xbs
Apr  6 22:28:41.459: INFO: Got endpoints: latency-svc-pbzxc [750.305286ms]
Apr  6 22:28:41.470: INFO: Created: latency-svc-pqtzq
Apr  6 22:28:41.509: INFO: Got endpoints: latency-svc-bn7fc [750.246409ms]
Apr  6 22:28:41.517: INFO: Created: latency-svc-5klkh
Apr  6 22:28:41.562: INFO: Got endpoints: latency-svc-nb6j4 [753.235758ms]
Apr  6 22:28:41.569: INFO: Created: latency-svc-j55qw
Apr  6 22:28:41.609: INFO: Got endpoints: latency-svc-n8tst [749.919388ms]
Apr  6 22:28:41.617: INFO: Created: latency-svc-fnm8x
Apr  6 22:28:41.659: INFO: Got endpoints: latency-svc-p6d27 [749.69241ms]
Apr  6 22:28:41.667: INFO: Created: latency-svc-pz8zb
Apr  6 22:28:41.708: INFO: Got endpoints: latency-svc-pncdq [749.198341ms]
Apr  6 22:28:41.719: INFO: Created: latency-svc-rm86m
Apr  6 22:28:41.759: INFO: Got endpoints: latency-svc-m8hzw [750.024409ms]
Apr  6 22:28:41.770: INFO: Created: latency-svc-6ww7b
Apr  6 22:28:41.808: INFO: Got endpoints: latency-svc-p98n7 [749.647488ms]
Apr  6 22:28:41.817: INFO: Created: latency-svc-66n8x
Apr  6 22:28:41.859: INFO: Got endpoints: latency-svc-2v8q6 [749.890153ms]
Apr  6 22:28:41.866: INFO: Created: latency-svc-xzt64
Apr  6 22:28:41.909: INFO: Got endpoints: latency-svc-pxjhk [749.891876ms]
Apr  6 22:28:41.916: INFO: Created: latency-svc-w8qfn
Apr  6 22:28:41.959: INFO: Got endpoints: latency-svc-h65v8 [750.093541ms]
Apr  6 22:28:41.970: INFO: Created: latency-svc-rndm8
Apr  6 22:28:42.010: INFO: Got endpoints: latency-svc-g6v6v [751.308354ms]
Apr  6 22:28:42.018: INFO: Created: latency-svc-6kthm
Apr  6 22:28:42.058: INFO: Got endpoints: latency-svc-ppzpd [749.301462ms]
Apr  6 22:28:42.067: INFO: Created: latency-svc-nfzjc
Apr  6 22:28:42.109: INFO: Got endpoints: latency-svc-wn8lc [750.625071ms]
Apr  6 22:28:42.117: INFO: Created: latency-svc-k9jcp
Apr  6 22:28:42.159: INFO: Got endpoints: latency-svc-d5xbs [749.429621ms]
Apr  6 22:28:42.166: INFO: Created: latency-svc-ksgs6
Apr  6 22:28:42.209: INFO: Got endpoints: latency-svc-pqtzq [749.749481ms]
Apr  6 22:28:42.219: INFO: Created: latency-svc-6sg6z
Apr  6 22:28:42.259: INFO: Got endpoints: latency-svc-5klkh [749.881028ms]
Apr  6 22:28:42.266: INFO: Created: latency-svc-dwpwr
Apr  6 22:28:42.309: INFO: Got endpoints: latency-svc-j55qw [746.787926ms]
Apr  6 22:28:42.317: INFO: Created: latency-svc-s599p
Apr  6 22:28:42.359: INFO: Got endpoints: latency-svc-fnm8x [750.466172ms]
Apr  6 22:28:42.368: INFO: Created: latency-svc-5v84c
Apr  6 22:28:42.410: INFO: Got endpoints: latency-svc-pz8zb [750.621185ms]
Apr  6 22:28:42.417: INFO: Created: latency-svc-zr4zn
Apr  6 22:28:42.459: INFO: Got endpoints: latency-svc-rm86m [750.757755ms]
Apr  6 22:28:42.470: INFO: Created: latency-svc-gqh5h
Apr  6 22:28:42.509: INFO: Got endpoints: latency-svc-6ww7b [749.753879ms]
Apr  6 22:28:42.516: INFO: Created: latency-svc-6bmlz
Apr  6 22:28:42.559: INFO: Got endpoints: latency-svc-66n8x [750.382079ms]
Apr  6 22:28:42.567: INFO: Created: latency-svc-874jq
Apr  6 22:28:42.609: INFO: Got endpoints: latency-svc-xzt64 [750.207641ms]
Apr  6 22:28:42.616: INFO: Created: latency-svc-5dcd6
Apr  6 22:28:42.659: INFO: Got endpoints: latency-svc-w8qfn [749.836718ms]
Apr  6 22:28:42.668: INFO: Created: latency-svc-948lw
Apr  6 22:28:42.709: INFO: Got endpoints: latency-svc-rndm8 [749.968657ms]
Apr  6 22:28:42.719: INFO: Created: latency-svc-vtdd2
Apr  6 22:28:42.758: INFO: Got endpoints: latency-svc-6kthm [748.557234ms]
Apr  6 22:28:42.766: INFO: Created: latency-svc-f7c9t
Apr  6 22:28:42.808: INFO: Got endpoints: latency-svc-nfzjc [750.162616ms]
Apr  6 22:28:42.817: INFO: Created: latency-svc-v6z7n
Apr  6 22:28:42.859: INFO: Got endpoints: latency-svc-k9jcp [749.431927ms]
Apr  6 22:28:42.867: INFO: Created: latency-svc-nwnhb
Apr  6 22:28:42.909: INFO: Got endpoints: latency-svc-ksgs6 [750.162865ms]
Apr  6 22:28:42.916: INFO: Created: latency-svc-tmn9x
Apr  6 22:28:42.959: INFO: Got endpoints: latency-svc-6sg6z [749.931663ms]
Apr  6 22:28:42.969: INFO: Created: latency-svc-fgjwj
Apr  6 22:28:43.009: INFO: Got endpoints: latency-svc-dwpwr [750.17606ms]
Apr  6 22:28:43.021: INFO: Created: latency-svc-rv4z9
Apr  6 22:28:43.059: INFO: Got endpoints: latency-svc-s599p [749.772475ms]
Apr  6 22:28:43.065: INFO: Created: latency-svc-8b6zk
Apr  6 22:28:43.110: INFO: Got endpoints: latency-svc-5v84c [750.419189ms]
Apr  6 22:28:43.116: INFO: Created: latency-svc-rd6bl
Apr  6 22:28:43.159: INFO: Got endpoints: latency-svc-zr4zn [749.199813ms]
Apr  6 22:28:43.165: INFO: Created: latency-svc-k7xkq
Apr  6 22:28:43.209: INFO: Got endpoints: latency-svc-gqh5h [750.329662ms]
Apr  6 22:28:43.218: INFO: Created: latency-svc-5pnhw
Apr  6 22:28:43.259: INFO: Got endpoints: latency-svc-6bmlz [750.020388ms]
Apr  6 22:28:43.265: INFO: Created: latency-svc-dtnff
Apr  6 22:28:43.309: INFO: Got endpoints: latency-svc-874jq [749.63189ms]
Apr  6 22:28:43.317: INFO: Created: latency-svc-f7h79
Apr  6 22:28:43.359: INFO: Got endpoints: latency-svc-5dcd6 [749.579948ms]
Apr  6 22:28:43.366: INFO: Created: latency-svc-gk5zh
Apr  6 22:28:43.409: INFO: Got endpoints: latency-svc-948lw [750.136019ms]
Apr  6 22:28:43.416: INFO: Created: latency-svc-rzp45
Apr  6 22:28:43.459: INFO: Got endpoints: latency-svc-vtdd2 [749.779825ms]
Apr  6 22:28:43.468: INFO: Created: latency-svc-lt4xr
Apr  6 22:28:43.509: INFO: Got endpoints: latency-svc-f7c9t [750.162994ms]
Apr  6 22:28:43.515: INFO: Created: latency-svc-bcbt5
Apr  6 22:28:43.559: INFO: Got endpoints: latency-svc-v6z7n [750.456823ms]
Apr  6 22:28:43.566: INFO: Created: latency-svc-ktftw
Apr  6 22:28:43.609: INFO: Got endpoints: latency-svc-nwnhb [749.873293ms]
Apr  6 22:28:43.615: INFO: Created: latency-svc-vj9qg
Apr  6 22:28:43.659: INFO: Got endpoints: latency-svc-tmn9x [750.029258ms]
Apr  6 22:28:43.665: INFO: Created: latency-svc-kwjpm
Apr  6 22:28:43.709: INFO: Got endpoints: latency-svc-fgjwj [750.267751ms]
Apr  6 22:28:43.718: INFO: Created: latency-svc-g6bb2
Apr  6 22:28:43.759: INFO: Got endpoints: latency-svc-rv4z9 [750.082325ms]
Apr  6 22:28:43.767: INFO: Created: latency-svc-9222g
Apr  6 22:28:43.809: INFO: Got endpoints: latency-svc-8b6zk [750.663626ms]
Apr  6 22:28:43.816: INFO: Created: latency-svc-shwkd
Apr  6 22:28:43.859: INFO: Got endpoints: latency-svc-rd6bl [749.229433ms]
Apr  6 22:28:43.865: INFO: Created: latency-svc-m94t9
Apr  6 22:28:43.909: INFO: Got endpoints: latency-svc-k7xkq [750.076172ms]
Apr  6 22:28:43.915: INFO: Created: latency-svc-v4dj8
Apr  6 22:28:43.959: INFO: Got endpoints: latency-svc-5pnhw [749.089204ms]
Apr  6 22:28:43.968: INFO: Created: latency-svc-787pw
Apr  6 22:28:44.008: INFO: Got endpoints: latency-svc-dtnff [749.735671ms]
Apr  6 22:28:44.015: INFO: Created: latency-svc-bm7wm
Apr  6 22:28:44.060: INFO: Got endpoints: latency-svc-f7h79 [751.019104ms]
Apr  6 22:28:44.067: INFO: Created: latency-svc-64pj6
Apr  6 22:28:44.109: INFO: Got endpoints: latency-svc-gk5zh [750.039798ms]
Apr  6 22:28:44.115: INFO: Created: latency-svc-vqkfw
Apr  6 22:28:44.159: INFO: Got endpoints: latency-svc-rzp45 [749.873365ms]
Apr  6 22:28:44.165: INFO: Created: latency-svc-pv986
Apr  6 22:28:44.209: INFO: Got endpoints: latency-svc-lt4xr [749.998141ms]
Apr  6 22:28:44.218: INFO: Created: latency-svc-s6sjq
Apr  6 22:28:44.258: INFO: Got endpoints: latency-svc-bcbt5 [749.734243ms]
Apr  6 22:28:44.266: INFO: Created: latency-svc-wl6v4
Apr  6 22:28:44.309: INFO: Got endpoints: latency-svc-ktftw [749.837968ms]
Apr  6 22:28:44.315: INFO: Created: latency-svc-qcbp6
Apr  6 22:28:44.359: INFO: Got endpoints: latency-svc-vj9qg [749.945862ms]
Apr  6 22:28:44.366: INFO: Created: latency-svc-xd8bg
Apr  6 22:28:44.409: INFO: Got endpoints: latency-svc-kwjpm [750.022425ms]
Apr  6 22:28:44.417: INFO: Created: latency-svc-mv7qb
Apr  6 22:28:44.459: INFO: Got endpoints: latency-svc-g6bb2 [749.652314ms]
Apr  6 22:28:44.468: INFO: Created: latency-svc-ss7j9
Apr  6 22:28:44.509: INFO: Got endpoints: latency-svc-9222g [749.412541ms]
Apr  6 22:28:44.516: INFO: Created: latency-svc-tz7q4
Apr  6 22:28:44.559: INFO: Got endpoints: latency-svc-shwkd [749.928836ms]
Apr  6 22:28:44.566: INFO: Created: latency-svc-fb4qt
Apr  6 22:28:44.609: INFO: Got endpoints: latency-svc-m94t9 [749.60829ms]
Apr  6 22:28:44.615: INFO: Created: latency-svc-dg99h
Apr  6 22:28:44.659: INFO: Got endpoints: latency-svc-v4dj8 [750.005136ms]
Apr  6 22:28:44.667: INFO: Created: latency-svc-hmtzs
Apr  6 22:28:44.709: INFO: Got endpoints: latency-svc-787pw [750.292593ms]
Apr  6 22:28:44.715: INFO: Created: latency-svc-cwbrg
Apr  6 22:28:44.759: INFO: Got endpoints: latency-svc-bm7wm [750.399234ms]
Apr  6 22:28:44.767: INFO: Created: latency-svc-xhpk5
Apr  6 22:28:44.809: INFO: Got endpoints: latency-svc-64pj6 [748.848096ms]
Apr  6 22:28:44.816: INFO: Created: latency-svc-6jnz4
Apr  6 22:28:44.859: INFO: Got endpoints: latency-svc-vqkfw [750.132703ms]
Apr  6 22:28:44.866: INFO: Created: latency-svc-sfx9k
Apr  6 22:28:44.909: INFO: Got endpoints: latency-svc-pv986 [750.194251ms]
Apr  6 22:28:44.916: INFO: Created: latency-svc-6k2mx
Apr  6 22:28:44.959: INFO: Got endpoints: latency-svc-s6sjq [749.959202ms]
Apr  6 22:28:44.966: INFO: Created: latency-svc-kz49h
Apr  6 22:28:45.009: INFO: Got endpoints: latency-svc-wl6v4 [750.187246ms]
Apr  6 22:28:45.017: INFO: Created: latency-svc-s4n9s
Apr  6 22:28:45.062: INFO: Got endpoints: latency-svc-qcbp6 [753.267899ms]
Apr  6 22:28:45.069: INFO: Created: latency-svc-tg5mt
Apr  6 22:28:45.109: INFO: Got endpoints: latency-svc-xd8bg [749.973512ms]
Apr  6 22:28:45.117: INFO: Created: latency-svc-spfzd
Apr  6 22:28:45.158: INFO: Got endpoints: latency-svc-mv7qb [749.427254ms]
Apr  6 22:28:45.167: INFO: Created: latency-svc-n65nd
Apr  6 22:28:45.209: INFO: Got endpoints: latency-svc-ss7j9 [750.27354ms]
Apr  6 22:28:45.217: INFO: Created: latency-svc-7bl69
Apr  6 22:28:45.260: INFO: Got endpoints: latency-svc-tz7q4 [750.894865ms]
Apr  6 22:28:45.270: INFO: Created: latency-svc-l4n7v
Apr  6 22:28:45.309: INFO: Got endpoints: latency-svc-fb4qt [749.923954ms]
Apr  6 22:28:45.316: INFO: Created: latency-svc-k7lp4
Apr  6 22:28:45.359: INFO: Got endpoints: latency-svc-dg99h [750.176054ms]
Apr  6 22:28:45.366: INFO: Created: latency-svc-2pdz8
Apr  6 22:28:45.409: INFO: Got endpoints: latency-svc-hmtzs [749.5646ms]
Apr  6 22:28:45.415: INFO: Created: latency-svc-7sd96
Apr  6 22:28:45.458: INFO: Got endpoints: latency-svc-cwbrg [749.391366ms]
Apr  6 22:28:45.466: INFO: Created: latency-svc-26rb8
Apr  6 22:28:45.509: INFO: Got endpoints: latency-svc-xhpk5 [749.666349ms]
Apr  6 22:28:45.517: INFO: Created: latency-svc-wp4sr
Apr  6 22:28:45.559: INFO: Got endpoints: latency-svc-6jnz4 [750.329775ms]
Apr  6 22:28:45.567: INFO: Created: latency-svc-2mp7l
Apr  6 22:28:45.608: INFO: Got endpoints: latency-svc-sfx9k [749.426905ms]
Apr  6 22:28:45.617: INFO: Created: latency-svc-k89mf
Apr  6 22:28:45.659: INFO: Got endpoints: latency-svc-6k2mx [749.774917ms]
Apr  6 22:28:45.666: INFO: Created: latency-svc-mj6k6
Apr  6 22:28:45.709: INFO: Got endpoints: latency-svc-kz49h [749.694049ms]
Apr  6 22:28:45.715: INFO: Created: latency-svc-fx2l8
Apr  6 22:28:45.759: INFO: Got endpoints: latency-svc-s4n9s [749.99875ms]
Apr  6 22:28:45.767: INFO: Created: latency-svc-z4zkz
Apr  6 22:28:45.809: INFO: Got endpoints: latency-svc-tg5mt [746.897887ms]
Apr  6 22:28:45.816: INFO: Created: latency-svc-smnj5
Apr  6 22:28:45.859: INFO: Got endpoints: latency-svc-spfzd [750.17639ms]
Apr  6 22:28:45.866: INFO: Created: latency-svc-4knq7
Apr  6 22:28:45.909: INFO: Got endpoints: latency-svc-n65nd [750.628535ms]
Apr  6 22:28:45.917: INFO: Created: latency-svc-6jjxs
Apr  6 22:28:45.959: INFO: Got endpoints: latency-svc-7bl69 [749.977139ms]
Apr  6 22:28:45.967: INFO: Created: latency-svc-fbjth
Apr  6 22:28:46.009: INFO: Got endpoints: latency-svc-l4n7v [749.291216ms]
Apr  6 22:28:46.019: INFO: Created: latency-svc-rtnv6
Apr  6 22:28:46.059: INFO: Got endpoints: latency-svc-k7lp4 [749.738079ms]
Apr  6 22:28:46.067: INFO: Created: latency-svc-4hd6r
Apr  6 22:28:46.109: INFO: Got endpoints: latency-svc-2pdz8 [750.215429ms]
Apr  6 22:28:46.116: INFO: Created: latency-svc-m2vcz
Apr  6 22:28:46.160: INFO: Got endpoints: latency-svc-7sd96 [750.936145ms]
Apr  6 22:28:46.167: INFO: Created: latency-svc-rqgjs
Apr  6 22:28:46.209: INFO: Got endpoints: latency-svc-26rb8 [750.261091ms]
Apr  6 22:28:46.215: INFO: Created: latency-svc-4jhj8
Apr  6 22:28:46.259: INFO: Got endpoints: latency-svc-wp4sr [750.166015ms]
Apr  6 22:28:46.270: INFO: Created: latency-svc-wrdpn
Apr  6 22:28:46.309: INFO: Got endpoints: latency-svc-2mp7l [750.004141ms]
Apr  6 22:28:46.316: INFO: Created: latency-svc-z8mnl
Apr  6 22:28:46.359: INFO: Got endpoints: latency-svc-k89mf [750.273945ms]
Apr  6 22:28:46.366: INFO: Created: latency-svc-76gn9
Apr  6 22:28:46.409: INFO: Got endpoints: latency-svc-mj6k6 [750.046927ms]
Apr  6 22:28:46.416: INFO: Created: latency-svc-b5zlj
Apr  6 22:28:46.459: INFO: Got endpoints: latency-svc-fx2l8 [749.963444ms]
Apr  6 22:28:46.466: INFO: Created: latency-svc-qtflg
Apr  6 22:28:46.509: INFO: Got endpoints: latency-svc-z4zkz [749.802944ms]
Apr  6 22:28:46.519: INFO: Created: latency-svc-ph5lb
Apr  6 22:28:46.559: INFO: Got endpoints: latency-svc-smnj5 [749.549215ms]
Apr  6 22:28:46.567: INFO: Created: latency-svc-mqtdj
Apr  6 22:28:46.609: INFO: Got endpoints: latency-svc-4knq7 [749.815922ms]
Apr  6 22:28:46.616: INFO: Created: latency-svc-7rn5r
Apr  6 22:28:46.659: INFO: Got endpoints: latency-svc-6jjxs [749.899671ms]
Apr  6 22:28:46.666: INFO: Created: latency-svc-ffr5t
Apr  6 22:28:46.710: INFO: Got endpoints: latency-svc-fbjth [750.771355ms]
Apr  6 22:28:46.717: INFO: Created: latency-svc-r9slp
Apr  6 22:28:46.759: INFO: Got endpoints: latency-svc-rtnv6 [750.414559ms]
Apr  6 22:28:46.809: INFO: Got endpoints: latency-svc-4hd6r [749.4642ms]
Apr  6 22:28:46.859: INFO: Got endpoints: latency-svc-m2vcz [749.609288ms]
Apr  6 22:28:46.909: INFO: Got endpoints: latency-svc-rqgjs [749.531209ms]
Apr  6 22:28:46.959: INFO: Got endpoints: latency-svc-4jhj8 [750.247078ms]
Apr  6 22:28:47.009: INFO: Got endpoints: latency-svc-wrdpn [749.641488ms]
Apr  6 22:28:47.059: INFO: Got endpoints: latency-svc-z8mnl [749.973851ms]
Apr  6 22:28:47.109: INFO: Got endpoints: latency-svc-76gn9 [750.414563ms]
Apr  6 22:28:47.159: INFO: Got endpoints: latency-svc-b5zlj [749.919331ms]
Apr  6 22:28:47.209: INFO: Got endpoints: latency-svc-qtflg [749.830488ms]
Apr  6 22:28:47.259: INFO: Got endpoints: latency-svc-ph5lb [750.268863ms]
Apr  6 22:28:47.309: INFO: Got endpoints: latency-svc-mqtdj [750.532094ms]
Apr  6 22:28:47.359: INFO: Got endpoints: latency-svc-7rn5r [750.010414ms]
Apr  6 22:28:47.410: INFO: Got endpoints: latency-svc-ffr5t [750.892537ms]
Apr  6 22:28:47.459: INFO: Got endpoints: latency-svc-r9slp [748.855096ms]
Apr  6 22:28:47.459: INFO: Latencies: [14.927709ms 16.37018ms 25.789438ms 31.002565ms 35.387157ms 49.316064ms 49.605868ms 52.56926ms 55.697476ms 62.728493ms 72.012201ms 78.476003ms 83.764595ms 84.008629ms 85.311448ms 89.65114ms 89.68559ms 91.531105ms 94.025105ms 94.986288ms 95.528567ms 95.663533ms 95.974741ms 96.03306ms 96.26711ms 97.198491ms 97.398601ms 97.469944ms 98.135333ms 98.848288ms 99.326111ms 100.137348ms 101.613394ms 123.382749ms 167.989879ms 216.1937ms 258.814428ms 296.59361ms 341.319947ms 387.231172ms 431.865954ms 473.2736ms 516.362924ms 562.127137ms 608.736848ms 650.903517ms 698.059433ms 738.769364ms 746.787926ms 746.897887ms 748.557234ms 748.848096ms 748.855096ms 749.029444ms 749.089204ms 749.198341ms 749.199813ms 749.229433ms 749.291216ms 749.301462ms 749.372645ms 749.391366ms 749.412541ms 749.426905ms 749.427254ms 749.429621ms 749.431927ms 749.4642ms 749.531209ms 749.549215ms 749.561579ms 749.5646ms 749.579948ms 749.60829ms 749.609288ms 749.63189ms 749.641488ms 749.647488ms 749.650034ms 749.652314ms 749.666349ms 749.69241ms 749.694049ms 749.705073ms 749.706745ms 749.722279ms 749.729285ms 749.734243ms 749.735671ms 749.738079ms 749.749481ms 749.753879ms 749.772475ms 749.774917ms 749.779825ms 749.802944ms 749.815922ms 749.830488ms 749.836718ms 749.837968ms 749.87028ms 749.873293ms 749.873365ms 749.874226ms 749.881028ms 749.890153ms 749.891876ms 749.899671ms 749.912982ms 749.918617ms 749.919331ms 749.919388ms 749.923954ms 749.924494ms 749.928836ms 749.93029ms 749.931663ms 749.945862ms 749.947797ms 749.950282ms 749.959202ms 749.963444ms 749.966427ms 749.968657ms 749.972575ms 749.973512ms 749.973851ms 749.977139ms 749.985002ms 749.998141ms 749.99875ms 750.004141ms 750.005136ms 750.010414ms 750.020388ms 750.0208ms 750.022425ms 750.024409ms 750.029258ms 750.03092ms 750.03849ms 750.039798ms 750.046927ms 750.068799ms 750.076172ms 750.082157ms 750.082325ms 750.083103ms 750.093541ms 750.114418ms 750.117264ms 750.132703ms 750.136019ms 750.14949ms 750.162616ms 750.162865ms 750.162994ms 750.166015ms 750.176054ms 750.17606ms 750.17639ms 750.187246ms 750.194251ms 750.207641ms 750.215429ms 750.246409ms 750.247078ms 750.261091ms 750.267751ms 750.268863ms 750.27354ms 750.273945ms 750.292593ms 750.305286ms 750.329662ms 750.329775ms 750.350731ms 750.382079ms 750.399234ms 750.414559ms 750.414563ms 750.419189ms 750.454619ms 750.456823ms 750.466172ms 750.470696ms 750.532094ms 750.621185ms 750.625071ms 750.628535ms 750.663626ms 750.757755ms 750.771355ms 750.892537ms 750.894865ms 750.936145ms 751.019104ms 751.308354ms 753.235758ms 753.267899ms]
Apr  6 22:28:47.459: INFO: 50 %ile: 749.87028ms
Apr  6 22:28:47.459: INFO: 90 %ile: 750.414563ms
Apr  6 22:28:47.459: INFO: 99 %ile: 753.235758ms
Apr  6 22:28:47.459: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:28:47.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-9038" for this suite.
Apr  6 22:28:57.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:28:57.621: INFO: namespace svc-latency-9038 deletion completed in 10.156891378s

• [SLOW TEST:20.897 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:28:57.621: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-ec51b270-9d73-4f84-966d-49b08e42be2d
STEP: Creating a pod to test consume secrets
Apr  6 22:28:57.649: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-759505b1-aaea-40ec-8007-9466f12b4827" in namespace "projected-7774" to be "success or failure"
Apr  6 22:28:57.652: INFO: Pod "pod-projected-secrets-759505b1-aaea-40ec-8007-9466f12b4827": Phase="Pending", Reason="", readiness=false. Elapsed: 3.546242ms
Apr  6 22:28:59.656: INFO: Pod "pod-projected-secrets-759505b1-aaea-40ec-8007-9466f12b4827": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007211363s
STEP: Saw pod success
Apr  6 22:28:59.656: INFO: Pod "pod-projected-secrets-759505b1-aaea-40ec-8007-9466f12b4827" satisfied condition "success or failure"
Apr  6 22:28:59.659: INFO: Trying to get logs from node 10.0.0.44 pod pod-projected-secrets-759505b1-aaea-40ec-8007-9466f12b4827 container secret-volume-test: <nil>
STEP: delete the pod
Apr  6 22:28:59.678: INFO: Waiting for pod pod-projected-secrets-759505b1-aaea-40ec-8007-9466f12b4827 to disappear
Apr  6 22:28:59.681: INFO: Pod pod-projected-secrets-759505b1-aaea-40ec-8007-9466f12b4827 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:28:59.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7774" for this suite.
Apr  6 22:29:05.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:29:05.769: INFO: namespace projected-7774 deletion completed in 6.083975253s

• [SLOW TEST:8.148 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:29:05.770: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 22:29:05.794: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr  6 22:29:07.591: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 --namespace=crd-publish-openapi-527 create -f -'
Apr  6 22:29:08.115: INFO: stderr: ""
Apr  6 22:29:08.115: INFO: stdout: "e2e-test-crd-publish-openapi-788-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr  6 22:29:08.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 --namespace=crd-publish-openapi-527 delete e2e-test-crd-publish-openapi-788-crds test-cr'
Apr  6 22:29:08.185: INFO: stderr: ""
Apr  6 22:29:08.185: INFO: stdout: "e2e-test-crd-publish-openapi-788-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Apr  6 22:29:08.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 --namespace=crd-publish-openapi-527 apply -f -'
Apr  6 22:29:08.325: INFO: stderr: ""
Apr  6 22:29:08.325: INFO: stdout: "e2e-test-crd-publish-openapi-788-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Apr  6 22:29:08.325: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 --namespace=crd-publish-openapi-527 delete e2e-test-crd-publish-openapi-788-crds test-cr'
Apr  6 22:29:08.401: INFO: stderr: ""
Apr  6 22:29:08.401: INFO: stdout: "e2e-test-crd-publish-openapi-788-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Apr  6 22:29:08.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 explain e2e-test-crd-publish-openapi-788-crds'
Apr  6 22:29:08.530: INFO: stderr: ""
Apr  6 22:29:08.530: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-788-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:29:10.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-527" for this suite.
Apr  6 22:29:16.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:29:16.424: INFO: namespace crd-publish-openapi-527 deletion completed in 6.076922194s

• [SLOW TEST:10.655 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:29:16.425: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:29:32.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6453" for this suite.
Apr  6 22:29:38.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:29:38.588: INFO: namespace resourcequota-6453 deletion completed in 6.07547531s

• [SLOW TEST:22.163 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:29:38.588: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6772.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6772.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  6 22:29:50.648: INFO: DNS probes using dns-6772/dns-test-c4d488d8-1565-439a-9de8-b4afc9d6635b succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:29:50.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6772" for this suite.
Apr  6 22:29:56.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:29:56.750: INFO: namespace dns-6772 deletion completed in 6.087222498s

• [SLOW TEST:18.162 seconds]
[sig-network] DNS
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:29:56.750: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Apr  6 22:29:56.772: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 cluster-info'
Apr  6 22:29:56.844: INFO: stderr: ""
Apr  6 22:29:56.844: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.21.0.1:443\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://10.21.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mMetrics-server\x1b[0m is running at \x1b[0;33mhttps://10.21.0.1:443/api/v1/namespaces/kube-system/services/https:metrics-server:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:29:56.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6114" for this suite.
Apr  6 22:30:02.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:30:02.925: INFO: namespace kubectl-6114 deletion completed in 6.077553312s

• [SLOW TEST:6.175 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:30:02.925: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-7077, will wait for the garbage collector to delete the pods
Apr  6 22:30:07.013: INFO: Deleting Job.batch foo took: 6.078051ms
Apr  6 22:30:07.614: INFO: Terminating Job.batch foo pods took: 600.294372ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:30:46.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7077" for this suite.
Apr  6 22:30:52.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:30:52.504: INFO: namespace job-7077 deletion completed in 6.083264001s

• [SLOW TEST:49.579 seconds]
[sig-apps] Job
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:30:52.504: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr  6 22:30:52.574: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-3215'
Apr  6 22:30:52.655: INFO: stderr: ""
Apr  6 22:30:52.655: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Apr  6 22:30:57.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pod e2e-test-httpd-pod --namespace=kubectl-3215 -o json'
Apr  6 22:30:57.780: INFO: stderr: ""
Apr  6 22:30:57.780: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"creationTimestamp\": \"2020-04-06T22:30:52Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-3215\",\n        \"resourceVersion\": \"11002\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-3215/pods/e2e-test-httpd-pod\",\n        \"uid\": \"b469838b-06a2-48dc-88d1-7335de0c3037\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-99w5p\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"10.0.0.43\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-99w5p\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-99w5p\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-06T22:30:52Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-06T22:30:54Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-06T22:30:54Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2020-04-06T22:30:52Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://52c19f87db2366621dc7c7463080677d9ccca403fa1ea0440dafb26250899908\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2020-04-06T22:30:53Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.0.0.43\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.20.8.53\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.20.8.53\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2020-04-06T22:30:52Z\"\n    }\n}\n"
STEP: replace the image in the pod
Apr  6 22:30:57.780: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 replace -f - --namespace=kubectl-3215'
Apr  6 22:30:57.985: INFO: stderr: ""
Apr  6 22:30:57.985: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Apr  6 22:30:57.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 delete pods e2e-test-httpd-pod --namespace=kubectl-3215'
Apr  6 22:31:09.855: INFO: stderr: ""
Apr  6 22:31:09.856: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:31:09.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3215" for this suite.
Apr  6 22:31:15.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:31:15.939: INFO: namespace kubectl-3215 deletion completed in 6.079553964s

• [SLOW TEST:23.435 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:31:15.939: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-f7f1cdd8-25ef-43f0-8330-590ab0c161cc
STEP: Creating a pod to test consume configMaps
Apr  6 22:31:15.970: INFO: Waiting up to 5m0s for pod "pod-configmaps-60882a29-a49c-4981-a9a1-157f7019d207" in namespace "configmap-1694" to be "success or failure"
Apr  6 22:31:15.976: INFO: Pod "pod-configmaps-60882a29-a49c-4981-a9a1-157f7019d207": Phase="Pending", Reason="", readiness=false. Elapsed: 6.905688ms
Apr  6 22:31:17.980: INFO: Pod "pod-configmaps-60882a29-a49c-4981-a9a1-157f7019d207": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010069299s
STEP: Saw pod success
Apr  6 22:31:17.980: INFO: Pod "pod-configmaps-60882a29-a49c-4981-a9a1-157f7019d207" satisfied condition "success or failure"
Apr  6 22:31:17.982: INFO: Trying to get logs from node 10.0.0.42 pod pod-configmaps-60882a29-a49c-4981-a9a1-157f7019d207 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  6 22:31:18.004: INFO: Waiting for pod pod-configmaps-60882a29-a49c-4981-a9a1-157f7019d207 to disappear
Apr  6 22:31:18.006: INFO: Pod pod-configmaps-60882a29-a49c-4981-a9a1-157f7019d207 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:31:18.006: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1694" for this suite.
Apr  6 22:31:24.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:31:24.094: INFO: namespace configmap-1694 deletion completed in 6.084602578s

• [SLOW TEST:8.155 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:31:24.094: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 22:31:24.113: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr  6 22:31:26.413: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 --namespace=crd-publish-openapi-1526 create -f -'
Apr  6 22:31:26.863: INFO: stderr: ""
Apr  6 22:31:26.863: INFO: stdout: "e2e-test-crd-publish-openapi-3270-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr  6 22:31:26.863: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 --namespace=crd-publish-openapi-1526 delete e2e-test-crd-publish-openapi-3270-crds test-cr'
Apr  6 22:31:26.936: INFO: stderr: ""
Apr  6 22:31:26.936: INFO: stdout: "e2e-test-crd-publish-openapi-3270-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Apr  6 22:31:26.936: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 --namespace=crd-publish-openapi-1526 apply -f -'
Apr  6 22:31:27.082: INFO: stderr: ""
Apr  6 22:31:27.082: INFO: stdout: "e2e-test-crd-publish-openapi-3270-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Apr  6 22:31:27.082: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 --namespace=crd-publish-openapi-1526 delete e2e-test-crd-publish-openapi-3270-crds test-cr'
Apr  6 22:31:27.157: INFO: stderr: ""
Apr  6 22:31:27.157: INFO: stdout: "e2e-test-crd-publish-openapi-3270-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Apr  6 22:31:27.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 explain e2e-test-crd-publish-openapi-3270-crds'
Apr  6 22:31:27.286: INFO: stderr: ""
Apr  6 22:31:27.286: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3270-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:31:30.086: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1526" for this suite.
Apr  6 22:31:36.098: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:31:36.176: INFO: namespace crd-publish-openapi-1526 deletion completed in 6.08698679s

• [SLOW TEST:12.082 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:31:36.177: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Apr  6 22:31:36.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 --namespace=kubectl-4132 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Apr  6 22:31:38.122: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Apr  6 22:31:38.123: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:31:40.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4132" for this suite.
Apr  6 22:31:46.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:31:46.213: INFO: namespace kubectl-4132 deletion completed in 6.080158556s

• [SLOW TEST:10.037 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:31:46.213: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr  6 22:31:46.241: INFO: Waiting up to 5m0s for pod "downwardapi-volume-980890fb-2d3b-4f6f-9fbb-794720bad48e" in namespace "downward-api-9572" to be "success or failure"
Apr  6 22:31:46.244: INFO: Pod "downwardapi-volume-980890fb-2d3b-4f6f-9fbb-794720bad48e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.808005ms
Apr  6 22:31:48.246: INFO: Pod "downwardapi-volume-980890fb-2d3b-4f6f-9fbb-794720bad48e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005584302s
STEP: Saw pod success
Apr  6 22:31:48.246: INFO: Pod "downwardapi-volume-980890fb-2d3b-4f6f-9fbb-794720bad48e" satisfied condition "success or failure"
Apr  6 22:31:48.249: INFO: Trying to get logs from node 10.0.0.42 pod downwardapi-volume-980890fb-2d3b-4f6f-9fbb-794720bad48e container client-container: <nil>
STEP: delete the pod
Apr  6 22:31:48.263: INFO: Waiting for pod downwardapi-volume-980890fb-2d3b-4f6f-9fbb-794720bad48e to disappear
Apr  6 22:31:48.265: INFO: Pod downwardapi-volume-980890fb-2d3b-4f6f-9fbb-794720bad48e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:31:48.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9572" for this suite.
Apr  6 22:31:54.276: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:31:54.356: INFO: namespace downward-api-9572 deletion completed in 6.088003773s

• [SLOW TEST:8.143 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:31:54.356: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-9bb64e27-3c95-49a7-acb5-7bde3ee8f1b7
STEP: Creating a pod to test consume configMaps
Apr  6 22:31:54.384: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e00e9f51-45c1-4924-a95c-a4a6c35971e8" in namespace "projected-685" to be "success or failure"
Apr  6 22:31:54.387: INFO: Pod "pod-projected-configmaps-e00e9f51-45c1-4924-a95c-a4a6c35971e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.865444ms
Apr  6 22:31:56.390: INFO: Pod "pod-projected-configmaps-e00e9f51-45c1-4924-a95c-a4a6c35971e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006398232s
STEP: Saw pod success
Apr  6 22:31:56.390: INFO: Pod "pod-projected-configmaps-e00e9f51-45c1-4924-a95c-a4a6c35971e8" satisfied condition "success or failure"
Apr  6 22:31:56.393: INFO: Trying to get logs from node 10.0.0.43 pod pod-projected-configmaps-e00e9f51-45c1-4924-a95c-a4a6c35971e8 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  6 22:31:56.417: INFO: Waiting for pod pod-projected-configmaps-e00e9f51-45c1-4924-a95c-a4a6c35971e8 to disappear
Apr  6 22:31:56.420: INFO: Pod pod-projected-configmaps-e00e9f51-45c1-4924-a95c-a4a6c35971e8 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:31:56.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-685" for this suite.
Apr  6 22:32:02.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:32:02.505: INFO: namespace projected-685 deletion completed in 6.0806178s

• [SLOW TEST:8.148 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:32:02.505: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:32:04.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6732" for this suite.
Apr  6 22:32:48.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:32:48.716: INFO: namespace kubelet-test-6732 deletion completed in 44.154887049s

• [SLOW TEST:46.211 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:32:48.717: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-pnxv
STEP: Creating a pod to test atomic-volume-subpath
Apr  6 22:32:48.747: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-pnxv" in namespace "subpath-828" to be "success or failure"
Apr  6 22:32:48.750: INFO: Pod "pod-subpath-test-configmap-pnxv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.258409ms
Apr  6 22:32:50.753: INFO: Pod "pod-subpath-test-configmap-pnxv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00536594s
Apr  6 22:32:52.756: INFO: Pod "pod-subpath-test-configmap-pnxv": Phase="Running", Reason="", readiness=true. Elapsed: 4.008384602s
Apr  6 22:32:54.759: INFO: Pod "pod-subpath-test-configmap-pnxv": Phase="Running", Reason="", readiness=true. Elapsed: 6.011298834s
Apr  6 22:32:56.761: INFO: Pod "pod-subpath-test-configmap-pnxv": Phase="Running", Reason="", readiness=true. Elapsed: 8.014035183s
Apr  6 22:32:58.765: INFO: Pod "pod-subpath-test-configmap-pnxv": Phase="Running", Reason="", readiness=true. Elapsed: 10.017267149s
Apr  6 22:33:00.767: INFO: Pod "pod-subpath-test-configmap-pnxv": Phase="Running", Reason="", readiness=true. Elapsed: 12.020071337s
Apr  6 22:33:02.771: INFO: Pod "pod-subpath-test-configmap-pnxv": Phase="Running", Reason="", readiness=true. Elapsed: 14.023404321s
Apr  6 22:33:04.774: INFO: Pod "pod-subpath-test-configmap-pnxv": Phase="Running", Reason="", readiness=true. Elapsed: 16.026743031s
Apr  6 22:33:06.777: INFO: Pod "pod-subpath-test-configmap-pnxv": Phase="Running", Reason="", readiness=true. Elapsed: 18.029980003s
Apr  6 22:33:08.781: INFO: Pod "pod-subpath-test-configmap-pnxv": Phase="Running", Reason="", readiness=true. Elapsed: 20.03325352s
Apr  6 22:33:10.784: INFO: Pod "pod-subpath-test-configmap-pnxv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.036247751s
STEP: Saw pod success
Apr  6 22:33:10.784: INFO: Pod "pod-subpath-test-configmap-pnxv" satisfied condition "success or failure"
Apr  6 22:33:10.786: INFO: Trying to get logs from node 10.0.0.43 pod pod-subpath-test-configmap-pnxv container test-container-subpath-configmap-pnxv: <nil>
STEP: delete the pod
Apr  6 22:33:10.804: INFO: Waiting for pod pod-subpath-test-configmap-pnxv to disappear
Apr  6 22:33:10.808: INFO: Pod pod-subpath-test-configmap-pnxv no longer exists
STEP: Deleting pod pod-subpath-test-configmap-pnxv
Apr  6 22:33:10.808: INFO: Deleting pod "pod-subpath-test-configmap-pnxv" in namespace "subpath-828"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:33:10.810: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-828" for this suite.
Apr  6 22:33:16.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:33:16.938: INFO: namespace subpath-828 deletion completed in 6.123569013s

• [SLOW TEST:28.222 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:33:16.938: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Apr  6 22:33:16.960: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:33:20.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9831" for this suite.
Apr  6 22:33:26.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:33:26.380: INFO: namespace init-container-9831 deletion completed in 6.068456175s

• [SLOW TEST:9.442 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:33:26.380: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Apr  6 22:33:26.404: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 create -f - --namespace=kubectl-4592'
Apr  6 22:33:26.600: INFO: stderr: ""
Apr  6 22:33:26.600: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  6 22:33:26.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4592'
Apr  6 22:33:26.674: INFO: stderr: ""
Apr  6 22:33:26.674: INFO: stdout: "update-demo-nautilus-c6xfc update-demo-nautilus-dsvrl "
Apr  6 22:33:26.674: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-c6xfc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4592'
Apr  6 22:33:26.740: INFO: stderr: ""
Apr  6 22:33:26.740: INFO: stdout: ""
Apr  6 22:33:26.740: INFO: update-demo-nautilus-c6xfc is created but not running
Apr  6 22:33:31.741: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4592'
Apr  6 22:33:31.816: INFO: stderr: ""
Apr  6 22:33:31.816: INFO: stdout: "update-demo-nautilus-c6xfc update-demo-nautilus-dsvrl "
Apr  6 22:33:31.816: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-c6xfc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4592'
Apr  6 22:33:31.885: INFO: stderr: ""
Apr  6 22:33:31.885: INFO: stdout: "true"
Apr  6 22:33:31.885: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-c6xfc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4592'
Apr  6 22:33:31.954: INFO: stderr: ""
Apr  6 22:33:31.954: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  6 22:33:31.954: INFO: validating pod update-demo-nautilus-c6xfc
Apr  6 22:33:31.959: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  6 22:33:31.959: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  6 22:33:31.959: INFO: update-demo-nautilus-c6xfc is verified up and running
Apr  6 22:33:31.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-dsvrl -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4592'
Apr  6 22:33:32.033: INFO: stderr: ""
Apr  6 22:33:32.033: INFO: stdout: "true"
Apr  6 22:33:32.033: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-dsvrl -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4592'
Apr  6 22:33:32.106: INFO: stderr: ""
Apr  6 22:33:32.106: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  6 22:33:32.106: INFO: validating pod update-demo-nautilus-dsvrl
Apr  6 22:33:32.111: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  6 22:33:32.111: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  6 22:33:32.111: INFO: update-demo-nautilus-dsvrl is verified up and running
STEP: using delete to clean up resources
Apr  6 22:33:32.111: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 delete --grace-period=0 --force -f - --namespace=kubectl-4592'
Apr  6 22:33:32.185: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  6 22:33:32.185: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr  6 22:33:32.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4592'
Apr  6 22:33:32.259: INFO: stderr: "No resources found in kubectl-4592 namespace.\n"
Apr  6 22:33:32.259: INFO: stdout: ""
Apr  6 22:33:32.259: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods -l name=update-demo --namespace=kubectl-4592 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  6 22:33:32.335: INFO: stderr: ""
Apr  6 22:33:32.335: INFO: stdout: "update-demo-nautilus-c6xfc\nupdate-demo-nautilus-dsvrl\n"
Apr  6 22:33:32.835: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4592'
Apr  6 22:33:32.913: INFO: stderr: "No resources found in kubectl-4592 namespace.\n"
Apr  6 22:33:32.914: INFO: stdout: ""
Apr  6 22:33:32.914: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods -l name=update-demo --namespace=kubectl-4592 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  6 22:33:32.984: INFO: stderr: ""
Apr  6 22:33:32.984: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:33:32.984: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4592" for this suite.
Apr  6 22:33:38.996: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:33:39.119: INFO: namespace kubectl-4592 deletion completed in 6.131006348s

• [SLOW TEST:12.739 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:33:39.119: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Apr  6 22:33:45.159: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W0406 22:33:45.159771      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  6 22:33:45.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1882" for this suite.
Apr  6 22:33:51.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:33:51.240: INFO: namespace gc-1882 deletion completed in 6.076978402s

• [SLOW TEST:12.121 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:33:51.240: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-5195.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-5195.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5195.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-5195.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-5195.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5195.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  6 22:34:01.306: INFO: DNS probes using dns-5195/dns-test-983647d5-c5e6-408c-aec6-f2ccd9edfb9c succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:34:01.325: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5195" for this suite.
Apr  6 22:34:07.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:34:07.415: INFO: namespace dns-5195 deletion completed in 6.086207898s

• [SLOW TEST:16.175 seconds]
[sig-network] DNS
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:34:07.415: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:34:07.438: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1520" for this suite.
Apr  6 22:34:13.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:34:13.519: INFO: namespace services-1520 deletion completed in 6.077217267s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.104 seconds]
[sig-network] Services
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:34:13.519: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  6 22:34:13.829: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  6 22:34:16.844: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:34:16.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9553" for this suite.
Apr  6 22:34:22.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:34:22.933: INFO: namespace webhook-9553 deletion completed in 6.080049332s
STEP: Destroying namespace "webhook-9553-markers" for this suite.
Apr  6 22:34:28.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:34:29.016: INFO: namespace webhook-9553-markers deletion completed in 6.082728071s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.506 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:34:29.025: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr  6 22:34:29.047: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-7436'
Apr  6 22:34:29.127: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr  6 22:34:29.127: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Apr  6 22:34:29.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 delete deployment e2e-test-httpd-deployment --namespace=kubectl-7436'
Apr  6 22:34:29.208: INFO: stderr: ""
Apr  6 22:34:29.208: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:34:29.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7436" for this suite.
Apr  6 22:34:41.224: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:34:41.324: INFO: namespace kubectl-7436 deletion completed in 12.110188848s

• [SLOW TEST:12.299 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:34:41.324: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-4818
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Apr  6 22:34:41.356: INFO: Found 0 stateful pods, waiting for 3
Apr  6 22:34:51.359: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  6 22:34:51.359: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  6 22:34:51.359: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Apr  6 22:34:51.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=statefulset-4818 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr  6 22:34:51.569: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr  6 22:34:51.569: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr  6 22:34:51.569: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Apr  6 22:35:01.597: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Apr  6 22:35:11.612: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=statefulset-4818 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr  6 22:35:11.820: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr  6 22:35:11.820: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr  6 22:35:11.820: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr  6 22:35:31.838: INFO: Waiting for StatefulSet statefulset-4818/ss2 to complete update
Apr  6 22:35:31.838: INFO: Waiting for Pod statefulset-4818/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Apr  6 22:35:41.843: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=statefulset-4818 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr  6 22:35:42.046: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr  6 22:35:42.046: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr  6 22:35:42.046: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr  6 22:35:52.073: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Apr  6 22:36:02.092: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=statefulset-4818 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr  6 22:36:02.311: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr  6 22:36:02.311: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr  6 22:36:02.311: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr  6 22:36:22.328: INFO: Waiting for StatefulSet statefulset-4818/ss2 to complete update
Apr  6 22:36:22.328: INFO: Waiting for Pod statefulset-4818/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Apr  6 22:36:32.335: INFO: Deleting all statefulset in ns statefulset-4818
Apr  6 22:36:32.338: INFO: Scaling statefulset ss2 to 0
Apr  6 22:37:02.353: INFO: Waiting for statefulset status.replicas updated to 0
Apr  6 22:37:02.357: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:37:02.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4818" for this suite.
Apr  6 22:37:08.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:37:08.446: INFO: namespace statefulset-4818 deletion completed in 6.074411581s

• [SLOW TEST:147.122 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:37:08.446: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr  6 22:37:08.475: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c7d69328-e98c-487f-ac40-511ce01b4969" in namespace "projected-9737" to be "success or failure"
Apr  6 22:37:08.477: INFO: Pod "downwardapi-volume-c7d69328-e98c-487f-ac40-511ce01b4969": Phase="Pending", Reason="", readiness=false. Elapsed: 2.479434ms
Apr  6 22:37:10.481: INFO: Pod "downwardapi-volume-c7d69328-e98c-487f-ac40-511ce01b4969": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005690708s
STEP: Saw pod success
Apr  6 22:37:10.481: INFO: Pod "downwardapi-volume-c7d69328-e98c-487f-ac40-511ce01b4969" satisfied condition "success or failure"
Apr  6 22:37:10.483: INFO: Trying to get logs from node 10.0.0.42 pod downwardapi-volume-c7d69328-e98c-487f-ac40-511ce01b4969 container client-container: <nil>
STEP: delete the pod
Apr  6 22:37:10.507: INFO: Waiting for pod downwardapi-volume-c7d69328-e98c-487f-ac40-511ce01b4969 to disappear
Apr  6 22:37:10.509: INFO: Pod downwardapi-volume-c7d69328-e98c-487f-ac40-511ce01b4969 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:37:10.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9737" for this suite.
Apr  6 22:37:16.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:37:16.590: INFO: namespace projected-9737 deletion completed in 6.076622628s

• [SLOW TEST:8.144 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:37:16.590: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-44eb2526-02a5-4c97-9a02-2832887b1bb7 in namespace container-probe-5647
Apr  6 22:37:18.627: INFO: Started pod busybox-44eb2526-02a5-4c97-9a02-2832887b1bb7 in namespace container-probe-5647
STEP: checking the pod's current state and verifying that restartCount is present
Apr  6 22:37:18.629: INFO: Initial restart count of pod busybox-44eb2526-02a5-4c97-9a02-2832887b1bb7 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:41:19.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5647" for this suite.
Apr  6 22:41:25.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:41:25.119: INFO: namespace container-probe-5647 deletion completed in 6.078890821s

• [SLOW TEST:248.529 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:41:25.119: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Apr  6 22:41:28.168: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:41:29.179: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5562" for this suite.
Apr  6 22:41:41.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:41:41.272: INFO: namespace replicaset-5562 deletion completed in 12.088316322s

• [SLOW TEST:16.153 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:41:41.272: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-929a4f95-5d1a-44f4-ab6e-edd395b12017
STEP: Creating a pod to test consume secrets
Apr  6 22:41:41.299: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-89cafba9-41b6-4bf0-9657-a0ed7a530f57" in namespace "projected-1358" to be "success or failure"
Apr  6 22:41:41.301: INFO: Pod "pod-projected-secrets-89cafba9-41b6-4bf0-9657-a0ed7a530f57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.279358ms
Apr  6 22:41:43.305: INFO: Pod "pod-projected-secrets-89cafba9-41b6-4bf0-9657-a0ed7a530f57": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005804189s
Apr  6 22:41:45.308: INFO: Pod "pod-projected-secrets-89cafba9-41b6-4bf0-9657-a0ed7a530f57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008972081s
STEP: Saw pod success
Apr  6 22:41:45.308: INFO: Pod "pod-projected-secrets-89cafba9-41b6-4bf0-9657-a0ed7a530f57" satisfied condition "success or failure"
Apr  6 22:41:45.311: INFO: Trying to get logs from node 10.0.0.42 pod pod-projected-secrets-89cafba9-41b6-4bf0-9657-a0ed7a530f57 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  6 22:41:45.338: INFO: Waiting for pod pod-projected-secrets-89cafba9-41b6-4bf0-9657-a0ed7a530f57 to disappear
Apr  6 22:41:45.340: INFO: Pod pod-projected-secrets-89cafba9-41b6-4bf0-9657-a0ed7a530f57 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:41:45.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1358" for this suite.
Apr  6 22:41:51.351: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:41:51.426: INFO: namespace projected-1358 deletion completed in 6.083844048s

• [SLOW TEST:10.155 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:41:51.427: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Apr  6 22:41:53.462: INFO: Pod pod-hostip-659e69a3-b06f-4226-9435-e276cac89542 has hostIP: 10.0.0.43
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:41:53.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8084" for this suite.
Apr  6 22:42:05.475: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:42:05.544: INFO: namespace pods-8084 deletion completed in 12.078118618s

• [SLOW TEST:14.117 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:42:05.544: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename aggregator
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Apr  6 22:42:05.566: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Apr  6 22:42:06.046: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Apr  6 22:42:08.082: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721809726, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721809726, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721809726, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721809726, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  6 22:42:10.085: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721809726, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721809726, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721809726, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721809726, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  6 22:42:12.084: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721809726, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721809726, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721809726, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721809726, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  6 22:42:14.709: INFO: Waited 620.960003ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:42:15.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-7892" for this suite.
Apr  6 22:42:21.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:42:21.737: INFO: namespace aggregator-7892 deletion completed in 6.24031171s

• [SLOW TEST:16.193 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:42:21.737: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Apr  6 22:42:21.767: INFO: Waiting up to 5m0s for pod "pod-4196ed17-954a-40e8-8ba0-7467ef412ec1" in namespace "emptydir-8237" to be "success or failure"
Apr  6 22:42:21.769: INFO: Pod "pod-4196ed17-954a-40e8-8ba0-7467ef412ec1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.328727ms
Apr  6 22:42:23.772: INFO: Pod "pod-4196ed17-954a-40e8-8ba0-7467ef412ec1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005102164s
Apr  6 22:42:25.775: INFO: Pod "pod-4196ed17-954a-40e8-8ba0-7467ef412ec1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008375868s
STEP: Saw pod success
Apr  6 22:42:25.775: INFO: Pod "pod-4196ed17-954a-40e8-8ba0-7467ef412ec1" satisfied condition "success or failure"
Apr  6 22:42:25.777: INFO: Trying to get logs from node 10.0.0.42 pod pod-4196ed17-954a-40e8-8ba0-7467ef412ec1 container test-container: <nil>
STEP: delete the pod
Apr  6 22:42:25.791: INFO: Waiting for pod pod-4196ed17-954a-40e8-8ba0-7467ef412ec1 to disappear
Apr  6 22:42:25.793: INFO: Pod pod-4196ed17-954a-40e8-8ba0-7467ef412ec1 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:42:25.793: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8237" for this suite.
Apr  6 22:42:31.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:42:31.888: INFO: namespace emptydir-8237 deletion completed in 6.09030106s

• [SLOW TEST:10.151 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:42:31.888: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-9e9dd52f-fd48-40fc-ab5d-06a1a4ee90d1
STEP: Creating a pod to test consume configMaps
Apr  6 22:42:31.916: INFO: Waiting up to 5m0s for pod "pod-configmaps-72be644f-769d-41d5-8931-1ae51411f28d" in namespace "configmap-9077" to be "success or failure"
Apr  6 22:42:31.918: INFO: Pod "pod-configmaps-72be644f-769d-41d5-8931-1ae51411f28d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.597879ms
Apr  6 22:42:33.923: INFO: Pod "pod-configmaps-72be644f-769d-41d5-8931-1ae51411f28d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007778254s
STEP: Saw pod success
Apr  6 22:42:33.923: INFO: Pod "pod-configmaps-72be644f-769d-41d5-8931-1ae51411f28d" satisfied condition "success or failure"
Apr  6 22:42:33.928: INFO: Trying to get logs from node 10.0.0.42 pod pod-configmaps-72be644f-769d-41d5-8931-1ae51411f28d container configmap-volume-test: <nil>
STEP: delete the pod
Apr  6 22:42:33.944: INFO: Waiting for pod pod-configmaps-72be644f-769d-41d5-8931-1ae51411f28d to disappear
Apr  6 22:42:33.947: INFO: Pod pod-configmaps-72be644f-769d-41d5-8931-1ae51411f28d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:42:33.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9077" for this suite.
Apr  6 22:42:39.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:42:40.033: INFO: namespace configmap-9077 deletion completed in 6.083023363s

• [SLOW TEST:8.145 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:42:40.034: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename containers
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:42:42.076: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-4557" for this suite.
Apr  6 22:42:50.088: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:42:50.182: INFO: namespace containers-4557 deletion completed in 8.102184612s

• [SLOW TEST:10.148 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:42:50.182: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Apr  6 22:42:50.208: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9471 /api/v1/namespaces/watch-9471/configmaps/e2e-watch-test-watch-closed 1876be1f-06ec-4f60-b05b-bfa0e92b63cb 13679 0 2020-04-06 22:42:50 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  6 22:42:50.208: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9471 /api/v1/namespaces/watch-9471/configmaps/e2e-watch-test-watch-closed 1876be1f-06ec-4f60-b05b-bfa0e92b63cb 13680 0 2020-04-06 22:42:50 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Apr  6 22:42:50.218: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9471 /api/v1/namespaces/watch-9471/configmaps/e2e-watch-test-watch-closed 1876be1f-06ec-4f60-b05b-bfa0e92b63cb 13681 0 2020-04-06 22:42:50 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  6 22:42:50.219: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-9471 /api/v1/namespaces/watch-9471/configmaps/e2e-watch-test-watch-closed 1876be1f-06ec-4f60-b05b-bfa0e92b63cb 13682 0 2020-04-06 22:42:50 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:42:50.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9471" for this suite.
Apr  6 22:42:56.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:42:56.319: INFO: namespace watch-9471 deletion completed in 6.097390061s

• [SLOW TEST:6.138 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:42:56.320: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-c665b83e-0ffd-46d4-ad07-df234629a24f in namespace container-probe-2829
Apr  6 22:42:58.351: INFO: Started pod liveness-c665b83e-0ffd-46d4-ad07-df234629a24f in namespace container-probe-2829
STEP: checking the pod's current state and verifying that restartCount is present
Apr  6 22:42:58.354: INFO: Initial restart count of pod liveness-c665b83e-0ffd-46d4-ad07-df234629a24f is 0
Apr  6 22:43:14.381: INFO: Restart count of pod container-probe-2829/liveness-c665b83e-0ffd-46d4-ad07-df234629a24f is now 1 (16.026653192s elapsed)
Apr  6 22:43:32.410: INFO: Restart count of pod container-probe-2829/liveness-c665b83e-0ffd-46d4-ad07-df234629a24f is now 2 (34.055696583s elapsed)
Apr  6 22:43:52.452: INFO: Restart count of pod container-probe-2829/liveness-c665b83e-0ffd-46d4-ad07-df234629a24f is now 3 (54.098279773s elapsed)
Apr  6 22:44:12.484: INFO: Restart count of pod container-probe-2829/liveness-c665b83e-0ffd-46d4-ad07-df234629a24f is now 4 (1m14.129726196s elapsed)
Apr  6 22:45:14.581: INFO: Restart count of pod container-probe-2829/liveness-c665b83e-0ffd-46d4-ad07-df234629a24f is now 5 (2m16.22744103s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:45:14.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2829" for this suite.
Apr  6 22:45:20.602: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:45:20.671: INFO: namespace container-probe-2829 deletion completed in 6.077577737s

• [SLOW TEST:144.351 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:45:20.671: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr  6 22:45:20.699: INFO: Waiting up to 5m0s for pod "downwardapi-volume-66b87d41-5ae3-44c4-aabb-40851366137d" in namespace "projected-9509" to be "success or failure"
Apr  6 22:45:20.702: INFO: Pod "downwardapi-volume-66b87d41-5ae3-44c4-aabb-40851366137d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.370547ms
Apr  6 22:45:22.706: INFO: Pod "downwardapi-volume-66b87d41-5ae3-44c4-aabb-40851366137d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006620604s
STEP: Saw pod success
Apr  6 22:45:22.706: INFO: Pod "downwardapi-volume-66b87d41-5ae3-44c4-aabb-40851366137d" satisfied condition "success or failure"
Apr  6 22:45:22.708: INFO: Trying to get logs from node 10.0.0.44 pod downwardapi-volume-66b87d41-5ae3-44c4-aabb-40851366137d container client-container: <nil>
STEP: delete the pod
Apr  6 22:45:22.731: INFO: Waiting for pod downwardapi-volume-66b87d41-5ae3-44c4-aabb-40851366137d to disappear
Apr  6 22:45:22.733: INFO: Pod downwardapi-volume-66b87d41-5ae3-44c4-aabb-40851366137d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:45:22.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9509" for this suite.
Apr  6 22:45:28.746: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:45:28.823: INFO: namespace projected-9509 deletion completed in 6.085651385s

• [SLOW TEST:8.151 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:45:28.823: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr  6 22:45:28.847: INFO: Waiting up to 5m0s for pod "pod-e7720442-00f8-4a3f-9230-9916d9e10e89" in namespace "emptydir-2129" to be "success or failure"
Apr  6 22:45:28.849: INFO: Pod "pod-e7720442-00f8-4a3f-9230-9916d9e10e89": Phase="Pending", Reason="", readiness=false. Elapsed: 2.014166ms
Apr  6 22:45:30.853: INFO: Pod "pod-e7720442-00f8-4a3f-9230-9916d9e10e89": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005306959s
STEP: Saw pod success
Apr  6 22:45:30.853: INFO: Pod "pod-e7720442-00f8-4a3f-9230-9916d9e10e89" satisfied condition "success or failure"
Apr  6 22:45:30.855: INFO: Trying to get logs from node 10.0.0.44 pod pod-e7720442-00f8-4a3f-9230-9916d9e10e89 container test-container: <nil>
STEP: delete the pod
Apr  6 22:45:30.873: INFO: Waiting for pod pod-e7720442-00f8-4a3f-9230-9916d9e10e89 to disappear
Apr  6 22:45:30.875: INFO: Pod pod-e7720442-00f8-4a3f-9230-9916d9e10e89 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:45:30.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2129" for this suite.
Apr  6 22:45:36.887: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:45:37.033: INFO: namespace emptydir-2129 deletion completed in 6.153893261s

• [SLOW TEST:8.210 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:45:37.033: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 22:45:37.058: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-f5ccda49-31e3-4fe7-83db-9e941bf7d688" in namespace "security-context-test-7290" to be "success or failure"
Apr  6 22:45:37.060: INFO: Pod "busybox-privileged-false-f5ccda49-31e3-4fe7-83db-9e941bf7d688": Phase="Pending", Reason="", readiness=false. Elapsed: 2.201422ms
Apr  6 22:45:39.063: INFO: Pod "busybox-privileged-false-f5ccda49-31e3-4fe7-83db-9e941bf7d688": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005244751s
Apr  6 22:45:39.063: INFO: Pod "busybox-privileged-false-f5ccda49-31e3-4fe7-83db-9e941bf7d688" satisfied condition "success or failure"
Apr  6 22:45:39.071: INFO: Got logs for pod "busybox-privileged-false-f5ccda49-31e3-4fe7-83db-9e941bf7d688": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:45:39.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7290" for this suite.
Apr  6 22:45:45.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:45:45.238: INFO: namespace security-context-test-7290 deletion completed in 6.163341379s

• [SLOW TEST:8.205 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:45:45.238: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Apr  6 22:45:45.543: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Apr  6 22:45:47.555: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721809945, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721809945, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721809945, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721809945, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  6 22:45:50.565: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 22:45:50.568: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:45:51.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-7303" for this suite.
Apr  6 22:45:57.668: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:45:57.833: INFO: namespace crd-webhook-7303 deletion completed in 6.173916576s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:12.605 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:45:57.843: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6086
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-6086
Apr  6 22:45:57.880: INFO: Found 0 stateful pods, waiting for 1
Apr  6 22:46:07.884: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Apr  6 22:46:07.898: INFO: Deleting all statefulset in ns statefulset-6086
Apr  6 22:46:07.902: INFO: Scaling statefulset ss to 0
Apr  6 22:46:27.916: INFO: Waiting for statefulset status.replicas updated to 0
Apr  6 22:46:27.918: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:46:27.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6086" for this suite.
Apr  6 22:46:33.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:46:34.010: INFO: namespace statefulset-6086 deletion completed in 6.078148783s

• [SLOW TEST:36.166 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:46:34.010: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-9387
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-9387
STEP: creating replication controller externalsvc in namespace services-9387
I0406 22:46:34.055150      23 runners.go:184] Created replication controller with name: externalsvc, namespace: services-9387, replica count: 2
I0406 22:46:37.105711      23 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Apr  6 22:46:37.118: INFO: Creating new exec pod
Apr  6 22:46:39.127: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=services-9387 execpod7cq2l -- /bin/sh -x -c nslookup nodeport-service'
Apr  6 22:46:39.565: INFO: stderr: "+ nslookup nodeport-service\n"
Apr  6 22:46:39.565: INFO: stdout: "Server:\t\t10.21.0.10\nAddress:\t10.21.0.10#53\n\nnodeport-service.services-9387.svc.cluster.local\tcanonical name = externalsvc.services-9387.svc.cluster.local.\nName:\texternalsvc.services-9387.svc.cluster.local\nAddress: 10.21.128.134\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-9387, will wait for the garbage collector to delete the pods
Apr  6 22:46:39.623: INFO: Deleting ReplicationController externalsvc took: 4.994687ms
Apr  6 22:46:40.223: INFO: Terminating ReplicationController externalsvc pods took: 600.252474ms
Apr  6 22:46:46.437: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:46:46.448: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9387" for this suite.
Apr  6 22:46:52.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:46:52.534: INFO: namespace services-9387 deletion completed in 6.082161254s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:18.524 seconds]
[sig-network] Services
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:46:52.534: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Apr  6 22:46:52.556: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Apr  6 22:46:52.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 create -f - --namespace=kubectl-5832'
Apr  6 22:46:52.757: INFO: stderr: ""
Apr  6 22:46:52.757: INFO: stdout: "service/redis-slave created\n"
Apr  6 22:46:52.757: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Apr  6 22:46:52.757: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 create -f - --namespace=kubectl-5832'
Apr  6 22:46:52.902: INFO: stderr: ""
Apr  6 22:46:52.902: INFO: stdout: "service/redis-master created\n"
Apr  6 22:46:52.902: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Apr  6 22:46:52.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 create -f - --namespace=kubectl-5832'
Apr  6 22:46:53.043: INFO: stderr: ""
Apr  6 22:46:53.043: INFO: stdout: "service/frontend created\n"
Apr  6 22:46:53.043: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Apr  6 22:46:53.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 create -f - --namespace=kubectl-5832'
Apr  6 22:46:53.178: INFO: stderr: ""
Apr  6 22:46:53.178: INFO: stdout: "deployment.apps/frontend created\n"
Apr  6 22:46:53.178: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Apr  6 22:46:53.178: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 create -f - --namespace=kubectl-5832'
Apr  6 22:46:53.319: INFO: stderr: ""
Apr  6 22:46:53.319: INFO: stdout: "deployment.apps/redis-master created\n"
Apr  6 22:46:53.320: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Apr  6 22:46:53.320: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 create -f - --namespace=kubectl-5832'
Apr  6 22:46:53.450: INFO: stderr: ""
Apr  6 22:46:53.450: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Apr  6 22:46:53.450: INFO: Waiting for all frontend pods to be Running.
Apr  6 22:47:08.501: INFO: Waiting for frontend to serve content.
Apr  6 22:47:08.526: INFO: Trying to add a new entry to the guestbook.
Apr  6 22:47:08.539: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Apr  6 22:47:08.549: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 delete --grace-period=0 --force -f - --namespace=kubectl-5832'
Apr  6 22:47:08.632: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  6 22:47:08.632: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Apr  6 22:47:08.632: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 delete --grace-period=0 --force -f - --namespace=kubectl-5832'
Apr  6 22:47:08.716: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  6 22:47:08.716: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr  6 22:47:08.716: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 delete --grace-period=0 --force -f - --namespace=kubectl-5832'
Apr  6 22:47:08.796: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  6 22:47:08.796: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr  6 22:47:08.796: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 delete --grace-period=0 --force -f - --namespace=kubectl-5832'
Apr  6 22:47:08.870: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  6 22:47:08.870: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Apr  6 22:47:08.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 delete --grace-period=0 --force -f - --namespace=kubectl-5832'
Apr  6 22:47:08.940: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  6 22:47:08.940: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Apr  6 22:47:08.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 delete --grace-period=0 --force -f - --namespace=kubectl-5832'
Apr  6 22:47:09.014: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  6 22:47:09.014: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:47:09.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5832" for this suite.
Apr  6 22:47:37.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:47:37.093: INFO: namespace kubectl-5832 deletion completed in 28.075314774s

• [SLOW TEST:44.559 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:47:37.094: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 22:47:37.116: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Apr  6 22:47:38.940: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 --namespace=crd-publish-openapi-3245 create -f -'
Apr  6 22:47:39.414: INFO: stderr: ""
Apr  6 22:47:39.414: INFO: stdout: "e2e-test-crd-publish-openapi-8764-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr  6 22:47:39.414: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 --namespace=crd-publish-openapi-3245 delete e2e-test-crd-publish-openapi-8764-crds test-foo'
Apr  6 22:47:39.496: INFO: stderr: ""
Apr  6 22:47:39.496: INFO: stdout: "e2e-test-crd-publish-openapi-8764-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Apr  6 22:47:39.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 --namespace=crd-publish-openapi-3245 apply -f -'
Apr  6 22:47:39.648: INFO: stderr: ""
Apr  6 22:47:39.648: INFO: stdout: "e2e-test-crd-publish-openapi-8764-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Apr  6 22:47:39.648: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 --namespace=crd-publish-openapi-3245 delete e2e-test-crd-publish-openapi-8764-crds test-foo'
Apr  6 22:47:39.722: INFO: stderr: ""
Apr  6 22:47:39.722: INFO: stdout: "e2e-test-crd-publish-openapi-8764-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Apr  6 22:47:39.722: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 --namespace=crd-publish-openapi-3245 create -f -'
Apr  6 22:47:39.844: INFO: rc: 1
Apr  6 22:47:39.844: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 --namespace=crd-publish-openapi-3245 apply -f -'
Apr  6 22:47:39.967: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Apr  6 22:47:39.967: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 --namespace=crd-publish-openapi-3245 create -f -'
Apr  6 22:47:40.097: INFO: rc: 1
Apr  6 22:47:40.097: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 --namespace=crd-publish-openapi-3245 apply -f -'
Apr  6 22:47:40.239: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Apr  6 22:47:40.240: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 explain e2e-test-crd-publish-openapi-8764-crds'
Apr  6 22:47:40.390: INFO: stderr: ""
Apr  6 22:47:40.390: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8764-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Apr  6 22:47:40.391: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 explain e2e-test-crd-publish-openapi-8764-crds.metadata'
Apr  6 22:47:40.527: INFO: stderr: ""
Apr  6 22:47:40.527: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8764-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Apr  6 22:47:40.528: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 explain e2e-test-crd-publish-openapi-8764-crds.spec'
Apr  6 22:47:40.657: INFO: stderr: ""
Apr  6 22:47:40.657: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8764-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Apr  6 22:47:40.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 explain e2e-test-crd-publish-openapi-8764-crds.spec.bars'
Apr  6 22:47:40.792: INFO: stderr: ""
Apr  6 22:47:40.792: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8764-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Apr  6 22:47:40.792: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 explain e2e-test-crd-publish-openapi-8764-crds.spec.bars2'
Apr  6 22:47:40.916: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:47:42.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3245" for this suite.
Apr  6 22:47:48.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:47:48.794: INFO: namespace crd-publish-openapi-3245 deletion completed in 6.082531147s

• [SLOW TEST:11.701 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:47:48.795: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-b91e6a23-bcb5-4d4f-8e48-22d04f77ad9e
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:47:48.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5370" for this suite.
Apr  6 22:47:54.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:47:54.902: INFO: namespace configmap-5370 deletion completed in 6.080919842s

• [SLOW TEST:6.107 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:47:54.903: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Apr  6 22:47:54.924: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:48:09.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7502" for this suite.
Apr  6 22:48:15.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:48:15.476: INFO: namespace crd-publish-openapi-7502 deletion completed in 6.078749398s

• [SLOW TEST:20.574 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:48:15.477: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8387.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8387.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8387.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8387.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  6 22:48:19.524: INFO: DNS probes using dns-test-3ba9ee9c-4758-4ee8-8a0a-fb58f67ada08 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8387.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-8387.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8387.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-8387.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  6 22:48:23.565: INFO: File wheezy_udp@dns-test-service-3.dns-8387.svc.cluster.local from pod  dns-8387/dns-test-fdc5e859-8d98-425b-9311-88ca2c719f5a contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr  6 22:48:23.568: INFO: File jessie_udp@dns-test-service-3.dns-8387.svc.cluster.local from pod  dns-8387/dns-test-fdc5e859-8d98-425b-9311-88ca2c719f5a contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr  6 22:48:23.568: INFO: Lookups using dns-8387/dns-test-fdc5e859-8d98-425b-9311-88ca2c719f5a failed for: [wheezy_udp@dns-test-service-3.dns-8387.svc.cluster.local jessie_udp@dns-test-service-3.dns-8387.svc.cluster.local]

Apr  6 22:48:28.573: INFO: File wheezy_udp@dns-test-service-3.dns-8387.svc.cluster.local from pod  dns-8387/dns-test-fdc5e859-8d98-425b-9311-88ca2c719f5a contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr  6 22:48:28.577: INFO: File jessie_udp@dns-test-service-3.dns-8387.svc.cluster.local from pod  dns-8387/dns-test-fdc5e859-8d98-425b-9311-88ca2c719f5a contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr  6 22:48:28.577: INFO: Lookups using dns-8387/dns-test-fdc5e859-8d98-425b-9311-88ca2c719f5a failed for: [wheezy_udp@dns-test-service-3.dns-8387.svc.cluster.local jessie_udp@dns-test-service-3.dns-8387.svc.cluster.local]

Apr  6 22:48:33.573: INFO: File wheezy_udp@dns-test-service-3.dns-8387.svc.cluster.local from pod  dns-8387/dns-test-fdc5e859-8d98-425b-9311-88ca2c719f5a contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr  6 22:48:33.576: INFO: File jessie_udp@dns-test-service-3.dns-8387.svc.cluster.local from pod  dns-8387/dns-test-fdc5e859-8d98-425b-9311-88ca2c719f5a contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr  6 22:48:33.576: INFO: Lookups using dns-8387/dns-test-fdc5e859-8d98-425b-9311-88ca2c719f5a failed for: [wheezy_udp@dns-test-service-3.dns-8387.svc.cluster.local jessie_udp@dns-test-service-3.dns-8387.svc.cluster.local]

Apr  6 22:48:38.573: INFO: File wheezy_udp@dns-test-service-3.dns-8387.svc.cluster.local from pod  dns-8387/dns-test-fdc5e859-8d98-425b-9311-88ca2c719f5a contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr  6 22:48:38.579: INFO: File jessie_udp@dns-test-service-3.dns-8387.svc.cluster.local from pod  dns-8387/dns-test-fdc5e859-8d98-425b-9311-88ca2c719f5a contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr  6 22:48:38.579: INFO: Lookups using dns-8387/dns-test-fdc5e859-8d98-425b-9311-88ca2c719f5a failed for: [wheezy_udp@dns-test-service-3.dns-8387.svc.cluster.local jessie_udp@dns-test-service-3.dns-8387.svc.cluster.local]

Apr  6 22:48:43.573: INFO: File wheezy_udp@dns-test-service-3.dns-8387.svc.cluster.local from pod  dns-8387/dns-test-fdc5e859-8d98-425b-9311-88ca2c719f5a contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr  6 22:48:43.578: INFO: File jessie_udp@dns-test-service-3.dns-8387.svc.cluster.local from pod  dns-8387/dns-test-fdc5e859-8d98-425b-9311-88ca2c719f5a contains 'foo.example.com.
' instead of 'bar.example.com.'
Apr  6 22:48:43.578: INFO: Lookups using dns-8387/dns-test-fdc5e859-8d98-425b-9311-88ca2c719f5a failed for: [wheezy_udp@dns-test-service-3.dns-8387.svc.cluster.local jessie_udp@dns-test-service-3.dns-8387.svc.cluster.local]

Apr  6 22:48:48.576: INFO: DNS probes using dns-test-fdc5e859-8d98-425b-9311-88ca2c719f5a succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8387.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-8387.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-8387.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-8387.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  6 22:48:52.628: INFO: DNS probes using dns-test-38c2532c-6dc4-4fa3-a107-35998079a1fa succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:48:52.647: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8387" for this suite.
Apr  6 22:48:58.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:48:58.735: INFO: namespace dns-8387 deletion completed in 6.08370971s

• [SLOW TEST:43.258 seconds]
[sig-network] DNS
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:48:58.735: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Apr  6 22:49:02.780: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  6 22:49:02.782: INFO: Pod pod-with-prestop-http-hook still exists
Apr  6 22:49:04.783: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  6 22:49:04.785: INFO: Pod pod-with-prestop-http-hook still exists
Apr  6 22:49:06.783: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  6 22:49:06.785: INFO: Pod pod-with-prestop-http-hook still exists
Apr  6 22:49:08.783: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  6 22:49:08.786: INFO: Pod pod-with-prestop-http-hook still exists
Apr  6 22:49:10.783: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  6 22:49:10.786: INFO: Pod pod-with-prestop-http-hook still exists
Apr  6 22:49:12.783: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  6 22:49:12.785: INFO: Pod pod-with-prestop-http-hook still exists
Apr  6 22:49:14.783: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  6 22:49:14.785: INFO: Pod pod-with-prestop-http-hook still exists
Apr  6 22:49:16.783: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Apr  6 22:49:16.785: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:49:16.801: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2920" for this suite.
Apr  6 22:49:28.814: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:49:28.890: INFO: namespace container-lifecycle-hook-2920 deletion completed in 12.084523957s

• [SLOW TEST:30.155 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:49:28.890: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Apr  6 22:49:28.911: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  6 22:49:28.922: INFO: Waiting for terminating namespaces to be deleted...
Apr  6 22:49:28.924: INFO: 
Logging pods the kubelet thinks is on node 10.0.0.42 before test
Apr  6 22:49:28.935: INFO: sonobuoy from sonobuoy started at 2020-04-06 21:55:11 +0000 UTC (1 container statuses recorded)
Apr  6 22:49:28.935: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr  6 22:49:28.935: INFO: sonobuoy-systemd-logs-daemon-set-3f2ae32d33c24b28-z5vfz from sonobuoy started at 2020-04-06 21:55:15 +0000 UTC (2 container statuses recorded)
Apr  6 22:49:28.935: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  6 22:49:28.935: INFO: 	Container systemd-logs ready: true, restart count 0
Apr  6 22:49:28.935: INFO: prometheus-operator-546b677c-8nsvj from pf9-operators started at 2020-04-06 22:08:44 +0000 UTC (1 container statuses recorded)
Apr  6 22:49:28.935: INFO: 	Container prometheus-operator ready: true, restart count 0
Apr  6 22:49:28.935: INFO: comms-proxy-f9jz2 from pf9-monitoring started at 2020-04-06 22:08:48 +0000 UTC (1 container statuses recorded)
Apr  6 22:49:28.935: INFO: 	Container envoy ready: true, restart count 0
Apr  6 22:49:28.935: INFO: olm-operator-76d446f94c-rhq8h from pf9-olm started at 2020-04-06 21:53:11 +0000 UTC (1 container statuses recorded)
Apr  6 22:49:28.935: INFO: 	Container olm-operator ready: true, restart count 0
Apr  6 22:49:28.935: INFO: kube-state-metrics-595cb5cc-hkr95 from pf9-monitoring started at 2020-04-06 21:53:20 +0000 UTC (1 container statuses recorded)
Apr  6 22:49:28.935: INFO: 	Container kube-state-metrics ready: true, restart count 0
Apr  6 22:49:28.935: INFO: node-exporter-q8z8v from pf9-monitoring started at 2020-04-06 21:53:24 +0000 UTC (1 container statuses recorded)
Apr  6 22:49:28.935: INFO: 	Container node-exporter ready: true, restart count 0
Apr  6 22:49:28.935: INFO: 
Logging pods the kubelet thinks is on node 10.0.0.43 before test
Apr  6 22:49:28.948: INFO: catalog-operator-5898bbb7d6-86vpd from pf9-olm started at 2020-04-06 21:53:10 +0000 UTC (1 container statuses recorded)
Apr  6 22:49:28.948: INFO: 	Container catalog-operator ready: true, restart count 0
Apr  6 22:49:28.948: INFO: node-exporter-xl5fz from pf9-monitoring started at 2020-04-06 21:53:24 +0000 UTC (1 container statuses recorded)
Apr  6 22:49:28.948: INFO: 	Container node-exporter ready: true, restart count 0
Apr  6 22:49:28.948: INFO: prometheus-system-0 from pf9-monitoring started at 2020-04-06 22:09:29 +0000 UTC (3 container statuses recorded)
Apr  6 22:49:28.948: INFO: 	Container prometheus ready: true, restart count 1
Apr  6 22:49:28.948: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Apr  6 22:49:28.948: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Apr  6 22:49:28.948: INFO: sonobuoy-systemd-logs-daemon-set-3f2ae32d33c24b28-2j6sr from sonobuoy started at 2020-04-06 21:55:15 +0000 UTC (2 container statuses recorded)
Apr  6 22:49:28.948: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  6 22:49:28.948: INFO: 	Container systemd-logs ready: true, restart count 0
Apr  6 22:49:28.948: INFO: packageserver-7799547bfb-ztvbk from pf9-olm started at 2020-04-06 21:53:29 +0000 UTC (1 container statuses recorded)
Apr  6 22:49:28.948: INFO: 	Container packageserver ready: true, restart count 0
Apr  6 22:49:28.948: INFO: comms-proxy-gpw8d from pf9-monitoring started at 2020-04-06 22:08:48 +0000 UTC (1 container statuses recorded)
Apr  6 22:49:28.948: INFO: 	Container envoy ready: true, restart count 0
Apr  6 22:49:28.948: INFO: grafana-86dfdd45b7-78rmr from pf9-monitoring started at 2020-04-06 22:09:29 +0000 UTC (2 container statuses recorded)
Apr  6 22:49:28.948: INFO: 	Container grafana ready: true, restart count 0
Apr  6 22:49:28.948: INFO: 	Container proxy ready: true, restart count 0
Apr  6 22:49:28.948: INFO: 
Logging pods the kubelet thinks is on node 10.0.0.44 before test
Apr  6 22:49:28.955: INFO: sonobuoy-e2e-job-c807e2fec0184d0b from sonobuoy started at 2020-04-06 21:55:15 +0000 UTC (2 container statuses recorded)
Apr  6 22:49:28.955: INFO: 	Container e2e ready: true, restart count 0
Apr  6 22:49:28.955: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  6 22:49:28.955: INFO: packageserver-7799547bfb-5vjt4 from pf9-olm started at 2020-04-06 21:53:20 +0000 UTC (1 container statuses recorded)
Apr  6 22:49:28.955: INFO: 	Container packageserver ready: true, restart count 0
Apr  6 22:49:28.955: INFO: platform9-operators-z62nw from pf9-olm started at 2020-04-06 21:53:38 +0000 UTC (1 container statuses recorded)
Apr  6 22:49:28.955: INFO: 	Container registry-server ready: true, restart count 0
Apr  6 22:49:28.955: INFO: alertmanager-sysalert-0 from pf9-monitoring started at 2020-04-06 22:09:29 +0000 UTC (2 container statuses recorded)
Apr  6 22:49:28.955: INFO: 	Container alertmanager ready: true, restart count 0
Apr  6 22:49:28.955: INFO: 	Container config-reloader ready: true, restart count 0
Apr  6 22:49:28.955: INFO: node-exporter-w7m2g from pf9-monitoring started at 2020-04-06 21:53:24 +0000 UTC (1 container statuses recorded)
Apr  6 22:49:28.955: INFO: 	Container node-exporter ready: true, restart count 0
Apr  6 22:49:28.955: INFO: sonobuoy-systemd-logs-daemon-set-3f2ae32d33c24b28-cst5h from sonobuoy started at 2020-04-06 21:55:15 +0000 UTC (2 container statuses recorded)
Apr  6 22:49:28.955: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  6 22:49:28.955: INFO: 	Container systemd-logs ready: true, restart count 0
Apr  6 22:49:28.955: INFO: monhelper-666465d6b5-8t499 from pf9-operators started at 2020-04-06 22:08:44 +0000 UTC (1 container statuses recorded)
Apr  6 22:49:28.955: INFO: 	Container monhelper ready: true, restart count 0
Apr  6 22:49:28.955: INFO: comms-proxy-28brb from pf9-monitoring started at 2020-04-06 22:08:48 +0000 UTC (1 container statuses recorded)
Apr  6 22:49:28.955: INFO: 	Container envoy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-803d7e24-0d81-43bb-b2b4-c1111de6fd12 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-803d7e24-0d81-43bb-b2b4-c1111de6fd12 off the node 10.0.0.44
STEP: verifying the node doesn't have the label kubernetes.io/e2e-803d7e24-0d81-43bb-b2b4-c1111de6fd12
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:49:33.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6473" for this suite.
Apr  6 22:49:41.020: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:49:41.131: INFO: namespace sched-pred-6473 deletion completed in 8.122466516s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:12.241 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:49:41.131: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Apr  6 22:49:43.172: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-273020805 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Apr  6 22:49:48.240: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:49:48.243: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8499" for this suite.
Apr  6 22:49:54.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:49:54.316: INFO: namespace pods-8499 deletion completed in 6.069008112s

• [SLOW TEST:13.184 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:49:54.316: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-687e20cd-2701-48bb-8677-7d6de67b5d06
STEP: Creating a pod to test consume secrets
Apr  6 22:49:54.348: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-22c01008-2c30-4291-8217-65daccbd9259" in namespace "projected-1831" to be "success or failure"
Apr  6 22:49:54.352: INFO: Pod "pod-projected-secrets-22c01008-2c30-4291-8217-65daccbd9259": Phase="Pending", Reason="", readiness=false. Elapsed: 4.05723ms
Apr  6 22:49:56.356: INFO: Pod "pod-projected-secrets-22c01008-2c30-4291-8217-65daccbd9259": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007365759s
STEP: Saw pod success
Apr  6 22:49:56.356: INFO: Pod "pod-projected-secrets-22c01008-2c30-4291-8217-65daccbd9259" satisfied condition "success or failure"
Apr  6 22:49:56.358: INFO: Trying to get logs from node 10.0.0.44 pod pod-projected-secrets-22c01008-2c30-4291-8217-65daccbd9259 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  6 22:49:56.374: INFO: Waiting for pod pod-projected-secrets-22c01008-2c30-4291-8217-65daccbd9259 to disappear
Apr  6 22:49:56.377: INFO: Pod pod-projected-secrets-22c01008-2c30-4291-8217-65daccbd9259 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:49:56.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1831" for this suite.
Apr  6 22:50:02.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:50:02.455: INFO: namespace projected-1831 deletion completed in 6.074482214s

• [SLOW TEST:8.140 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:50:02.456: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 22:50:02.478: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:50:08.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8215" for this suite.
Apr  6 22:50:14.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:50:14.322: INFO: namespace custom-resource-definition-8215 deletion completed in 6.08667186s

• [SLOW TEST:11.867 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:50:14.323: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:50:14.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3690" for this suite.
Apr  6 22:50:20.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:50:20.449: INFO: namespace kubelet-test-3690 deletion completed in 6.078856391s

• [SLOW TEST:6.126 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:50:20.449: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  6 22:50:20.728: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr  6 22:50:22.736: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721810220, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721810220, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721810220, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721810220, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  6 22:50:25.746: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:50:25.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-937" for this suite.
Apr  6 22:50:31.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:50:31.860: INFO: namespace webhook-937 deletion completed in 6.082549599s
STEP: Destroying namespace "webhook-937-markers" for this suite.
Apr  6 22:50:37.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:50:38.036: INFO: namespace webhook-937-markers deletion completed in 6.175564075s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.598 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:50:38.047: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-e9d5f307-e313-4092-92d2-db8406c0cf88
STEP: Creating secret with name s-test-opt-upd-60f9d46f-7a14-4c29-97c3-014a5d5cf3e0
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-e9d5f307-e313-4092-92d2-db8406c0cf88
STEP: Updating secret s-test-opt-upd-60f9d46f-7a14-4c29-97c3-014a5d5cf3e0
STEP: Creating secret with name s-test-opt-create-053a1f10-def7-4589-bd1a-229d1a890590
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:52:10.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7993" for this suite.
Apr  6 22:52:28.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:52:28.628: INFO: namespace secrets-7993 deletion completed in 18.087057496s

• [SLOW TEST:110.581 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:52:28.628: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 22:52:28.653: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-6e1d93b5-9f50-48cd-8700-dc693aee3707" in namespace "security-context-test-2434" to be "success or failure"
Apr  6 22:52:28.656: INFO: Pod "busybox-readonly-false-6e1d93b5-9f50-48cd-8700-dc693aee3707": Phase="Pending", Reason="", readiness=false. Elapsed: 2.290757ms
Apr  6 22:52:30.659: INFO: Pod "busybox-readonly-false-6e1d93b5-9f50-48cd-8700-dc693aee3707": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005323509s
Apr  6 22:52:30.659: INFO: Pod "busybox-readonly-false-6e1d93b5-9f50-48cd-8700-dc693aee3707" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:52:30.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2434" for this suite.
Apr  6 22:52:36.671: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:52:36.742: INFO: namespace security-context-test-2434 deletion completed in 6.078966875s

• [SLOW TEST:8.114 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:52:36.742: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  6 22:52:37.069: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  6 22:52:40.083: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:52:40.135: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7058" for this suite.
Apr  6 22:52:46.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:52:46.225: INFO: namespace webhook-7058 deletion completed in 6.085904903s
STEP: Destroying namespace "webhook-7058-markers" for this suite.
Apr  6 22:52:52.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:52:52.310: INFO: namespace webhook-7058-markers deletion completed in 6.085509275s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.580 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:52:52.322: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-10948d17-4dda-4df8-b0ef-5a4ba66ccc5f
STEP: Creating a pod to test consume secrets
Apr  6 22:52:52.353: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-4efb1cf6-20c6-466c-b5ab-d8da73a13203" in namespace "projected-1375" to be "success or failure"
Apr  6 22:52:52.356: INFO: Pod "pod-projected-secrets-4efb1cf6-20c6-466c-b5ab-d8da73a13203": Phase="Pending", Reason="", readiness=false. Elapsed: 2.914304ms
Apr  6 22:52:54.359: INFO: Pod "pod-projected-secrets-4efb1cf6-20c6-466c-b5ab-d8da73a13203": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006178337s
STEP: Saw pod success
Apr  6 22:52:54.359: INFO: Pod "pod-projected-secrets-4efb1cf6-20c6-466c-b5ab-d8da73a13203" satisfied condition "success or failure"
Apr  6 22:52:54.361: INFO: Trying to get logs from node 10.0.0.42 pod pod-projected-secrets-4efb1cf6-20c6-466c-b5ab-d8da73a13203 container projected-secret-volume-test: <nil>
STEP: delete the pod
Apr  6 22:52:54.386: INFO: Waiting for pod pod-projected-secrets-4efb1cf6-20c6-466c-b5ab-d8da73a13203 to disappear
Apr  6 22:52:54.388: INFO: Pod pod-projected-secrets-4efb1cf6-20c6-466c-b5ab-d8da73a13203 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:52:54.388: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1375" for this suite.
Apr  6 22:53:00.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:53:00.550: INFO: namespace projected-1375 deletion completed in 6.158036012s

• [SLOW TEST:8.228 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:53:00.550: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:53:02.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2618" for this suite.
Apr  6 22:53:46.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:53:46.737: INFO: namespace kubelet-test-2618 deletion completed in 44.133890043s

• [SLOW TEST:46.187 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:53:46.738: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  6 22:53:47.101: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  6 22:53:50.118: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 22:53:50.121: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5180-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:53:51.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2473" for this suite.
Apr  6 22:53:57.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:53:57.365: INFO: namespace webhook-2473 deletion completed in 6.08298013s
STEP: Destroying namespace "webhook-2473-markers" for this suite.
Apr  6 22:54:03.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:54:03.443: INFO: namespace webhook-2473-markers deletion completed in 6.078386807s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.715 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:54:03.453: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Apr  6 22:54:03.476: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 create -f - --namespace=kubectl-4124'
Apr  6 22:54:03.675: INFO: stderr: ""
Apr  6 22:54:03.675: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  6 22:54:03.676: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4124'
Apr  6 22:54:03.748: INFO: stderr: ""
Apr  6 22:54:03.748: INFO: stdout: "update-demo-nautilus-kmwv2 update-demo-nautilus-l5zr7 "
Apr  6 22:54:03.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-kmwv2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4124'
Apr  6 22:54:03.819: INFO: stderr: ""
Apr  6 22:54:03.819: INFO: stdout: ""
Apr  6 22:54:03.819: INFO: update-demo-nautilus-kmwv2 is created but not running
Apr  6 22:54:08.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4124'
Apr  6 22:54:08.892: INFO: stderr: ""
Apr  6 22:54:08.892: INFO: stdout: "update-demo-nautilus-kmwv2 update-demo-nautilus-l5zr7 "
Apr  6 22:54:08.892: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-kmwv2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4124'
Apr  6 22:54:08.962: INFO: stderr: ""
Apr  6 22:54:08.962: INFO: stdout: "true"
Apr  6 22:54:08.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-kmwv2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4124'
Apr  6 22:54:09.031: INFO: stderr: ""
Apr  6 22:54:09.031: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  6 22:54:09.031: INFO: validating pod update-demo-nautilus-kmwv2
Apr  6 22:54:09.036: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  6 22:54:09.036: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  6 22:54:09.036: INFO: update-demo-nautilus-kmwv2 is verified up and running
Apr  6 22:54:09.036: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-l5zr7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4124'
Apr  6 22:54:09.107: INFO: stderr: ""
Apr  6 22:54:09.107: INFO: stdout: "true"
Apr  6 22:54:09.107: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-l5zr7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4124'
Apr  6 22:54:09.176: INFO: stderr: ""
Apr  6 22:54:09.176: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  6 22:54:09.176: INFO: validating pod update-demo-nautilus-l5zr7
Apr  6 22:54:09.181: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  6 22:54:09.181: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  6 22:54:09.181: INFO: update-demo-nautilus-l5zr7 is verified up and running
STEP: rolling-update to new replication controller
Apr  6 22:54:09.183: INFO: scanned /root for discovery docs: <nil>
Apr  6 22:54:09.183: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-4124'
Apr  6 22:54:31.485: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr  6 22:54:31.486: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  6 22:54:31.486: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4124'
Apr  6 22:54:31.556: INFO: stderr: ""
Apr  6 22:54:31.556: INFO: stdout: "update-demo-kitten-7dcjq update-demo-kitten-whlf7 "
Apr  6 22:54:31.556: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-kitten-7dcjq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4124'
Apr  6 22:54:31.629: INFO: stderr: ""
Apr  6 22:54:31.629: INFO: stdout: "true"
Apr  6 22:54:31.629: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-kitten-7dcjq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4124'
Apr  6 22:54:31.701: INFO: stderr: ""
Apr  6 22:54:31.701: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr  6 22:54:31.701: INFO: validating pod update-demo-kitten-7dcjq
Apr  6 22:54:31.705: INFO: got data: {
  "image": "kitten.jpg"
}

Apr  6 22:54:31.705: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr  6 22:54:31.705: INFO: update-demo-kitten-7dcjq is verified up and running
Apr  6 22:54:31.705: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-kitten-whlf7 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4124'
Apr  6 22:54:31.773: INFO: stderr: ""
Apr  6 22:54:31.773: INFO: stdout: "true"
Apr  6 22:54:31.773: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-kitten-whlf7 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4124'
Apr  6 22:54:31.844: INFO: stderr: ""
Apr  6 22:54:31.844: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Apr  6 22:54:31.844: INFO: validating pod update-demo-kitten-whlf7
Apr  6 22:54:31.848: INFO: got data: {
  "image": "kitten.jpg"
}

Apr  6 22:54:31.848: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Apr  6 22:54:31.848: INFO: update-demo-kitten-whlf7 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:54:31.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4124" for this suite.
Apr  6 22:54:43.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:54:43.942: INFO: namespace kubectl-4124 deletion completed in 12.090652867s

• [SLOW TEST:40.489 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:54:43.942: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename daemonsets
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Apr  6 22:54:43.999: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:54:44.002: INFO: Number of nodes with available pods: 0
Apr  6 22:54:44.002: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:54:45.007: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:54:45.011: INFO: Number of nodes with available pods: 0
Apr  6 22:54:45.011: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:54:46.006: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:54:46.010: INFO: Number of nodes with available pods: 1
Apr  6 22:54:46.010: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:54:47.007: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:54:47.010: INFO: Number of nodes with available pods: 3
Apr  6 22:54:47.010: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Apr  6 22:54:47.024: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:54:47.027: INFO: Number of nodes with available pods: 2
Apr  6 22:54:47.027: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:54:48.031: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:54:48.034: INFO: Number of nodes with available pods: 2
Apr  6 22:54:48.034: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:54:49.032: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:54:49.035: INFO: Number of nodes with available pods: 2
Apr  6 22:54:49.035: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:54:50.032: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:54:50.035: INFO: Number of nodes with available pods: 2
Apr  6 22:54:50.035: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:54:51.034: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:54:51.036: INFO: Number of nodes with available pods: 2
Apr  6 22:54:51.036: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:54:52.032: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:54:52.035: INFO: Number of nodes with available pods: 2
Apr  6 22:54:52.035: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:54:53.031: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:54:53.035: INFO: Number of nodes with available pods: 2
Apr  6 22:54:53.035: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:54:54.032: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:54:54.034: INFO: Number of nodes with available pods: 2
Apr  6 22:54:54.034: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:54:55.032: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:54:55.035: INFO: Number of nodes with available pods: 2
Apr  6 22:54:55.035: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:54:56.031: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:54:56.034: INFO: Number of nodes with available pods: 2
Apr  6 22:54:56.034: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:54:57.031: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:54:57.035: INFO: Number of nodes with available pods: 2
Apr  6 22:54:57.035: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:54:58.031: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:54:58.034: INFO: Number of nodes with available pods: 2
Apr  6 22:54:58.034: INFO: Node 10.0.0.42 is running more than one daemon pod
Apr  6 22:54:59.032: INFO: DaemonSet pods can't tolerate node 10.0.0.41 with taints [{Key:node-role.kubernetes.io/master Value:true Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Apr  6 22:54:59.038: INFO: Number of nodes with available pods: 3
Apr  6 22:54:59.038: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8943, will wait for the garbage collector to delete the pods
Apr  6 22:54:59.098: INFO: Deleting DaemonSet.extensions daemon-set took: 5.446021ms
Apr  6 22:54:59.699: INFO: Terminating DaemonSet.extensions daemon-set pods took: 600.256066ms
Apr  6 22:55:09.901: INFO: Number of nodes with available pods: 0
Apr  6 22:55:09.901: INFO: Number of running nodes: 0, number of available pods: 0
Apr  6 22:55:09.903: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8943/daemonsets","resourceVersion":"16644"},"items":null}

Apr  6 22:55:09.905: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8943/pods","resourceVersion":"16644"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:55:09.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8943" for this suite.
Apr  6 22:55:15.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:55:15.994: INFO: namespace daemonsets-8943 deletion completed in 6.076164459s

• [SLOW TEST:32.052 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:55:15.995: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-88940320-8a47-4af9-b588-2249ed56a6b4
STEP: Creating a pod to test consume configMaps
Apr  6 22:55:16.024: INFO: Waiting up to 5m0s for pod "pod-configmaps-ac5b2af3-c261-4861-815a-0da79a138e94" in namespace "configmap-5777" to be "success or failure"
Apr  6 22:55:16.028: INFO: Pod "pod-configmaps-ac5b2af3-c261-4861-815a-0da79a138e94": Phase="Pending", Reason="", readiness=false. Elapsed: 3.216337ms
Apr  6 22:55:18.030: INFO: Pod "pod-configmaps-ac5b2af3-c261-4861-815a-0da79a138e94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005775005s
STEP: Saw pod success
Apr  6 22:55:18.030: INFO: Pod "pod-configmaps-ac5b2af3-c261-4861-815a-0da79a138e94" satisfied condition "success or failure"
Apr  6 22:55:18.032: INFO: Trying to get logs from node 10.0.0.44 pod pod-configmaps-ac5b2af3-c261-4861-815a-0da79a138e94 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  6 22:55:18.055: INFO: Waiting for pod pod-configmaps-ac5b2af3-c261-4861-815a-0da79a138e94 to disappear
Apr  6 22:55:18.058: INFO: Pod pod-configmaps-ac5b2af3-c261-4861-815a-0da79a138e94 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:55:18.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5777" for this suite.
Apr  6 22:55:24.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:55:24.136: INFO: namespace configmap-5777 deletion completed in 6.074882624s

• [SLOW TEST:8.141 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:55:24.136: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-5295
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  6 22:55:24.158: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  6 22:55:50.217: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.20.14.72 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5295 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 22:55:50.217: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 22:55:51.340: INFO: Found all expected endpoints: [netserver-0]
Apr  6 22:55:51.342: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.20.16.82 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5295 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 22:55:51.342: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 22:55:52.472: INFO: Found all expected endpoints: [netserver-1]
Apr  6 22:55:52.475: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.20.8.78 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5295 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 22:55:52.475: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 22:55:53.618: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:55:53.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5295" for this suite.
Apr  6 22:56:05.631: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:56:05.836: INFO: namespace pod-network-test-5295 deletion completed in 12.213185137s

• [SLOW TEST:41.700 seconds]
[sig-network] Networking
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:56:05.836: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-9984/configmap-test-adde502c-87b0-4415-b155-0bd09304e7a6
STEP: Creating a pod to test consume configMaps
Apr  6 22:56:05.868: INFO: Waiting up to 5m0s for pod "pod-configmaps-c02bef03-6fee-48de-af56-35a67408209c" in namespace "configmap-9984" to be "success or failure"
Apr  6 22:56:05.874: INFO: Pod "pod-configmaps-c02bef03-6fee-48de-af56-35a67408209c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.032197ms
Apr  6 22:56:07.877: INFO: Pod "pod-configmaps-c02bef03-6fee-48de-af56-35a67408209c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009361858s
STEP: Saw pod success
Apr  6 22:56:07.877: INFO: Pod "pod-configmaps-c02bef03-6fee-48de-af56-35a67408209c" satisfied condition "success or failure"
Apr  6 22:56:07.880: INFO: Trying to get logs from node 10.0.0.42 pod pod-configmaps-c02bef03-6fee-48de-af56-35a67408209c container env-test: <nil>
STEP: delete the pod
Apr  6 22:56:07.896: INFO: Waiting for pod pod-configmaps-c02bef03-6fee-48de-af56-35a67408209c to disappear
Apr  6 22:56:07.898: INFO: Pod pod-configmaps-c02bef03-6fee-48de-af56-35a67408209c no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:56:07.898: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9984" for this suite.
Apr  6 22:56:13.912: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:56:13.986: INFO: namespace configmap-9984 deletion completed in 6.083528966s

• [SLOW TEST:8.150 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:56:13.986: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  6 22:56:14.393: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr  6 22:56:16.401: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721810574, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721810574, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721810574, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721810574, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  6 22:56:19.411: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 22:56:19.414: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4024-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:56:20.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3062" for this suite.
Apr  6 22:56:26.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:56:26.629: INFO: namespace webhook-3062 deletion completed in 6.139820361s
STEP: Destroying namespace "webhook-3062-markers" for this suite.
Apr  6 22:56:32.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:56:32.710: INFO: namespace webhook-3062-markers deletion completed in 6.080142976s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.734 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:56:32.720: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Apr  6 22:56:32.759: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7932 /api/v1/namespaces/watch-7932/configmaps/e2e-watch-test-resource-version ea3865dc-0bd1-40e5-b9b6-55dd5ef309b6 17091 0 2020-04-06 22:56:32 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  6 22:56:32.759: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-7932 /api/v1/namespaces/watch-7932/configmaps/e2e-watch-test-resource-version ea3865dc-0bd1-40e5-b9b6-55dd5ef309b6 17092 0 2020-04-06 22:56:32 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:56:32.760: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7932" for this suite.
Apr  6 22:56:38.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:56:38.929: INFO: namespace watch-7932 deletion completed in 6.166247663s

• [SLOW TEST:6.209 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:56:38.929: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-91b6e302-f997-445e-ab96-4e00a1ad559b
STEP: Creating a pod to test consume configMaps
Apr  6 22:56:38.957: INFO: Waiting up to 5m0s for pod "pod-configmaps-c43ef1db-4754-4892-97ae-73d48c7d9e70" in namespace "configmap-706" to be "success or failure"
Apr  6 22:56:38.959: INFO: Pod "pod-configmaps-c43ef1db-4754-4892-97ae-73d48c7d9e70": Phase="Pending", Reason="", readiness=false. Elapsed: 2.304333ms
Apr  6 22:56:40.962: INFO: Pod "pod-configmaps-c43ef1db-4754-4892-97ae-73d48c7d9e70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005522307s
STEP: Saw pod success
Apr  6 22:56:40.962: INFO: Pod "pod-configmaps-c43ef1db-4754-4892-97ae-73d48c7d9e70" satisfied condition "success or failure"
Apr  6 22:56:40.964: INFO: Trying to get logs from node 10.0.0.42 pod pod-configmaps-c43ef1db-4754-4892-97ae-73d48c7d9e70 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  6 22:56:40.983: INFO: Waiting for pod pod-configmaps-c43ef1db-4754-4892-97ae-73d48c7d9e70 to disappear
Apr  6 22:56:40.985: INFO: Pod pod-configmaps-c43ef1db-4754-4892-97ae-73d48c7d9e70 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:56:40.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-706" for this suite.
Apr  6 22:56:46.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:56:47.070: INFO: namespace configmap-706 deletion completed in 6.080894035s

• [SLOW TEST:8.141 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:56:47.070: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Apr  6 22:56:51.612: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1943 pod-service-account-00840508-d364-47e9-8564-e3f7e7326fd0 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Apr  6 22:56:51.835: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1943 pod-service-account-00840508-d364-47e9-8564-e3f7e7326fd0 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Apr  6 22:56:52.049: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-1943 pod-service-account-00840508-d364-47e9-8564-e3f7e7326fd0 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:56:52.257: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1943" for this suite.
Apr  6 22:56:58.272: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:56:58.339: INFO: namespace svcaccounts-1943 deletion completed in 6.077384507s

• [SLOW TEST:11.268 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:56:58.339: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Apr  6 22:56:58.360: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Apr  6 22:57:09.226: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 22:57:12.020: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:57:21.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7109" for this suite.
Apr  6 22:57:27.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:57:27.154: INFO: namespace crd-publish-openapi-7109 deletion completed in 6.089672453s

• [SLOW TEST:28.815 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:57:27.154: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-3605
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-3605
STEP: creating replication controller externalsvc in namespace services-3605
I0406 22:57:27.199440      23 runners.go:184] Created replication controller with name: externalsvc, namespace: services-3605, replica count: 2
I0406 22:57:30.249948      23 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Apr  6 22:57:30.261: INFO: Creating new exec pod
Apr  6 22:57:32.271: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=services-3605 execpodf2kdk -- /bin/sh -x -c nslookup clusterip-service'
Apr  6 22:57:32.489: INFO: stderr: "+ nslookup clusterip-service\n"
Apr  6 22:57:32.489: INFO: stdout: "Server:\t\t10.21.0.10\nAddress:\t10.21.0.10#53\n\nclusterip-service.services-3605.svc.cluster.local\tcanonical name = externalsvc.services-3605.svc.cluster.local.\nName:\texternalsvc.services-3605.svc.cluster.local\nAddress: 10.21.186.93\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-3605, will wait for the garbage collector to delete the pods
Apr  6 22:57:32.547: INFO: Deleting ReplicationController externalsvc took: 5.123488ms
Apr  6 22:57:33.147: INFO: Terminating ReplicationController externalsvc pods took: 600.297554ms
Apr  6 22:57:46.362: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:57:46.377: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3605" for this suite.
Apr  6 22:57:52.390: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:57:52.526: INFO: namespace services-3605 deletion completed in 6.145008444s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:25.372 seconds]
[sig-network] Services
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:57:52.526: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:58:08.609: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8245" for this suite.
Apr  6 22:58:14.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:58:14.693: INFO: namespace resourcequota-8245 deletion completed in 6.080617443s

• [SLOW TEST:22.168 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:58:14.694: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr  6 22:58:14.719: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2172d751-8d06-494b-ac99-d739c9ba13dd" in namespace "projected-969" to be "success or failure"
Apr  6 22:58:14.723: INFO: Pod "downwardapi-volume-2172d751-8d06-494b-ac99-d739c9ba13dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.991019ms
Apr  6 22:58:16.726: INFO: Pod "downwardapi-volume-2172d751-8d06-494b-ac99-d739c9ba13dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006832322s
Apr  6 22:58:18.729: INFO: Pod "downwardapi-volume-2172d751-8d06-494b-ac99-d739c9ba13dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009780814s
STEP: Saw pod success
Apr  6 22:58:18.730: INFO: Pod "downwardapi-volume-2172d751-8d06-494b-ac99-d739c9ba13dd" satisfied condition "success or failure"
Apr  6 22:58:18.732: INFO: Trying to get logs from node 10.0.0.43 pod downwardapi-volume-2172d751-8d06-494b-ac99-d739c9ba13dd container client-container: <nil>
STEP: delete the pod
Apr  6 22:58:18.756: INFO: Waiting for pod downwardapi-volume-2172d751-8d06-494b-ac99-d739c9ba13dd to disappear
Apr  6 22:58:18.759: INFO: Pod downwardapi-volume-2172d751-8d06-494b-ac99-d739c9ba13dd no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:58:18.759: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-969" for this suite.
Apr  6 22:58:24.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:58:24.844: INFO: namespace projected-969 deletion completed in 6.081519543s

• [SLOW TEST:10.151 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:58:24.844: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-810
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-810 to expose endpoints map[]
Apr  6 22:58:24.879: INFO: successfully validated that service endpoint-test2 in namespace services-810 exposes endpoints map[] (5.390341ms elapsed)
STEP: Creating pod pod1 in namespace services-810
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-810 to expose endpoints map[pod1:[80]]
Apr  6 22:58:26.898: INFO: successfully validated that service endpoint-test2 in namespace services-810 exposes endpoints map[pod1:[80]] (2.01464366s elapsed)
STEP: Creating pod pod2 in namespace services-810
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-810 to expose endpoints map[pod1:[80] pod2:[80]]
Apr  6 22:58:28.923: INFO: successfully validated that service endpoint-test2 in namespace services-810 exposes endpoints map[pod1:[80] pod2:[80]] (2.021904367s elapsed)
STEP: Deleting pod pod1 in namespace services-810
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-810 to expose endpoints map[pod2:[80]]
Apr  6 22:58:29.937: INFO: successfully validated that service endpoint-test2 in namespace services-810 exposes endpoints map[pod2:[80]] (1.009929797s elapsed)
STEP: Deleting pod pod2 in namespace services-810
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-810 to expose endpoints map[]
Apr  6 22:58:30.945: INFO: successfully validated that service endpoint-test2 in namespace services-810 exposes endpoints map[] (1.004367976s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:58:30.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-810" for this suite.
Apr  6 22:58:36.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:58:37.051: INFO: namespace services-810 deletion completed in 6.084686191s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:12.206 seconds]
[sig-network] Services
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:58:37.051: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Apr  6 22:58:40.603: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W0406 22:58:40.603427      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  6 22:58:40.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-5383" for this suite.
Apr  6 22:58:46.615: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:58:46.685: INFO: namespace gc-5383 deletion completed in 6.079263576s

• [SLOW TEST:9.635 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:58:46.686: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Apr  6 22:58:46.715: INFO: Waiting up to 5m0s for pod "var-expansion-838ff95b-e208-436f-bc56-dd7ab3467d31" in namespace "var-expansion-770" to be "success or failure"
Apr  6 22:58:46.717: INFO: Pod "var-expansion-838ff95b-e208-436f-bc56-dd7ab3467d31": Phase="Pending", Reason="", readiness=false. Elapsed: 2.055041ms
Apr  6 22:58:48.721: INFO: Pod "var-expansion-838ff95b-e208-436f-bc56-dd7ab3467d31": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005431178s
STEP: Saw pod success
Apr  6 22:58:48.721: INFO: Pod "var-expansion-838ff95b-e208-436f-bc56-dd7ab3467d31" satisfied condition "success or failure"
Apr  6 22:58:48.723: INFO: Trying to get logs from node 10.0.0.44 pod var-expansion-838ff95b-e208-436f-bc56-dd7ab3467d31 container dapi-container: <nil>
STEP: delete the pod
Apr  6 22:58:48.745: INFO: Waiting for pod var-expansion-838ff95b-e208-436f-bc56-dd7ab3467d31 to disappear
Apr  6 22:58:48.752: INFO: Pod var-expansion-838ff95b-e208-436f-bc56-dd7ab3467d31 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:58:48.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-770" for this suite.
Apr  6 22:58:54.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:58:54.930: INFO: namespace var-expansion-770 deletion completed in 6.174936873s

• [SLOW TEST:8.244 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:58:54.930: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  6 22:58:55.344: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr  6 22:58:57.352: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721810735, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721810735, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721810735, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721810735, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  6 22:59:00.361: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:59:00.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9202" for this suite.
Apr  6 22:59:12.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:59:12.481: INFO: namespace webhook-9202 deletion completed in 12.080624798s
STEP: Destroying namespace "webhook-9202-markers" for this suite.
Apr  6 22:59:18.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:59:18.628: INFO: namespace webhook-9202-markers deletion completed in 6.146894208s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:23.708 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:59:18.639: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Apr  6 22:59:18.662: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 22:59:21.448: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:59:32.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3600" for this suite.
Apr  6 22:59:38.416: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 22:59:38.490: INFO: namespace crd-publish-openapi-3600 deletion completed in 6.082924605s

• [SLOW TEST:19.851 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 22:59:38.490: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 22:59:54.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8476" for this suite.
Apr  6 23:00:00.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:00:00.630: INFO: namespace resourcequota-8476 deletion completed in 6.080937528s

• [SLOW TEST:22.140 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:00:00.631: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr  6 23:00:00.651: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-5024'
Apr  6 23:00:00.980: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr  6 23:00:00.980: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: rolling-update to same image controller
Apr  6 23:00:00.988: INFO: scanned /root for discovery docs: <nil>
Apr  6 23:00:00.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-5024'
Apr  6 23:00:16.734: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Apr  6 23:00:16.734: INFO: stdout: "Created e2e-test-httpd-rc-b6ce6bc812da418e6dee3e8ba7235a8f\nScaling up e2e-test-httpd-rc-b6ce6bc812da418e6dee3e8ba7235a8f from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-b6ce6bc812da418e6dee3e8ba7235a8f up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-b6ce6bc812da418e6dee3e8ba7235a8f to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Apr  6 23:00:16.734: INFO: stdout: "Created e2e-test-httpd-rc-b6ce6bc812da418e6dee3e8ba7235a8f\nScaling up e2e-test-httpd-rc-b6ce6bc812da418e6dee3e8ba7235a8f from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-b6ce6bc812da418e6dee3e8ba7235a8f up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-b6ce6bc812da418e6dee3e8ba7235a8f to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Apr  6 23:00:16.735: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-5024'
Apr  6 23:00:16.809: INFO: stderr: ""
Apr  6 23:00:16.809: INFO: stdout: "e2e-test-httpd-rc-b6ce6bc812da418e6dee3e8ba7235a8f-k9jm9 "
Apr  6 23:00:16.809: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods e2e-test-httpd-rc-b6ce6bc812da418e6dee3e8ba7235a8f-k9jm9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5024'
Apr  6 23:00:16.880: INFO: stderr: ""
Apr  6 23:00:16.880: INFO: stdout: "true"
Apr  6 23:00:16.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods e2e-test-httpd-rc-b6ce6bc812da418e6dee3e8ba7235a8f-k9jm9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5024'
Apr  6 23:00:16.952: INFO: stderr: ""
Apr  6 23:00:16.952: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Apr  6 23:00:16.952: INFO: e2e-test-httpd-rc-b6ce6bc812da418e6dee3e8ba7235a8f-k9jm9 is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Apr  6 23:00:16.952: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 delete rc e2e-test-httpd-rc --namespace=kubectl-5024'
Apr  6 23:00:17.043: INFO: stderr: ""
Apr  6 23:00:17.043: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:00:17.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5024" for this suite.
Apr  6 23:00:23.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:00:23.125: INFO: namespace kubectl-5024 deletion completed in 6.077371791s

• [SLOW TEST:22.494 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:00:23.125: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-3146
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-3146
I0406 23:00:23.163625      23 runners.go:184] Created replication controller with name: externalname-service, namespace: services-3146, replica count: 2
Apr  6 23:00:26.214: INFO: Creating new exec pod
I0406 23:00:26.214277      23 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  6 23:00:29.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=services-3146 execpodc8dgz -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Apr  6 23:00:29.430: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Apr  6 23:00:29.430: INFO: stdout: ""
Apr  6 23:00:29.431: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=services-3146 execpodc8dgz -- /bin/sh -x -c nc -zv -t -w 2 10.21.136.72 80'
Apr  6 23:00:29.625: INFO: stderr: "+ nc -zv -t -w 2 10.21.136.72 80\nConnection to 10.21.136.72 80 port [tcp/http] succeeded!\n"
Apr  6 23:00:29.625: INFO: stdout: ""
Apr  6 23:00:29.625: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:00:29.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3146" for this suite.
Apr  6 23:00:35.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:00:35.729: INFO: namespace services-3146 deletion completed in 6.08022857s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:12.603 seconds]
[sig-network] Services
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:00:35.729: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-0e902603-da84-472d-86e1-8df5acf53540
STEP: Creating a pod to test consume configMaps
Apr  6 23:00:35.754: INFO: Waiting up to 5m0s for pod "pod-configmaps-46c2cfb0-5a25-45cf-8cc2-24fdb6ffca6f" in namespace "configmap-4440" to be "success or failure"
Apr  6 23:00:35.756: INFO: Pod "pod-configmaps-46c2cfb0-5a25-45cf-8cc2-24fdb6ffca6f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.394702ms
Apr  6 23:00:37.760: INFO: Pod "pod-configmaps-46c2cfb0-5a25-45cf-8cc2-24fdb6ffca6f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005593838s
STEP: Saw pod success
Apr  6 23:00:37.760: INFO: Pod "pod-configmaps-46c2cfb0-5a25-45cf-8cc2-24fdb6ffca6f" satisfied condition "success or failure"
Apr  6 23:00:37.762: INFO: Trying to get logs from node 10.0.0.44 pod pod-configmaps-46c2cfb0-5a25-45cf-8cc2-24fdb6ffca6f container configmap-volume-test: <nil>
STEP: delete the pod
Apr  6 23:00:37.788: INFO: Waiting for pod pod-configmaps-46c2cfb0-5a25-45cf-8cc2-24fdb6ffca6f to disappear
Apr  6 23:00:37.790: INFO: Pod pod-configmaps-46c2cfb0-5a25-45cf-8cc2-24fdb6ffca6f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:00:37.790: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4440" for this suite.
Apr  6 23:00:43.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:00:43.878: INFO: namespace configmap-4440 deletion completed in 6.083790482s

• [SLOW TEST:8.149 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:00:43.878: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-764c5ee5-aa97-40bf-9dad-93bfa93d4f5d
STEP: Creating a pod to test consume secrets
Apr  6 23:00:43.904: INFO: Waiting up to 5m0s for pod "pod-secrets-ff546999-fba9-47e8-aaa4-39f32c8bc620" in namespace "secrets-132" to be "success or failure"
Apr  6 23:00:43.907: INFO: Pod "pod-secrets-ff546999-fba9-47e8-aaa4-39f32c8bc620": Phase="Pending", Reason="", readiness=false. Elapsed: 2.576555ms
Apr  6 23:00:45.914: INFO: Pod "pod-secrets-ff546999-fba9-47e8-aaa4-39f32c8bc620": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009389845s
STEP: Saw pod success
Apr  6 23:00:45.914: INFO: Pod "pod-secrets-ff546999-fba9-47e8-aaa4-39f32c8bc620" satisfied condition "success or failure"
Apr  6 23:00:45.916: INFO: Trying to get logs from node 10.0.0.43 pod pod-secrets-ff546999-fba9-47e8-aaa4-39f32c8bc620 container secret-volume-test: <nil>
STEP: delete the pod
Apr  6 23:00:45.941: INFO: Waiting for pod pod-secrets-ff546999-fba9-47e8-aaa4-39f32c8bc620 to disappear
Apr  6 23:00:45.945: INFO: Pod pod-secrets-ff546999-fba9-47e8-aaa4-39f32c8bc620 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:00:45.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-132" for this suite.
Apr  6 23:00:51.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:00:52.025: INFO: namespace secrets-132 deletion completed in 6.076342145s

• [SLOW TEST:8.147 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:00:52.025: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Apr  6 23:00:52.053: INFO: Waiting up to 5m0s for pod "pod-32e211a2-f75a-4e07-b91e-4e0b811150cf" in namespace "emptydir-9753" to be "success or failure"
Apr  6 23:00:52.055: INFO: Pod "pod-32e211a2-f75a-4e07-b91e-4e0b811150cf": Phase="Pending", Reason="", readiness=false. Elapsed: 1.926458ms
Apr  6 23:00:54.057: INFO: Pod "pod-32e211a2-f75a-4e07-b91e-4e0b811150cf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004806292s
STEP: Saw pod success
Apr  6 23:00:54.057: INFO: Pod "pod-32e211a2-f75a-4e07-b91e-4e0b811150cf" satisfied condition "success or failure"
Apr  6 23:00:54.060: INFO: Trying to get logs from node 10.0.0.42 pod pod-32e211a2-f75a-4e07-b91e-4e0b811150cf container test-container: <nil>
STEP: delete the pod
Apr  6 23:00:54.081: INFO: Waiting for pod pod-32e211a2-f75a-4e07-b91e-4e0b811150cf to disappear
Apr  6 23:00:54.083: INFO: Pod pod-32e211a2-f75a-4e07-b91e-4e0b811150cf no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:00:54.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9753" for this suite.
Apr  6 23:01:00.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:01:00.166: INFO: namespace emptydir-9753 deletion completed in 6.079174412s

• [SLOW TEST:8.141 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:01:00.166: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename crd-watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 23:01:00.187: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Creating first CR 
Apr  6 23:01:00.797: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-06T23:01:00Z generation:1 name:name1 resourceVersion:18439 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:3361674f-5d42-47ae-9aa9-bc0409baba50] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Apr  6 23:01:10.801: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-06T23:01:10Z generation:1 name:name2 resourceVersion:18465 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:c69065b7-bcb0-4f1a-91de-fe3dd5da4cd0] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Apr  6 23:01:20.805: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-06T23:01:00Z generation:2 name:name1 resourceVersion:18489 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:3361674f-5d42-47ae-9aa9-bc0409baba50] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Apr  6 23:01:30.808: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-06T23:01:10Z generation:2 name:name2 resourceVersion:18506 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:c69065b7-bcb0-4f1a-91de-fe3dd5da4cd0] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Apr  6 23:01:40.814: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-06T23:01:00Z generation:2 name:name1 resourceVersion:18524 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:3361674f-5d42-47ae-9aa9-bc0409baba50] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Apr  6 23:01:50.820: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2020-04-06T23:01:10Z generation:2 name:name2 resourceVersion:18540 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:c69065b7-bcb0-4f1a-91de-fe3dd5da4cd0] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:02:01.328: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-725" for this suite.
Apr  6 23:02:07.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:02:07.435: INFO: namespace crd-watch-725 deletion completed in 6.10331623s

• [SLOW TEST:67.269 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:02:07.436: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:02:14.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6240" for this suite.
Apr  6 23:02:20.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:02:20.555: INFO: namespace resourcequota-6240 deletion completed in 6.08636216s

• [SLOW TEST:13.119 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:02:20.555: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-8011
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8011 to expose endpoints map[]
Apr  6 23:02:20.589: INFO: successfully validated that service multi-endpoint-test in namespace services-8011 exposes endpoints map[] (3.976157ms elapsed)
STEP: Creating pod pod1 in namespace services-8011
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8011 to expose endpoints map[pod1:[100]]
Apr  6 23:02:21.606: INFO: successfully validated that service multi-endpoint-test in namespace services-8011 exposes endpoints map[pod1:[100]] (1.011612132s elapsed)
STEP: Creating pod pod2 in namespace services-8011
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8011 to expose endpoints map[pod1:[100] pod2:[101]]
Apr  6 23:02:23.631: INFO: successfully validated that service multi-endpoint-test in namespace services-8011 exposes endpoints map[pod1:[100] pod2:[101]] (2.021536476s elapsed)
STEP: Deleting pod pod1 in namespace services-8011
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8011 to expose endpoints map[pod2:[101]]
Apr  6 23:02:24.647: INFO: successfully validated that service multi-endpoint-test in namespace services-8011 exposes endpoints map[pod2:[101]] (1.012105874s elapsed)
STEP: Deleting pod pod2 in namespace services-8011
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-8011 to expose endpoints map[]
Apr  6 23:02:25.655: INFO: successfully validated that service multi-endpoint-test in namespace services-8011 exposes endpoints map[] (1.004121657s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:02:25.670: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8011" for this suite.
Apr  6 23:02:37.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:02:37.749: INFO: namespace services-8011 deletion completed in 12.075285664s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:17.194 seconds]
[sig-network] Services
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:02:37.749: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr  6 23:02:37.772: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2774fe45-67de-452c-9dc5-084c43224142" in namespace "downward-api-7098" to be "success or failure"
Apr  6 23:02:37.774: INFO: Pod "downwardapi-volume-2774fe45-67de-452c-9dc5-084c43224142": Phase="Pending", Reason="", readiness=false. Elapsed: 1.956163ms
Apr  6 23:02:39.777: INFO: Pod "downwardapi-volume-2774fe45-67de-452c-9dc5-084c43224142": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004590568s
STEP: Saw pod success
Apr  6 23:02:39.777: INFO: Pod "downwardapi-volume-2774fe45-67de-452c-9dc5-084c43224142" satisfied condition "success or failure"
Apr  6 23:02:39.782: INFO: Trying to get logs from node 10.0.0.42 pod downwardapi-volume-2774fe45-67de-452c-9dc5-084c43224142 container client-container: <nil>
STEP: delete the pod
Apr  6 23:02:39.805: INFO: Waiting for pod downwardapi-volume-2774fe45-67de-452c-9dc5-084c43224142 to disappear
Apr  6 23:02:39.807: INFO: Pod downwardapi-volume-2774fe45-67de-452c-9dc5-084c43224142 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:02:39.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7098" for this suite.
Apr  6 23:02:45.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:02:45.885: INFO: namespace downward-api-7098 deletion completed in 6.073588955s

• [SLOW TEST:8.136 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:02:45.885: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-1a0ef870-54e4-4dbb-85c6-3924bfe249e3
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-1a0ef870-54e4-4dbb-85c6-3924bfe249e3
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:02:49.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8578" for this suite.
Apr  6 23:03:01.988: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:03:02.127: INFO: namespace configmap-8578 deletion completed in 12.147041549s

• [SLOW TEST:16.242 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:03:02.127: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr  6 23:03:02.156: INFO: Waiting up to 5m0s for pod "downwardapi-volume-75a741ed-7309-4038-a640-30cbb18e64d6" in namespace "projected-6671" to be "success or failure"
Apr  6 23:03:02.161: INFO: Pod "downwardapi-volume-75a741ed-7309-4038-a640-30cbb18e64d6": Phase="Pending", Reason="", readiness=false. Elapsed: 5.316787ms
Apr  6 23:03:04.164: INFO: Pod "downwardapi-volume-75a741ed-7309-4038-a640-30cbb18e64d6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.008302884s
Apr  6 23:03:06.167: INFO: Pod "downwardapi-volume-75a741ed-7309-4038-a640-30cbb18e64d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011560844s
STEP: Saw pod success
Apr  6 23:03:06.167: INFO: Pod "downwardapi-volume-75a741ed-7309-4038-a640-30cbb18e64d6" satisfied condition "success or failure"
Apr  6 23:03:06.169: INFO: Trying to get logs from node 10.0.0.42 pod downwardapi-volume-75a741ed-7309-4038-a640-30cbb18e64d6 container client-container: <nil>
STEP: delete the pod
Apr  6 23:03:06.184: INFO: Waiting for pod downwardapi-volume-75a741ed-7309-4038-a640-30cbb18e64d6 to disappear
Apr  6 23:03:06.187: INFO: Pod downwardapi-volume-75a741ed-7309-4038-a640-30cbb18e64d6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:03:06.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6671" for this suite.
Apr  6 23:03:12.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:03:12.269: INFO: namespace projected-6671 deletion completed in 6.078105802s

• [SLOW TEST:10.142 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:03:12.269: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Apr  6 23:03:12.289: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  6 23:03:12.301: INFO: Waiting for terminating namespaces to be deleted...
Apr  6 23:03:12.303: INFO: 
Logging pods the kubelet thinks is on node 10.0.0.42 before test
Apr  6 23:03:12.308: INFO: sonobuoy-systemd-logs-daemon-set-3f2ae32d33c24b28-z5vfz from sonobuoy started at 2020-04-06 21:55:15 +0000 UTC (2 container statuses recorded)
Apr  6 23:03:12.308: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr  6 23:03:12.308: INFO: 	Container systemd-logs ready: true, restart count 0
Apr  6 23:03:12.308: INFO: prometheus-operator-546b677c-8nsvj from pf9-operators started at 2020-04-06 22:08:44 +0000 UTC (1 container statuses recorded)
Apr  6 23:03:12.308: INFO: 	Container prometheus-operator ready: true, restart count 0
Apr  6 23:03:12.308: INFO: comms-proxy-f9jz2 from pf9-monitoring started at 2020-04-06 22:08:48 +0000 UTC (1 container statuses recorded)
Apr  6 23:03:12.308: INFO: 	Container envoy ready: true, restart count 0
Apr  6 23:03:12.308: INFO: olm-operator-76d446f94c-rhq8h from pf9-olm started at 2020-04-06 21:53:11 +0000 UTC (1 container statuses recorded)
Apr  6 23:03:12.308: INFO: 	Container olm-operator ready: true, restart count 0
Apr  6 23:03:12.308: INFO: kube-state-metrics-595cb5cc-hkr95 from pf9-monitoring started at 2020-04-06 21:53:20 +0000 UTC (1 container statuses recorded)
Apr  6 23:03:12.308: INFO: 	Container kube-state-metrics ready: true, restart count 0
Apr  6 23:03:12.308: INFO: node-exporter-q8z8v from pf9-monitoring started at 2020-04-06 21:53:24 +0000 UTC (1 container statuses recorded)
Apr  6 23:03:12.308: INFO: 	Container node-exporter ready: true, restart count 0
Apr  6 23:03:12.308: INFO: sonobuoy from sonobuoy started at 2020-04-06 21:55:11 +0000 UTC (1 container statuses recorded)
Apr  6 23:03:12.308: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr  6 23:03:12.308: INFO: 
Logging pods the kubelet thinks is on node 10.0.0.43 before test
Apr  6 23:03:12.313: INFO: comms-proxy-gpw8d from pf9-monitoring started at 2020-04-06 22:08:48 +0000 UTC (1 container statuses recorded)
Apr  6 23:03:12.314: INFO: 	Container envoy ready: true, restart count 0
Apr  6 23:03:12.314: INFO: grafana-86dfdd45b7-78rmr from pf9-monitoring started at 2020-04-06 22:09:29 +0000 UTC (2 container statuses recorded)
Apr  6 23:03:12.314: INFO: 	Container grafana ready: true, restart count 0
Apr  6 23:03:12.314: INFO: 	Container proxy ready: true, restart count 0
Apr  6 23:03:12.314: INFO: prometheus-system-0 from pf9-monitoring started at 2020-04-06 22:09:29 +0000 UTC (3 container statuses recorded)
Apr  6 23:03:12.314: INFO: 	Container prometheus ready: true, restart count 1
Apr  6 23:03:12.314: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Apr  6 23:03:12.314: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Apr  6 23:03:12.314: INFO: sonobuoy-systemd-logs-daemon-set-3f2ae32d33c24b28-2j6sr from sonobuoy started at 2020-04-06 21:55:15 +0000 UTC (2 container statuses recorded)
Apr  6 23:03:12.314: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr  6 23:03:12.314: INFO: 	Container systemd-logs ready: true, restart count 0
Apr  6 23:03:12.314: INFO: packageserver-7799547bfb-ztvbk from pf9-olm started at 2020-04-06 21:53:29 +0000 UTC (1 container statuses recorded)
Apr  6 23:03:12.314: INFO: 	Container packageserver ready: true, restart count 0
Apr  6 23:03:12.314: INFO: catalog-operator-5898bbb7d6-86vpd from pf9-olm started at 2020-04-06 21:53:10 +0000 UTC (1 container statuses recorded)
Apr  6 23:03:12.314: INFO: 	Container catalog-operator ready: true, restart count 0
Apr  6 23:03:12.314: INFO: node-exporter-xl5fz from pf9-monitoring started at 2020-04-06 21:53:24 +0000 UTC (1 container statuses recorded)
Apr  6 23:03:12.314: INFO: 	Container node-exporter ready: true, restart count 0
Apr  6 23:03:12.314: INFO: 
Logging pods the kubelet thinks is on node 10.0.0.44 before test
Apr  6 23:03:12.327: INFO: packageserver-7799547bfb-5vjt4 from pf9-olm started at 2020-04-06 21:53:20 +0000 UTC (1 container statuses recorded)
Apr  6 23:03:12.327: INFO: 	Container packageserver ready: true, restart count 0
Apr  6 23:03:12.327: INFO: platform9-operators-z62nw from pf9-olm started at 2020-04-06 21:53:38 +0000 UTC (1 container statuses recorded)
Apr  6 23:03:12.327: INFO: 	Container registry-server ready: true, restart count 0
Apr  6 23:03:12.327: INFO: alertmanager-sysalert-0 from pf9-monitoring started at 2020-04-06 22:09:29 +0000 UTC (2 container statuses recorded)
Apr  6 23:03:12.327: INFO: 	Container alertmanager ready: true, restart count 0
Apr  6 23:03:12.327: INFO: 	Container config-reloader ready: true, restart count 0
Apr  6 23:03:12.327: INFO: sonobuoy-e2e-job-c807e2fec0184d0b from sonobuoy started at 2020-04-06 21:55:15 +0000 UTC (2 container statuses recorded)
Apr  6 23:03:12.327: INFO: 	Container e2e ready: true, restart count 0
Apr  6 23:03:12.327: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  6 23:03:12.327: INFO: sonobuoy-systemd-logs-daemon-set-3f2ae32d33c24b28-cst5h from sonobuoy started at 2020-04-06 21:55:15 +0000 UTC (2 container statuses recorded)
Apr  6 23:03:12.327: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr  6 23:03:12.327: INFO: 	Container systemd-logs ready: true, restart count 0
Apr  6 23:03:12.327: INFO: monhelper-666465d6b5-8t499 from pf9-operators started at 2020-04-06 22:08:44 +0000 UTC (1 container statuses recorded)
Apr  6 23:03:12.327: INFO: 	Container monhelper ready: true, restart count 0
Apr  6 23:03:12.327: INFO: comms-proxy-28brb from pf9-monitoring started at 2020-04-06 22:08:48 +0000 UTC (1 container statuses recorded)
Apr  6 23:03:12.327: INFO: 	Container envoy ready: true, restart count 0
Apr  6 23:03:12.327: INFO: node-exporter-w7m2g from pf9-monitoring started at 2020-04-06 21:53:24 +0000 UTC (1 container statuses recorded)
Apr  6 23:03:12.327: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.16035d67609e544f], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.16035d6760faeeb8], Reason = [FailedScheduling], Message = [0/4 nodes are available: 4 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:03:13.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2742" for this suite.
Apr  6 23:03:19.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:03:19.425: INFO: namespace sched-pred-2742 deletion completed in 6.071798257s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.156 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:03:19.426: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Apr  6 23:03:19.449: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 create -f - --namespace=kubectl-4248'
Apr  6 23:03:19.640: INFO: stderr: ""
Apr  6 23:03:19.640: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr  6 23:03:20.643: INFO: Selector matched 1 pods for map[app:redis]
Apr  6 23:03:20.643: INFO: Found 0 / 1
Apr  6 23:03:21.643: INFO: Selector matched 1 pods for map[app:redis]
Apr  6 23:03:21.643: INFO: Found 1 / 1
Apr  6 23:03:21.643: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Apr  6 23:03:21.646: INFO: Selector matched 1 pods for map[app:redis]
Apr  6 23:03:21.646: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr  6 23:03:21.646: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 patch pod redis-master-94rxx --namespace=kubectl-4248 -p {"metadata":{"annotations":{"x":"y"}}}'
Apr  6 23:03:21.716: INFO: stderr: ""
Apr  6 23:03:21.716: INFO: stdout: "pod/redis-master-94rxx patched\n"
STEP: checking annotations
Apr  6 23:03:21.719: INFO: Selector matched 1 pods for map[app:redis]
Apr  6 23:03:21.719: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:03:21.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4248" for this suite.
Apr  6 23:03:33.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:03:33.805: INFO: namespace kubectl-4248 deletion completed in 12.08351372s

• [SLOW TEST:14.380 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:03:33.806: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-efaa1442-11d1-4ee4-bb4b-5cd65b741ce5 in namespace container-probe-220
Apr  6 23:03:35.844: INFO: Started pod busybox-efaa1442-11d1-4ee4-bb4b-5cd65b741ce5 in namespace container-probe-220
STEP: checking the pod's current state and verifying that restartCount is present
Apr  6 23:03:35.847: INFO: Initial restart count of pod busybox-efaa1442-11d1-4ee4-bb4b-5cd65b741ce5 is 0
Apr  6 23:04:29.934: INFO: Restart count of pod container-probe-220/busybox-efaa1442-11d1-4ee4-bb4b-5cd65b741ce5 is now 1 (54.087294474s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:04:29.941: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-220" for this suite.
Apr  6 23:04:35.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:04:36.030: INFO: namespace container-probe-220 deletion completed in 6.08444278s

• [SLOW TEST:62.224 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:04:36.030: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Apr  6 23:04:36.057: INFO: Waiting up to 5m0s for pod "pod-c3121256-90d3-4cfa-a163-bcc0815d682a" in namespace "emptydir-7187" to be "success or failure"
Apr  6 23:04:36.059: INFO: Pod "pod-c3121256-90d3-4cfa-a163-bcc0815d682a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.555583ms
Apr  6 23:04:38.063: INFO: Pod "pod-c3121256-90d3-4cfa-a163-bcc0815d682a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005837673s
STEP: Saw pod success
Apr  6 23:04:38.063: INFO: Pod "pod-c3121256-90d3-4cfa-a163-bcc0815d682a" satisfied condition "success or failure"
Apr  6 23:04:38.065: INFO: Trying to get logs from node 10.0.0.43 pod pod-c3121256-90d3-4cfa-a163-bcc0815d682a container test-container: <nil>
STEP: delete the pod
Apr  6 23:04:38.082: INFO: Waiting for pod pod-c3121256-90d3-4cfa-a163-bcc0815d682a to disappear
Apr  6 23:04:38.084: INFO: Pod pod-c3121256-90d3-4cfa-a163-bcc0815d682a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:04:38.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7187" for this suite.
Apr  6 23:04:44.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:04:44.170: INFO: namespace emptydir-7187 deletion completed in 6.082778312s

• [SLOW TEST:8.140 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:04:44.170: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Apr  6 23:04:54.242: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0406 23:04:54.242197      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:04:54.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1276" for this suite.
Apr  6 23:05:00.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:05:00.338: INFO: namespace gc-1276 deletion completed in 6.092773702s

• [SLOW TEST:16.167 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:05:00.338: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr  6 23:05:00.365: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f8a9da77-45c6-4ab7-aae4-65297193216e" in namespace "downward-api-8254" to be "success or failure"
Apr  6 23:05:00.367: INFO: Pod "downwardapi-volume-f8a9da77-45c6-4ab7-aae4-65297193216e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.561926ms
Apr  6 23:05:02.370: INFO: Pod "downwardapi-volume-f8a9da77-45c6-4ab7-aae4-65297193216e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005576659s
STEP: Saw pod success
Apr  6 23:05:02.370: INFO: Pod "downwardapi-volume-f8a9da77-45c6-4ab7-aae4-65297193216e" satisfied condition "success or failure"
Apr  6 23:05:02.372: INFO: Trying to get logs from node 10.0.0.44 pod downwardapi-volume-f8a9da77-45c6-4ab7-aae4-65297193216e container client-container: <nil>
STEP: delete the pod
Apr  6 23:05:02.398: INFO: Waiting for pod downwardapi-volume-f8a9da77-45c6-4ab7-aae4-65297193216e to disappear
Apr  6 23:05:02.400: INFO: Pod downwardapi-volume-f8a9da77-45c6-4ab7-aae4-65297193216e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:05:02.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8254" for this suite.
Apr  6 23:05:08.415: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:05:08.485: INFO: namespace downward-api-8254 deletion completed in 6.081785401s

• [SLOW TEST:8.147 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:05:08.486: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-2h2d
STEP: Creating a pod to test atomic-volume-subpath
Apr  6 23:05:08.520: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-2h2d" in namespace "subpath-7195" to be "success or failure"
Apr  6 23:05:08.523: INFO: Pod "pod-subpath-test-projected-2h2d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.25679ms
Apr  6 23:05:10.527: INFO: Pod "pod-subpath-test-projected-2h2d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006255393s
Apr  6 23:05:12.530: INFO: Pod "pod-subpath-test-projected-2h2d": Phase="Running", Reason="", readiness=true. Elapsed: 4.009247256s
Apr  6 23:05:14.533: INFO: Pod "pod-subpath-test-projected-2h2d": Phase="Running", Reason="", readiness=true. Elapsed: 6.012519446s
Apr  6 23:05:16.536: INFO: Pod "pod-subpath-test-projected-2h2d": Phase="Running", Reason="", readiness=true. Elapsed: 8.01555029s
Apr  6 23:05:18.538: INFO: Pod "pod-subpath-test-projected-2h2d": Phase="Running", Reason="", readiness=true. Elapsed: 10.018138436s
Apr  6 23:05:20.541: INFO: Pod "pod-subpath-test-projected-2h2d": Phase="Running", Reason="", readiness=true. Elapsed: 12.021108953s
Apr  6 23:05:22.545: INFO: Pod "pod-subpath-test-projected-2h2d": Phase="Running", Reason="", readiness=true. Elapsed: 14.024301537s
Apr  6 23:05:24.547: INFO: Pod "pod-subpath-test-projected-2h2d": Phase="Running", Reason="", readiness=true. Elapsed: 16.026913415s
Apr  6 23:05:26.551: INFO: Pod "pod-subpath-test-projected-2h2d": Phase="Running", Reason="", readiness=true. Elapsed: 18.030212689s
Apr  6 23:05:28.553: INFO: Pod "pod-subpath-test-projected-2h2d": Phase="Running", Reason="", readiness=true. Elapsed: 20.033111295s
Apr  6 23:05:30.556: INFO: Pod "pod-subpath-test-projected-2h2d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.035933565s
STEP: Saw pod success
Apr  6 23:05:30.556: INFO: Pod "pod-subpath-test-projected-2h2d" satisfied condition "success or failure"
Apr  6 23:05:30.558: INFO: Trying to get logs from node 10.0.0.44 pod pod-subpath-test-projected-2h2d container test-container-subpath-projected-2h2d: <nil>
STEP: delete the pod
Apr  6 23:05:30.573: INFO: Waiting for pod pod-subpath-test-projected-2h2d to disappear
Apr  6 23:05:30.575: INFO: Pod pod-subpath-test-projected-2h2d no longer exists
STEP: Deleting pod pod-subpath-test-projected-2h2d
Apr  6 23:05:30.575: INFO: Deleting pod "pod-subpath-test-projected-2h2d" in namespace "subpath-7195"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:05:30.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7195" for this suite.
Apr  6 23:05:36.588: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:05:36.658: INFO: namespace subpath-7195 deletion completed in 6.07728846s

• [SLOW TEST:28.173 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:05:36.659: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr  6 23:05:36.685: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e2e81388-649e-46f3-870c-4a19c1969e53" in namespace "downward-api-4108" to be "success or failure"
Apr  6 23:05:36.687: INFO: Pod "downwardapi-volume-e2e81388-649e-46f3-870c-4a19c1969e53": Phase="Pending", Reason="", readiness=false. Elapsed: 2.136653ms
Apr  6 23:05:38.690: INFO: Pod "downwardapi-volume-e2e81388-649e-46f3-870c-4a19c1969e53": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005301584s
STEP: Saw pod success
Apr  6 23:05:38.690: INFO: Pod "downwardapi-volume-e2e81388-649e-46f3-870c-4a19c1969e53" satisfied condition "success or failure"
Apr  6 23:05:38.693: INFO: Trying to get logs from node 10.0.0.43 pod downwardapi-volume-e2e81388-649e-46f3-870c-4a19c1969e53 container client-container: <nil>
STEP: delete the pod
Apr  6 23:05:38.708: INFO: Waiting for pod downwardapi-volume-e2e81388-649e-46f3-870c-4a19c1969e53 to disappear
Apr  6 23:05:38.711: INFO: Pod downwardapi-volume-e2e81388-649e-46f3-870c-4a19c1969e53 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:05:38.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4108" for this suite.
Apr  6 23:05:44.724: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:05:44.835: INFO: namespace downward-api-4108 deletion completed in 6.120504413s

• [SLOW TEST:8.176 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:05:44.835: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Apr  6 23:05:44.860: INFO: Waiting up to 5m0s for pod "pod-37f796cb-8daa-4f54-9986-93ae365f833e" in namespace "emptydir-2918" to be "success or failure"
Apr  6 23:05:44.862: INFO: Pod "pod-37f796cb-8daa-4f54-9986-93ae365f833e": Phase="Pending", Reason="", readiness=false. Elapsed: 1.908652ms
Apr  6 23:05:46.865: INFO: Pod "pod-37f796cb-8daa-4f54-9986-93ae365f833e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.004759615s
STEP: Saw pod success
Apr  6 23:05:46.865: INFO: Pod "pod-37f796cb-8daa-4f54-9986-93ae365f833e" satisfied condition "success or failure"
Apr  6 23:05:46.867: INFO: Trying to get logs from node 10.0.0.44 pod pod-37f796cb-8daa-4f54-9986-93ae365f833e container test-container: <nil>
STEP: delete the pod
Apr  6 23:05:46.890: INFO: Waiting for pod pod-37f796cb-8daa-4f54-9986-93ae365f833e to disappear
Apr  6 23:05:46.892: INFO: Pod pod-37f796cb-8daa-4f54-9986-93ae365f833e no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:05:46.892: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2918" for this suite.
Apr  6 23:05:52.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:05:53.139: INFO: namespace emptydir-2918 deletion completed in 6.243638488s

• [SLOW TEST:8.304 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:05:53.139: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr  6 23:05:53.169: INFO: Waiting up to 5m0s for pod "downwardapi-volume-967c490a-7917-469b-b345-e1bd0ea8cc32" in namespace "projected-5687" to be "success or failure"
Apr  6 23:05:53.171: INFO: Pod "downwardapi-volume-967c490a-7917-469b-b345-e1bd0ea8cc32": Phase="Pending", Reason="", readiness=false. Elapsed: 2.584056ms
Apr  6 23:05:55.174: INFO: Pod "downwardapi-volume-967c490a-7917-469b-b345-e1bd0ea8cc32": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005550213s
STEP: Saw pod success
Apr  6 23:05:55.174: INFO: Pod "downwardapi-volume-967c490a-7917-469b-b345-e1bd0ea8cc32" satisfied condition "success or failure"
Apr  6 23:05:55.177: INFO: Trying to get logs from node 10.0.0.43 pod downwardapi-volume-967c490a-7917-469b-b345-e1bd0ea8cc32 container client-container: <nil>
STEP: delete the pod
Apr  6 23:05:55.192: INFO: Waiting for pod downwardapi-volume-967c490a-7917-469b-b345-e1bd0ea8cc32 to disappear
Apr  6 23:05:55.195: INFO: Pod downwardapi-volume-967c490a-7917-469b-b345-e1bd0ea8cc32 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:05:55.195: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5687" for this suite.
Apr  6 23:06:01.206: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:06:01.275: INFO: namespace projected-5687 deletion completed in 6.076033571s

• [SLOW TEST:8.135 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:06:01.275: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-8417
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-8417
STEP: Creating statefulset with conflicting port in namespace statefulset-8417
STEP: Waiting until pod test-pod will start running in namespace statefulset-8417
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-8417
Apr  6 23:06:05.319: INFO: Observed stateful pod in namespace: statefulset-8417, name: ss-0, uid: 40a04297-bdb9-4edc-9a0b-864e53cb2c03, status phase: Failed. Waiting for statefulset controller to delete.
Apr  6 23:06:05.321: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-8417
STEP: Removing pod with conflicting port in namespace statefulset-8417
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-8417 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Apr  6 23:06:09.337: INFO: Deleting all statefulset in ns statefulset-8417
Apr  6 23:06:09.339: INFO: Scaling statefulset ss to 0
Apr  6 23:06:19.350: INFO: Waiting for statefulset status.replicas updated to 0
Apr  6 23:06:19.352: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:06:19.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8417" for this suite.
Apr  6 23:06:25.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:06:25.437: INFO: namespace statefulset-8417 deletion completed in 6.072691611s

• [SLOW TEST:24.162 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:06:25.437: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename replicaset
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 23:06:25.461: INFO: Creating ReplicaSet my-hostname-basic-37b6cb98-4b0e-4dcf-8046-3e7bb2659716
Apr  6 23:06:25.466: INFO: Pod name my-hostname-basic-37b6cb98-4b0e-4dcf-8046-3e7bb2659716: Found 0 pods out of 1
Apr  6 23:06:30.469: INFO: Pod name my-hostname-basic-37b6cb98-4b0e-4dcf-8046-3e7bb2659716: Found 1 pods out of 1
Apr  6 23:06:30.469: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-37b6cb98-4b0e-4dcf-8046-3e7bb2659716" is running
Apr  6 23:06:30.472: INFO: Pod "my-hostname-basic-37b6cb98-4b0e-4dcf-8046-3e7bb2659716-wwnqg" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-06 23:06:25 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-06 23:06:26 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-06 23:06:26 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2020-04-06 23:06:25 +0000 UTC Reason: Message:}])
Apr  6 23:06:30.472: INFO: Trying to dial the pod
Apr  6 23:06:35.482: INFO: Controller my-hostname-basic-37b6cb98-4b0e-4dcf-8046-3e7bb2659716: Got expected result from replica 1 [my-hostname-basic-37b6cb98-4b0e-4dcf-8046-3e7bb2659716-wwnqg]: "my-hostname-basic-37b6cb98-4b0e-4dcf-8046-3e7bb2659716-wwnqg", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:06:35.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9545" for this suite.
Apr  6 23:06:41.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:06:41.562: INFO: namespace replicaset-9545 deletion completed in 6.074863143s

• [SLOW TEST:16.125 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:06:41.562: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Apr  6 23:06:41.589: INFO: Waiting up to 5m0s for pod "pod-c5b8cdd3-26b2-4ece-aa52-fba812fe8021" in namespace "emptydir-9293" to be "success or failure"
Apr  6 23:06:41.592: INFO: Pod "pod-c5b8cdd3-26b2-4ece-aa52-fba812fe8021": Phase="Pending", Reason="", readiness=false. Elapsed: 2.09347ms
Apr  6 23:06:43.595: INFO: Pod "pod-c5b8cdd3-26b2-4ece-aa52-fba812fe8021": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005377389s
STEP: Saw pod success
Apr  6 23:06:43.595: INFO: Pod "pod-c5b8cdd3-26b2-4ece-aa52-fba812fe8021" satisfied condition "success or failure"
Apr  6 23:06:43.597: INFO: Trying to get logs from node 10.0.0.42 pod pod-c5b8cdd3-26b2-4ece-aa52-fba812fe8021 container test-container: <nil>
STEP: delete the pod
Apr  6 23:06:43.620: INFO: Waiting for pod pod-c5b8cdd3-26b2-4ece-aa52-fba812fe8021 to disappear
Apr  6 23:06:43.622: INFO: Pod pod-c5b8cdd3-26b2-4ece-aa52-fba812fe8021 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:06:43.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9293" for this suite.
Apr  6 23:06:49.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:06:49.709: INFO: namespace emptydir-9293 deletion completed in 6.083118692s

• [SLOW TEST:8.146 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:06:49.709: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-616b13a8-a9ec-4ff8-96a8-9666ab287898
STEP: Creating a pod to test consume configMaps
Apr  6 23:06:49.739: INFO: Waiting up to 5m0s for pod "pod-configmaps-5369355e-c743-434b-b6d0-848bb6af6bb1" in namespace "configmap-6124" to be "success or failure"
Apr  6 23:06:49.742: INFO: Pod "pod-configmaps-5369355e-c743-434b-b6d0-848bb6af6bb1": Phase="Pending", Reason="", readiness=false. Elapsed: 3.076766ms
Apr  6 23:06:51.746: INFO: Pod "pod-configmaps-5369355e-c743-434b-b6d0-848bb6af6bb1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006218944s
STEP: Saw pod success
Apr  6 23:06:51.746: INFO: Pod "pod-configmaps-5369355e-c743-434b-b6d0-848bb6af6bb1" satisfied condition "success or failure"
Apr  6 23:06:51.748: INFO: Trying to get logs from node 10.0.0.43 pod pod-configmaps-5369355e-c743-434b-b6d0-848bb6af6bb1 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  6 23:06:51.764: INFO: Waiting for pod pod-configmaps-5369355e-c743-434b-b6d0-848bb6af6bb1 to disappear
Apr  6 23:06:51.768: INFO: Pod pod-configmaps-5369355e-c743-434b-b6d0-848bb6af6bb1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:06:51.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6124" for this suite.
Apr  6 23:06:57.780: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:06:57.935: INFO: namespace configmap-6124 deletion completed in 6.163075948s

• [SLOW TEST:8.226 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:06:57.935: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-756019fa-259f-4308-97a0-aee483eaa251
STEP: Creating a pod to test consume configMaps
Apr  6 23:06:57.966: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-f2f36c8b-5076-494d-9b70-66e4fbda98bd" in namespace "projected-6449" to be "success or failure"
Apr  6 23:06:57.968: INFO: Pod "pod-projected-configmaps-f2f36c8b-5076-494d-9b70-66e4fbda98bd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.106696ms
Apr  6 23:06:59.973: INFO: Pod "pod-projected-configmaps-f2f36c8b-5076-494d-9b70-66e4fbda98bd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006553384s
STEP: Saw pod success
Apr  6 23:06:59.973: INFO: Pod "pod-projected-configmaps-f2f36c8b-5076-494d-9b70-66e4fbda98bd" satisfied condition "success or failure"
Apr  6 23:06:59.976: INFO: Trying to get logs from node 10.0.0.44 pod pod-projected-configmaps-f2f36c8b-5076-494d-9b70-66e4fbda98bd container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  6 23:06:59.992: INFO: Waiting for pod pod-projected-configmaps-f2f36c8b-5076-494d-9b70-66e4fbda98bd to disappear
Apr  6 23:06:59.995: INFO: Pod pod-projected-configmaps-f2f36c8b-5076-494d-9b70-66e4fbda98bd no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:06:59.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6449" for this suite.
Apr  6 23:07:06.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:07:06.079: INFO: namespace projected-6449 deletion completed in 6.080569976s

• [SLOW TEST:8.145 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:07:06.079: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename svcaccounts
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Apr  6 23:07:06.615: INFO: created pod pod-service-account-defaultsa
Apr  6 23:07:06.615: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Apr  6 23:07:06.618: INFO: created pod pod-service-account-mountsa
Apr  6 23:07:06.618: INFO: pod pod-service-account-mountsa service account token volume mount: true
Apr  6 23:07:06.622: INFO: created pod pod-service-account-nomountsa
Apr  6 23:07:06.622: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Apr  6 23:07:06.627: INFO: created pod pod-service-account-defaultsa-mountspec
Apr  6 23:07:06.627: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Apr  6 23:07:06.632: INFO: created pod pod-service-account-mountsa-mountspec
Apr  6 23:07:06.632: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Apr  6 23:07:06.639: INFO: created pod pod-service-account-nomountsa-mountspec
Apr  6 23:07:06.639: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Apr  6 23:07:06.644: INFO: created pod pod-service-account-defaultsa-nomountspec
Apr  6 23:07:06.644: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Apr  6 23:07:06.651: INFO: created pod pod-service-account-mountsa-nomountspec
Apr  6 23:07:06.651: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Apr  6 23:07:06.657: INFO: created pod pod-service-account-nomountsa-nomountspec
Apr  6 23:07:06.657: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:07:06.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-3183" for this suite.
Apr  6 23:07:12.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:07:12.743: INFO: namespace svcaccounts-3183 deletion completed in 6.082407731s

• [SLOW TEST:6.664 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:07:12.743: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr  6 23:07:12.770: INFO: Waiting up to 5m0s for pod "downwardapi-volume-64a871cb-c4de-45c9-a9a0-a29a6f35b53e" in namespace "downward-api-1175" to be "success or failure"
Apr  6 23:07:12.774: INFO: Pod "downwardapi-volume-64a871cb-c4de-45c9-a9a0-a29a6f35b53e": Phase="Pending", Reason="", readiness=false. Elapsed: 3.436845ms
Apr  6 23:07:14.776: INFO: Pod "downwardapi-volume-64a871cb-c4de-45c9-a9a0-a29a6f35b53e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005710296s
STEP: Saw pod success
Apr  6 23:07:14.776: INFO: Pod "downwardapi-volume-64a871cb-c4de-45c9-a9a0-a29a6f35b53e" satisfied condition "success or failure"
Apr  6 23:07:14.780: INFO: Trying to get logs from node 10.0.0.44 pod downwardapi-volume-64a871cb-c4de-45c9-a9a0-a29a6f35b53e container client-container: <nil>
STEP: delete the pod
Apr  6 23:07:14.793: INFO: Waiting for pod downwardapi-volume-64a871cb-c4de-45c9-a9a0-a29a6f35b53e to disappear
Apr  6 23:07:14.796: INFO: Pod downwardapi-volume-64a871cb-c4de-45c9-a9a0-a29a6f35b53e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:07:14.796: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1175" for this suite.
Apr  6 23:07:20.808: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:07:21.729: INFO: namespace downward-api-1175 deletion completed in 6.928817029s

• [SLOW TEST:8.985 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:07:21.729: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:07:21.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-8971" for this suite.
Apr  6 23:07:27.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:07:27.838: INFO: namespace custom-resource-definition-8971 deletion completed in 6.081950799s

• [SLOW TEST:6.109 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:07:27.838: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Apr  6 23:07:27.865: INFO: Pod name pod-release: Found 0 pods out of 1
Apr  6 23:07:32.868: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:07:33.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2987" for this suite.
Apr  6 23:07:39.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:07:39.969: INFO: namespace replication-controller-2987 deletion completed in 6.086075119s

• [SLOW TEST:12.131 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:07:39.969: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename crd-webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Apr  6 23:07:40.369: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  6 23:07:43.382: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 23:07:43.385: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:07:44.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-6121" for this suite.
Apr  6 23:07:50.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:07:50.591: INFO: namespace crd-webhook-6121 deletion completed in 6.080743038s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:10.632 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:07:50.602: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-38816df2-461d-45f8-95b8-f598296b6ad2
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:07:50.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4428" for this suite.
Apr  6 23:07:56.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:07:56.719: INFO: namespace secrets-4428 deletion completed in 6.090010346s

• [SLOW TEST:6.117 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:07:56.719: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-c6663e25-b13c-4404-9d60-f6ed3b014655 in namespace container-probe-1411
Apr  6 23:07:58.751: INFO: Started pod test-webserver-c6663e25-b13c-4404-9d60-f6ed3b014655 in namespace container-probe-1411
STEP: checking the pod's current state and verifying that restartCount is present
Apr  6 23:07:58.753: INFO: Initial restart count of pod test-webserver-c6663e25-b13c-4404-9d60-f6ed3b014655 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:11:59.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1411" for this suite.
Apr  6 23:12:05.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:12:05.217: INFO: namespace container-probe-1411 deletion completed in 6.073341274s

• [SLOW TEST:248.498 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:12:05.217: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  6 23:12:05.470: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  6 23:12:08.488: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Apr  6 23:12:10.512: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 attach --namespace=webhook-3165 to-be-attached-pod -i -c=container1'
Apr  6 23:12:10.817: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:12:10.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3165" for this suite.
Apr  6 23:12:22.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:12:22.911: INFO: namespace webhook-3165 deletion completed in 12.085416604s
STEP: Destroying namespace "webhook-3165-markers" for this suite.
Apr  6 23:12:28.919: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:12:28.985: INFO: namespace webhook-3165-markers deletion completed in 6.073725367s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:23.779 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:12:28.996: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr  6 23:12:29.017: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-7515'
Apr  6 23:12:29.089: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Apr  6 23:12:29.089: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Apr  6 23:12:29.104: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 delete jobs e2e-test-httpd-job --namespace=kubectl-7515'
Apr  6 23:12:29.177: INFO: stderr: ""
Apr  6 23:12:29.177: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:12:29.177: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7515" for this suite.
Apr  6 23:12:41.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:12:41.337: INFO: namespace kubectl-7515 deletion completed in 12.155726759s

• [SLOW TEST:12.341 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:12:41.337: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename security-context-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 23:12:41.367: INFO: Waiting up to 5m0s for pod "busybox-user-65534-0777e0f1-2529-48fa-817e-d013dea939f4" in namespace "security-context-test-9860" to be "success or failure"
Apr  6 23:12:41.372: INFO: Pod "busybox-user-65534-0777e0f1-2529-48fa-817e-d013dea939f4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.392195ms
Apr  6 23:12:43.375: INFO: Pod "busybox-user-65534-0777e0f1-2529-48fa-817e-d013dea939f4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007270378s
Apr  6 23:12:43.375: INFO: Pod "busybox-user-65534-0777e0f1-2529-48fa-817e-d013dea939f4" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:12:43.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9860" for this suite.
Apr  6 23:12:49.386: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:12:49.457: INFO: namespace security-context-test-9860 deletion completed in 6.078817604s

• [SLOW TEST:8.120 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:12:49.458: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-0f0c35bc-a32f-4b69-ae7e-cfd4d5f2d515
STEP: Creating configMap with name cm-test-opt-upd-8cd392da-1467-456b-a062-9aa339df2205
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-0f0c35bc-a32f-4b69-ae7e-cfd4d5f2d515
STEP: Updating configmap cm-test-opt-upd-8cd392da-1467-456b-a062-9aa339df2205
STEP: Creating configMap with name cm-test-opt-create-26f889f5-216a-4c00-8560-1ff3f928c739
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:12:53.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2735" for this suite.
Apr  6 23:13:07.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:13:07.644: INFO: namespace projected-2735 deletion completed in 14.073837221s

• [SLOW TEST:18.186 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:13:07.646: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 23:13:07.668: INFO: Creating deployment "webserver-deployment"
Apr  6 23:13:07.670: INFO: Waiting for observed generation 1
Apr  6 23:13:09.675: INFO: Waiting for all required pods to come up
Apr  6 23:13:09.679: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Apr  6 23:13:11.687: INFO: Waiting for deployment "webserver-deployment" to complete
Apr  6 23:13:11.691: INFO: Updating deployment "webserver-deployment" with a non-existent image
Apr  6 23:13:11.697: INFO: Updating deployment webserver-deployment
Apr  6 23:13:11.697: INFO: Waiting for observed generation 2
Apr  6 23:13:13.702: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Apr  6 23:13:13.703: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Apr  6 23:13:13.705: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr  6 23:13:13.711: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Apr  6 23:13:13.711: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Apr  6 23:13:13.717: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Apr  6 23:13:13.723: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Apr  6 23:13:13.723: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Apr  6 23:13:13.731: INFO: Updating deployment webserver-deployment
Apr  6 23:13:13.731: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Apr  6 23:13:13.735: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Apr  6 23:13:15.749: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Apr  6 23:13:15.755: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-3695 /apis/apps/v1/namespaces/deployment-3695/deployments/webserver-deployment 89bc5d8a-876c-4b2a-bffe-8fee017fc4d9 21457 3 2020-04-06 23:13:07 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003533768 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2020-04-06 23:13:13 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2020-04-06 23:13:13 +0000 UTC,LastTransitionTime:2020-04-06 23:13:07 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Apr  6 23:13:15.758: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-3695 /apis/apps/v1/namespaces/deployment-3695/replicasets/webserver-deployment-c7997dcc8 465fec2b-f149-46cd-b758-20b34bb75e1c 21456 3 2020-04-06 23:13:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 89bc5d8a-876c-4b2a-bffe-8fee017fc4d9 0xc0008220d7 0xc0008220d8}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000822158 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr  6 23:13:15.759: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Apr  6 23:13:15.759: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-3695 /apis/apps/v1/namespaces/deployment-3695/replicasets/webserver-deployment-595b5b9587 f1146504-d489-46d7-8fdc-13e40047c2f3 21443 3 2020-04-06 23:13:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 89bc5d8a-876c-4b2a-bffe-8fee017fc4d9 0xc000822017 0xc000822018}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000822078 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Apr  6 23:13:15.766: INFO: Pod "webserver-deployment-595b5b9587-2ftww" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2ftww webserver-deployment-595b5b9587- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-595b5b9587-2ftww 578defbb-e8b2-4a3f-9ea7-591d46ad9721 21262 0 2020-04-06 23:13:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 f1146504-d489-46d7-8fdc-13e40047c2f3 0xc001854ca7 0xc001854ca8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.44,PodIP:10.20.16.108,StartTime:2020-04-06 23:13:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-06 23:13:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://91d4d70761b1ef3221311bd5981c079a12264296d2d769576df6daad1f111897,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.20.16.108,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.766: INFO: Pod "webserver-deployment-595b5b9587-2npl6" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2npl6 webserver-deployment-595b5b9587- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-595b5b9587-2npl6 cafb65d9-26f2-49e3-a119-23ebe9168486 21289 0 2020-04-06 23:13:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 f1146504-d489-46d7-8fdc-13e40047c2f3 0xc001855090 0xc001855091}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.43,PodIP:10.20.8.102,StartTime:2020-04-06 23:13:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-06 23:13:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://ceaf2d3166f4ad60d2eb74fb58be329c3672d858d40eee567733f95e7aa9b53f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.20.8.102,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.766: INFO: Pod "webserver-deployment-595b5b9587-2ntpk" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2ntpk webserver-deployment-595b5b9587- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-595b5b9587-2ntpk 22542d02-3ad4-4c1c-a511-46efa6ea1952 21447 0 2020-04-06 23:13:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 f1146504-d489-46d7-8fdc-13e40047c2f3 0xc0018553c0 0xc0018553c1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.43,PodIP:,StartTime:2020-04-06 23:13:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.766: INFO: Pod "webserver-deployment-595b5b9587-488j8" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-488j8 webserver-deployment-595b5b9587- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-595b5b9587-488j8 48e490c9-f4f9-4669-8582-a391edef78a4 21446 0 2020-04-06 23:13:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 f1146504-d489-46d7-8fdc-13e40047c2f3 0xc0018556d0 0xc0018556d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.44,PodIP:,StartTime:2020-04-06 23:13:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.766: INFO: Pod "webserver-deployment-595b5b9587-6dc5b" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6dc5b webserver-deployment-595b5b9587- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-595b5b9587-6dc5b f448b839-38cd-45ac-894b-79053750fdeb 21271 0 2020-04-06 23:13:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 f1146504-d489-46d7-8fdc-13e40047c2f3 0xc001855a20 0xc001855a21}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.42,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.42,PodIP:10.20.14.100,StartTime:2020-04-06 23:13:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-06 23:13:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://9fe2aa048e3042cc19bb901fb7f401fc343915b45bcc3a84481e32125e5bf733,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.20.14.100,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.767: INFO: Pod "webserver-deployment-595b5b9587-6ftjw" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6ftjw webserver-deployment-595b5b9587- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-595b5b9587-6ftjw ee403f6d-aaa9-47b9-9675-49a63dcf47ba 21445 0 2020-04-06 23:13:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 f1146504-d489-46d7-8fdc-13e40047c2f3 0xc001855d80 0xc001855d81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.42,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.42,PodIP:,StartTime:2020-04-06 23:13:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.767: INFO: Pod "webserver-deployment-595b5b9587-779mx" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-779mx webserver-deployment-595b5b9587- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-595b5b9587-779mx a5068d08-1023-4852-87cc-a53b55944933 21259 0 2020-04-06 23:13:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 f1146504-d489-46d7-8fdc-13e40047c2f3 0xc00170c020 0xc00170c021}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.44,PodIP:10.20.16.110,StartTime:2020-04-06 23:13:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-06 23:13:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://52a0cc0773ee048f3c1623fb00369c100f3b2ed69300e6df621f8c43db5982f2,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.20.16.110,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.767: INFO: Pod "webserver-deployment-595b5b9587-9hrzd" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9hrzd webserver-deployment-595b5b9587- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-595b5b9587-9hrzd 7a6062e7-622a-4c6d-ade3-64a1bb7569ea 21452 0 2020-04-06 23:13:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 f1146504-d489-46d7-8fdc-13e40047c2f3 0xc00170c190 0xc00170c191}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.44,PodIP:,StartTime:2020-04-06 23:13:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.767: INFO: Pod "webserver-deployment-595b5b9587-bkjpx" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-bkjpx webserver-deployment-595b5b9587- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-595b5b9587-bkjpx 47adc26b-1219-4895-aec8-fe85ac1eab9f 21283 0 2020-04-06 23:13:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 f1146504-d489-46d7-8fdc-13e40047c2f3 0xc00170c2f0 0xc00170c2f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.43,PodIP:10.20.8.103,StartTime:2020-04-06 23:13:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-06 23:13:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://fbd981813364b490bfd56db1b9ece9e83e834809cc70b0c502ba7bc577416e0d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.20.8.103,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.767: INFO: Pod "webserver-deployment-595b5b9587-chmrr" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-chmrr webserver-deployment-595b5b9587- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-595b5b9587-chmrr b97f67fe-cd77-4cc9-a5b8-5abc26fdc23d 21465 0 2020-04-06 23:13:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 f1146504-d489-46d7-8fdc-13e40047c2f3 0xc00170c5a0 0xc00170c5a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.43,PodIP:,StartTime:2020-04-06 23:13:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.767: INFO: Pod "webserver-deployment-595b5b9587-fqx4k" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-fqx4k webserver-deployment-595b5b9587- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-595b5b9587-fqx4k 1cf93e81-afc9-4b8a-8352-9b253ea2d131 21280 0 2020-04-06 23:13:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 f1146504-d489-46d7-8fdc-13e40047c2f3 0xc00170c980 0xc00170c981}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.43,PodIP:10.20.8.104,StartTime:2020-04-06 23:13:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-06 23:13:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://872861f3cc212bdb68451c8e96c14c8a1959088a20eb80f0bbe652f4ea17a365,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.20.8.104,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.768: INFO: Pod "webserver-deployment-595b5b9587-gkm5m" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gkm5m webserver-deployment-595b5b9587- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-595b5b9587-gkm5m 397eda3e-24d5-413d-b79d-4a89665b4635 21449 0 2020-04-06 23:13:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 f1146504-d489-46d7-8fdc-13e40047c2f3 0xc00170cbf0 0xc00170cbf1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.42,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.42,PodIP:,StartTime:2020-04-06 23:13:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.768: INFO: Pod "webserver-deployment-595b5b9587-n2l9h" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-n2l9h webserver-deployment-595b5b9587- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-595b5b9587-n2l9h 59f7bb24-94dc-4da8-8b19-aeb1aeccaa16 21498 0 2020-04-06 23:13:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 f1146504-d489-46d7-8fdc-13e40047c2f3 0xc00170cf00 0xc00170cf01}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.43,PodIP:,StartTime:2020-04-06 23:13:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.768: INFO: Pod "webserver-deployment-595b5b9587-plqst" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-plqst webserver-deployment-595b5b9587- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-595b5b9587-plqst b4efb017-6618-4e9f-bef8-672b51a56c6c 21409 0 2020-04-06 23:13:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 f1146504-d489-46d7-8fdc-13e40047c2f3 0xc00170d1f0 0xc00170d1f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.44,PodIP:,StartTime:2020-04-06 23:13:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.768: INFO: Pod "webserver-deployment-595b5b9587-rgkhh" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-rgkhh webserver-deployment-595b5b9587- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-595b5b9587-rgkhh 58d8af3d-fb18-44a0-a3ef-eeeb59398497 21267 0 2020-04-06 23:13:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 f1146504-d489-46d7-8fdc-13e40047c2f3 0xc00170d410 0xc00170d411}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.42,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.42,PodIP:10.20.14.101,StartTime:2020-04-06 23:13:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-06 23:13:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://340b05470fed9e98124bf72919c8a2ebd383f2d2f5a4270d163d3762b5cd63ea,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.20.14.101,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.768: INFO: Pod "webserver-deployment-595b5b9587-rhsmp" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-rhsmp webserver-deployment-595b5b9587- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-595b5b9587-rhsmp c89dea44-9177-4542-b616-d04acdaee40a 21263 0 2020-04-06 23:13:07 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 f1146504-d489-46d7-8fdc-13e40047c2f3 0xc00170d590 0xc00170d591}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.42,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:07 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:09 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:07 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.42,PodIP:10.20.14.99,StartTime:2020-04-06 23:13:07 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-06 23:13:08 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://f1217a498c1a18194d8ea719290fbb93b2bd85deecdb94465e960cbe85a0198c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.20.14.99,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.768: INFO: Pod "webserver-deployment-595b5b9587-snjmz" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-snjmz webserver-deployment-595b5b9587- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-595b5b9587-snjmz 4d8e2942-d41e-467f-a214-784af5f31b91 21473 0 2020-04-06 23:13:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 f1146504-d489-46d7-8fdc-13e40047c2f3 0xc00170d700 0xc00170d701}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.44,PodIP:,StartTime:2020-04-06 23:13:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.769: INFO: Pod "webserver-deployment-595b5b9587-vbxqx" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-vbxqx webserver-deployment-595b5b9587- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-595b5b9587-vbxqx a184e508-c0b8-4a79-a18d-b6936d45364e 21460 0 2020-04-06 23:13:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 f1146504-d489-46d7-8fdc-13e40047c2f3 0xc00170d850 0xc00170d851}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.42,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.42,PodIP:,StartTime:2020-04-06 23:13:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.769: INFO: Pod "webserver-deployment-595b5b9587-vtm64" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-vtm64 webserver-deployment-595b5b9587- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-595b5b9587-vtm64 e7ff2d56-141a-4c3d-96a3-8862df8ff6ee 21441 0 2020-04-06 23:13:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 f1146504-d489-46d7-8fdc-13e40047c2f3 0xc00170d9a0 0xc00170d9a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.43,PodIP:,StartTime:2020-04-06 23:13:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.769: INFO: Pod "webserver-deployment-595b5b9587-wg5vz" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-wg5vz webserver-deployment-595b5b9587- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-595b5b9587-wg5vz b1fac6a1-8e5b-4942-a011-c19d31dec795 21454 0 2020-04-06 23:13:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 f1146504-d489-46d7-8fdc-13e40047c2f3 0xc00170daf0 0xc00170daf1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.43,PodIP:,StartTime:2020-04-06 23:13:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.769: INFO: Pod "webserver-deployment-c7997dcc8-27k2k" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-27k2k webserver-deployment-c7997dcc8- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-c7997dcc8-27k2k 266b724a-3d93-4ec9-9646-50bfb7f06845 21439 0 2020-04-06 23:13:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 465fec2b-f149-46cd-b758-20b34bb75e1c 0xc00170dc40 0xc00170dc41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.44,PodIP:,StartTime:2020-04-06 23:13:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.770: INFO: Pod "webserver-deployment-c7997dcc8-bjr9z" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-bjr9z webserver-deployment-c7997dcc8- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-c7997dcc8-bjr9z 6f66d860-ff68-473e-84e3-1a54ca99a921 21508 0 2020-04-06 23:13:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 465fec2b-f149-46cd-b758-20b34bb75e1c 0xc00170ddb0 0xc00170ddb1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.44,PodIP:,StartTime:2020-04-06 23:13:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login',},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.770: INFO: Pod "webserver-deployment-c7997dcc8-dh4vm" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-dh4vm webserver-deployment-c7997dcc8- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-c7997dcc8-dh4vm e508d08b-3029-48d3-8f3a-558d6212f0e3 21487 0 2020-04-06 23:13:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 465fec2b-f149-46cd-b758-20b34bb75e1c 0xc00170df30 0xc00170df31}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.42,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.42,PodIP:10.20.14.103,StartTime:2020-04-06 23:13:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login',},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.20.14.103,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.770: INFO: Pod "webserver-deployment-c7997dcc8-fqnlr" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-fqnlr webserver-deployment-c7997dcc8- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-c7997dcc8-fqnlr 7376b0b2-d82e-407d-b0b9-515e8871bb85 21464 0 2020-04-06 23:13:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 465fec2b-f149-46cd-b758-20b34bb75e1c 0xc003c2a1f0 0xc003c2a1f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.44,PodIP:,StartTime:2020-04-06 23:13:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.770: INFO: Pod "webserver-deployment-c7997dcc8-fwbfd" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-fwbfd webserver-deployment-c7997dcc8- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-c7997dcc8-fwbfd 87abce9f-d32c-4a98-b2ac-7df239f5bf9a 21517 0 2020-04-06 23:13:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 465fec2b-f149-46cd-b758-20b34bb75e1c 0xc003c2a3e0 0xc003c2a3e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.43,PodIP:10.20.8.106,StartTime:2020-04-06 23:13:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login',},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.20.8.106,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.770: INFO: Pod "webserver-deployment-c7997dcc8-gqtc8" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-gqtc8 webserver-deployment-c7997dcc8- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-c7997dcc8-gqtc8 cfbfe633-32fb-49bc-add9-423692a466d0 21474 0 2020-04-06 23:13:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 465fec2b-f149-46cd-b758-20b34bb75e1c 0xc003c2a7e0 0xc003c2a7e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.43,PodIP:,StartTime:2020-04-06 23:13:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.770: INFO: Pod "webserver-deployment-c7997dcc8-h9dv8" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-h9dv8 webserver-deployment-c7997dcc8- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-c7997dcc8-h9dv8 c8a49290-2820-43e0-b387-dd2a8a8a2606 21451 0 2020-04-06 23:13:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 465fec2b-f149-46cd-b758-20b34bb75e1c 0xc003c2a950 0xc003c2a951}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.43,PodIP:,StartTime:2020-04-06 23:13:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.771: INFO: Pod "webserver-deployment-c7997dcc8-kh26z" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-kh26z webserver-deployment-c7997dcc8- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-c7997dcc8-kh26z 0d352ae5-4f10-4f8c-9231-e3b09a125098 21453 0 2020-04-06 23:13:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 465fec2b-f149-46cd-b758-20b34bb75e1c 0xc003c2aac0 0xc003c2aac1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.42,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.42,PodIP:,StartTime:2020-04-06 23:13:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.771: INFO: Pod "webserver-deployment-c7997dcc8-ksq6h" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-ksq6h webserver-deployment-c7997dcc8- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-c7997dcc8-ksq6h b16d5021-504c-47c0-b1a9-35b9216a1800 21448 0 2020-04-06 23:13:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 465fec2b-f149-46cd-b758-20b34bb75e1c 0xc003c2ad70 0xc003c2ad71}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.44,PodIP:,StartTime:2020-04-06 23:13:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.771: INFO: Pod "webserver-deployment-c7997dcc8-lqx4j" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-lqx4j webserver-deployment-c7997dcc8- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-c7997dcc8-lqx4j 5fc82655-5a38-453a-b53c-f411c72d09aa 21359 0 2020-04-06 23:13:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 465fec2b-f149-46cd-b758-20b34bb75e1c 0xc003c2afa0 0xc003c2afa1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.42,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.42,PodIP:10.20.14.102,StartTime:2020-04-06 23:13:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login',},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.20.14.102,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.771: INFO: Pod "webserver-deployment-c7997dcc8-m27xk" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-m27xk webserver-deployment-c7997dcc8- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-c7997dcc8-m27xk e7af132f-47e7-4110-b7fa-99ff660e7ad2 21450 0 2020-04-06 23:13:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 465fec2b-f149-46cd-b758-20b34bb75e1c 0xc003c2b1c0 0xc003c2b1c1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.43,PodIP:,StartTime:2020-04-06 23:13:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.771: INFO: Pod "webserver-deployment-c7997dcc8-wm44x" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-wm44x webserver-deployment-c7997dcc8- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-c7997dcc8-wm44x cba6c386-8518-4fc5-b42c-9e2cd0ad1f38 21442 0 2020-04-06 23:13:13 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 465fec2b-f149-46cd-b758-20b34bb75e1c 0xc003c2b360 0xc003c2b361}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.42,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:13 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.42,PodIP:,StartTime:2020-04-06 23:13:13 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Apr  6 23:13:15.772: INFO: Pod "webserver-deployment-c7997dcc8-xjr95" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-xjr95 webserver-deployment-c7997dcc8- deployment-3695 /api/v1/namespaces/deployment-3695/pods/webserver-deployment-c7997dcc8-xjr95 8201a166-8f80-4cd7-a024-c2446af91217 21327 0 2020-04-06 23:13:11 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 465fec2b-f149-46cd-b758-20b34bb75e1c 0xc003c2b550 0xc003c2b551}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2ldlz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2ldlz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2ldlz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.43,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:13:11 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.43,PodIP:,StartTime:2020-04-06 23:13:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:13:15.772: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-3695" for this suite.
Apr  6 23:13:23.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:13:23.885: INFO: namespace deployment-3695 deletion completed in 8.110069591s

• [SLOW TEST:16.239 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:13:23.886: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-8933
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  6 23:13:23.918: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  6 23:13:47.994: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.20.16.121:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8933 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 23:13:47.994: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 23:13:48.139: INFO: Found all expected endpoints: [netserver-0]
Apr  6 23:13:48.142: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.20.8.120:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8933 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 23:13:48.142: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 23:13:48.281: INFO: Found all expected endpoints: [netserver-1]
Apr  6 23:13:48.283: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.20.14.110:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-8933 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 23:13:48.284: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 23:13:48.412: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:13:48.412: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8933" for this suite.
Apr  6 23:14:00.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:14:00.535: INFO: namespace pod-network-test-8933 deletion completed in 12.119249167s

• [SLOW TEST:36.650 seconds]
[sig-network] Networking
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:14:00.536: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr  6 23:14:02.581: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:14:02.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1918" for this suite.
Apr  6 23:14:08.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:14:08.709: INFO: namespace container-runtime-1918 deletion completed in 6.111279459s

• [SLOW TEST:8.173 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:14:08.709: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename events
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Apr  6 23:14:10.753: INFO: &Pod{ObjectMeta:{send-events-fddfc165-2d31-4ce1-86b4-f3d143327737  events-9160 /api/v1/namespaces/events-9160/pods/send-events-fddfc165-2d31-4ce1-86b4-f3d143327737 8a98f8f9-3dfd-4ca1-aac0-448a157006f9 22018 0 2020-04-06 23:14:08 +0000 UTC <nil> <nil> map[name:foo time:739508879] map[] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-787dn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-787dn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-787dn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.42,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:14:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:14:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:14:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:14:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.42,PodIP:10.20.14.112,StartTime:2020-04-06 23:14:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-06 23:14:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:docker://b2c03c391e5f9f007d493b8b2557f116f692433054281aa2271032cb1f7652c3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.20.14.112,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Apr  6 23:14:12.757: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Apr  6 23:14:14.760: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:14:14.765: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-9160" for this suite.
Apr  6 23:14:58.785: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:14:58.880: INFO: namespace events-9160 deletion completed in 44.109871556s

• [SLOW TEST:50.171 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:14:58.880: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename replication-controller
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 23:14:58.906: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Apr  6 23:14:59.923: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:15:00.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-7641" for this suite.
Apr  6 23:15:06.948: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:15:07.042: INFO: namespace replication-controller-7641 deletion completed in 6.104339944s

• [SLOW TEST:8.162 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:15:07.042: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 23:15:29.087: INFO: Container started at 2020-04-06 23:15:08 +0000 UTC, pod became ready at 2020-04-06 23:15:29 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:15:29.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5905" for this suite.
Apr  6 23:15:57.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:15:57.187: INFO: namespace container-probe-5905 deletion completed in 28.096415058s

• [SLOW TEST:50.144 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:15:57.187: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
W0406 23:16:27.737905      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Apr  6 23:16:27.738: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:16:27.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1963" for this suite.
Apr  6 23:16:33.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:16:33.846: INFO: namespace gc-1963 deletion completed in 6.10492439s

• [SLOW TEST:36.660 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:16:33.847: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-11320071-fcad-463f-9b0e-aadd5fa9dc25 in namespace container-probe-4644
Apr  6 23:16:35.885: INFO: Started pod liveness-11320071-fcad-463f-9b0e-aadd5fa9dc25 in namespace container-probe-4644
STEP: checking the pod's current state and verifying that restartCount is present
Apr  6 23:16:35.887: INFO: Initial restart count of pod liveness-11320071-fcad-463f-9b0e-aadd5fa9dc25 is 0
Apr  6 23:16:59.929: INFO: Restart count of pod container-probe-4644/liveness-11320071-fcad-463f-9b0e-aadd5fa9dc25 is now 1 (24.041668072s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:16:59.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4644" for this suite.
Apr  6 23:17:05.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:17:06.053: INFO: namespace container-probe-4644 deletion completed in 6.104704718s

• [SLOW TEST:32.207 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:17:06.054: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:17:10.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7815" for this suite.
Apr  6 23:17:58.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:17:58.227: INFO: namespace kubelet-test-7815 deletion completed in 48.103297233s

• [SLOW TEST:52.173 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:17:58.227: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename hostpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Apr  6 23:17:58.270: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-7120" to be "success or failure"
Apr  6 23:17:58.272: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.176741ms
Apr  6 23:18:00.275: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005470423s
STEP: Saw pod success
Apr  6 23:18:00.275: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Apr  6 23:18:00.277: INFO: Trying to get logs from node 10.0.0.42 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Apr  6 23:18:00.295: INFO: Waiting for pod pod-host-path-test to disappear
Apr  6 23:18:00.297: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:18:00.297: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-7120" for this suite.
Apr  6 23:18:06.313: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:18:06.410: INFO: namespace hostpath-7120 deletion completed in 6.107278936s

• [SLOW TEST:8.183 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:18:06.410: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:18:06.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6530" for this suite.
Apr  6 23:18:12.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:18:12.564: INFO: namespace resourcequota-6530 deletion completed in 6.087648858s

• [SLOW TEST:6.153 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:18:12.564: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr  6 23:18:14.606: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:18:14.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5387" for this suite.
Apr  6 23:18:20.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:18:20.732: INFO: namespace container-runtime-5387 deletion completed in 6.094462193s

• [SLOW TEST:8.168 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:18:20.732: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  6 23:18:21.967: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr  6 23:18:23.975: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721811901, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721811901, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721811901, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721811901, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  6 23:18:26.991: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:18:27.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8794" for this suite.
Apr  6 23:18:33.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:18:33.138: INFO: namespace webhook-8794 deletion completed in 6.100480415s
STEP: Destroying namespace "webhook-8794-markers" for this suite.
Apr  6 23:18:39.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:18:39.237: INFO: namespace webhook-8794-markers deletion completed in 6.098866918s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.516 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:18:39.248: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename dns
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5495.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-5495.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5495.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5495.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-5495.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5495.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Apr  6 23:18:43.316: INFO: DNS probes using dns-5495/dns-test-9cdb9052-baab-4849-b730-e873f02b46db succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:18:43.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5495" for this suite.
Apr  6 23:18:49.352: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:18:49.455: INFO: namespace dns-5495 deletion completed in 6.12478217s

• [SLOW TEST:10.207 seconds]
[sig-network] DNS
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:18:49.455: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename statefulset
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6460
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-6460
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6460
Apr  6 23:18:49.493: INFO: Found 0 stateful pods, waiting for 1
Apr  6 23:18:59.496: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Apr  6 23:18:59.500: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=statefulset-6460 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr  6 23:18:59.717: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr  6 23:18:59.717: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr  6 23:18:59.717: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr  6 23:18:59.720: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Apr  6 23:19:09.724: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  6 23:19:09.724: INFO: Waiting for statefulset status.replicas updated to 0
Apr  6 23:19:09.739: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Apr  6 23:19:09.739: INFO: ss-0  10.0.0.44  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:18:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:18:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:18:59 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:18:49 +0000 UTC  }]
Apr  6 23:19:09.739: INFO: 
Apr  6 23:19:09.739: INFO: StatefulSet ss has not reached scale 3, at 1
Apr  6 23:19:10.743: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99673776s
Apr  6 23:19:11.747: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992713883s
Apr  6 23:19:12.749: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.989072223s
Apr  6 23:19:13.753: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.986180724s
Apr  6 23:19:14.757: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.982584597s
Apr  6 23:19:15.760: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.979044922s
Apr  6 23:19:16.764: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.975466166s
Apr  6 23:19:17.767: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.971945894s
Apr  6 23:19:18.771: INFO: Verifying statefulset ss doesn't scale past 3 for another 968.34693ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6460
Apr  6 23:19:19.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=statefulset-6460 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr  6 23:19:19.976: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Apr  6 23:19:19.976: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr  6 23:19:19.976: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr  6 23:19:19.976: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=statefulset-6460 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr  6 23:19:20.168: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr  6 23:19:20.168: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr  6 23:19:20.168: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr  6 23:19:20.168: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=statefulset-6460 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Apr  6 23:19:20.371: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Apr  6 23:19:20.371: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Apr  6 23:19:20.371: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Apr  6 23:19:20.374: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=false
Apr  6 23:19:30.381: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Apr  6 23:19:30.381: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Apr  6 23:19:30.381: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Apr  6 23:19:30.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=statefulset-6460 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr  6 23:19:30.577: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr  6 23:19:30.577: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr  6 23:19:30.577: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr  6 23:19:30.577: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=statefulset-6460 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr  6 23:19:30.781: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr  6 23:19:30.781: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr  6 23:19:30.781: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr  6 23:19:30.781: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=statefulset-6460 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Apr  6 23:19:31.019: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Apr  6 23:19:31.019: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Apr  6 23:19:31.019: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Apr  6 23:19:31.019: INFO: Waiting for statefulset status.replicas updated to 0
Apr  6 23:19:31.022: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Apr  6 23:19:41.028: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Apr  6 23:19:41.028: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Apr  6 23:19:41.028: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Apr  6 23:19:41.039: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Apr  6 23:19:41.039: INFO: ss-0  10.0.0.44  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:18:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:18:49 +0000 UTC  }]
Apr  6 23:19:41.039: INFO: ss-1  10.0.0.42  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:09 +0000 UTC  }]
Apr  6 23:19:41.039: INFO: ss-2  10.0.0.43  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:09 +0000 UTC  }]
Apr  6 23:19:41.039: INFO: 
Apr  6 23:19:41.039: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  6 23:19:42.043: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Apr  6 23:19:42.043: INFO: ss-0  10.0.0.44  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:18:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:18:49 +0000 UTC  }]
Apr  6 23:19:42.043: INFO: ss-1  10.0.0.42  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:09 +0000 UTC  }]
Apr  6 23:19:42.043: INFO: ss-2  10.0.0.43  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:09 +0000 UTC  }]
Apr  6 23:19:42.043: INFO: 
Apr  6 23:19:42.043: INFO: StatefulSet ss has not reached scale 0, at 3
Apr  6 23:19:43.047: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Apr  6 23:19:43.047: INFO: ss-0  10.0.0.44  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:18:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:18:49 +0000 UTC  }]
Apr  6 23:19:43.047: INFO: ss-1  10.0.0.42  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:09 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:31 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:09 +0000 UTC  }]
Apr  6 23:19:43.047: INFO: 
Apr  6 23:19:43.047: INFO: StatefulSet ss has not reached scale 0, at 2
Apr  6 23:19:44.050: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Apr  6 23:19:44.050: INFO: ss-0  10.0.0.44  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:18:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:18:49 +0000 UTC  }]
Apr  6 23:19:44.050: INFO: 
Apr  6 23:19:44.050: INFO: StatefulSet ss has not reached scale 0, at 1
Apr  6 23:19:45.054: INFO: POD   NODE       PHASE    GRACE  CONDITIONS
Apr  6 23:19:45.054: INFO: ss-0  10.0.0.44  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:18:49 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:19:30 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2020-04-06 23:18:49 +0000 UTC  }]
Apr  6 23:19:45.054: INFO: 
Apr  6 23:19:45.054: INFO: StatefulSet ss has not reached scale 0, at 1
Apr  6 23:19:46.057: INFO: Verifying statefulset ss doesn't scale past 0 for another 4.980816969s
Apr  6 23:19:47.060: INFO: Verifying statefulset ss doesn't scale past 0 for another 3.977617444s
Apr  6 23:19:48.064: INFO: Verifying statefulset ss doesn't scale past 0 for another 2.974547078s
Apr  6 23:19:49.066: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.971032416s
Apr  6 23:19:50.069: INFO: Verifying statefulset ss doesn't scale past 0 for another 968.26508ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6460
Apr  6 23:19:51.072: INFO: Scaling statefulset ss to 0
Apr  6 23:19:51.079: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Apr  6 23:19:51.081: INFO: Deleting all statefulset in ns statefulset-6460
Apr  6 23:19:51.083: INFO: Scaling statefulset ss to 0
Apr  6 23:19:51.093: INFO: Waiting for statefulset status.replicas updated to 0
Apr  6 23:19:51.095: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:19:51.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6460" for this suite.
Apr  6 23:19:57.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:19:57.258: INFO: namespace statefulset-6460 deletion completed in 6.14859854s

• [SLOW TEST:67.803 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:19:57.259: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Apr  6 23:19:57.290: INFO: Waiting up to 5m0s for pod "downward-api-cdb65eab-0366-43af-b8de-f933bab9e665" in namespace "downward-api-3963" to be "success or failure"
Apr  6 23:19:57.293: INFO: Pod "downward-api-cdb65eab-0366-43af-b8de-f933bab9e665": Phase="Pending", Reason="", readiness=false. Elapsed: 2.980665ms
Apr  6 23:19:59.297: INFO: Pod "downward-api-cdb65eab-0366-43af-b8de-f933bab9e665": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006101073s
STEP: Saw pod success
Apr  6 23:19:59.297: INFO: Pod "downward-api-cdb65eab-0366-43af-b8de-f933bab9e665" satisfied condition "success or failure"
Apr  6 23:19:59.299: INFO: Trying to get logs from node 10.0.0.43 pod downward-api-cdb65eab-0366-43af-b8de-f933bab9e665 container dapi-container: <nil>
STEP: delete the pod
Apr  6 23:19:59.326: INFO: Waiting for pod downward-api-cdb65eab-0366-43af-b8de-f933bab9e665 to disappear
Apr  6 23:19:59.328: INFO: Pod downward-api-cdb65eab-0366-43af-b8de-f933bab9e665 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:19:59.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3963" for this suite.
Apr  6 23:20:05.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:20:05.429: INFO: namespace downward-api-3963 deletion completed in 6.094951351s

• [SLOW TEST:8.170 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:20:05.429: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Apr  6 23:20:05.457: INFO: Waiting up to 5m0s for pod "pod-19f6a215-5753-47ce-9e0d-605bc63e9f78" in namespace "emptydir-6245" to be "success or failure"
Apr  6 23:20:05.459: INFO: Pod "pod-19f6a215-5753-47ce-9e0d-605bc63e9f78": Phase="Pending", Reason="", readiness=false. Elapsed: 2.249059ms
Apr  6 23:20:07.462: INFO: Pod "pod-19f6a215-5753-47ce-9e0d-605bc63e9f78": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005184268s
STEP: Saw pod success
Apr  6 23:20:07.462: INFO: Pod "pod-19f6a215-5753-47ce-9e0d-605bc63e9f78" satisfied condition "success or failure"
Apr  6 23:20:07.467: INFO: Trying to get logs from node 10.0.0.43 pod pod-19f6a215-5753-47ce-9e0d-605bc63e9f78 container test-container: <nil>
STEP: delete the pod
Apr  6 23:20:07.484: INFO: Waiting for pod pod-19f6a215-5753-47ce-9e0d-605bc63e9f78 to disappear
Apr  6 23:20:07.486: INFO: Pod pod-19f6a215-5753-47ce-9e0d-605bc63e9f78 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:20:07.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6245" for this suite.
Apr  6 23:20:13.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:20:13.599: INFO: namespace emptydir-6245 deletion completed in 6.109494924s

• [SLOW TEST:8.170 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:20:13.599: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:20:13.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3649" for this suite.
Apr  6 23:20:25.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:20:25.741: INFO: namespace pods-3649 deletion completed in 12.104676146s

• [SLOW TEST:12.141 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:20:25.741: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  6 23:20:26.034: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr  6 23:20:28.045: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812026, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812026, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812026, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812026, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  6 23:20:31.060: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:20:31.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-289" for this suite.
Apr  6 23:20:37.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:20:37.244: INFO: namespace webhook-289 deletion completed in 6.129120782s
STEP: Destroying namespace "webhook-289-markers" for this suite.
Apr  6 23:20:43.254: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:20:43.334: INFO: namespace webhook-289-markers deletion completed in 6.090500253s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:17.606 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:20:43.346: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Apr  6 23:20:43.372: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 api-versions'
Apr  6 23:20:43.460: INFO: stderr: ""
Apr  6 23:20:43.460: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nmonitoring.coreos.com/v1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\noperators.coreos.com/v1\noperators.coreos.com/v1alpha1\noperators.coreos.com/v1alpha2\npackages.operators.coreos.com/v1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1alpha1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:20:43.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6630" for this suite.
Apr  6 23:20:49.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:20:49.645: INFO: namespace kubectl-6630 deletion completed in 6.181453591s

• [SLOW TEST:6.299 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:20:49.645: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 23:20:49.670: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:20:51.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8358" for this suite.
Apr  6 23:21:31.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:21:31.793: INFO: namespace pods-8358 deletion completed in 40.089931323s

• [SLOW TEST:42.147 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:21:31.793: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 23:21:31.820: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Apr  6 23:21:34.616: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 --namespace=crd-publish-openapi-2784 create -f -'
Apr  6 23:21:35.282: INFO: stderr: ""
Apr  6 23:21:35.282: INFO: stdout: "e2e-test-crd-publish-openapi-4054-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr  6 23:21:35.282: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 --namespace=crd-publish-openapi-2784 delete e2e-test-crd-publish-openapi-4054-crds test-cr'
Apr  6 23:21:35.362: INFO: stderr: ""
Apr  6 23:21:35.363: INFO: stdout: "e2e-test-crd-publish-openapi-4054-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Apr  6 23:21:35.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 --namespace=crd-publish-openapi-2784 apply -f -'
Apr  6 23:21:35.506: INFO: stderr: ""
Apr  6 23:21:35.506: INFO: stdout: "e2e-test-crd-publish-openapi-4054-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Apr  6 23:21:35.506: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 --namespace=crd-publish-openapi-2784 delete e2e-test-crd-publish-openapi-4054-crds test-cr'
Apr  6 23:21:35.583: INFO: stderr: ""
Apr  6 23:21:35.583: INFO: stdout: "e2e-test-crd-publish-openapi-4054-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Apr  6 23:21:35.583: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 explain e2e-test-crd-publish-openapi-4054-crds'
Apr  6 23:21:35.727: INFO: stderr: ""
Apr  6 23:21:35.727: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4054-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:21:38.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2784" for this suite.
Apr  6 23:21:44.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:21:44.606: INFO: namespace crd-publish-openapi-2784 deletion completed in 6.092328098s

• [SLOW TEST:12.813 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:21:44.606: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename container-probe
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:22:44.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-645" for this suite.
Apr  6 23:23:12.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:23:12.732: INFO: namespace container-probe-645 deletion completed in 28.086784677s

• [SLOW TEST:88.126 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:23:12.733: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename gc
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Apr  6 23:23:52.783: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W0406 23:23:52.783186      23 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:23:52.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4064" for this suite.
Apr  6 23:23:58.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:23:58.949: INFO: namespace gc-4064 deletion completed in 6.163875125s

• [SLOW TEST:46.217 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:23:58.950: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-1381/configmap-test-bdb95fd3-38eb-46cf-abd2-96d55a766c17
STEP: Creating a pod to test consume configMaps
Apr  6 23:23:58.982: INFO: Waiting up to 5m0s for pod "pod-configmaps-569d9719-9be0-4b9b-b470-0c82d0b3cfb0" in namespace "configmap-1381" to be "success or failure"
Apr  6 23:23:58.989: INFO: Pod "pod-configmaps-569d9719-9be0-4b9b-b470-0c82d0b3cfb0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.950692ms
Apr  6 23:24:00.992: INFO: Pod "pod-configmaps-569d9719-9be0-4b9b-b470-0c82d0b3cfb0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010104588s
Apr  6 23:24:02.995: INFO: Pod "pod-configmaps-569d9719-9be0-4b9b-b470-0c82d0b3cfb0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013353469s
STEP: Saw pod success
Apr  6 23:24:02.995: INFO: Pod "pod-configmaps-569d9719-9be0-4b9b-b470-0c82d0b3cfb0" satisfied condition "success or failure"
Apr  6 23:24:03.001: INFO: Trying to get logs from node 10.0.0.43 pod pod-configmaps-569d9719-9be0-4b9b-b470-0c82d0b3cfb0 container env-test: <nil>
STEP: delete the pod
Apr  6 23:24:03.028: INFO: Waiting for pod pod-configmaps-569d9719-9be0-4b9b-b470-0c82d0b3cfb0 to disappear
Apr  6 23:24:03.031: INFO: Pod pod-configmaps-569d9719-9be0-4b9b-b470-0c82d0b3cfb0 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:24:03.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1381" for this suite.
Apr  6 23:24:09.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:24:09.143: INFO: namespace configmap-1381 deletion completed in 6.10848207s

• [SLOW TEST:10.193 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:24:09.144: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:24:26.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6893" for this suite.
Apr  6 23:24:32.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:24:32.300: INFO: namespace resourcequota-6893 deletion completed in 6.096647242s

• [SLOW TEST:23.156 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:24:32.300: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename var-expansion
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Apr  6 23:24:32.327: INFO: Waiting up to 5m0s for pod "var-expansion-74232d95-6304-4615-b464-3d602a74f1d0" in namespace "var-expansion-4843" to be "success or failure"
Apr  6 23:24:32.333: INFO: Pod "var-expansion-74232d95-6304-4615-b464-3d602a74f1d0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.044336ms
Apr  6 23:24:34.337: INFO: Pod "var-expansion-74232d95-6304-4615-b464-3d602a74f1d0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009325474s
STEP: Saw pod success
Apr  6 23:24:34.337: INFO: Pod "var-expansion-74232d95-6304-4615-b464-3d602a74f1d0" satisfied condition "success or failure"
Apr  6 23:24:34.339: INFO: Trying to get logs from node 10.0.0.44 pod var-expansion-74232d95-6304-4615-b464-3d602a74f1d0 container dapi-container: <nil>
STEP: delete the pod
Apr  6 23:24:34.362: INFO: Waiting for pod var-expansion-74232d95-6304-4615-b464-3d602a74f1d0 to disappear
Apr  6 23:24:34.366: INFO: Pod var-expansion-74232d95-6304-4615-b464-3d602a74f1d0 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:24:34.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4843" for this suite.
Apr  6 23:24:40.380: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:24:40.466: INFO: namespace var-expansion-4843 deletion completed in 6.09647114s

• [SLOW TEST:8.166 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:24:40.466: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Apr  6 23:24:40.500: INFO: Waiting up to 5m0s for pod "downward-api-e354b368-5c69-44c2-9c33-f87ece6b9536" in namespace "downward-api-8768" to be "success or failure"
Apr  6 23:24:40.503: INFO: Pod "downward-api-e354b368-5c69-44c2-9c33-f87ece6b9536": Phase="Pending", Reason="", readiness=false. Elapsed: 2.348343ms
Apr  6 23:24:42.506: INFO: Pod "downward-api-e354b368-5c69-44c2-9c33-f87ece6b9536": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005566841s
STEP: Saw pod success
Apr  6 23:24:42.506: INFO: Pod "downward-api-e354b368-5c69-44c2-9c33-f87ece6b9536" satisfied condition "success or failure"
Apr  6 23:24:42.508: INFO: Trying to get logs from node 10.0.0.44 pod downward-api-e354b368-5c69-44c2-9c33-f87ece6b9536 container dapi-container: <nil>
STEP: delete the pod
Apr  6 23:24:42.528: INFO: Waiting for pod downward-api-e354b368-5c69-44c2-9c33-f87ece6b9536 to disappear
Apr  6 23:24:42.532: INFO: Pod downward-api-e354b368-5c69-44c2-9c33-f87ece6b9536 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:24:42.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8768" for this suite.
Apr  6 23:24:48.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:24:48.633: INFO: namespace downward-api-8768 deletion completed in 6.097675967s

• [SLOW TEST:8.167 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:24:48.633: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Apr  6 23:24:48.659: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 create -f - --namespace=kubectl-6464'
Apr  6 23:24:48.865: INFO: stderr: ""
Apr  6 23:24:48.865: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  6 23:24:48.865: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6464'
Apr  6 23:24:48.941: INFO: stderr: ""
Apr  6 23:24:48.941: INFO: stdout: "update-demo-nautilus-78mjd update-demo-nautilus-p7drg "
Apr  6 23:24:48.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-78mjd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6464'
Apr  6 23:24:49.008: INFO: stderr: ""
Apr  6 23:24:49.008: INFO: stdout: ""
Apr  6 23:24:49.008: INFO: update-demo-nautilus-78mjd is created but not running
Apr  6 23:24:54.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6464'
Apr  6 23:24:54.078: INFO: stderr: ""
Apr  6 23:24:54.078: INFO: stdout: "update-demo-nautilus-78mjd update-demo-nautilus-p7drg "
Apr  6 23:24:54.078: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-78mjd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6464'
Apr  6 23:24:54.145: INFO: stderr: ""
Apr  6 23:24:54.145: INFO: stdout: "true"
Apr  6 23:24:54.145: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-78mjd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6464'
Apr  6 23:24:54.225: INFO: stderr: ""
Apr  6 23:24:54.225: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  6 23:24:54.225: INFO: validating pod update-demo-nautilus-78mjd
Apr  6 23:24:54.230: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  6 23:24:54.230: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  6 23:24:54.230: INFO: update-demo-nautilus-78mjd is verified up and running
Apr  6 23:24:54.230: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-p7drg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6464'
Apr  6 23:24:54.301: INFO: stderr: ""
Apr  6 23:24:54.301: INFO: stdout: "true"
Apr  6 23:24:54.301: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-p7drg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6464'
Apr  6 23:24:54.375: INFO: stderr: ""
Apr  6 23:24:54.375: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  6 23:24:54.375: INFO: validating pod update-demo-nautilus-p7drg
Apr  6 23:24:54.379: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  6 23:24:54.379: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  6 23:24:54.379: INFO: update-demo-nautilus-p7drg is verified up and running
STEP: scaling down the replication controller
Apr  6 23:24:54.382: INFO: scanned /root for discovery docs: <nil>
Apr  6 23:24:54.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-6464'
Apr  6 23:24:55.480: INFO: stderr: ""
Apr  6 23:24:55.480: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  6 23:24:55.480: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6464'
Apr  6 23:24:55.555: INFO: stderr: ""
Apr  6 23:24:55.555: INFO: stdout: "update-demo-nautilus-78mjd update-demo-nautilus-p7drg "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr  6 23:25:00.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6464'
Apr  6 23:25:00.624: INFO: stderr: ""
Apr  6 23:25:00.624: INFO: stdout: "update-demo-nautilus-78mjd update-demo-nautilus-p7drg "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr  6 23:25:05.624: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6464'
Apr  6 23:25:05.698: INFO: stderr: ""
Apr  6 23:25:05.698: INFO: stdout: "update-demo-nautilus-78mjd update-demo-nautilus-p7drg "
STEP: Replicas for name=update-demo: expected=1 actual=2
Apr  6 23:25:10.698: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6464'
Apr  6 23:25:10.769: INFO: stderr: ""
Apr  6 23:25:10.769: INFO: stdout: "update-demo-nautilus-78mjd "
Apr  6 23:25:10.769: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-78mjd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6464'
Apr  6 23:25:10.839: INFO: stderr: ""
Apr  6 23:25:10.839: INFO: stdout: "true"
Apr  6 23:25:10.839: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-78mjd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6464'
Apr  6 23:25:10.906: INFO: stderr: ""
Apr  6 23:25:10.906: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  6 23:25:10.906: INFO: validating pod update-demo-nautilus-78mjd
Apr  6 23:25:10.909: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  6 23:25:10.909: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  6 23:25:10.909: INFO: update-demo-nautilus-78mjd is verified up and running
STEP: scaling up the replication controller
Apr  6 23:25:10.911: INFO: scanned /root for discovery docs: <nil>
Apr  6 23:25:10.911: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-6464'
Apr  6 23:25:12.000: INFO: stderr: ""
Apr  6 23:25:12.001: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Apr  6 23:25:12.001: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6464'
Apr  6 23:25:12.072: INFO: stderr: ""
Apr  6 23:25:12.072: INFO: stdout: "update-demo-nautilus-78mjd update-demo-nautilus-pwgb8 "
Apr  6 23:25:12.072: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-78mjd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6464'
Apr  6 23:25:12.139: INFO: stderr: ""
Apr  6 23:25:12.139: INFO: stdout: "true"
Apr  6 23:25:12.139: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-78mjd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6464'
Apr  6 23:25:12.212: INFO: stderr: ""
Apr  6 23:25:12.212: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  6 23:25:12.212: INFO: validating pod update-demo-nautilus-78mjd
Apr  6 23:25:12.216: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  6 23:25:12.216: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  6 23:25:12.216: INFO: update-demo-nautilus-78mjd is verified up and running
Apr  6 23:25:12.216: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-pwgb8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6464'
Apr  6 23:25:12.289: INFO: stderr: ""
Apr  6 23:25:12.289: INFO: stdout: ""
Apr  6 23:25:12.289: INFO: update-demo-nautilus-pwgb8 is created but not running
Apr  6 23:25:17.290: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6464'
Apr  6 23:25:17.363: INFO: stderr: ""
Apr  6 23:25:17.363: INFO: stdout: "update-demo-nautilus-78mjd update-demo-nautilus-pwgb8 "
Apr  6 23:25:17.363: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-78mjd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6464'
Apr  6 23:25:17.432: INFO: stderr: ""
Apr  6 23:25:17.432: INFO: stdout: "true"
Apr  6 23:25:17.433: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-78mjd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6464'
Apr  6 23:25:17.504: INFO: stderr: ""
Apr  6 23:25:17.504: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  6 23:25:17.504: INFO: validating pod update-demo-nautilus-78mjd
Apr  6 23:25:17.508: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  6 23:25:17.508: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  6 23:25:17.509: INFO: update-demo-nautilus-78mjd is verified up and running
Apr  6 23:25:17.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-pwgb8 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6464'
Apr  6 23:25:17.579: INFO: stderr: ""
Apr  6 23:25:17.579: INFO: stdout: "true"
Apr  6 23:25:17.579: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods update-demo-nautilus-pwgb8 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6464'
Apr  6 23:25:17.653: INFO: stderr: ""
Apr  6 23:25:17.653: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Apr  6 23:25:17.653: INFO: validating pod update-demo-nautilus-pwgb8
Apr  6 23:25:17.657: INFO: got data: {
  "image": "nautilus.jpg"
}

Apr  6 23:25:17.657: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Apr  6 23:25:17.657: INFO: update-demo-nautilus-pwgb8 is verified up and running
STEP: using delete to clean up resources
Apr  6 23:25:17.657: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 delete --grace-period=0 --force -f - --namespace=kubectl-6464'
Apr  6 23:25:17.731: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  6 23:25:17.731: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Apr  6 23:25:17.731: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6464'
Apr  6 23:25:17.803: INFO: stderr: "No resources found in kubectl-6464 namespace.\n"
Apr  6 23:25:17.803: INFO: stdout: ""
Apr  6 23:25:17.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods -l name=update-demo --namespace=kubectl-6464 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  6 23:25:17.881: INFO: stderr: ""
Apr  6 23:25:17.881: INFO: stdout: "update-demo-nautilus-78mjd\nupdate-demo-nautilus-pwgb8\n"
Apr  6 23:25:18.381: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-6464'
Apr  6 23:25:18.461: INFO: stderr: "No resources found in kubectl-6464 namespace.\n"
Apr  6 23:25:18.461: INFO: stdout: ""
Apr  6 23:25:18.461: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods -l name=update-demo --namespace=kubectl-6464 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  6 23:25:18.532: INFO: stderr: ""
Apr  6 23:25:18.532: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:25:18.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6464" for this suite.
Apr  6 23:25:30.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:25:30.623: INFO: namespace kubectl-6464 deletion completed in 12.0875694s

• [SLOW TEST:41.990 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:25:30.623: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr  6 23:25:30.661: INFO: Waiting up to 5m0s for pod "downwardapi-volume-5f1df2cc-6546-4ffd-8cca-85864cc104fb" in namespace "downward-api-6112" to be "success or failure"
Apr  6 23:25:30.668: INFO: Pod "downwardapi-volume-5f1df2cc-6546-4ffd-8cca-85864cc104fb": Phase="Pending", Reason="", readiness=false. Elapsed: 7.0409ms
Apr  6 23:25:32.671: INFO: Pod "downwardapi-volume-5f1df2cc-6546-4ffd-8cca-85864cc104fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010484734s
STEP: Saw pod success
Apr  6 23:25:32.671: INFO: Pod "downwardapi-volume-5f1df2cc-6546-4ffd-8cca-85864cc104fb" satisfied condition "success or failure"
Apr  6 23:25:32.674: INFO: Trying to get logs from node 10.0.0.43 pod downwardapi-volume-5f1df2cc-6546-4ffd-8cca-85864cc104fb container client-container: <nil>
STEP: delete the pod
Apr  6 23:25:32.695: INFO: Waiting for pod downwardapi-volume-5f1df2cc-6546-4ffd-8cca-85864cc104fb to disappear
Apr  6 23:25:32.698: INFO: Pod downwardapi-volume-5f1df2cc-6546-4ffd-8cca-85864cc104fb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:25:32.698: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6112" for this suite.
Apr  6 23:25:38.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:25:38.818: INFO: namespace downward-api-6112 deletion completed in 6.1156851s

• [SLOW TEST:8.195 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:25:38.818: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubelet-test
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:25:42.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1762" for this suite.
Apr  6 23:25:48.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:25:49.057: INFO: namespace kubelet-test-1762 deletion completed in 6.195459581s

• [SLOW TEST:10.238 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:25:49.057: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Apr  6 23:25:49.081: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-2216'
Apr  6 23:25:49.162: INFO: stderr: ""
Apr  6 23:25:49.162: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Apr  6 23:25:49.164: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 delete pods e2e-test-httpd-pod --namespace=kubectl-2216'
Apr  6 23:25:59.861: INFO: stderr: ""
Apr  6 23:25:59.861: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:25:59.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2216" for this suite.
Apr  6 23:26:05.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:26:05.951: INFO: namespace kubectl-2216 deletion completed in 6.084606324s

• [SLOW TEST:16.895 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:26:05.952: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Apr  6 23:26:05.982: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-273020805 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:26:06.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-855" for this suite.
Apr  6 23:26:12.079: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:26:12.145: INFO: namespace kubectl-855 deletion completed in 6.097883734s

• [SLOW TEST:6.193 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:26:12.145: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename configmap
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-11be5b2a-3504-4a77-a265-009c45f2536c
STEP: Creating a pod to test consume configMaps
Apr  6 23:26:12.172: INFO: Waiting up to 5m0s for pod "pod-configmaps-d99d9c8c-65b4-41bb-9d55-c3a646dc7f54" in namespace "configmap-710" to be "success or failure"
Apr  6 23:26:12.175: INFO: Pod "pod-configmaps-d99d9c8c-65b4-41bb-9d55-c3a646dc7f54": Phase="Pending", Reason="", readiness=false. Elapsed: 2.364712ms
Apr  6 23:26:14.178: INFO: Pod "pod-configmaps-d99d9c8c-65b4-41bb-9d55-c3a646dc7f54": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005351637s
STEP: Saw pod success
Apr  6 23:26:14.178: INFO: Pod "pod-configmaps-d99d9c8c-65b4-41bb-9d55-c3a646dc7f54" satisfied condition "success or failure"
Apr  6 23:26:14.180: INFO: Trying to get logs from node 10.0.0.42 pod pod-configmaps-d99d9c8c-65b4-41bb-9d55-c3a646dc7f54 container configmap-volume-test: <nil>
STEP: delete the pod
Apr  6 23:26:14.208: INFO: Waiting for pod pod-configmaps-d99d9c8c-65b4-41bb-9d55-c3a646dc7f54 to disappear
Apr  6 23:26:14.211: INFO: Pod pod-configmaps-d99d9c8c-65b4-41bb-9d55-c3a646dc7f54 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:26:14.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-710" for this suite.
Apr  6 23:26:20.225: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:26:20.344: INFO: namespace configmap-710 deletion completed in 6.129436204s

• [SLOW TEST:8.199 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:26:20.344: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename deployment
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 23:26:20.380: INFO: Pod name rollover-pod: Found 0 pods out of 1
Apr  6 23:26:25.383: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Apr  6 23:26:25.383: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Apr  6 23:26:27.387: INFO: Creating deployment "test-rollover-deployment"
Apr  6 23:26:27.394: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Apr  6 23:26:29.403: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Apr  6 23:26:29.409: INFO: Ensure that both replica sets have 1 created replica
Apr  6 23:26:29.413: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Apr  6 23:26:29.419: INFO: Updating deployment test-rollover-deployment
Apr  6 23:26:29.419: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Apr  6 23:26:31.424: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Apr  6 23:26:31.431: INFO: Make sure deployment "test-rollover-deployment" is complete
Apr  6 23:26:31.435: INFO: all replica sets need to contain the pod-template-hash label
Apr  6 23:26:31.436: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812387, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812387, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812391, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812387, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  6 23:26:33.441: INFO: all replica sets need to contain the pod-template-hash label
Apr  6 23:26:33.441: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812387, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812387, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812391, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812387, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  6 23:26:35.441: INFO: all replica sets need to contain the pod-template-hash label
Apr  6 23:26:35.441: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812387, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812387, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812391, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812387, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  6 23:26:37.447: INFO: all replica sets need to contain the pod-template-hash label
Apr  6 23:26:37.447: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812387, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812387, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812391, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812387, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  6 23:26:39.447: INFO: all replica sets need to contain the pod-template-hash label
Apr  6 23:26:39.447: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812387, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812387, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812391, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812387, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Apr  6 23:26:41.441: INFO: 
Apr  6 23:26:41.441: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Apr  6 23:26:41.448: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-555 /apis/apps/v1/namespaces/deployment-555/deployments/test-rollover-deployment 487a3c20-0a2d-48b8-8322-e9ad8924c3e1 24878 2 2020-04-06 23:26:27 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002ca2818 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2020-04-06 23:26:27 +0000 UTC,LastTransitionTime:2020-04-06 23:26:27 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2020-04-06 23:26:41 +0000 UTC,LastTransitionTime:2020-04-06 23:26:27 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Apr  6 23:26:41.453: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-555 /apis/apps/v1/namespaces/deployment-555/replicasets/test-rollover-deployment-7d7dc6548c d0b579b2-2d50-4724-bb6c-38b002186919 24867 2 2020-04-06 23:26:29 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment 487a3c20-0a2d-48b8-8322-e9ad8924c3e1 0xc002ca2cc7 0xc002ca2cc8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002ca2d28 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Apr  6 23:26:41.453: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Apr  6 23:26:41.454: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-555 /apis/apps/v1/namespaces/deployment-555/replicasets/test-rollover-controller 0be6126c-dbb7-48d5-b978-876cd261a3b0 24876 2 2020-04-06 23:26:20 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment 487a3c20-0a2d-48b8-8322-e9ad8924c3e1 0xc002ca2bf7 0xc002ca2bf8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002ca2c58 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr  6 23:26:41.454: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-555 /apis/apps/v1/namespaces/deployment-555/replicasets/test-rollover-deployment-f6c94f66c 916a64ff-2618-44c4-b4c0-05bda8661e71 24829 2 2020-04-06 23:26:27 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment 487a3c20-0a2d-48b8-8322-e9ad8924c3e1 0xc002ca2d90 0xc002ca2d91}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002ca2e08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Apr  6 23:26:41.456: INFO: Pod "test-rollover-deployment-7d7dc6548c-lz7g4" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-lz7g4 test-rollover-deployment-7d7dc6548c- deployment-555 /api/v1/namespaces/deployment-555/pods/test-rollover-deployment-7d7dc6548c-lz7g4 7a65f30c-ce58-4d36-ac93-0e8599027751 24839 0 2020-04-06 23:26:29 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c d0b579b2-2d50-4724-bb6c-38b002186919 0xc002ca3367 0xc002ca3368}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-x2rjs,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-x2rjs,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-x2rjs,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:10.0.0.44,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:26:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:26:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:26:31 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2020-04-06 23:26:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.0.0.44,PodIP:10.20.16.134,StartTime:2020-04-06 23:26:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2020-04-06 23:26:30 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://93410afe7c8cf4c91f675e8c61433dddfbea7d1551f2c770f528e481dd3fbc42,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.20.16.134,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:26:41.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-555" for this suite.
Apr  6 23:26:47.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:26:47.637: INFO: namespace deployment-555 deletion completed in 6.176595284s

• [SLOW TEST:27.292 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:26:47.637: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename subpath
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-wsr6
STEP: Creating a pod to test atomic-volume-subpath
Apr  6 23:26:47.681: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-wsr6" in namespace "subpath-7131" to be "success or failure"
Apr  6 23:26:47.683: INFO: Pod "pod-subpath-test-secret-wsr6": Phase="Pending", Reason="", readiness=false. Elapsed: 1.934499ms
Apr  6 23:26:49.686: INFO: Pod "pod-subpath-test-secret-wsr6": Phase="Running", Reason="", readiness=true. Elapsed: 2.004863031s
Apr  6 23:26:51.690: INFO: Pod "pod-subpath-test-secret-wsr6": Phase="Running", Reason="", readiness=true. Elapsed: 4.008156392s
Apr  6 23:26:53.693: INFO: Pod "pod-subpath-test-secret-wsr6": Phase="Running", Reason="", readiness=true. Elapsed: 6.011443368s
Apr  6 23:26:55.696: INFO: Pod "pod-subpath-test-secret-wsr6": Phase="Running", Reason="", readiness=true. Elapsed: 8.014134357s
Apr  6 23:26:57.699: INFO: Pod "pod-subpath-test-secret-wsr6": Phase="Running", Reason="", readiness=true. Elapsed: 10.017233948s
Apr  6 23:26:59.702: INFO: Pod "pod-subpath-test-secret-wsr6": Phase="Running", Reason="", readiness=true. Elapsed: 12.020161198s
Apr  6 23:27:01.705: INFO: Pod "pod-subpath-test-secret-wsr6": Phase="Running", Reason="", readiness=true. Elapsed: 14.023252866s
Apr  6 23:27:03.712: INFO: Pod "pod-subpath-test-secret-wsr6": Phase="Running", Reason="", readiness=true. Elapsed: 16.030918269s
Apr  6 23:27:05.715: INFO: Pod "pod-subpath-test-secret-wsr6": Phase="Running", Reason="", readiness=true. Elapsed: 18.033896943s
Apr  6 23:27:07.719: INFO: Pod "pod-subpath-test-secret-wsr6": Phase="Running", Reason="", readiness=true. Elapsed: 20.03706303s
Apr  6 23:27:09.722: INFO: Pod "pod-subpath-test-secret-wsr6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.040491614s
STEP: Saw pod success
Apr  6 23:27:09.722: INFO: Pod "pod-subpath-test-secret-wsr6" satisfied condition "success or failure"
Apr  6 23:27:09.724: INFO: Trying to get logs from node 10.0.0.44 pod pod-subpath-test-secret-wsr6 container test-container-subpath-secret-wsr6: <nil>
STEP: delete the pod
Apr  6 23:27:09.751: INFO: Waiting for pod pod-subpath-test-secret-wsr6 to disappear
Apr  6 23:27:09.754: INFO: Pod pod-subpath-test-secret-wsr6 no longer exists
STEP: Deleting pod pod-subpath-test-secret-wsr6
Apr  6 23:27:09.754: INFO: Deleting pod "pod-subpath-test-secret-wsr6" in namespace "subpath-7131"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:27:09.756: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7131" for this suite.
Apr  6 23:27:15.774: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:27:16.250: INFO: namespace subpath-7131 deletion completed in 6.487127845s

• [SLOW TEST:28.613 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:27:16.250: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Apr  6 23:27:16.282: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9622 /api/v1/namespaces/watch-9622/configmaps/e2e-watch-test-configmap-a 8c91b840-687d-4673-85b4-f9f00d405a18 25020 0 2020-04-06 23:27:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  6 23:27:16.282: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9622 /api/v1/namespaces/watch-9622/configmaps/e2e-watch-test-configmap-a 8c91b840-687d-4673-85b4-f9f00d405a18 25020 0 2020-04-06 23:27:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Apr  6 23:27:26.300: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9622 /api/v1/namespaces/watch-9622/configmaps/e2e-watch-test-configmap-a 8c91b840-687d-4673-85b4-f9f00d405a18 25043 0 2020-04-06 23:27:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Apr  6 23:27:26.300: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9622 /api/v1/namespaces/watch-9622/configmaps/e2e-watch-test-configmap-a 8c91b840-687d-4673-85b4-f9f00d405a18 25043 0 2020-04-06 23:27:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Apr  6 23:27:36.306: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9622 /api/v1/namespaces/watch-9622/configmaps/e2e-watch-test-configmap-a 8c91b840-687d-4673-85b4-f9f00d405a18 25063 0 2020-04-06 23:27:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  6 23:27:36.306: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9622 /api/v1/namespaces/watch-9622/configmaps/e2e-watch-test-configmap-a 8c91b840-687d-4673-85b4-f9f00d405a18 25063 0 2020-04-06 23:27:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Apr  6 23:27:46.313: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9622 /api/v1/namespaces/watch-9622/configmaps/e2e-watch-test-configmap-a 8c91b840-687d-4673-85b4-f9f00d405a18 25088 0 2020-04-06 23:27:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Apr  6 23:27:46.313: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9622 /api/v1/namespaces/watch-9622/configmaps/e2e-watch-test-configmap-a 8c91b840-687d-4673-85b4-f9f00d405a18 25088 0 2020-04-06 23:27:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Apr  6 23:27:56.319: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9622 /api/v1/namespaces/watch-9622/configmaps/e2e-watch-test-configmap-b e433dac6-82cc-4512-800e-1f0f92c1ad3d 25105 0 2020-04-06 23:27:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  6 23:27:56.319: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9622 /api/v1/namespaces/watch-9622/configmaps/e2e-watch-test-configmap-b e433dac6-82cc-4512-800e-1f0f92c1ad3d 25105 0 2020-04-06 23:27:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Apr  6 23:28:06.326: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9622 /api/v1/namespaces/watch-9622/configmaps/e2e-watch-test-configmap-b e433dac6-82cc-4512-800e-1f0f92c1ad3d 25121 0 2020-04-06 23:27:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Apr  6 23:28:06.326: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9622 /api/v1/namespaces/watch-9622/configmaps/e2e-watch-test-configmap-b e433dac6-82cc-4512-800e-1f0f92c1ad3d 25121 0 2020-04-06 23:27:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:28:16.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9622" for this suite.
Apr  6 23:28:22.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:28:22.435: INFO: namespace watch-9622 deletion completed in 6.10464275s

• [SLOW TEST:66.185 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:28:22.435: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Apr  6 23:28:22.702: INFO: Pod name wrapped-volume-race-760e65a5-edae-4fd2-97b0-88aef08623b6: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-760e65a5-edae-4fd2-97b0-88aef08623b6 in namespace emptydir-wrapper-3797, will wait for the garbage collector to delete the pods
Apr  6 23:28:38.837: INFO: Deleting ReplicationController wrapped-volume-race-760e65a5-edae-4fd2-97b0-88aef08623b6 took: 9.902264ms
Apr  6 23:28:39.437: INFO: Terminating ReplicationController wrapped-volume-race-760e65a5-edae-4fd2-97b0-88aef08623b6 pods took: 600.300066ms
STEP: Creating RC which spawns configmap-volume pods
Apr  6 23:29:17.349: INFO: Pod name wrapped-volume-race-c9a383c0-0144-417b-8e52-461ce87870df: Found 0 pods out of 5
Apr  6 23:29:22.355: INFO: Pod name wrapped-volume-race-c9a383c0-0144-417b-8e52-461ce87870df: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-c9a383c0-0144-417b-8e52-461ce87870df in namespace emptydir-wrapper-3797, will wait for the garbage collector to delete the pods
Apr  6 23:29:32.436: INFO: Deleting ReplicationController wrapped-volume-race-c9a383c0-0144-417b-8e52-461ce87870df took: 6.674121ms
Apr  6 23:29:33.037: INFO: Terminating ReplicationController wrapped-volume-race-c9a383c0-0144-417b-8e52-461ce87870df pods took: 600.312898ms
STEP: Creating RC which spawns configmap-volume pods
Apr  6 23:30:16.450: INFO: Pod name wrapped-volume-race-4d5a4801-9e4e-4804-b0a6-47878e6336d4: Found 0 pods out of 5
Apr  6 23:30:21.456: INFO: Pod name wrapped-volume-race-4d5a4801-9e4e-4804-b0a6-47878e6336d4: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-4d5a4801-9e4e-4804-b0a6-47878e6336d4 in namespace emptydir-wrapper-3797, will wait for the garbage collector to delete the pods
Apr  6 23:30:33.553: INFO: Deleting ReplicationController wrapped-volume-race-4d5a4801-9e4e-4804-b0a6-47878e6336d4 took: 11.690299ms
Apr  6 23:30:34.154: INFO: Terminating ReplicationController wrapped-volume-race-4d5a4801-9e4e-4804-b0a6-47878e6336d4 pods took: 600.337716ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:31:17.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3797" for this suite.
Apr  6 23:31:25.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:31:25.181: INFO: namespace emptydir-wrapper-3797 deletion completed in 8.087999121s

• [SLOW TEST:182.745 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:31:25.181: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr  6 23:31:25.211: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c7134994-57e3-4c10-ba03-a27dafc61f6d" in namespace "downward-api-7505" to be "success or failure"
Apr  6 23:31:25.214: INFO: Pod "downwardapi-volume-c7134994-57e3-4c10-ba03-a27dafc61f6d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.617805ms
Apr  6 23:31:27.217: INFO: Pod "downwardapi-volume-c7134994-57e3-4c10-ba03-a27dafc61f6d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00664909s
Apr  6 23:31:29.221: INFO: Pod "downwardapi-volume-c7134994-57e3-4c10-ba03-a27dafc61f6d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009984502s
STEP: Saw pod success
Apr  6 23:31:29.221: INFO: Pod "downwardapi-volume-c7134994-57e3-4c10-ba03-a27dafc61f6d" satisfied condition "success or failure"
Apr  6 23:31:29.223: INFO: Trying to get logs from node 10.0.0.44 pod downwardapi-volume-c7134994-57e3-4c10-ba03-a27dafc61f6d container client-container: <nil>
STEP: delete the pod
Apr  6 23:31:29.250: INFO: Waiting for pod downwardapi-volume-c7134994-57e3-4c10-ba03-a27dafc61f6d to disappear
Apr  6 23:31:29.253: INFO: Pod downwardapi-volume-c7134994-57e3-4c10-ba03-a27dafc61f6d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:31:29.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7505" for this suite.
Apr  6 23:31:35.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:31:35.370: INFO: namespace downward-api-7505 deletion completed in 6.113661842s

• [SLOW TEST:10.190 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:31:35.371: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename tables
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:31:35.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-8378" for this suite.
Apr  6 23:31:41.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:31:41.501: INFO: namespace tables-8378 deletion completed in 6.094646215s

• [SLOW TEST:6.130 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:31:41.501: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename init-container
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Apr  6 23:31:41.527: INFO: PodSpec: initContainers in spec.initContainers
Apr  6 23:32:22.289: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-df02df8f-f85a-4ee6-97c7-6ccc97f33577", GenerateName:"", Namespace:"init-container-60", SelfLink:"/api/v1/namespaces/init-container-60/pods/pod-init-df02df8f-f85a-4ee6-97c7-6ccc97f33577", UID:"33c17f9c-fb52-40c1-9912-3956c8a51b12", ResourceVersion:"26485", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63721812701, loc:(*time.Location)(0x789e8e0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"527552591"}, Annotations:map[string]string(nil), OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-f4ljb", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002690000), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-f4ljb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-f4ljb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-f4ljb", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc0054e2088), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"10.0.0.42", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0025c4000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0054e2110)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc0054e2130)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc0054e2138), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc0054e213c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812701, loc:(*time.Location)(0x789e8e0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812701, loc:(*time.Location)(0x789e8e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812701, loc:(*time.Location)(0x789e8e0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721812701, loc:(*time.Location)(0x789e8e0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.0.0.42", PodIP:"10.20.14.141", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.20.14.141"}}, StartTime:(*v1.Time)(0xc00446e260), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001b1a230)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc001b1a2a0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://8fdc1b0d2f1469f81cf09faf7f8c59061fbd3cc594ae30850b5756ffd4d4bc20", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00446e3a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00446e300), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc0054e21bf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:32:22.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-60" for this suite.
Apr  6 23:32:50.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:32:50.399: INFO: namespace init-container-60 deletion completed in 28.104498052s

• [SLOW TEST:68.898 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:32:50.399: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename emptydir
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Apr  6 23:32:50.431: INFO: Waiting up to 5m0s for pod "pod-792c4d85-5b8d-4105-adb4-9903d34ec711" in namespace "emptydir-2297" to be "success or failure"
Apr  6 23:32:50.444: INFO: Pod "pod-792c4d85-5b8d-4105-adb4-9903d34ec711": Phase="Pending", Reason="", readiness=false. Elapsed: 12.212853ms
Apr  6 23:32:52.447: INFO: Pod "pod-792c4d85-5b8d-4105-adb4-9903d34ec711": Phase="Pending", Reason="", readiness=false. Elapsed: 2.015275267s
Apr  6 23:32:54.450: INFO: Pod "pod-792c4d85-5b8d-4105-adb4-9903d34ec711": Phase="Pending", Reason="", readiness=false. Elapsed: 4.018454174s
Apr  6 23:32:56.453: INFO: Pod "pod-792c4d85-5b8d-4105-adb4-9903d34ec711": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.021444768s
STEP: Saw pod success
Apr  6 23:32:56.453: INFO: Pod "pod-792c4d85-5b8d-4105-adb4-9903d34ec711" satisfied condition "success or failure"
Apr  6 23:32:56.455: INFO: Trying to get logs from node 10.0.0.43 pod pod-792c4d85-5b8d-4105-adb4-9903d34ec711 container test-container: <nil>
STEP: delete the pod
Apr  6 23:32:56.484: INFO: Waiting for pod pod-792c4d85-5b8d-4105-adb4-9903d34ec711 to disappear
Apr  6 23:32:56.486: INFO: Pod pod-792c4d85-5b8d-4105-adb4-9903d34ec711 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:32:56.486: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2297" for this suite.
Apr  6 23:33:02.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:33:02.593: INFO: namespace emptydir-2297 deletion completed in 6.102327824s

• [SLOW TEST:12.194 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:33:02.593: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename prestop
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-5104
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-5104
STEP: Deleting pre-stop pod
Apr  6 23:33:13.650: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:33:13.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-5104" for this suite.
Apr  6 23:33:57.672: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:33:57.780: INFO: namespace prestop-5104 deletion completed in 44.121222126s

• [SLOW TEST:55.187 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:33:57.780: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Apr  6 23:33:57.808: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-273020805 proxy --unix-socket=/tmp/kubectl-proxy-unix876401760/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:33:57.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9312" for this suite.
Apr  6 23:34:03.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:34:03.948: INFO: namespace kubectl-9312 deletion completed in 6.086464072s

• [SLOW TEST:6.168 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:34:03.948: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr  6 23:34:03.979: INFO: Waiting up to 5m0s for pod "downwardapi-volume-35193e27-3e21-4ac9-8e87-caca266682aa" in namespace "projected-7033" to be "success or failure"
Apr  6 23:34:03.982: INFO: Pod "downwardapi-volume-35193e27-3e21-4ac9-8e87-caca266682aa": Phase="Pending", Reason="", readiness=false. Elapsed: 2.471319ms
Apr  6 23:34:05.985: INFO: Pod "downwardapi-volume-35193e27-3e21-4ac9-8e87-caca266682aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00552081s
STEP: Saw pod success
Apr  6 23:34:05.985: INFO: Pod "downwardapi-volume-35193e27-3e21-4ac9-8e87-caca266682aa" satisfied condition "success or failure"
Apr  6 23:34:05.987: INFO: Trying to get logs from node 10.0.0.42 pod downwardapi-volume-35193e27-3e21-4ac9-8e87-caca266682aa container client-container: <nil>
STEP: delete the pod
Apr  6 23:34:06.016: INFO: Waiting for pod downwardapi-volume-35193e27-3e21-4ac9-8e87-caca266682aa to disappear
Apr  6 23:34:06.018: INFO: Pod downwardapi-volume-35193e27-3e21-4ac9-8e87-caca266682aa no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:34:06.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7033" for this suite.
Apr  6 23:34:12.031: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:34:12.111: INFO: namespace projected-7033 deletion completed in 6.089956028s

• [SLOW TEST:8.163 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:34:12.111: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr  6 23:34:15.158: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:34:15.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6264" for this suite.
Apr  6 23:34:21.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:34:21.273: INFO: namespace container-runtime-6264 deletion completed in 6.099142438s

• [SLOW TEST:9.162 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:34:21.274: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 23:34:21.298: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:34:22.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2808" for this suite.
Apr  6 23:34:28.329: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:34:28.401: INFO: namespace custom-resource-definition-2808 deletion completed in 6.083901815s

• [SLOW TEST:7.128 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:34:28.402: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Apr  6 23:34:30.942: INFO: Successfully updated pod "adopt-release-hcvn8"
STEP: Checking that the Job readopts the Pod
Apr  6 23:34:30.942: INFO: Waiting up to 15m0s for pod "adopt-release-hcvn8" in namespace "job-226" to be "adopted"
Apr  6 23:34:30.945: INFO: Pod "adopt-release-hcvn8": Phase="Running", Reason="", readiness=true. Elapsed: 2.506515ms
Apr  6 23:34:32.948: INFO: Pod "adopt-release-hcvn8": Phase="Running", Reason="", readiness=true. Elapsed: 2.00565786s
Apr  6 23:34:32.948: INFO: Pod "adopt-release-hcvn8" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Apr  6 23:34:33.455: INFO: Successfully updated pod "adopt-release-hcvn8"
STEP: Checking that the Job releases the Pod
Apr  6 23:34:33.456: INFO: Waiting up to 15m0s for pod "adopt-release-hcvn8" in namespace "job-226" to be "released"
Apr  6 23:34:33.459: INFO: Pod "adopt-release-hcvn8": Phase="Running", Reason="", readiness=true. Elapsed: 2.834225ms
Apr  6 23:34:35.462: INFO: Pod "adopt-release-hcvn8": Phase="Running", Reason="", readiness=true. Elapsed: 2.005836348s
Apr  6 23:34:35.462: INFO: Pod "adopt-release-hcvn8" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:34:35.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-226" for this suite.
Apr  6 23:35:21.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:35:21.572: INFO: namespace job-226 deletion completed in 46.107007445s

• [SLOW TEST:53.170 seconds]
[sig-apps] Job
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:35:21.573: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-5023
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  6 23:35:21.601: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  6 23:35:47.671: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.20.8.142:8080/dial?request=hostName&protocol=udp&host=10.20.16.140&port=8081&tries=1'] Namespace:pod-network-test-5023 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 23:35:47.671: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 23:35:47.792: INFO: Waiting for endpoints: map[]
Apr  6 23:35:47.795: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.20.8.142:8080/dial?request=hostName&protocol=udp&host=10.20.8.141&port=8081&tries=1'] Namespace:pod-network-test-5023 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 23:35:47.795: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 23:35:47.934: INFO: Waiting for endpoints: map[]
Apr  6 23:35:47.936: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.20.8.142:8080/dial?request=hostName&protocol=udp&host=10.20.14.145&port=8081&tries=1'] Namespace:pod-network-test-5023 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 23:35:47.936: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 23:35:48.062: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:35:48.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5023" for this suite.
Apr  6 23:36:00.076: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:36:00.168: INFO: namespace pod-network-test-5023 deletion completed in 12.100895057s

• [SLOW TEST:38.595 seconds]
[sig-network] Networking
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:36:00.168: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Apr  6 23:36:00.194: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 23:36:02.004: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:36:12.037: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5772" for this suite.
Apr  6 23:36:18.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:36:18.135: INFO: namespace crd-publish-openapi-5772 deletion completed in 6.094500828s

• [SLOW TEST:17.967 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:36:18.136: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-21f67960-9434-4cf0-b819-88ff28ecae69
STEP: Creating a pod to test consume secrets
Apr  6 23:36:18.167: INFO: Waiting up to 5m0s for pod "pod-secrets-a1d22dcc-ce30-4598-b6db-b0391155b412" in namespace "secrets-8804" to be "success or failure"
Apr  6 23:36:18.170: INFO: Pod "pod-secrets-a1d22dcc-ce30-4598-b6db-b0391155b412": Phase="Pending", Reason="", readiness=false. Elapsed: 2.567078ms
Apr  6 23:36:20.173: INFO: Pod "pod-secrets-a1d22dcc-ce30-4598-b6db-b0391155b412": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005915562s
STEP: Saw pod success
Apr  6 23:36:20.173: INFO: Pod "pod-secrets-a1d22dcc-ce30-4598-b6db-b0391155b412" satisfied condition "success or failure"
Apr  6 23:36:20.175: INFO: Trying to get logs from node 10.0.0.44 pod pod-secrets-a1d22dcc-ce30-4598-b6db-b0391155b412 container secret-volume-test: <nil>
STEP: delete the pod
Apr  6 23:36:20.204: INFO: Waiting for pod pod-secrets-a1d22dcc-ce30-4598-b6db-b0391155b412 to disappear
Apr  6 23:36:20.207: INFO: Pod pod-secrets-a1d22dcc-ce30-4598-b6db-b0391155b412 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:36:20.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8804" for this suite.
Apr  6 23:36:26.239: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:36:26.331: INFO: namespace secrets-8804 deletion completed in 6.120668379s

• [SLOW TEST:8.195 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:36:26.331: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  6 23:36:26.680: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  6 23:36:29.698: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 23:36:29.701: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:36:30.808: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2407" for this suite.
Apr  6 23:36:36.821: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:36:36.946: INFO: namespace webhook-2407 deletion completed in 6.133781988s
STEP: Destroying namespace "webhook-2407-markers" for this suite.
Apr  6 23:36:42.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:36:43.043: INFO: namespace webhook-2407-markers deletion completed in 6.097623261s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:16.722 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:36:43.053: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-9f95bbd3-5bc6-45ee-a68e-c16657d6712d
STEP: Creating a pod to test consume configMaps
Apr  6 23:36:43.084: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-9425354e-d8f8-4e9c-87ab-6b71a72d776f" in namespace "projected-6219" to be "success or failure"
Apr  6 23:36:43.087: INFO: Pod "pod-projected-configmaps-9425354e-d8f8-4e9c-87ab-6b71a72d776f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.667628ms
Apr  6 23:36:45.091: INFO: Pod "pod-projected-configmaps-9425354e-d8f8-4e9c-87ab-6b71a72d776f": Phase="Running", Reason="", readiness=true. Elapsed: 2.007058213s
Apr  6 23:36:47.093: INFO: Pod "pod-projected-configmaps-9425354e-d8f8-4e9c-87ab-6b71a72d776f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009605349s
STEP: Saw pod success
Apr  6 23:36:47.093: INFO: Pod "pod-projected-configmaps-9425354e-d8f8-4e9c-87ab-6b71a72d776f" satisfied condition "success or failure"
Apr  6 23:36:47.095: INFO: Trying to get logs from node 10.0.0.42 pod pod-projected-configmaps-9425354e-d8f8-4e9c-87ab-6b71a72d776f container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  6 23:36:47.121: INFO: Waiting for pod pod-projected-configmaps-9425354e-d8f8-4e9c-87ab-6b71a72d776f to disappear
Apr  6 23:36:47.123: INFO: Pod pod-projected-configmaps-9425354e-d8f8-4e9c-87ab-6b71a72d776f no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:36:47.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6219" for this suite.
Apr  6 23:36:53.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:36:53.235: INFO: namespace projected-6219 deletion completed in 6.108656436s

• [SLOW TEST:10.182 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:36:53.235: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Apr  6 23:36:57.792: INFO: Successfully updated pod "annotationupdate8b94f73c-9ede-434e-84b6-977fef2136b3"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:36:59.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6936" for this suite.
Apr  6 23:37:11.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:37:11.927: INFO: namespace projected-6936 deletion completed in 12.107531587s

• [SLOW TEST:18.692 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:37:11.927: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename container-runtime
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Apr  6 23:37:13.971: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:37:13.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4042" for this suite.
Apr  6 23:37:20.000: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:37:20.085: INFO: namespace container-runtime-4042 deletion completed in 6.095025029s

• [SLOW TEST:8.158 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:37:20.086: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename proxy
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-l8rlq in namespace proxy-84
I0406 23:37:20.124525      23 runners.go:184] Created replication controller with name: proxy-service-l8rlq, namespace: proxy-84, replica count: 1
I0406 23:37:21.175562      23 runners.go:184] proxy-service-l8rlq Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I0406 23:37:22.175788      23 runners.go:184] proxy-service-l8rlq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0406 23:37:23.175994      23 runners.go:184] proxy-service-l8rlq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0406 23:37:24.176190      23 runners.go:184] proxy-service-l8rlq Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I0406 23:37:25.176388      23 runners.go:184] proxy-service-l8rlq Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  6 23:37:25.180: INFO: setup took 5.068970372s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Apr  6 23:37:25.185: INFO: (0) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">test</a... (200; 5.572476ms)
Apr  6 23:37:25.185: INFO: (0) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">te... (200; 5.710836ms)
Apr  6 23:37:25.186: INFO: (0) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 6.05131ms)
Apr  6 23:37:25.186: INFO: (0) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 5.974183ms)
Apr  6 23:37:25.186: INFO: (0) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 6.013739ms)
Apr  6 23:37:25.189: INFO: (0) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/rewriteme">test</a> (200; 8.843103ms)
Apr  6 23:37:25.189: INFO: (0) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 8.987767ms)
Apr  6 23:37:25.189: INFO: (0) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname2/proxy/: bar (200; 9.291801ms)
Apr  6 23:37:25.189: INFO: (0) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname2/proxy/: bar (200; 9.489605ms)
Apr  6 23:37:25.189: INFO: (0) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname1/proxy/: foo (200; 9.409503ms)
Apr  6 23:37:25.192: INFO: (0) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname1/proxy/: foo (200; 12.289562ms)
Apr  6 23:37:25.194: INFO: (0) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/tlsrewriteme"... (200; 14.608613ms)
Apr  6 23:37:25.194: INFO: (0) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname2/proxy/: tls qux (200; 14.820674ms)
Apr  6 23:37:25.194: INFO: (0) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:462/proxy/: tls qux (200; 14.724943ms)
Apr  6 23:37:25.195: INFO: (0) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname1/proxy/: tls baz (200; 14.951911ms)
Apr  6 23:37:25.195: INFO: (0) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:460/proxy/: tls baz (200; 14.936523ms)
Apr  6 23:37:25.201: INFO: (1) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 5.983711ms)
Apr  6 23:37:25.201: INFO: (1) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">te... (200; 5.918469ms)
Apr  6 23:37:25.201: INFO: (1) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:462/proxy/: tls qux (200; 5.989553ms)
Apr  6 23:37:25.201: INFO: (1) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname1/proxy/: foo (200; 5.962092ms)
Apr  6 23:37:25.201: INFO: (1) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">test</a... (200; 5.965277ms)
Apr  6 23:37:25.201: INFO: (1) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 6.090203ms)
Apr  6 23:37:25.201: INFO: (1) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/tlsrewriteme"... (200; 5.958334ms)
Apr  6 23:37:25.201: INFO: (1) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/rewriteme">test</a> (200; 6.015903ms)
Apr  6 23:37:25.201: INFO: (1) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 5.988101ms)
Apr  6 23:37:25.201: INFO: (1) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 6.054466ms)
Apr  6 23:37:25.201: INFO: (1) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:460/proxy/: tls baz (200; 6.075195ms)
Apr  6 23:37:25.202: INFO: (1) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname1/proxy/: foo (200; 6.823379ms)
Apr  6 23:37:25.202: INFO: (1) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname2/proxy/: tls qux (200; 6.869855ms)
Apr  6 23:37:25.202: INFO: (1) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname2/proxy/: bar (200; 7.056068ms)
Apr  6 23:37:25.202: INFO: (1) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname1/proxy/: tls baz (200; 7.218294ms)
Apr  6 23:37:25.202: INFO: (1) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname2/proxy/: bar (200; 7.199158ms)
Apr  6 23:37:25.207: INFO: (2) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/tlsrewriteme"... (200; 5.03429ms)
Apr  6 23:37:25.209: INFO: (2) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">te... (200; 6.563908ms)
Apr  6 23:37:25.209: INFO: (2) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:462/proxy/: tls qux (200; 6.590548ms)
Apr  6 23:37:25.209: INFO: (2) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 7.028326ms)
Apr  6 23:37:25.209: INFO: (2) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:460/proxy/: tls baz (200; 7.024769ms)
Apr  6 23:37:25.209: INFO: (2) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/rewriteme">test</a> (200; 7.329063ms)
Apr  6 23:37:25.210: INFO: (2) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">test</a... (200; 7.430435ms)
Apr  6 23:37:25.210: INFO: (2) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 8.153962ms)
Apr  6 23:37:25.212: INFO: (2) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname1/proxy/: tls baz (200; 9.662401ms)
Apr  6 23:37:25.215: INFO: (2) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 13.028219ms)
Apr  6 23:37:25.215: INFO: (2) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 13.111566ms)
Apr  6 23:37:25.215: INFO: (2) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname2/proxy/: tls qux (200; 13.165298ms)
Apr  6 23:37:25.215: INFO: (2) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname1/proxy/: foo (200; 13.155549ms)
Apr  6 23:37:25.215: INFO: (2) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname1/proxy/: foo (200; 13.169385ms)
Apr  6 23:37:25.216: INFO: (2) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname2/proxy/: bar (200; 13.863055ms)
Apr  6 23:37:25.216: INFO: (2) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname2/proxy/: bar (200; 13.764529ms)
Apr  6 23:37:25.220: INFO: (3) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/rewriteme">test</a> (200; 4.36291ms)
Apr  6 23:37:25.241: INFO: (3) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 25.27509ms)
Apr  6 23:37:25.241: INFO: (3) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 25.42234ms)
Apr  6 23:37:25.242: INFO: (3) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">test</a... (200; 25.37557ms)
Apr  6 23:37:25.242: INFO: (3) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 25.329663ms)
Apr  6 23:37:25.242: INFO: (3) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:462/proxy/: tls qux (200; 25.34399ms)
Apr  6 23:37:25.242: INFO: (3) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/tlsrewriteme"... (200; 25.333912ms)
Apr  6 23:37:25.242: INFO: (3) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:460/proxy/: tls baz (200; 25.37606ms)
Apr  6 23:37:25.242: INFO: (3) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 25.331977ms)
Apr  6 23:37:25.242: INFO: (3) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">te... (200; 25.427437ms)
Apr  6 23:37:25.243: INFO: (3) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname2/proxy/: bar (200; 26.494373ms)
Apr  6 23:37:25.243: INFO: (3) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname1/proxy/: tls baz (200; 26.368295ms)
Apr  6 23:37:25.243: INFO: (3) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname2/proxy/: tls qux (200; 26.422377ms)
Apr  6 23:37:25.243: INFO: (3) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname1/proxy/: foo (200; 26.438428ms)
Apr  6 23:37:25.243: INFO: (3) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname1/proxy/: foo (200; 26.760997ms)
Apr  6 23:37:25.243: INFO: (3) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname2/proxy/: bar (200; 26.820349ms)
Apr  6 23:37:25.246: INFO: (4) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">te... (200; 2.913552ms)
Apr  6 23:37:25.249: INFO: (4) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 5.5217ms)
Apr  6 23:37:25.249: INFO: (4) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:462/proxy/: tls qux (200; 5.672264ms)
Apr  6 23:37:25.249: INFO: (4) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 5.852323ms)
Apr  6 23:37:25.249: INFO: (4) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 5.755972ms)
Apr  6 23:37:25.249: INFO: (4) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">test</a... (200; 5.724642ms)
Apr  6 23:37:25.249: INFO: (4) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:460/proxy/: tls baz (200; 5.876871ms)
Apr  6 23:37:25.250: INFO: (4) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 6.816255ms)
Apr  6 23:37:25.250: INFO: (4) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/rewriteme">test</a> (200; 6.869024ms)
Apr  6 23:37:25.250: INFO: (4) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/tlsrewriteme"... (200; 7.045268ms)
Apr  6 23:37:25.251: INFO: (4) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname2/proxy/: tls qux (200; 7.581861ms)
Apr  6 23:37:25.251: INFO: (4) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname1/proxy/: foo (200; 7.6503ms)
Apr  6 23:37:25.251: INFO: (4) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname2/proxy/: bar (200; 7.585768ms)
Apr  6 23:37:25.251: INFO: (4) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname1/proxy/: tls baz (200; 7.58177ms)
Apr  6 23:37:25.251: INFO: (4) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname1/proxy/: foo (200; 7.569998ms)
Apr  6 23:37:25.251: INFO: (4) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname2/proxy/: bar (200; 7.610755ms)
Apr  6 23:37:25.255: INFO: (5) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:462/proxy/: tls qux (200; 3.611952ms)
Apr  6 23:37:25.259: INFO: (5) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 8.468816ms)
Apr  6 23:37:25.259: INFO: (5) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 8.545971ms)
Apr  6 23:37:25.260: INFO: (5) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 8.548907ms)
Apr  6 23:37:25.260: INFO: (5) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">te... (200; 8.755457ms)
Apr  6 23:37:25.260: INFO: (5) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">test</a... (200; 8.816062ms)
Apr  6 23:37:25.260: INFO: (5) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname1/proxy/: tls baz (200; 8.868961ms)
Apr  6 23:37:25.260: INFO: (5) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/tlsrewriteme"... (200; 8.950766ms)
Apr  6 23:37:25.260: INFO: (5) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/rewriteme">test</a> (200; 8.981846ms)
Apr  6 23:37:25.260: INFO: (5) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:460/proxy/: tls baz (200; 8.889231ms)
Apr  6 23:37:25.260: INFO: (5) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 9.006973ms)
Apr  6 23:37:25.261: INFO: (5) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname1/proxy/: foo (200; 9.663303ms)
Apr  6 23:37:25.261: INFO: (5) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname2/proxy/: bar (200; 9.763181ms)
Apr  6 23:37:25.261: INFO: (5) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname2/proxy/: bar (200; 9.737893ms)
Apr  6 23:37:25.261: INFO: (5) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname2/proxy/: tls qux (200; 9.776626ms)
Apr  6 23:37:25.261: INFO: (5) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname1/proxy/: foo (200; 9.75228ms)
Apr  6 23:37:25.267: INFO: (6) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 6.219357ms)
Apr  6 23:37:25.267: INFO: (6) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 6.357158ms)
Apr  6 23:37:25.267: INFO: (6) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:462/proxy/: tls qux (200; 6.16823ms)
Apr  6 23:37:25.267: INFO: (6) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 6.455834ms)
Apr  6 23:37:25.268: INFO: (6) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname1/proxy/: foo (200; 6.621317ms)
Apr  6 23:37:25.268: INFO: (6) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">te... (200; 6.953024ms)
Apr  6 23:37:25.268: INFO: (6) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/rewriteme">test</a> (200; 7.015171ms)
Apr  6 23:37:25.268: INFO: (6) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:460/proxy/: tls baz (200; 7.09928ms)
Apr  6 23:37:25.268: INFO: (6) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 7.108898ms)
Apr  6 23:37:25.268: INFO: (6) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">test</a... (200; 7.460853ms)
Apr  6 23:37:25.269: INFO: (6) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/tlsrewriteme"... (200; 8.152099ms)
Apr  6 23:37:25.269: INFO: (6) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname1/proxy/: foo (200; 8.240817ms)
Apr  6 23:37:25.269: INFO: (6) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname2/proxy/: tls qux (200; 8.178978ms)
Apr  6 23:37:25.269: INFO: (6) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname1/proxy/: tls baz (200; 8.259472ms)
Apr  6 23:37:25.269: INFO: (6) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname2/proxy/: bar (200; 8.3541ms)
Apr  6 23:37:25.269: INFO: (6) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname2/proxy/: bar (200; 8.26454ms)
Apr  6 23:37:25.283: INFO: (7) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 6.748687ms)
Apr  6 23:37:25.283: INFO: (7) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 6.704785ms)
Apr  6 23:37:25.283: INFO: (7) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 6.764436ms)
Apr  6 23:37:25.284: INFO: (7) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 7.213686ms)
Apr  6 23:37:25.284: INFO: (7) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/rewriteme">test</a> (200; 7.330525ms)
Apr  6 23:37:25.284: INFO: (7) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/tlsrewriteme"... (200; 7.244674ms)
Apr  6 23:37:25.284: INFO: (7) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:460/proxy/: tls baz (200; 7.279119ms)
Apr  6 23:37:25.284: INFO: (7) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:462/proxy/: tls qux (200; 7.213636ms)
Apr  6 23:37:25.284: INFO: (7) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">test</a... (200; 7.214216ms)
Apr  6 23:37:25.284: INFO: (7) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">te... (200; 7.540582ms)
Apr  6 23:37:25.287: INFO: (7) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname1/proxy/: foo (200; 10.252124ms)
Apr  6 23:37:25.287: INFO: (7) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname2/proxy/: bar (200; 10.247216ms)
Apr  6 23:37:25.287: INFO: (7) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname2/proxy/: bar (200; 10.515242ms)
Apr  6 23:37:25.287: INFO: (7) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname1/proxy/: foo (200; 10.282843ms)
Apr  6 23:37:25.287: INFO: (7) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname1/proxy/: tls baz (200; 10.275077ms)
Apr  6 23:37:25.287: INFO: (7) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname2/proxy/: tls qux (200; 10.339489ms)
Apr  6 23:37:25.296: INFO: (8) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname2/proxy/: tls qux (200; 8.50785ms)
Apr  6 23:37:25.296: INFO: (8) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">test</a... (200; 8.475668ms)
Apr  6 23:37:25.296: INFO: (8) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 8.572151ms)
Apr  6 23:37:25.296: INFO: (8) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 8.921341ms)
Apr  6 23:37:25.296: INFO: (8) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 8.955073ms)
Apr  6 23:37:25.296: INFO: (8) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 9.020657ms)
Apr  6 23:37:25.296: INFO: (8) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:460/proxy/: tls baz (200; 8.994029ms)
Apr  6 23:37:25.296: INFO: (8) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/tlsrewriteme"... (200; 9.048942ms)
Apr  6 23:37:25.296: INFO: (8) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">te... (200; 8.989349ms)
Apr  6 23:37:25.296: INFO: (8) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:462/proxy/: tls qux (200; 9.009557ms)
Apr  6 23:37:25.296: INFO: (8) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/rewriteme">test</a> (200; 9.033703ms)
Apr  6 23:37:25.297: INFO: (8) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname1/proxy/: foo (200; 10.491576ms)
Apr  6 23:37:25.298: INFO: (8) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname1/proxy/: tls baz (200; 10.423739ms)
Apr  6 23:37:25.298: INFO: (8) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname2/proxy/: bar (200; 10.476528ms)
Apr  6 23:37:25.298: INFO: (8) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname1/proxy/: foo (200; 10.658612ms)
Apr  6 23:37:25.298: INFO: (8) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname2/proxy/: bar (200; 10.543384ms)
Apr  6 23:37:25.301: INFO: (9) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 3.231233ms)
Apr  6 23:37:25.309: INFO: (9) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 11.49897ms)
Apr  6 23:37:25.309: INFO: (9) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:462/proxy/: tls qux (200; 11.600151ms)
Apr  6 23:37:25.309: INFO: (9) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">te... (200; 11.650386ms)
Apr  6 23:37:25.310: INFO: (9) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/rewriteme">test</a> (200; 11.720238ms)
Apr  6 23:37:25.310: INFO: (9) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:460/proxy/: tls baz (200; 12.222446ms)
Apr  6 23:37:25.310: INFO: (9) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">test</a... (200; 12.547691ms)
Apr  6 23:37:25.310: INFO: (9) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/tlsrewriteme"... (200; 12.460105ms)
Apr  6 23:37:25.310: INFO: (9) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 12.582126ms)
Apr  6 23:37:25.310: INFO: (9) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 12.489821ms)
Apr  6 23:37:25.311: INFO: (9) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname2/proxy/: bar (200; 13.560263ms)
Apr  6 23:37:25.311: INFO: (9) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname1/proxy/: foo (200; 13.500209ms)
Apr  6 23:37:25.311: INFO: (9) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname1/proxy/: foo (200; 13.539694ms)
Apr  6 23:37:25.311: INFO: (9) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname1/proxy/: tls baz (200; 13.637699ms)
Apr  6 23:37:25.311: INFO: (9) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname2/proxy/: bar (200; 13.652717ms)
Apr  6 23:37:25.313: INFO: (9) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname2/proxy/: tls qux (200; 14.858335ms)
Apr  6 23:37:25.316: INFO: (10) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 3.813091ms)
Apr  6 23:37:25.320: INFO: (10) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">test</a... (200; 7.323724ms)
Apr  6 23:37:25.320: INFO: (10) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/rewriteme">test</a> (200; 7.33749ms)
Apr  6 23:37:25.320: INFO: (10) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 7.356035ms)
Apr  6 23:37:25.320: INFO: (10) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">te... (200; 7.286443ms)
Apr  6 23:37:25.320: INFO: (10) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:462/proxy/: tls qux (200; 7.472484ms)
Apr  6 23:37:25.320: INFO: (10) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:460/proxy/: tls baz (200; 7.304288ms)
Apr  6 23:37:25.320: INFO: (10) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 7.347177ms)
Apr  6 23:37:25.320: INFO: (10) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/tlsrewriteme"... (200; 7.351205ms)
Apr  6 23:37:25.320: INFO: (10) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 7.525915ms)
Apr  6 23:37:25.321: INFO: (10) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname1/proxy/: foo (200; 8.00047ms)
Apr  6 23:37:25.321: INFO: (10) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname1/proxy/: tls baz (200; 8.341084ms)
Apr  6 23:37:25.321: INFO: (10) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname2/proxy/: tls qux (200; 8.552184ms)
Apr  6 23:37:25.321: INFO: (10) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname2/proxy/: bar (200; 8.493031ms)
Apr  6 23:37:25.322: INFO: (10) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname1/proxy/: foo (200; 8.807176ms)
Apr  6 23:37:25.322: INFO: (10) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname2/proxy/: bar (200; 8.872258ms)
Apr  6 23:37:25.325: INFO: (11) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/rewriteme">test</a> (200; 3.353685ms)
Apr  6 23:37:25.325: INFO: (11) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:462/proxy/: tls qux (200; 3.520009ms)
Apr  6 23:37:25.325: INFO: (11) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">test</a... (200; 3.501484ms)
Apr  6 23:37:25.325: INFO: (11) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/tlsrewriteme"... (200; 3.551338ms)
Apr  6 23:37:25.327: INFO: (11) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 5.011826ms)
Apr  6 23:37:25.327: INFO: (11) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 5.526199ms)
Apr  6 23:37:25.327: INFO: (11) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:460/proxy/: tls baz (200; 5.539543ms)
Apr  6 23:37:25.327: INFO: (11) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 5.609546ms)
Apr  6 23:37:25.327: INFO: (11) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">te... (200; 5.697902ms)
Apr  6 23:37:25.327: INFO: (11) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname2/proxy/: tls qux (200; 5.736405ms)
Apr  6 23:37:25.328: INFO: (11) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname2/proxy/: bar (200; 5.785868ms)
Apr  6 23:37:25.328: INFO: (11) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 5.747425ms)
Apr  6 23:37:25.329: INFO: (11) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname2/proxy/: bar (200; 6.882711ms)
Apr  6 23:37:25.329: INFO: (11) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname1/proxy/: foo (200; 6.876198ms)
Apr  6 23:37:25.329: INFO: (11) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname1/proxy/: tls baz (200; 6.887499ms)
Apr  6 23:37:25.330: INFO: (11) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname1/proxy/: foo (200; 8.612037ms)
Apr  6 23:37:25.337: INFO: (12) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 6.559559ms)
Apr  6 23:37:25.337: INFO: (12) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">test</a... (200; 6.634642ms)
Apr  6 23:37:25.337: INFO: (12) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname1/proxy/: foo (200; 6.744149ms)
Apr  6 23:37:25.337: INFO: (12) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 6.64969ms)
Apr  6 23:37:25.337: INFO: (12) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/tlsrewriteme"... (200; 6.787851ms)
Apr  6 23:37:25.337: INFO: (12) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:462/proxy/: tls qux (200; 6.608712ms)
Apr  6 23:37:25.337: INFO: (12) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 6.696007ms)
Apr  6 23:37:25.337: INFO: (12) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 6.664328ms)
Apr  6 23:37:25.337: INFO: (12) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/rewriteme">test</a> (200; 6.708862ms)
Apr  6 23:37:25.337: INFO: (12) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:460/proxy/: tls baz (200; 6.776089ms)
Apr  6 23:37:25.337: INFO: (12) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">te... (200; 6.644931ms)
Apr  6 23:37:25.341: INFO: (12) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname1/proxy/: foo (200; 10.63061ms)
Apr  6 23:37:25.341: INFO: (12) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname2/proxy/: bar (200; 10.488772ms)
Apr  6 23:37:25.341: INFO: (12) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname1/proxy/: tls baz (200; 10.792716ms)
Apr  6 23:37:25.341: INFO: (12) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname2/proxy/: bar (200; 10.898124ms)
Apr  6 23:37:25.341: INFO: (12) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname2/proxy/: tls qux (200; 10.944642ms)
Apr  6 23:37:25.348: INFO: (13) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 6.057972ms)
Apr  6 23:37:25.348: INFO: (13) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/rewriteme">test</a> (200; 6.178941ms)
Apr  6 23:37:25.348: INFO: (13) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 6.273209ms)
Apr  6 23:37:25.348: INFO: (13) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">test</a... (200; 6.358921ms)
Apr  6 23:37:25.348: INFO: (13) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 6.509335ms)
Apr  6 23:37:25.348: INFO: (13) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 6.478677ms)
Apr  6 23:37:25.348: INFO: (13) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname1/proxy/: tls baz (200; 6.481342ms)
Apr  6 23:37:25.348: INFO: (13) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/tlsrewriteme"... (200; 6.41106ms)
Apr  6 23:37:25.348: INFO: (13) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">te... (200; 6.601259ms)
Apr  6 23:37:25.348: INFO: (13) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:460/proxy/: tls baz (200; 6.425497ms)
Apr  6 23:37:25.348: INFO: (13) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:462/proxy/: tls qux (200; 6.430406ms)
Apr  6 23:37:25.349: INFO: (13) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname1/proxy/: foo (200; 7.715191ms)
Apr  6 23:37:25.350: INFO: (13) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname1/proxy/: foo (200; 7.833847ms)
Apr  6 23:37:25.350: INFO: (13) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname2/proxy/: tls qux (200; 7.912074ms)
Apr  6 23:37:25.350: INFO: (13) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname2/proxy/: bar (200; 7.836631ms)
Apr  6 23:37:25.350: INFO: (13) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname2/proxy/: bar (200; 7.809921ms)
Apr  6 23:37:25.353: INFO: (14) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:460/proxy/: tls baz (200; 2.867586ms)
Apr  6 23:37:25.358: INFO: (14) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">test</a... (200; 8.393223ms)
Apr  6 23:37:25.358: INFO: (14) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 8.249702ms)
Apr  6 23:37:25.358: INFO: (14) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 8.293594ms)
Apr  6 23:37:25.358: INFO: (14) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">te... (200; 8.386912ms)
Apr  6 23:37:25.358: INFO: (14) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/tlsrewriteme"... (200; 8.279469ms)
Apr  6 23:37:25.358: INFO: (14) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 8.43888ms)
Apr  6 23:37:25.358: INFO: (14) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/rewriteme">test</a> (200; 8.322029ms)
Apr  6 23:37:25.358: INFO: (14) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 8.32285ms)
Apr  6 23:37:25.358: INFO: (14) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:462/proxy/: tls qux (200; 8.399094ms)
Apr  6 23:37:25.362: INFO: (14) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname2/proxy/: tls qux (200; 12.178363ms)
Apr  6 23:37:25.362: INFO: (14) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname1/proxy/: foo (200; 12.193872ms)
Apr  6 23:37:25.362: INFO: (14) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname1/proxy/: tls baz (200; 12.258454ms)
Apr  6 23:37:25.362: INFO: (14) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname2/proxy/: bar (200; 12.246861ms)
Apr  6 23:37:25.362: INFO: (14) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname2/proxy/: bar (200; 12.321273ms)
Apr  6 23:37:25.362: INFO: (14) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname1/proxy/: foo (200; 12.270678ms)
Apr  6 23:37:25.366: INFO: (15) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/rewriteme">test</a> (200; 3.734414ms)
Apr  6 23:37:25.368: INFO: (15) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 5.681222ms)
Apr  6 23:37:25.368: INFO: (15) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">test</a... (200; 5.806487ms)
Apr  6 23:37:25.368: INFO: (15) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 5.802821ms)
Apr  6 23:37:25.368: INFO: (15) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:462/proxy/: tls qux (200; 5.774245ms)
Apr  6 23:37:25.368: INFO: (15) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:460/proxy/: tls baz (200; 5.879165ms)
Apr  6 23:37:25.368: INFO: (15) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/tlsrewriteme"... (200; 5.882893ms)
Apr  6 23:37:25.368: INFO: (15) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 5.921044ms)
Apr  6 23:37:25.368: INFO: (15) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">te... (200; 5.914922ms)
Apr  6 23:37:25.368: INFO: (15) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 5.899532ms)
Apr  6 23:37:25.369: INFO: (15) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname1/proxy/: tls baz (200; 7.204447ms)
Apr  6 23:37:25.371: INFO: (15) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname2/proxy/: bar (200; 9.248038ms)
Apr  6 23:37:25.371: INFO: (15) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname1/proxy/: foo (200; 9.208863ms)
Apr  6 23:37:25.371: INFO: (15) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname1/proxy/: foo (200; 9.276031ms)
Apr  6 23:37:25.371: INFO: (15) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname2/proxy/: bar (200; 9.410826ms)
Apr  6 23:37:25.371: INFO: (15) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname2/proxy/: tls qux (200; 9.266212ms)
Apr  6 23:37:25.376: INFO: (16) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 3.995737ms)
Apr  6 23:37:25.378: INFO: (16) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 5.806948ms)
Apr  6 23:37:25.378: INFO: (16) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:462/proxy/: tls qux (200; 6.011445ms)
Apr  6 23:37:25.378: INFO: (16) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">test</a... (200; 6.316391ms)
Apr  6 23:37:25.378: INFO: (16) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/rewriteme">test</a> (200; 6.328944ms)
Apr  6 23:37:25.378: INFO: (16) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 6.392024ms)
Apr  6 23:37:25.378: INFO: (16) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/tlsrewriteme"... (200; 6.421409ms)
Apr  6 23:37:25.378: INFO: (16) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">te... (200; 6.544632ms)
Apr  6 23:37:25.378: INFO: (16) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:460/proxy/: tls baz (200; 6.465733ms)
Apr  6 23:37:25.378: INFO: (16) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 6.548379ms)
Apr  6 23:37:25.381: INFO: (16) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname2/proxy/: bar (200; 9.077175ms)
Apr  6 23:37:25.381: INFO: (16) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname2/proxy/: tls qux (200; 9.595083ms)
Apr  6 23:37:25.381: INFO: (16) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname2/proxy/: bar (200; 9.512047ms)
Apr  6 23:37:25.381: INFO: (16) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname1/proxy/: foo (200; 9.735058ms)
Apr  6 23:37:25.381: INFO: (16) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname1/proxy/: tls baz (200; 9.686537ms)
Apr  6 23:37:25.381: INFO: (16) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname1/proxy/: foo (200; 9.69348ms)
Apr  6 23:37:25.388: INFO: (17) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">test</a... (200; 6.335766ms)
Apr  6 23:37:25.389: INFO: (17) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:462/proxy/: tls qux (200; 7.09995ms)
Apr  6 23:37:25.389: INFO: (17) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 7.179671ms)
Apr  6 23:37:25.389: INFO: (17) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/rewriteme">test</a> (200; 7.172668ms)
Apr  6 23:37:25.389: INFO: (17) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname1/proxy/: foo (200; 7.186153ms)
Apr  6 23:37:25.389: INFO: (17) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 7.195561ms)
Apr  6 23:37:25.389: INFO: (17) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 7.474828ms)
Apr  6 23:37:25.389: INFO: (17) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/tlsrewriteme"... (200; 7.541585ms)
Apr  6 23:37:25.389: INFO: (17) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:460/proxy/: tls baz (200; 7.500046ms)
Apr  6 23:37:25.389: INFO: (17) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 7.959224ms)
Apr  6 23:37:25.389: INFO: (17) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">te... (200; 7.956649ms)
Apr  6 23:37:25.389: INFO: (17) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname1/proxy/: tls baz (200; 8.063219ms)
Apr  6 23:37:25.389: INFO: (17) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname2/proxy/: tls qux (200; 7.997385ms)
Apr  6 23:37:25.390: INFO: (17) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname2/proxy/: bar (200; 8.193757ms)
Apr  6 23:37:25.390: INFO: (17) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname2/proxy/: bar (200; 8.314925ms)
Apr  6 23:37:25.390: INFO: (17) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname1/proxy/: foo (200; 8.14836ms)
Apr  6 23:37:25.394: INFO: (18) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/tlsrewriteme"... (200; 3.829313ms)
Apr  6 23:37:25.396: INFO: (18) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:460/proxy/: tls baz (200; 6.051951ms)
Apr  6 23:37:25.396: INFO: (18) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname1/proxy/: foo (200; 6.195583ms)
Apr  6 23:37:25.396: INFO: (18) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 6.376533ms)
Apr  6 23:37:25.396: INFO: (18) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 6.416359ms)
Apr  6 23:37:25.396: INFO: (18) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:462/proxy/: tls qux (200; 6.401271ms)
Apr  6 23:37:25.396: INFO: (18) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 6.483927ms)
Apr  6 23:37:25.397: INFO: (18) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/rewriteme">test</a> (200; 6.608092ms)
Apr  6 23:37:25.397: INFO: (18) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">te... (200; 6.603684ms)
Apr  6 23:37:25.397: INFO: (18) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">test</a... (200; 6.726765ms)
Apr  6 23:37:25.397: INFO: (18) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 6.72328ms)
Apr  6 23:37:25.398: INFO: (18) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname2/proxy/: tls qux (200; 7.537908ms)
Apr  6 23:37:25.398: INFO: (18) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname2/proxy/: bar (200; 7.60765ms)
Apr  6 23:37:25.398: INFO: (18) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname2/proxy/: bar (200; 7.892096ms)
Apr  6 23:37:25.398: INFO: (18) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname1/proxy/: foo (200; 8.193898ms)
Apr  6 23:37:25.398: INFO: (18) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname1/proxy/: tls baz (200; 8.188046ms)
Apr  6 23:37:25.407: INFO: (19) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 3.113711ms)
Apr  6 23:37:25.409: INFO: (19) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:160/proxy/: foo (200; 5.393768ms)
Apr  6 23:37:25.410: INFO: (19) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:462/proxy/: tls qux (200; 5.740733ms)
Apr  6 23:37:25.410: INFO: (19) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk/proxy/rewriteme">test</a> (200; 5.714724ms)
Apr  6 23:37:25.410: INFO: (19) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">test</a... (200; 5.701249ms)
Apr  6 23:37:25.410: INFO: (19) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:1080/proxy/rewriteme">te... (200; 5.728671ms)
Apr  6 23:37:25.410: INFO: (19) /api/v1/namespaces/proxy-84/pods/http:proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 5.730684ms)
Apr  6 23:37:25.410: INFO: (19) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/: <a href="/api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:443/proxy/tlsrewriteme"... (200; 5.904363ms)
Apr  6 23:37:25.410: INFO: (19) /api/v1/namespaces/proxy-84/pods/proxy-service-l8rlq-rpsnk:162/proxy/: bar (200; 5.742205ms)
Apr  6 23:37:25.410: INFO: (19) /api/v1/namespaces/proxy-84/pods/https:proxy-service-l8rlq-rpsnk:460/proxy/: tls baz (200; 5.823709ms)
Apr  6 23:37:25.413: INFO: (19) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname2/proxy/: tls qux (200; 8.945938ms)
Apr  6 23:37:25.413: INFO: (19) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname1/proxy/: foo (200; 9.042681ms)
Apr  6 23:37:25.413: INFO: (19) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname1/proxy/: foo (200; 9.103314ms)
Apr  6 23:37:25.413: INFO: (19) /api/v1/namespaces/proxy-84/services/https:proxy-service-l8rlq:tlsportname1/proxy/: tls baz (200; 9.258558ms)
Apr  6 23:37:25.413: INFO: (19) /api/v1/namespaces/proxy-84/services/proxy-service-l8rlq:portname2/proxy/: bar (200; 9.336745ms)
Apr  6 23:37:25.413: INFO: (19) /api/v1/namespaces/proxy-84/services/http:proxy-service-l8rlq:portname2/proxy/: bar (200; 9.30238ms)
STEP: deleting ReplicationController proxy-service-l8rlq in namespace proxy-84, will wait for the garbage collector to delete the pods
Apr  6 23:37:25.474: INFO: Deleting ReplicationController proxy-service-l8rlq took: 7.892367ms
Apr  6 23:37:26.074: INFO: Terminating ReplicationController proxy-service-l8rlq pods took: 600.28704ms
[AfterEach] version v1
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:37:36.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-84" for this suite.
Apr  6 23:37:42.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:37:42.486: INFO: namespace proxy-84 deletion completed in 6.107969072s

• [SLOW TEST:22.401 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:37:42.486: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename job
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:37:48.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7937" for this suite.
Apr  6 23:37:54.534: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:37:54.631: INFO: namespace job-7937 deletion completed in 6.109189948s

• [SLOW TEST:12.145 seconds]
[sig-apps] Job
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:37:54.631: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:38:05.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5548" for this suite.
Apr  6 23:38:11.719: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:38:11.831: INFO: namespace resourcequota-5548 deletion completed in 6.125151871s

• [SLOW TEST:17.200 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:38:11.831: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  6 23:38:12.126: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr  6 23:38:14.134: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721813092, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721813092, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721813092, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721813092, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  6 23:38:17.147: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 23:38:17.151: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5808-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:38:18.229: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-157" for this suite.
Apr  6 23:38:24.243: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:38:24.334: INFO: namespace webhook-157 deletion completed in 6.10064457s
STEP: Destroying namespace "webhook-157-markers" for this suite.
Apr  6 23:38:30.346: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:38:30.445: INFO: namespace webhook-157-markers deletion completed in 6.111378056s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.626 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:38:30.457: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Apr  6 23:38:30.484: INFO: namespace kubectl-3140
Apr  6 23:38:30.484: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 create -f - --namespace=kubectl-3140'
Apr  6 23:38:31.184: INFO: stderr: ""
Apr  6 23:38:31.184: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Apr  6 23:38:32.187: INFO: Selector matched 1 pods for map[app:redis]
Apr  6 23:38:32.187: INFO: Found 0 / 1
Apr  6 23:38:33.187: INFO: Selector matched 1 pods for map[app:redis]
Apr  6 23:38:33.187: INFO: Found 1 / 1
Apr  6 23:38:33.187: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Apr  6 23:38:33.192: INFO: Selector matched 1 pods for map[app:redis]
Apr  6 23:38:33.192: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Apr  6 23:38:33.192: INFO: wait on redis-master startup in kubectl-3140 
Apr  6 23:38:33.192: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 logs redis-master-bvxqh redis-master --namespace=kubectl-3140'
Apr  6 23:38:33.282: INFO: stderr: ""
Apr  6 23:38:33.282: INFO: stdout: "1:C 06 Apr 2020 23:38:32.179 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 06 Apr 2020 23:38:32.179 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 06 Apr 2020 23:38:32.179 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 06 Apr 2020 23:38:32.180 * Running mode=standalone, port=6379.\n1:M 06 Apr 2020 23:38:32.180 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 06 Apr 2020 23:38:32.180 # Server initialized\n1:M 06 Apr 2020 23:38:32.181 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 06 Apr 2020 23:38:32.181 * Ready to accept connections\n"
STEP: exposing RC
Apr  6 23:38:33.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-3140'
Apr  6 23:38:33.372: INFO: stderr: ""
Apr  6 23:38:33.372: INFO: stdout: "service/rm2 exposed\n"
Apr  6 23:38:33.375: INFO: Service rm2 in namespace kubectl-3140 found.
STEP: exposing service
Apr  6 23:38:35.380: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-3140'
Apr  6 23:38:35.477: INFO: stderr: ""
Apr  6 23:38:35.477: INFO: stdout: "service/rm3 exposed\n"
Apr  6 23:38:35.480: INFO: Service rm3 in namespace kubectl-3140 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:38:37.485: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3140" for this suite.
Apr  6 23:38:49.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:38:49.577: INFO: namespace kubectl-3140 deletion completed in 12.088915953s

• [SLOW TEST:19.120 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:38:49.577: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Apr  6 23:38:49.602: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0de3e80c-2ace-40cd-af54-1d6d154be6e4" in namespace "downward-api-2105" to be "success or failure"
Apr  6 23:38:49.607: INFO: Pod "downwardapi-volume-0de3e80c-2ace-40cd-af54-1d6d154be6e4": Phase="Pending", Reason="", readiness=false. Elapsed: 5.232782ms
Apr  6 23:38:51.609: INFO: Pod "downwardapi-volume-0de3e80c-2ace-40cd-af54-1d6d154be6e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007694216s
STEP: Saw pod success
Apr  6 23:38:51.609: INFO: Pod "downwardapi-volume-0de3e80c-2ace-40cd-af54-1d6d154be6e4" satisfied condition "success or failure"
Apr  6 23:38:51.611: INFO: Trying to get logs from node 10.0.0.43 pod downwardapi-volume-0de3e80c-2ace-40cd-af54-1d6d154be6e4 container client-container: <nil>
STEP: delete the pod
Apr  6 23:38:51.634: INFO: Waiting for pod downwardapi-volume-0de3e80c-2ace-40cd-af54-1d6d154be6e4 to disappear
Apr  6 23:38:51.636: INFO: Pod downwardapi-volume-0de3e80c-2ace-40cd-af54-1d6d154be6e4 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:38:51.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2105" for this suite.
Apr  6 23:38:57.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:38:57.737: INFO: namespace downward-api-2105 deletion completed in 6.097253239s

• [SLOW TEST:8.160 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:38:57.738: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename sched-pred
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Apr  6 23:38:57.770: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Apr  6 23:38:57.780: INFO: Waiting for terminating namespaces to be deleted...
Apr  6 23:38:57.782: INFO: 
Logging pods the kubelet thinks is on node 10.0.0.42 before test
Apr  6 23:38:57.788: INFO: kube-state-metrics-595cb5cc-hkr95 from pf9-monitoring started at 2020-04-06 21:53:20 +0000 UTC (1 container statuses recorded)
Apr  6 23:38:57.788: INFO: 	Container kube-state-metrics ready: true, restart count 0
Apr  6 23:38:57.788: INFO: node-exporter-q8z8v from pf9-monitoring started at 2020-04-06 21:53:24 +0000 UTC (1 container statuses recorded)
Apr  6 23:38:57.788: INFO: 	Container node-exporter ready: true, restart count 0
Apr  6 23:38:57.788: INFO: prometheus-operator-546b677c-8nsvj from pf9-operators started at 2020-04-06 22:08:44 +0000 UTC (1 container statuses recorded)
Apr  6 23:38:57.788: INFO: 	Container prometheus-operator ready: true, restart count 0
Apr  6 23:38:57.788: INFO: sonobuoy from sonobuoy started at 2020-04-06 21:55:11 +0000 UTC (1 container statuses recorded)
Apr  6 23:38:57.788: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Apr  6 23:38:57.788: INFO: olm-operator-76d446f94c-rhq8h from pf9-olm started at 2020-04-06 21:53:11 +0000 UTC (1 container statuses recorded)
Apr  6 23:38:57.788: INFO: 	Container olm-operator ready: true, restart count 0
Apr  6 23:38:57.788: INFO: sonobuoy-systemd-logs-daemon-set-3f2ae32d33c24b28-z5vfz from sonobuoy started at 2020-04-06 21:55:15 +0000 UTC (2 container statuses recorded)
Apr  6 23:38:57.788: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr  6 23:38:57.788: INFO: 	Container systemd-logs ready: true, restart count 0
Apr  6 23:38:57.788: INFO: comms-proxy-f9jz2 from pf9-monitoring started at 2020-04-06 22:08:48 +0000 UTC (1 container statuses recorded)
Apr  6 23:38:57.788: INFO: 	Container envoy ready: true, restart count 0
Apr  6 23:38:57.788: INFO: 
Logging pods the kubelet thinks is on node 10.0.0.43 before test
Apr  6 23:38:57.794: INFO: grafana-86dfdd45b7-78rmr from pf9-monitoring started at 2020-04-06 22:09:29 +0000 UTC (2 container statuses recorded)
Apr  6 23:38:57.794: INFO: 	Container grafana ready: true, restart count 0
Apr  6 23:38:57.794: INFO: 	Container proxy ready: true, restart count 0
Apr  6 23:38:57.794: INFO: sonobuoy-systemd-logs-daemon-set-3f2ae32d33c24b28-2j6sr from sonobuoy started at 2020-04-06 21:55:15 +0000 UTC (2 container statuses recorded)
Apr  6 23:38:57.794: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr  6 23:38:57.794: INFO: 	Container systemd-logs ready: true, restart count 0
Apr  6 23:38:57.794: INFO: catalog-operator-5898bbb7d6-86vpd from pf9-olm started at 2020-04-06 21:53:10 +0000 UTC (1 container statuses recorded)
Apr  6 23:38:57.794: INFO: 	Container catalog-operator ready: true, restart count 0
Apr  6 23:38:57.794: INFO: comms-proxy-gpw8d from pf9-monitoring started at 2020-04-06 22:08:48 +0000 UTC (1 container statuses recorded)
Apr  6 23:38:57.794: INFO: 	Container envoy ready: true, restart count 0
Apr  6 23:38:57.794: INFO: prometheus-system-0 from pf9-monitoring started at 2020-04-06 22:09:29 +0000 UTC (3 container statuses recorded)
Apr  6 23:38:57.794: INFO: 	Container prometheus ready: true, restart count 1
Apr  6 23:38:57.794: INFO: 	Container prometheus-config-reloader ready: true, restart count 0
Apr  6 23:38:57.794: INFO: 	Container rules-configmap-reloader ready: true, restart count 0
Apr  6 23:38:57.794: INFO: packageserver-7799547bfb-ztvbk from pf9-olm started at 2020-04-06 21:53:29 +0000 UTC (1 container statuses recorded)
Apr  6 23:38:57.794: INFO: 	Container packageserver ready: true, restart count 0
Apr  6 23:38:57.794: INFO: node-exporter-xl5fz from pf9-monitoring started at 2020-04-06 21:53:24 +0000 UTC (1 container statuses recorded)
Apr  6 23:38:57.794: INFO: 	Container node-exporter ready: true, restart count 0
Apr  6 23:38:57.794: INFO: 
Logging pods the kubelet thinks is on node 10.0.0.44 before test
Apr  6 23:38:57.806: INFO: comms-proxy-28brb from pf9-monitoring started at 2020-04-06 22:08:48 +0000 UTC (1 container statuses recorded)
Apr  6 23:38:57.806: INFO: 	Container envoy ready: true, restart count 0
Apr  6 23:38:57.806: INFO: alertmanager-sysalert-0 from pf9-monitoring started at 2020-04-06 22:09:29 +0000 UTC (2 container statuses recorded)
Apr  6 23:38:57.806: INFO: 	Container alertmanager ready: true, restart count 0
Apr  6 23:38:57.806: INFO: 	Container config-reloader ready: true, restart count 0
Apr  6 23:38:57.806: INFO: monhelper-666465d6b5-8t499 from pf9-operators started at 2020-04-06 22:08:44 +0000 UTC (1 container statuses recorded)
Apr  6 23:38:57.806: INFO: 	Container monhelper ready: true, restart count 0
Apr  6 23:38:57.806: INFO: node-exporter-w7m2g from pf9-monitoring started at 2020-04-06 21:53:24 +0000 UTC (1 container statuses recorded)
Apr  6 23:38:57.806: INFO: 	Container node-exporter ready: true, restart count 0
Apr  6 23:38:57.806: INFO: sonobuoy-systemd-logs-daemon-set-3f2ae32d33c24b28-cst5h from sonobuoy started at 2020-04-06 21:55:15 +0000 UTC (2 container statuses recorded)
Apr  6 23:38:57.806: INFO: 	Container sonobuoy-worker ready: true, restart count 1
Apr  6 23:38:57.806: INFO: 	Container systemd-logs ready: true, restart count 0
Apr  6 23:38:57.806: INFO: platform9-operators-z62nw from pf9-olm started at 2020-04-06 21:53:38 +0000 UTC (1 container statuses recorded)
Apr  6 23:38:57.806: INFO: 	Container registry-server ready: true, restart count 0
Apr  6 23:38:57.806: INFO: sonobuoy-e2e-job-c807e2fec0184d0b from sonobuoy started at 2020-04-06 21:55:15 +0000 UTC (2 container statuses recorded)
Apr  6 23:38:57.806: INFO: 	Container e2e ready: true, restart count 0
Apr  6 23:38:57.806: INFO: 	Container sonobuoy-worker ready: true, restart count 0
Apr  6 23:38:57.806: INFO: packageserver-7799547bfb-5vjt4 from pf9-olm started at 2020-04-06 21:53:20 +0000 UTC (1 container statuses recorded)
Apr  6 23:38:57.806: INFO: 	Container packageserver ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-742d2d7a-1d9f-48f8-b641-0c3228e853af 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-742d2d7a-1d9f-48f8-b641-0c3228e853af off the node 10.0.0.43
STEP: verifying the node doesn't have the label kubernetes.io/e2e-742d2d7a-1d9f-48f8-b641-0c3228e853af
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:39:09.883: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5678" for this suite.
Apr  6 23:39:39.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:39:39.995: INFO: namespace sched-pred-5678 deletion completed in 30.108738443s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:42.257 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:39:39.995: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename services
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-9779
STEP: creating replication controller nodeport-test in namespace services-9779
I0406 23:39:40.044138      23 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-9779, replica count: 2
Apr  6 23:39:43.094: INFO: Creating new exec pod
I0406 23:39:43.094544      23 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Apr  6 23:39:46.110: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=services-9779 execpodxc9bw -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Apr  6 23:39:46.311: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Apr  6 23:39:46.311: INFO: stdout: ""
Apr  6 23:39:46.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=services-9779 execpodxc9bw -- /bin/sh -x -c nc -zv -t -w 2 10.21.18.242 80'
Apr  6 23:39:46.514: INFO: stderr: "+ nc -zv -t -w 2 10.21.18.242 80\nConnection to 10.21.18.242 80 port [tcp/http] succeeded!\n"
Apr  6 23:39:46.514: INFO: stdout: ""
Apr  6 23:39:46.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=services-9779 execpodxc9bw -- /bin/sh -x -c nc -zv -t -w 2 10.0.0.42 31778'
Apr  6 23:39:46.728: INFO: stderr: "+ nc -zv -t -w 2 10.0.0.42 31778\nConnection to 10.0.0.42 31778 port [tcp/31778] succeeded!\n"
Apr  6 23:39:46.728: INFO: stdout: ""
Apr  6 23:39:46.729: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 exec --namespace=services-9779 execpodxc9bw -- /bin/sh -x -c nc -zv -t -w 2 10.0.0.43 31778'
Apr  6 23:39:46.920: INFO: stderr: "+ nc -zv -t -w 2 10.0.0.43 31778\nConnection to 10.0.0.43 31778 port [tcp/31778] succeeded!\n"
Apr  6 23:39:46.920: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:39:46.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9779" for this suite.
Apr  6 23:39:52.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:39:53.011: INFO: namespace services-9779 deletion completed in 6.086620397s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:13.016 seconds]
[sig-network] Services
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:39:53.011: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Apr  6 23:39:53.043: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 create -f - --namespace=kubectl-2315'
Apr  6 23:39:53.191: INFO: stderr: ""
Apr  6 23:39:53.191: INFO: stdout: "pod/pause created\n"
Apr  6 23:39:53.191: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Apr  6 23:39:53.191: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-2315" to be "running and ready"
Apr  6 23:39:53.194: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.752419ms
Apr  6 23:39:55.197: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.005998272s
Apr  6 23:39:55.197: INFO: Pod "pause" satisfied condition "running and ready"
Apr  6 23:39:55.197: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Apr  6 23:39:55.197: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 label pods pause testing-label=testing-label-value --namespace=kubectl-2315'
Apr  6 23:39:55.272: INFO: stderr: ""
Apr  6 23:39:55.272: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Apr  6 23:39:55.272: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pod pause -L testing-label --namespace=kubectl-2315'
Apr  6 23:39:55.343: INFO: stderr: ""
Apr  6 23:39:55.343: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Apr  6 23:39:55.343: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 label pods pause testing-label- --namespace=kubectl-2315'
Apr  6 23:39:55.422: INFO: stderr: ""
Apr  6 23:39:55.422: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Apr  6 23:39:55.422: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pod pause -L testing-label --namespace=kubectl-2315'
Apr  6 23:39:55.492: INFO: stderr: ""
Apr  6 23:39:55.492: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Apr  6 23:39:55.492: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 delete --grace-period=0 --force -f - --namespace=kubectl-2315'
Apr  6 23:39:55.568: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Apr  6 23:39:55.568: INFO: stdout: "pod \"pause\" force deleted\n"
Apr  6 23:39:55.568: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get rc,svc -l name=pause --no-headers --namespace=kubectl-2315'
Apr  6 23:39:55.644: INFO: stderr: "No resources found in kubectl-2315 namespace.\n"
Apr  6 23:39:55.644: INFO: stdout: ""
Apr  6 23:39:55.644: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 get pods -l name=pause --namespace=kubectl-2315 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Apr  6 23:39:55.715: INFO: stderr: ""
Apr  6 23:39:55.715: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:39:55.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2315" for this suite.
Apr  6 23:40:01.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:40:01.811: INFO: namespace kubectl-2315 deletion completed in 6.091667906s

• [SLOW TEST:8.801 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:40:01.811: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename secrets
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-da3227f7-0762-45a4-9699-0f2e4a0904b8
STEP: Creating a pod to test consume secrets
Apr  6 23:40:01.842: INFO: Waiting up to 5m0s for pod "pod-secrets-8d346572-043a-484c-84b8-4a8401a76e68" in namespace "secrets-4807" to be "success or failure"
Apr  6 23:40:01.844: INFO: Pod "pod-secrets-8d346572-043a-484c-84b8-4a8401a76e68": Phase="Pending", Reason="", readiness=false. Elapsed: 2.567179ms
Apr  6 23:40:03.848: INFO: Pod "pod-secrets-8d346572-043a-484c-84b8-4a8401a76e68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.005983399s
STEP: Saw pod success
Apr  6 23:40:03.848: INFO: Pod "pod-secrets-8d346572-043a-484c-84b8-4a8401a76e68" satisfied condition "success or failure"
Apr  6 23:40:03.850: INFO: Trying to get logs from node 10.0.0.44 pod pod-secrets-8d346572-043a-484c-84b8-4a8401a76e68 container secret-env-test: <nil>
STEP: delete the pod
Apr  6 23:40:03.868: INFO: Waiting for pod pod-secrets-8d346572-043a-484c-84b8-4a8401a76e68 to disappear
Apr  6 23:40:03.871: INFO: Pod pod-secrets-8d346572-043a-484c-84b8-4a8401a76e68 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:40:03.871: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4807" for this suite.
Apr  6 23:40:09.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:40:09.966: INFO: namespace secrets-4807 deletion completed in 6.089468482s

• [SLOW TEST:8.154 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:40:09.966: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  6 23:40:10.389: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  6 23:40:13.405: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:40:13.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8164" for this suite.
Apr  6 23:40:19.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:40:19.683: INFO: namespace webhook-8164 deletion completed in 6.093134242s
STEP: Destroying namespace "webhook-8164-markers" for this suite.
Apr  6 23:40:25.691: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:40:25.778: INFO: namespace webhook-8164-markers deletion completed in 6.095285023s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:15.832 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:40:25.798: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename pods
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 23:40:27.864: INFO: Waiting up to 5m0s for pod "client-envvars-b70054ba-354f-44ec-be28-3ee2939334db" in namespace "pods-4553" to be "success or failure"
Apr  6 23:40:27.869: INFO: Pod "client-envvars-b70054ba-354f-44ec-be28-3ee2939334db": Phase="Pending", Reason="", readiness=false. Elapsed: 4.620456ms
Apr  6 23:40:29.871: INFO: Pod "client-envvars-b70054ba-354f-44ec-be28-3ee2939334db": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007468421s
STEP: Saw pod success
Apr  6 23:40:29.871: INFO: Pod "client-envvars-b70054ba-354f-44ec-be28-3ee2939334db" satisfied condition "success or failure"
Apr  6 23:40:29.874: INFO: Trying to get logs from node 10.0.0.42 pod client-envvars-b70054ba-354f-44ec-be28-3ee2939334db container env3cont: <nil>
STEP: delete the pod
Apr  6 23:40:29.904: INFO: Waiting for pod client-envvars-b70054ba-354f-44ec-be28-3ee2939334db to disappear
Apr  6 23:40:29.907: INFO: Pod client-envvars-b70054ba-354f-44ec-be28-3ee2939334db no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:40:29.907: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4553" for this suite.
Apr  6 23:40:41.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:40:42.021: INFO: namespace pods-4553 deletion completed in 12.110009181s

• [SLOW TEST:16.223 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:40:42.021: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename kubectl
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Apr  6 23:40:42.048: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-273020805 version'
Apr  6 23:40:42.117: INFO: stderr: ""
Apr  6 23:40:42.118: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.8\", GitCommit:\"ec6eb119b81be488b030e849b9e64fda4caaf33c\", GitTreeState:\"clean\", BuildDate:\"2020-03-12T21:00:06Z\", GoVersion:\"go1.13.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.8\", GitCommit:\"ec6eb119b81be488b030e849b9e64fda4caaf33c\", GitTreeState:\"clean\", BuildDate:\"2020-03-12T20:52:22Z\", GoVersion:\"go1.13.8\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:40:42.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6258" for this suite.
Apr  6 23:40:48.131: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:40:48.213: INFO: namespace kubectl-6258 deletion completed in 6.091905373s

• [SLOW TEST:6.192 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:40:48.213: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename resourcequota
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:41:01.282: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2560" for this suite.
Apr  6 23:41:07.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:41:07.388: INFO: namespace resourcequota-2560 deletion completed in 6.102281409s

• [SLOW TEST:19.175 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:41:07.388: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-43381cbe-3b03-4717-8e18-7ac7d3553fb7
STEP: Creating a pod to test consume configMaps
Apr  6 23:41:07.425: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-a4b3c8f3-e69b-41c1-9e1e-706b3008d847" in namespace "projected-9794" to be "success or failure"
Apr  6 23:41:07.429: INFO: Pod "pod-projected-configmaps-a4b3c8f3-e69b-41c1-9e1e-706b3008d847": Phase="Pending", Reason="", readiness=false. Elapsed: 4.286665ms
Apr  6 23:41:09.433: INFO: Pod "pod-projected-configmaps-a4b3c8f3-e69b-41c1-9e1e-706b3008d847": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.007828744s
STEP: Saw pod success
Apr  6 23:41:09.433: INFO: Pod "pod-projected-configmaps-a4b3c8f3-e69b-41c1-9e1e-706b3008d847" satisfied condition "success or failure"
Apr  6 23:41:09.435: INFO: Trying to get logs from node 10.0.0.42 pod pod-projected-configmaps-a4b3c8f3-e69b-41c1-9e1e-706b3008d847 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Apr  6 23:41:09.453: INFO: Waiting for pod pod-projected-configmaps-a4b3c8f3-e69b-41c1-9e1e-706b3008d847 to disappear
Apr  6 23:41:09.456: INFO: Pod pod-projected-configmaps-a4b3c8f3-e69b-41c1-9e1e-706b3008d847 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:41:09.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9794" for this suite.
Apr  6 23:41:15.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:41:15.565: INFO: namespace projected-9794 deletion completed in 6.10385835s

• [SLOW TEST:8.177 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:41:15.566: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename projected
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-9c0db5a6-50f2-4ffa-99d4-c85bccdd8fdd
STEP: Creating secret with name s-test-opt-upd-5b729ebf-c64a-4c8c-889f-57821b07a2be
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-9c0db5a6-50f2-4ffa-99d4-c85bccdd8fdd
STEP: Updating secret s-test-opt-upd-5b729ebf-c64a-4c8c-889f-57821b07a2be
STEP: Creating secret with name s-test-opt-create-a1942464-a7b0-42f9-ae66-c26fb26c197c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:41:19.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6527" for this suite.
Apr  6 23:41:31.708: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:41:31.858: INFO: namespace projected-6527 deletion completed in 12.159219278s

• [SLOW TEST:16.292 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:41:31.858: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename watch
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:41:37.713: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8869" for this suite.
Apr  6 23:41:43.868: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:41:43.956: INFO: namespace watch-8869 deletion completed in 6.191274491s

• [SLOW TEST:12.097 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:41:43.956: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename pod-network-test
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-3265
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Apr  6 23:41:43.981: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Apr  6 23:42:08.055: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.20.16.151:8080/dial?request=hostName&protocol=http&host=10.20.8.156&port=8080&tries=1'] Namespace:pod-network-test-3265 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 23:42:08.055: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 23:42:08.178: INFO: Waiting for endpoints: map[]
Apr  6 23:42:08.181: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.20.16.151:8080/dial?request=hostName&protocol=http&host=10.20.16.150&port=8080&tries=1'] Namespace:pod-network-test-3265 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 23:42:08.182: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 23:42:08.331: INFO: Waiting for endpoints: map[]
Apr  6 23:42:08.334: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.20.16.151:8080/dial?request=hostName&protocol=http&host=10.20.14.156&port=8080&tries=1'] Namespace:pod-network-test-3265 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Apr  6 23:42:08.334: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
Apr  6 23:42:08.460: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:42:08.460: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3265" for this suite.
Apr  6 23:42:20.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:42:20.561: INFO: namespace pod-network-test-3265 deletion completed in 12.097183012s

• [SLOW TEST:36.605 seconds]
[sig-network] Networking
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:42:20.561: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Apr  6 23:42:20.585: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:42:34.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2296" for this suite.
Apr  6 23:42:40.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:42:40.963: INFO: namespace crd-publish-openapi-2296 deletion completed in 6.096398175s

• [SLOW TEST:20.402 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:42:40.963: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename downward-api
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Apr  6 23:42:43.516: INFO: Successfully updated pod "labelsupdatec4d99b6b-1217-4224-9103-4ba8cbfe5d45"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:42:45.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1086" for this suite.
Apr  6 23:43:01.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:43:01.641: INFO: namespace downward-api-1086 deletion completed in 16.101160435s

• [SLOW TEST:20.678 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Apr  6 23:43:01.641: INFO: >>> kubeConfig: /tmp/kubeconfig-273020805
STEP: Building a namespace api object, basename webhook
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Apr  6 23:43:02.229: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Apr  6 23:43:04.240: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721813382, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721813382, loc:(*time.Location)(0x789e8e0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63721813382, loc:(*time.Location)(0x789e8e0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63721813382, loc:(*time.Location)(0x789e8e0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Apr  6 23:43:07.253: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Apr  6 23:43:19.381: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2638" for this suite.
Apr  6 23:43:25.394: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:43:25.540: INFO: namespace webhook-2638 deletion completed in 6.155153086s
STEP: Destroying namespace "webhook-2638-markers" for this suite.
Apr  6 23:43:31.548: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Apr  6 23:43:31.645: INFO: namespace webhook-2638-markers deletion completed in 6.105151317s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:30.016 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.8-beta.0.65+ef1ba35b1a4560/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SApr  6 23:43:31.657: INFO: Running AfterSuite actions on all nodes
Apr  6 23:43:31.657: INFO: Running AfterSuite actions on node 1
Apr  6 23:43:31.657: INFO: Skipping dumping logs from cluster

Ran 274 of 4731 Specs in 6480.738 seconds
SUCCESS! -- 274 Passed | 0 Failed | 0 Pending | 4457 Skipped
PASS

Ginkgo ran 1 suite in 1h48m1.960135625s
Test Suite Passed
