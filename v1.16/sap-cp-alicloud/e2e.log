Conformance test: not doing test setup.
I1203 14:39:03.885709    5091 e2e.go:92] Starting e2e run "3ed23c52-e8ac-49cb-b7fb-9bf07a2e81e4" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1575383942 - Will randomize all specs
Will run 276 of 4732 specs

Dec  3 14:39:04.099: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Deleting namespaces
STEP: Waiting for namespaces to vanish
I1203 14:39:04.127045    5091 suites.go:70] Waiting for deletion of the following namespaces: []
Dec  3 14:39:06.132: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec  3 14:39:06.148: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec  3 14:39:06.200: INFO: 22 / 22 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec  3 14:39:06.200: INFO: expected 12 pod replicas in namespace 'kube-system', 12 are Running and Ready.
Dec  3 14:39:06.200: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec  3 14:39:06.211: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Dec  3 14:39:06.211: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'csi-disk-plugin-alicloud' (0 seconds elapsed)
Dec  3 14:39:06.211: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec  3 14:39:06.211: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Dec  3 14:39:06.211: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-problem-detector' (0 seconds elapsed)
Dec  3 14:39:06.211: INFO: e2e test version: v1.16.3
Dec  3 14:39:06.215: INFO: kube-apiserver version: v1.16.3
Dec  3 14:39:06.215: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 14:39:06.222: INFO: Cluster IP family: ipv4
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:39:06.223: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
Dec  3 14:39:06.464: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Dec  3 14:39:06.486: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3580
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:39:06.615: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0c1331ad-d1fc-4d8d-8340-b982a8d6160e" in namespace "downward-api-3580" to be "success or failure"
Dec  3 14:39:06.619: INFO: Pod "downwardapi-volume-0c1331ad-d1fc-4d8d-8340-b982a8d6160e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.469212ms
Dec  3 14:39:08.624: INFO: Pod "downwardapi-volume-0c1331ad-d1fc-4d8d-8340-b982a8d6160e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00947306s
Dec  3 14:39:10.630: INFO: Pod "downwardapi-volume-0c1331ad-d1fc-4d8d-8340-b982a8d6160e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014666967s
STEP: Saw pod success
Dec  3 14:39:10.630: INFO: Pod "downwardapi-volume-0c1331ad-d1fc-4d8d-8340-b982a8d6160e" satisfied condition "success or failure"
Dec  3 14:39:10.634: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downwardapi-volume-0c1331ad-d1fc-4d8d-8340-b982a8d6160e container client-container: <nil>
STEP: delete the pod
Dec  3 14:39:10.795: INFO: Waiting for pod downwardapi-volume-0c1331ad-d1fc-4d8d-8340-b982a8d6160e to disappear
Dec  3 14:39:10.800: INFO: Pod downwardapi-volume-0c1331ad-d1fc-4d8d-8340-b982a8d6160e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:39:10.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3580" for this suite.
Dec  3 14:39:16.822: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:39:17.101: INFO: namespace downward-api-3580 deletion completed in 6.29381822s
•SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:39:17.101: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3853
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Dec  3 14:39:17.768: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config cluster-info'
Dec  3 14:39:22.859: INFO: stderr: ""
Dec  3 14:39:23.128: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:39:23.128: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3853" for this suite.
Dec  3 14:39:29.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:39:29.352: INFO: namespace kubectl-3853 deletion completed in 6.215351646s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:39:29.352: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3458
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-3458
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 14:39:29.974: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 14:39:58.062: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.7:8080/dial?request=hostName&protocol=http&host=100.64.0.14&port=8080&tries=1'] Namespace:pod-network-test-3458 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:39:58.062: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 14:39:58.603: INFO: Waiting for endpoints: map[]
Dec  3 14:39:58.608: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.7:8080/dial?request=hostName&protocol=http&host=100.64.1.6&port=8080&tries=1'] Namespace:pod-network-test-3458 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 14:39:58.608: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 14:39:59.003: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:39:59.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3458" for this suite.
Dec  3 14:40:11.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:40:11.183: INFO: namespace pod-network-test-3458 deletion completed in 12.171306972s
•SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:40:11.184: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4297
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-4297/configmap-test-5977f0c0-0089-4085-99b8-bd7c922501af
STEP: Creating a pod to test consume configMaps
Dec  3 14:40:11.583: INFO: Waiting up to 5m0s for pod "pod-configmaps-5d9a24de-0c95-46ad-acb3-30d6446421b7" in namespace "configmap-4297" to be "success or failure"
Dec  3 14:40:11.588: INFO: Pod "pod-configmaps-5d9a24de-0c95-46ad-acb3-30d6446421b7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.291947ms
Dec  3 14:40:13.595: INFO: Pod "pod-configmaps-5d9a24de-0c95-46ad-acb3-30d6446421b7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.011346935s
Dec  3 14:40:15.600: INFO: Pod "pod-configmaps-5d9a24de-0c95-46ad-acb3-30d6446421b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016734275s
STEP: Saw pod success
Dec  3 14:40:15.600: INFO: Pod "pod-configmaps-5d9a24de-0c95-46ad-acb3-30d6446421b7" satisfied condition "success or failure"
Dec  3 14:40:15.605: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-configmaps-5d9a24de-0c95-46ad-acb3-30d6446421b7 container env-test: <nil>
STEP: delete the pod
Dec  3 14:40:15.629: INFO: Waiting for pod pod-configmaps-5d9a24de-0c95-46ad-acb3-30d6446421b7 to disappear
Dec  3 14:40:15.634: INFO: Pod pod-configmaps-5d9a24de-0c95-46ad-acb3-30d6446421b7 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:40:15.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4297" for this suite.
Dec  3 14:40:23.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:40:23.815: INFO: namespace configmap-4297 deletion completed in 8.173447512s
•SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:40:23.815: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3989
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:40:24.181: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4500d266-8acc-4b2d-84e3-467006dcd248" in namespace "downward-api-3989" to be "success or failure"
Dec  3 14:40:24.185: INFO: Pod "downwardapi-volume-4500d266-8acc-4b2d-84e3-467006dcd248": Phase="Pending", Reason="", readiness=false. Elapsed: 4.694775ms
Dec  3 14:40:26.191: INFO: Pod "downwardapi-volume-4500d266-8acc-4b2d-84e3-467006dcd248": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010452881s
STEP: Saw pod success
Dec  3 14:40:26.191: INFO: Pod "downwardapi-volume-4500d266-8acc-4b2d-84e3-467006dcd248" satisfied condition "success or failure"
Dec  3 14:40:26.196: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downwardapi-volume-4500d266-8acc-4b2d-84e3-467006dcd248 container client-container: <nil>
STEP: delete the pod
Dec  3 14:40:26.218: INFO: Waiting for pod downwardapi-volume-4500d266-8acc-4b2d-84e3-467006dcd248 to disappear
Dec  3 14:40:26.222: INFO: Pod downwardapi-volume-4500d266-8acc-4b2d-84e3-467006dcd248 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:40:26.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3989" for this suite.
Dec  3 14:40:34.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:40:34.444: INFO: namespace downward-api-3989 deletion completed in 8.213576966s
•SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:40:34.444: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9748
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec  3 14:40:34.872: INFO: PodSpec: initContainers in spec.initContainers
Dec  3 14:41:16.201: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-67e1461c-6cf0-4f44-a44e-0632df14eee6", GenerateName:"", Namespace:"init-container-9748", SelfLink:"/api/v1/namespaces/init-container-9748/pods/pod-init-67e1461c-6cf0-4f44-a44e-0632df14eee6", UID:"a4fd9b8c-ff77-4042-b24b-f8e5a9668707", ResourceVersion:"4350", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63710980834, loc:(*time.Location)(0x84bfb00)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"872696702"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.64.1.10/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-qcwns", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002868080), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-qcwns", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-qcwns", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-qcwns", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00261e098), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"izgw8fisrtg04goc4t8tqaz", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0030f0000), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00261e110)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00261e130)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00261e138), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00261e13c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980834, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980834, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980834, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980834, loc:(*time.Location)(0x84bfb00)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.2.117", PodIP:"100.64.1.10", PodIPs:[]v1.PodIP{v1.PodIP{IP:"100.64.1.10"}}, StartTime:(*v1.Time)(0xc002588060), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc003128070)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0031280e0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://6ec8c29ecefcbb602ae878448e4d5bfd8064ec91a4c2a4b04d3e9bab3dd682d6", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc0025880a0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc002588080), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc00261e1bf)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:41:16.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9748" for this suite.
Dec  3 14:41:46.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:41:46.394: INFO: namespace init-container-9748 deletion completed in 30.184693493s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:41:46.395: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5908
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:41:46.891: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4aa08d1a-fbcb-4567-bc84-42d4b3e09c8f" in namespace "projected-5908" to be "success or failure"
Dec  3 14:41:46.896: INFO: Pod "downwardapi-volume-4aa08d1a-fbcb-4567-bc84-42d4b3e09c8f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.347543ms
Dec  3 14:41:48.902: INFO: Pod "downwardapi-volume-4aa08d1a-fbcb-4567-bc84-42d4b3e09c8f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010704595s
STEP: Saw pod success
Dec  3 14:41:48.902: INFO: Pod "downwardapi-volume-4aa08d1a-fbcb-4567-bc84-42d4b3e09c8f" satisfied condition "success or failure"
Dec  3 14:41:48.907: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downwardapi-volume-4aa08d1a-fbcb-4567-bc84-42d4b3e09c8f container client-container: <nil>
STEP: delete the pod
Dec  3 14:41:48.928: INFO: Waiting for pod downwardapi-volume-4aa08d1a-fbcb-4567-bc84-42d4b3e09c8f to disappear
Dec  3 14:41:48.933: INFO: Pod downwardapi-volume-4aa08d1a-fbcb-4567-bc84-42d4b3e09c8f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:41:48.933: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5908" for this suite.
Dec  3 14:41:54.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:41:55.162: INFO: namespace projected-5908 deletion completed in 6.221916649s
•SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:41:55.162: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4336
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec  3 14:42:05.664: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1203 14:42:05.664680    5091 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:42:05.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4336" for this suite.
Dec  3 14:42:13.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:42:13.834: INFO: namespace gc-4336 deletion completed in 8.165186178s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:42:13.835: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5265
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-f71b1064-e65e-42a7-9c85-69320b01bcc7
STEP: Creating a pod to test consume secrets
Dec  3 14:42:14.092: INFO: Waiting up to 5m0s for pod "pod-secrets-54082830-9969-480f-a408-3d7cfc67606e" in namespace "secrets-5265" to be "success or failure"
Dec  3 14:42:14.096: INFO: Pod "pod-secrets-54082830-9969-480f-a408-3d7cfc67606e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.277288ms
Dec  3 14:42:16.102: INFO: Pod "pod-secrets-54082830-9969-480f-a408-3d7cfc67606e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010083993s
STEP: Saw pod success
Dec  3 14:42:16.102: INFO: Pod "pod-secrets-54082830-9969-480f-a408-3d7cfc67606e" satisfied condition "success or failure"
Dec  3 14:42:16.107: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-secrets-54082830-9969-480f-a408-3d7cfc67606e container secret-env-test: <nil>
STEP: delete the pod
Dec  3 14:42:16.133: INFO: Waiting for pod pod-secrets-54082830-9969-480f-a408-3d7cfc67606e to disappear
Dec  3 14:42:16.137: INFO: Pod pod-secrets-54082830-9969-480f-a408-3d7cfc67606e no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:42:16.137: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5265" for this suite.
Dec  3 14:43:18.163: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:43:18.319: INFO: namespace secrets-5265 deletion completed in 1m2.172722033s
•SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:43:18.319: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9928
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9928.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-9928.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9928.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-9928.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9928.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-9928.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-9928.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-9928.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-9928.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9928.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 14:43:38.716: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:38.762: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:38.770: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:38.777: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:38.918: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:38.925: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:38.933: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:38.941: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:39.036: INFO: Lookups using dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9928.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9928.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local jessie_udp@dns-test-service-2.dns-9928.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9928.svc.cluster.local]

Dec  3 14:43:44.044: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:44.052: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:44.059: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:44.067: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:44.209: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:44.217: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:44.228: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:44.235: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:44.331: INFO: Lookups using dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9928.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9928.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local jessie_udp@dns-test-service-2.dns-9928.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9928.svc.cluster.local]

Dec  3 14:43:49.045: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:49.053: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:49.060: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:49.068: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:49.210: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:49.218: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:49.225: INFO: Unable to read jessie_udp@dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:49.233: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:49.329: INFO: Lookups using dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local wheezy_udp@dns-test-service-2.dns-9928.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-9928.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-9928.svc.cluster.local jessie_udp@dns-test-service-2.dns-9928.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9928.svc.cluster.local]

Dec  3 14:43:54.179: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:54.589: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-9928.svc.cluster.local from pod dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20: the server could not find the requested resource (get pods dns-test-3456d3df-100c-47e8-a18c-1a7075601d20)
Dec  3 14:43:54.684: INFO: Lookups using dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20 failed for: [wheezy_udp@dns-test-service-2.dns-9928.svc.cluster.local jessie_tcp@dns-test-service-2.dns-9928.svc.cluster.local]

Dec  3 14:43:59.803: INFO: DNS probes using dns-9928/dns-test-3456d3df-100c-47e8-a18c-1a7075601d20 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:43:59.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9928" for this suite.
Dec  3 14:44:05.839: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:44:05.998: INFO: namespace dns-9928 deletion completed in 6.172937707s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:44:05.999: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8881
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-xmt2
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 14:44:06.309: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-xmt2" in namespace "subpath-8881" to be "success or failure"
Dec  3 14:44:06.313: INFO: Pod "pod-subpath-test-downwardapi-xmt2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.439158ms
Dec  3 14:44:08.319: INFO: Pod "pod-subpath-test-downwardapi-xmt2": Phase="Running", Reason="", readiness=true. Elapsed: 2.010241736s
Dec  3 14:44:10.325: INFO: Pod "pod-subpath-test-downwardapi-xmt2": Phase="Running", Reason="", readiness=true. Elapsed: 4.015648144s
Dec  3 14:44:12.330: INFO: Pod "pod-subpath-test-downwardapi-xmt2": Phase="Running", Reason="", readiness=true. Elapsed: 6.021113877s
Dec  3 14:44:14.335: INFO: Pod "pod-subpath-test-downwardapi-xmt2": Phase="Running", Reason="", readiness=true. Elapsed: 8.026506441s
Dec  3 14:44:16.341: INFO: Pod "pod-subpath-test-downwardapi-xmt2": Phase="Running", Reason="", readiness=true. Elapsed: 10.032076661s
Dec  3 14:44:18.347: INFO: Pod "pod-subpath-test-downwardapi-xmt2": Phase="Running", Reason="", readiness=true. Elapsed: 12.037654984s
Dec  3 14:44:20.352: INFO: Pod "pod-subpath-test-downwardapi-xmt2": Phase="Running", Reason="", readiness=true. Elapsed: 14.043273025s
Dec  3 14:44:22.359: INFO: Pod "pod-subpath-test-downwardapi-xmt2": Phase="Running", Reason="", readiness=true. Elapsed: 16.049923756s
Dec  3 14:44:24.364: INFO: Pod "pod-subpath-test-downwardapi-xmt2": Phase="Running", Reason="", readiness=true. Elapsed: 18.055397932s
Dec  3 14:44:26.370: INFO: Pod "pod-subpath-test-downwardapi-xmt2": Phase="Running", Reason="", readiness=true. Elapsed: 20.060967728s
Dec  3 14:44:28.376: INFO: Pod "pod-subpath-test-downwardapi-xmt2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.067095825s
STEP: Saw pod success
Dec  3 14:44:28.376: INFO: Pod "pod-subpath-test-downwardapi-xmt2" satisfied condition "success or failure"
Dec  3 14:44:28.381: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-subpath-test-downwardapi-xmt2 container test-container-subpath-downwardapi-xmt2: <nil>
STEP: delete the pod
Dec  3 14:44:28.524: INFO: Waiting for pod pod-subpath-test-downwardapi-xmt2 to disappear
Dec  3 14:44:28.528: INFO: Pod pod-subpath-test-downwardapi-xmt2 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-xmt2
Dec  3 14:44:28.528: INFO: Deleting pod "pod-subpath-test-downwardapi-xmt2" in namespace "subpath-8881"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:44:28.532: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8881" for this suite.
Dec  3 14:44:36.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:44:36.712: INFO: namespace subpath-8881 deletion completed in 8.17180441s
•SSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:44:36.712: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3986
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Dec  3 14:44:36.996: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 14:44:40.116: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:44:53.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3986" for this suite.
Dec  3 14:45:01.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:45:02.137: INFO: namespace crd-publish-openapi-3986 deletion completed in 8.203234677s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:45:02.137: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3343
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  3 14:45:02.406: INFO: Waiting up to 5m0s for pod "pod-7ddc5e00-e0cb-402e-916d-e46fd8522cc8" in namespace "emptydir-3343" to be "success or failure"
Dec  3 14:45:02.411: INFO: Pod "pod-7ddc5e00-e0cb-402e-916d-e46fd8522cc8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.795035ms
Dec  3 14:45:04.417: INFO: Pod "pod-7ddc5e00-e0cb-402e-916d-e46fd8522cc8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010922403s
Dec  3 14:45:06.423: INFO: Pod "pod-7ddc5e00-e0cb-402e-916d-e46fd8522cc8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.016966836s
STEP: Saw pod success
Dec  3 14:45:06.423: INFO: Pod "pod-7ddc5e00-e0cb-402e-916d-e46fd8522cc8" satisfied condition "success or failure"
Dec  3 14:45:06.428: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-7ddc5e00-e0cb-402e-916d-e46fd8522cc8 container test-container: <nil>
STEP: delete the pod
Dec  3 14:45:06.588: INFO: Waiting for pod pod-7ddc5e00-e0cb-402e-916d-e46fd8522cc8 to disappear
Dec  3 14:45:06.593: INFO: Pod pod-7ddc5e00-e0cb-402e-916d-e46fd8522cc8 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:45:06.593: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3343" for this suite.
Dec  3 14:45:12.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:45:12.789: INFO: namespace emptydir-3343 deletion completed in 6.187289981s
•SSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:45:12.789: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4469
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-750b2065-e3b3-44df-9a63-6c2da1ca0965
STEP: Creating a pod to test consume configMaps
Dec  3 14:45:13.107: INFO: Waiting up to 5m0s for pod "pod-configmaps-31967cea-98a3-4538-8e22-b5ba60239723" in namespace "configmap-4469" to be "success or failure"
Dec  3 14:45:13.112: INFO: Pod "pod-configmaps-31967cea-98a3-4538-8e22-b5ba60239723": Phase="Pending", Reason="", readiness=false. Elapsed: 4.798953ms
Dec  3 14:45:15.118: INFO: Pod "pod-configmaps-31967cea-98a3-4538-8e22-b5ba60239723": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010896394s
STEP: Saw pod success
Dec  3 14:45:15.118: INFO: Pod "pod-configmaps-31967cea-98a3-4538-8e22-b5ba60239723" satisfied condition "success or failure"
Dec  3 14:45:15.123: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-configmaps-31967cea-98a3-4538-8e22-b5ba60239723 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 14:45:15.145: INFO: Waiting for pod pod-configmaps-31967cea-98a3-4538-8e22-b5ba60239723 to disappear
Dec  3 14:45:15.150: INFO: Pod pod-configmaps-31967cea-98a3-4538-8e22-b5ba60239723 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:45:15.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4469" for this suite.
Dec  3 14:45:21.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:45:21.349: INFO: namespace configmap-4469 deletion completed in 6.189795948s
•SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:45:21.349: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1985
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1985
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-1985
STEP: Creating statefulset with conflicting port in namespace statefulset-1985
STEP: Waiting until pod test-pod will start running in namespace statefulset-1985
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-1985
Dec  3 14:45:33.828: INFO: Observed stateful pod in namespace: statefulset-1985, name: ss-0, uid: 2142e1b2-c8cc-41a0-b3f0-ccd9bb3d3b48, status phase: Failed. Waiting for statefulset controller to delete.
Dec  3 14:45:33.978: INFO: Observed stateful pod in namespace: statefulset-1985, name: ss-0, uid: 2142e1b2-c8cc-41a0-b3f0-ccd9bb3d3b48, status phase: Failed. Waiting for statefulset controller to delete.
Dec  3 14:45:33.979: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-1985
STEP: Removing pod with conflicting port in namespace statefulset-1985
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-1985 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  3 14:45:38.004: INFO: Deleting all statefulset in ns statefulset-1985
Dec  3 14:45:38.009: INFO: Scaling statefulset ss to 0
Dec  3 14:45:48.031: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 14:45:48.036: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:45:48.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1985" for this suite.
Dec  3 14:45:54.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:45:54.252: INFO: namespace statefulset-1985 deletion completed in 6.191874963s
•SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:45:54.252: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-1675
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-hhb6
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 14:45:54.606: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-hhb6" in namespace "subpath-1675" to be "success or failure"
Dec  3 14:45:54.611: INFO: Pod "pod-subpath-test-configmap-hhb6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.531919ms
Dec  3 14:45:56.617: INFO: Pod "pod-subpath-test-configmap-hhb6": Phase="Running", Reason="", readiness=true. Elapsed: 2.010442644s
Dec  3 14:45:58.623: INFO: Pod "pod-subpath-test-configmap-hhb6": Phase="Running", Reason="", readiness=true. Elapsed: 4.016185251s
Dec  3 14:46:00.629: INFO: Pod "pod-subpath-test-configmap-hhb6": Phase="Running", Reason="", readiness=true. Elapsed: 6.022191521s
Dec  3 14:46:02.635: INFO: Pod "pod-subpath-test-configmap-hhb6": Phase="Running", Reason="", readiness=true. Elapsed: 8.028125879s
Dec  3 14:46:04.641: INFO: Pod "pod-subpath-test-configmap-hhb6": Phase="Running", Reason="", readiness=true. Elapsed: 10.034046348s
Dec  3 14:46:06.646: INFO: Pod "pod-subpath-test-configmap-hhb6": Phase="Running", Reason="", readiness=true. Elapsed: 12.039942566s
Dec  3 14:46:08.652: INFO: Pod "pod-subpath-test-configmap-hhb6": Phase="Running", Reason="", readiness=true. Elapsed: 14.045962419s
Dec  3 14:46:10.658: INFO: Pod "pod-subpath-test-configmap-hhb6": Phase="Running", Reason="", readiness=true. Elapsed: 16.051468015s
Dec  3 14:46:12.664: INFO: Pod "pod-subpath-test-configmap-hhb6": Phase="Running", Reason="", readiness=true. Elapsed: 18.05740918s
Dec  3 14:46:14.670: INFO: Pod "pod-subpath-test-configmap-hhb6": Phase="Running", Reason="", readiness=true. Elapsed: 20.06357248s
Dec  3 14:46:16.676: INFO: Pod "pod-subpath-test-configmap-hhb6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.069572789s
STEP: Saw pod success
Dec  3 14:46:16.676: INFO: Pod "pod-subpath-test-configmap-hhb6" satisfied condition "success or failure"
Dec  3 14:46:16.681: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-subpath-test-configmap-hhb6 container test-container-subpath-configmap-hhb6: <nil>
STEP: delete the pod
Dec  3 14:46:16.705: INFO: Waiting for pod pod-subpath-test-configmap-hhb6 to disappear
Dec  3 14:46:16.710: INFO: Pod pod-subpath-test-configmap-hhb6 no longer exists
STEP: Deleting pod pod-subpath-test-configmap-hhb6
Dec  3 14:46:16.710: INFO: Deleting pod "pod-subpath-test-configmap-hhb6" in namespace "subpath-1675"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:46:16.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-1675" for this suite.
Dec  3 14:46:22.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:46:22.906: INFO: namespace subpath-1675 deletion completed in 6.183197627s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:46:22.907: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8178
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:46:23.404: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8178" for this suite.
Dec  3 14:46:29.425: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:46:29.615: INFO: namespace kubelet-test-8178 deletion completed in 6.205114167s
•SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:46:29.615: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2347
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:46:29.901: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d5ae505c-6618-476f-a5bb-7c316407740d" in namespace "downward-api-2347" to be "success or failure"
Dec  3 14:46:29.924: INFO: Pod "downwardapi-volume-d5ae505c-6618-476f-a5bb-7c316407740d": Phase="Pending", Reason="", readiness=false. Elapsed: 5.071843ms
Dec  3 14:46:31.929: INFO: Pod "downwardapi-volume-d5ae505c-6618-476f-a5bb-7c316407740d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010839243s
STEP: Saw pod success
Dec  3 14:46:31.929: INFO: Pod "downwardapi-volume-d5ae505c-6618-476f-a5bb-7c316407740d" satisfied condition "success or failure"
Dec  3 14:46:31.934: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downwardapi-volume-d5ae505c-6618-476f-a5bb-7c316407740d container client-container: <nil>
STEP: delete the pod
Dec  3 14:46:31.956: INFO: Waiting for pod downwardapi-volume-d5ae505c-6618-476f-a5bb-7c316407740d to disappear
Dec  3 14:46:31.961: INFO: Pod downwardapi-volume-d5ae505c-6618-476f-a5bb-7c316407740d no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:46:31.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2347" for this suite.
Dec  3 14:46:37.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:46:38.244: INFO: namespace downward-api-2347 deletion completed in 6.270466735s
•SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:46:38.245: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-2149
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:46:42.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2149" for this suite.
Dec  3 14:46:58.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:46:58.827: INFO: namespace containers-2149 deletion completed in 16.183726165s
•SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:46:58.827: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1347
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:47:15.236: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1347" for this suite.
Dec  3 14:47:21.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:47:21.448: INFO: namespace resourcequota-1347 deletion completed in 6.203691285s
•
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:47:21.448: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8611
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  3 14:47:24.332: INFO: Successfully updated pod "pod-update-activedeadlineseconds-9e2ada61-cd57-480f-9e12-4f4fe95ef391"
Dec  3 14:47:24.332: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-9e2ada61-cd57-480f-9e12-4f4fe95ef391" in namespace "pods-8611" to be "terminated due to deadline exceeded"
Dec  3 14:47:24.337: INFO: Pod "pod-update-activedeadlineseconds-9e2ada61-cd57-480f-9e12-4f4fe95ef391": Phase="Running", Reason="", readiness=true. Elapsed: 4.506865ms
Dec  3 14:47:26.342: INFO: Pod "pod-update-activedeadlineseconds-9e2ada61-cd57-480f-9e12-4f4fe95ef391": Phase="Running", Reason="", readiness=true. Elapsed: 2.009883004s
Dec  3 14:47:28.348: INFO: Pod "pod-update-activedeadlineseconds-9e2ada61-cd57-480f-9e12-4f4fe95ef391": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.015532906s
Dec  3 14:47:28.348: INFO: Pod "pod-update-activedeadlineseconds-9e2ada61-cd57-480f-9e12-4f4fe95ef391" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:47:28.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8611" for this suite.
Dec  3 14:47:34.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:47:34.547: INFO: namespace pods-8611 deletion completed in 6.190561585s
•SSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:47:34.547: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6541
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 14:47:34.892: INFO: Creating deployment "test-recreate-deployment"
Dec  3 14:47:34.898: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec  3 14:47:34.908: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Dec  3 14:47:36.920: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec  3 14:47:36.925: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981254, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981254, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981254, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981254, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:47:38.931: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981254, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981254, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981254, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981254, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:47:40.931: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec  3 14:47:40.941: INFO: Updating deployment test-recreate-deployment
Dec  3 14:47:40.941: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec  3 14:47:40.986: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-6541 /apis/apps/v1/namespaces/deployment-6541/deployments/test-recreate-deployment 04eda42d-8aee-459f-82cb-1d053bea0d5e 6316 2 2019-12-03 14:47:34 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005626198 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-12-03 14:47:40 +0000 UTC,LastTransitionTime:2019-12-03 14:47:40 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2019-12-03 14:47:40 +0000 UTC,LastTransitionTime:2019-12-03 14:47:34 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Dec  3 14:47:40.992: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-6541 /apis/apps/v1/namespaces/deployment-6541/replicasets/test-recreate-deployment-5f94c574ff 1fb5401c-2a23-42a3-81ff-2b2b93a72229 6315 1 2019-12-03 14:47:40 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 04eda42d-8aee-459f-82cb-1d053bea0d5e 0xc0064ffc67 0xc0064ffc68}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0064ffcc8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 14:47:40.993: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec  3 14:47:40.993: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-6541 /apis/apps/v1/namespaces/deployment-6541/replicasets/test-recreate-deployment-68fc85c7bb d27ae225-9dbd-4024-bc36-394d5051d83f 6308 2 2019-12-03 14:47:34 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 04eda42d-8aee-459f-82cb-1d053bea0d5e 0xc0064ffd27 0xc0064ffd28}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0064ffd88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 14:47:40.998: INFO: Pod "test-recreate-deployment-5f94c574ff-frt6j" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-frt6j test-recreate-deployment-5f94c574ff- deployment-6541 /api/v1/namespaces/deployment-6541/pods/test-recreate-deployment-5f94c574ff-frt6j 82188940-74a0-4788-b477-3a80aafc92d9 6313 0 2019-12-03 14:47:40 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 1fb5401c-2a23-42a3-81ff-2b2b93a72229 0xc005626537 0xc005626538}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-tmkj8,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-tmkj8,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-tmkj8,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 14:47:40 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:47:40.998: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6541" for this suite.
Dec  3 14:47:49.023: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:47:49.199: INFO: namespace deployment-6541 deletion completed in 8.192780347s
•SSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:47:49.200: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3358
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:47:49.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3358" for this suite.
Dec  3 14:48:17.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:48:17.794: INFO: namespace pods-3358 deletion completed in 28.186097487s
•
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:48:17.794: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3708
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  3 14:48:18.194: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-3708'
Dec  3 14:48:39.023: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 14:48:39.023: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Dec  3 14:48:43.040: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete deployment e2e-test-httpd-deployment --namespace=kubectl-3708'
Dec  3 14:48:48.418: INFO: stderr: ""
Dec  3 14:48:48.418: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:48:48.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3708" for this suite.
Dec  3 14:48:54.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:48:54.623: INFO: namespace kubectl-3708 deletion completed in 6.196604045s
•SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:48:54.624: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9552
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 14:48:55.023: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"d40db900-660b-4b61-9034-c996db25309b", Controller:(*bool)(0xc003365e8a), BlockOwnerDeletion:(*bool)(0xc003365e8b)}}
Dec  3 14:48:55.030: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"c7ab1c8e-c950-49fd-9ccd-fb4180cd9a39", Controller:(*bool)(0xc0036ada76), BlockOwnerDeletion:(*bool)(0xc0036ada77)}}
Dec  3 14:48:55.035: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"fc23fb56-458e-4658-9441-0c7b5c757413", Controller:(*bool)(0xc004eb3a86), BlockOwnerDeletion:(*bool)(0xc004eb3a87)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:49:00.047: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9552" for this suite.
Dec  3 14:49:06.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:49:06.245: INFO: namespace gc-9552 deletion completed in 6.189352159s
•SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:49:06.245: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8701
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 14:49:06.711: INFO: (0) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 110.205258ms)
Dec  3 14:49:06.719: INFO: (1) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.379541ms)
Dec  3 14:49:06.727: INFO: (2) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.87974ms)
Dec  3 14:49:06.735: INFO: (3) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.742836ms)
Dec  3 14:49:06.743: INFO: (4) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.784803ms)
Dec  3 14:49:06.751: INFO: (5) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.869789ms)
Dec  3 14:49:06.758: INFO: (6) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.688109ms)
Dec  3 14:49:06.766: INFO: (7) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.562785ms)
Dec  3 14:49:06.774: INFO: (8) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.617518ms)
Dec  3 14:49:06.781: INFO: (9) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.478694ms)
Dec  3 14:49:06.789: INFO: (10) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.424535ms)
Dec  3 14:49:06.797: INFO: (11) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.105062ms)
Dec  3 14:49:06.805: INFO: (12) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.649821ms)
Dec  3 14:49:06.812: INFO: (13) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.684942ms)
Dec  3 14:49:06.820: INFO: (14) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.482242ms)
Dec  3 14:49:06.827: INFO: (15) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.424318ms)
Dec  3 14:49:06.835: INFO: (16) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.269385ms)
Dec  3 14:49:06.842: INFO: (17) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.51282ms)
Dec  3 14:49:06.850: INFO: (18) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.573493ms)
Dec  3 14:49:06.858: INFO: (19) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.698565ms)
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:49:06.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8701" for this suite.
Dec  3 14:49:12.879: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:49:13.048: INFO: namespace proxy-8701 deletion completed in 6.184802304s
•SSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:49:13.048: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-816
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 14:49:15.429: INFO: Waiting up to 5m0s for pod "client-envvars-a0dc4ab5-03dd-4454-af0b-110272a43e5f" in namespace "pods-816" to be "success or failure"
Dec  3 14:49:15.434: INFO: Pod "client-envvars-a0dc4ab5-03dd-4454-af0b-110272a43e5f": Phase="Pending", Reason="", readiness=false. Elapsed: 4.788731ms
Dec  3 14:49:17.440: INFO: Pod "client-envvars-a0dc4ab5-03dd-4454-af0b-110272a43e5f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010726817s
STEP: Saw pod success
Dec  3 14:49:17.440: INFO: Pod "client-envvars-a0dc4ab5-03dd-4454-af0b-110272a43e5f" satisfied condition "success or failure"
Dec  3 14:49:17.446: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod client-envvars-a0dc4ab5-03dd-4454-af0b-110272a43e5f container env3cont: <nil>
STEP: delete the pod
Dec  3 14:49:17.590: INFO: Waiting for pod client-envvars-a0dc4ab5-03dd-4454-af0b-110272a43e5f to disappear
Dec  3 14:49:17.595: INFO: Pod client-envvars-a0dc4ab5-03dd-4454-af0b-110272a43e5f no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:49:17.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-816" for this suite.
Dec  3 14:49:29.620: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:49:29.785: INFO: namespace pods-816 deletion completed in 12.181101265s
•SSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:49:29.786: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3236
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec  3 14:49:30.288: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 14:49:30.305: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 14:49:30.310: INFO: 
Logging pods the kubelet thinks is on node izgw88vcbd5x6ev7zbjg8vz before test
Dec  3 14:49:30.340: INFO: vpn-shoot-76845cddf7-dh4gs from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 14:49:30.340: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec  3 14:49:30.340: INFO: addons-nginx-ingress-controller-7c75bb76db-8qn7n from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 14:49:30.340: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec  3 14:49:30.340: INFO: csi-disk-plugin-alicloud-55sss from kube-system started at 2019-12-03 14:26:56 +0000 UTC (2 container statuses recorded)
Dec  3 14:49:30.340: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec  3 14:49:30.340: INFO: 	Container driver-registrar ready: true, restart count 0
Dec  3 14:49:30.340: INFO: calico-node-rx7sf from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 14:49:30.340: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 14:49:30.341: INFO: node-exporter-xwww8 from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 14:49:30.341: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 14:49:30.341: INFO: kube-proxy-frcrz from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 14:49:30.341: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 14:49:30.341: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-95f65778d-6v4hg from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 14:49:30.341: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec  3 14:49:30.341: INFO: calico-typha-horizontal-autoscaler-69df649c59-wrrxb from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 14:49:30.341: INFO: 	Container autoscaler ready: true, restart count 0
Dec  3 14:49:30.341: INFO: addons-kubernetes-dashboard-78954cc66b-mh5g8 from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 14:49:30.341: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  3 14:49:30.341: INFO: blackbox-exporter-7bd7b55dfc-jjbg2 from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 14:49:30.341: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec  3 14:49:30.341: INFO: node-problem-detector-jj8gj from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 14:49:30.341: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 14:49:30.341: INFO: coredns-59c969ffb8-xnfvv from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 14:49:30.341: INFO: 	Container coredns ready: true, restart count 0
Dec  3 14:49:30.341: INFO: metrics-server-69dcc87559-8j9rx from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 14:49:30.341: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 14:49:30.341: INFO: calico-typha-vertical-autoscaler-847d859f8c-6xhsp from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 14:49:30.341: INFO: 	Container autoscaler ready: true, restart count 2
Dec  3 14:49:30.341: INFO: coredns-59c969ffb8-9mq2d from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 14:49:30.341: INFO: 	Container coredns ready: true, restart count 0
Dec  3 14:49:30.341: INFO: 
Logging pods the kubelet thinks is on node izgw8fisrtg04goc4t8tqaz before test
Dec  3 14:49:30.365: INFO: calico-node-8d72b from kube-system started at 2019-12-03 14:26:18 +0000 UTC (1 container statuses recorded)
Dec  3 14:49:30.365: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 14:49:30.365: INFO: calico-typha-deploy-9f6b455c4-9z5nc from kube-system started at 2019-12-03 14:28:12 +0000 UTC (1 container statuses recorded)
Dec  3 14:49:30.365: INFO: 	Container calico-typha ready: true, restart count 0
Dec  3 14:49:30.365: INFO: node-problem-detector-g8scm from kube-system started at 2019-12-03 14:26:18 +0000 UTC (1 container statuses recorded)
Dec  3 14:49:30.365: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 14:49:30.365: INFO: kube-proxy-dgc7z from kube-system started at 2019-12-03 14:26:18 +0000 UTC (1 container statuses recorded)
Dec  3 14:49:30.365: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 14:49:30.365: INFO: csi-disk-plugin-alicloud-qmj7l from kube-system started at 2019-12-03 14:26:58 +0000 UTC (2 container statuses recorded)
Dec  3 14:49:30.365: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec  3 14:49:30.365: INFO: 	Container driver-registrar ready: true, restart count 0
Dec  3 14:49:30.365: INFO: calico-kube-controllers-79bcd784b6-s67m5 from kube-system started at 2019-12-03 14:26:58 +0000 UTC (1 container statuses recorded)
Dec  3 14:49:30.365: INFO: 	Container calico-kube-controllers ready: true, restart count 1
Dec  3 14:49:30.365: INFO: node-exporter-2jhhv from kube-system started at 2019-12-03 14:26:18 +0000 UTC (1 container statuses recorded)
Dec  3 14:49:30.365: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node izgw88vcbd5x6ev7zbjg8vz
STEP: verifying the node has the label node izgw8fisrtg04goc4t8tqaz
Dec  3 14:49:30.411: INFO: Pod addons-kubernetes-dashboard-78954cc66b-mh5g8 requesting resource cpu=50m on Node izgw88vcbd5x6ev7zbjg8vz
Dec  3 14:49:30.411: INFO: Pod addons-nginx-ingress-controller-7c75bb76db-8qn7n requesting resource cpu=100m on Node izgw88vcbd5x6ev7zbjg8vz
Dec  3 14:49:30.411: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-95f65778d-6v4hg requesting resource cpu=0m on Node izgw88vcbd5x6ev7zbjg8vz
Dec  3 14:49:30.411: INFO: Pod blackbox-exporter-7bd7b55dfc-jjbg2 requesting resource cpu=5m on Node izgw88vcbd5x6ev7zbjg8vz
Dec  3 14:49:30.411: INFO: Pod calico-kube-controllers-79bcd784b6-s67m5 requesting resource cpu=0m on Node izgw8fisrtg04goc4t8tqaz
Dec  3 14:49:30.411: INFO: Pod calico-node-8d72b requesting resource cpu=100m on Node izgw8fisrtg04goc4t8tqaz
Dec  3 14:49:30.411: INFO: Pod calico-node-rx7sf requesting resource cpu=100m on Node izgw88vcbd5x6ev7zbjg8vz
Dec  3 14:49:30.411: INFO: Pod calico-typha-deploy-9f6b455c4-9z5nc requesting resource cpu=0m on Node izgw8fisrtg04goc4t8tqaz
Dec  3 14:49:30.411: INFO: Pod calico-typha-horizontal-autoscaler-69df649c59-wrrxb requesting resource cpu=10m on Node izgw88vcbd5x6ev7zbjg8vz
Dec  3 14:49:30.411: INFO: Pod calico-typha-vertical-autoscaler-847d859f8c-6xhsp requesting resource cpu=0m on Node izgw88vcbd5x6ev7zbjg8vz
Dec  3 14:49:30.411: INFO: Pod coredns-59c969ffb8-9mq2d requesting resource cpu=50m on Node izgw88vcbd5x6ev7zbjg8vz
Dec  3 14:49:30.411: INFO: Pod coredns-59c969ffb8-xnfvv requesting resource cpu=50m on Node izgw88vcbd5x6ev7zbjg8vz
Dec  3 14:49:30.411: INFO: Pod csi-disk-plugin-alicloud-55sss requesting resource cpu=0m on Node izgw88vcbd5x6ev7zbjg8vz
Dec  3 14:49:30.411: INFO: Pod csi-disk-plugin-alicloud-qmj7l requesting resource cpu=0m on Node izgw8fisrtg04goc4t8tqaz
Dec  3 14:49:30.411: INFO: Pod kube-proxy-dgc7z requesting resource cpu=20m on Node izgw8fisrtg04goc4t8tqaz
Dec  3 14:49:30.411: INFO: Pod kube-proxy-frcrz requesting resource cpu=20m on Node izgw88vcbd5x6ev7zbjg8vz
Dec  3 14:49:30.411: INFO: Pod metrics-server-69dcc87559-8j9rx requesting resource cpu=20m on Node izgw88vcbd5x6ev7zbjg8vz
Dec  3 14:49:30.411: INFO: Pod node-exporter-2jhhv requesting resource cpu=5m on Node izgw8fisrtg04goc4t8tqaz
Dec  3 14:49:30.411: INFO: Pod node-exporter-xwww8 requesting resource cpu=5m on Node izgw88vcbd5x6ev7zbjg8vz
Dec  3 14:49:30.411: INFO: Pod node-problem-detector-g8scm requesting resource cpu=20m on Node izgw8fisrtg04goc4t8tqaz
Dec  3 14:49:30.411: INFO: Pod node-problem-detector-jj8gj requesting resource cpu=20m on Node izgw88vcbd5x6ev7zbjg8vz
Dec  3 14:49:30.411: INFO: Pod vpn-shoot-76845cddf7-dh4gs requesting resource cpu=100m on Node izgw88vcbd5x6ev7zbjg8vz
STEP: Starting Pods to consume most of the cluster CPU.
Dec  3 14:49:30.411: INFO: Creating a pod which consumes cpu=973m on Node izgw88vcbd5x6ev7zbjg8vz
Dec  3 14:49:30.419: INFO: Creating a pod which consumes cpu=1242m on Node izgw8fisrtg04goc4t8tqaz
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5c480fc6-6565-4038-bd4a-3e6042f11c7d.15dce3eb88d0e01d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3236/filler-pod-5c480fc6-6565-4038-bd4a-3e6042f11c7d to izgw8fisrtg04goc4t8tqaz]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5c480fc6-6565-4038-bd4a-3e6042f11c7d.15dce3ebb32383b3], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5c480fc6-6565-4038-bd4a-3e6042f11c7d.15dce3ebb5a6f9ea], Reason = [Created], Message = [Created container filler-pod-5c480fc6-6565-4038-bd4a-3e6042f11c7d]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-5c480fc6-6565-4038-bd4a-3e6042f11c7d.15dce3ebbc7e55ef], Reason = [Started], Message = [Started container filler-pod-5c480fc6-6565-4038-bd4a-3e6042f11c7d]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6abb6385-1532-4871-9bec-6a3bef769bd8.15dce3eb88858d6d], Reason = [Scheduled], Message = [Successfully assigned sched-pred-3236/filler-pod-6abb6385-1532-4871-9bec-6a3bef769bd8 to izgw88vcbd5x6ev7zbjg8vz]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6abb6385-1532-4871-9bec-6a3bef769bd8.15dce3ebb1ef888e], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6abb6385-1532-4871-9bec-6a3bef769bd8.15dce3ebd6a26bb3], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6abb6385-1532-4871-9bec-6a3bef769bd8.15dce3ebd91cd252], Reason = [Created], Message = [Created container filler-pod-6abb6385-1532-4871-9bec-6a3bef769bd8]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6abb6385-1532-4871-9bec-6a3bef769bd8.15dce3ebe073f079], Reason = [Started], Message = [Started container filler-pod-6abb6385-1532-4871-9bec-6a3bef769bd8]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15dce3ec01d35312], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node izgw8fisrtg04goc4t8tqaz
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node izgw88vcbd5x6ev7zbjg8vz
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:49:33.496: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3236" for this suite.
Dec  3 14:49:39.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:49:39.725: INFO: namespace sched-pred-3236 deletion completed in 6.223174306s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
•SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:49:39.725: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9660
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:49:44.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9660" for this suite.
Dec  3 14:49:53.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:49:53.325: INFO: namespace watch-9660 deletion completed in 8.289426175s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:49:53.326: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-771
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec  3 14:49:53.693: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:50:14.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-771" for this suite.
Dec  3 14:50:20.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:21.362: INFO: namespace crd-publish-openapi-771 deletion completed in 6.656848937s
•
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:50:21.362: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2518
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:50:21.748: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b054645d-bc10-47c1-af8d-6a696a18a731" in namespace "projected-2518" to be "success or failure"
Dec  3 14:50:21.764: INFO: Pod "downwardapi-volume-b054645d-bc10-47c1-af8d-6a696a18a731": Phase="Pending", Reason="", readiness=false. Elapsed: 15.632947ms
Dec  3 14:50:23.781: INFO: Pod "downwardapi-volume-b054645d-bc10-47c1-af8d-6a696a18a731": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03266029s
STEP: Saw pod success
Dec  3 14:50:23.781: INFO: Pod "downwardapi-volume-b054645d-bc10-47c1-af8d-6a696a18a731" satisfied condition "success or failure"
Dec  3 14:50:23.797: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downwardapi-volume-b054645d-bc10-47c1-af8d-6a696a18a731 container client-container: <nil>
STEP: delete the pod
Dec  3 14:50:23.977: INFO: Waiting for pod downwardapi-volume-b054645d-bc10-47c1-af8d-6a696a18a731 to disappear
Dec  3 14:50:23.993: INFO: Pod downwardapi-volume-b054645d-bc10-47c1-af8d-6a696a18a731 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:50:23.993: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2518" for this suite.
Dec  3 14:50:32.073: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:32.651: INFO: namespace projected-2518 deletion completed in 8.627866512s
•SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:50:32.652: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-9081
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 14:50:33.621: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec  3 14:50:37.060: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9081 create -f -'
Dec  3 14:50:37.712: INFO: stderr: ""
Dec  3 14:50:37.712: INFO: stdout: "e2e-test-crd-publish-openapi-855-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec  3 14:50:37.712: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9081 delete e2e-test-crd-publish-openapi-855-crds test-cr'
Dec  3 14:50:37.848: INFO: stderr: ""
Dec  3 14:50:37.848: INFO: stdout: "e2e-test-crd-publish-openapi-855-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Dec  3 14:50:37.848: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9081 apply -f -'
Dec  3 14:50:38.132: INFO: stderr: ""
Dec  3 14:50:38.132: INFO: stdout: "e2e-test-crd-publish-openapi-855-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec  3 14:50:38.132: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9081 delete e2e-test-crd-publish-openapi-855-crds test-cr'
Dec  3 14:50:38.239: INFO: stderr: ""
Dec  3 14:50:38.239: INFO: stdout: "e2e-test-crd-publish-openapi-855-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec  3 14:50:38.239: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-855-crds'
Dec  3 14:50:38.475: INFO: stderr: ""
Dec  3 14:50:38.475: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-855-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:50:41.874: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9081" for this suite.
Dec  3 14:50:47.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:48.547: INFO: namespace crd-publish-openapi-9081 deletion completed in 6.640663717s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:50:48.548: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4912
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 14:50:49.937: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:0, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:0, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981449, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981449, loc:(*time.Location)(0x84bfb00)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-86d95b659d\""}}, CollisionCount:(*int32)(nil)}
Dec  3 14:50:51.954: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981449, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981449, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981450, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981449, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 14:50:54.975: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Dec  3 14:50:57.219: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config attach --namespace=webhook-4912 to-be-attached-pod -i -c=container1'
Dec  3 14:50:57.378: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:50:57.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4912" for this suite.
Dec  3 14:51:11.479: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:12.052: INFO: namespace webhook-4912 deletion completed in 14.623260866s
STEP: Destroying namespace "webhook-4912-markers" for this suite.
Dec  3 14:51:18.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:18.686: INFO: namespace webhook-4912-markers deletion completed in 6.634178104s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:51:18.752: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9294
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-44a1c994-a6bd-4ac5-9573-244c9febeb20
STEP: Creating a pod to test consume secrets
Dec  3 14:51:19.168: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-15ea43ae-0b89-4718-be37-8ac3a10adbdd" in namespace "projected-9294" to be "success or failure"
Dec  3 14:51:19.184: INFO: Pod "pod-projected-secrets-15ea43ae-0b89-4718-be37-8ac3a10adbdd": Phase="Pending", Reason="", readiness=false. Elapsed: 16.088242ms
Dec  3 14:51:21.201: INFO: Pod "pod-projected-secrets-15ea43ae-0b89-4718-be37-8ac3a10adbdd": Phase="Running", Reason="", readiness=true. Elapsed: 2.032876834s
Dec  3 14:51:23.218: INFO: Pod "pod-projected-secrets-15ea43ae-0b89-4718-be37-8ac3a10adbdd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.050130578s
STEP: Saw pod success
Dec  3 14:51:23.220: INFO: Pod "pod-projected-secrets-15ea43ae-0b89-4718-be37-8ac3a10adbdd" satisfied condition "success or failure"
Dec  3 14:51:23.237: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-projected-secrets-15ea43ae-0b89-4718-be37-8ac3a10adbdd container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:51:23.420: INFO: Waiting for pod pod-projected-secrets-15ea43ae-0b89-4718-be37-8ac3a10adbdd to disappear
Dec  3 14:51:23.436: INFO: Pod pod-projected-secrets-15ea43ae-0b89-4718-be37-8ac3a10adbdd no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:51:23.436: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9294" for this suite.
Dec  3 14:51:29.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:30.094: INFO: namespace projected-9294 deletion completed in 6.626865901s
•SSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:51:30.095: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3551
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-e5941724-d559-4c90-8244-54a12cdabe4b in namespace container-probe-3551
Dec  3 14:51:32.485: INFO: Started pod liveness-e5941724-d559-4c90-8244-54a12cdabe4b in namespace container-probe-3551
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 14:51:32.501: INFO: Initial restart count of pod liveness-e5941724-d559-4c90-8244-54a12cdabe4b is 0
Dec  3 14:51:56.719: INFO: Restart count of pod container-probe-3551/liveness-e5941724-d559-4c90-8244-54a12cdabe4b is now 1 (24.217603876s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:51:56.738: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3551" for this suite.
Dec  3 14:52:02.817: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:52:03.397: INFO: namespace container-probe-3551 deletion completed in 6.62860647s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:52:03.398: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-2005
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec  3 14:52:04.620: INFO: Pod name wrapped-volume-race-4b8c1197-715f-4982-807c-7c0a2d90c4de: Found 3 pods out of 5
Dec  3 14:52:09.653: INFO: Pod name wrapped-volume-race-4b8c1197-715f-4982-807c-7c0a2d90c4de: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-4b8c1197-715f-4982-807c-7c0a2d90c4de in namespace emptydir-wrapper-2005, will wait for the garbage collector to delete the pods
Dec  3 14:52:17.872: INFO: Deleting ReplicationController wrapped-volume-race-4b8c1197-715f-4982-807c-7c0a2d90c4de took: 18.484835ms
Dec  3 14:52:18.473: INFO: Terminating ReplicationController wrapped-volume-race-4b8c1197-715f-4982-807c-7c0a2d90c4de pods took: 600.429529ms
STEP: Creating RC which spawns configmap-volume pods
Dec  3 14:52:56.529: INFO: Pod name wrapped-volume-race-51e2985b-06e7-488f-8457-787787325665: Found 3 pods out of 5
Dec  3 14:53:01.563: INFO: Pod name wrapped-volume-race-51e2985b-06e7-488f-8457-787787325665: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-51e2985b-06e7-488f-8457-787787325665 in namespace emptydir-wrapper-2005, will wait for the garbage collector to delete the pods
Dec  3 14:53:01.731: INFO: Deleting ReplicationController wrapped-volume-race-51e2985b-06e7-488f-8457-787787325665 took: 18.869327ms
Dec  3 14:53:02.232: INFO: Terminating ReplicationController wrapped-volume-race-51e2985b-06e7-488f-8457-787787325665 pods took: 500.525516ms
STEP: Creating RC which spawns configmap-volume pods
Dec  3 14:53:46.585: INFO: Pod name wrapped-volume-race-8c3e1c1c-5600-47b0-8758-50bf8f9b446e: Found 1 pods out of 5
Dec  3 14:53:51.619: INFO: Pod name wrapped-volume-race-8c3e1c1c-5600-47b0-8758-50bf8f9b446e: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-8c3e1c1c-5600-47b0-8758-50bf8f9b446e in namespace emptydir-wrapper-2005, will wait for the garbage collector to delete the pods
Dec  3 14:53:51.793: INFO: Deleting ReplicationController wrapped-volume-race-8c3e1c1c-5600-47b0-8758-50bf8f9b446e took: 18.912264ms
Dec  3 14:53:51.893: INFO: Terminating ReplicationController wrapped-volume-race-8c3e1c1c-5600-47b0-8758-50bf8f9b446e pods took: 100.343402ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:54:37.365: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2005" for this suite.
Dec  3 14:54:43.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:54:44.006: INFO: namespace emptydir-wrapper-2005 deletion completed in 6.624425765s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:54:44.007: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6923
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-cc9c63f7-08d0-483d-a57d-06dd449e6c2e
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:54:46.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6923" for this suite.
Dec  3 14:54:58.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:54:59.428: INFO: namespace configmap-6923 deletion completed in 12.644018908s
•SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:54:59.429: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2408
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-2408
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-2408
I1203 14:55:00.102033    5091 runners.go:184] Created replication controller with name: externalname-service, namespace: services-2408, replica count: 2
Dec  3 14:55:03.152: INFO: Creating new exec pod
I1203 14:55:03.152589    5091 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 14:55:06.237: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-2408 execpodz8gqc -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec  3 14:55:06.902: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec  3 14:55:06.902: INFO: stdout: ""
Dec  3 14:55:06.903: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-2408 execpodz8gqc -- /bin/sh -x -c nc -zv -t -w 2 100.107.211.129 80'
Dec  3 14:55:07.549: INFO: stderr: "+ nc -zv -t -w 2 100.107.211.129 80\nConnection to 100.107.211.129 80 port [tcp/http] succeeded!\n"
Dec  3 14:55:07.549: INFO: stdout: ""
Dec  3 14:55:07.549: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-2408 execpodz8gqc -- /bin/sh -x -c nc -zv -t -w 2 10.250.2.118 31046'
Dec  3 14:55:08.136: INFO: stderr: "+ nc -zv -t -w 2 10.250.2.118 31046\nConnection to 10.250.2.118 31046 port [tcp/31046] succeeded!\n"
Dec  3 14:55:08.136: INFO: stdout: ""
Dec  3 14:55:08.136: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-2408 execpodz8gqc -- /bin/sh -x -c nc -zv -t -w 2 10.250.2.117 31046'
Dec  3 14:55:08.741: INFO: stderr: "+ nc -zv -t -w 2 10.250.2.117 31046\nConnection to 10.250.2.117 31046 port [tcp/31046] succeeded!\n"
Dec  3 14:55:08.742: INFO: stdout: ""
Dec  3 14:55:08.742: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:55:08.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2408" for this suite.
Dec  3 14:55:14.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:55:15.420: INFO: namespace services-2408 deletion completed in 6.621220678s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:55:15.420: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-7974
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 14:55:15.962: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  3 14:55:17.994: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec  3 14:55:20.011: INFO: Creating deployment "test-rollover-deployment"
Dec  3 14:55:20.044: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec  3 14:55:22.076: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec  3 14:55:22.109: INFO: Ensure that both replica sets have 1 created replica
Dec  3 14:55:22.142: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec  3 14:55:22.175: INFO: Updating deployment test-rollover-deployment
Dec  3 14:55:22.175: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec  3 14:55:24.209: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec  3 14:55:24.244: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec  3 14:55:24.277: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:55:24.277: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981720, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981720, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981723, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981720, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:55:26.311: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:55:26.311: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981720, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981720, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981723, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981720, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:55:28.310: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:55:28.310: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981720, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981720, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981723, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981720, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:55:30.311: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:55:30.311: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981720, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981720, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981723, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981720, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:55:32.311: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:55:32.311: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981720, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981720, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981723, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981720, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:55:34.310: INFO: 
Dec  3 14:55:34.310: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec  3 14:55:34.359: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-7974 /apis/apps/v1/namespaces/deployment-7974/deployments/test-rollover-deployment b13fb66c-e68d-4b3b-a0b6-cc07a9722f7c 8672 2 2019-12-03 14:55:20 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0007875c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-03 14:55:20 +0000 UTC,LastTransitionTime:2019-12-03 14:55:20 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2019-12-03 14:55:34 +0000 UTC,LastTransitionTime:2019-12-03 14:55:20 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 14:55:34.376: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-7974 /apis/apps/v1/namespaces/deployment-7974/replicasets/test-rollover-deployment-7d7dc6548c 6e9b0a30-cdb5-44d4-9d81-9d9d3894b2ee 8665 2 2019-12-03 14:55:22 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment b13fb66c-e68d-4b3b-a0b6-cc07a9722f7c 0xc000787a67 0xc000787a68}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000787ac8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec  3 14:55:34.376: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec  3 14:55:34.376: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-7974 /apis/apps/v1/namespaces/deployment-7974/replicasets/test-rollover-controller 82b7d253-5615-4df6-ac60-0158f9034998 8671 2 2019-12-03 14:55:15 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment b13fb66c-e68d-4b3b-a0b6-cc07a9722f7c 0xc00078798f 0xc0007879a0}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc000787a08 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 14:55:34.376: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-7974 /apis/apps/v1/namespaces/deployment-7974/replicasets/test-rollover-deployment-f6c94f66c 1ab22fb5-a458-40ad-8d3e-cc15c2147a11 8619 2 2019-12-03 14:55:20 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment b13fb66c-e68d-4b3b-a0b6-cc07a9722f7c 0xc000787b20 0xc000787b21}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000787b98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 14:55:34.393: INFO: Pod "test-rollover-deployment-7d7dc6548c-kbjxj" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-kbjxj test-rollover-deployment-7d7dc6548c- deployment-7974 /api/v1/namespaces/deployment-7974/pods/test-rollover-deployment-7d7dc6548c-kbjxj c22abec9-ab22-4e64-a8d2-32ff0790858f 8631 0 2019-12-03 14:55:22 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[cni.projectcalico.org/podIP:100.64.1.46/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c 6e9b0a30-cdb5-44d4-9d81-9d9d3894b2ee 0xc0071cf2b7 0xc0071cf2b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-2g4ch,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-2g4ch,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-2g4ch,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 14:55:22 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 14:55:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 14:55:23 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 14:55:22 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:100.64.1.46,StartTime:2019-12-03 14:55:22 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 14:55:23 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://ffa26c252315deb93f68f1ed87e32f6193824b50d224ab207d277c11775d39ec,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.46,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:55:34.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-7974" for this suite.
Dec  3 14:55:44.474: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:55:45.092: INFO: namespace deployment-7974 deletion completed in 10.667600698s
•SSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:55:45.092: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2541
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Dec  3 14:55:45.825: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Dec  3 14:55:58.884: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 14:56:01.940: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:56:15.355: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2541" for this suite.
Dec  3 14:56:21.381: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:56:21.550: INFO: namespace crd-publish-openapi-2541 deletion completed in 6.185267683s
•SSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:56:21.550: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-3044
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Dec  3 14:56:24.330: INFO: Successfully updated pod "adopt-release-4dcvf"
STEP: Checking that the Job readopts the Pod
Dec  3 14:56:24.330: INFO: Waiting up to 15m0s for pod "adopt-release-4dcvf" in namespace "job-3044" to be "adopted"
Dec  3 14:56:24.335: INFO: Pod "adopt-release-4dcvf": Phase="Running", Reason="", readiness=true. Elapsed: 4.898473ms
Dec  3 14:56:26.340: INFO: Pod "adopt-release-4dcvf": Phase="Running", Reason="", readiness=true. Elapsed: 2.010517234s
Dec  3 14:56:26.341: INFO: Pod "adopt-release-4dcvf" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Dec  3 14:56:26.855: INFO: Successfully updated pod "adopt-release-4dcvf"
STEP: Checking that the Job releases the Pod
Dec  3 14:56:26.855: INFO: Waiting up to 15m0s for pod "adopt-release-4dcvf" in namespace "job-3044" to be "released"
Dec  3 14:56:26.860: INFO: Pod "adopt-release-4dcvf": Phase="Running", Reason="", readiness=true. Elapsed: 4.869929ms
Dec  3 14:56:26.860: INFO: Pod "adopt-release-4dcvf" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:56:26.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3044" for this suite.
Dec  3 14:57:12.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:57:13.051: INFO: namespace job-3044 deletion completed in 46.181899446s
•SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:57:13.052: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7929
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  3 14:57:13.398: INFO: Waiting up to 5m0s for pod "pod-b6c8e4cf-c47f-4901-ab25-962fb81cb81c" in namespace "emptydir-7929" to be "success or failure"
Dec  3 14:57:13.403: INFO: Pod "pod-b6c8e4cf-c47f-4901-ab25-962fb81cb81c": Phase="Pending", Reason="", readiness=false. Elapsed: 5.040307ms
Dec  3 14:57:15.409: INFO: Pod "pod-b6c8e4cf-c47f-4901-ab25-962fb81cb81c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010686729s
STEP: Saw pod success
Dec  3 14:57:15.409: INFO: Pod "pod-b6c8e4cf-c47f-4901-ab25-962fb81cb81c" satisfied condition "success or failure"
Dec  3 14:57:15.415: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-b6c8e4cf-c47f-4901-ab25-962fb81cb81c container test-container: <nil>
STEP: delete the pod
Dec  3 14:57:15.574: INFO: Waiting for pod pod-b6c8e4cf-c47f-4901-ab25-962fb81cb81c to disappear
Dec  3 14:57:15.579: INFO: Pod pod-b6c8e4cf-c47f-4901-ab25-962fb81cb81c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:57:15.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7929" for this suite.
Dec  3 14:57:21.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:57:21.773: INFO: namespace emptydir-7929 deletion completed in 6.185753474s
•
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:57:21.774: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-7520
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:57:30.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7520" for this suite.
Dec  3 14:57:36.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:57:36.312: INFO: namespace job-7520 deletion completed in 6.193327429s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:57:36.313: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1746
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 14:57:36.605: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec  3 14:57:39.703: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-1746 create -f -'
Dec  3 14:57:40.279: INFO: stderr: ""
Dec  3 14:57:40.279: INFO: stdout: "e2e-test-crd-publish-openapi-2472-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec  3 14:57:40.279: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-1746 delete e2e-test-crd-publish-openapi-2472-crds test-cr'
Dec  3 14:57:40.370: INFO: stderr: ""
Dec  3 14:57:40.370: INFO: stdout: "e2e-test-crd-publish-openapi-2472-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Dec  3 14:57:40.370: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-1746 apply -f -'
Dec  3 14:57:40.713: INFO: stderr: ""
Dec  3 14:57:40.713: INFO: stdout: "e2e-test-crd-publish-openapi-2472-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec  3 14:57:40.713: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-1746 delete e2e-test-crd-publish-openapi-2472-crds test-cr'
Dec  3 14:57:40.892: INFO: stderr: ""
Dec  3 14:57:40.892: INFO: stdout: "e2e-test-crd-publish-openapi-2472-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec  3 14:57:40.892: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-2472-crds'
Dec  3 14:57:41.055: INFO: stderr: ""
Dec  3 14:57:41.056: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2472-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:57:44.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1746" for this suite.
Dec  3 14:57:50.744: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:57:50.887: INFO: namespace crd-publish-openapi-1746 deletion completed in 6.15758698s
•S
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:57:50.887: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8416
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Dec  3 14:57:51.487: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:57:51.605: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8416" for this suite.
Dec  3 14:57:59.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:57:59.766: INFO: namespace kubectl-8416 deletion completed in 8.155247465s
•
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:57:59.766: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-546
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Dec  3 14:58:00.093: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-546 -- logs-generator --log-lines-total 100 --run-duration 20s'
Dec  3 14:58:00.241: INFO: stderr: ""
Dec  3 14:58:00.241: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Dec  3 14:58:00.241: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Dec  3 14:58:00.241: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-546" to be "running and ready, or succeeded"
Dec  3 14:58:00.245: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 4.154278ms
Dec  3 14:58:02.251: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.009592513s
Dec  3 14:58:02.251: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Dec  3 14:58:02.251: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Dec  3 14:58:02.251: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-546'
Dec  3 14:58:02.509: INFO: stderr: ""
Dec  3 14:58:02.509: INFO: stdout: "I1203 14:58:01.149849       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/psp6 220\nI1203 14:58:01.349950       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/gr5 228\nI1203 14:58:01.550002       1 logs_generator.go:76] 2 POST /api/v1/namespaces/ns/pods/lpl 486\nI1203 14:58:01.750054       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/ztcv 329\nI1203 14:58:01.949987       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/kl8f 562\nI1203 14:58:02.149987       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/qbd 216\nI1203 14:58:02.349974       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/7wbm 363\n"
STEP: limiting log lines
Dec  3 14:58:02.509: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-546 --tail=1'
Dec  3 14:58:02.856: INFO: stderr: ""
Dec  3 14:58:02.856: INFO: stdout: "I1203 14:58:02.749981       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/h28 379\n"
STEP: limiting log bytes
Dec  3 14:58:02.856: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-546 --limit-bytes=1'
Dec  3 14:58:03.015: INFO: stderr: ""
Dec  3 14:58:03.015: INFO: stdout: "I"
STEP: exposing timestamps
Dec  3 14:58:03.015: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-546 --tail=1 --timestamps'
Dec  3 14:58:03.172: INFO: stderr: ""
Dec  3 14:58:03.172: INFO: stdout: "2019-12-03T14:58:03.150180646Z I1203 14:58:03.149980       1 logs_generator.go:76] 10 POST /api/v1/namespaces/default/pods/dgld 433\n"
STEP: restricting to a time range
Dec  3 14:58:05.672: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-546 --since=1s'
Dec  3 14:58:05.775: INFO: stderr: ""
Dec  3 14:58:05.775: INFO: stdout: "I1203 14:58:04.949962       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/jxm 275\nI1203 14:58:05.150002       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/rc97 394\nI1203 14:58:05.350032       1 logs_generator.go:76] 21 POST /api/v1/namespaces/ns/pods/sdfw 282\nI1203 14:58:05.550004       1 logs_generator.go:76] 22 POST /api/v1/namespaces/kube-system/pods/tg9v 320\nI1203 14:58:05.750060       1 logs_generator.go:76] 23 GET /api/v1/namespaces/ns/pods/ch2j 381\n"
Dec  3 14:58:05.775: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-546 --since=24h'
Dec  3 14:58:05.931: INFO: stderr: ""
Dec  3 14:58:05.931: INFO: stdout: "I1203 14:58:01.149849       1 logs_generator.go:76] 0 POST /api/v1/namespaces/ns/pods/psp6 220\nI1203 14:58:01.349950       1 logs_generator.go:76] 1 GET /api/v1/namespaces/default/pods/gr5 228\nI1203 14:58:01.550002       1 logs_generator.go:76] 2 POST /api/v1/namespaces/ns/pods/lpl 486\nI1203 14:58:01.750054       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/ztcv 329\nI1203 14:58:01.949987       1 logs_generator.go:76] 4 PUT /api/v1/namespaces/default/pods/kl8f 562\nI1203 14:58:02.149987       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/qbd 216\nI1203 14:58:02.349974       1 logs_generator.go:76] 6 POST /api/v1/namespaces/kube-system/pods/7wbm 363\nI1203 14:58:02.549995       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/l76m 351\nI1203 14:58:02.749981       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/ns/pods/h28 379\nI1203 14:58:02.949974       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/ns/pods/m9r4 250\nI1203 14:58:03.149980       1 logs_generator.go:76] 10 POST /api/v1/namespaces/default/pods/dgld 433\nI1203 14:58:03.349973       1 logs_generator.go:76] 11 POST /api/v1/namespaces/kube-system/pods/qg5l 235\nI1203 14:58:03.550111       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/9f6 266\nI1203 14:58:03.749990       1 logs_generator.go:76] 13 POST /api/v1/namespaces/ns/pods/z8n 244\nI1203 14:58:03.949962       1 logs_generator.go:76] 14 POST /api/v1/namespaces/ns/pods/s9v 317\nI1203 14:58:04.149998       1 logs_generator.go:76] 15 GET /api/v1/namespaces/kube-system/pods/xzf 250\nI1203 14:58:04.350076       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/qdpz 585\nI1203 14:58:04.549984       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/xb8 510\nI1203 14:58:04.749971       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/default/pods/q6h8 355\nI1203 14:58:04.949962       1 logs_generator.go:76] 19 POST /api/v1/namespaces/default/pods/jxm 275\nI1203 14:58:05.150002       1 logs_generator.go:76] 20 POST /api/v1/namespaces/kube-system/pods/rc97 394\nI1203 14:58:05.350032       1 logs_generator.go:76] 21 POST /api/v1/namespaces/ns/pods/sdfw 282\nI1203 14:58:05.550004       1 logs_generator.go:76] 22 POST /api/v1/namespaces/kube-system/pods/tg9v 320\nI1203 14:58:05.750060       1 logs_generator.go:76] 23 GET /api/v1/namespaces/ns/pods/ch2j 381\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Dec  3 14:58:05.931: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pod logs-generator --namespace=kubectl-546'
Dec  3 14:58:08.288: INFO: stderr: ""
Dec  3 14:58:08.288: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:58:08.288: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-546" for this suite.
Dec  3 14:58:14.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:58:14.447: INFO: namespace kubectl-546 deletion completed in 6.151730618s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:58:14.447: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5445
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-5445
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-5445
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5445
Dec  3 14:58:14.708: INFO: Found 0 stateful pods, waiting for 1
Dec  3 14:58:24.714: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec  3 14:58:24.720: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5445 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 14:58:25.227: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 14:58:25.227: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 14:58:25.227: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 14:58:25.232: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  3 14:58:35.238: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 14:58:35.238: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 14:58:35.256: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Dec  3 14:58:35.256: INFO: ss-0  izgw8fisrtg04goc4t8tqaz  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:25 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:25 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  }]
Dec  3 14:58:35.256: INFO: ss-1                           Pending         []
Dec  3 14:58:35.256: INFO: 
Dec  3 14:58:35.256: INFO: StatefulSet ss has not reached scale 3, at 2
Dec  3 14:58:36.262: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.994990761s
Dec  3 14:58:37.267: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989283473s
Dec  3 14:58:38.273: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.98381647s
Dec  3 14:58:39.279: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.977637689s
Dec  3 14:58:40.285: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.971928205s
Dec  3 14:58:41.290: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.966258726s
Dec  3 14:58:42.296: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.960476117s
Dec  3 14:58:43.302: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.954581832s
Dec  3 14:58:44.308: INFO: Verifying statefulset ss doesn't scale past 3 for another 948.81241ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5445
Dec  3 14:58:45.314: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5445 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 14:58:45.855: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 14:58:45.855: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 14:58:45.855: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 14:58:45.855: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5445 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 14:58:46.414: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec  3 14:58:46.414: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 14:58:46.414: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 14:58:46.414: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5445 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 14:58:46.888: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec  3 14:58:46.888: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 14:58:46.888: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 14:58:46.894: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 14:58:46.894: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 14:58:46.894: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec  3 14:58:46.898: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5445 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 14:58:47.395: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 14:58:47.395: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 14:58:47.395: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 14:58:47.395: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5445 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 14:58:48.027: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 14:58:48.027: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 14:58:48.027: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 14:58:48.027: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5445 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 14:58:48.556: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 14:58:48.556: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 14:58:48.556: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 14:58:48.556: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 14:58:48.561: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec  3 14:58:58.572: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 14:58:58.572: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 14:58:58.572: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 14:58:58.585: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Dec  3 14:58:58.586: INFO: ss-0  izgw8fisrtg04goc4t8tqaz  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  }]
Dec  3 14:58:58.586: INFO: ss-1  izgw88vcbd5x6ev7zbjg8vz  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  }]
Dec  3 14:58:58.586: INFO: ss-2  izgw8fisrtg04goc4t8tqaz  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  }]
Dec  3 14:58:58.586: INFO: 
Dec  3 14:58:58.586: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 14:58:59.591: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Dec  3 14:58:59.591: INFO: ss-0  izgw8fisrtg04goc4t8tqaz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  }]
Dec  3 14:58:59.591: INFO: ss-1  izgw88vcbd5x6ev7zbjg8vz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  }]
Dec  3 14:58:59.592: INFO: ss-2  izgw8fisrtg04goc4t8tqaz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  }]
Dec  3 14:58:59.592: INFO: 
Dec  3 14:58:59.592: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 14:59:00.597: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Dec  3 14:59:00.597: INFO: ss-0  izgw8fisrtg04goc4t8tqaz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  }]
Dec  3 14:59:00.597: INFO: ss-1  izgw88vcbd5x6ev7zbjg8vz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:48 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  }]
Dec  3 14:59:00.597: INFO: ss-2  izgw8fisrtg04goc4t8tqaz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  }]
Dec  3 14:59:00.598: INFO: 
Dec  3 14:59:00.598: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 14:59:01.603: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Dec  3 14:59:01.603: INFO: ss-0  izgw8fisrtg04goc4t8tqaz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  }]
Dec  3 14:59:01.603: INFO: ss-2  izgw8fisrtg04goc4t8tqaz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  }]
Dec  3 14:59:01.603: INFO: 
Dec  3 14:59:01.603: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 14:59:02.609: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Dec  3 14:59:02.609: INFO: ss-0  izgw8fisrtg04goc4t8tqaz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  }]
Dec  3 14:59:02.609: INFO: ss-2  izgw8fisrtg04goc4t8tqaz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  }]
Dec  3 14:59:02.609: INFO: 
Dec  3 14:59:02.609: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 14:59:03.614: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Dec  3 14:59:03.615: INFO: ss-0  izgw8fisrtg04goc4t8tqaz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  }]
Dec  3 14:59:03.615: INFO: ss-2  izgw8fisrtg04goc4t8tqaz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  }]
Dec  3 14:59:03.615: INFO: 
Dec  3 14:59:03.615: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 14:59:04.620: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Dec  3 14:59:04.621: INFO: ss-0  izgw8fisrtg04goc4t8tqaz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  }]
Dec  3 14:59:04.621: INFO: ss-2  izgw8fisrtg04goc4t8tqaz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  }]
Dec  3 14:59:04.621: INFO: 
Dec  3 14:59:04.621: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 14:59:05.626: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Dec  3 14:59:05.626: INFO: ss-0  izgw8fisrtg04goc4t8tqaz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  }]
Dec  3 14:59:05.626: INFO: ss-2  izgw8fisrtg04goc4t8tqaz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  }]
Dec  3 14:59:05.626: INFO: 
Dec  3 14:59:05.626: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 14:59:06.632: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Dec  3 14:59:06.632: INFO: ss-0  izgw8fisrtg04goc4t8tqaz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  }]
Dec  3 14:59:06.632: INFO: ss-2  izgw8fisrtg04goc4t8tqaz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  }]
Dec  3 14:59:06.632: INFO: 
Dec  3 14:59:06.632: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 14:59:07.637: INFO: POD   NODE                     PHASE    GRACE  CONDITIONS
Dec  3 14:59:07.638: INFO: ss-0  izgw8fisrtg04goc4t8tqaz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:14 +0000 UTC  }]
Dec  3 14:59:07.638: INFO: ss-2  izgw8fisrtg04goc4t8tqaz  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:49 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 14:58:35 +0000 UTC  }]
Dec  3 14:59:07.638: INFO: 
Dec  3 14:59:07.638: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5445
Dec  3 14:59:08.643: INFO: Scaling statefulset ss to 0
Dec  3 14:59:08.657: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  3 14:59:08.661: INFO: Deleting all statefulset in ns statefulset-5445
Dec  3 14:59:08.665: INFO: Scaling statefulset ss to 0
Dec  3 14:59:08.677: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 14:59:08.681: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:59:08.695: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5445" for this suite.
Dec  3 14:59:16.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:59:16.864: INFO: namespace statefulset-5445 deletion completed in 8.162035276s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:59:16.865: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2436
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2436
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec  3 14:59:17.213: INFO: Found 0 stateful pods, waiting for 3
Dec  3 14:59:27.219: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 14:59:27.219: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 14:59:27.219: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec  3 14:59:27.254: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec  3 14:59:37.294: INFO: Updating stateful set ss2
Dec  3 14:59:37.303: INFO: Waiting for Pod statefulset-2436/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  3 14:59:47.317: INFO: Waiting for Pod statefulset-2436/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Dec  3 14:59:57.333: INFO: Found 2 stateful pods, waiting for 3
Dec  3 15:00:07.339: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:00:07.339: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:00:07.339: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec  3 15:00:07.369: INFO: Updating stateful set ss2
Dec  3 15:00:07.379: INFO: Waiting for Pod statefulset-2436/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  3 15:00:17.409: INFO: Updating stateful set ss2
Dec  3 15:00:17.418: INFO: Waiting for StatefulSet statefulset-2436/ss2 to complete update
Dec  3 15:00:17.419: INFO: Waiting for Pod statefulset-2436/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  3 15:00:27.429: INFO: Waiting for StatefulSet statefulset-2436/ss2 to complete update
Dec  3 15:00:27.429: INFO: Waiting for Pod statefulset-2436/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  3 15:00:37.429: INFO: Waiting for StatefulSet statefulset-2436/ss2 to complete update
Dec  3 15:00:37.429: INFO: Waiting for Pod statefulset-2436/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  3 15:00:47.429: INFO: Deleting all statefulset in ns statefulset-2436
Dec  3 15:00:47.434: INFO: Scaling statefulset ss2 to 0
Dec  3 15:01:17.453: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:01:17.458: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:01:17.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2436" for this suite.
Dec  3 15:01:23.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:01:23.644: INFO: namespace statefulset-2436 deletion completed in 6.164709927s
•
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:01:23.644: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-4831
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:01:23.903: INFO: Waiting up to 5m0s for pod "busybox-user-65534-c5a3282a-e06c-4fd0-afc5-b067f72937a8" in namespace "security-context-test-4831" to be "success or failure"
Dec  3 15:01:23.907: INFO: Pod "busybox-user-65534-c5a3282a-e06c-4fd0-afc5-b067f72937a8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.030946ms
Dec  3 15:01:25.912: INFO: Pod "busybox-user-65534-c5a3282a-e06c-4fd0-afc5-b067f72937a8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009126473s
Dec  3 15:01:25.912: INFO: Pod "busybox-user-65534-c5a3282a-e06c-4fd0-afc5-b067f72937a8" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:01:25.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4831" for this suite.
Dec  3 15:01:33.933: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:01:34.079: INFO: namespace security-context-test-4831 deletion completed in 8.159149362s
•SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:01:34.079: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9536
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:01:50.546: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9536" for this suite.
Dec  3 15:01:56.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:01:56.713: INFO: namespace resourcequota-9536 deletion completed in 6.158954149s
•SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:01:56.713: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1731
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:01:57.355: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
Dec  3 15:01:59.369: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982117, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982117, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982117, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982117, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:02:02.385: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:02:15.028: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1731" for this suite.
Dec  3 15:02:25.050: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:02:25.198: INFO: namespace webhook-1731 deletion completed in 10.162653589s
STEP: Destroying namespace "webhook-1731-markers" for this suite.
Dec  3 15:02:31.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:02:31.409: INFO: namespace webhook-1731-markers deletion completed in 6.210668751s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:02:31.428: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7722
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  3 15:02:31.896: INFO: Waiting up to 5m0s for pod "pod-b841fa20-31f8-4889-8255-65b0f9c3d838" in namespace "emptydir-7722" to be "success or failure"
Dec  3 15:02:31.900: INFO: Pod "pod-b841fa20-31f8-4889-8255-65b0f9c3d838": Phase="Pending", Reason="", readiness=false. Elapsed: 4.014264ms
Dec  3 15:02:33.905: INFO: Pod "pod-b841fa20-31f8-4889-8255-65b0f9c3d838": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009418186s
STEP: Saw pod success
Dec  3 15:02:33.905: INFO: Pod "pod-b841fa20-31f8-4889-8255-65b0f9c3d838" satisfied condition "success or failure"
Dec  3 15:02:33.910: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-b841fa20-31f8-4889-8255-65b0f9c3d838 container test-container: <nil>
STEP: delete the pod
Dec  3 15:02:34.070: INFO: Waiting for pod pod-b841fa20-31f8-4889-8255-65b0f9c3d838 to disappear
Dec  3 15:02:34.074: INFO: Pod pod-b841fa20-31f8-4889-8255-65b0f9c3d838 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:02:34.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7722" for this suite.
Dec  3 15:02:40.095: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:02:40.242: INFO: namespace emptydir-7722 deletion completed in 6.161008499s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:02:40.242: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6374
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:02:40.921: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:02:43.943: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:02:44.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6374" for this suite.
Dec  3 15:02:52.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:02:52.322: INFO: namespace webhook-6374 deletion completed in 8.16772891s
STEP: Destroying namespace "webhook-6374-markers" for this suite.
Dec  3 15:02:58.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:02:58.519: INFO: namespace webhook-6374-markers deletion completed in 6.196699091s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:02:58.537: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7651
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-771c223b-c4b1-4785-a0fb-c9504338c5dc
STEP: Creating a pod to test consume secrets
Dec  3 15:02:58.804: INFO: Waiting up to 5m0s for pod "pod-secrets-2dbcae68-a1f4-427d-8489-b01f151a1c01" in namespace "secrets-7651" to be "success or failure"
Dec  3 15:02:58.812: INFO: Pod "pod-secrets-2dbcae68-a1f4-427d-8489-b01f151a1c01": Phase="Pending", Reason="", readiness=false. Elapsed: 7.221004ms
Dec  3 15:03:00.817: INFO: Pod "pod-secrets-2dbcae68-a1f4-427d-8489-b01f151a1c01": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01254663s
STEP: Saw pod success
Dec  3 15:03:00.817: INFO: Pod "pod-secrets-2dbcae68-a1f4-427d-8489-b01f151a1c01" satisfied condition "success or failure"
Dec  3 15:03:00.821: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-secrets-2dbcae68-a1f4-427d-8489-b01f151a1c01 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:03:00.842: INFO: Waiting for pod pod-secrets-2dbcae68-a1f4-427d-8489-b01f151a1c01 to disappear
Dec  3 15:03:00.846: INFO: Pod pod-secrets-2dbcae68-a1f4-427d-8489-b01f151a1c01 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:03:00.846: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7651" for this suite.
Dec  3 15:03:06.867: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:03:07.011: INFO: namespace secrets-7651 deletion completed in 6.157848365s
•SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:03:07.011: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-340
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  3 15:03:07.293: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-340'
Dec  3 15:03:07.440: INFO: stderr: ""
Dec  3 15:03:07.440: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Dec  3 15:03:12.490: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod e2e-test-httpd-pod --namespace=kubectl-340 -o json'
Dec  3 15:03:12.615: INFO: stderr: ""
Dec  3 15:03:12.615: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"100.64.1.69/32\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-12-03T15:03:07Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-340\",\n        \"resourceVersion\": \"10795\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-340/pods/e2e-test-httpd-pod\",\n        \"uid\": \"9d5b3463-01e2-4fe7-a6a3-2edea0a89ed5\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-t8fgt\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"izgw8fisrtg04goc4t8tqaz\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-t8fgt\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-t8fgt\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-03T15:03:07Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-03T15:03:08Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-03T15:03:08Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-03T15:03:07Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://38487264d5fd74683a3338872eb80f32a7c7fa4cabb07f01a6a8deb4f6bb47dc\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-12-03T15:03:08Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.2.117\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.64.1.69\",\n        \"podIPs\": [\n            {\n                \"ip\": \"100.64.1.69\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-12-03T15:03:07Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec  3 15:03:12.615: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config replace -f - --namespace=kubectl-340'
Dec  3 15:03:12.902: INFO: stderr: ""
Dec  3 15:03:12.902: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Dec  3 15:03:12.906: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pods e2e-test-httpd-pod --namespace=kubectl-340'
Dec  3 15:03:14.708: INFO: stderr: ""
Dec  3 15:03:14.708: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:03:14.708: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-340" for this suite.
Dec  3 15:03:20.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:03:20.867: INFO: namespace kubectl-340 deletion completed in 6.151351138s
•SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:03:20.867: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5255
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  3 15:03:21.392: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-5255'
Dec  3 15:03:21.488: INFO: stderr: ""
Dec  3 15:03:21.488: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Dec  3 15:03:21.493: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pods e2e-test-httpd-pod --namespace=kubectl-5255'
Dec  3 15:03:37.911: INFO: stderr: ""
Dec  3 15:03:37.911: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:03:37.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5255" for this suite.
Dec  3 15:03:43.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:03:44.077: INFO: namespace kubectl-5255 deletion completed in 6.15864717s
•SSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:03:44.077: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-9174
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Dec  3 15:03:44.493: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Dec  3 15:03:45.125: INFO: new replicaset for deployment "sample-apiserver-deployment" is yet to be created
Dec  3 15:03:47.165: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:03:49.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:03:51.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:03:53.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:03:55.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:03:57.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:03:59.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:04:01.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:04:03.171: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982225, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:04:06.035: INFO: Waited 856.568541ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:04:06.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-9174" for this suite.
Dec  3 15:04:12.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:04:12.872: INFO: namespace aggregator-9174 deletion completed in 6.160855569s
•SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:04:12.873: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-179
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:04:13.195: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:04:14.515: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-179" for this suite.
Dec  3 15:04:20.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:04:20.681: INFO: namespace custom-resource-definition-179 deletion completed in 6.158985322s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:04:20.682: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3983
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-mg8p
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 15:04:21.211: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-mg8p" in namespace "subpath-3983" to be "success or failure"
Dec  3 15:04:21.216: INFO: Pod "pod-subpath-test-secret-mg8p": Phase="Pending", Reason="", readiness=false. Elapsed: 4.054492ms
Dec  3 15:04:23.221: INFO: Pod "pod-subpath-test-secret-mg8p": Phase="Running", Reason="", readiness=true. Elapsed: 2.009329825s
Dec  3 15:04:25.226: INFO: Pod "pod-subpath-test-secret-mg8p": Phase="Running", Reason="", readiness=true. Elapsed: 4.014476825s
Dec  3 15:04:27.231: INFO: Pod "pod-subpath-test-secret-mg8p": Phase="Running", Reason="", readiness=true. Elapsed: 6.019615994s
Dec  3 15:04:29.239: INFO: Pod "pod-subpath-test-secret-mg8p": Phase="Running", Reason="", readiness=true. Elapsed: 8.027244278s
Dec  3 15:04:31.244: INFO: Pod "pod-subpath-test-secret-mg8p": Phase="Running", Reason="", readiness=true. Elapsed: 10.032652962s
Dec  3 15:04:33.249: INFO: Pod "pod-subpath-test-secret-mg8p": Phase="Running", Reason="", readiness=true. Elapsed: 12.037746994s
Dec  3 15:04:35.255: INFO: Pod "pod-subpath-test-secret-mg8p": Phase="Running", Reason="", readiness=true. Elapsed: 14.042990634s
Dec  3 15:04:37.260: INFO: Pod "pod-subpath-test-secret-mg8p": Phase="Running", Reason="", readiness=true. Elapsed: 16.048303322s
Dec  3 15:04:39.265: INFO: Pod "pod-subpath-test-secret-mg8p": Phase="Running", Reason="", readiness=true. Elapsed: 18.053481373s
Dec  3 15:04:41.270: INFO: Pod "pod-subpath-test-secret-mg8p": Phase="Running", Reason="", readiness=true. Elapsed: 20.058732765s
Dec  3 15:04:43.275: INFO: Pod "pod-subpath-test-secret-mg8p": Phase="Running", Reason="", readiness=true. Elapsed: 22.063662139s
Dec  3 15:04:45.281: INFO: Pod "pod-subpath-test-secret-mg8p": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.068973696s
STEP: Saw pod success
Dec  3 15:04:45.281: INFO: Pod "pod-subpath-test-secret-mg8p" satisfied condition "success or failure"
Dec  3 15:04:45.285: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-subpath-test-secret-mg8p container test-container-subpath-secret-mg8p: <nil>
STEP: delete the pod
Dec  3 15:04:45.422: INFO: Waiting for pod pod-subpath-test-secret-mg8p to disappear
Dec  3 15:04:45.426: INFO: Pod pod-subpath-test-secret-mg8p no longer exists
STEP: Deleting pod pod-subpath-test-secret-mg8p
Dec  3 15:04:45.426: INFO: Deleting pod "pod-subpath-test-secret-mg8p" in namespace "subpath-3983"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:04:45.430: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3983" for this suite.
Dec  3 15:04:53.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:04:53.594: INFO: namespace subpath-3983 deletion completed in 8.156781282s
•SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:04:53.594: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5328
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:04:54.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5328" for this suite.
Dec  3 15:05:02.213: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:05:02.402: INFO: namespace services-5328 deletion completed in 8.20315346s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:05:02.402: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6511
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec  3 15:05:02.701: INFO: Waiting up to 5m0s for pod "downward-api-e39181e4-4aa2-4f0d-918f-8bfdf23027e6" in namespace "downward-api-6511" to be "success or failure"
Dec  3 15:05:02.705: INFO: Pod "downward-api-e39181e4-4aa2-4f0d-918f-8bfdf23027e6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.006296ms
Dec  3 15:05:04.710: INFO: Pod "downward-api-e39181e4-4aa2-4f0d-918f-8bfdf23027e6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009389224s
STEP: Saw pod success
Dec  3 15:05:04.710: INFO: Pod "downward-api-e39181e4-4aa2-4f0d-918f-8bfdf23027e6" satisfied condition "success or failure"
Dec  3 15:05:04.715: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downward-api-e39181e4-4aa2-4f0d-918f-8bfdf23027e6 container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:05:04.739: INFO: Waiting for pod downward-api-e39181e4-4aa2-4f0d-918f-8bfdf23027e6 to disappear
Dec  3 15:05:04.744: INFO: Pod downward-api-e39181e4-4aa2-4f0d-918f-8bfdf23027e6 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:05:04.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6511" for this suite.
Dec  3 15:05:10.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:05:10.908: INFO: namespace downward-api-6511 deletion completed in 6.156247479s
•SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:05:10.908: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8337
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec  3 15:05:11.304: INFO: Waiting up to 5m0s for pod "downward-api-797b10c3-893b-4ecb-ab7a-b24a5dc877c9" in namespace "downward-api-8337" to be "success or failure"
Dec  3 15:05:11.308: INFO: Pod "downward-api-797b10c3-893b-4ecb-ab7a-b24a5dc877c9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.256391ms
Dec  3 15:05:13.313: INFO: Pod "downward-api-797b10c3-893b-4ecb-ab7a-b24a5dc877c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00951083s
STEP: Saw pod success
Dec  3 15:05:13.314: INFO: Pod "downward-api-797b10c3-893b-4ecb-ab7a-b24a5dc877c9" satisfied condition "success or failure"
Dec  3 15:05:13.318: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downward-api-797b10c3-893b-4ecb-ab7a-b24a5dc877c9 container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:05:13.340: INFO: Waiting for pod downward-api-797b10c3-893b-4ecb-ab7a-b24a5dc877c9 to disappear
Dec  3 15:05:13.344: INFO: Pod downward-api-797b10c3-893b-4ecb-ab7a-b24a5dc877c9 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:05:13.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8337" for this suite.
Dec  3 15:05:21.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:05:21.506: INFO: namespace downward-api-8337 deletion completed in 8.155285059s
•SSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:05:21.507: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2040
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:05:21.893: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Dec  3 15:05:22.925: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:05:22.931: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2040" for this suite.
Dec  3 15:05:30.953: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:05:31.096: INFO: namespace replication-controller-2040 deletion completed in 8.157641902s
•SSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:05:31.097: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-5867
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Dec  3 15:05:33.928: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-5867 pod-service-account-1fd2b883-887a-4ef6-a968-2a37eb6b64bf -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Dec  3 15:05:34.590: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-5867 pod-service-account-1fd2b883-887a-4ef6-a968-2a37eb6b64bf -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Dec  3 15:05:35.231: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-5867 pod-service-account-1fd2b883-887a-4ef6-a968-2a37eb6b64bf -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:05:35.784: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-5867" for this suite.
Dec  3 15:05:43.806: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:05:43.957: INFO: namespace svcaccounts-5867 deletion completed in 8.165519182s
•SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:05:43.958: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4354
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4354.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-4354.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4354.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-4354.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-4354.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4354.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:05:46.904: INFO: DNS probes using dns-4354/dns-test-4a0f918a-903d-4067-bbb9-1767a383bf69 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:05:46.920: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4354" for this suite.
Dec  3 15:05:52.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:05:53.088: INFO: namespace dns-4354 deletion completed in 6.160849858s
•SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:05:53.088: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2014
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:06:53.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2014" for this suite.
Dec  3 15:07:23.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:23.760: INFO: namespace container-probe-2014 deletion completed in 30.149654861s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:07:23.761: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9454
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:07:24.101: INFO: Waiting up to 5m0s for pod "downwardapi-volume-be025765-b69a-48b8-be74-66a826cd805e" in namespace "downward-api-9454" to be "success or failure"
Dec  3 15:07:24.105: INFO: Pod "downwardapi-volume-be025765-b69a-48b8-be74-66a826cd805e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.137412ms
Dec  3 15:07:26.110: INFO: Pod "downwardapi-volume-be025765-b69a-48b8-be74-66a826cd805e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009078748s
STEP: Saw pod success
Dec  3 15:07:26.110: INFO: Pod "downwardapi-volume-be025765-b69a-48b8-be74-66a826cd805e" satisfied condition "success or failure"
Dec  3 15:07:26.115: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downwardapi-volume-be025765-b69a-48b8-be74-66a826cd805e container client-container: <nil>
STEP: delete the pod
Dec  3 15:07:26.274: INFO: Waiting for pod downwardapi-volume-be025765-b69a-48b8-be74-66a826cd805e to disappear
Dec  3 15:07:26.278: INFO: Pod downwardapi-volume-be025765-b69a-48b8-be74-66a826cd805e no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:07:26.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9454" for this suite.
Dec  3 15:07:32.300: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:32.441: INFO: namespace downward-api-9454 deletion completed in 6.155864676s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:07:32.442: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-261
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:07:32.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-261" for this suite.
Dec  3 15:07:38.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:38.967: INFO: namespace custom-resource-definition-261 deletion completed in 6.155763144s
•SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:07:38.967: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5045
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:07:52.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5045" for this suite.
Dec  3 15:08:00.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:08:00.524: INFO: namespace resourcequota-5045 deletion completed in 8.160696238s
•S
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:08:00.524: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8744
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  3 15:08:00.832: INFO: Number of nodes with available pods: 0
Dec  3 15:08:00.832: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 15:08:01.845: INFO: Number of nodes with available pods: 0
Dec  3 15:08:01.845: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 15:08:02.846: INFO: Number of nodes with available pods: 2
Dec  3 15:08:02.846: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec  3 15:08:02.873: INFO: Number of nodes with available pods: 1
Dec  3 15:08:02.873: INFO: Node izgw8fisrtg04goc4t8tqaz is running more than one daemon pod
Dec  3 15:08:03.885: INFO: Number of nodes with available pods: 1
Dec  3 15:08:03.885: INFO: Node izgw8fisrtg04goc4t8tqaz is running more than one daemon pod
Dec  3 15:08:04.886: INFO: Number of nodes with available pods: 2
Dec  3 15:08:04.886: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8744, will wait for the garbage collector to delete the pods
Dec  3 15:08:04.958: INFO: Deleting DaemonSet.extensions daemon-set took: 7.199586ms
Dec  3 15:08:05.058: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.365667ms
Dec  3 15:08:08.363: INFO: Number of nodes with available pods: 0
Dec  3 15:08:08.363: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 15:08:08.369: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8744/daemonsets","resourceVersion":"12159"},"items":null}

Dec  3 15:08:08.374: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8744/pods","resourceVersion":"12159"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:08:08.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8744" for this suite.
Dec  3 15:08:16.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:08:16.556: INFO: namespace daemonsets-8744 deletion completed in 8.161664748s
•SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:08:16.556: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6234
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:08:16.988: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config version'
Dec  3 15:08:17.119: INFO: stderr: ""
Dec  3 15:08:17.119: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.3\", GitCommit:\"b3cbbae08ec52a7fc73d334838e18d17e8512749\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:23:11Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.3\", GitCommit:\"b3cbbae08ec52a7fc73d334838e18d17e8512749\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:13:49Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:08:17.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6234" for this suite.
Dec  3 15:08:23.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:08:23.282: INFO: namespace kubectl-6234 deletion completed in 6.157640636s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:08:23.283: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6797
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  3 15:08:23.697: INFO: Waiting up to 5m0s for pod "pod-12dc187b-f02d-4fa4-9e50-d07917bdd7ff" in namespace "emptydir-6797" to be "success or failure"
Dec  3 15:08:23.701: INFO: Pod "pod-12dc187b-f02d-4fa4-9e50-d07917bdd7ff": Phase="Pending", Reason="", readiness=false. Elapsed: 4.137498ms
Dec  3 15:08:25.706: INFO: Pod "pod-12dc187b-f02d-4fa4-9e50-d07917bdd7ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009573541s
STEP: Saw pod success
Dec  3 15:08:25.706: INFO: Pod "pod-12dc187b-f02d-4fa4-9e50-d07917bdd7ff" satisfied condition "success or failure"
Dec  3 15:08:25.711: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-12dc187b-f02d-4fa4-9e50-d07917bdd7ff container test-container: <nil>
STEP: delete the pod
Dec  3 15:08:25.736: INFO: Waiting for pod pod-12dc187b-f02d-4fa4-9e50-d07917bdd7ff to disappear
Dec  3 15:08:25.740: INFO: Pod pod-12dc187b-f02d-4fa4-9e50-d07917bdd7ff no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:08:25.741: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6797" for this suite.
Dec  3 15:08:31.762: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:08:31.907: INFO: namespace emptydir-6797 deletion completed in 6.159453933s
•SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:08:31.908: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5920
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:08:33.006: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:08:36.029: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:08:36.034: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-1159-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:08:36.958: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5920" for this suite.
Dec  3 15:08:44.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:08:45.122: INFO: namespace webhook-5920 deletion completed in 8.156062715s
STEP: Destroying namespace "webhook-5920-markers" for this suite.
Dec  3 15:08:51.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:08:51.278: INFO: namespace webhook-5920-markers deletion completed in 6.156321056s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:08:51.296: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-7175
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:08:53.646: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-7175" for this suite.
Dec  3 15:09:01.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:09:01.815: INFO: namespace emptydir-wrapper-7175 deletion completed in 8.161543556s
•SS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:09:01.815: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7078
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-cf0c9aaf-4fd0-4865-9041-c89e4bc0db8b in namespace container-probe-7078
Dec  3 15:09:04.307: INFO: Started pod test-webserver-cf0c9aaf-4fd0-4865-9041-c89e4bc0db8b in namespace container-probe-7078
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 15:09:04.312: INFO: Initial restart count of pod test-webserver-cf0c9aaf-4fd0-4865-9041-c89e4bc0db8b is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:13:04.949: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7078" for this suite.
Dec  3 15:13:10.970: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:13:11.108: INFO: namespace container-probe-7078 deletion completed in 6.151765049s
•SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:13:11.108: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9847
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:13:11.595: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1b5cbf36-806f-4140-b799-e11ba2b0022d" in namespace "projected-9847" to be "success or failure"
Dec  3 15:13:11.599: INFO: Pod "downwardapi-volume-1b5cbf36-806f-4140-b799-e11ba2b0022d": Phase="Pending", Reason="", readiness=false. Elapsed: 3.9567ms
Dec  3 15:13:13.604: INFO: Pod "downwardapi-volume-1b5cbf36-806f-4140-b799-e11ba2b0022d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009314255s
STEP: Saw pod success
Dec  3 15:13:13.604: INFO: Pod "downwardapi-volume-1b5cbf36-806f-4140-b799-e11ba2b0022d" satisfied condition "success or failure"
Dec  3 15:13:13.608: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downwardapi-volume-1b5cbf36-806f-4140-b799-e11ba2b0022d container client-container: <nil>
STEP: delete the pod
Dec  3 15:13:13.770: INFO: Waiting for pod downwardapi-volume-1b5cbf36-806f-4140-b799-e11ba2b0022d to disappear
Dec  3 15:13:13.774: INFO: Pod downwardapi-volume-1b5cbf36-806f-4140-b799-e11ba2b0022d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:13:13.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9847" for this suite.
Dec  3 15:13:19.795: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:13:19.935: INFO: namespace projected-9847 deletion completed in 6.153731675s
•SSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:13:19.935: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5107
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:13:44.513: INFO: Container started at 2019-12-03 15:13:21 +0000 UTC, pod became ready at 2019-12-03 15:13:42 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:13:44.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5107" for this suite.
Dec  3 15:14:14.535: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:14:14.672: INFO: namespace container-probe-5107 deletion completed in 30.151696855s
•SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:14:14.673: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6821
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:14:15.098: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c1c167f9-193f-4cb4-bea4-62c538b35fd7" in namespace "projected-6821" to be "success or failure"
Dec  3 15:14:15.103: INFO: Pod "downwardapi-volume-c1c167f9-193f-4cb4-bea4-62c538b35fd7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.066719ms
Dec  3 15:14:17.107: INFO: Pod "downwardapi-volume-c1c167f9-193f-4cb4-bea4-62c538b35fd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009017853s
STEP: Saw pod success
Dec  3 15:14:17.108: INFO: Pod "downwardapi-volume-c1c167f9-193f-4cb4-bea4-62c538b35fd7" satisfied condition "success or failure"
Dec  3 15:14:17.112: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downwardapi-volume-c1c167f9-193f-4cb4-bea4-62c538b35fd7 container client-container: <nil>
STEP: delete the pod
Dec  3 15:14:17.140: INFO: Waiting for pod downwardapi-volume-c1c167f9-193f-4cb4-bea4-62c538b35fd7 to disappear
Dec  3 15:14:17.150: INFO: Pod downwardapi-volume-c1c167f9-193f-4cb4-bea4-62c538b35fd7 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:14:17.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6821" for this suite.
Dec  3 15:14:23.172: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:14:23.353: INFO: namespace projected-6821 deletion completed in 6.195187241s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:14:23.355: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5849
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-a06adcce-a8a0-4fe4-879d-6fc2538e8875
STEP: Creating a pod to test consume secrets
Dec  3 15:14:23.803: INFO: Waiting up to 5m0s for pod "pod-secrets-caa88831-19c7-47fc-91e0-e0b5ccd56c64" in namespace "secrets-5849" to be "success or failure"
Dec  3 15:14:23.807: INFO: Pod "pod-secrets-caa88831-19c7-47fc-91e0-e0b5ccd56c64": Phase="Pending", Reason="", readiness=false. Elapsed: 3.815025ms
Dec  3 15:14:25.812: INFO: Pod "pod-secrets-caa88831-19c7-47fc-91e0-e0b5ccd56c64": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00905031s
STEP: Saw pod success
Dec  3 15:14:25.812: INFO: Pod "pod-secrets-caa88831-19c7-47fc-91e0-e0b5ccd56c64" satisfied condition "success or failure"
Dec  3 15:14:25.816: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-secrets-caa88831-19c7-47fc-91e0-e0b5ccd56c64 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:14:25.837: INFO: Waiting for pod pod-secrets-caa88831-19c7-47fc-91e0-e0b5ccd56c64 to disappear
Dec  3 15:14:25.841: INFO: Pod pod-secrets-caa88831-19c7-47fc-91e0-e0b5ccd56c64 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:14:25.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5849" for this suite.
Dec  3 15:14:31.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:14:31.999: INFO: namespace secrets-5849 deletion completed in 6.150975855s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:14:31.999: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7811
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:14:33.075: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:14:36.100: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:14:36.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7811" for this suite.
Dec  3 15:14:44.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:14:44.555: INFO: namespace webhook-7811 deletion completed in 8.156599048s
STEP: Destroying namespace "webhook-7811-markers" for this suite.
Dec  3 15:14:50.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:14:50.719: INFO: namespace webhook-7811-markers deletion completed in 6.1648276s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:14:50.738: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8804
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:15:02.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8804" for this suite.
Dec  3 15:15:08.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:15:08.300: INFO: namespace resourcequota-8804 deletion completed in 6.158682873s
•S
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:15:08.300: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-9868
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1849
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-6528
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:15:15.395: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-9868" for this suite.
Dec  3 15:15:23.417: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:15:23.565: INFO: namespace namespaces-9868 deletion completed in 8.162392738s
STEP: Destroying namespace "nsdeletetest-1849" for this suite.
Dec  3 15:15:23.569: INFO: Namespace nsdeletetest-1849 was already deleted
STEP: Destroying namespace "nsdeletetest-6528" for this suite.
Dec  3 15:15:29.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:15:29.720: INFO: namespace nsdeletetest-6528 deletion completed in 6.15120812s
•SSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:15:29.721: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-7873
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec  3 15:15:30.091: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:15:33.878: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-7873" for this suite.
Dec  3 15:15:39.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:15:40.039: INFO: namespace init-container-7873 deletion completed in 6.153735808s
•SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:15:40.040: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1782
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Dec  3 15:16:20.429: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1203 15:16:20.429503    5091 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:16:20.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1782" for this suite.
Dec  3 15:16:28.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:16:28.600: INFO: namespace gc-1782 deletion completed in 8.165709s
•SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:16:28.600: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5217
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-4a825b6a-83ff-41c3-8af7-0df018c4a09d
STEP: Creating a pod to test consume secrets
Dec  3 15:16:28.920: INFO: Waiting up to 5m0s for pod "pod-secrets-aaaa44d9-79b6-44bf-996b-455919b981e4" in namespace "secrets-5217" to be "success or failure"
Dec  3 15:16:28.925: INFO: Pod "pod-secrets-aaaa44d9-79b6-44bf-996b-455919b981e4": Phase="Pending", Reason="", readiness=false. Elapsed: 4.576912ms
Dec  3 15:16:30.930: INFO: Pod "pod-secrets-aaaa44d9-79b6-44bf-996b-455919b981e4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009898123s
STEP: Saw pod success
Dec  3 15:16:30.930: INFO: Pod "pod-secrets-aaaa44d9-79b6-44bf-996b-455919b981e4" satisfied condition "success or failure"
Dec  3 15:16:30.935: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-secrets-aaaa44d9-79b6-44bf-996b-455919b981e4 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:16:31.097: INFO: Waiting for pod pod-secrets-aaaa44d9-79b6-44bf-996b-455919b981e4 to disappear
Dec  3 15:16:31.101: INFO: Pod pod-secrets-aaaa44d9-79b6-44bf-996b-455919b981e4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:16:31.101: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5217" for this suite.
Dec  3 15:16:37.123: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:16:37.314: INFO: namespace secrets-5217 deletion completed in 6.205549596s
•SSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:16:37.314: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6806
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Dec  3 15:16:37.898: INFO: Waiting up to 5m0s for pod "client-containers-5fa9c531-9c3d-463a-b972-98170d9966f7" in namespace "containers-6806" to be "success or failure"
Dec  3 15:16:37.903: INFO: Pod "client-containers-5fa9c531-9c3d-463a-b972-98170d9966f7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.937646ms
Dec  3 15:16:39.909: INFO: Pod "client-containers-5fa9c531-9c3d-463a-b972-98170d9966f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01066341s
STEP: Saw pod success
Dec  3 15:16:39.909: INFO: Pod "client-containers-5fa9c531-9c3d-463a-b972-98170d9966f7" satisfied condition "success or failure"
Dec  3 15:16:39.914: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod client-containers-5fa9c531-9c3d-463a-b972-98170d9966f7 container test-container: <nil>
STEP: delete the pod
Dec  3 15:16:39.936: INFO: Waiting for pod client-containers-5fa9c531-9c3d-463a-b972-98170d9966f7 to disappear
Dec  3 15:16:39.940: INFO: Pod client-containers-5fa9c531-9c3d-463a-b972-98170d9966f7 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:16:39.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6806" for this suite.
Dec  3 15:16:45.961: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:16:46.108: INFO: namespace containers-6806 deletion completed in 6.160624024s
•SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:16:46.108: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2503
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  3 15:16:46.502: INFO: Waiting up to 5m0s for pod "pod-083b413f-f400-4b69-93cc-d210d2abf956" in namespace "emptydir-2503" to be "success or failure"
Dec  3 15:16:46.507: INFO: Pod "pod-083b413f-f400-4b69-93cc-d210d2abf956": Phase="Pending", Reason="", readiness=false. Elapsed: 4.268916ms
Dec  3 15:16:48.512: INFO: Pod "pod-083b413f-f400-4b69-93cc-d210d2abf956": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009372794s
STEP: Saw pod success
Dec  3 15:16:48.512: INFO: Pod "pod-083b413f-f400-4b69-93cc-d210d2abf956" satisfied condition "success or failure"
Dec  3 15:16:48.517: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-083b413f-f400-4b69-93cc-d210d2abf956 container test-container: <nil>
STEP: delete the pod
Dec  3 15:16:48.583: INFO: Waiting for pod pod-083b413f-f400-4b69-93cc-d210d2abf956 to disappear
Dec  3 15:16:48.587: INFO: Pod pod-083b413f-f400-4b69-93cc-d210d2abf956 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:16:48.588: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2503" for this suite.
Dec  3 15:16:54.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:16:54.794: INFO: namespace emptydir-2503 deletion completed in 6.199906365s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:16:54.795: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9718
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:16:55.293: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-9718'
Dec  3 15:16:55.899: INFO: stderr: ""
Dec  3 15:16:55.899: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec  3 15:16:55.899: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-9718'
Dec  3 15:16:56.128: INFO: stderr: ""
Dec  3 15:16:56.128: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  3 15:16:57.134: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:16:57.134: INFO: Found 0 / 1
Dec  3 15:16:58.134: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:16:58.134: INFO: Found 1 / 1
Dec  3 15:16:58.134: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  3 15:16:58.139: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:16:58.139: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 15:16:58.139: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe pod redis-master-rfr6p --namespace=kubectl-9718'
Dec  3 15:16:58.304: INFO: stderr: ""
Dec  3 15:16:58.305: INFO: stdout: "Name:         redis-master-rfr6p\nNamespace:    kubectl-9718\nPriority:     0\nNode:         izgw8fisrtg04goc4t8tqaz/10.250.2.117\nStart Time:   Tue, 03 Dec 2019 15:16:55 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  cni.projectcalico.org/podIP: 100.64.1.102/32\n              kubernetes.io/psp: e2e-test-privileged-psp\nStatus:       Running\nIP:           100.64.1.102\nIPs:\n  IP:           100.64.1.102\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://4af41fee8102838fdc7abe104b5a73c018b7145b00d68acfb8ada5e64ca60cd4\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 03 Dec 2019 15:16:56 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-np7jv (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-np7jv:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-np7jv\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                              Message\n  ----    ------     ----       ----                              -------\n  Normal  Scheduled  <unknown>  default-scheduler                 Successfully assigned kubectl-9718/redis-master-rfr6p to izgw8fisrtg04goc4t8tqaz\n  Normal  Pulled     2s         kubelet, izgw8fisrtg04goc4t8tqaz  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    2s         kubelet, izgw8fisrtg04goc4t8tqaz  Created container redis-master\n  Normal  Started    2s         kubelet, izgw8fisrtg04goc4t8tqaz  Started container redis-master\n"
Dec  3 15:16:58.305: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe rc redis-master --namespace=kubectl-9718'
Dec  3 15:16:58.494: INFO: stderr: ""
Dec  3 15:16:58.494: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-9718\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-rfr6p\n"
Dec  3 15:16:58.494: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe service redis-master --namespace=kubectl-9718'
Dec  3 15:16:58.673: INFO: stderr: ""
Dec  3 15:16:58.673: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-9718\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                100.111.54.105\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         100.64.1.102:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec  3 15:16:58.681: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe node izgw88vcbd5x6ev7zbjg8vz'
Dec  3 15:16:58.806: INFO: stderr: ""
Dec  3 15:16:58.806: INFO: stdout: "Name:               izgw88vcbd5x6ev7zbjg8vz\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=ecs.sn2ne.large\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=eu-central-1\n                    failure-domain.beta.kubernetes.io/zone=eu-central-1b\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=izgw88vcbd5x6ev7zbjg8vz\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/role=node\n                    topology.diskplugin.csi.alibabacloud.com/zone=eu-central-1b\n                    worker.garden.sapcloud.io/group=worker-1\n                    worker.gardener.cloud/pool=worker-1\nAnnotations:        csi.volume.kubernetes.io/nodeid: {\"diskplugin.csi.alibabacloud.com\":\"i-gw88vcbd5x6ev7zbjg8v\"}\n                    node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.250.2.118/19\n                    projectcalico.org/IPv4IPIPTunnelAddr: 100.64.0.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 03 Dec 2019 14:26:16 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                          Status  LastHeartbeatTime                 LastTransitionTime                Reason                          Message\n  ----                          ------  -----------------                 ------------------                ------                          -------\n  CorruptDockerOverlay2         False   Tue, 03 Dec 2019 15:16:51 +0000   Tue, 03 Dec 2019 14:27:18 +0000   NoCorruptDockerOverlay2         docker overlay2 is functioning properly\n  FrequentUnregisterNetDevice   False   Tue, 03 Dec 2019 15:16:51 +0000   Tue, 03 Dec 2019 14:27:18 +0000   NoFrequentUnregisterNetDevice   node is functioning properly\n  FrequentKubeletRestart        False   Tue, 03 Dec 2019 15:16:51 +0000   Tue, 03 Dec 2019 14:27:18 +0000   NoFrequentKubeletRestart        kubelet is functioning properly\n  FrequentDockerRestart         False   Tue, 03 Dec 2019 15:16:51 +0000   Tue, 03 Dec 2019 14:27:18 +0000   NoFrequentDockerRestart         docker is functioning properly\n  FrequentContainerdRestart     False   Tue, 03 Dec 2019 15:16:51 +0000   Tue, 03 Dec 2019 14:27:18 +0000   NoFrequentContainerdRestart     containerd is functioning properly\n  KernelDeadlock                False   Tue, 03 Dec 2019 15:16:51 +0000   Tue, 03 Dec 2019 14:27:18 +0000   KernelHasNoDeadlock             kernel has no deadlock\n  ReadonlyFilesystem            False   Tue, 03 Dec 2019 15:16:51 +0000   Tue, 03 Dec 2019 14:27:18 +0000   FilesystemIsNotReadOnly         Filesystem is not read-only\n  NetworkUnavailable            False   Tue, 03 Dec 2019 14:27:07 +0000   Tue, 03 Dec 2019 14:27:07 +0000   CalicoIsUp                      Calico is running on this node\n  MemoryPressure                False   Tue, 03 Dec 2019 15:16:51 +0000   Tue, 03 Dec 2019 14:26:16 +0000   KubeletHasSufficientMemory      kubelet has sufficient memory available\n  DiskPressure                  False   Tue, 03 Dec 2019 15:16:51 +0000   Tue, 03 Dec 2019 14:26:16 +0000   KubeletHasNoDiskPressure        kubelet has no disk pressure\n  PIDPressure                   False   Tue, 03 Dec 2019 15:16:51 +0000   Tue, 03 Dec 2019 14:26:16 +0000   KubeletHasSufficientPID         kubelet has sufficient PID available\n  Ready                         True    Tue, 03 Dec 2019 15:16:51 +0000   Tue, 03 Dec 2019 14:26:56 +0000   KubeletReady                    kubelet is posting ready status\nAddresses:\n  InternalIP:  10.250.2.118\n  Hostname:    izgw88vcbd5x6ev7zbjg8vz\nCapacity:\n cpu:                2\n ephemeral-storage:  33136428Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             8169216Ki\n pods:               110\nAllocatable:\n cpu:                1920m\n ephemeral-storage:  32235117134\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             6873271495\n pods:               110\nSystem Info:\n Machine ID:                 d08effa587b640daa6bc22c4c5caed40\n System UUID:                d08effa5-87b6-40da-a6bc-22c4c5caed40\n Boot ID:                    471fdf30-43d8-4f0e-8f80-b7dec4be1cea\n Kernel Version:             4.19.66-coreos\n OS Image:                   Container Linux by CoreOS 2191.4.1 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.16.3\n Kube-Proxy Version:         v1.16.3\nPodCIDR:                     100.64.0.0/24\nPodCIDRs:                    100.64.0.0/24\nProviderID:                  eu-central-1.i-gw88vcbd5x6ev7zbjg8v\nNon-terminated Pods:         (15 in total)\n  Namespace                  Name                                                              CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                              ------------  ----------  ---------------  -------------  ---\n  kube-system                addons-kubernetes-dashboard-78954cc66b-mh5g8                      50m (2%)      100m (5%)   50Mi (0%)        256Mi (3%)     52m\n  kube-system                addons-nginx-ingress-controller-7c75bb76db-8qn7n                  100m (5%)     2 (104%)    100Mi (1%)       1Gi (15%)      52m\n  kube-system                addons-nginx-ingress-nginx-ingress-k8s-backend-95f65778d-6v4hg    0 (0%)        0 (0%)      0 (0%)           0 (0%)         52m\n  kube-system                blackbox-exporter-7bd7b55dfc-jjbg2                                5m (0%)       10m (0%)    5Mi (0%)         35Mi (0%)      52m\n  kube-system                calico-node-rx7sf                                                 100m (5%)     500m (26%)  100Mi (1%)       700Mi (10%)    50m\n  kube-system                calico-typha-horizontal-autoscaler-69df649c59-wrrxb               10m (0%)      10m (0%)    0 (0%)           0 (0%)         52m\n  kube-system                calico-typha-vertical-autoscaler-847d859f8c-6xhsp                 0 (0%)        0 (0%)      0 (0%)           0 (0%)         52m\n  kube-system                coredns-59c969ffb8-9mq2d                                          50m (2%)      100m (5%)   15Mi (0%)        100Mi (1%)     52m\n  kube-system                coredns-59c969ffb8-xnfvv                                          50m (2%)      100m (5%)   15Mi (0%)        100Mi (1%)     52m\n  kube-system                csi-disk-plugin-alicloud-55sss                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         50m\n  kube-system                kube-proxy-frcrz                                                  20m (1%)      0 (0%)      64Mi (0%)        0 (0%)         50m\n  kube-system                metrics-server-69dcc87559-8j9rx                                   20m (1%)      80m (4%)    100Mi (1%)       400Mi (6%)     52m\n  kube-system                node-exporter-xwww8                                               5m (0%)       25m (1%)    10Mi (0%)        100Mi (1%)     50m\n  kube-system                node-problem-detector-jj8gj                                       20m (1%)      200m (10%)  20Mi (0%)        100Mi (1%)     50m\n  kube-system                vpn-shoot-76845cddf7-dh4gs                                        100m (5%)     1 (52%)     100Mi (1%)       1000Mi (15%)   52m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                530m (27%)  4125m (214%)\n  memory             579Mi (8%)  3815Mi (58%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:\n  Type     Reason                   Age                From                                      Message\n  ----     ------                   ----               ----                                      -------\n  Normal   Starting                 50m                kubelet, izgw88vcbd5x6ev7zbjg8vz          Starting kubelet.\n  Normal   NodeHasSufficientMemory  50m                kubelet, izgw88vcbd5x6ev7zbjg8vz          Node izgw88vcbd5x6ev7zbjg8vz status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    50m                kubelet, izgw88vcbd5x6ev7zbjg8vz          Node izgw88vcbd5x6ev7zbjg8vz status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     50m                kubelet, izgw88vcbd5x6ev7zbjg8vz          Node izgw88vcbd5x6ev7zbjg8vz status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  50m                kubelet, izgw88vcbd5x6ev7zbjg8vz          Updated Node Allocatable limit across pods\n  Normal   Starting                 50m                kube-proxy, izgw88vcbd5x6ev7zbjg8vz       Starting kube-proxy.\n  Normal   NodeReady                50m                kubelet, izgw88vcbd5x6ev7zbjg8vz          Node izgw88vcbd5x6ev7zbjg8vz status is now: NodeReady\n  Warning  DockerStart              49m (x3 over 49m)  systemd-monitor, izgw88vcbd5x6ev7zbjg8vz  Starting Docker Application Container Engine...\n"
Dec  3 15:16:58.806: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe namespace kubectl-9718'
Dec  3 15:16:58.985: INFO: stderr: ""
Dec  3 15:16:58.985: INFO: stdout: "Name:         kubectl-9718\nLabels:       e2e-framework=kubectl\n              e2e-run=3ed23c52-e8ac-49cb-b7fb-9bf07a2e81e4\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:16:58.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9718" for this suite.
Dec  3 15:17:13.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:17:13.144: INFO: namespace kubectl-9718 deletion completed in 14.151741001s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:17:13.145: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3130
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:17:30.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3130" for this suite.
Dec  3 15:17:36.465: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:17:36.605: INFO: namespace resourcequota-3130 deletion completed in 6.153670758s
•SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:17:36.605: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6257
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-c974120a-049f-452f-bdc1-e42f652fe11c
STEP: Creating a pod to test consume configMaps
Dec  3 15:17:37.110: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-1cc870b3-bae1-411b-b7d0-d5a5b1450a3e" in namespace "projected-6257" to be "success or failure"
Dec  3 15:17:37.114: INFO: Pod "pod-projected-configmaps-1cc870b3-bae1-411b-b7d0-d5a5b1450a3e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.210027ms
Dec  3 15:17:39.120: INFO: Pod "pod-projected-configmaps-1cc870b3-bae1-411b-b7d0-d5a5b1450a3e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009759302s
STEP: Saw pod success
Dec  3 15:17:39.120: INFO: Pod "pod-projected-configmaps-1cc870b3-bae1-411b-b7d0-d5a5b1450a3e" satisfied condition "success or failure"
Dec  3 15:17:39.124: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-projected-configmaps-1cc870b3-bae1-411b-b7d0-d5a5b1450a3e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:17:39.146: INFO: Waiting for pod pod-projected-configmaps-1cc870b3-bae1-411b-b7d0-d5a5b1450a3e to disappear
Dec  3 15:17:39.150: INFO: Pod pod-projected-configmaps-1cc870b3-bae1-411b-b7d0-d5a5b1450a3e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:17:39.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6257" for this suite.
Dec  3 15:17:47.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:17:47.540: INFO: namespace projected-6257 deletion completed in 8.383029602s
•
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:17:47.540: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9393
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:17:58.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9393" for this suite.
Dec  3 15:18:04.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:18:05.047: INFO: namespace resourcequota-9393 deletion completed in 6.200975924s
•
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:18:05.047: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1591
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Dec  3 15:18:05.491: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-1591'
Dec  3 15:18:05.691: INFO: stderr: ""
Dec  3 15:18:05.691: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 15:18:05.691: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1591'
Dec  3 15:18:05.844: INFO: stderr: ""
Dec  3 15:18:05.845: INFO: stdout: "update-demo-nautilus-jsgzf update-demo-nautilus-tqw2w "
Dec  3 15:18:05.845: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-jsgzf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1591'
Dec  3 15:18:06.004: INFO: stderr: ""
Dec  3 15:18:06.004: INFO: stdout: ""
Dec  3 15:18:06.004: INFO: update-demo-nautilus-jsgzf is created but not running
Dec  3 15:18:11.005: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1591'
Dec  3 15:18:11.102: INFO: stderr: ""
Dec  3 15:18:11.102: INFO: stdout: "update-demo-nautilus-jsgzf update-demo-nautilus-tqw2w "
Dec  3 15:18:11.103: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-jsgzf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1591'
Dec  3 15:18:11.252: INFO: stderr: ""
Dec  3 15:18:11.253: INFO: stdout: "true"
Dec  3 15:18:11.253: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-jsgzf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1591'
Dec  3 15:18:11.343: INFO: stderr: ""
Dec  3 15:18:11.343: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:18:11.343: INFO: validating pod update-demo-nautilus-jsgzf
Dec  3 15:18:11.438: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:18:11.438: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:18:11.438: INFO: update-demo-nautilus-jsgzf is verified up and running
Dec  3 15:18:11.438: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-tqw2w -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1591'
Dec  3 15:18:11.591: INFO: stderr: ""
Dec  3 15:18:11.591: INFO: stdout: "true"
Dec  3 15:18:11.591: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-tqw2w -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1591'
Dec  3 15:18:11.687: INFO: stderr: ""
Dec  3 15:18:11.687: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:18:11.688: INFO: validating pod update-demo-nautilus-tqw2w
Dec  3 15:18:11.784: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:18:11.784: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:18:11.784: INFO: update-demo-nautilus-tqw2w is verified up and running
STEP: rolling-update to new replication controller
Dec  3 15:18:11.786: INFO: scanned /root for discovery docs: <nil>
Dec  3 15:18:11.786: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-1591'
Dec  3 15:18:34.268: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  3 15:18:34.268: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 15:18:34.268: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1591'
Dec  3 15:18:34.402: INFO: stderr: ""
Dec  3 15:18:34.402: INFO: stdout: "update-demo-kitten-kfdbz update-demo-kitten-xs6q2 "
Dec  3 15:18:34.402: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-kfdbz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1591'
Dec  3 15:18:34.505: INFO: stderr: ""
Dec  3 15:18:34.505: INFO: stdout: "true"
Dec  3 15:18:34.505: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-kfdbz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1591'
Dec  3 15:18:34.674: INFO: stderr: ""
Dec  3 15:18:34.674: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  3 15:18:34.674: INFO: validating pod update-demo-kitten-kfdbz
Dec  3 15:18:34.770: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  3 15:18:34.770: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  3 15:18:34.770: INFO: update-demo-kitten-kfdbz is verified up and running
Dec  3 15:18:34.770: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-xs6q2 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1591'
Dec  3 15:18:34.901: INFO: stderr: ""
Dec  3 15:18:34.901: INFO: stdout: "true"
Dec  3 15:18:34.901: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-xs6q2 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1591'
Dec  3 15:18:34.999: INFO: stderr: ""
Dec  3 15:18:34.999: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  3 15:18:34.999: INFO: validating pod update-demo-kitten-xs6q2
Dec  3 15:18:35.096: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  3 15:18:35.096: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  3 15:18:35.096: INFO: update-demo-kitten-xs6q2 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:18:35.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1591" for this suite.
Dec  3 15:19:03.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:19:03.265: INFO: namespace kubectl-1591 deletion completed in 28.161127844s
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:19:03.265: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1444
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec  3 15:19:03.710: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1444 /api/v1/namespaces/watch-1444/configmaps/e2e-watch-test-configmap-a ec15a97e-54a6-413f-814c-911d7639d1b8 14951 0 2019-12-03 15:19:03 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:19:03.710: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1444 /api/v1/namespaces/watch-1444/configmaps/e2e-watch-test-configmap-a ec15a97e-54a6-413f-814c-911d7639d1b8 14951 0 2019-12-03 15:19:03 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec  3 15:19:13.720: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1444 /api/v1/namespaces/watch-1444/configmaps/e2e-watch-test-configmap-a ec15a97e-54a6-413f-814c-911d7639d1b8 14983 0 2019-12-03 15:19:03 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  3 15:19:13.721: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1444 /api/v1/namespaces/watch-1444/configmaps/e2e-watch-test-configmap-a ec15a97e-54a6-413f-814c-911d7639d1b8 14983 0 2019-12-03 15:19:03 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec  3 15:19:23.731: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1444 /api/v1/namespaces/watch-1444/configmaps/e2e-watch-test-configmap-a ec15a97e-54a6-413f-814c-911d7639d1b8 15016 0 2019-12-03 15:19:03 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 15:19:23.731: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1444 /api/v1/namespaces/watch-1444/configmaps/e2e-watch-test-configmap-a ec15a97e-54a6-413f-814c-911d7639d1b8 15016 0 2019-12-03 15:19:03 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec  3 15:19:33.738: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1444 /api/v1/namespaces/watch-1444/configmaps/e2e-watch-test-configmap-a ec15a97e-54a6-413f-814c-911d7639d1b8 15048 0 2019-12-03 15:19:03 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 15:19:33.738: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1444 /api/v1/namespaces/watch-1444/configmaps/e2e-watch-test-configmap-a ec15a97e-54a6-413f-814c-911d7639d1b8 15048 0 2019-12-03 15:19:03 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec  3 15:19:43.745: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1444 /api/v1/namespaces/watch-1444/configmaps/e2e-watch-test-configmap-b 06898523-9edc-43aa-84a5-26916f898412 15080 0 2019-12-03 15:19:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:19:43.746: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1444 /api/v1/namespaces/watch-1444/configmaps/e2e-watch-test-configmap-b 06898523-9edc-43aa-84a5-26916f898412 15080 0 2019-12-03 15:19:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec  3 15:19:53.753: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1444 /api/v1/namespaces/watch-1444/configmaps/e2e-watch-test-configmap-b 06898523-9edc-43aa-84a5-26916f898412 15113 0 2019-12-03 15:19:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:19:53.753: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1444 /api/v1/namespaces/watch-1444/configmaps/e2e-watch-test-configmap-b 06898523-9edc-43aa-84a5-26916f898412 15113 0 2019-12-03 15:19:43 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:20:03.753: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1444" for this suite.
Dec  3 15:20:11.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:20:11.915: INFO: namespace watch-1444 deletion completed in 8.153330078s
•SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:20:11.916: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5246
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  3 15:20:12.297: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-5246'
Dec  3 15:20:12.403: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 15:20:12.403: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Dec  3 15:20:12.407: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete deployment e2e-test-httpd-deployment --namespace=kubectl-5246'
Dec  3 15:20:12.556: INFO: stderr: ""
Dec  3 15:20:12.556: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:20:12.556: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5246" for this suite.
Dec  3 15:20:42.578: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:20:42.716: INFO: namespace kubectl-5246 deletion completed in 30.152806948s
•SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:20:42.716: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-9741
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:20:43.088: INFO: Creating ReplicaSet my-hostname-basic-8521d0dd-3f11-498b-8df3-dbdb9b34f5f8
Dec  3 15:20:43.097: INFO: Pod name my-hostname-basic-8521d0dd-3f11-498b-8df3-dbdb9b34f5f8: Found 0 pods out of 1
Dec  3 15:20:48.103: INFO: Pod name my-hostname-basic-8521d0dd-3f11-498b-8df3-dbdb9b34f5f8: Found 1 pods out of 1
Dec  3 15:20:48.103: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-8521d0dd-3f11-498b-8df3-dbdb9b34f5f8" is running
Dec  3 15:20:48.108: INFO: Pod "my-hostname-basic-8521d0dd-3f11-498b-8df3-dbdb9b34f5f8-47vxz" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 15:20:43 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 15:20:44 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 15:20:44 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 15:20:43 +0000 UTC Reason: Message:}])
Dec  3 15:20:48.108: INFO: Trying to dial the pod
Dec  3 15:20:53.213: INFO: Controller my-hostname-basic-8521d0dd-3f11-498b-8df3-dbdb9b34f5f8: Got expected result from replica 1 [my-hostname-basic-8521d0dd-3f11-498b-8df3-dbdb9b34f5f8-47vxz]: "my-hostname-basic-8521d0dd-3f11-498b-8df3-dbdb9b34f5f8-47vxz", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:20:53.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-9741" for this suite.
Dec  3 15:21:01.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:21:01.422: INFO: namespace replicaset-9741 deletion completed in 8.20119585s
•SSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:21:01.422: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7252
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Dec  3 15:21:01.888: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config api-versions'
Dec  3 15:21:01.986: INFO: stderr: ""
Dec  3 15:21:01.986: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncert.gardener.cloud/v1alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nsnapshot.storage.k8s.io/v1alpha1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:21:01.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7252" for this suite.
Dec  3 15:21:08.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:21:08.148: INFO: namespace kubectl-7252 deletion completed in 6.155918641s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:21:08.148: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6662
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-60e13a38-5b31-4aa6-b320-4c65876789e0
Dec  3 15:21:08.402: INFO: Pod name my-hostname-basic-60e13a38-5b31-4aa6-b320-4c65876789e0: Found 0 pods out of 1
Dec  3 15:21:13.408: INFO: Pod name my-hostname-basic-60e13a38-5b31-4aa6-b320-4c65876789e0: Found 1 pods out of 1
Dec  3 15:21:13.408: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-60e13a38-5b31-4aa6-b320-4c65876789e0" are running
Dec  3 15:21:13.412: INFO: Pod "my-hostname-basic-60e13a38-5b31-4aa6-b320-4c65876789e0-hppr9" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 15:21:08 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 15:21:10 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 15:21:10 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 15:21:08 +0000 UTC Reason: Message:}])
Dec  3 15:21:13.413: INFO: Trying to dial the pod
Dec  3 15:21:18.487: INFO: Controller my-hostname-basic-60e13a38-5b31-4aa6-b320-4c65876789e0: Got expected result from replica 1 [my-hostname-basic-60e13a38-5b31-4aa6-b320-4c65876789e0-hppr9]: "my-hostname-basic-60e13a38-5b31-4aa6-b320-4c65876789e0-hppr9", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:21:18.488: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6662" for this suite.
Dec  3 15:21:26.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:21:26.661: INFO: namespace replication-controller-6662 deletion completed in 8.1659273s
•SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:21:26.662: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-413
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:21:27.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-413" for this suite.
Dec  3 15:21:35.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:21:35.467: INFO: namespace tables-413 deletion completed in 8.163184678s
•SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:21:35.468: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2757
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-61705e09-4726-4092-8720-12dcdeb6fc3b
STEP: Creating a pod to test consume configMaps
Dec  3 15:21:36.006: INFO: Waiting up to 5m0s for pod "pod-configmaps-4ea1184e-865f-4f48-a6aa-175408105d6e" in namespace "configmap-2757" to be "success or failure"
Dec  3 15:21:36.010: INFO: Pod "pod-configmaps-4ea1184e-865f-4f48-a6aa-175408105d6e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.11473ms
Dec  3 15:21:38.016: INFO: Pod "pod-configmaps-4ea1184e-865f-4f48-a6aa-175408105d6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009682499s
STEP: Saw pod success
Dec  3 15:21:38.016: INFO: Pod "pod-configmaps-4ea1184e-865f-4f48-a6aa-175408105d6e" satisfied condition "success or failure"
Dec  3 15:21:38.020: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-configmaps-4ea1184e-865f-4f48-a6aa-175408105d6e container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:21:38.183: INFO: Waiting for pod pod-configmaps-4ea1184e-865f-4f48-a6aa-175408105d6e to disappear
Dec  3 15:21:38.187: INFO: Pod pod-configmaps-4ea1184e-865f-4f48-a6aa-175408105d6e no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:21:38.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2757" for this suite.
Dec  3 15:21:44.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:21:44.353: INFO: namespace configmap-2757 deletion completed in 6.15924793s
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:21:44.354: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9995
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec  3 15:21:44.800: INFO: Pod name pod-release: Found 0 pods out of 1
Dec  3 15:21:49.806: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:21:49.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9995" for this suite.
Dec  3 15:21:57.844: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:21:57.982: INFO: namespace replication-controller-9995 deletion completed in 8.153110105s
•SSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:21:57.983: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-3916
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Dec  3 15:21:58.495: INFO: Waiting up to 5m0s for pod "var-expansion-6b882968-30ad-478f-9961-d5b45e353753" in namespace "var-expansion-3916" to be "success or failure"
Dec  3 15:21:58.499: INFO: Pod "var-expansion-6b882968-30ad-478f-9961-d5b45e353753": Phase="Pending", Reason="", readiness=false. Elapsed: 4.136577ms
Dec  3 15:22:00.504: INFO: Pod "var-expansion-6b882968-30ad-478f-9961-d5b45e353753": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009370915s
STEP: Saw pod success
Dec  3 15:22:00.505: INFO: Pod "var-expansion-6b882968-30ad-478f-9961-d5b45e353753" satisfied condition "success or failure"
Dec  3 15:22:00.509: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod var-expansion-6b882968-30ad-478f-9961-d5b45e353753 container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:22:00.532: INFO: Waiting for pod var-expansion-6b882968-30ad-478f-9961-d5b45e353753 to disappear
Dec  3 15:22:00.535: INFO: Pod var-expansion-6b882968-30ad-478f-9961-d5b45e353753 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:22:00.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-3916" for this suite.
Dec  3 15:22:06.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:22:06.741: INFO: namespace var-expansion-3916 deletion completed in 6.198061332s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:22:06.742: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6628
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:22:11.111: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6628" for this suite.
Dec  3 15:22:17.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:22:17.300: INFO: namespace kubelet-test-6628 deletion completed in 6.180828226s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:22:17.300: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-205
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:22:18.141: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec  3 15:22:20.155: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983338, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983338, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983338, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983338, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:22:23.169: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Dec  3 15:22:23.325: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:22:23.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-205" for this suite.
Dec  3 15:22:31.408: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:22:31.551: INFO: namespace webhook-205 deletion completed in 8.158672743s
STEP: Destroying namespace "webhook-205-markers" for this suite.
Dec  3 15:22:37.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:22:37.702: INFO: namespace webhook-205-markers deletion completed in 6.1511178s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:22:37.721: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1216
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1216.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1216.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:22:43.299: INFO: DNS probes using dns-1216/dns-test-cb446df8-1bc0-448e-b39b-bc6eb6431607 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:22:43.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1216" for this suite.
Dec  3 15:22:49.330: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:22:49.473: INFO: namespace dns-1216 deletion completed in 6.157084139s
•SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:22:49.473: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8799
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:22:50.389: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec  3 15:22:52.403: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983370, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983370, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983370, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983370, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:22:55.418: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:23:06.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8799" for this suite.
Dec  3 15:23:14.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:23:14.362: INFO: namespace webhook-8799 deletion completed in 8.157172438s
STEP: Destroying namespace "webhook-8799-markers" for this suite.
Dec  3 15:23:20.377: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:23:20.519: INFO: namespace webhook-8799-markers deletion completed in 6.156260549s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•S
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:23:20.536: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-279
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec  3 15:23:20.794: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:23:23.516: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-279" for this suite.
Dec  3 15:23:29.538: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:23:29.686: INFO: namespace init-container-279 deletion completed in 6.162329102s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:23:29.686: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-1843
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:23:30.577: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:23:33.601: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:23:33.606: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:23:34.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-1843" for this suite.
Dec  3 15:23:42.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:23:42.809: INFO: namespace crd-webhook-1843 deletion completed in 8.194548448s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:23:42.827: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-139
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:23:43.104: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d0494196-475d-488c-bf90-b024991bf1b6" in namespace "projected-139" to be "success or failure"
Dec  3 15:23:43.108: INFO: Pod "downwardapi-volume-d0494196-475d-488c-bf90-b024991bf1b6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033876ms
Dec  3 15:23:45.113: INFO: Pod "downwardapi-volume-d0494196-475d-488c-bf90-b024991bf1b6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009281556s
STEP: Saw pod success
Dec  3 15:23:45.113: INFO: Pod "downwardapi-volume-d0494196-475d-488c-bf90-b024991bf1b6" satisfied condition "success or failure"
Dec  3 15:23:45.118: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downwardapi-volume-d0494196-475d-488c-bf90-b024991bf1b6 container client-container: <nil>
STEP: delete the pod
Dec  3 15:23:45.274: INFO: Waiting for pod downwardapi-volume-d0494196-475d-488c-bf90-b024991bf1b6 to disappear
Dec  3 15:23:45.278: INFO: Pod downwardapi-volume-d0494196-475d-488c-bf90-b024991bf1b6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:23:45.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-139" for this suite.
Dec  3 15:23:51.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:23:51.444: INFO: namespace projected-139 deletion completed in 6.158862159s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:23:51.445: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1690
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-1690
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 15:23:51.700: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 15:24:09.792: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.121:8080/dial?request=hostName&protocol=udp&host=100.64.0.48&port=8081&tries=1'] Namespace:pod-network-test-1690 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:24:09.792: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:24:10.317: INFO: Waiting for endpoints: map[]
Dec  3 15:24:10.322: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.121:8080/dial?request=hostName&protocol=udp&host=100.64.1.120&port=8081&tries=1'] Namespace:pod-network-test-1690 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:24:10.322: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:24:10.802: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:24:10.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1690" for this suite.
Dec  3 15:24:22.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:24:22.968: INFO: namespace pod-network-test-1690 deletion completed in 12.158567045s
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:24:22.969: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1787
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-f69094f6-2a38-422c-a053-ee5bee8a43b4
STEP: Creating a pod to test consume configMaps
Dec  3 15:24:23.507: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-19738e59-d872-4247-8429-4be87045c0b7" in namespace "projected-1787" to be "success or failure"
Dec  3 15:24:23.511: INFO: Pod "pod-projected-configmaps-19738e59-d872-4247-8429-4be87045c0b7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.363244ms
Dec  3 15:24:25.517: INFO: Pod "pod-projected-configmaps-19738e59-d872-4247-8429-4be87045c0b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009837419s
STEP: Saw pod success
Dec  3 15:24:25.517: INFO: Pod "pod-projected-configmaps-19738e59-d872-4247-8429-4be87045c0b7" satisfied condition "success or failure"
Dec  3 15:24:25.522: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-projected-configmaps-19738e59-d872-4247-8429-4be87045c0b7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:24:25.544: INFO: Waiting for pod pod-projected-configmaps-19738e59-d872-4247-8429-4be87045c0b7 to disappear
Dec  3 15:24:25.548: INFO: Pod pod-projected-configmaps-19738e59-d872-4247-8429-4be87045c0b7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:24:25.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1787" for this suite.
Dec  3 15:24:31.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:24:31.749: INFO: namespace projected-1787 deletion completed in 6.194173559s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:24:31.750: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-4534
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-4534
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 15:24:32.091: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 15:24:54.176: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.1.123:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4534 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:24:54.176: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:24:54.667: INFO: Found all expected endpoints: [netserver-0]
Dec  3 15:24:54.672: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.0.49:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-4534 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:24:54.672: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:24:55.164: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:24:55.164: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-4534" for this suite.
Dec  3 15:25:09.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:25:09.327: INFO: namespace pod-network-test-4534 deletion completed in 14.154920013s
•SSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:25:09.327: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-6399
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Dec  3 15:25:09.702: INFO: Waiting up to 5m0s for pod "var-expansion-a00ffcc6-fca1-4b71-9299-7da82278efd2" in namespace "var-expansion-6399" to be "success or failure"
Dec  3 15:25:09.707: INFO: Pod "var-expansion-a00ffcc6-fca1-4b71-9299-7da82278efd2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.541975ms
Dec  3 15:25:11.712: INFO: Pod "var-expansion-a00ffcc6-fca1-4b71-9299-7da82278efd2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009946509s
STEP: Saw pod success
Dec  3 15:25:11.712: INFO: Pod "var-expansion-a00ffcc6-fca1-4b71-9299-7da82278efd2" satisfied condition "success or failure"
Dec  3 15:25:11.716: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod var-expansion-a00ffcc6-fca1-4b71-9299-7da82278efd2 container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:25:11.737: INFO: Waiting for pod var-expansion-a00ffcc6-fca1-4b71-9299-7da82278efd2 to disappear
Dec  3 15:25:11.741: INFO: Pod var-expansion-a00ffcc6-fca1-4b71-9299-7da82278efd2 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:25:11.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6399" for this suite.
Dec  3 15:25:17.763: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:25:17.905: INFO: namespace var-expansion-6399 deletion completed in 6.155799609s
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:25:17.905: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8999
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  3 15:25:18.523: INFO: Number of nodes with available pods: 0
Dec  3 15:25:18.523: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 15:25:19.536: INFO: Number of nodes with available pods: 1
Dec  3 15:25:19.536: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 15:25:20.535: INFO: Number of nodes with available pods: 2
Dec  3 15:25:20.535: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec  3 15:25:20.559: INFO: Number of nodes with available pods: 1
Dec  3 15:25:20.559: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 15:25:21.572: INFO: Number of nodes with available pods: 1
Dec  3 15:25:21.572: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 15:25:22.571: INFO: Number of nodes with available pods: 1
Dec  3 15:25:22.572: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 15:25:23.571: INFO: Number of nodes with available pods: 1
Dec  3 15:25:23.571: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 15:25:24.571: INFO: Number of nodes with available pods: 1
Dec  3 15:25:24.571: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 15:25:25.571: INFO: Number of nodes with available pods: 1
Dec  3 15:25:25.571: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 15:25:26.572: INFO: Number of nodes with available pods: 1
Dec  3 15:25:26.572: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 15:25:27.572: INFO: Number of nodes with available pods: 1
Dec  3 15:25:27.572: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 15:25:28.572: INFO: Number of nodes with available pods: 2
Dec  3 15:25:28.572: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8999, will wait for the garbage collector to delete the pods
Dec  3 15:25:28.639: INFO: Deleting DaemonSet.extensions daemon-set took: 8.72812ms
Dec  3 15:25:29.140: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.361661ms
Dec  3 15:25:36.445: INFO: Number of nodes with available pods: 0
Dec  3 15:25:36.445: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 15:25:36.449: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8999/daemonsets","resourceVersion":"16793"},"items":null}

Dec  3 15:25:36.453: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8999/pods","resourceVersion":"16793"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:25:36.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8999" for this suite.
Dec  3 15:25:42.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:25:42.629: INFO: namespace daemonsets-8999 deletion completed in 6.155144522s
•SSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:25:42.629: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7344
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-7344/configmap-test-d13a2fdd-859e-4d00-8034-0898b71ac8f7
STEP: Creating a pod to test consume configMaps
Dec  3 15:25:42.907: INFO: Waiting up to 5m0s for pod "pod-configmaps-993d58d3-56b1-4587-a4ef-44ba2e206560" in namespace "configmap-7344" to be "success or failure"
Dec  3 15:25:42.911: INFO: Pod "pod-configmaps-993d58d3-56b1-4587-a4ef-44ba2e206560": Phase="Pending", Reason="", readiness=false. Elapsed: 3.800758ms
Dec  3 15:25:44.916: INFO: Pod "pod-configmaps-993d58d3-56b1-4587-a4ef-44ba2e206560": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008917438s
STEP: Saw pod success
Dec  3 15:25:44.916: INFO: Pod "pod-configmaps-993d58d3-56b1-4587-a4ef-44ba2e206560" satisfied condition "success or failure"
Dec  3 15:25:44.920: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-configmaps-993d58d3-56b1-4587-a4ef-44ba2e206560 container env-test: <nil>
STEP: delete the pod
Dec  3 15:25:44.943: INFO: Waiting for pod pod-configmaps-993d58d3-56b1-4587-a4ef-44ba2e206560 to disappear
Dec  3 15:25:44.947: INFO: Pod pod-configmaps-993d58d3-56b1-4587-a4ef-44ba2e206560 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:25:44.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7344" for this suite.
Dec  3 15:25:50.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:25:51.111: INFO: namespace configmap-7344 deletion completed in 6.157152347s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:25:51.112: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8221
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec  3 15:25:51.510: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8221 /api/v1/namespaces/watch-8221/configmaps/e2e-watch-test-watch-closed b56b9889-7400-48de-833c-64a1e9a1eb2d 16873 0 2019-12-03 15:25:51 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:25:51.510: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8221 /api/v1/namespaces/watch-8221/configmaps/e2e-watch-test-watch-closed b56b9889-7400-48de-833c-64a1e9a1eb2d 16874 0 2019-12-03 15:25:51 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec  3 15:25:51.527: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8221 /api/v1/namespaces/watch-8221/configmaps/e2e-watch-test-watch-closed b56b9889-7400-48de-833c-64a1e9a1eb2d 16875 0 2019-12-03 15:25:51 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 15:25:51.527: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-8221 /api/v1/namespaces/watch-8221/configmaps/e2e-watch-test-watch-closed b56b9889-7400-48de-833c-64a1e9a1eb2d 16876 0 2019-12-03 15:25:51 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:25:51.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8221" for this suite.
Dec  3 15:25:57.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:25:57.734: INFO: namespace watch-8221 deletion completed in 6.202442819s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:25:57.734: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4351
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-d8bb13ab-64c0-4fa5-8127-c26aa01d809b
STEP: Creating a pod to test consume configMaps
Dec  3 15:25:58.200: INFO: Waiting up to 5m0s for pod "pod-configmaps-675805b5-87de-4462-99d0-d0ce7cfbbbfb" in namespace "configmap-4351" to be "success or failure"
Dec  3 15:25:58.204: INFO: Pod "pod-configmaps-675805b5-87de-4462-99d0-d0ce7cfbbbfb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.097308ms
Dec  3 15:26:00.209: INFO: Pod "pod-configmaps-675805b5-87de-4462-99d0-d0ce7cfbbbfb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009515661s
STEP: Saw pod success
Dec  3 15:26:00.209: INFO: Pod "pod-configmaps-675805b5-87de-4462-99d0-d0ce7cfbbbfb" satisfied condition "success or failure"
Dec  3 15:26:00.214: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-configmaps-675805b5-87de-4462-99d0-d0ce7cfbbbfb container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:26:00.235: INFO: Waiting for pod pod-configmaps-675805b5-87de-4462-99d0-d0ce7cfbbbfb to disappear
Dec  3 15:26:00.239: INFO: Pod pod-configmaps-675805b5-87de-4462-99d0-d0ce7cfbbbfb no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:26:00.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4351" for this suite.
Dec  3 15:26:08.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:26:08.401: INFO: namespace configmap-4351 deletion completed in 8.154683451s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:26:08.402: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-93
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-e5c036ef-fb95-4e46-a418-6ce5c2bcf330
STEP: Creating a pod to test consume secrets
Dec  3 15:26:08.705: INFO: Waiting up to 5m0s for pod "pod-secrets-c379521b-4dfd-4ca0-804c-d5ca98ac70f7" in namespace "secrets-93" to be "success or failure"
Dec  3 15:26:08.710: INFO: Pod "pod-secrets-c379521b-4dfd-4ca0-804c-d5ca98ac70f7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.995429ms
Dec  3 15:26:10.715: INFO: Pod "pod-secrets-c379521b-4dfd-4ca0-804c-d5ca98ac70f7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010081269s
STEP: Saw pod success
Dec  3 15:26:10.715: INFO: Pod "pod-secrets-c379521b-4dfd-4ca0-804c-d5ca98ac70f7" satisfied condition "success or failure"
Dec  3 15:26:10.719: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-secrets-c379521b-4dfd-4ca0-804c-d5ca98ac70f7 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:26:10.740: INFO: Waiting for pod pod-secrets-c379521b-4dfd-4ca0-804c-d5ca98ac70f7 to disappear
Dec  3 15:26:10.744: INFO: Pod pod-secrets-c379521b-4dfd-4ca0-804c-d5ca98ac70f7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:26:10.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-93" for this suite.
Dec  3 15:26:16.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:26:16.904: INFO: namespace secrets-93 deletion completed in 6.152137709s
•SSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:26:16.904: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8484
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec  3 15:26:17.793: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-8484'
Dec  3 15:26:18.139: INFO: stderr: ""
Dec  3 15:26:18.139: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 15:26:18.139: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8484'
Dec  3 15:26:18.222: INFO: stderr: ""
Dec  3 15:26:18.222: INFO: stdout: "update-demo-nautilus-lfknk "
STEP: Replicas for name=update-demo: expected=2 actual=1
Dec  3 15:26:23.222: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8484'
Dec  3 15:26:23.309: INFO: stderr: ""
Dec  3 15:26:23.309: INFO: stdout: "update-demo-nautilus-2lxm4 update-demo-nautilus-lfknk "
Dec  3 15:26:23.309: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-2lxm4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8484'
Dec  3 15:26:23.435: INFO: stderr: ""
Dec  3 15:26:23.435: INFO: stdout: "true"
Dec  3 15:26:23.435: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-2lxm4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8484'
Dec  3 15:26:23.570: INFO: stderr: ""
Dec  3 15:26:23.570: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:26:23.570: INFO: validating pod update-demo-nautilus-2lxm4
Dec  3 15:26:23.670: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:26:23.670: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:26:23.670: INFO: update-demo-nautilus-2lxm4 is verified up and running
Dec  3 15:26:23.670: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-lfknk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8484'
Dec  3 15:26:23.799: INFO: stderr: ""
Dec  3 15:26:23.799: INFO: stdout: "true"
Dec  3 15:26:23.799: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-lfknk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8484'
Dec  3 15:26:23.931: INFO: stderr: ""
Dec  3 15:26:23.931: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:26:23.931: INFO: validating pod update-demo-nautilus-lfknk
Dec  3 15:26:24.027: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:26:24.027: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:26:24.027: INFO: update-demo-nautilus-lfknk is verified up and running
STEP: scaling down the replication controller
Dec  3 15:26:24.029: INFO: scanned /root for discovery docs: <nil>
Dec  3 15:26:24.029: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-8484'
Dec  3 15:26:25.138: INFO: stderr: ""
Dec  3 15:26:25.138: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 15:26:25.138: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8484'
Dec  3 15:26:25.222: INFO: stderr: ""
Dec  3 15:26:25.222: INFO: stdout: "update-demo-nautilus-2lxm4 update-demo-nautilus-lfknk "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  3 15:26:30.222: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8484'
Dec  3 15:26:30.361: INFO: stderr: ""
Dec  3 15:26:30.361: INFO: stdout: "update-demo-nautilus-2lxm4 update-demo-nautilus-lfknk "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  3 15:26:35.361: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8484'
Dec  3 15:26:35.462: INFO: stderr: ""
Dec  3 15:26:35.462: INFO: stdout: "update-demo-nautilus-2lxm4 update-demo-nautilus-lfknk "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  3 15:26:40.462: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8484'
Dec  3 15:26:40.592: INFO: stderr: ""
Dec  3 15:26:40.592: INFO: stdout: "update-demo-nautilus-lfknk "
Dec  3 15:26:40.592: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-lfknk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8484'
Dec  3 15:26:40.677: INFO: stderr: ""
Dec  3 15:26:40.677: INFO: stdout: "true"
Dec  3 15:26:40.677: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-lfknk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8484'
Dec  3 15:26:40.759: INFO: stderr: ""
Dec  3 15:26:40.759: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:26:40.759: INFO: validating pod update-demo-nautilus-lfknk
Dec  3 15:26:40.769: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:26:40.770: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:26:40.770: INFO: update-demo-nautilus-lfknk is verified up and running
STEP: scaling up the replication controller
Dec  3 15:26:40.771: INFO: scanned /root for discovery docs: <nil>
Dec  3 15:26:40.771: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-8484'
Dec  3 15:26:40.942: INFO: stderr: ""
Dec  3 15:26:40.942: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 15:26:40.942: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8484'
Dec  3 15:26:41.043: INFO: stderr: ""
Dec  3 15:26:41.043: INFO: stdout: "update-demo-nautilus-lfknk update-demo-nautilus-n9wpq "
Dec  3 15:26:41.043: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-lfknk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8484'
Dec  3 15:26:41.174: INFO: stderr: ""
Dec  3 15:26:41.174: INFO: stdout: "true"
Dec  3 15:26:41.174: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-lfknk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8484'
Dec  3 15:26:41.302: INFO: stderr: ""
Dec  3 15:26:41.302: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:26:41.302: INFO: validating pod update-demo-nautilus-lfknk
Dec  3 15:26:41.312: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:26:41.312: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:26:41.312: INFO: update-demo-nautilus-lfknk is verified up and running
Dec  3 15:26:41.312: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-n9wpq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8484'
Dec  3 15:26:41.455: INFO: stderr: ""
Dec  3 15:26:41.455: INFO: stdout: ""
Dec  3 15:26:41.455: INFO: update-demo-nautilus-n9wpq is created but not running
Dec  3 15:26:46.455: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8484'
Dec  3 15:26:46.542: INFO: stderr: ""
Dec  3 15:26:46.542: INFO: stdout: "update-demo-nautilus-lfknk update-demo-nautilus-n9wpq "
Dec  3 15:26:46.542: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-lfknk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8484'
Dec  3 15:26:46.631: INFO: stderr: ""
Dec  3 15:26:46.631: INFO: stdout: "true"
Dec  3 15:26:46.631: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-lfknk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8484'
Dec  3 15:26:46.756: INFO: stderr: ""
Dec  3 15:26:46.756: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:26:46.756: INFO: validating pod update-demo-nautilus-lfknk
Dec  3 15:26:46.766: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:26:46.766: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:26:46.766: INFO: update-demo-nautilus-lfknk is verified up and running
Dec  3 15:26:46.766: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-n9wpq -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8484'
Dec  3 15:26:46.890: INFO: stderr: ""
Dec  3 15:26:46.890: INFO: stdout: "true"
Dec  3 15:26:46.890: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-n9wpq -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8484'
Dec  3 15:26:47.017: INFO: stderr: ""
Dec  3 15:26:47.017: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:26:47.017: INFO: validating pod update-demo-nautilus-n9wpq
Dec  3 15:26:47.113: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:26:47.113: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:26:47.113: INFO: update-demo-nautilus-n9wpq is verified up and running
STEP: using delete to clean up resources
Dec  3 15:26:47.113: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-8484'
Dec  3 15:26:47.257: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:26:47.257: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  3 15:26:47.257: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8484'
Dec  3 15:26:47.346: INFO: stderr: "No resources found in kubectl-8484 namespace.\n"
Dec  3 15:26:47.347: INFO: stdout: ""
Dec  3 15:26:47.347: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-8484 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 15:26:47.481: INFO: stderr: ""
Dec  3 15:26:47.481: INFO: stdout: "update-demo-nautilus-lfknk\nupdate-demo-nautilus-n9wpq\n"
Dec  3 15:26:47.981: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8484'
Dec  3 15:26:48.126: INFO: stderr: "No resources found in kubectl-8484 namespace.\n"
Dec  3 15:26:48.126: INFO: stdout: ""
Dec  3 15:26:48.126: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-8484 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 15:26:48.214: INFO: stderr: ""
Dec  3 15:26:48.214: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:26:48.214: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8484" for this suite.
Dec  3 15:27:00.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:27:00.418: INFO: namespace kubectl-8484 deletion completed in 12.195687503s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:27:00.418: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1318
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  3 15:27:00.795: INFO: Waiting up to 5m0s for pod "pod-7759448e-0d73-4870-990b-e843d2527e91" in namespace "emptydir-1318" to be "success or failure"
Dec  3 15:27:00.799: INFO: Pod "pod-7759448e-0d73-4870-990b-e843d2527e91": Phase="Pending", Reason="", readiness=false. Elapsed: 4.269553ms
Dec  3 15:27:02.804: INFO: Pod "pod-7759448e-0d73-4870-990b-e843d2527e91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009278748s
STEP: Saw pod success
Dec  3 15:27:02.804: INFO: Pod "pod-7759448e-0d73-4870-990b-e843d2527e91" satisfied condition "success or failure"
Dec  3 15:27:02.809: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-7759448e-0d73-4870-990b-e843d2527e91 container test-container: <nil>
STEP: delete the pod
Dec  3 15:27:02.833: INFO: Waiting for pod pod-7759448e-0d73-4870-990b-e843d2527e91 to disappear
Dec  3 15:27:02.837: INFO: Pod pod-7759448e-0d73-4870-990b-e843d2527e91 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:27:02.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1318" for this suite.
Dec  3 15:27:08.858: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:27:09.000: INFO: namespace emptydir-1318 deletion completed in 6.15503406s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:27:09.001: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7504
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  3 15:27:09.293: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-7504'
Dec  3 15:27:09.644: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 15:27:09.644: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Dec  3 15:27:09.649: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete jobs e2e-test-httpd-job --namespace=kubectl-7504'
Dec  3 15:27:09.732: INFO: stderr: ""
Dec  3 15:27:09.732: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:27:09.732: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7504" for this suite.
Dec  3 15:27:21.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:27:21.896: INFO: namespace kubectl-7504 deletion completed in 12.157255015s
•SSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:27:21.896: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-699
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec  3 15:27:25.235: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:27:25.249: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-699" for this suite.
Dec  3 15:27:53.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:27:53.415: INFO: namespace replicaset-699 deletion completed in 28.15767276s
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:27:53.415: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2050
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec  3 15:27:53.787: INFO: namespace kubectl-2050
Dec  3 15:27:53.787: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2050'
Dec  3 15:27:54.016: INFO: stderr: ""
Dec  3 15:27:54.016: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  3 15:27:55.022: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:27:55.022: INFO: Found 0 / 1
Dec  3 15:27:56.022: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:27:56.022: INFO: Found 1 / 1
Dec  3 15:27:56.022: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  3 15:27:56.027: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:27:56.027: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 15:27:56.027: INFO: wait on redis-master startup in kubectl-2050 
Dec  3 15:27:56.027: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs redis-master-qz56j redis-master --namespace=kubectl-2050'
Dec  3 15:27:56.288: INFO: stderr: ""
Dec  3 15:27:56.288: INFO: stdout: "1:C 03 Dec 2019 15:27:54.999 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 03 Dec 2019 15:27:54.999 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 03 Dec 2019 15:27:54.999 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 03 Dec 2019 15:27:55.002 * Running mode=standalone, port=6379.\n1:M 03 Dec 2019 15:27:55.002 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Dec 2019 15:27:55.002 # Server initialized\n1:M 03 Dec 2019 15:27:55.002 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Dec 2019 15:27:55.002 * Ready to accept connections\n"
STEP: exposing RC
Dec  3 15:27:56.288: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-2050'
Dec  3 15:27:56.390: INFO: stderr: ""
Dec  3 15:27:56.390: INFO: stdout: "service/rm2 exposed\n"
Dec  3 15:27:56.394: INFO: Service rm2 in namespace kubectl-2050 found.
STEP: exposing service
Dec  3 15:27:58.404: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-2050'
Dec  3 15:27:58.565: INFO: stderr: ""
Dec  3 15:27:58.565: INFO: stdout: "service/rm3 exposed\n"
Dec  3 15:27:58.570: INFO: Service rm3 in namespace kubectl-2050 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:28:00.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2050" for this suite.
Dec  3 15:28:12.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:28:12.747: INFO: namespace kubectl-2050 deletion completed in 12.159634222s
•SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:28:12.747: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7956
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:28:14.393: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:28:17.415: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:28:17.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7956" for this suite.
Dec  3 15:28:23.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:28:23.588: INFO: namespace webhook-7956 deletion completed in 6.15194474s
STEP: Destroying namespace "webhook-7956-markers" for this suite.
Dec  3 15:28:31.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:28:31.744: INFO: namespace webhook-7956-markers deletion completed in 8.155210573s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:28:31.761: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-547
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:28:32.196: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f61fee0d-8167-4298-9383-3d085578293b" in namespace "projected-547" to be "success or failure"
Dec  3 15:28:32.200: INFO: Pod "downwardapi-volume-f61fee0d-8167-4298-9383-3d085578293b": Phase="Pending", Reason="", readiness=false. Elapsed: 4.19943ms
Dec  3 15:28:34.205: INFO: Pod "downwardapi-volume-f61fee0d-8167-4298-9383-3d085578293b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009411253s
STEP: Saw pod success
Dec  3 15:28:34.205: INFO: Pod "downwardapi-volume-f61fee0d-8167-4298-9383-3d085578293b" satisfied condition "success or failure"
Dec  3 15:28:34.210: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downwardapi-volume-f61fee0d-8167-4298-9383-3d085578293b container client-container: <nil>
STEP: delete the pod
Dec  3 15:28:34.368: INFO: Waiting for pod downwardapi-volume-f61fee0d-8167-4298-9383-3d085578293b to disappear
Dec  3 15:28:34.372: INFO: Pod downwardapi-volume-f61fee0d-8167-4298-9383-3d085578293b no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:28:34.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-547" for this suite.
Dec  3 15:28:40.393: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:28:40.534: INFO: namespace projected-547 deletion completed in 6.155335747s
•
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:28:40.535: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1326
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Dec  3 15:28:40.887: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy --unix-socket=/tmp/kubectl-proxy-unix193200990/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:28:40.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1326" for this suite.
Dec  3 15:28:48.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:28:49.142: INFO: namespace kubectl-1326 deletion completed in 8.196383871s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:28:49.143: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2310
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Dec  3 15:28:49.595: INFO: Waiting up to 5m0s for pod "pod-1b8b7b3a-0d18-4d65-8fcb-b88b99382c12" in namespace "emptydir-2310" to be "success or failure"
Dec  3 15:28:49.599: INFO: Pod "pod-1b8b7b3a-0d18-4d65-8fcb-b88b99382c12": Phase="Pending", Reason="", readiness=false. Elapsed: 4.764173ms
Dec  3 15:28:51.604: INFO: Pod "pod-1b8b7b3a-0d18-4d65-8fcb-b88b99382c12": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00971296s
STEP: Saw pod success
Dec  3 15:28:51.604: INFO: Pod "pod-1b8b7b3a-0d18-4d65-8fcb-b88b99382c12" satisfied condition "success or failure"
Dec  3 15:28:51.609: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-1b8b7b3a-0d18-4d65-8fcb-b88b99382c12 container test-container: <nil>
STEP: delete the pod
Dec  3 15:28:51.629: INFO: Waiting for pod pod-1b8b7b3a-0d18-4d65-8fcb-b88b99382c12 to disappear
Dec  3 15:28:51.634: INFO: Pod pod-1b8b7b3a-0d18-4d65-8fcb-b88b99382c12 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:28:51.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2310" for this suite.
Dec  3 15:28:59.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:28:59.791: INFO: namespace emptydir-2310 deletion completed in 8.150474365s
•SSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:28:59.792: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5509
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec  3 15:29:00.294: INFO: Waiting up to 5m0s for pod "downward-api-f26f93a2-1f86-4ec5-a31f-ed1831879e7c" in namespace "downward-api-5509" to be "success or failure"
Dec  3 15:29:00.299: INFO: Pod "downward-api-f26f93a2-1f86-4ec5-a31f-ed1831879e7c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.121168ms
Dec  3 15:29:02.304: INFO: Pod "downward-api-f26f93a2-1f86-4ec5-a31f-ed1831879e7c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009637748s
STEP: Saw pod success
Dec  3 15:29:02.304: INFO: Pod "downward-api-f26f93a2-1f86-4ec5-a31f-ed1831879e7c" satisfied condition "success or failure"
Dec  3 15:29:02.308: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downward-api-f26f93a2-1f86-4ec5-a31f-ed1831879e7c container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:29:02.332: INFO: Waiting for pod downward-api-f26f93a2-1f86-4ec5-a31f-ed1831879e7c to disappear
Dec  3 15:29:02.336: INFO: Pod downward-api-f26f93a2-1f86-4ec5-a31f-ed1831879e7c no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:29:02.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5509" for this suite.
Dec  3 15:29:10.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:29:10.539: INFO: namespace downward-api-5509 deletion completed in 8.196566798s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:29:10.540: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8106
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:29:11.352: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:29:14.375: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:29:14.380: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4642-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:29:15.110: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8106" for this suite.
Dec  3 15:29:21.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:29:21.312: INFO: namespace webhook-8106 deletion completed in 6.193254843s
STEP: Destroying namespace "webhook-8106-markers" for this suite.
Dec  3 15:29:29.326: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:29:29.471: INFO: namespace webhook-8106-markers deletion completed in 8.159360851s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:29:29.489: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1407
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-67ca271c-6a0f-40d4-9216-471c96e6cbf1
STEP: Creating secret with name s-test-opt-upd-f8be9ea7-300f-4910-902d-570e198072e5
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-67ca271c-6a0f-40d4-9216-471c96e6cbf1
STEP: Updating secret s-test-opt-upd-f8be9ea7-300f-4910-902d-570e198072e5
STEP: Creating secret with name s-test-opt-create-c3414c84-d7bb-41c4-966e-04cddc6545ab
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:29:34.369: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1407" for this suite.
Dec  3 15:30:04.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:30:04.537: INFO: namespace secrets-1407 deletion completed in 30.160647098s
•SSSSSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:30:04.538: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-7898
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:30:04.904: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-c9ca84a7-6876-49cb-9527-c7af2c99fbe7" in namespace "security-context-test-7898" to be "success or failure"
Dec  3 15:30:04.909: INFO: Pod "alpine-nnp-false-c9ca84a7-6876-49cb-9527-c7af2c99fbe7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.01087ms
Dec  3 15:30:06.914: INFO: Pod "alpine-nnp-false-c9ca84a7-6876-49cb-9527-c7af2c99fbe7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009584049s
Dec  3 15:30:08.919: INFO: Pod "alpine-nnp-false-c9ca84a7-6876-49cb-9527-c7af2c99fbe7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014884511s
Dec  3 15:30:08.919: INFO: Pod "alpine-nnp-false-c9ca84a7-6876-49cb-9527-c7af2c99fbe7" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:30:08.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-7898" for this suite.
Dec  3 15:30:14.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:30:15.131: INFO: namespace security-context-test-7898 deletion completed in 6.152715137s
•SSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:30:15.131: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4387
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-a28b7a7b-c626-4617-a8fd-263fdffd1208
STEP: Creating a pod to test consume configMaps
Dec  3 15:30:15.501: INFO: Waiting up to 5m0s for pod "pod-configmaps-35e38e17-b261-4042-8af6-96391649ed94" in namespace "configmap-4387" to be "success or failure"
Dec  3 15:30:15.505: INFO: Pod "pod-configmaps-35e38e17-b261-4042-8af6-96391649ed94": Phase="Pending", Reason="", readiness=false. Elapsed: 4.041533ms
Dec  3 15:30:17.510: INFO: Pod "pod-configmaps-35e38e17-b261-4042-8af6-96391649ed94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008942651s
STEP: Saw pod success
Dec  3 15:30:17.510: INFO: Pod "pod-configmaps-35e38e17-b261-4042-8af6-96391649ed94" satisfied condition "success or failure"
Dec  3 15:30:17.514: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-configmaps-35e38e17-b261-4042-8af6-96391649ed94 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:30:17.535: INFO: Waiting for pod pod-configmaps-35e38e17-b261-4042-8af6-96391649ed94 to disappear
Dec  3 15:30:17.539: INFO: Pod pod-configmaps-35e38e17-b261-4042-8af6-96391649ed94 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:30:17.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4387" for this suite.
Dec  3 15:30:23.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:30:23.699: INFO: namespace configmap-4387 deletion completed in 6.153173271s
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:30:23.700: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-6814
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec  3 15:30:24.096: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 15:30:24.113: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 15:30:24.117: INFO: 
Logging pods the kubelet thinks is on node izgw88vcbd5x6ev7zbjg8vz before test
Dec  3 15:30:24.264: INFO: blackbox-exporter-7bd7b55dfc-jjbg2 from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 15:30:24.264: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec  3 15:30:24.264: INFO: node-problem-detector-jj8gj from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 15:30:24.264: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:30:24.264: INFO: coredns-59c969ffb8-xnfvv from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:30:24.264: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:30:24.264: INFO: metrics-server-69dcc87559-8j9rx from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:30:24.264: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 15:30:24.264: INFO: calico-typha-vertical-autoscaler-847d859f8c-6xhsp from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:30:24.264: INFO: 	Container autoscaler ready: true, restart count 2
Dec  3 15:30:24.264: INFO: coredns-59c969ffb8-9mq2d from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:30:24.264: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:30:24.264: INFO: vpn-shoot-76845cddf7-dh4gs from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:30:24.264: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec  3 15:30:24.264: INFO: addons-nginx-ingress-controller-7c75bb76db-8qn7n from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:30:24.264: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec  3 15:30:24.264: INFO: csi-disk-plugin-alicloud-55sss from kube-system started at 2019-12-03 14:26:56 +0000 UTC (2 container statuses recorded)
Dec  3 15:30:24.264: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec  3 15:30:24.264: INFO: 	Container driver-registrar ready: true, restart count 0
Dec  3 15:30:24.264: INFO: calico-node-rx7sf from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 15:30:24.264: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:30:24.264: INFO: node-exporter-xwww8 from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 15:30:24.264: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:30:24.264: INFO: kube-proxy-frcrz from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 15:30:24.264: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:30:24.264: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-95f65778d-6v4hg from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:30:24.264: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec  3 15:30:24.264: INFO: calico-typha-horizontal-autoscaler-69df649c59-wrrxb from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:30:24.264: INFO: 	Container autoscaler ready: true, restart count 0
Dec  3 15:30:24.264: INFO: addons-kubernetes-dashboard-78954cc66b-mh5g8 from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:30:24.264: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  3 15:30:24.264: INFO: 
Logging pods the kubelet thinks is on node izgw8fisrtg04goc4t8tqaz before test
Dec  3 15:30:24.305: INFO: node-exporter-2jhhv from kube-system started at 2019-12-03 14:26:18 +0000 UTC (1 container statuses recorded)
Dec  3 15:30:24.305: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:30:24.305: INFO: calico-typha-deploy-9f6b455c4-9z5nc from kube-system started at 2019-12-03 14:28:12 +0000 UTC (1 container statuses recorded)
Dec  3 15:30:24.305: INFO: 	Container calico-typha ready: true, restart count 0
Dec  3 15:30:24.305: INFO: csi-disk-plugin-alicloud-qmj7l from kube-system started at 2019-12-03 14:26:58 +0000 UTC (2 container statuses recorded)
Dec  3 15:30:24.305: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec  3 15:30:24.305: INFO: 	Container driver-registrar ready: true, restart count 0
Dec  3 15:30:24.305: INFO: calico-kube-controllers-79bcd784b6-s67m5 from kube-system started at 2019-12-03 14:26:58 +0000 UTC (1 container statuses recorded)
Dec  3 15:30:24.305: INFO: 	Container calico-kube-controllers ready: true, restart count 1
Dec  3 15:30:24.305: INFO: kube-proxy-dgc7z from kube-system started at 2019-12-03 14:26:18 +0000 UTC (1 container statuses recorded)
Dec  3 15:30:24.305: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:30:24.305: INFO: calico-node-8d72b from kube-system started at 2019-12-03 14:26:18 +0000 UTC (1 container statuses recorded)
Dec  3 15:30:24.305: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:30:24.305: INFO: node-problem-detector-g8scm from kube-system started at 2019-12-03 14:26:18 +0000 UTC (1 container statuses recorded)
Dec  3 15:30:24.305: INFO: 	Container node-problem-detector ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-470e1ddd-85ce-4507-a620-39913ecee46b 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-470e1ddd-85ce-4507-a620-39913ecee46b off the node izgw8fisrtg04goc4t8tqaz
STEP: verifying the node doesn't have the label kubernetes.io/e2e-470e1ddd-85ce-4507-a620-39913ecee46b
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:30:32.407: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-6814" for this suite.
Dec  3 15:30:52.426: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:30:52.576: INFO: namespace sched-pred-6814 deletion completed in 20.164013653s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
•SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:30:52.576: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1557
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:30:53.523: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:30:56.545: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:30:56.550: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3253-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:30:57.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1557" for this suite.
Dec  3 15:31:05.404: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:31:05.544: INFO: namespace webhook-1557 deletion completed in 8.157897975s
STEP: Destroying namespace "webhook-1557-markers" for this suite.
Dec  3 15:31:13.558: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:31:13.701: INFO: namespace webhook-1557-markers deletion completed in 8.156499656s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:31:13.719: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2370
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-d149aa87-7e2c-4615-bf47-644a009655df
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-d149aa87-7e2c-4615-bf47-644a009655df
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:31:18.352: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2370" for this suite.
Dec  3 15:31:32.373: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:31:32.524: INFO: namespace projected-2370 deletion completed in 14.164489551s
•SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:31:32.524: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4159
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:31:32.802: INFO: Waiting up to 5m0s for pod "downwardapi-volume-91c347e7-24b2-454e-ba7d-48b1227eb1bb" in namespace "downward-api-4159" to be "success or failure"
Dec  3 15:31:32.806: INFO: Pod "downwardapi-volume-91c347e7-24b2-454e-ba7d-48b1227eb1bb": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025249ms
Dec  3 15:31:34.812: INFO: Pod "downwardapi-volume-91c347e7-24b2-454e-ba7d-48b1227eb1bb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009253424s
STEP: Saw pod success
Dec  3 15:31:34.812: INFO: Pod "downwardapi-volume-91c347e7-24b2-454e-ba7d-48b1227eb1bb" satisfied condition "success or failure"
Dec  3 15:31:34.816: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downwardapi-volume-91c347e7-24b2-454e-ba7d-48b1227eb1bb container client-container: <nil>
STEP: delete the pod
Dec  3 15:31:34.837: INFO: Waiting for pod downwardapi-volume-91c347e7-24b2-454e-ba7d-48b1227eb1bb to disappear
Dec  3 15:31:34.841: INFO: Pod downwardapi-volume-91c347e7-24b2-454e-ba7d-48b1227eb1bb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:31:34.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4159" for this suite.
Dec  3 15:31:40.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:31:41.000: INFO: namespace downward-api-4159 deletion completed in 6.152189781s
•SSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:31:41.000: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-8611
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-205
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3095
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:31:56.296: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8611" for this suite.
Dec  3 15:32:02.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:32:02.472: INFO: namespace namespaces-8611 deletion completed in 6.169143164s
STEP: Destroying namespace "nsdeletetest-205" for this suite.
Dec  3 15:32:02.477: INFO: Namespace nsdeletetest-205 was already deleted
STEP: Destroying namespace "nsdeletetest-3095" for this suite.
Dec  3 15:32:08.490: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:32:08.627: INFO: namespace nsdeletetest-3095 deletion completed in 6.15058303s
•SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:32:08.628: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1032
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-ebdc799a-511d-43cc-bb58-7f9846802ed5
STEP: Creating configMap with name cm-test-opt-upd-0c31cd74-becd-4495-a0cf-032390685a68
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-ebdc799a-511d-43cc-bb58-7f9846802ed5
STEP: Updating configmap cm-test-opt-upd-0c31cd74-becd-4495-a0cf-032390685a68
STEP: Creating configMap with name cm-test-opt-create-d1700932-7665-488d-b563-8e805e3bf4ca
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:32:15.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1032" for this suite.
Dec  3 15:32:29.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:32:29.583: INFO: namespace configmap-1032 deletion completed in 14.195768099s
•
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:32:29.583: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-2704
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:32:55.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-2704" for this suite.
Dec  3 15:33:03.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:33:03.510: INFO: namespace container-runtime-2704 deletion completed in 8.163202237s
•
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:33:03.511: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-2321
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Dec  3 15:33:03.803: INFO: Waiting up to 5m0s for pod "client-containers-c5b3e1f0-3acb-424d-8c0b-44bd62d5b819" in namespace "containers-2321" to be "success or failure"
Dec  3 15:33:03.807: INFO: Pod "client-containers-c5b3e1f0-3acb-424d-8c0b-44bd62d5b819": Phase="Pending", Reason="", readiness=false. Elapsed: 4.130477ms
Dec  3 15:33:05.812: INFO: Pod "client-containers-c5b3e1f0-3acb-424d-8c0b-44bd62d5b819": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0092423s
STEP: Saw pod success
Dec  3 15:33:05.812: INFO: Pod "client-containers-c5b3e1f0-3acb-424d-8c0b-44bd62d5b819" satisfied condition "success or failure"
Dec  3 15:33:05.816: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod client-containers-c5b3e1f0-3acb-424d-8c0b-44bd62d5b819 container test-container: <nil>
STEP: delete the pod
Dec  3 15:33:05.841: INFO: Waiting for pod client-containers-c5b3e1f0-3acb-424d-8c0b-44bd62d5b819 to disappear
Dec  3 15:33:05.845: INFO: Pod client-containers-c5b3e1f0-3acb-424d-8c0b-44bd62d5b819 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:33:05.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2321" for this suite.
Dec  3 15:33:11.866: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:33:12.008: INFO: namespace containers-2321 deletion completed in 6.155996579s
•SSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:33:12.008: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9842
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-9360487e-122e-4ae3-9402-8b976ae2a5fd
STEP: Creating a pod to test consume secrets
Dec  3 15:33:12.406: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-0f377fec-32ea-4348-a6f4-c3608d9672be" in namespace "projected-9842" to be "success or failure"
Dec  3 15:33:12.410: INFO: Pod "pod-projected-secrets-0f377fec-32ea-4348-a6f4-c3608d9672be": Phase="Pending", Reason="", readiness=false. Elapsed: 4.027062ms
Dec  3 15:33:14.415: INFO: Pod "pod-projected-secrets-0f377fec-32ea-4348-a6f4-c3608d9672be": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009359856s
STEP: Saw pod success
Dec  3 15:33:14.415: INFO: Pod "pod-projected-secrets-0f377fec-32ea-4348-a6f4-c3608d9672be" satisfied condition "success or failure"
Dec  3 15:33:14.420: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-projected-secrets-0f377fec-32ea-4348-a6f4-c3608d9672be container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:33:14.442: INFO: Waiting for pod pod-projected-secrets-0f377fec-32ea-4348-a6f4-c3608d9672be to disappear
Dec  3 15:33:14.446: INFO: Pod pod-projected-secrets-0f377fec-32ea-4348-a6f4-c3608d9672be no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:33:14.446: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9842" for this suite.
Dec  3 15:33:22.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:33:22.609: INFO: namespace projected-9842 deletion completed in 8.15594677s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:33:22.610: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8542
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Dec  3 15:33:23.089: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-8542'
Dec  3 15:33:23.347: INFO: stderr: ""
Dec  3 15:33:23.347: INFO: stdout: "pod/pause created\n"
Dec  3 15:33:23.347: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec  3 15:33:23.347: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-8542" to be "running and ready"
Dec  3 15:33:23.351: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 4.133695ms
Dec  3 15:33:25.357: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.009444096s
Dec  3 15:33:25.357: INFO: Pod "pause" satisfied condition "running and ready"
Dec  3 15:33:25.357: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Dec  3 15:33:25.357: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config label pods pause testing-label=testing-label-value --namespace=kubectl-8542'
Dec  3 15:33:25.456: INFO: stderr: ""
Dec  3 15:33:25.456: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec  3 15:33:25.456: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod pause -L testing-label --namespace=kubectl-8542'
Dec  3 15:33:25.536: INFO: stderr: ""
Dec  3 15:33:25.536: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec  3 15:33:25.536: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config label pods pause testing-label- --namespace=kubectl-8542'
Dec  3 15:33:25.629: INFO: stderr: ""
Dec  3 15:33:25.629: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec  3 15:33:25.629: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod pause -L testing-label --namespace=kubectl-8542'
Dec  3 15:33:25.758: INFO: stderr: ""
Dec  3 15:33:25.758: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Dec  3 15:33:25.758: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-8542'
Dec  3 15:33:25.901: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:33:25.901: INFO: stdout: "pod \"pause\" force deleted\n"
Dec  3 15:33:25.901: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=pause --no-headers --namespace=kubectl-8542'
Dec  3 15:33:25.987: INFO: stderr: "No resources found in kubectl-8542 namespace.\n"
Dec  3 15:33:25.987: INFO: stdout: ""
Dec  3 15:33:25.987: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=pause --namespace=kubectl-8542 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 15:33:26.187: INFO: stderr: ""
Dec  3 15:33:26.187: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:33:26.187: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8542" for this suite.
Dec  3 15:33:32.209: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:33:32.348: INFO: namespace kubectl-8542 deletion completed in 6.153018485s
•SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:33:32.348: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5116
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec  3 15:33:35.141: INFO: Successfully updated pod "labelsupdate7798dc6f-ed65-464f-88ae-3cac66052362"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:33:39.183: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5116" for this suite.
Dec  3 15:33:51.205: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:33:51.425: INFO: namespace projected-5116 deletion completed in 12.234365145s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:33:51.425: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5270
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:33:51.701: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3b797f12-3e05-43e5-a952-0178393e995c" in namespace "downward-api-5270" to be "success or failure"
Dec  3 15:33:51.705: INFO: Pod "downwardapi-volume-3b797f12-3e05-43e5-a952-0178393e995c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.086114ms
Dec  3 15:33:53.711: INFO: Pod "downwardapi-volume-3b797f12-3e05-43e5-a952-0178393e995c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009575252s
STEP: Saw pod success
Dec  3 15:33:53.711: INFO: Pod "downwardapi-volume-3b797f12-3e05-43e5-a952-0178393e995c" satisfied condition "success or failure"
Dec  3 15:33:53.716: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downwardapi-volume-3b797f12-3e05-43e5-a952-0178393e995c container client-container: <nil>
STEP: delete the pod
Dec  3 15:33:53.738: INFO: Waiting for pod downwardapi-volume-3b797f12-3e05-43e5-a952-0178393e995c to disappear
Dec  3 15:33:53.742: INFO: Pod downwardapi-volume-3b797f12-3e05-43e5-a952-0178393e995c no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:33:53.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5270" for this suite.
Dec  3 15:33:59.764: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:33:59.902: INFO: namespace downward-api-5270 deletion completed in 6.152502967s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:33:59.902: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1732
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-89eb3206-1112-4895-80a4-53f048b5a455
STEP: Creating a pod to test consume configMaps
Dec  3 15:34:00.299: INFO: Waiting up to 5m0s for pod "pod-configmaps-ae644900-2ace-4ea9-ae50-b03319ac3a98" in namespace "configmap-1732" to be "success or failure"
Dec  3 15:34:00.303: INFO: Pod "pod-configmaps-ae644900-2ace-4ea9-ae50-b03319ac3a98": Phase="Pending", Reason="", readiness=false. Elapsed: 4.366792ms
Dec  3 15:34:02.309: INFO: Pod "pod-configmaps-ae644900-2ace-4ea9-ae50-b03319ac3a98": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009576659s
STEP: Saw pod success
Dec  3 15:34:02.309: INFO: Pod "pod-configmaps-ae644900-2ace-4ea9-ae50-b03319ac3a98" satisfied condition "success or failure"
Dec  3 15:34:02.313: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-configmaps-ae644900-2ace-4ea9-ae50-b03319ac3a98 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:34:02.339: INFO: Waiting for pod pod-configmaps-ae644900-2ace-4ea9-ae50-b03319ac3a98 to disappear
Dec  3 15:34:02.345: INFO: Pod pod-configmaps-ae644900-2ace-4ea9-ae50-b03319ac3a98 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:34:02.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1732" for this suite.
Dec  3 15:34:10.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:34:10.515: INFO: namespace configmap-1732 deletion completed in 8.162573061s
•S
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:34:10.515: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5415
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Dec  3 15:34:10.888: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec  3 15:34:10.888: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-5415'
Dec  3 15:34:11.126: INFO: stderr: ""
Dec  3 15:34:11.126: INFO: stdout: "service/redis-slave created\n"
Dec  3 15:34:11.126: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec  3 15:34:11.126: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-5415'
Dec  3 15:34:11.359: INFO: stderr: ""
Dec  3 15:34:11.359: INFO: stdout: "service/redis-master created\n"
Dec  3 15:34:11.359: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec  3 15:34:11.359: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-5415'
Dec  3 15:34:11.594: INFO: stderr: ""
Dec  3 15:34:11.594: INFO: stdout: "service/frontend created\n"
Dec  3 15:34:11.594: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec  3 15:34:11.594: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-5415'
Dec  3 15:34:11.814: INFO: stderr: ""
Dec  3 15:34:11.814: INFO: stdout: "deployment.apps/frontend created\n"
Dec  3 15:34:11.814: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec  3 15:34:11.815: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-5415'
Dec  3 15:34:12.027: INFO: stderr: ""
Dec  3 15:34:12.027: INFO: stdout: "deployment.apps/redis-master created\n"
Dec  3 15:34:12.027: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec  3 15:34:12.027: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-5415'
Dec  3 15:34:12.246: INFO: stderr: ""
Dec  3 15:34:12.246: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Dec  3 15:34:12.246: INFO: Waiting for all frontend pods to be Running.
Dec  3 15:34:37.298: INFO: Waiting for frontend to serve content.
Dec  3 15:34:37.394: INFO: Trying to add a new entry to the guestbook.
Dec  3 15:34:37.482: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec  3 15:34:37.578: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-5415'
Dec  3 15:34:37.722: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:34:37.722: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 15:34:37.722: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-5415'
Dec  3 15:34:37.811: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:34:37.811: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 15:34:37.811: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-5415'
Dec  3 15:34:37.957: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:34:37.957: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 15:34:37.957: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-5415'
Dec  3 15:34:38.041: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:34:38.041: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 15:34:38.041: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-5415'
Dec  3 15:34:38.127: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:34:38.127: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 15:34:38.127: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-5415'
Dec  3 15:34:38.269: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:34:38.269: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:34:38.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5415" for this suite.
Dec  3 15:34:50.290: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:34:50.435: INFO: namespace kubectl-5415 deletion completed in 12.159164567s
•SS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:34:50.435: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5740
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-5740
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-5740
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-5740
Dec  3 15:34:50.710: INFO: Found 0 stateful pods, waiting for 1
Dec  3 15:35:00.715: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec  3 15:35:00.720: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 15:35:01.335: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 15:35:01.335: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 15:35:01.335: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 15:35:01.340: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  3 15:35:11.346: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 15:35:11.346: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:35:11.364: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999509s
Dec  3 15:35:12.370: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.994701831s
Dec  3 15:35:13.376: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.988899546s
Dec  3 15:35:14.381: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.983366069s
Dec  3 15:35:15.387: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.977918413s
Dec  3 15:35:16.396: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.968567986s
Dec  3 15:35:17.401: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.963531144s
Dec  3 15:35:18.406: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.95805061s
Dec  3 15:35:19.417: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.947586804s
Dec  3 15:35:20.422: INFO: Verifying statefulset ss doesn't scale past 1 for another 942.248902ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-5740
Dec  3 15:35:21.427: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:35:21.996: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 15:35:21.996: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 15:35:21.996: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 15:35:22.001: INFO: Found 1 stateful pods, waiting for 3
Dec  3 15:35:32.007: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:35:32.007: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:35:32.007: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec  3 15:35:32.016: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 15:35:32.610: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 15:35:32.610: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 15:35:32.610: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 15:35:32.610: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 15:35:33.279: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 15:35:33.280: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 15:35:33.280: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 15:35:33.280: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 15:35:33.943: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 15:35:33.943: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 15:35:33.943: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 15:35:33.943: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:35:33.948: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec  3 15:35:43.960: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 15:35:43.960: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 15:35:43.960: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 15:35:43.974: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999085s
Dec  3 15:35:44.980: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.995166184s
Dec  3 15:35:45.985: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.989429221s
Dec  3 15:35:46.991: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.984018033s
Dec  3 15:35:47.996: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.978311926s
Dec  3 15:35:49.002: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.972807471s
Dec  3 15:35:50.008: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.966868694s
Dec  3 15:35:51.014: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.960995987s
Dec  3 15:35:52.021: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.955136743s
Dec  3 15:35:53.026: INFO: Verifying statefulset ss doesn't scale past 3 for another 948.085227ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-5740
Dec  3 15:35:54.032: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:35:54.659: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 15:35:54.659: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 15:35:54.659: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 15:35:54.659: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:35:55.133: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 15:35:55.133: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 15:35:55.133: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 15:35:55.133: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:35:55.720: INFO: rc: 1
Dec  3 15:35:55.720: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  error: Internal error occurred: error executing command in container: container not running (fe47bf428d894df414cdf19ed13511379b93590eff7e968635b57b8fb6fa49f3)
 [] <nil> 0xc003643cb0 exit status 1 <nil> <nil> true [0xc0024162b0 0xc002416330 0xc0024163d0] [0xc0024162b0 0xc002416330 0xc0024163d0] [0xc002416308 0xc0024163b0] [0x10efe30 0x10efe30] 0xc00299a7e0 <nil>}:
Command stdout:

stderr:
error: Internal error occurred: error executing command in container: container not running (fe47bf428d894df414cdf19ed13511379b93590eff7e968635b57b8fb6fa49f3)

error:
exit status 1
Dec  3 15:36:05.721: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:36:05.993: INFO: rc: 1
Dec  3 15:36:05.994: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  error: unable to upgrade connection: container not found ("webserver")
 [] <nil> 0xc0078af080 exit status 1 <nil> <nil> true [0xc0005d68b0 0xc0005d69e8 0xc0005d6ab8] [0xc0005d68b0 0xc0005d69e8 0xc0005d6ab8] [0xc0005d69b0 0xc0005d6a70] [0x10efe30 0x10efe30] 0xc001b25e00 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Dec  3 15:36:15.994: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:36:16.097: INFO: rc: 1
Dec  3 15:36:16.097: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc004d524b0 exit status 1 <nil> <nil> true [0xc0024163f0 0xc0024164a0 0xc0024165a8] [0xc0024163f0 0xc0024164a0 0xc0024165a8] [0xc002416400 0xc002416568] [0x10efe30 0x10efe30] 0xc00299aae0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:36:26.098: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:36:26.266: INFO: rc: 1
Dec  3 15:36:26.266: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc004d52ab0 exit status 1 <nil> <nil> true [0xc002416610 0xc002416688 0xc002416790] [0xc002416610 0xc002416688 0xc002416790] [0xc002416678 0xc002416780] [0x10efe30 0x10efe30] 0xc00299ade0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:36:36.266: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:36:36.416: INFO: rc: 1
Dec  3 15:36:36.416: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001569bc0 exit status 1 <nil> <nil> true [0xc001ca78b0 0xc001ca78c8 0xc001ca78e0] [0xc001ca78b0 0xc001ca78c8 0xc001ca78e0] [0xc001ca78c0 0xc001ca78d8] [0x10efe30 0x10efe30] 0xc006efd800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:36:46.416: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:36:46.528: INFO: rc: 1
Dec  3 15:36:46.528: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002ca8270 exit status 1 <nil> <nil> true [0xc001ca78e8 0xc001ca7900 0xc001ca7918] [0xc001ca78e8 0xc001ca7900 0xc001ca7918] [0xc001ca78f8 0xc001ca7910] [0x10efe30 0x10efe30] 0xc006efdb60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:36:56.529: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:36:56.710: INFO: rc: 1
Dec  3 15:36:56.710: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0015685a0 exit status 1 <nil> <nil> true [0xc000b3a008 0xc000b3a038 0xc000b3a050] [0xc000b3a008 0xc000b3a038 0xc000b3a050] [0xc000b3a030 0xc000b3a048] [0x10efe30 0x10efe30] 0xc00390f260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:37:06.711: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:37:06.810: INFO: rc: 1
Dec  3 15:37:06.811: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000bdc630 exit status 1 <nil> <nil> true [0xc002416028 0xc0024160f0 0xc002416128] [0xc002416028 0xc0024160f0 0xc002416128] [0xc0024160d8 0xc002416118] [0x10efe30 0x10efe30] 0xc003dd4240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:37:16.811: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:37:17.129: INFO: rc: 1
Dec  3 15:37:17.129: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001568b70 exit status 1 <nil> <nil> true [0xc000b3a058 0xc000b3a098 0xc000b3a0c0] [0xc000b3a058 0xc000b3a098 0xc000b3a0c0] [0xc000b3a090 0xc000b3a0b8] [0x10efe30 0x10efe30] 0xc00390f560 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:37:27.130: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:37:27.226: INFO: rc: 1
Dec  3 15:37:27.226: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001569140 exit status 1 <nil> <nil> true [0xc000b3a0c8 0xc000b3a0e0 0xc000b3a0f8] [0xc000b3a0c8 0xc000b3a0e0 0xc000b3a0f8] [0xc000b3a0d8 0xc000b3a0f0] [0x10efe30 0x10efe30] 0xc00390f8c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:37:37.226: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:37:37.381: INFO: rc: 1
Dec  3 15:37:37.381: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0026106c0 exit status 1 <nil> <nil> true [0xc0005d6090 0xc0005d6130 0xc0005d61c8] [0xc0005d6090 0xc0005d6130 0xc0005d61c8] [0xc0005d6100 0xc0005d6198] [0x10efe30 0x10efe30] 0xc00299a240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:37:47.381: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:37:47.531: INFO: rc: 1
Dec  3 15:37:47.532: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0015697a0 exit status 1 <nil> <nil> true [0xc000b3a100 0xc000b3a130 0xc000b3a178] [0xc000b3a100 0xc000b3a130 0xc000b3a178] [0xc000b3a118 0xc000b3a160] [0x10efe30 0x10efe30] 0xc00390fbc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:37:57.532: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:37:57.676: INFO: rc: 1
Dec  3 15:37:57.676: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000bdcd50 exit status 1 <nil> <nil> true [0xc002416160 0xc002416228 0xc002416308] [0xc002416160 0xc002416228 0xc002416308] [0xc0024161f8 0xc0024162b8] [0x10efe30 0x10efe30] 0xc003dd45a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:38:07.676: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:38:07.824: INFO: rc: 1
Dec  3 15:38:07.824: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001569dd0 exit status 1 <nil> <nil> true [0xc000b3a188 0xc000b3a1e0 0xc000b3a228] [0xc000b3a188 0xc000b3a1e0 0xc000b3a228] [0xc000b3a1c8 0xc000b3a210] [0x10efe30 0x10efe30] 0xc00390ff80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:38:17.824: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:38:17.964: INFO: rc: 1
Dec  3 15:38:17.965: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002610cf0 exit status 1 <nil> <nil> true [0xc0005d61e8 0xc0005d6270 0xc0005d62f0] [0xc0005d61e8 0xc0005d6270 0xc0005d62f0] [0xc0005d6260 0xc0005d62c0] [0x10efe30 0x10efe30] 0xc00299a600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:38:27.965: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:38:28.054: INFO: rc: 1
Dec  3 15:38:28.054: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000bdd410 exit status 1 <nil> <nil> true [0xc002416330 0xc0024163d0 0xc002416400] [0xc002416330 0xc0024163d0 0xc002416400] [0xc0024163b0 0xc0024163f8] [0x10efe30 0x10efe30] 0xc003dd48a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:38:38.055: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:38:38.197: INFO: rc: 1
Dec  3 15:38:38.197: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0026112f0 exit status 1 <nil> <nil> true [0xc0005d6310 0xc0005d6340 0xc0005d6420] [0xc0005d6310 0xc0005d6340 0xc0005d6420] [0xc0005d6330 0xc0005d63a8] [0x10efe30 0x10efe30] 0xc00299a960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:38:48.198: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:38:48.339: INFO: rc: 1
Dec  3 15:38:48.339: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002611950 exit status 1 <nil> <nil> true [0xc0005d6430 0xc0005d6478 0xc0005d64e8] [0xc0005d6430 0xc0005d6478 0xc0005d64e8] [0xc0005d6468 0xc0005d64c8] [0x10efe30 0x10efe30] 0xc00299ac60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:38:58.339: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:38:58.483: INFO: rc: 1
Dec  3 15:38:58.483: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc000bdc660 exit status 1 <nil> <nil> true [0xc002416048 0xc002416100 0xc002416160] [0xc002416048 0xc002416100 0xc002416160] [0xc0024160f0 0xc002416128] [0x10efe30 0x10efe30] 0xc00390f260 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:39:08.483: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:39:08.628: INFO: rc: 1
Dec  3 15:39:08.628: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0015685d0 exit status 1 <nil> <nil> true [0xc000b3a000 0xc000b3a030 0xc000b3a048] [0xc000b3a000 0xc000b3a030 0xc000b3a048] [0xc000b3a028 0xc000b3a040] [0x10efe30 0x10efe30] 0xc003dd4240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:39:18.628: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:39:18.718: INFO: rc: 1
Dec  3 15:39:18.718: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002610660 exit status 1 <nil> <nil> true [0xc0005d6090 0xc0005d6130 0xc0005d61c8] [0xc0005d6090 0xc0005d6130 0xc0005d61c8] [0xc0005d6100 0xc0005d6198] [0x10efe30 0x10efe30] 0xc001b246c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:39:28.718: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:39:28.859: INFO: rc: 1
Dec  3 15:39:28.859: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002610c90 exit status 1 <nil> <nil> true [0xc0005d61e8 0xc0005d6270 0xc0005d62f0] [0xc0005d61e8 0xc0005d6270 0xc0005d62f0] [0xc0005d6260 0xc0005d62c0] [0x10efe30 0x10efe30] 0xc001b24b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:39:38.860: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:39:39.002: INFO: rc: 1
Dec  3 15:39:39.002: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002611290 exit status 1 <nil> <nil> true [0xc0005d6310 0xc0005d6340 0xc0005d6420] [0xc0005d6310 0xc0005d6340 0xc0005d6420] [0xc0005d6330 0xc0005d63a8] [0x10efe30 0x10efe30] 0xc001b24f00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:39:49.003: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:39:49.148: INFO: rc: 1
Dec  3 15:39:49.148: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00215e7e0 exit status 1 <nil> <nil> true [0xc001ca6008 0xc001ca6058 0xc001ca6108] [0xc001ca6008 0xc001ca6058 0xc001ca6108] [0xc001ca6050 0xc001ca60c0] [0x10efe30 0x10efe30] 0xc00299a240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:39:59.148: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:39:59.238: INFO: rc: 1
Dec  3 15:39:59.238: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001568c30 exit status 1 <nil> <nil> true [0xc000b3a050 0xc000b3a090 0xc000b3a0b8] [0xc000b3a050 0xc000b3a090 0xc000b3a0b8] [0xc000b3a070 0xc000b3a0b0] [0x10efe30 0x10efe30] 0xc003dd4540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:40:09.239: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:40:09.384: INFO: rc: 1
Dec  3 15:40:09.384: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001569230 exit status 1 <nil> <nil> true [0xc000b3a0c0 0xc000b3a0d8 0xc000b3a0f0] [0xc000b3a0c0 0xc000b3a0d8 0xc000b3a0f0] [0xc000b3a0d0 0xc000b3a0e8] [0x10efe30 0x10efe30] 0xc003dd4840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:40:19.385: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:40:19.478: INFO: rc: 1
Dec  3 15:40:19.478: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00215ede0 exit status 1 <nil> <nil> true [0xc001ca61f8 0xc001ca6290 0xc001ca6300] [0xc001ca61f8 0xc001ca6290 0xc001ca6300] [0xc001ca6240 0xc001ca62e0] [0x10efe30 0x10efe30] 0xc00299a600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:40:29.478: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:40:29.620: INFO: rc: 1
Dec  3 15:40:29.620: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001569890 exit status 1 <nil> <nil> true [0xc000b3a0f8 0xc000b3a118 0xc000b3a160] [0xc000b3a0f8 0xc000b3a118 0xc000b3a160] [0xc000b3a108 0xc000b3a148] [0x10efe30 0x10efe30] 0xc003dd4b40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:40:39.621: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:40:39.715: INFO: rc: 1
Dec  3 15:40:39.715: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001569ec0 exit status 1 <nil> <nil> true [0xc000b3a178 0xc000b3a1c8 0xc000b3a210] [0xc000b3a178 0xc000b3a1c8 0xc000b3a210] [0xc000b3a1a8 0xc000b3a1f0] [0x10efe30 0x10efe30] 0xc003dd4e40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:40:49.715: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:40:49.902: INFO: rc: 1
Dec  3 15:40:49.902: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00215f3b0 exit status 1 <nil> <nil> true [0xc001ca63d8 0xc001ca6478 0xc001ca64e8] [0xc001ca63d8 0xc001ca6478 0xc001ca64e8] [0xc001ca6438 0xc001ca64d0] [0x10efe30 0x10efe30] 0xc00299a960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 15:40:59.902: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-5740 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 15:41:00.041: INFO: rc: 1
Dec  3 15:41:00.041: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
Dec  3 15:41:00.041: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  3 15:41:00.056: INFO: Deleting all statefulset in ns statefulset-5740
Dec  3 15:41:00.059: INFO: Scaling statefulset ss to 0
Dec  3 15:41:00.071: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:41:00.075: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:41:00.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5740" for this suite.
Dec  3 15:41:06.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:41:06.297: INFO: namespace statefulset-5740 deletion completed in 6.200998159s

• [SLOW TEST:375.862 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:41:06.297: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2894
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec  3 15:41:06.696: INFO: Waiting up to 5m0s for pod "downward-api-164b4f22-108c-4518-b7ee-d0ecd4df8f67" in namespace "downward-api-2894" to be "success or failure"
Dec  3 15:41:06.700: INFO: Pod "downward-api-164b4f22-108c-4518-b7ee-d0ecd4df8f67": Phase="Pending", Reason="", readiness=false. Elapsed: 4.04269ms
Dec  3 15:41:08.705: INFO: Pod "downward-api-164b4f22-108c-4518-b7ee-d0ecd4df8f67": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00927151s
STEP: Saw pod success
Dec  3 15:41:08.705: INFO: Pod "downward-api-164b4f22-108c-4518-b7ee-d0ecd4df8f67" satisfied condition "success or failure"
Dec  3 15:41:08.710: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downward-api-164b4f22-108c-4518-b7ee-d0ecd4df8f67 container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:41:08.852: INFO: Waiting for pod downward-api-164b4f22-108c-4518-b7ee-d0ecd4df8f67 to disappear
Dec  3 15:41:08.856: INFO: Pod downward-api-164b4f22-108c-4518-b7ee-d0ecd4df8f67 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:41:08.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2894" for this suite.
Dec  3 15:41:14.877: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:41:15.017: INFO: namespace downward-api-2894 deletion completed in 6.15344036s
•SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:41:15.017: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8957
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:41:15.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8957" for this suite.
Dec  3 15:41:21.436: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:41:21.577: INFO: namespace resourcequota-8957 deletion completed in 6.155906857s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:41:21.578: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3805
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-46nk
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 15:41:22.011: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-46nk" in namespace "subpath-3805" to be "success or failure"
Dec  3 15:41:22.015: INFO: Pod "pod-subpath-test-projected-46nk": Phase="Pending", Reason="", readiness=false. Elapsed: 4.186304ms
Dec  3 15:41:24.020: INFO: Pod "pod-subpath-test-projected-46nk": Phase="Running", Reason="", readiness=true. Elapsed: 2.009371458s
Dec  3 15:41:26.025: INFO: Pod "pod-subpath-test-projected-46nk": Phase="Running", Reason="", readiness=true. Elapsed: 4.014457677s
Dec  3 15:41:28.031: INFO: Pod "pod-subpath-test-projected-46nk": Phase="Running", Reason="", readiness=true. Elapsed: 6.019843429s
Dec  3 15:41:30.036: INFO: Pod "pod-subpath-test-projected-46nk": Phase="Running", Reason="", readiness=true. Elapsed: 8.024887548s
Dec  3 15:41:32.041: INFO: Pod "pod-subpath-test-projected-46nk": Phase="Running", Reason="", readiness=true. Elapsed: 10.029939977s
Dec  3 15:41:34.046: INFO: Pod "pod-subpath-test-projected-46nk": Phase="Running", Reason="", readiness=true. Elapsed: 12.035268835s
Dec  3 15:41:36.052: INFO: Pod "pod-subpath-test-projected-46nk": Phase="Running", Reason="", readiness=true. Elapsed: 14.040741374s
Dec  3 15:41:38.057: INFO: Pod "pod-subpath-test-projected-46nk": Phase="Running", Reason="", readiness=true. Elapsed: 16.045812116s
Dec  3 15:41:40.062: INFO: Pod "pod-subpath-test-projected-46nk": Phase="Running", Reason="", readiness=true. Elapsed: 18.050819789s
Dec  3 15:41:42.067: INFO: Pod "pod-subpath-test-projected-46nk": Phase="Running", Reason="", readiness=true. Elapsed: 20.05639206s
Dec  3 15:41:44.072: INFO: Pod "pod-subpath-test-projected-46nk": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.061456399s
STEP: Saw pod success
Dec  3 15:41:44.072: INFO: Pod "pod-subpath-test-projected-46nk" satisfied condition "success or failure"
Dec  3 15:41:44.077: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-subpath-test-projected-46nk container test-container-subpath-projected-46nk: <nil>
STEP: delete the pod
Dec  3 15:41:44.103: INFO: Waiting for pod pod-subpath-test-projected-46nk to disappear
Dec  3 15:41:44.107: INFO: Pod pod-subpath-test-projected-46nk no longer exists
STEP: Deleting pod pod-subpath-test-projected-46nk
Dec  3 15:41:44.107: INFO: Deleting pod "pod-subpath-test-projected-46nk" in namespace "subpath-3805"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:41:44.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3805" for this suite.
Dec  3 15:41:50.135: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:41:50.277: INFO: namespace subpath-3805 deletion completed in 6.156892663s
•SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:41:50.277: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4634
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:41:50.697: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c27a66e0-2dd3-4bc1-9e14-6ec403e57c91" in namespace "downward-api-4634" to be "success or failure"
Dec  3 15:41:50.702: INFO: Pod "downwardapi-volume-c27a66e0-2dd3-4bc1-9e14-6ec403e57c91": Phase="Pending", Reason="", readiness=false. Elapsed: 4.335138ms
Dec  3 15:41:52.707: INFO: Pod "downwardapi-volume-c27a66e0-2dd3-4bc1-9e14-6ec403e57c91": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009533123s
STEP: Saw pod success
Dec  3 15:41:52.707: INFO: Pod "downwardapi-volume-c27a66e0-2dd3-4bc1-9e14-6ec403e57c91" satisfied condition "success or failure"
Dec  3 15:41:52.712: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downwardapi-volume-c27a66e0-2dd3-4bc1-9e14-6ec403e57c91 container client-container: <nil>
STEP: delete the pod
Dec  3 15:41:52.733: INFO: Waiting for pod downwardapi-volume-c27a66e0-2dd3-4bc1-9e14-6ec403e57c91 to disappear
Dec  3 15:41:52.737: INFO: Pod downwardapi-volume-c27a66e0-2dd3-4bc1-9e14-6ec403e57c91 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:41:52.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4634" for this suite.
Dec  3 15:41:58.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:41:58.940: INFO: namespace downward-api-4634 deletion completed in 6.195369327s
•SSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:41:58.940: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7939
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-a3e00ebc-5229-4264-a322-9386e33b5e0f in namespace container-probe-7939
Dec  3 15:42:01.519: INFO: Started pod busybox-a3e00ebc-5229-4264-a322-9386e33b5e0f in namespace container-probe-7939
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 15:42:01.524: INFO: Initial restart count of pod busybox-a3e00ebc-5229-4264-a322-9386e33b5e0f is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:46:02.155: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7939" for this suite.
Dec  3 15:46:08.181: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:46:08.323: INFO: namespace container-probe-7939 deletion completed in 6.160271444s
•SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:46:08.323: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8410
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-207e5705-1f84-4b73-8b43-e75eddf91388
STEP: Creating a pod to test consume configMaps
Dec  3 15:46:08.609: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-77022880-0672-44ce-9ed5-821a7cb33df7" in namespace "projected-8410" to be "success or failure"
Dec  3 15:46:08.613: INFO: Pod "pod-projected-configmaps-77022880-0672-44ce-9ed5-821a7cb33df7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.103867ms
Dec  3 15:46:10.618: INFO: Pod "pod-projected-configmaps-77022880-0672-44ce-9ed5-821a7cb33df7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009216109s
STEP: Saw pod success
Dec  3 15:46:10.619: INFO: Pod "pod-projected-configmaps-77022880-0672-44ce-9ed5-821a7cb33df7" satisfied condition "success or failure"
Dec  3 15:46:10.623: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-projected-configmaps-77022880-0672-44ce-9ed5-821a7cb33df7 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:46:10.785: INFO: Waiting for pod pod-projected-configmaps-77022880-0672-44ce-9ed5-821a7cb33df7 to disappear
Dec  3 15:46:10.789: INFO: Pod pod-projected-configmaps-77022880-0672-44ce-9ed5-821a7cb33df7 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:46:10.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8410" for this suite.
Dec  3 15:46:18.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:46:18.950: INFO: namespace projected-8410 deletion completed in 8.154056844s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:46:18.951: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7393
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Dec  3 15:46:21.223: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec pod-sharedvolume-8fae7da0-0407-4fb7-a083-1083373cddb3 -c busybox-main-container --namespace=emptydir-7393 -- cat /usr/share/volumeshare/shareddata.txt'
Dec  3 15:46:21.819: INFO: stderr: ""
Dec  3 15:46:21.819: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:46:21.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7393" for this suite.
Dec  3 15:46:27.847: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:46:27.987: INFO: namespace emptydir-7393 deletion completed in 6.160185075s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:46:27.988: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-359
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  3 15:46:30.829: INFO: Successfully updated pod "pod-update-1df08816-9761-4cb3-9c85-2ac58b794d82"
STEP: verifying the updated pod is in kubernetes
Dec  3 15:46:30.838: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:46:30.838: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-359" for this suite.
Dec  3 15:46:42.859: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:46:43.009: INFO: namespace pods-359 deletion completed in 12.164120515s
•SSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:46:43.010: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-4774
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Dec  3 15:46:43.389: INFO: Waiting up to 1m0s for all nodes to be ready
Dec  3 15:47:43.429: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:47:43.434: INFO: Starting informer...
STEP: Starting pods...
Dec  3 15:47:43.449: INFO: Pod1 is running on izgw8fisrtg04goc4t8tqaz. Tainting Node
Dec  3 15:47:45.471: INFO: Pod2 is running on izgw8fisrtg04goc4t8tqaz. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Dec  3 15:47:57.937: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Dec  3 15:48:12.017: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:48:12.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-4774" for this suite.
Dec  3 15:48:18.053: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:48:18.192: INFO: namespace taint-multiple-pods-4774 deletion completed in 6.155877296s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:48:18.193: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-190
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-67a8f4e1-261b-41a4-8189-6d89addb473b
STEP: Creating a pod to test consume secrets
Dec  3 15:48:18.507: INFO: Waiting up to 5m0s for pod "pod-secrets-9769df9a-198a-4495-9805-639bdcf3fff6" in namespace "secrets-190" to be "success or failure"
Dec  3 15:48:18.511: INFO: Pod "pod-secrets-9769df9a-198a-4495-9805-639bdcf3fff6": Phase="Pending", Reason="", readiness=false. Elapsed: 3.74554ms
Dec  3 15:48:20.516: INFO: Pod "pod-secrets-9769df9a-198a-4495-9805-639bdcf3fff6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009080707s
STEP: Saw pod success
Dec  3 15:48:20.516: INFO: Pod "pod-secrets-9769df9a-198a-4495-9805-639bdcf3fff6" satisfied condition "success or failure"
Dec  3 15:48:20.520: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-secrets-9769df9a-198a-4495-9805-639bdcf3fff6 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:48:20.678: INFO: Waiting for pod pod-secrets-9769df9a-198a-4495-9805-639bdcf3fff6 to disappear
Dec  3 15:48:20.682: INFO: Pod pod-secrets-9769df9a-198a-4495-9805-639bdcf3fff6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:48:20.682: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-190" for this suite.
Dec  3 15:48:26.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:48:26.850: INFO: namespace secrets-190 deletion completed in 6.160693435s
•
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:48:26.850: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7526
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7526.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7526.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7526.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7526.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:48:31.302: INFO: DNS probes using dns-test-4615c46e-0a39-4629-a521-1741d80f36e5 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7526.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-7526.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7526.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-7526.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:48:35.434: INFO: File wheezy_udp@dns-test-service-3.dns-7526.svc.cluster.local from pod  dns-7526/dns-test-8a57c0ac-4544-4db7-98e3-15b02e172b7d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:48:35.521: INFO: File jessie_udp@dns-test-service-3.dns-7526.svc.cluster.local from pod  dns-7526/dns-test-8a57c0ac-4544-4db7-98e3-15b02e172b7d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:48:35.522: INFO: Lookups using dns-7526/dns-test-8a57c0ac-4544-4db7-98e3-15b02e172b7d failed for: [wheezy_udp@dns-test-service-3.dns-7526.svc.cluster.local jessie_udp@dns-test-service-3.dns-7526.svc.cluster.local]

Dec  3 15:48:40.532: INFO: File wheezy_udp@dns-test-service-3.dns-7526.svc.cluster.local from pod  dns-7526/dns-test-8a57c0ac-4544-4db7-98e3-15b02e172b7d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:48:40.578: INFO: File jessie_udp@dns-test-service-3.dns-7526.svc.cluster.local from pod  dns-7526/dns-test-8a57c0ac-4544-4db7-98e3-15b02e172b7d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:48:40.578: INFO: Lookups using dns-7526/dns-test-8a57c0ac-4544-4db7-98e3-15b02e172b7d failed for: [wheezy_udp@dns-test-service-3.dns-7526.svc.cluster.local jessie_udp@dns-test-service-3.dns-7526.svc.cluster.local]

Dec  3 15:48:45.573: INFO: File wheezy_udp@dns-test-service-3.dns-7526.svc.cluster.local from pod  dns-7526/dns-test-8a57c0ac-4544-4db7-98e3-15b02e172b7d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:48:45.618: INFO: File jessie_udp@dns-test-service-3.dns-7526.svc.cluster.local from pod  dns-7526/dns-test-8a57c0ac-4544-4db7-98e3-15b02e172b7d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:48:45.618: INFO: Lookups using dns-7526/dns-test-8a57c0ac-4544-4db7-98e3-15b02e172b7d failed for: [wheezy_udp@dns-test-service-3.dns-7526.svc.cluster.local jessie_udp@dns-test-service-3.dns-7526.svc.cluster.local]

Dec  3 15:48:50.533: INFO: File wheezy_udp@dns-test-service-3.dns-7526.svc.cluster.local from pod  dns-7526/dns-test-8a57c0ac-4544-4db7-98e3-15b02e172b7d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:48:50.621: INFO: File jessie_udp@dns-test-service-3.dns-7526.svc.cluster.local from pod  dns-7526/dns-test-8a57c0ac-4544-4db7-98e3-15b02e172b7d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:48:50.622: INFO: Lookups using dns-7526/dns-test-8a57c0ac-4544-4db7-98e3-15b02e172b7d failed for: [wheezy_udp@dns-test-service-3.dns-7526.svc.cluster.local jessie_udp@dns-test-service-3.dns-7526.svc.cluster.local]

Dec  3 15:48:55.532: INFO: File wheezy_udp@dns-test-service-3.dns-7526.svc.cluster.local from pod  dns-7526/dns-test-8a57c0ac-4544-4db7-98e3-15b02e172b7d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:48:55.619: INFO: File jessie_udp@dns-test-service-3.dns-7526.svc.cluster.local from pod  dns-7526/dns-test-8a57c0ac-4544-4db7-98e3-15b02e172b7d contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:48:55.619: INFO: Lookups using dns-7526/dns-test-8a57c0ac-4544-4db7-98e3-15b02e172b7d failed for: [wheezy_udp@dns-test-service-3.dns-7526.svc.cluster.local jessie_udp@dns-test-service-3.dns-7526.svc.cluster.local]

Dec  3 15:49:00.617: INFO: DNS probes using dns-test-8a57c0ac-4544-4db7-98e3-15b02e172b7d succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7526.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-7526.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-7526.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-7526.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:49:04.846: INFO: DNS probes using dns-test-a2510dfb-bcd2-48c1-8692-b2f2f102372b succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:49:04.865: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7526" for this suite.
Dec  3 15:49:10.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:49:11.029: INFO: namespace dns-7526 deletion completed in 6.157352603s
•SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:49:11.030: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4357
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  3 15:49:13.420: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:49:13.431: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4357" for this suite.
Dec  3 15:49:21.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:49:21.594: INFO: namespace container-runtime-4357 deletion completed in 8.155927196s
•SSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:49:21.594: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3314
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  3 15:49:24.014: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:49:24.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3314" for this suite.
Dec  3 15:49:30.047: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:49:30.191: INFO: namespace container-runtime-3314 deletion completed in 6.157985225s
•SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:49:30.192: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-9403
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec  3 15:49:30.597: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:49:51.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9403" for this suite.
Dec  3 15:49:57.716: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:49:57.859: INFO: namespace crd-publish-openapi-9403 deletion completed in 6.157352201s
•SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:49:57.860: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5620
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:49:58.193: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:50:00.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5620" for this suite.
Dec  3 15:50:50.454: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:50:50.593: INFO: namespace pods-5620 deletion completed in 50.153309522s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:50:50.594: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-1314
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Dec  3 15:50:51.614: INFO: created pod pod-service-account-defaultsa
Dec  3 15:50:51.614: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec  3 15:50:51.620: INFO: created pod pod-service-account-mountsa
Dec  3 15:50:51.620: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec  3 15:50:51.626: INFO: created pod pod-service-account-nomountsa
Dec  3 15:50:51.626: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec  3 15:50:51.630: INFO: created pod pod-service-account-defaultsa-mountspec
Dec  3 15:50:51.630: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec  3 15:50:51.635: INFO: created pod pod-service-account-mountsa-mountspec
Dec  3 15:50:51.635: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec  3 15:50:51.640: INFO: created pod pod-service-account-nomountsa-mountspec
Dec  3 15:50:51.640: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec  3 15:50:51.644: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec  3 15:50:51.644: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec  3 15:50:51.649: INFO: created pod pod-service-account-mountsa-nomountspec
Dec  3 15:50:51.649: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec  3 15:50:51.655: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec  3 15:50:51.655: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:50:51.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-1314" for this suite.
Dec  3 15:51:09.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:51:09.817: INFO: namespace svcaccounts-1314 deletion completed in 18.15476399s
•
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:51:09.817: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-7369
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-svb5x in namespace proxy-7369
I1203 15:51:10.107105    5091 runners.go:184] Created replication controller with name: proxy-service-svb5x, namespace: proxy-7369, replica count: 1
I1203 15:51:11.157577    5091 runners.go:184] proxy-service-svb5x Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 15:51:12.157882    5091 runners.go:184] proxy-service-svb5x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 15:51:13.158109    5091 runners.go:184] proxy-service-svb5x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 15:51:14.158399    5091 runners.go:184] proxy-service-svb5x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 15:51:15.158737    5091 runners.go:184] proxy-service-svb5x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 15:51:16.159257    5091 runners.go:184] proxy-service-svb5x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 15:51:17.159472    5091 runners.go:184] proxy-service-svb5x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 15:51:18.159847    5091 runners.go:184] proxy-service-svb5x Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 15:51:19.160134    5091 runners.go:184] proxy-service-svb5x Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 15:51:19.164: INFO: setup took 9.071225198s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec  3 15:51:19.179: INFO: (0) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">test<... (200; 14.204634ms)
Dec  3 15:51:19.184: INFO: (0) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">... (200; 17.989165ms)
Dec  3 15:51:19.185: INFO: (0) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/rewriteme">test</a> (200; 20.273985ms)
Dec  3 15:51:19.187: INFO: (0) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname2/proxy/: bar (200; 21.83953ms)
Dec  3 15:51:19.187: INFO: (0) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname1/proxy/: foo (200; 21.899063ms)
Dec  3 15:51:19.190: INFO: (0) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 24.175063ms)
Dec  3 15:51:19.190: INFO: (0) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 24.801618ms)
Dec  3 15:51:19.190: INFO: (0) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 24.442779ms)
Dec  3 15:51:19.190: INFO: (0) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname1/proxy/: foo (200; 24.657918ms)
Dec  3 15:51:19.190: INFO: (0) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname2/proxy/: bar (200; 25.245ms)
Dec  3 15:51:19.190: INFO: (0) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 25.017775ms)
Dec  3 15:51:19.197: INFO: (0) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname2/proxy/: tls qux (200; 31.355902ms)
Dec  3 15:51:19.197: INFO: (0) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:462/proxy/: tls qux (200; 32.318784ms)
Dec  3 15:51:19.199: INFO: (0) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/tlsrewritem... (200; 33.923624ms)
Dec  3 15:51:19.201: INFO: (0) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname1/proxy/: tls baz (200; 35.488357ms)
Dec  3 15:51:19.203: INFO: (0) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:460/proxy/: tls baz (200; 37.811685ms)
Dec  3 15:51:19.211: INFO: (1) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/rewriteme">test</a> (200; 7.703388ms)
Dec  3 15:51:19.212: INFO: (1) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 8.292147ms)
Dec  3 15:51:19.212: INFO: (1) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 8.245516ms)
Dec  3 15:51:19.212: INFO: (1) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname1/proxy/: tls baz (200; 8.258515ms)
Dec  3 15:51:19.212: INFO: (1) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">... (200; 8.462764ms)
Dec  3 15:51:19.212: INFO: (1) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/tlsrewritem... (200; 8.454465ms)
Dec  3 15:51:19.212: INFO: (1) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:460/proxy/: tls baz (200; 8.51464ms)
Dec  3 15:51:19.212: INFO: (1) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 8.471921ms)
Dec  3 15:51:19.214: INFO: (1) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:462/proxy/: tls qux (200; 10.38522ms)
Dec  3 15:51:19.214: INFO: (1) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname2/proxy/: tls qux (200; 10.463785ms)
Dec  3 15:51:19.214: INFO: (1) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">test<... (200; 10.486622ms)
Dec  3 15:51:19.214: INFO: (1) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 10.302164ms)
Dec  3 15:51:19.216: INFO: (1) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname1/proxy/: foo (200; 12.395816ms)
Dec  3 15:51:19.216: INFO: (1) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname2/proxy/: bar (200; 12.540033ms)
Dec  3 15:51:19.218: INFO: (1) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname1/proxy/: foo (200; 14.490446ms)
Dec  3 15:51:19.220: INFO: (1) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname2/proxy/: bar (200; 16.784268ms)
Dec  3 15:51:19.229: INFO: (2) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 8.503956ms)
Dec  3 15:51:19.229: INFO: (2) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/rewriteme">test</a> (200; 8.435368ms)
Dec  3 15:51:19.229: INFO: (2) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname1/proxy/: foo (200; 8.539784ms)
Dec  3 15:51:19.229: INFO: (2) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 8.610759ms)
Dec  3 15:51:19.229: INFO: (2) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname1/proxy/: tls baz (200; 9.028741ms)
Dec  3 15:51:19.229: INFO: (2) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 8.823488ms)
Dec  3 15:51:19.229: INFO: (2) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">... (200; 8.844514ms)
Dec  3 15:51:19.229: INFO: (2) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/tlsrewritem... (200; 8.840316ms)
Dec  3 15:51:19.229: INFO: (2) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">test<... (200; 8.815901ms)
Dec  3 15:51:19.229: INFO: (2) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname2/proxy/: tls qux (200; 8.946403ms)
Dec  3 15:51:19.231: INFO: (2) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:460/proxy/: tls baz (200; 10.320821ms)
Dec  3 15:51:19.233: INFO: (2) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname2/proxy/: bar (200; 12.629404ms)
Dec  3 15:51:19.233: INFO: (2) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:462/proxy/: tls qux (200; 12.536834ms)
Dec  3 15:51:19.235: INFO: (2) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname2/proxy/: bar (200; 14.750419ms)
Dec  3 15:51:19.235: INFO: (2) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname1/proxy/: foo (200; 14.629338ms)
Dec  3 15:51:19.235: INFO: (2) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 14.655266ms)
Dec  3 15:51:19.244: INFO: (3) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 9.248244ms)
Dec  3 15:51:19.244: INFO: (3) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:460/proxy/: tls baz (200; 9.21099ms)
Dec  3 15:51:19.244: INFO: (3) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">test<... (200; 9.300624ms)
Dec  3 15:51:19.247: INFO: (3) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 12.132354ms)
Dec  3 15:51:19.247: INFO: (3) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 12.250583ms)
Dec  3 15:51:19.247: INFO: (3) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:462/proxy/: tls qux (200; 12.168679ms)
Dec  3 15:51:19.247: INFO: (3) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">... (200; 12.204032ms)
Dec  3 15:51:19.247: INFO: (3) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/rewriteme">test</a> (200; 12.100266ms)
Dec  3 15:51:19.247: INFO: (3) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/tlsrewritem... (200; 12.144364ms)
Dec  3 15:51:19.249: INFO: (3) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 13.298213ms)
Dec  3 15:51:19.249: INFO: (3) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname1/proxy/: tls baz (200; 13.319483ms)
Dec  3 15:51:19.249: INFO: (3) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname2/proxy/: tls qux (200; 13.314284ms)
Dec  3 15:51:19.250: INFO: (3) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname1/proxy/: foo (200; 15.305678ms)
Dec  3 15:51:19.253: INFO: (3) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname2/proxy/: bar (200; 17.444753ms)
Dec  3 15:51:19.253: INFO: (3) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname2/proxy/: bar (200; 17.453765ms)
Dec  3 15:51:19.255: INFO: (3) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname1/proxy/: foo (200; 19.752594ms)
Dec  3 15:51:19.263: INFO: (4) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:460/proxy/: tls baz (200; 7.692355ms)
Dec  3 15:51:19.263: INFO: (4) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 7.827726ms)
Dec  3 15:51:19.263: INFO: (4) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/tlsrewritem... (200; 8.096599ms)
Dec  3 15:51:19.263: INFO: (4) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 7.596503ms)
Dec  3 15:51:19.263: INFO: (4) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/rewriteme">test</a> (200; 7.972679ms)
Dec  3 15:51:19.263: INFO: (4) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">... (200; 7.426234ms)
Dec  3 15:51:19.264: INFO: (4) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 7.418906ms)
Dec  3 15:51:19.264: INFO: (4) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:462/proxy/: tls qux (200; 7.666914ms)
Dec  3 15:51:19.264: INFO: (4) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">test<... (200; 7.56899ms)
Dec  3 15:51:19.264: INFO: (4) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 7.773069ms)
Dec  3 15:51:19.266: INFO: (4) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname2/proxy/: tls qux (200; 10.084471ms)
Dec  3 15:51:19.266: INFO: (4) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname1/proxy/: tls baz (200; 10.182057ms)
Dec  3 15:51:19.268: INFO: (4) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname2/proxy/: bar (200; 11.991757ms)
Dec  3 15:51:19.268: INFO: (4) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname1/proxy/: foo (200; 12.33286ms)
Dec  3 15:51:19.270: INFO: (4) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname1/proxy/: foo (200; 14.21225ms)
Dec  3 15:51:19.270: INFO: (4) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname2/proxy/: bar (200; 13.874098ms)
Dec  3 15:51:19.278: INFO: (5) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 7.509266ms)
Dec  3 15:51:19.278: INFO: (5) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 8.19257ms)
Dec  3 15:51:19.278: INFO: (5) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 7.372694ms)
Dec  3 15:51:19.278: INFO: (5) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 7.856572ms)
Dec  3 15:51:19.278: INFO: (5) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:462/proxy/: tls qux (200; 7.795799ms)
Dec  3 15:51:19.278: INFO: (5) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">test<... (200; 7.681628ms)
Dec  3 15:51:19.279: INFO: (5) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/tlsrewritem... (200; 8.091035ms)
Dec  3 15:51:19.279: INFO: (5) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/rewriteme">test</a> (200; 8.040626ms)
Dec  3 15:51:19.279: INFO: (5) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">... (200; 8.540413ms)
Dec  3 15:51:19.281: INFO: (5) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:460/proxy/: tls baz (200; 9.945267ms)
Dec  3 15:51:19.281: INFO: (5) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname2/proxy/: tls qux (200; 9.822865ms)
Dec  3 15:51:19.281: INFO: (5) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname2/proxy/: bar (200; 10.660988ms)
Dec  3 15:51:19.281: INFO: (5) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname1/proxy/: tls baz (200; 9.919048ms)
Dec  3 15:51:19.283: INFO: (5) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname1/proxy/: foo (200; 12.740576ms)
Dec  3 15:51:19.283: INFO: (5) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname2/proxy/: bar (200; 12.435927ms)
Dec  3 15:51:19.283: INFO: (5) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname1/proxy/: foo (200; 11.980237ms)
Dec  3 15:51:19.291: INFO: (6) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">... (200; 7.911982ms)
Dec  3 15:51:19.291: INFO: (6) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 7.808648ms)
Dec  3 15:51:19.291: INFO: (6) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">test<... (200; 7.99128ms)
Dec  3 15:51:19.291: INFO: (6) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/rewriteme">test</a> (200; 7.858432ms)
Dec  3 15:51:19.291: INFO: (6) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:460/proxy/: tls baz (200; 7.974172ms)
Dec  3 15:51:19.291: INFO: (6) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 7.891656ms)
Dec  3 15:51:19.292: INFO: (6) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname1/proxy/: foo (200; 8.933559ms)
Dec  3 15:51:19.292: INFO: (6) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:462/proxy/: tls qux (200; 8.990222ms)
Dec  3 15:51:19.292: INFO: (6) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 9.029476ms)
Dec  3 15:51:19.292: INFO: (6) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/tlsrewritem... (200; 9.010029ms)
Dec  3 15:51:19.294: INFO: (6) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname1/proxy/: tls baz (200; 10.781641ms)
Dec  3 15:51:19.294: INFO: (6) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname2/proxy/: tls qux (200; 10.926362ms)
Dec  3 15:51:19.296: INFO: (6) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 12.83918ms)
Dec  3 15:51:19.296: INFO: (6) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname1/proxy/: foo (200; 12.941508ms)
Dec  3 15:51:19.296: INFO: (6) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname2/proxy/: bar (200; 12.996954ms)
Dec  3 15:51:19.298: INFO: (6) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname2/proxy/: bar (200; 14.956522ms)
Dec  3 15:51:19.306: INFO: (7) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/rewriteme">test</a> (200; 8.003908ms)
Dec  3 15:51:19.306: INFO: (7) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 8.019974ms)
Dec  3 15:51:19.306: INFO: (7) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 7.977644ms)
Dec  3 15:51:19.306: INFO: (7) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">... (200; 8.061928ms)
Dec  3 15:51:19.306: INFO: (7) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:462/proxy/: tls qux (200; 7.961142ms)
Dec  3 15:51:19.307: INFO: (7) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 8.384538ms)
Dec  3 15:51:19.307: INFO: (7) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname2/proxy/: bar (200; 9.274655ms)
Dec  3 15:51:19.307: INFO: (7) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:460/proxy/: tls baz (200; 9.17028ms)
Dec  3 15:51:19.307: INFO: (7) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/tlsrewritem... (200; 9.217644ms)
Dec  3 15:51:19.307: INFO: (7) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">test<... (200; 9.192719ms)
Dec  3 15:51:19.307: INFO: (7) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname1/proxy/: tls baz (200; 9.123205ms)
Dec  3 15:51:19.309: INFO: (7) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname2/proxy/: tls qux (200; 10.567301ms)
Dec  3 15:51:19.311: INFO: (7) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 12.84233ms)
Dec  3 15:51:19.311: INFO: (7) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname1/proxy/: foo (200; 13.004206ms)
Dec  3 15:51:19.311: INFO: (7) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname1/proxy/: foo (200; 12.817948ms)
Dec  3 15:51:19.313: INFO: (7) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname2/proxy/: bar (200; 14.915042ms)
Dec  3 15:51:19.322: INFO: (8) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:462/proxy/: tls qux (200; 8.642423ms)
Dec  3 15:51:19.322: INFO: (8) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 8.426662ms)
Dec  3 15:51:19.322: INFO: (8) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/rewriteme">test</a> (200; 8.479979ms)
Dec  3 15:51:19.322: INFO: (8) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">test<... (200; 8.41254ms)
Dec  3 15:51:19.322: INFO: (8) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/tlsrewritem... (200; 8.596778ms)
Dec  3 15:51:19.322: INFO: (8) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 8.536992ms)
Dec  3 15:51:19.322: INFO: (8) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname1/proxy/: tls baz (200; 9.052781ms)
Dec  3 15:51:19.322: INFO: (8) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname1/proxy/: foo (200; 9.208024ms)
Dec  3 15:51:19.323: INFO: (8) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 9.06466ms)
Dec  3 15:51:19.323: INFO: (8) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">... (200; 9.115814ms)
Dec  3 15:51:19.322: INFO: (8) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:460/proxy/: tls baz (200; 8.996315ms)
Dec  3 15:51:19.324: INFO: (8) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname2/proxy/: tls qux (200; 10.40924ms)
Dec  3 15:51:19.326: INFO: (8) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname2/proxy/: bar (200; 12.568714ms)
Dec  3 15:51:19.326: INFO: (8) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname2/proxy/: bar (200; 12.998581ms)
Dec  3 15:51:19.328: INFO: (8) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname1/proxy/: foo (200; 14.711811ms)
Dec  3 15:51:19.328: INFO: (8) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 14.598822ms)
Dec  3 15:51:19.336: INFO: (9) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:462/proxy/: tls qux (200; 7.894915ms)
Dec  3 15:51:19.336: INFO: (9) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 7.452777ms)
Dec  3 15:51:19.336: INFO: (9) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/rewriteme">test</a> (200; 7.524025ms)
Dec  3 15:51:19.336: INFO: (9) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 7.681276ms)
Dec  3 15:51:19.336: INFO: (9) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/tlsrewritem... (200; 7.621467ms)
Dec  3 15:51:19.336: INFO: (9) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">test<... (200; 7.754821ms)
Dec  3 15:51:19.337: INFO: (9) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:460/proxy/: tls baz (200; 8.42444ms)
Dec  3 15:51:19.337: INFO: (9) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname1/proxy/: tls baz (200; 8.431855ms)
Dec  3 15:51:19.337: INFO: (9) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 8.130243ms)
Dec  3 15:51:19.337: INFO: (9) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">... (200; 8.204293ms)
Dec  3 15:51:19.337: INFO: (9) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname2/proxy/: bar (200; 9.050784ms)
Dec  3 15:51:19.339: INFO: (9) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname2/proxy/: tls qux (200; 10.208466ms)
Dec  3 15:51:19.341: INFO: (9) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 12.323295ms)
Dec  3 15:51:19.341: INFO: (9) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname1/proxy/: foo (200; 12.562793ms)
Dec  3 15:51:19.343: INFO: (9) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname1/proxy/: foo (200; 14.291751ms)
Dec  3 15:51:19.343: INFO: (9) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname2/proxy/: bar (200; 14.271511ms)
Dec  3 15:51:19.352: INFO: (10) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname1/proxy/: tls baz (200; 8.985621ms)
Dec  3 15:51:19.352: INFO: (10) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">... (200; 8.976299ms)
Dec  3 15:51:19.353: INFO: (10) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 9.130163ms)
Dec  3 15:51:19.353: INFO: (10) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname2/proxy/: tls qux (200; 8.986172ms)
Dec  3 15:51:19.353: INFO: (10) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:460/proxy/: tls baz (200; 9.071068ms)
Dec  3 15:51:19.353: INFO: (10) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/rewriteme">test</a> (200; 9.061464ms)
Dec  3 15:51:19.353: INFO: (10) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname1/proxy/: foo (200; 9.006973ms)
Dec  3 15:51:19.353: INFO: (10) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 9.073967ms)
Dec  3 15:51:19.353: INFO: (10) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname2/proxy/: bar (200; 9.19866ms)
Dec  3 15:51:19.353: INFO: (10) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">test<... (200; 9.233572ms)
Dec  3 15:51:19.354: INFO: (10) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/tlsrewritem... (200; 10.757942ms)
Dec  3 15:51:19.354: INFO: (10) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:462/proxy/: tls qux (200; 10.800852ms)
Dec  3 15:51:19.356: INFO: (10) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname1/proxy/: foo (200; 12.868486ms)
Dec  3 15:51:19.356: INFO: (10) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 12.896013ms)
Dec  3 15:51:19.358: INFO: (10) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 15.012892ms)
Dec  3 15:51:19.359: INFO: (10) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname2/proxy/: bar (200; 15.051478ms)
Dec  3 15:51:19.367: INFO: (11) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 7.529486ms)
Dec  3 15:51:19.367: INFO: (11) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 8.022981ms)
Dec  3 15:51:19.367: INFO: (11) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">... (200; 7.132931ms)
Dec  3 15:51:19.367: INFO: (11) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:460/proxy/: tls baz (200; 7.731762ms)
Dec  3 15:51:19.367: INFO: (11) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/rewriteme">test</a> (200; 7.913892ms)
Dec  3 15:51:19.367: INFO: (11) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 7.856074ms)
Dec  3 15:51:19.367: INFO: (11) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:462/proxy/: tls qux (200; 7.764625ms)
Dec  3 15:51:19.369: INFO: (11) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/tlsrewritem... (200; 9.504802ms)
Dec  3 15:51:19.369: INFO: (11) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 9.898551ms)
Dec  3 15:51:19.369: INFO: (11) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">test<... (200; 9.454674ms)
Dec  3 15:51:19.369: INFO: (11) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname1/proxy/: tls baz (200; 10.075332ms)
Dec  3 15:51:19.369: INFO: (11) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname2/proxy/: tls qux (200; 10.056246ms)
Dec  3 15:51:19.369: INFO: (11) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname2/proxy/: bar (200; 9.901865ms)
Dec  3 15:51:19.369: INFO: (11) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname1/proxy/: foo (200; 10.313ms)
Dec  3 15:51:19.372: INFO: (11) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname2/proxy/: bar (200; 11.776294ms)
Dec  3 15:51:19.374: INFO: (11) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname1/proxy/: foo (200; 14.493792ms)
Dec  3 15:51:19.382: INFO: (12) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/rewriteme">test</a> (200; 7.221397ms)
Dec  3 15:51:19.382: INFO: (12) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 7.79326ms)
Dec  3 15:51:19.382: INFO: (12) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">test<... (200; 7.548447ms)
Dec  3 15:51:19.382: INFO: (12) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:460/proxy/: tls baz (200; 7.220756ms)
Dec  3 15:51:19.382: INFO: (12) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/tlsrewritem... (200; 7.459637ms)
Dec  3 15:51:19.382: INFO: (12) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 7.551677ms)
Dec  3 15:51:19.383: INFO: (12) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 7.896643ms)
Dec  3 15:51:19.385: INFO: (12) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname2/proxy/: tls qux (200; 10.055955ms)
Dec  3 15:51:19.385: INFO: (12) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:462/proxy/: tls qux (200; 9.978063ms)
Dec  3 15:51:19.385: INFO: (12) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname1/proxy/: tls baz (200; 10.201159ms)
Dec  3 15:51:19.385: INFO: (12) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">... (200; 9.843825ms)
Dec  3 15:51:19.385: INFO: (12) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname2/proxy/: bar (200; 10.859794ms)
Dec  3 15:51:19.387: INFO: (12) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 12.062278ms)
Dec  3 15:51:19.388: INFO: (12) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname1/proxy/: foo (200; 13.172011ms)
Dec  3 15:51:19.389: INFO: (12) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname1/proxy/: foo (200; 13.999925ms)
Dec  3 15:51:19.391: INFO: (12) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname2/proxy/: bar (200; 15.991941ms)
Dec  3 15:51:19.399: INFO: (13) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/tlsrewritem... (200; 7.421855ms)
Dec  3 15:51:19.399: INFO: (13) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname2/proxy/: bar (200; 7.637054ms)
Dec  3 15:51:19.399: INFO: (13) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:462/proxy/: tls qux (200; 7.862415ms)
Dec  3 15:51:19.399: INFO: (13) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 7.496914ms)
Dec  3 15:51:19.399: INFO: (13) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">test<... (200; 7.602997ms)
Dec  3 15:51:19.399: INFO: (13) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/rewriteme">test</a> (200; 7.452943ms)
Dec  3 15:51:19.400: INFO: (13) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname1/proxy/: tls baz (200; 7.655071ms)
Dec  3 15:51:19.400: INFO: (13) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 7.878488ms)
Dec  3 15:51:19.400: INFO: (13) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:460/proxy/: tls baz (200; 7.846619ms)
Dec  3 15:51:19.400: INFO: (13) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">... (200; 7.434682ms)
Dec  3 15:51:19.402: INFO: (13) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 9.393564ms)
Dec  3 15:51:19.402: INFO: (13) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname2/proxy/: tls qux (200; 9.757431ms)
Dec  3 15:51:19.402: INFO: (13) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 9.768055ms)
Dec  3 15:51:19.404: INFO: (13) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname2/proxy/: bar (200; 11.747322ms)
Dec  3 15:51:19.406: INFO: (13) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname1/proxy/: foo (200; 14.163302ms)
Dec  3 15:51:19.408: INFO: (13) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname1/proxy/: foo (200; 15.90657ms)
Dec  3 15:51:19.416: INFO: (14) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">test<... (200; 7.387407ms)
Dec  3 15:51:19.416: INFO: (14) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 7.829069ms)
Dec  3 15:51:19.416: INFO: (14) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:460/proxy/: tls baz (200; 8.214125ms)
Dec  3 15:51:19.416: INFO: (14) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname1/proxy/: foo (200; 8.080147ms)
Dec  3 15:51:19.416: INFO: (14) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">... (200; 7.674507ms)
Dec  3 15:51:19.417: INFO: (14) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname1/proxy/: tls baz (200; 8.192954ms)
Dec  3 15:51:19.417: INFO: (14) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname2/proxy/: tls qux (200; 8.148308ms)
Dec  3 15:51:19.417: INFO: (14) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 7.618829ms)
Dec  3 15:51:19.417: INFO: (14) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:462/proxy/: tls qux (200; 8.041827ms)
Dec  3 15:51:19.417: INFO: (14) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/tlsrewritem... (200; 7.563396ms)
Dec  3 15:51:19.417: INFO: (14) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 7.803346ms)
Dec  3 15:51:19.419: INFO: (14) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/rewriteme">test</a> (200; 9.542171ms)
Dec  3 15:51:19.421: INFO: (14) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname1/proxy/: foo (200; 12.113192ms)
Dec  3 15:51:19.421: INFO: (14) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname2/proxy/: bar (200; 12.068581ms)
Dec  3 15:51:19.421: INFO: (14) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname2/proxy/: bar (200; 11.927721ms)
Dec  3 15:51:19.423: INFO: (14) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 13.78189ms)
Dec  3 15:51:19.431: INFO: (15) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 8.188572ms)
Dec  3 15:51:19.431: INFO: (15) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 8.177127ms)
Dec  3 15:51:19.431: INFO: (15) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">... (200; 8.277032ms)
Dec  3 15:51:19.431: INFO: (15) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:460/proxy/: tls baz (200; 8.189724ms)
Dec  3 15:51:19.431: INFO: (15) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:462/proxy/: tls qux (200; 8.258885ms)
Dec  3 15:51:19.431: INFO: (15) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 8.365785ms)
Dec  3 15:51:19.432: INFO: (15) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">test<... (200; 8.597551ms)
Dec  3 15:51:19.432: INFO: (15) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/tlsrewritem... (200; 8.749553ms)
Dec  3 15:51:19.434: INFO: (15) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 10.717838ms)
Dec  3 15:51:19.434: INFO: (15) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname2/proxy/: bar (200; 10.743394ms)
Dec  3 15:51:19.434: INFO: (15) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname2/proxy/: tls qux (200; 10.775703ms)
Dec  3 15:51:19.434: INFO: (15) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname1/proxy/: foo (200; 10.762742ms)
Dec  3 15:51:19.434: INFO: (15) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname1/proxy/: tls baz (200; 10.859166ms)
Dec  3 15:51:19.434: INFO: (15) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/rewriteme">test</a> (200; 10.907005ms)
Dec  3 15:51:19.436: INFO: (15) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname1/proxy/: foo (200; 12.773864ms)
Dec  3 15:51:19.479: INFO: (15) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname2/proxy/: bar (200; 55.411722ms)
Dec  3 15:51:19.487: INFO: (16) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 7.987049ms)
Dec  3 15:51:19.487: INFO: (16) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:462/proxy/: tls qux (200; 8.075419ms)
Dec  3 15:51:19.487: INFO: (16) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/tlsrewritem... (200; 8.129489ms)
Dec  3 15:51:19.487: INFO: (16) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:460/proxy/: tls baz (200; 8.097881ms)
Dec  3 15:51:19.487: INFO: (16) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">test<... (200; 8.110481ms)
Dec  3 15:51:19.487: INFO: (16) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 8.743694ms)
Dec  3 15:51:19.489: INFO: (16) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 9.970612ms)
Dec  3 15:51:19.489: INFO: (16) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/rewriteme">test</a> (200; 9.971309ms)
Dec  3 15:51:19.489: INFO: (16) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 10.34377ms)
Dec  3 15:51:19.489: INFO: (16) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">... (200; 10.167649ms)
Dec  3 15:51:19.489: INFO: (16) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname2/proxy/: tls qux (200; 10.436811ms)
Dec  3 15:51:19.489: INFO: (16) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname1/proxy/: tls baz (200; 10.225169ms)
Dec  3 15:51:19.491: INFO: (16) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname1/proxy/: foo (200; 12.171057ms)
Dec  3 15:51:19.493: INFO: (16) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname1/proxy/: foo (200; 13.995514ms)
Dec  3 15:51:19.493: INFO: (16) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname2/proxy/: bar (200; 13.962187ms)
Dec  3 15:51:19.495: INFO: (16) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname2/proxy/: bar (200; 16.151335ms)
Dec  3 15:51:19.504: INFO: (17) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">test<... (200; 8.485823ms)
Dec  3 15:51:19.504: INFO: (17) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:462/proxy/: tls qux (200; 8.124968ms)
Dec  3 15:51:19.504: INFO: (17) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:460/proxy/: tls baz (200; 8.307235ms)
Dec  3 15:51:19.504: INFO: (17) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/tlsrewritem... (200; 8.104555ms)
Dec  3 15:51:19.504: INFO: (17) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 8.208823ms)
Dec  3 15:51:19.504: INFO: (17) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 8.149668ms)
Dec  3 15:51:19.504: INFO: (17) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">... (200; 8.049748ms)
Dec  3 15:51:19.506: INFO: (17) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 10.068239ms)
Dec  3 15:51:19.506: INFO: (17) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname2/proxy/: bar (200; 10.166368ms)
Dec  3 15:51:19.508: INFO: (17) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname1/proxy/: tls baz (200; 12.214627ms)
Dec  3 15:51:19.508: INFO: (17) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname2/proxy/: tls qux (200; 12.209225ms)
Dec  3 15:51:19.508: INFO: (17) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/rewriteme">test</a> (200; 12.448697ms)
Dec  3 15:51:19.510: INFO: (17) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname1/proxy/: foo (200; 14.28572ms)
Dec  3 15:51:19.510: INFO: (17) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 14.278832ms)
Dec  3 15:51:19.512: INFO: (17) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname2/proxy/: bar (200; 16.501544ms)
Dec  3 15:51:19.512: INFO: (17) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname1/proxy/: foo (200; 16.476306ms)
Dec  3 15:51:19.521: INFO: (18) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/rewriteme">test</a> (200; 7.863402ms)
Dec  3 15:51:19.521: INFO: (18) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:460/proxy/: tls baz (200; 8.054143ms)
Dec  3 15:51:19.521: INFO: (18) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 8.039351ms)
Dec  3 15:51:19.521: INFO: (18) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/tlsrewritem... (200; 7.933513ms)
Dec  3 15:51:19.521: INFO: (18) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname1/proxy/: tls baz (200; 8.064856ms)
Dec  3 15:51:19.521: INFO: (18) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">... (200; 8.057309ms)
Dec  3 15:51:19.521: INFO: (18) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">test<... (200; 8.412546ms)
Dec  3 15:51:19.521: INFO: (18) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 8.427306ms)
Dec  3 15:51:19.521: INFO: (18) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:462/proxy/: tls qux (200; 8.547665ms)
Dec  3 15:51:19.521: INFO: (18) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 8.549254ms)
Dec  3 15:51:19.523: INFO: (18) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 10.565616ms)
Dec  3 15:51:19.523: INFO: (18) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname2/proxy/: tls qux (200; 10.638523ms)
Dec  3 15:51:19.525: INFO: (18) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname2/proxy/: bar (200; 12.632437ms)
Dec  3 15:51:19.525: INFO: (18) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname2/proxy/: bar (200; 12.678036ms)
Dec  3 15:51:19.527: INFO: (18) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname1/proxy/: foo (200; 14.719457ms)
Dec  3 15:51:19.530: INFO: (18) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname1/proxy/: foo (200; 16.915454ms)
Dec  3 15:51:19.538: INFO: (19) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 8.32091ms)
Dec  3 15:51:19.538: INFO: (19) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">... (200; 8.235327ms)
Dec  3 15:51:19.538: INFO: (19) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:160/proxy/: foo (200; 8.214845ms)
Dec  3 15:51:19.538: INFO: (19) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:1080/proxy/rewriteme">test<... (200; 8.190434ms)
Dec  3 15:51:19.538: INFO: (19) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:462/proxy/: tls qux (200; 8.298442ms)
Dec  3 15:51:19.538: INFO: (19) /api/v1/namespaces/proxy-7369/pods/http:proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 8.458577ms)
Dec  3 15:51:19.541: INFO: (19) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname2/proxy/: bar (200; 10.678539ms)
Dec  3 15:51:19.541: INFO: (19) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:443/proxy/tlsrewritem... (200; 10.694365ms)
Dec  3 15:51:19.541: INFO: (19) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname1/proxy/: tls baz (200; 10.878474ms)
Dec  3 15:51:19.541: INFO: (19) /api/v1/namespaces/proxy-7369/services/https:proxy-service-svb5x:tlsportname2/proxy/: tls qux (200; 10.795355ms)
Dec  3 15:51:19.541: INFO: (19) /api/v1/namespaces/proxy-7369/pods/https:proxy-service-svb5x-zdz4j:460/proxy/: tls baz (200; 10.793347ms)
Dec  3 15:51:19.543: INFO: (19) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/: <a href="/api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j/proxy/rewriteme">test</a> (200; 12.761171ms)
Dec  3 15:51:19.543: INFO: (19) /api/v1/namespaces/proxy-7369/services/http:proxy-service-svb5x:portname1/proxy/: foo (200; 12.722297ms)
Dec  3 15:51:19.543: INFO: (19) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname1/proxy/: foo (200; 12.949734ms)
Dec  3 15:51:19.545: INFO: (19) /api/v1/namespaces/proxy-7369/services/proxy-service-svb5x:portname2/proxy/: bar (200; 14.834886ms)
Dec  3 15:51:19.547: INFO: (19) /api/v1/namespaces/proxy-7369/pods/proxy-service-svb5x-zdz4j:162/proxy/: bar (200; 17.397526ms)
STEP: deleting ReplicationController proxy-service-svb5x in namespace proxy-7369, will wait for the garbage collector to delete the pods
Dec  3 15:51:19.609: INFO: Deleting ReplicationController proxy-service-svb5x took: 7.005687ms
Dec  3 15:51:19.709: INFO: Terminating ReplicationController proxy-service-svb5x pods took: 100.291554ms
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:51:27.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-7369" for this suite.
Dec  3 15:51:33.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:51:34.073: INFO: namespace proxy-7369 deletion completed in 6.155958304s
•S
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:51:34.073: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3073
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  3 15:51:34.589: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-3073'
Dec  3 15:51:35.192: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 15:51:35.192: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: rolling-update to same image controller
Dec  3 15:51:35.203: INFO: scanned /root for discovery docs: <nil>
Dec  3 15:51:35.203: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-3073'
Dec  3 15:51:45.982: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  3 15:51:45.982: INFO: stdout: "Created e2e-test-httpd-rc-be346e1dfa1061687b680b5475092bb7\nScaling up e2e-test-httpd-rc-be346e1dfa1061687b680b5475092bb7 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-be346e1dfa1061687b680b5475092bb7 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-be346e1dfa1061687b680b5475092bb7 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Dec  3 15:51:45.982: INFO: stdout: "Created e2e-test-httpd-rc-be346e1dfa1061687b680b5475092bb7\nScaling up e2e-test-httpd-rc-be346e1dfa1061687b680b5475092bb7 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-be346e1dfa1061687b680b5475092bb7 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-be346e1dfa1061687b680b5475092bb7 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Dec  3 15:51:45.982: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-3073'
Dec  3 15:51:46.076: INFO: stderr: ""
Dec  3 15:51:46.077: INFO: stdout: "e2e-test-httpd-rc-be346e1dfa1061687b680b5475092bb7-24r2m "
Dec  3 15:51:46.077: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods e2e-test-httpd-rc-be346e1dfa1061687b680b5475092bb7-24r2m -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3073'
Dec  3 15:51:46.200: INFO: stderr: ""
Dec  3 15:51:46.200: INFO: stdout: "true"
Dec  3 15:51:46.200: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods e2e-test-httpd-rc-be346e1dfa1061687b680b5475092bb7-24r2m -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3073'
Dec  3 15:51:46.316: INFO: stderr: ""
Dec  3 15:51:46.316: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Dec  3 15:51:46.316: INFO: e2e-test-httpd-rc-be346e1dfa1061687b680b5475092bb7-24r2m is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Dec  3 15:51:46.316: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete rc e2e-test-httpd-rc --namespace=kubectl-3073'
Dec  3 15:51:46.476: INFO: stderr: ""
Dec  3 15:51:46.476: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:51:46.476: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3073" for this suite.
Dec  3 15:51:52.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:51:52.680: INFO: namespace kubectl-3073 deletion completed in 6.1975449s
•SSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:51:52.681: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3943
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec  3 15:51:55.882: INFO: Successfully updated pod "annotationupdate0c58a19c-c46e-4820-a672-69290755a08b"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:51:59.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3943" for this suite.
Dec  3 15:52:11.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:52:12.085: INFO: namespace projected-3943 deletion completed in 12.154511145s
•SSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:52:12.085: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-779
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Dec  3 15:52:12.488: INFO: Waiting up to 1m0s for all nodes to be ready
Dec  3 15:53:12.525: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:53:12.529: INFO: Starting informer...
STEP: Starting pod...
Dec  3 15:53:12.542: INFO: Pod is running on izgw8fisrtg04goc4t8tqaz. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Dec  3 15:53:12.563: INFO: Pod wasn't evicted. Proceeding
Dec  3 15:53:12.563: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Dec  3 15:54:27.578: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:54:27.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-779" for this suite.
Dec  3 15:54:39.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:54:39.741: INFO: namespace taint-single-pod-779 deletion completed in 12.154509483s
•
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:54:39.741: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-3667
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-3667, will wait for the garbage collector to delete the pods
Dec  3 15:54:42.068: INFO: Deleting Job.batch foo took: 6.671356ms
Dec  3 15:54:42.568: INFO: Terminating Job.batch foo pods took: 500.298915ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:55:17.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3667" for this suite.
Dec  3 15:55:25.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:55:26.133: INFO: namespace job-3667 deletion completed in 8.152643213s
•SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:55:26.133: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6938
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Dec  3 15:55:56.629: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1203 15:55:56.629333    5091 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:55:56.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6938" for this suite.
Dec  3 15:56:04.648: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:56:04.792: INFO: namespace gc-6938 deletion completed in 8.157279732s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:56:04.792: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4190
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-c34d5f25-857a-486a-a476-e5e68fa0feef
STEP: Creating secret with name secret-projected-all-test-volume-c394b677-9ca1-4e9c-a9f0-3198b93bca94
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec  3 15:56:05.306: INFO: Waiting up to 5m0s for pod "projected-volume-7ec6d8a2-ab30-4f04-88d3-8f2ddb26078d" in namespace "projected-4190" to be "success or failure"
Dec  3 15:56:05.310: INFO: Pod "projected-volume-7ec6d8a2-ab30-4f04-88d3-8f2ddb26078d": Phase="Pending", Reason="", readiness=false. Elapsed: 4.239206ms
Dec  3 15:56:07.316: INFO: Pod "projected-volume-7ec6d8a2-ab30-4f04-88d3-8f2ddb26078d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009644521s
STEP: Saw pod success
Dec  3 15:56:07.316: INFO: Pod "projected-volume-7ec6d8a2-ab30-4f04-88d3-8f2ddb26078d" satisfied condition "success or failure"
Dec  3 15:56:07.320: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod projected-volume-7ec6d8a2-ab30-4f04-88d3-8f2ddb26078d container projected-all-volume-test: <nil>
STEP: delete the pod
Dec  3 15:56:07.478: INFO: Waiting for pod projected-volume-7ec6d8a2-ab30-4f04-88d3-8f2ddb26078d to disappear
Dec  3 15:56:07.482: INFO: Pod projected-volume-7ec6d8a2-ab30-4f04-88d3-8f2ddb26078d no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:56:07.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4190" for this suite.
Dec  3 15:56:13.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:56:13.654: INFO: namespace projected-4190 deletion completed in 6.165152951s
•
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:56:13.654: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8251
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Dec  3 15:56:24.120: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1203 15:56:24.120631    5091 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:56:24.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8251" for this suite.
Dec  3 15:56:30.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:56:30.318: INFO: namespace gc-8251 deletion completed in 6.193059348s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:56:30.319: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1239
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec  3 15:56:30.596: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 15:56:30.611: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 15:56:30.615: INFO: 
Logging pods the kubelet thinks is on node izgw88vcbd5x6ev7zbjg8vz before test
Dec  3 15:56:30.647: INFO: kube-proxy-frcrz from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 15:56:30.647: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:56:30.647: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-95f65778d-6v4hg from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:56:30.647: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec  3 15:56:30.647: INFO: calico-typha-horizontal-autoscaler-69df649c59-wrrxb from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:56:30.647: INFO: 	Container autoscaler ready: true, restart count 0
Dec  3 15:56:30.647: INFO: addons-kubernetes-dashboard-78954cc66b-mh5g8 from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:56:30.647: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  3 15:56:30.647: INFO: calico-node-rx7sf from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 15:56:30.647: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:56:30.647: INFO: node-exporter-xwww8 from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 15:56:30.647: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:56:30.647: INFO: coredns-59c969ffb8-xnfvv from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:56:30.647: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:56:30.647: INFO: metrics-server-69dcc87559-8j9rx from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:56:30.647: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 15:56:30.647: INFO: blackbox-exporter-7bd7b55dfc-jjbg2 from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 15:56:30.647: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec  3 15:56:30.647: INFO: node-problem-detector-jj8gj from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 15:56:30.647: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:56:30.647: INFO: calico-typha-deploy-9f6b455c4-zqh59 from kube-system started at 2019-12-03 15:47:45 +0000 UTC (1 container statuses recorded)
Dec  3 15:56:30.647: INFO: 	Container calico-typha ready: true, restart count 0
Dec  3 15:56:30.647: INFO: calico-typha-vertical-autoscaler-847d859f8c-6xhsp from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:56:30.647: INFO: 	Container autoscaler ready: true, restart count 2
Dec  3 15:56:30.647: INFO: coredns-59c969ffb8-9mq2d from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:56:30.647: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:56:30.647: INFO: csi-disk-plugin-alicloud-55sss from kube-system started at 2019-12-03 14:26:56 +0000 UTC (2 container statuses recorded)
Dec  3 15:56:30.647: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec  3 15:56:30.647: INFO: 	Container driver-registrar ready: true, restart count 0
Dec  3 15:56:30.647: INFO: calico-kube-controllers-79bcd784b6-vbln2 from kube-system started at 2019-12-03 15:47:45 +0000 UTC (1 container statuses recorded)
Dec  3 15:56:30.647: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  3 15:56:30.647: INFO: vpn-shoot-76845cddf7-dh4gs from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:56:30.647: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec  3 15:56:30.647: INFO: addons-nginx-ingress-controller-7c75bb76db-8qn7n from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:56:30.647: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec  3 15:56:30.647: INFO: 
Logging pods the kubelet thinks is on node izgw8fisrtg04goc4t8tqaz before test
Dec  3 15:56:30.670: INFO: kube-proxy-dgc7z from kube-system started at 2019-12-03 14:26:18 +0000 UTC (1 container statuses recorded)
Dec  3 15:56:30.670: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:56:30.670: INFO: csi-disk-plugin-alicloud-sdzcv from kube-system started at 2019-12-03 15:53:14 +0000 UTC (2 container statuses recorded)
Dec  3 15:56:30.670: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec  3 15:56:30.670: INFO: 	Container driver-registrar ready: true, restart count 0
Dec  3 15:56:30.670: INFO: node-problem-detector-g8scm from kube-system started at 2019-12-03 14:26:18 +0000 UTC (1 container statuses recorded)
Dec  3 15:56:30.670: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:56:30.670: INFO: calico-node-8d72b from kube-system started at 2019-12-03 14:26:18 +0000 UTC (1 container statuses recorded)
Dec  3 15:56:30.670: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:56:30.670: INFO: node-exporter-2jhhv from kube-system started at 2019-12-03 14:26:18 +0000 UTC (1 container statuses recorded)
Dec  3 15:56:30.670: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15dce7939390126e], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:56:31.700: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1239" for this suite.
Dec  3 15:56:37.722: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:56:37.901: INFO: namespace sched-pred-1239 deletion completed in 6.193894428s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
•SSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:56:37.902: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-9082
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  3 15:56:42.338: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:56:42.342: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:56:44.342: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:56:44.348: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:56:46.342: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:56:46.348: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:56:48.342: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:56:48.347: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:56:48.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9082" for this suite.
Dec  3 15:57:00.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:57:00.576: INFO: namespace container-lifecycle-hook-9082 deletion completed in 12.207185721s
•SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:57:00.576: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7912
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:57:01.002: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec  3 15:57:04.294: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7912 create -f -'
Dec  3 15:57:04.723: INFO: stderr: ""
Dec  3 15:57:04.723: INFO: stdout: "e2e-test-crd-publish-openapi-3294-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec  3 15:57:04.723: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7912 delete e2e-test-crd-publish-openapi-3294-crds test-cr'
Dec  3 15:57:04.935: INFO: stderr: ""
Dec  3 15:57:04.935: INFO: stdout: "e2e-test-crd-publish-openapi-3294-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Dec  3 15:57:04.935: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7912 apply -f -'
Dec  3 15:57:05.237: INFO: stderr: ""
Dec  3 15:57:05.237: INFO: stdout: "e2e-test-crd-publish-openapi-3294-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec  3 15:57:05.237: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7912 delete e2e-test-crd-publish-openapi-3294-crds test-cr'
Dec  3 15:57:05.347: INFO: stderr: ""
Dec  3 15:57:05.347: INFO: stdout: "e2e-test-crd-publish-openapi-3294-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Dec  3 15:57:05.347: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-3294-crds'
Dec  3 15:57:05.596: INFO: stderr: ""
Dec  3 15:57:05.596: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3294-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:57:09.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7912" for this suite.
Dec  3 15:57:15.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:57:15.458: INFO: namespace crd-publish-openapi-7912 deletion completed in 6.159703589s
•SSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:57:15.458: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-8529
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-8529
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 15:57:16.299: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 15:57:36.383: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.0.58 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8529 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:57:36.383: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:57:37.861: INFO: Found all expected endpoints: [netserver-0]
Dec  3 15:57:37.866: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.1.209 8081 | grep -v '^\s*$'] Namespace:pod-network-test-8529 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:57:37.866: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:57:39.263: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:57:39.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-8529" for this suite.
Dec  3 15:57:51.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:57:51.444: INFO: namespace pod-network-test-8529 deletion completed in 12.172714457s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:57:51.445: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-97
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-dbe5be6b-7be9-4f1a-8c63-64799911aab4
STEP: Creating secret with name s-test-opt-upd-a6982ee1-b14a-4d6c-ae85-d92cee9271e0
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-dbe5be6b-7be9-4f1a-8c63-64799911aab4
STEP: Updating secret s-test-opt-upd-a6982ee1-b14a-4d6c-ae85-d92cee9271e0
STEP: Creating secret with name s-test-opt-create-8d3b6723-7087-49de-940a-4651d4fd2436
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:57:56.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-97" for this suite.
Dec  3 15:58:08.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:58:08.448: INFO: namespace projected-97 deletion completed in 12.153531976s
•SSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:58:08.448: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9965
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec  3 15:58:08.789: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 15:58:08.805: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 15:58:08.809: INFO: 
Logging pods the kubelet thinks is on node izgw88vcbd5x6ev7zbjg8vz before test
Dec  3 15:58:08.837: INFO: node-problem-detector-jj8gj from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 15:58:08.837: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:58:08.837: INFO: coredns-59c969ffb8-xnfvv from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:58:08.837: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:58:08.837: INFO: metrics-server-69dcc87559-8j9rx from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:58:08.837: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 15:58:08.837: INFO: blackbox-exporter-7bd7b55dfc-jjbg2 from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 15:58:08.837: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec  3 15:58:08.837: INFO: coredns-59c969ffb8-9mq2d from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:58:08.837: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:58:08.837: INFO: calico-typha-deploy-9f6b455c4-zqh59 from kube-system started at 2019-12-03 15:47:45 +0000 UTC (1 container statuses recorded)
Dec  3 15:58:08.837: INFO: 	Container calico-typha ready: true, restart count 0
Dec  3 15:58:08.837: INFO: calico-typha-vertical-autoscaler-847d859f8c-6xhsp from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:58:08.837: INFO: 	Container autoscaler ready: true, restart count 2
Dec  3 15:58:08.837: INFO: addons-nginx-ingress-controller-7c75bb76db-8qn7n from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:58:08.837: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec  3 15:58:08.837: INFO: csi-disk-plugin-alicloud-55sss from kube-system started at 2019-12-03 14:26:56 +0000 UTC (2 container statuses recorded)
Dec  3 15:58:08.837: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec  3 15:58:08.837: INFO: 	Container driver-registrar ready: true, restart count 0
Dec  3 15:58:08.837: INFO: calico-kube-controllers-79bcd784b6-vbln2 from kube-system started at 2019-12-03 15:47:45 +0000 UTC (1 container statuses recorded)
Dec  3 15:58:08.837: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  3 15:58:08.837: INFO: vpn-shoot-76845cddf7-dh4gs from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:58:08.837: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec  3 15:58:08.837: INFO: node-exporter-xwww8 from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 15:58:08.837: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:58:08.837: INFO: kube-proxy-frcrz from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 15:58:08.837: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:58:08.837: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-95f65778d-6v4hg from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:58:08.837: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec  3 15:58:08.837: INFO: calico-typha-horizontal-autoscaler-69df649c59-wrrxb from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:58:08.837: INFO: 	Container autoscaler ready: true, restart count 0
Dec  3 15:58:08.837: INFO: addons-kubernetes-dashboard-78954cc66b-mh5g8 from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 15:58:08.837: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  3 15:58:08.837: INFO: calico-node-rx7sf from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 15:58:08.837: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:58:08.837: INFO: 
Logging pods the kubelet thinks is on node izgw8fisrtg04goc4t8tqaz before test
Dec  3 15:58:08.890: INFO: node-problem-detector-g8scm from kube-system started at 2019-12-03 14:26:18 +0000 UTC (1 container statuses recorded)
Dec  3 15:58:08.890: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:58:08.890: INFO: calico-node-8d72b from kube-system started at 2019-12-03 14:26:18 +0000 UTC (1 container statuses recorded)
Dec  3 15:58:08.890: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:58:08.890: INFO: node-exporter-2jhhv from kube-system started at 2019-12-03 14:26:18 +0000 UTC (1 container statuses recorded)
Dec  3 15:58:08.891: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:58:08.891: INFO: kube-proxy-dgc7z from kube-system started at 2019-12-03 14:26:18 +0000 UTC (1 container statuses recorded)
Dec  3 15:58:08.891: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:58:08.891: INFO: csi-disk-plugin-alicloud-sdzcv from kube-system started at 2019-12-03 15:53:14 +0000 UTC (2 container statuses recorded)
Dec  3 15:58:08.891: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec  3 15:58:08.891: INFO: 	Container driver-registrar ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-b9b7e796-b3d0-42d0-b954-28e49aaf9031 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-b9b7e796-b3d0-42d0-b954-28e49aaf9031 off the node izgw8fisrtg04goc4t8tqaz
STEP: verifying the node doesn't have the label kubernetes.io/e2e-b9b7e796-b3d0-42d0-b954-28e49aaf9031
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:58:14.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9965" for this suite.
Dec  3 15:58:22.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:58:23.118: INFO: namespace sched-pred-9965 deletion completed in 8.151611682s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
•
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:58:23.118: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5076
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:58:23.855: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:58:26.879: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:58:27.133: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5076" for this suite.
Dec  3 15:58:35.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:58:35.293: INFO: namespace webhook-5076 deletion completed in 8.152647275s
STEP: Destroying namespace "webhook-5076-markers" for this suite.
Dec  3 15:58:41.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:58:41.451: INFO: namespace webhook-5076-markers deletion completed in 6.157922407s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:58:41.472: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9631
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-9631
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9631 to expose endpoints map[]
Dec  3 15:58:42.005: INFO: successfully validated that service multi-endpoint-test in namespace services-9631 exposes endpoints map[] (4.22824ms elapsed)
STEP: Creating pod pod1 in namespace services-9631
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9631 to expose endpoints map[pod1:[100]]
Dec  3 15:58:44.039: INFO: successfully validated that service multi-endpoint-test in namespace services-9631 exposes endpoints map[pod1:[100]] (2.026794355s elapsed)
STEP: Creating pod pod2 in namespace services-9631
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9631 to expose endpoints map[pod1:[100] pod2:[101]]
Dec  3 15:58:46.085: INFO: successfully validated that service multi-endpoint-test in namespace services-9631 exposes endpoints map[pod1:[100] pod2:[101]] (2.040084675s elapsed)
STEP: Deleting pod pod1 in namespace services-9631
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9631 to expose endpoints map[pod2:[101]]
Dec  3 15:58:46.099: INFO: successfully validated that service multi-endpoint-test in namespace services-9631 exposes endpoints map[pod2:[101]] (8.267805ms elapsed)
STEP: Deleting pod pod2 in namespace services-9631
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-9631 to expose endpoints map[]
Dec  3 15:58:46.108: INFO: successfully validated that service multi-endpoint-test in namespace services-9631 exposes endpoints map[] (3.748219ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:58:46.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9631" for this suite.
Dec  3 15:59:16.141: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:59:16.287: INFO: namespace services-9631 deletion completed in 30.159923603s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:59:16.288: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6350
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Dec  3 15:59:16.506: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:59:27.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6350" for this suite.
Dec  3 15:59:35.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:59:36.069: INFO: namespace pods-6350 deletion completed in 8.158172418s
•SSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:59:36.070: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2888
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-2fc5d825-662a-481a-aa33-c2deafd0ec06 in namespace container-probe-2888
Dec  3 15:59:38.414: INFO: Started pod liveness-2fc5d825-662a-481a-aa33-c2deafd0ec06 in namespace container-probe-2888
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 15:59:38.418: INFO: Initial restart count of pod liveness-2fc5d825-662a-481a-aa33-c2deafd0ec06 is 0
Dec  3 15:59:52.459: INFO: Restart count of pod container-probe-2888/liveness-2fc5d825-662a-481a-aa33-c2deafd0ec06 is now 1 (14.040492279s elapsed)
Dec  3 16:00:10.506: INFO: Restart count of pod container-probe-2888/liveness-2fc5d825-662a-481a-aa33-c2deafd0ec06 is now 2 (32.088268893s elapsed)
Dec  3 16:00:30.558: INFO: Restart count of pod container-probe-2888/liveness-2fc5d825-662a-481a-aa33-c2deafd0ec06 is now 3 (52.139954064s elapsed)
Dec  3 16:00:50.625: INFO: Restart count of pod container-probe-2888/liveness-2fc5d825-662a-481a-aa33-c2deafd0ec06 is now 4 (1m12.207104345s elapsed)
Dec  3 16:01:52.790: INFO: Restart count of pod container-probe-2888/liveness-2fc5d825-662a-481a-aa33-c2deafd0ec06 is now 5 (2m14.371477855s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:01:52.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2888" for this suite.
Dec  3 16:02:00.819: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:02:00.959: INFO: namespace container-probe-2888 deletion completed in 8.154381713s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:02:00.960: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2875
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  3 16:02:01.303: INFO: Waiting up to 5m0s for pod "pod-2d69a64d-77af-4bc4-b4fc-582988ec1af2" in namespace "emptydir-2875" to be "success or failure"
Dec  3 16:02:01.307: INFO: Pod "pod-2d69a64d-77af-4bc4-b4fc-582988ec1af2": Phase="Pending", Reason="", readiness=false. Elapsed: 4.092572ms
Dec  3 16:02:03.312: INFO: Pod "pod-2d69a64d-77af-4bc4-b4fc-582988ec1af2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009378051s
STEP: Saw pod success
Dec  3 16:02:03.312: INFO: Pod "pod-2d69a64d-77af-4bc4-b4fc-582988ec1af2" satisfied condition "success or failure"
Dec  3 16:02:03.317: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-2d69a64d-77af-4bc4-b4fc-582988ec1af2 container test-container: <nil>
STEP: delete the pod
Dec  3 16:02:03.477: INFO: Waiting for pod pod-2d69a64d-77af-4bc4-b4fc-582988ec1af2 to disappear
Dec  3 16:02:03.482: INFO: Pod pod-2d69a64d-77af-4bc4-b4fc-582988ec1af2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:02:03.482: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2875" for this suite.
Dec  3 16:02:11.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:02:11.639: INFO: namespace emptydir-2875 deletion completed in 8.150365416s
•SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:02:11.640: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8841
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:02:12.114: INFO: (0) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 10.587634ms)
Dec  3 16:02:12.159: INFO: (1) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 45.414433ms)
Dec  3 16:02:12.167: INFO: (2) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.526741ms)
Dec  3 16:02:12.174: INFO: (3) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.143052ms)
Dec  3 16:02:12.181: INFO: (4) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.371826ms)
Dec  3 16:02:12.189: INFO: (5) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.075772ms)
Dec  3 16:02:12.196: INFO: (6) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.257755ms)
Dec  3 16:02:12.204: INFO: (7) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.488491ms)
Dec  3 16:02:12.212: INFO: (8) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.45373ms)
Dec  3 16:02:12.219: INFO: (9) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.012701ms)
Dec  3 16:02:12.226: INFO: (10) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.058205ms)
Dec  3 16:02:12.234: INFO: (11) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.73176ms)
Dec  3 16:02:12.242: INFO: (12) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.787888ms)
Dec  3 16:02:12.249: INFO: (13) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.670306ms)
Dec  3 16:02:12.256: INFO: (14) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.742502ms)
Dec  3 16:02:12.262: INFO: (15) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.746844ms)
Dec  3 16:02:12.270: INFO: (16) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 7.067603ms)
Dec  3 16:02:12.277: INFO: (17) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.868506ms)
Dec  3 16:02:12.285: INFO: (18) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 8.043157ms)
Dec  3 16:02:12.292: INFO: (19) /api/v1/nodes/izgw88vcbd5x6ev7zbjg8vz:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="cloud-init.log">cloud-init.log</a>
<a href="containers/">c... (200; 6.839237ms)
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:02:12.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8841" for this suite.
Dec  3 16:02:18.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:02:18.448: INFO: namespace proxy-8841 deletion completed in 6.152198467s
•S
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:02:18.449: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1245
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec  3 16:02:21.243: INFO: Successfully updated pod "labelsupdate3f94eafc-1908-4f02-af48-3d77edbb0ed6"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:02:25.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1245" for this suite.
Dec  3 16:02:37.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:02:37.490: INFO: namespace downward-api-1245 deletion completed in 12.196773714s
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:02:37.491: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-345
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  3 16:02:39.822: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:02:39.833: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-345" for this suite.
Dec  3 16:02:47.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:02:47.993: INFO: namespace container-runtime-345 deletion completed in 8.152323268s
•SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:02:47.993: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2162
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 16:02:48.596: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c863ca8c-c919-499c-ac53-22b051b9a971" in namespace "projected-2162" to be "success or failure"
Dec  3 16:02:48.600: INFO: Pod "downwardapi-volume-c863ca8c-c919-499c-ac53-22b051b9a971": Phase="Pending", Reason="", readiness=false. Elapsed: 4.226756ms
Dec  3 16:02:50.606: INFO: Pod "downwardapi-volume-c863ca8c-c919-499c-ac53-22b051b9a971": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010064963s
Dec  3 16:02:52.612: INFO: Pod "downwardapi-volume-c863ca8c-c919-499c-ac53-22b051b9a971": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.015564784s
STEP: Saw pod success
Dec  3 16:02:52.612: INFO: Pod "downwardapi-volume-c863ca8c-c919-499c-ac53-22b051b9a971" satisfied condition "success or failure"
Dec  3 16:02:52.616: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downwardapi-volume-c863ca8c-c919-499c-ac53-22b051b9a971 container client-container: <nil>
STEP: delete the pod
Dec  3 16:02:52.638: INFO: Waiting for pod downwardapi-volume-c863ca8c-c919-499c-ac53-22b051b9a971 to disappear
Dec  3 16:02:52.642: INFO: Pod downwardapi-volume-c863ca8c-c919-499c-ac53-22b051b9a971 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:02:52.642: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2162" for this suite.
Dec  3 16:02:58.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:02:58.809: INFO: namespace projected-2162 deletion completed in 6.159649498s
•SSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:02:58.810: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9174
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:03:01.235: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9174" for this suite.
Dec  3 16:03:45.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:03:45.398: INFO: namespace kubelet-test-9174 deletion completed in 44.155134247s
•SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:03:45.398: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-8527
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: expected 0 rs, got 1 rs
STEP: Gathering metrics
Dec  3 16:03:47.242: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1203 16:03:47.242705    5091 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:03:47.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-8527" for this suite.
Dec  3 16:03:53.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:03:53.402: INFO: namespace gc-8527 deletion completed in 6.15522272s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:03:53.403: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9181
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-9181
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-9181
STEP: creating replication controller externalsvc in namespace services-9181
I1203 16:03:53.717663    5091 runners.go:184] Created replication controller with name: externalsvc, namespace: services-9181, replica count: 2
I1203 16:03:56.768192    5091 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Dec  3 16:03:56.787: INFO: Creating new exec pod
Dec  3 16:03:58.803: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-9181 execpodflxdk -- /bin/sh -x -c nslookup clusterip-service'
Dec  3 16:03:59.583: INFO: stderr: "+ nslookup clusterip-service\n"
Dec  3 16:03:59.583: INFO: stdout: "Server:\t\t100.104.0.10\nAddress:\t100.104.0.10#53\n\nclusterip-service.services-9181.svc.cluster.local\tcanonical name = externalsvc.services-9181.svc.cluster.local.\nName:\texternalsvc.services-9181.svc.cluster.local\nAddress: 100.105.193.235\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-9181, will wait for the garbage collector to delete the pods
Dec  3 16:03:59.646: INFO: Deleting ReplicationController externalsvc took: 7.85301ms
Dec  3 16:04:00.146: INFO: Terminating ReplicationController externalsvc pods took: 500.218052ms
Dec  3 16:04:07.959: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:04:07.967: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9181" for this suite.
Dec  3 16:04:13.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:04:14.134: INFO: namespace services-9181 deletion completed in 6.158858217s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:04:14.134: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-1510
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec  3 16:04:16.424: INFO: &Pod{ObjectMeta:{send-events-283ff2a8-7448-4d44-b4da-a5ebd0c7e045  events-1510 /api/v1/namespaces/events-1510/pods/send-events-283ff2a8-7448-4d44-b4da-a5ebd0c7e045 175e951e-186d-445d-88ab-2c9543d226bd 26476 0 2019-12-03 16:04:14 +0000 UTC <nil> <nil> map[name:foo time:397302091] map[cni.projectcalico.org/podIP:100.64.1.229/32 kubernetes.io/psp:e2e-test-privileged-psp] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-cv95g,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-cv95g,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-cv95g,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:04:14 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:04:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:04:16 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:04:14 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:100.64.1.229,StartTime:2019-12-03 16:04:14 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 16:04:15 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:docker://2424ac378e8c36c91c0a91df1d58ed4ac362fade8e7066c5a438354cd8a93682,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.229,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Dec  3 16:04:18.430: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec  3 16:04:20.437: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:04:20.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-1510" for this suite.
Dec  3 16:05:04.464: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:05:04.607: INFO: namespace events-1510 deletion completed in 44.15675737s
•SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:05:04.607: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6349
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 16:05:04.998: INFO: Waiting up to 5m0s for pod "downwardapi-volume-307d37da-5665-4f52-a03b-5e9c1685db60" in namespace "projected-6349" to be "success or failure"
Dec  3 16:05:05.002: INFO: Pod "downwardapi-volume-307d37da-5665-4f52-a03b-5e9c1685db60": Phase="Pending", Reason="", readiness=false. Elapsed: 4.315411ms
Dec  3 16:05:07.008: INFO: Pod "downwardapi-volume-307d37da-5665-4f52-a03b-5e9c1685db60": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009666891s
STEP: Saw pod success
Dec  3 16:05:07.008: INFO: Pod "downwardapi-volume-307d37da-5665-4f52-a03b-5e9c1685db60" satisfied condition "success or failure"
Dec  3 16:05:07.012: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downwardapi-volume-307d37da-5665-4f52-a03b-5e9c1685db60 container client-container: <nil>
STEP: delete the pod
Dec  3 16:05:07.170: INFO: Waiting for pod downwardapi-volume-307d37da-5665-4f52-a03b-5e9c1685db60 to disappear
Dec  3 16:05:07.174: INFO: Pod downwardapi-volume-307d37da-5665-4f52-a03b-5e9c1685db60 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:05:07.174: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6349" for this suite.
Dec  3 16:05:15.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:05:15.340: INFO: namespace projected-6349 deletion completed in 8.158516404s
•
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:05:15.341: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5428
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  3 16:05:15.896: INFO: Waiting up to 5m0s for pod "pod-255eb7d6-2054-4155-a4fd-0472b7f83bd7" in namespace "emptydir-5428" to be "success or failure"
Dec  3 16:05:15.901: INFO: Pod "pod-255eb7d6-2054-4155-a4fd-0472b7f83bd7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.154382ms
Dec  3 16:05:17.906: INFO: Pod "pod-255eb7d6-2054-4155-a4fd-0472b7f83bd7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009451531s
STEP: Saw pod success
Dec  3 16:05:17.906: INFO: Pod "pod-255eb7d6-2054-4155-a4fd-0472b7f83bd7" satisfied condition "success or failure"
Dec  3 16:05:17.910: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-255eb7d6-2054-4155-a4fd-0472b7f83bd7 container test-container: <nil>
STEP: delete the pod
Dec  3 16:05:17.930: INFO: Waiting for pod pod-255eb7d6-2054-4155-a4fd-0472b7f83bd7 to disappear
Dec  3 16:05:17.934: INFO: Pod pod-255eb7d6-2054-4155-a4fd-0472b7f83bd7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:05:17.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5428" for this suite.
Dec  3 16:05:23.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:05:24.137: INFO: namespace emptydir-5428 deletion completed in 6.195720652s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:05:24.137: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-429
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-429/secret-test-ad027264-a8b7-4dbb-b69d-9ad1c09570f4
STEP: Creating a pod to test consume secrets
Dec  3 16:05:24.409: INFO: Waiting up to 5m0s for pod "pod-configmaps-24e941f8-d9b1-4ce8-b08e-2790edb060f9" in namespace "secrets-429" to be "success or failure"
Dec  3 16:05:24.413: INFO: Pod "pod-configmaps-24e941f8-d9b1-4ce8-b08e-2790edb060f9": Phase="Pending", Reason="", readiness=false. Elapsed: 4.047137ms
Dec  3 16:05:26.419: INFO: Pod "pod-configmaps-24e941f8-d9b1-4ce8-b08e-2790edb060f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010344467s
STEP: Saw pod success
Dec  3 16:05:26.419: INFO: Pod "pod-configmaps-24e941f8-d9b1-4ce8-b08e-2790edb060f9" satisfied condition "success or failure"
Dec  3 16:05:26.424: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-configmaps-24e941f8-d9b1-4ce8-b08e-2790edb060f9 container env-test: <nil>
STEP: delete the pod
Dec  3 16:05:26.452: INFO: Waiting for pod pod-configmaps-24e941f8-d9b1-4ce8-b08e-2790edb060f9 to disappear
Dec  3 16:05:26.456: INFO: Pod pod-configmaps-24e941f8-d9b1-4ce8-b08e-2790edb060f9 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:05:26.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-429" for this suite.
Dec  3 16:05:32.478: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:05:32.618: INFO: namespace secrets-429 deletion completed in 6.153379328s
•SSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:05:32.618: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2353
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec  3 16:05:33.003: INFO: Waiting up to 5m0s for pod "downward-api-7f167619-ed37-4ad6-a76b-2e192241a489" in namespace "downward-api-2353" to be "success or failure"
Dec  3 16:05:33.008: INFO: Pod "downward-api-7f167619-ed37-4ad6-a76b-2e192241a489": Phase="Pending", Reason="", readiness=false. Elapsed: 4.570537ms
Dec  3 16:05:35.013: INFO: Pod "downward-api-7f167619-ed37-4ad6-a76b-2e192241a489": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010158129s
STEP: Saw pod success
Dec  3 16:05:35.013: INFO: Pod "downward-api-7f167619-ed37-4ad6-a76b-2e192241a489" satisfied condition "success or failure"
Dec  3 16:05:35.018: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downward-api-7f167619-ed37-4ad6-a76b-2e192241a489 container dapi-container: <nil>
STEP: delete the pod
Dec  3 16:05:35.038: INFO: Waiting for pod downward-api-7f167619-ed37-4ad6-a76b-2e192241a489 to disappear
Dec  3 16:05:35.042: INFO: Pod downward-api-7f167619-ed37-4ad6-a76b-2e192241a489 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:05:35.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2353" for this suite.
Dec  3 16:05:41.062: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:05:41.208: INFO: namespace downward-api-2353 deletion completed in 6.158857159s
•SSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:05:41.208: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-463
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:05:41.797: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-d61febf1-800d-43de-9360-74b04b007ba0" in namespace "security-context-test-463" to be "success or failure"
Dec  3 16:05:41.801: INFO: Pod "busybox-readonly-false-d61febf1-800d-43de-9360-74b04b007ba0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.252504ms
Dec  3 16:05:43.806: INFO: Pod "busybox-readonly-false-d61febf1-800d-43de-9360-74b04b007ba0": Phase="Running", Reason="", readiness=true. Elapsed: 2.009075174s
Dec  3 16:05:45.811: INFO: Pod "busybox-readonly-false-d61febf1-800d-43de-9360-74b04b007ba0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014173636s
Dec  3 16:05:45.811: INFO: Pod "busybox-readonly-false-d61febf1-800d-43de-9360-74b04b007ba0" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:05:45.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-463" for this suite.
Dec  3 16:05:51.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:05:52.017: INFO: namespace security-context-test-463 deletion completed in 6.197719777s
•S
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:05:52.017: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1116
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Dec  3 16:05:52.303: INFO: Waiting up to 5m0s for pod "client-containers-8ce3e9e3-7211-4176-8ac4-a8d19b2882ea" in namespace "containers-1116" to be "success or failure"
Dec  3 16:05:52.307: INFO: Pod "client-containers-8ce3e9e3-7211-4176-8ac4-a8d19b2882ea": Phase="Pending", Reason="", readiness=false. Elapsed: 4.252138ms
Dec  3 16:05:54.312: INFO: Pod "client-containers-8ce3e9e3-7211-4176-8ac4-a8d19b2882ea": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009458152s
STEP: Saw pod success
Dec  3 16:05:54.312: INFO: Pod "client-containers-8ce3e9e3-7211-4176-8ac4-a8d19b2882ea" satisfied condition "success or failure"
Dec  3 16:05:54.316: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod client-containers-8ce3e9e3-7211-4176-8ac4-a8d19b2882ea container test-container: <nil>
STEP: delete the pod
Dec  3 16:05:54.338: INFO: Waiting for pod client-containers-8ce3e9e3-7211-4176-8ac4-a8d19b2882ea to disappear
Dec  3 16:05:54.341: INFO: Pod client-containers-8ce3e9e3-7211-4176-8ac4-a8d19b2882ea no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:05:54.341: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1116" for this suite.
Dec  3 16:06:00.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:06:00.511: INFO: namespace containers-1116 deletion completed in 6.162353269s
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:06:00.511: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1746
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 16:06:01.318: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 16:06:04.348: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:06:04.617: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1746" for this suite.
Dec  3 16:06:12.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:06:12.820: INFO: namespace webhook-1746 deletion completed in 8.195290534s
STEP: Destroying namespace "webhook-1746-markers" for this suite.
Dec  3 16:06:18.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:06:18.973: INFO: namespace webhook-1746-markers deletion completed in 6.153477441s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:06:18.992: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6202
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  3 16:06:19.304: INFO: Waiting up to 5m0s for pod "pod-3bb0f738-fb95-4139-bce7-c03c4049d9ae" in namespace "emptydir-6202" to be "success or failure"
Dec  3 16:06:19.308: INFO: Pod "pod-3bb0f738-fb95-4139-bce7-c03c4049d9ae": Phase="Pending", Reason="", readiness=false. Elapsed: 3.976289ms
Dec  3 16:06:21.313: INFO: Pod "pod-3bb0f738-fb95-4139-bce7-c03c4049d9ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009136184s
STEP: Saw pod success
Dec  3 16:06:21.314: INFO: Pod "pod-3bb0f738-fb95-4139-bce7-c03c4049d9ae" satisfied condition "success or failure"
Dec  3 16:06:21.318: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-3bb0f738-fb95-4139-bce7-c03c4049d9ae container test-container: <nil>
STEP: delete the pod
Dec  3 16:06:21.340: INFO: Waiting for pod pod-3bb0f738-fb95-4139-bce7-c03c4049d9ae to disappear
Dec  3 16:06:21.344: INFO: Pod pod-3bb0f738-fb95-4139-bce7-c03c4049d9ae no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:06:21.344: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6202" for this suite.
Dec  3 16:06:27.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:06:27.509: INFO: namespace emptydir-6202 deletion completed in 6.158084321s
•SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:06:27.509: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-672
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:06:39.032: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-672" for this suite.
Dec  3 16:06:47.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:06:47.244: INFO: namespace resourcequota-672 deletion completed in 8.204196521s
•SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:06:47.244: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5569
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-aa547b58-c81b-44a8-aaa6-a76bb8e5ca07
STEP: Creating a pod to test consume secrets
Dec  3 16:06:47.802: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-bb65d86a-7c88-4a73-aa91-a12ea609abc6" in namespace "projected-5569" to be "success or failure"
Dec  3 16:06:47.806: INFO: Pod "pod-projected-secrets-bb65d86a-7c88-4a73-aa91-a12ea609abc6": Phase="Pending", Reason="", readiness=false. Elapsed: 4.137128ms
Dec  3 16:06:49.812: INFO: Pod "pod-projected-secrets-bb65d86a-7c88-4a73-aa91-a12ea609abc6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009348399s
STEP: Saw pod success
Dec  3 16:06:49.812: INFO: Pod "pod-projected-secrets-bb65d86a-7c88-4a73-aa91-a12ea609abc6" satisfied condition "success or failure"
Dec  3 16:06:49.818: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-projected-secrets-bb65d86a-7c88-4a73-aa91-a12ea609abc6 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:06:49.840: INFO: Waiting for pod pod-projected-secrets-bb65d86a-7c88-4a73-aa91-a12ea609abc6 to disappear
Dec  3 16:06:49.844: INFO: Pod pod-projected-secrets-bb65d86a-7c88-4a73-aa91-a12ea609abc6 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:06:49.844: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5569" for this suite.
Dec  3 16:06:55.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:06:56.006: INFO: namespace projected-5569 deletion completed in 6.154542425s
•SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:06:56.006: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8847
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-473dedae-b5e1-4463-a6a7-8b7e6dda8d90
STEP: Creating a pod to test consume configMaps
Dec  3 16:06:56.310: INFO: Waiting up to 5m0s for pod "pod-configmaps-d785bb2d-8fb5-4bed-bef1-7d68098a6a57" in namespace "configmap-8847" to be "success or failure"
Dec  3 16:06:56.314: INFO: Pod "pod-configmaps-d785bb2d-8fb5-4bed-bef1-7d68098a6a57": Phase="Pending", Reason="", readiness=false. Elapsed: 4.152181ms
Dec  3 16:06:58.320: INFO: Pod "pod-configmaps-d785bb2d-8fb5-4bed-bef1-7d68098a6a57": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009668886s
STEP: Saw pod success
Dec  3 16:06:58.320: INFO: Pod "pod-configmaps-d785bb2d-8fb5-4bed-bef1-7d68098a6a57" satisfied condition "success or failure"
Dec  3 16:06:58.325: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-configmaps-d785bb2d-8fb5-4bed-bef1-7d68098a6a57 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 16:06:58.346: INFO: Waiting for pod pod-configmaps-d785bb2d-8fb5-4bed-bef1-7d68098a6a57 to disappear
Dec  3 16:06:58.350: INFO: Pod pod-configmaps-d785bb2d-8fb5-4bed-bef1-7d68098a6a57 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:06:58.350: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8847" for this suite.
Dec  3 16:07:04.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:07:04.564: INFO: namespace configmap-8847 deletion completed in 6.206847934s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:07:04.565: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6465
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-bf0332f1-2cce-48aa-bc91-5b2625ff6809
STEP: Creating a pod to test consume configMaps
Dec  3 16:07:04.909: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ddc77b1d-d51d-4028-b73b-f7eb5356c148" in namespace "projected-6465" to be "success or failure"
Dec  3 16:07:04.914: INFO: Pod "pod-projected-configmaps-ddc77b1d-d51d-4028-b73b-f7eb5356c148": Phase="Pending", Reason="", readiness=false. Elapsed: 4.131479ms
Dec  3 16:07:06.919: INFO: Pod "pod-projected-configmaps-ddc77b1d-d51d-4028-b73b-f7eb5356c148": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009370808s
STEP: Saw pod success
Dec  3 16:07:06.919: INFO: Pod "pod-projected-configmaps-ddc77b1d-d51d-4028-b73b-f7eb5356c148" satisfied condition "success or failure"
Dec  3 16:07:06.923: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-projected-configmaps-ddc77b1d-d51d-4028-b73b-f7eb5356c148 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 16:07:06.944: INFO: Waiting for pod pod-projected-configmaps-ddc77b1d-d51d-4028-b73b-f7eb5356c148 to disappear
Dec  3 16:07:06.948: INFO: Pod pod-projected-configmaps-ddc77b1d-d51d-4028-b73b-f7eb5356c148 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:07:06.948: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6465" for this suite.
Dec  3 16:07:12.968: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:07:13.107: INFO: namespace projected-6465 deletion completed in 6.151957768s
•SS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:07:13.107: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2820
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 16:07:13.406: INFO: Waiting up to 5m0s for pod "downwardapi-volume-abe17896-bc03-4d50-b0b0-1739c9d1ab75" in namespace "projected-2820" to be "success or failure"
Dec  3 16:07:13.410: INFO: Pod "downwardapi-volume-abe17896-bc03-4d50-b0b0-1739c9d1ab75": Phase="Pending", Reason="", readiness=false. Elapsed: 4.374088ms
Dec  3 16:07:15.416: INFO: Pod "downwardapi-volume-abe17896-bc03-4d50-b0b0-1739c9d1ab75": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.010072703s
STEP: Saw pod success
Dec  3 16:07:15.416: INFO: Pod "downwardapi-volume-abe17896-bc03-4d50-b0b0-1739c9d1ab75" satisfied condition "success or failure"
Dec  3 16:07:15.420: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downwardapi-volume-abe17896-bc03-4d50-b0b0-1739c9d1ab75 container client-container: <nil>
STEP: delete the pod
Dec  3 16:07:15.441: INFO: Waiting for pod downwardapi-volume-abe17896-bc03-4d50-b0b0-1739c9d1ab75 to disappear
Dec  3 16:07:15.445: INFO: Pod downwardapi-volume-abe17896-bc03-4d50-b0b0-1739c9d1ab75 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:07:15.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2820" for this suite.
Dec  3 16:07:21.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:07:21.607: INFO: namespace projected-2820 deletion completed in 6.154002688s
•SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:07:21.607: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7653
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-47b4662c-78dc-45e5-857f-02ad0113d7b5
STEP: Creating a pod to test consume configMaps
Dec  3 16:07:22.403: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-2782b367-0f01-43e8-ab24-ba5b1a1fc84a" in namespace "projected-7653" to be "success or failure"
Dec  3 16:07:22.407: INFO: Pod "pod-projected-configmaps-2782b367-0f01-43e8-ab24-ba5b1a1fc84a": Phase="Pending", Reason="", readiness=false. Elapsed: 3.804507ms
Dec  3 16:07:24.412: INFO: Pod "pod-projected-configmaps-2782b367-0f01-43e8-ab24-ba5b1a1fc84a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009218228s
STEP: Saw pod success
Dec  3 16:07:24.412: INFO: Pod "pod-projected-configmaps-2782b367-0f01-43e8-ab24-ba5b1a1fc84a" satisfied condition "success or failure"
Dec  3 16:07:24.417: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-projected-configmaps-2782b367-0f01-43e8-ab24-ba5b1a1fc84a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 16:07:24.440: INFO: Waiting for pod pod-projected-configmaps-2782b367-0f01-43e8-ab24-ba5b1a1fc84a to disappear
Dec  3 16:07:24.444: INFO: Pod pod-projected-configmaps-2782b367-0f01-43e8-ab24-ba5b1a1fc84a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:07:24.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7653" for this suite.
Dec  3 16:07:30.466: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:07:30.609: INFO: namespace projected-7653 deletion completed in 6.157858212s
•SSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:07:30.609: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9918
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-9918
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-9918
I1203 16:07:30.915694    5091 runners.go:184] Created replication controller with name: externalname-service, namespace: services-9918, replica count: 2
I1203 16:07:33.966363    5091 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 16:07:33.966: INFO: Creating new exec pod
Dec  3 16:07:36.984: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-9918 execpodj6crc -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec  3 16:07:37.592: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec  3 16:07:37.592: INFO: stdout: ""
Dec  3 16:07:37.593: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-9918 execpodj6crc -- /bin/sh -x -c nc -zv -t -w 2 100.109.43.30 80'
Dec  3 16:07:38.198: INFO: stderr: "+ nc -zv -t -w 2 100.109.43.30 80\nConnection to 100.109.43.30 80 port [tcp/http] succeeded!\n"
Dec  3 16:07:38.198: INFO: stdout: ""
Dec  3 16:07:38.198: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:07:38.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9918" for this suite.
Dec  3 16:07:46.233: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:07:46.374: INFO: namespace services-9918 deletion completed in 8.15506622s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:07:46.375: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-5857
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec  3 16:07:46.695: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:07:50.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-5857" for this suite.
Dec  3 16:08:18.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:08:18.778: INFO: namespace init-container-5857 deletion completed in 28.157176728s
•SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:08:18.778: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7824
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec  3 16:08:25.130: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1203 16:08:25.130073    5091 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:08:25.130: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7824" for this suite.
Dec  3 16:08:31.148: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:08:31.291: INFO: namespace gc-7824 deletion completed in 6.156344228s
•S
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:08:31.291: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4642
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 16:08:31.703: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9315be36-e981-4132-88f3-824e57818424" in namespace "downward-api-4642" to be "success or failure"
Dec  3 16:08:31.707: INFO: Pod "downwardapi-volume-9315be36-e981-4132-88f3-824e57818424": Phase="Pending", Reason="", readiness=false. Elapsed: 3.960934ms
Dec  3 16:08:33.712: INFO: Pod "downwardapi-volume-9315be36-e981-4132-88f3-824e57818424": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009423637s
STEP: Saw pod success
Dec  3 16:08:33.712: INFO: Pod "downwardapi-volume-9315be36-e981-4132-88f3-824e57818424" satisfied condition "success or failure"
Dec  3 16:08:33.716: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downwardapi-volume-9315be36-e981-4132-88f3-824e57818424 container client-container: <nil>
STEP: delete the pod
Dec  3 16:08:33.741: INFO: Waiting for pod downwardapi-volume-9315be36-e981-4132-88f3-824e57818424 to disappear
Dec  3 16:08:33.745: INFO: Pod downwardapi-volume-9315be36-e981-4132-88f3-824e57818424 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:08:33.745: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4642" for this suite.
Dec  3 16:08:41.765: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:08:41.907: INFO: namespace downward-api-4642 deletion completed in 8.15534528s
•SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:08:41.908: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1819
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:08:42.304: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec  3 16:08:47.310: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  3 16:08:47.310: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec  3 16:08:51.347: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-1819 /apis/apps/v1/namespaces/deployment-1819/deployments/test-cleanup-deployment cd397d3c-d7e9-4b7c-8d75-42254973d4a7 27884 1 2019-12-03 16:08:47 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0033cbb98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-03 16:08:47 +0000 UTC,LastTransitionTime:2019-12-03 16:08:47 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-65db99849b" has successfully progressed.,LastUpdateTime:2019-12-03 16:08:49 +0000 UTC,LastTransitionTime:2019-12-03 16:08:47 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 16:08:51.352: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-1819 /apis/apps/v1/namespaces/deployment-1819/replicasets/test-cleanup-deployment-65db99849b 731f61b6-54f8-443e-9521-6ac2f8d1dc18 27877 1 2019-12-03 16:08:47 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment cd397d3c-d7e9-4b7c-8d75-42254973d4a7 0xc0033cbf97 0xc0033cbf98}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0033cbff8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec  3 16:08:51.357: INFO: Pod "test-cleanup-deployment-65db99849b-tl7mr" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-65db99849b-tl7mr test-cleanup-deployment-65db99849b- deployment-1819 /api/v1/namespaces/deployment-1819/pods/test-cleanup-deployment-65db99849b-tl7mr 07a2043c-9390-44f8-a2a8-d94ce96bc9e7 27876 0 2019-12-03 16:08:47 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[cni.projectcalico.org/podIP:100.64.1.4/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-cleanup-deployment-65db99849b 731f61b6-54f8-443e-9521-6ac2f8d1dc18 0xc006566397 0xc006566398}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-xrgbg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-xrgbg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-xrgbg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:08:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:08:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:08:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:08:47 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:100.64.1.4,StartTime:2019-12-03 16:08:47 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 16:08:48 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://3d9970877ec893faa8f98c3e0076bf0e46b3cb5ae92f106f893a030bf8136ea3,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.4,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:08:51.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1819" for this suite.
Dec  3 16:08:59.378: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:08:59.523: INFO: namespace deployment-1819 deletion completed in 8.158601842s
•SSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:08:59.523: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8339
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-1607
STEP: Creating secret with name secret-test-f128d9ca-1e11-4068-9eb0-122cd8ecb7d3
STEP: Creating a pod to test consume secrets
Dec  3 16:09:00.505: INFO: Waiting up to 5m0s for pod "pod-secrets-d6c4529e-436e-4514-ab27-537f0cb6f54e" in namespace "secrets-8339" to be "success or failure"
Dec  3 16:09:00.509: INFO: Pod "pod-secrets-d6c4529e-436e-4514-ab27-537f0cb6f54e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.176838ms
Dec  3 16:09:02.515: INFO: Pod "pod-secrets-d6c4529e-436e-4514-ab27-537f0cb6f54e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009701438s
STEP: Saw pod success
Dec  3 16:09:02.515: INFO: Pod "pod-secrets-d6c4529e-436e-4514-ab27-537f0cb6f54e" satisfied condition "success or failure"
Dec  3 16:09:02.519: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-secrets-d6c4529e-436e-4514-ab27-537f0cb6f54e container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:09:02.541: INFO: Waiting for pod pod-secrets-d6c4529e-436e-4514-ab27-537f0cb6f54e to disappear
Dec  3 16:09:02.545: INFO: Pod pod-secrets-d6c4529e-436e-4514-ab27-537f0cb6f54e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:09:02.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8339" for this suite.
Dec  3 16:09:08.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:09:08.712: INFO: namespace secrets-8339 deletion completed in 6.159964592s
STEP: Destroying namespace "secret-namespace-1607" for this suite.
Dec  3 16:09:14.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:09:14.908: INFO: namespace secret-namespace-1607 deletion completed in 6.195360561s
•SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:09:14.908: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2875
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  3 16:09:15.196: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-2875'
Dec  3 16:09:15.342: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 16:09:15.342: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Dec  3 16:09:17.357: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-kfvkq]
Dec  3 16:09:17.357: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-kfvkq" in namespace "kubectl-2875" to be "running and ready"
Dec  3 16:09:17.361: INFO: Pod "e2e-test-httpd-rc-kfvkq": Phase="Running", Reason="", readiness=true. Elapsed: 4.436862ms
Dec  3 16:09:17.362: INFO: Pod "e2e-test-httpd-rc-kfvkq" satisfied condition "running and ready"
Dec  3 16:09:17.362: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-kfvkq]
Dec  3 16:09:17.362: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs rc/e2e-test-httpd-rc --namespace=kubectl-2875'
Dec  3 16:09:17.640: INFO: stderr: ""
Dec  3 16:09:17.640: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 100.64.1.6. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 100.64.1.6. Set the 'ServerName' directive globally to suppress this message\n[Tue Dec 03 16:09:16.309829 2019] [mpm_event:notice] [pid 1:tid 140534454471528] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Tue Dec 03 16:09:16.309882 2019] [core:notice] [pid 1:tid 140534454471528] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Dec  3 16:09:17.640: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete rc e2e-test-httpd-rc --namespace=kubectl-2875'
Dec  3 16:09:17.811: INFO: stderr: ""
Dec  3 16:09:17.811: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:09:17.811: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2875" for this suite.
Dec  3 16:09:29.834: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:09:29.972: INFO: namespace kubectl-2875 deletion completed in 12.152818426s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:09:29.973: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1816
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  3 16:09:30.500: INFO: Waiting up to 5m0s for pod "pod-7b07fcbd-d201-4c39-870e-88fd1a9391d9" in namespace "emptydir-1816" to be "success or failure"
Dec  3 16:09:30.504: INFO: Pod "pod-7b07fcbd-d201-4c39-870e-88fd1a9391d9": Phase="Pending", Reason="", readiness=false. Elapsed: 3.923907ms
Dec  3 16:09:32.509: INFO: Pod "pod-7b07fcbd-d201-4c39-870e-88fd1a9391d9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009003025s
STEP: Saw pod success
Dec  3 16:09:32.509: INFO: Pod "pod-7b07fcbd-d201-4c39-870e-88fd1a9391d9" satisfied condition "success or failure"
Dec  3 16:09:32.514: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-7b07fcbd-d201-4c39-870e-88fd1a9391d9 container test-container: <nil>
STEP: delete the pod
Dec  3 16:09:32.535: INFO: Waiting for pod pod-7b07fcbd-d201-4c39-870e-88fd1a9391d9 to disappear
Dec  3 16:09:32.539: INFO: Pod pod-7b07fcbd-d201-4c39-870e-88fd1a9391d9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:09:32.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1816" for this suite.
Dec  3 16:09:38.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:09:38.700: INFO: namespace emptydir-1816 deletion completed in 6.154459374s
•SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:09:38.700: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9260
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:09:46.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9260" for this suite.
Dec  3 16:09:54.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:09:54.180: INFO: namespace resourcequota-9260 deletion completed in 8.161868527s
•S
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:09:54.181: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4597
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:10:10.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4597" for this suite.
Dec  3 16:10:18.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:10:18.757: INFO: namespace resourcequota-4597 deletion completed in 8.167871603s
•SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:10:18.757: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6103
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 16:10:19.703: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec  3 16:10:21.718: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986219, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986219, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986219, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986219, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 16:10:24.731: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:10:24.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6103" for this suite.
Dec  3 16:10:30.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:10:31.107: INFO: namespace webhook-6103 deletion completed in 6.153475854s
STEP: Destroying namespace "webhook-6103-markers" for this suite.
Dec  3 16:10:37.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:10:37.302: INFO: namespace webhook-6103-markers deletion completed in 6.194978978s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:10:37.320: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9238
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-9ffe59e7-ae2c-41b7-a7c5-8a9a5fa2621a
STEP: Creating a pod to test consume secrets
Dec  3 16:10:38.201: INFO: Waiting up to 5m0s for pod "pod-secrets-9da128a6-cf40-4b36-882e-a7925ddd5f9e" in namespace "secrets-9238" to be "success or failure"
Dec  3 16:10:38.206: INFO: Pod "pod-secrets-9da128a6-cf40-4b36-882e-a7925ddd5f9e": Phase="Pending", Reason="", readiness=false. Elapsed: 4.342091ms
Dec  3 16:10:40.211: INFO: Pod "pod-secrets-9da128a6-cf40-4b36-882e-a7925ddd5f9e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009682506s
STEP: Saw pod success
Dec  3 16:10:40.211: INFO: Pod "pod-secrets-9da128a6-cf40-4b36-882e-a7925ddd5f9e" satisfied condition "success or failure"
Dec  3 16:10:40.215: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-secrets-9da128a6-cf40-4b36-882e-a7925ddd5f9e container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:10:40.236: INFO: Waiting for pod pod-secrets-9da128a6-cf40-4b36-882e-a7925ddd5f9e to disappear
Dec  3 16:10:40.240: INFO: Pod pod-secrets-9da128a6-cf40-4b36-882e-a7925ddd5f9e no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:10:40.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9238" for this suite.
Dec  3 16:10:46.261: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:10:46.404: INFO: namespace secrets-9238 deletion completed in 6.156362482s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:10:46.404: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3058
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-9d1260a0-71e5-40a1-bfe0-7b75cc9ee5a3 in namespace container-probe-3058
Dec  3 16:10:48.712: INFO: Started pod busybox-9d1260a0-71e5-40a1-bfe0-7b75cc9ee5a3 in namespace container-probe-3058
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 16:10:48.717: INFO: Initial restart count of pod busybox-9d1260a0-71e5-40a1-bfe0-7b75cc9ee5a3 is 0
Dec  3 16:11:40.870: INFO: Restart count of pod container-probe-3058/busybox-9d1260a0-71e5-40a1-bfe0-7b75cc9ee5a3 is now 1 (52.153004407s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:11:40.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3058" for this suite.
Dec  3 16:11:46.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:11:47.040: INFO: namespace container-probe-3058 deletion completed in 6.155811663s
•S
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:11:47.041: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4836
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-64fffb99-fbea-42ef-b0f9-a80d0730b3f9
STEP: Creating configMap with name cm-test-opt-upd-a5a01506-8929-4313-8b06-dfa67e11fcaa
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-64fffb99-fbea-42ef-b0f9-a80d0730b3f9
STEP: Updating configmap cm-test-opt-upd-a5a01506-8929-4313-8b06-dfa67e11fcaa
STEP: Creating configMap with name cm-test-opt-create-0f1ca45b-f02b-4731-9890-51b7c26440bd
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:11:53.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4836" for this suite.
Dec  3 16:12:23.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:12:24.132: INFO: namespace projected-4836 deletion completed in 30.156766812s
•SSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:12:24.132: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4280
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-4280
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-4280
STEP: creating replication controller externalsvc in namespace services-4280
I1203 16:12:24.517946    5091 runners.go:184] Created replication controller with name: externalsvc, namespace: services-4280, replica count: 2
I1203 16:12:27.568483    5091 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Dec  3 16:12:27.589: INFO: Creating new exec pod
Dec  3 16:12:29.606: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-4280 execpod54fdz -- /bin/sh -x -c nslookup nodeport-service'
Dec  3 16:12:30.288: INFO: stderr: "+ nslookup nodeport-service\n"
Dec  3 16:12:30.288: INFO: stdout: "Server:\t\t100.104.0.10\nAddress:\t100.104.0.10#53\n\nnodeport-service.services-4280.svc.cluster.local\tcanonical name = externalsvc.services-4280.svc.cluster.local.\nName:\texternalsvc.services-4280.svc.cluster.local\nAddress: 100.109.188.245\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-4280, will wait for the garbage collector to delete the pods
Dec  3 16:12:30.350: INFO: Deleting ReplicationController externalsvc took: 6.201486ms
Dec  3 16:12:30.850: INFO: Terminating ReplicationController externalsvc pods took: 500.277398ms
Dec  3 16:12:37.962: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:12:37.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4280" for this suite.
Dec  3 16:12:43.991: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:12:44.134: INFO: namespace services-4280 deletion completed in 6.155651097s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:12:44.134: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5563
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  3 16:12:44.512: INFO: Waiting up to 5m0s for pod "pod-59eb84f2-48fa-4961-9a8e-cdd0e0539b49" in namespace "emptydir-5563" to be "success or failure"
Dec  3 16:12:44.516: INFO: Pod "pod-59eb84f2-48fa-4961-9a8e-cdd0e0539b49": Phase="Pending", Reason="", readiness=false. Elapsed: 4.186196ms
Dec  3 16:12:46.522: INFO: Pod "pod-59eb84f2-48fa-4961-9a8e-cdd0e0539b49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009679898s
STEP: Saw pod success
Dec  3 16:12:46.522: INFO: Pod "pod-59eb84f2-48fa-4961-9a8e-cdd0e0539b49" satisfied condition "success or failure"
Dec  3 16:12:46.526: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-59eb84f2-48fa-4961-9a8e-cdd0e0539b49 container test-container: <nil>
STEP: delete the pod
Dec  3 16:12:46.544: INFO: Waiting for pod pod-59eb84f2-48fa-4961-9a8e-cdd0e0539b49 to disappear
Dec  3 16:12:46.548: INFO: Pod pod-59eb84f2-48fa-4961-9a8e-cdd0e0539b49 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:12:46.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5563" for this suite.
Dec  3 16:12:52.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:12:52.712: INFO: namespace emptydir-5563 deletion completed in 6.157211252s
•SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:12:52.712: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-926
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec  3 16:12:52.997: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-926'
Dec  3 16:12:53.263: INFO: stderr: ""
Dec  3 16:12:53.263: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 16:12:53.263: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-926'
Dec  3 16:12:53.405: INFO: stderr: ""
Dec  3 16:12:53.405: INFO: stdout: "update-demo-nautilus-psqrn update-demo-nautilus-tjhjf "
Dec  3 16:12:53.405: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-psqrn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-926'
Dec  3 16:12:53.563: INFO: stderr: ""
Dec  3 16:12:53.563: INFO: stdout: ""
Dec  3 16:12:53.563: INFO: update-demo-nautilus-psqrn is created but not running
Dec  3 16:12:58.563: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-926'
Dec  3 16:12:58.681: INFO: stderr: ""
Dec  3 16:12:58.681: INFO: stdout: "update-demo-nautilus-psqrn update-demo-nautilus-tjhjf "
Dec  3 16:12:58.681: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-psqrn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-926'
Dec  3 16:12:58.771: INFO: stderr: ""
Dec  3 16:12:58.771: INFO: stdout: "true"
Dec  3 16:12:58.771: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-psqrn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-926'
Dec  3 16:12:58.876: INFO: stderr: ""
Dec  3 16:12:58.876: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 16:12:58.876: INFO: validating pod update-demo-nautilus-psqrn
Dec  3 16:12:58.971: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 16:12:58.971: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 16:12:58.972: INFO: update-demo-nautilus-psqrn is verified up and running
Dec  3 16:12:58.972: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-tjhjf -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-926'
Dec  3 16:12:59.104: INFO: stderr: ""
Dec  3 16:12:59.104: INFO: stdout: "true"
Dec  3 16:12:59.104: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-tjhjf -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-926'
Dec  3 16:12:59.203: INFO: stderr: ""
Dec  3 16:12:59.203: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 16:12:59.203: INFO: validating pod update-demo-nautilus-tjhjf
Dec  3 16:12:59.300: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 16:12:59.300: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 16:12:59.300: INFO: update-demo-nautilus-tjhjf is verified up and running
STEP: using delete to clean up resources
Dec  3 16:12:59.300: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-926'
Dec  3 16:12:59.466: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 16:12:59.466: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  3 16:12:59.466: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-926'
Dec  3 16:12:59.565: INFO: stderr: "No resources found in kubectl-926 namespace.\n"
Dec  3 16:12:59.565: INFO: stdout: ""
Dec  3 16:12:59.565: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-926 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 16:12:59.700: INFO: stderr: ""
Dec  3 16:12:59.701: INFO: stdout: "update-demo-nautilus-psqrn\nupdate-demo-nautilus-tjhjf\n"
Dec  3 16:13:00.201: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-926'
Dec  3 16:13:00.309: INFO: stderr: "No resources found in kubectl-926 namespace.\n"
Dec  3 16:13:00.310: INFO: stdout: ""
Dec  3 16:13:00.310: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-926 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 16:13:00.465: INFO: stderr: ""
Dec  3 16:13:00.465: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:13:00.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-926" for this suite.
Dec  3 16:13:12.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:13:12.630: INFO: namespace kubectl-926 deletion completed in 12.157145956s
•SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:13:12.630: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-5828
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:13:13.113: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec  3 16:13:13.127: INFO: Number of nodes with available pods: 0
Dec  3 16:13:13.127: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 16:13:14.140: INFO: Number of nodes with available pods: 0
Dec  3 16:13:14.145: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 16:13:15.141: INFO: Number of nodes with available pods: 2
Dec  3 16:13:15.141: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec  3 16:13:15.266: INFO: Wrong image for pod: daemon-set-kqmm8. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 16:13:15.267: INFO: Wrong image for pod: daemon-set-z6pwh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 16:13:16.277: INFO: Wrong image for pod: daemon-set-kqmm8. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 16:13:16.277: INFO: Wrong image for pod: daemon-set-z6pwh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 16:13:17.281: INFO: Wrong image for pod: daemon-set-kqmm8. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 16:13:17.281: INFO: Wrong image for pod: daemon-set-z6pwh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 16:13:18.277: INFO: Wrong image for pod: daemon-set-kqmm8. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 16:13:18.277: INFO: Pod daemon-set-kqmm8 is not available
Dec  3 16:13:18.277: INFO: Wrong image for pod: daemon-set-z6pwh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 16:13:19.277: INFO: Wrong image for pod: daemon-set-z6pwh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 16:13:19.277: INFO: Pod daemon-set-zcfk6 is not available
Dec  3 16:13:20.277: INFO: Wrong image for pod: daemon-set-z6pwh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 16:13:20.277: INFO: Pod daemon-set-zcfk6 is not available
Dec  3 16:13:21.277: INFO: Wrong image for pod: daemon-set-z6pwh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 16:13:22.278: INFO: Wrong image for pod: daemon-set-z6pwh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 16:13:22.278: INFO: Pod daemon-set-z6pwh is not available
Dec  3 16:13:23.277: INFO: Wrong image for pod: daemon-set-z6pwh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 16:13:23.277: INFO: Pod daemon-set-z6pwh is not available
Dec  3 16:13:24.277: INFO: Wrong image for pod: daemon-set-z6pwh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 16:13:24.277: INFO: Pod daemon-set-z6pwh is not available
Dec  3 16:13:25.277: INFO: Wrong image for pod: daemon-set-z6pwh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 16:13:25.277: INFO: Pod daemon-set-z6pwh is not available
Dec  3 16:13:26.277: INFO: Wrong image for pod: daemon-set-z6pwh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 16:13:26.277: INFO: Pod daemon-set-z6pwh is not available
Dec  3 16:13:27.277: INFO: Wrong image for pod: daemon-set-z6pwh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 16:13:27.277: INFO: Pod daemon-set-z6pwh is not available
Dec  3 16:13:28.279: INFO: Pod daemon-set-qp2b8 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Dec  3 16:13:28.296: INFO: Number of nodes with available pods: 1
Dec  3 16:13:28.296: INFO: Node izgw8fisrtg04goc4t8tqaz is running more than one daemon pod
Dec  3 16:13:29.308: INFO: Number of nodes with available pods: 1
Dec  3 16:13:29.308: INFO: Node izgw8fisrtg04goc4t8tqaz is running more than one daemon pod
Dec  3 16:13:30.308: INFO: Number of nodes with available pods: 2
Dec  3 16:13:30.308: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-5828, will wait for the garbage collector to delete the pods
Dec  3 16:13:30.391: INFO: Deleting DaemonSet.extensions daemon-set took: 6.215447ms
Dec  3 16:13:30.891: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.269258ms
Dec  3 16:13:37.996: INFO: Number of nodes with available pods: 0
Dec  3 16:13:37.996: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 16:13:38.001: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-5828/daemonsets","resourceVersion":"29240"},"items":null}

Dec  3 16:13:38.005: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-5828/pods","resourceVersion":"29240"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:13:38.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-5828" for this suite.
Dec  3 16:13:44.040: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:13:44.180: INFO: namespace daemonsets-5828 deletion completed in 6.154546988s
•
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:13:44.180: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-6341
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-2gfc
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 16:13:44.511: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-2gfc" in namespace "subpath-6341" to be "success or failure"
Dec  3 16:13:44.515: INFO: Pod "pod-subpath-test-configmap-2gfc": Phase="Pending", Reason="", readiness=false. Elapsed: 4.021545ms
Dec  3 16:13:46.520: INFO: Pod "pod-subpath-test-configmap-2gfc": Phase="Running", Reason="", readiness=true. Elapsed: 2.00931032s
Dec  3 16:13:48.525: INFO: Pod "pod-subpath-test-configmap-2gfc": Phase="Running", Reason="", readiness=true. Elapsed: 4.014569154s
Dec  3 16:13:50.530: INFO: Pod "pod-subpath-test-configmap-2gfc": Phase="Running", Reason="", readiness=true. Elapsed: 6.019826988s
Dec  3 16:13:52.536: INFO: Pod "pod-subpath-test-configmap-2gfc": Phase="Running", Reason="", readiness=true. Elapsed: 8.025334219s
Dec  3 16:13:54.541: INFO: Pod "pod-subpath-test-configmap-2gfc": Phase="Running", Reason="", readiness=true. Elapsed: 10.030669895s
Dec  3 16:13:56.550: INFO: Pod "pod-subpath-test-configmap-2gfc": Phase="Running", Reason="", readiness=true. Elapsed: 12.039750433s
Dec  3 16:13:58.556: INFO: Pod "pod-subpath-test-configmap-2gfc": Phase="Running", Reason="", readiness=true. Elapsed: 14.045139212s
Dec  3 16:14:00.561: INFO: Pod "pod-subpath-test-configmap-2gfc": Phase="Running", Reason="", readiness=true. Elapsed: 16.050323052s
Dec  3 16:14:02.569: INFO: Pod "pod-subpath-test-configmap-2gfc": Phase="Running", Reason="", readiness=true. Elapsed: 18.058069868s
Dec  3 16:14:04.574: INFO: Pod "pod-subpath-test-configmap-2gfc": Phase="Running", Reason="", readiness=true. Elapsed: 20.063188979s
Dec  3 16:14:06.579: INFO: Pod "pod-subpath-test-configmap-2gfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.068367417s
STEP: Saw pod success
Dec  3 16:14:06.579: INFO: Pod "pod-subpath-test-configmap-2gfc" satisfied condition "success or failure"
Dec  3 16:14:06.584: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-subpath-test-configmap-2gfc container test-container-subpath-configmap-2gfc: <nil>
STEP: delete the pod
Dec  3 16:14:06.610: INFO: Waiting for pod pod-subpath-test-configmap-2gfc to disappear
Dec  3 16:14:06.614: INFO: Pod pod-subpath-test-configmap-2gfc no longer exists
STEP: Deleting pod pod-subpath-test-configmap-2gfc
Dec  3 16:14:06.614: INFO: Deleting pod "pod-subpath-test-configmap-2gfc" in namespace "subpath-6341"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:14:06.618: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-6341" for this suite.
Dec  3 16:14:12.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:14:12.792: INFO: namespace subpath-6341 deletion completed in 6.156918262s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:14:12.793: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5211
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-26c56a7e-7b52-46c6-b3c0-5991ffc63af7
STEP: Creating a pod to test consume secrets
Dec  3 16:14:13.189: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5208ab93-b78c-4c45-a8d0-ebe6e9cce69a" in namespace "projected-5211" to be "success or failure"
Dec  3 16:14:13.202: INFO: Pod "pod-projected-secrets-5208ab93-b78c-4c45-a8d0-ebe6e9cce69a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.025988ms
Dec  3 16:14:15.208: INFO: Pod "pod-projected-secrets-5208ab93-b78c-4c45-a8d0-ebe6e9cce69a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009079245s
STEP: Saw pod success
Dec  3 16:14:15.208: INFO: Pod "pod-projected-secrets-5208ab93-b78c-4c45-a8d0-ebe6e9cce69a" satisfied condition "success or failure"
Dec  3 16:14:15.212: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-projected-secrets-5208ab93-b78c-4c45-a8d0-ebe6e9cce69a container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:14:15.233: INFO: Waiting for pod pod-projected-secrets-5208ab93-b78c-4c45-a8d0-ebe6e9cce69a to disappear
Dec  3 16:14:15.237: INFO: Pod pod-projected-secrets-5208ab93-b78c-4c45-a8d0-ebe6e9cce69a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:14:15.237: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5211" for this suite.
Dec  3 16:14:21.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:14:21.546: INFO: namespace projected-5211 deletion completed in 6.30187735s
•SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:14:21.546: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-226
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:14:23.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-226" for this suite.
Dec  3 16:15:07.944: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:15:08.087: INFO: namespace kubelet-test-226 deletion completed in 44.156277838s
•SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:15:08.087: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-9441
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:15:08.396: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Dec  3 16:15:12.586: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9441 create -f -'
Dec  3 16:15:13.544: INFO: stderr: ""
Dec  3 16:15:13.544: INFO: stdout: "e2e-test-crd-publish-openapi-2058-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec  3 16:15:13.544: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9441 delete e2e-test-crd-publish-openapi-2058-crds test-foo'
Dec  3 16:15:13.784: INFO: stderr: ""
Dec  3 16:15:13.784: INFO: stdout: "e2e-test-crd-publish-openapi-2058-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Dec  3 16:15:13.784: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9441 apply -f -'
Dec  3 16:15:14.197: INFO: stderr: ""
Dec  3 16:15:14.197: INFO: stdout: "e2e-test-crd-publish-openapi-2058-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec  3 16:15:14.197: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9441 delete e2e-test-crd-publish-openapi-2058-crds test-foo'
Dec  3 16:15:14.416: INFO: stderr: ""
Dec  3 16:15:14.416: INFO: stdout: "e2e-test-crd-publish-openapi-2058-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Dec  3 16:15:14.416: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9441 create -f -'
Dec  3 16:15:14.829: INFO: rc: 1
Dec  3 16:15:14.829: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9441 apply -f -'
Dec  3 16:15:15.229: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Dec  3 16:15:15.229: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9441 create -f -'
Dec  3 16:15:15.687: INFO: rc: 1
Dec  3 16:15:15.687: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-9441 apply -f -'
Dec  3 16:15:16.018: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Dec  3 16:15:16.018: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-2058-crds'
Dec  3 16:15:16.400: INFO: stderr: ""
Dec  3 16:15:16.400: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2058-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Dec  3 16:15:16.400: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-2058-crds.metadata'
Dec  3 16:15:16.736: INFO: stderr: ""
Dec  3 16:15:16.736: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2058-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Dec  3 16:15:16.737: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-2058-crds.spec'
Dec  3 16:15:17.126: INFO: stderr: ""
Dec  3 16:15:17.126: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2058-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Dec  3 16:15:17.126: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-2058-crds.spec.bars'
Dec  3 16:15:17.565: INFO: stderr: ""
Dec  3 16:15:17.565: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-2058-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Dec  3 16:15:17.565: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-2058-crds.spec.bars2'
Dec  3 16:15:17.927: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:15:21.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-9441" for this suite.
Dec  3 16:15:27.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:15:27.882: INFO: namespace crd-publish-openapi-9441 deletion completed in 6.159459131s
•SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:15:27.882: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6885
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  3 16:15:32.257: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 16:15:32.261: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 16:15:34.262: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 16:15:34.267: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 16:15:36.263: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 16:15:36.268: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:15:36.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6885" for this suite.
Dec  3 16:15:50.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:15:50.438: INFO: namespace container-lifecycle-hook-6885 deletion completed in 14.162173619s
•SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:15:50.438: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2629
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-17ac1eb7-43f7-4c60-b436-f6bb970c0445
STEP: Creating a pod to test consume configMaps
Dec  3 16:15:50.812: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6ee145f7-0259-4ad4-9413-f9a0be90f0d3" in namespace "projected-2629" to be "success or failure"
Dec  3 16:15:50.816: INFO: Pod "pod-projected-configmaps-6ee145f7-0259-4ad4-9413-f9a0be90f0d3": Phase="Pending", Reason="", readiness=false. Elapsed: 3.941686ms
Dec  3 16:15:53.014: INFO: Pod "pod-projected-configmaps-6ee145f7-0259-4ad4-9413-f9a0be90f0d3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.201988741s
STEP: Saw pod success
Dec  3 16:15:53.014: INFO: Pod "pod-projected-configmaps-6ee145f7-0259-4ad4-9413-f9a0be90f0d3" satisfied condition "success or failure"
Dec  3 16:15:53.018: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-projected-configmaps-6ee145f7-0259-4ad4-9413-f9a0be90f0d3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 16:15:53.040: INFO: Waiting for pod pod-projected-configmaps-6ee145f7-0259-4ad4-9413-f9a0be90f0d3 to disappear
Dec  3 16:15:53.044: INFO: Pod pod-projected-configmaps-6ee145f7-0259-4ad4-9413-f9a0be90f0d3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:15:53.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2629" for this suite.
Dec  3 16:15:59.067: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:15:59.217: INFO: namespace projected-2629 deletion completed in 6.16449407s
•SSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:15:59.218: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-267
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-267
STEP: creating replication controller nodeport-test in namespace services-267
I1203 16:15:59.607990    5091 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-267, replica count: 2
Dec  3 16:16:02.658: INFO: Creating new exec pod
I1203 16:16:02.658614    5091 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 16:16:05.684: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-267 execpod86b8q -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Dec  3 16:16:06.349: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec  3 16:16:06.349: INFO: stdout: ""
Dec  3 16:16:06.349: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-267 execpod86b8q -- /bin/sh -x -c nc -zv -t -w 2 100.106.179.189 80'
Dec  3 16:16:07.151: INFO: stderr: "+ nc -zv -t -w 2 100.106.179.189 80\nConnection to 100.106.179.189 80 port [tcp/http] succeeded!\n"
Dec  3 16:16:07.151: INFO: stdout: ""
Dec  3 16:16:07.151: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-267 execpod86b8q -- /bin/sh -x -c nc -zv -t -w 2 10.250.2.118 30011'
Dec  3 16:16:07.753: INFO: stderr: "+ nc -zv -t -w 2 10.250.2.118 30011\nConnection to 10.250.2.118 30011 port [tcp/30011] succeeded!\n"
Dec  3 16:16:07.753: INFO: stdout: ""
Dec  3 16:16:07.753: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-267 execpod86b8q -- /bin/sh -x -c nc -zv -t -w 2 10.250.2.117 30011'
Dec  3 16:16:08.433: INFO: stderr: "+ nc -zv -t -w 2 10.250.2.117 30011\nConnection to 10.250.2.117 30011 port [tcp/30011] succeeded!\n"
Dec  3 16:16:08.433: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:16:08.433: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-267" for this suite.
Dec  3 16:16:16.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:16:16.604: INFO: namespace services-267 deletion completed in 8.16331989s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:16:16.604: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5844
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:16:18.929: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5844" for this suite.
Dec  3 16:17:02.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:17:03.102: INFO: namespace kubelet-test-5844 deletion completed in 44.165830336s
•SS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:17:03.103: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6070
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Dec  3 16:17:05.426: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec  3 16:17:20.664: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:17:20.669: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6070" for this suite.
Dec  3 16:17:26.688: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:17:26.869: INFO: namespace pods-6070 deletion completed in 6.194457685s
•SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:17:26.869: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8678
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 16:17:27.969: INFO: new replicaset for deployment "sample-webhook-deployment" is yet to be created
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 16:17:30.991: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:17:31.207: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8678" for this suite.
Dec  3 16:17:59.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:17:59.371: INFO: namespace webhook-8678 deletion completed in 28.156176578s
STEP: Destroying namespace "webhook-8678-markers" for this suite.
Dec  3 16:18:07.385: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:18:07.535: INFO: namespace webhook-8678-markers deletion completed in 8.164009221s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:18:07.552: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-344
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec  3 16:18:10.344: INFO: Successfully updated pod "annotationupdate448d6afa-7411-4406-b119-f989fd85e6fd"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:18:14.386: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-344" for this suite.
Dec  3 16:18:42.411: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:18:42.554: INFO: namespace downward-api-344 deletion completed in 28.15987571s
•SSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:18:42.554: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9662
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:18:42.796: INFO: Creating deployment "webserver-deployment"
Dec  3 16:18:42.800: INFO: Waiting for observed generation 1
Dec  3 16:18:44.810: INFO: Waiting for all required pods to come up
Dec  3 16:18:44.818: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec  3 16:18:48.828: INFO: Waiting for deployment "webserver-deployment" to complete
Dec  3 16:18:48.837: INFO: Updating deployment "webserver-deployment" with a non-existent image
Dec  3 16:18:48.849: INFO: Updating deployment webserver-deployment
Dec  3 16:18:48.849: INFO: Waiting for observed generation 2
Dec  3 16:18:50.858: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec  3 16:18:50.863: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec  3 16:18:50.867: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec  3 16:18:50.879: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec  3 16:18:50.880: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec  3 16:18:50.883: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec  3 16:18:50.891: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Dec  3 16:18:50.891: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Dec  3 16:18:50.901: INFO: Updating deployment webserver-deployment
Dec  3 16:18:50.901: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Dec  3 16:18:50.909: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec  3 16:18:52.919: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec  3 16:18:52.928: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-9662 /apis/apps/v1/namespaces/deployment-9662/deployments/webserver-deployment 05d35fff-f842-40b7-9b74-d9737381bec2 30735 3 2019-12-03 16:18:42 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004b7e358 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-12-03 16:18:50 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2019-12-03 16:18:51 +0000 UTC,LastTransitionTime:2019-12-03 16:18:43 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Dec  3 16:18:52.932: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-9662 /apis/apps/v1/namespaces/deployment-9662/replicasets/webserver-deployment-c7997dcc8 9253f7fe-9b83-4b02-aa02-c850ea36cc08 30717 3 2019-12-03 16:18:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 05d35fff-f842-40b7-9b74-d9737381bec2 0xc008c60c47 0xc008c60c48}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc008c60cb8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 16:18:52.932: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Dec  3 16:18:52.932: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-9662 /apis/apps/v1/namespaces/deployment-9662/replicasets/webserver-deployment-595b5b9587 e34bdba5-dd3a-4fe7-85dc-60532bc9b942 30734 3 2019-12-03 16:18:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 05d35fff-f842-40b7-9b74-d9737381bec2 0xc008c60b87 0xc008c60b88}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc008c60be8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Dec  3 16:18:52.944: INFO: Pod "webserver-deployment-595b5b9587-2lv94" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2lv94 webserver-deployment-595b5b9587- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-595b5b9587-2lv94 216aa2f1-59a5-41b0-8c61-63a9a51c8ffa 30702 0 2019-12-03 16:18:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e34bdba5-dd3a-4fe7-85dc-60532bc9b942 0xc003847c97 0xc003847c98}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw88vcbd5x6ev7zbjg8vz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.118,PodIP:,StartTime:2019-12-03 16:18:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.944: INFO: Pod "webserver-deployment-595b5b9587-2prp4" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2prp4 webserver-deployment-595b5b9587- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-595b5b9587-2prp4 ec81e91b-33ca-4a75-aaa7-e37dfb9ed9d7 30599 0 2019-12-03 16:18:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.1.42/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e34bdba5-dd3a-4fe7-85dc-60532bc9b942 0xc003847df7 0xc003847df8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:100.64.1.42,StartTime:2019-12-03 16:18:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 16:18:46 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://f42b8e0fa88f6aef4b3d084a0d610c4ea34deaa6f8ecd8fc46999f2f87ebf9d9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.42,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.944: INFO: Pod "webserver-deployment-595b5b9587-4n4hx" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-4n4hx webserver-deployment-595b5b9587- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-595b5b9587-4n4hx d860bf16-9d25-4e39-b958-a12f07d672cc 30742 0 2019-12-03 16:18:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.0.68/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e34bdba5-dd3a-4fe7-85dc-60532bc9b942 0xc003847f70 0xc003847f71}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw88vcbd5x6ev7zbjg8vz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.118,PodIP:,StartTime:2019-12-03 16:18:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.945: INFO: Pod "webserver-deployment-595b5b9587-82vm5" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-82vm5 webserver-deployment-595b5b9587- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-595b5b9587-82vm5 0c64fffe-eeb3-4401-97f3-63a60ec73a55 30704 0 2019-12-03 16:18:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e34bdba5-dd3a-4fe7-85dc-60532bc9b942 0xc008d700b7 0xc008d700b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw88vcbd5x6ev7zbjg8vz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.118,PodIP:,StartTime:2019-12-03 16:18:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.945: INFO: Pod "webserver-deployment-595b5b9587-8vvc8" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-8vvc8 webserver-deployment-595b5b9587- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-595b5b9587-8vvc8 a7909460-bc9e-4e13-9f0a-69f1b3bd8ba8 30605 0 2019-12-03 16:18:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.1.41/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e34bdba5-dd3a-4fe7-85dc-60532bc9b942 0xc008d70217 0xc008d70218}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:100.64.1.41,StartTime:2019-12-03 16:18:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 16:18:46 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://3af3eda9f2e384fa7caadf32cf3242cf3c6360082d46a12239575cc1b1f1f037,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.41,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.945: INFO: Pod "webserver-deployment-595b5b9587-cmxqv" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-cmxqv webserver-deployment-595b5b9587- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-595b5b9587-cmxqv 77ed9da6-5e56-4f81-968e-a085a6f1d41b 30723 0 2019-12-03 16:18:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e34bdba5-dd3a-4fe7-85dc-60532bc9b942 0xc008d70380 0xc008d70381}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:,StartTime:2019-12-03 16:18:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.945: INFO: Pod "webserver-deployment-595b5b9587-gcplv" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gcplv webserver-deployment-595b5b9587- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-595b5b9587-gcplv a03c76cc-4350-435c-8345-e02b988c56f0 30680 0 2019-12-03 16:18:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e34bdba5-dd3a-4fe7-85dc-60532bc9b942 0xc008d704c7 0xc008d704c8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:,StartTime:2019-12-03 16:18:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.946: INFO: Pod "webserver-deployment-595b5b9587-gzw4f" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gzw4f webserver-deployment-595b5b9587- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-595b5b9587-gzw4f bbd16662-214e-4488-a392-03f65dca1488 30699 0 2019-12-03 16:18:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e34bdba5-dd3a-4fe7-85dc-60532bc9b942 0xc008d70617 0xc008d70618}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:,StartTime:2019-12-03 16:18:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.946: INFO: Pod "webserver-deployment-595b5b9587-j6dll" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-j6dll webserver-deployment-595b5b9587- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-595b5b9587-j6dll 052d2df0-ad7f-4576-9133-397a9b09ffba 30574 0 2019-12-03 16:18:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.0.64/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e34bdba5-dd3a-4fe7-85dc-60532bc9b942 0xc008d70777 0xc008d70778}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw88vcbd5x6ev7zbjg8vz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.118,PodIP:100.64.0.64,StartTime:2019-12-03 16:18:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 16:18:44 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://7236128886b917d44d05b0101da887c107a4daa0c8223bc5ee888a452b7036b6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.64,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.946: INFO: Pod "webserver-deployment-595b5b9587-mrqzg" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mrqzg webserver-deployment-595b5b9587- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-595b5b9587-mrqzg d17b30a4-b328-4e9f-b4fe-059f93686fdb 30729 0 2019-12-03 16:18:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e34bdba5-dd3a-4fe7-85dc-60532bc9b942 0xc008d708e0 0xc008d708e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw88vcbd5x6ev7zbjg8vz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.118,PodIP:,StartTime:2019-12-03 16:18:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.946: INFO: Pod "webserver-deployment-595b5b9587-mxgx9" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mxgx9 webserver-deployment-595b5b9587- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-595b5b9587-mxgx9 8ebce971-b09d-4ff9-98e6-24503567b383 30577 0 2019-12-03 16:18:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.0.65/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e34bdba5-dd3a-4fe7-85dc-60532bc9b942 0xc008d70a37 0xc008d70a38}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw88vcbd5x6ev7zbjg8vz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.118,PodIP:100.64.0.65,StartTime:2019-12-03 16:18:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 16:18:44 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://33c48511ead41a0a64aa11ba1ca5813d33a5cc769c2445fd06e78482a2c8915d,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.65,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.946: INFO: Pod "webserver-deployment-595b5b9587-nnlph" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-nnlph webserver-deployment-595b5b9587- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-595b5b9587-nnlph d70b2d58-64a1-427e-a9e9-af4153650f0f 30722 0 2019-12-03 16:18:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e34bdba5-dd3a-4fe7-85dc-60532bc9b942 0xc008d70ba0 0xc008d70ba1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:,StartTime:2019-12-03 16:18:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.946: INFO: Pod "webserver-deployment-595b5b9587-r6msk" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-r6msk webserver-deployment-595b5b9587- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-595b5b9587-r6msk 01818270-2c2d-4bf0-bfa5-27ba703dc9b1 30606 0 2019-12-03 16:18:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.1.40/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e34bdba5-dd3a-4fe7-85dc-60532bc9b942 0xc008d70cf7 0xc008d70cf8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:100.64.1.40,StartTime:2019-12-03 16:18:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 16:18:46 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://a17f0fbf2ab20401da8122fda091bab3ecee7a6b3a64397812cd1a3dc99d2c00,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.40,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.947: INFO: Pod "webserver-deployment-595b5b9587-s7nhc" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-s7nhc webserver-deployment-595b5b9587- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-595b5b9587-s7nhc 9e867a34-6d8d-4633-a4ac-b98353d6d624 30585 0 2019-12-03 16:18:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.1.39/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e34bdba5-dd3a-4fe7-85dc-60532bc9b942 0xc008d70e70 0xc008d70e71}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:100.64.1.39,StartTime:2019-12-03 16:18:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 16:18:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://a7d88797a0d62a5589e0e505d548fc4514e11e17bfeb5a7ce5d825082cb31836,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.39,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.947: INFO: Pod "webserver-deployment-595b5b9587-ssgtx" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-ssgtx webserver-deployment-595b5b9587- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-595b5b9587-ssgtx 482a4a66-e632-481c-917c-32acc7da2331 30728 0 2019-12-03 16:18:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e34bdba5-dd3a-4fe7-85dc-60532bc9b942 0xc008d70fd0 0xc008d70fd1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw88vcbd5x6ev7zbjg8vz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.118,PodIP:,StartTime:2019-12-03 16:18:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.947: INFO: Pod "webserver-deployment-595b5b9587-tnrfk" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-tnrfk webserver-deployment-595b5b9587- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-595b5b9587-tnrfk 2eb15420-0ca0-4e55-8e1f-7f183f0ea763 30584 0 2019-12-03 16:18:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.1.37/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e34bdba5-dd3a-4fe7-85dc-60532bc9b942 0xc008d71127 0xc008d71128}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:100.64.1.37,StartTime:2019-12-03 16:18:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 16:18:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://a152d12c8f3f03a5071ca9617cf8a3adcc2c19b9c15b65e63a5ac79cd912b59c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.37,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.947: INFO: Pod "webserver-deployment-595b5b9587-vwqh5" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-vwqh5 webserver-deployment-595b5b9587- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-595b5b9587-vwqh5 6a0dbbfd-fc4d-4b49-8fe5-c363c45f9b50 30730 0 2019-12-03 16:18:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e34bdba5-dd3a-4fe7-85dc-60532bc9b942 0xc008d71290 0xc008d71291}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw88vcbd5x6ev7zbjg8vz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.118,PodIP:,StartTime:2019-12-03 16:18:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.947: INFO: Pod "webserver-deployment-595b5b9587-x286x" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-x286x webserver-deployment-595b5b9587- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-595b5b9587-x286x d62f8f3f-3e76-4a1a-ae74-61d517529766 30582 0 2019-12-03 16:18:43 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.1.36/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e34bdba5-dd3a-4fe7-85dc-60532bc9b942 0xc008d713e7 0xc008d713e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:43 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:100.64.1.36,StartTime:2019-12-03 16:18:43 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 16:18:45 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://977675a4af281c36326818fdb7a6c504732f79feaa80a7a5d1c437625d3eb1f1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.36,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.948: INFO: Pod "webserver-deployment-595b5b9587-zh2sv" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zh2sv webserver-deployment-595b5b9587- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-595b5b9587-zh2sv ed2bb137-4f6b-4a2d-8d9f-0aa6cc3e859f 30724 0 2019-12-03 16:18:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e34bdba5-dd3a-4fe7-85dc-60532bc9b942 0xc008d71550 0xc008d71551}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw88vcbd5x6ev7zbjg8vz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.118,PodIP:,StartTime:2019-12-03 16:18:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.948: INFO: Pod "webserver-deployment-595b5b9587-zwptl" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zwptl webserver-deployment-595b5b9587- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-595b5b9587-zwptl 762d7a9e-a0e6-49a0-8910-48744f6147c0 30703 0 2019-12-03 16:18:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 e34bdba5-dd3a-4fe7-85dc-60532bc9b942 0xc008d71697 0xc008d71698}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:,StartTime:2019-12-03 16:18:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.948: INFO: Pod "webserver-deployment-c7997dcc8-5b4dl" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-5b4dl webserver-deployment-c7997dcc8- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-c7997dcc8-5b4dl b70b9dfe-3162-417d-ae83-886979d7f535 30654 0 2019-12-03 16:18:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:100.64.0.67/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 9253f7fe-9b83-4b02-aa02-c850ea36cc08 0xc008d717f7 0xc008d717f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw88vcbd5x6ev7zbjg8vz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.118,PodIP:,StartTime:2019-12-03 16:18:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.948: INFO: Pod "webserver-deployment-c7997dcc8-5ghlw" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-5ghlw webserver-deployment-c7997dcc8- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-c7997dcc8-5ghlw 89f435e9-76a5-473a-99c9-b7e5e169aeac 30679 0 2019-12-03 16:18:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 9253f7fe-9b83-4b02-aa02-c850ea36cc08 0xc008d71967 0xc008d71968}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw88vcbd5x6ev7zbjg8vz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.118,PodIP:,StartTime:2019-12-03 16:18:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.948: INFO: Pod "webserver-deployment-c7997dcc8-6mvzz" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-6mvzz webserver-deployment-c7997dcc8- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-c7997dcc8-6mvzz 6588c900-a2f8-448a-b75b-4e61060c1b49 30725 0 2019-12-03 16:18:51 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 9253f7fe-9b83-4b02-aa02-c850ea36cc08 0xc008d71ad7 0xc008d71ad8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw88vcbd5x6ev7zbjg8vz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.118,PodIP:,StartTime:2019-12-03 16:18:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.949: INFO: Pod "webserver-deployment-c7997dcc8-cxk6f" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-cxk6f webserver-deployment-c7997dcc8- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-c7997dcc8-cxk6f 240ae19e-0352-4472-9823-58be31872c06 30700 0 2019-12-03 16:18:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 9253f7fe-9b83-4b02-aa02-c850ea36cc08 0xc008d71c47 0xc008d71c48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:,StartTime:2019-12-03 16:18:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.949: INFO: Pod "webserver-deployment-c7997dcc8-d65x9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-d65x9 webserver-deployment-c7997dcc8- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-c7997dcc8-d65x9 b3ea7cdb-5398-41e3-a940-de62c88641ed 30701 0 2019-12-03 16:18:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 9253f7fe-9b83-4b02-aa02-c850ea36cc08 0xc008d71db7 0xc008d71db8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:,StartTime:2019-12-03 16:18:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.949: INFO: Pod "webserver-deployment-c7997dcc8-ghsm8" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-ghsm8 webserver-deployment-c7997dcc8- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-c7997dcc8-ghsm8 3ed2cc88-5e59-433b-9ff5-5cd6e9bc1537 30737 0 2019-12-03 16:18:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:100.64.1.47/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 9253f7fe-9b83-4b02-aa02-c850ea36cc08 0xc008d71f47 0xc008d71f48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:,StartTime:2019-12-03 16:18:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.949: INFO: Pod "webserver-deployment-c7997dcc8-gw6pv" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-gw6pv webserver-deployment-c7997dcc8- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-c7997dcc8-gw6pv 9c609ff7-478d-4823-b3a5-0bace264e15f 30698 0 2019-12-03 16:18:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 9253f7fe-9b83-4b02-aa02-c850ea36cc08 0xc0037f8137 0xc0037f8138}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw88vcbd5x6ev7zbjg8vz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.118,PodIP:,StartTime:2019-12-03 16:18:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.949: INFO: Pod "webserver-deployment-c7997dcc8-jqzx9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-jqzx9 webserver-deployment-c7997dcc8- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-c7997dcc8-jqzx9 04a497b1-7d8b-4a3c-a864-f872dc10de47 30656 0 2019-12-03 16:18:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:100.64.1.44/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 9253f7fe-9b83-4b02-aa02-c850ea36cc08 0xc0037f82b7 0xc0037f82b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:48 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:48 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:,StartTime:2019-12-03 16:18:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.950: INFO: Pod "webserver-deployment-c7997dcc8-nsjxx" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-nsjxx webserver-deployment-c7997dcc8- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-c7997dcc8-nsjxx fb7c1836-a145-4e83-bc23-98d00379fbf5 30657 0 2019-12-03 16:18:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:100.64.1.45/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 9253f7fe-9b83-4b02-aa02-c850ea36cc08 0xc0037f8437 0xc0037f8438}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:48 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:48 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:,StartTime:2019-12-03 16:18:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.950: INFO: Pod "webserver-deployment-c7997dcc8-r7wmd" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-r7wmd webserver-deployment-c7997dcc8- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-c7997dcc8-r7wmd e50eb8a0-7e71-4797-a526-f33b60c256e7 30740 0 2019-12-03 16:18:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:100.64.1.48/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 9253f7fe-9b83-4b02-aa02-c850ea36cc08 0xc0037f85b7 0xc0037f85b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:,StartTime:2019-12-03 16:18:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.950: INFO: Pod "webserver-deployment-c7997dcc8-twxcs" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-twxcs webserver-deployment-c7997dcc8- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-c7997dcc8-twxcs e0af45c0-c369-4552-bc3a-81f51fa9a26d 30732 0 2019-12-03 16:18:48 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:100.64.0.66/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 9253f7fe-9b83-4b02-aa02-c850ea36cc08 0xc0037f8747 0xc0037f8748}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw88vcbd5x6ev7zbjg8vz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:48 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:48 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:48 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:48 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.118,PodIP:100.64.0.66,StartTime:2019-12-03 16:18:48 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ErrImagePull,Message:rpc error: code = Unknown desc = Error response from daemon: pull access denied for webserver, repository does not exist or may require 'docker login',},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.66,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.950: INFO: Pod "webserver-deployment-c7997dcc8-v9rj2" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-v9rj2 webserver-deployment-c7997dcc8- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-c7997dcc8-v9rj2 b4e17a17-330d-42d3-9c9a-5d6373eaaebe 30705 0 2019-12-03 16:18:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 9253f7fe-9b83-4b02-aa02-c850ea36cc08 0xc0037f88e0 0xc0037f88e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw88vcbd5x6ev7zbjg8vz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:51 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.118,PodIP:,StartTime:2019-12-03 16:18:51 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 16:18:52.951: INFO: Pod "webserver-deployment-c7997dcc8-vhpmr" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-vhpmr webserver-deployment-c7997dcc8- deployment-9662 /api/v1/namespaces/deployment-9662/pods/webserver-deployment-c7997dcc8-vhpmr 4901ca42-fe3b-4404-b417-4337e4758693 30658 0 2019-12-03 16:18:49 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:100.64.1.46/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 9253f7fe-9b83-4b02-aa02-c850ea36cc08 0xc0037f8a67 0xc0037f8a68}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-q85nq,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-q85nq,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-q85nq,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:49 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:49 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:18:49 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:,StartTime:2019-12-03 16:18:49 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:18:52.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9662" for this suite.
Dec  3 16:19:02.973: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:19:03.162: INFO: namespace deployment-9662 deletion completed in 10.206340617s
•SSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:19:03.162: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3606
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-41a273ac-5e38-4706-b1a9-2283c6bbb67a
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-41a273ac-5e38-4706-b1a9-2283c6bbb67a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:20:44.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3606" for this suite.
Dec  3 16:20:58.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:20:58.547: INFO: namespace configmap-3606 deletion completed in 14.157222523s
•S
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:20:58.548: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5776
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  3 16:21:01.023: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:21:01.034: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5776" for this suite.
Dec  3 16:21:07.055: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:21:07.198: INFO: namespace container-runtime-5776 deletion completed in 6.15681814s
•SSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:21:07.198: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-486
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-486
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec  3 16:21:07.803: INFO: Found 0 stateful pods, waiting for 3
Dec  3 16:21:17.810: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:21:17.810: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:21:17.810: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:21:17.824: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-486 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:21:18.472: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:21:18.472: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:21:18.472: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec  3 16:21:28.513: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec  3 16:21:38.538: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-486 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:21:39.239: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 16:21:39.239: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 16:21:39.239: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 16:21:49.268: INFO: Waiting for StatefulSet statefulset-486/ss2 to complete update
Dec  3 16:21:49.268: INFO: Waiting for Pod statefulset-486/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  3 16:21:49.268: INFO: Waiting for Pod statefulset-486/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  3 16:21:59.278: INFO: Waiting for StatefulSet statefulset-486/ss2 to complete update
Dec  3 16:21:59.278: INFO: Waiting for Pod statefulset-486/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Dec  3 16:22:09.279: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-486 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:22:09.832: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:22:09.832: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:22:09.832: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 16:22:19.872: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec  3 16:22:29.895: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-486 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:22:30.542: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 16:22:30.542: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 16:22:30.542: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 16:22:50.574: INFO: Waiting for StatefulSet statefulset-486/ss2 to complete update
Dec  3 16:22:50.574: INFO: Waiting for Pod statefulset-486/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  3 16:23:00.584: INFO: Deleting all statefulset in ns statefulset-486
Dec  3 16:23:00.588: INFO: Scaling statefulset ss2 to 0
Dec  3 16:23:10.607: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 16:23:10.611: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:23:10.625: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-486" for this suite.
Dec  3 16:23:16.649: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:23:16.797: INFO: namespace statefulset-486 deletion completed in 6.165111583s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:23:16.798: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8321
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:23:17.096: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:23:19.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8321" for this suite.
Dec  3 16:24:09.395: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:24:09.535: INFO: namespace pods-8321 deletion completed in 50.154535852s
•SS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:24:09.535: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-6265
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Dec  3 16:24:09.996: INFO: Waiting up to 5m0s for pod "var-expansion-11d1046a-8a81-4f21-8a39-cb0f015ced37" in namespace "var-expansion-6265" to be "success or failure"
Dec  3 16:24:10.000: INFO: Pod "var-expansion-11d1046a-8a81-4f21-8a39-cb0f015ced37": Phase="Pending", Reason="", readiness=false. Elapsed: 4.232778ms
Dec  3 16:24:12.006: INFO: Pod "var-expansion-11d1046a-8a81-4f21-8a39-cb0f015ced37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009665583s
STEP: Saw pod success
Dec  3 16:24:12.006: INFO: Pod "var-expansion-11d1046a-8a81-4f21-8a39-cb0f015ced37" satisfied condition "success or failure"
Dec  3 16:24:12.010: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod var-expansion-11d1046a-8a81-4f21-8a39-cb0f015ced37 container dapi-container: <nil>
STEP: delete the pod
Dec  3 16:24:12.167: INFO: Waiting for pod var-expansion-11d1046a-8a81-4f21-8a39-cb0f015ced37 to disappear
Dec  3 16:24:12.171: INFO: Pod var-expansion-11d1046a-8a81-4f21-8a39-cb0f015ced37 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:24:12.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-6265" for this suite.
Dec  3 16:24:20.193: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:24:20.338: INFO: namespace var-expansion-6265 deletion completed in 8.159088723s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:24:20.338: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-949
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:24:20.594: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:24:21.121: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-949" for this suite.
Dec  3 16:24:27.142: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:24:27.325: INFO: namespace custom-resource-definition-949 deletion completed in 6.197003391s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:24:27.326: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5643
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-c6bcb085-4860-4ec8-8ae2-7c5189594c65
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:24:27.597: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5643" for this suite.
Dec  3 16:24:35.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:24:35.758: INFO: namespace configmap-5643 deletion completed in 8.154915418s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:24:35.759: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-910
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 16:24:37.341: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 16:24:40.364: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:24:40.370: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:24:41.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-910" for this suite.
Dec  3 16:24:47.405: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:24:47.549: INFO: namespace webhook-910 deletion completed in 6.159083918s
STEP: Destroying namespace "webhook-910-markers" for this suite.
Dec  3 16:24:53.566: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:24:53.710: INFO: namespace webhook-910-markers deletion completed in 6.1604571s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:24:53.729: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-542
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-542
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-542
STEP: Deleting pre-stop pod
Dec  3 16:25:03.293: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:25:03.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-542" for this suite.
Dec  3 16:25:47.320: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:25:47.499: INFO: namespace prestop-542 deletion completed in 44.192345538s
•SSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:25:47.499: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2113
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2113.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-2113.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2113.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-2113.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-2113.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-2113.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 16:25:50.412: INFO: DNS probes using dns-2113/dns-test-ae599bc9-df85-4b0e-b7a5-e63d1617c5ee succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:25:50.421: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2113" for this suite.
Dec  3 16:25:56.442: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:25:56.592: INFO: namespace dns-2113 deletion completed in 6.16364569s
•SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:25:56.592: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-215
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 16:25:57.532: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 16:26:00.556: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:26:00.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-215" for this suite.
Dec  3 16:26:06.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:26:06.970: INFO: namespace webhook-215 deletion completed in 6.15884757s
STEP: Destroying namespace "webhook-215-markers" for this suite.
Dec  3 16:26:12.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:26:13.166: INFO: namespace webhook-215-markers deletion completed in 6.195327044s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:26:13.184: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4407
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Dec  3 16:26:13.689: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-4407 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec  3 16:26:16.419: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec  3 16:26:16.419: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:26:18.428: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4407" for this suite.
Dec  3 16:26:30.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:26:30.586: INFO: namespace kubectl-4407 deletion completed in 12.15094762s
•S
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:26:30.586: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-803
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:26:30.893: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec  3 16:26:30.902: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec  3 16:26:35.908: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  3 16:26:35.908: INFO: Creating deployment "test-rolling-update-deployment"
Dec  3 16:26:35.913: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec  3 16:26:35.921: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec  3 16:26:37.931: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec  3 16:26:37.935: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec  3 16:26:37.948: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-803 /apis/apps/v1/namespaces/deployment-803/deployments/test-rolling-update-deployment 54056249-eb63-4ab5-a09b-399b6b3edc97 32929 1 2019-12-03 16:26:35 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0073ed778 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-03 16:26:35 +0000 UTC,LastTransitionTime:2019-12-03 16:26:35 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2019-12-03 16:26:36 +0000 UTC,LastTransitionTime:2019-12-03 16:26:35 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 16:26:37.952: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-803 /apis/apps/v1/namespaces/deployment-803/replicasets/test-rolling-update-deployment-55d946486 2207c40b-8e92-4c89-bbca-0eaba63139ce 32922 1 2019-12-03 16:26:35 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment 54056249-eb63-4ab5-a09b-399b6b3edc97 0xc0073edc40 0xc0073edc41}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0073edca8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec  3 16:26:37.952: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec  3 16:26:37.953: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-803 /apis/apps/v1/namespaces/deployment-803/replicasets/test-rolling-update-controller 2546f47a-0909-49b0-89a1-6cd00dc29797 32928 2 2019-12-03 16:26:30 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment 54056249-eb63-4ab5-a09b-399b6b3edc97 0xc0073edb77 0xc0073edb78}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0073edbd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 16:26:37.957: INFO: Pod "test-rolling-update-deployment-55d946486-4m6kk" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-4m6kk test-rolling-update-deployment-55d946486- deployment-803 /api/v1/namespaces/deployment-803/pods/test-rolling-update-deployment-55d946486-4m6kk 6ebc6e66-1762-481d-bdac-1a46ff76c3da 32921 0 2019-12-03 16:26:35 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[cni.projectcalico.org/podIP:100.64.1.76/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 2207c40b-8e92-4c89-bbca-0eaba63139ce 0xc001fb8ef0 0xc001fb8ef1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-649dt,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-649dt,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-649dt,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:izgw8fisrtg04goc4t8tqaz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:26:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:26:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:26:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:26:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.2.117,PodIP:100.64.1.76,StartTime:2019-12-03 16:26:35 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 16:26:36 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://89ab108e6fc85655f80363b0b7105c6cdc0192760afebf04b783b4abd1e7660b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.76,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:26:37.957: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-803" for this suite.
Dec  3 16:26:45.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:26:46.115: INFO: namespace deployment-803 deletion completed in 8.150528451s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:26:46.115: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-1746
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:26:49.429: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-1746" for this suite.
Dec  3 16:27:17.451: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:27:17.732: INFO: namespace replication-controller-1746 deletion completed in 28.294755821s
•
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:27:17.732: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5098
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-d469eec0-9003-42b8-9975-2a2d28a95bc4
STEP: Creating a pod to test consume configMaps
Dec  3 16:27:18.110: INFO: Waiting up to 5m0s for pod "pod-configmaps-808dcdf3-e449-49a0-80d1-8dce5ed30355" in namespace "configmap-5098" to be "success or failure"
Dec  3 16:27:18.115: INFO: Pod "pod-configmaps-808dcdf3-e449-49a0-80d1-8dce5ed30355": Phase="Pending", Reason="", readiness=false. Elapsed: 4.511996ms
Dec  3 16:27:20.120: INFO: Pod "pod-configmaps-808dcdf3-e449-49a0-80d1-8dce5ed30355": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009499089s
STEP: Saw pod success
Dec  3 16:27:20.120: INFO: Pod "pod-configmaps-808dcdf3-e449-49a0-80d1-8dce5ed30355" satisfied condition "success or failure"
Dec  3 16:27:20.124: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-configmaps-808dcdf3-e449-49a0-80d1-8dce5ed30355 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 16:27:20.285: INFO: Waiting for pod pod-configmaps-808dcdf3-e449-49a0-80d1-8dce5ed30355 to disappear
Dec  3 16:27:20.289: INFO: Pod pod-configmaps-808dcdf3-e449-49a0-80d1-8dce5ed30355 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:27:20.289: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5098" for this suite.
Dec  3 16:27:26.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:27:26.448: INFO: namespace configmap-5098 deletion completed in 6.151371158s
•SSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:27:26.448: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-757
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec  3 16:27:27.315: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-757 /api/v1/namespaces/watch-757/configmaps/e2e-watch-test-label-changed abc6e9ec-ac35-4ab9-93e0-7272abb9dd2a 33150 0 2019-12-03 16:27:27 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 16:27:27.315: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-757 /api/v1/namespaces/watch-757/configmaps/e2e-watch-test-label-changed abc6e9ec-ac35-4ab9-93e0-7272abb9dd2a 33151 0 2019-12-03 16:27:27 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  3 16:27:27.315: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-757 /api/v1/namespaces/watch-757/configmaps/e2e-watch-test-label-changed abc6e9ec-ac35-4ab9-93e0-7272abb9dd2a 33152 0 2019-12-03 16:27:27 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec  3 16:27:37.349: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-757 /api/v1/namespaces/watch-757/configmaps/e2e-watch-test-label-changed abc6e9ec-ac35-4ab9-93e0-7272abb9dd2a 33187 0 2019-12-03 16:27:27 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 16:27:37.349: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-757 /api/v1/namespaces/watch-757/configmaps/e2e-watch-test-label-changed abc6e9ec-ac35-4ab9-93e0-7272abb9dd2a 33188 0 2019-12-03 16:27:27 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec  3 16:27:37.349: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-757 /api/v1/namespaces/watch-757/configmaps/e2e-watch-test-label-changed abc6e9ec-ac35-4ab9-93e0-7272abb9dd2a 33189 0 2019-12-03 16:27:27 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:27:37.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-757" for this suite.
Dec  3 16:27:43.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:27:43.515: INFO: namespace watch-757 deletion completed in 6.158299386s
•SSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:27:43.515: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-44
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Dec  3 16:27:43.803: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-44" to be "success or failure"
Dec  3 16:27:43.807: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.029952ms
Dec  3 16:27:45.812: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009220722s
STEP: Saw pod success
Dec  3 16:27:45.812: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec  3 16:27:45.817: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec  3 16:27:45.838: INFO: Waiting for pod pod-host-path-test to disappear
Dec  3 16:27:45.841: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:27:45.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-44" for this suite.
Dec  3 16:27:53.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:27:54.007: INFO: namespace hostpath-44 deletion completed in 8.158242947s
•S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:27:54.007: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2132
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Dec  3 16:27:54.398: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 16:27:59.108: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:28:17.956: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2132" for this suite.
Dec  3 16:28:23.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:28:24.133: INFO: namespace crd-publish-openapi-2132 deletion completed in 6.169719732s
•S
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:28:24.133: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-2517
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-2517
I1203 16:28:24.400672    5091 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-2517, replica count: 1
I1203 16:28:25.451460    5091 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 16:28:26.451671    5091 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 16:28:26.560: INFO: Created: latency-svc-kgh7t
Dec  3 16:28:26.564: INFO: Got endpoints: latency-svc-kgh7t [12.692153ms]
Dec  3 16:28:26.576: INFO: Created: latency-svc-7zk6h
Dec  3 16:28:26.578: INFO: Got endpoints: latency-svc-7zk6h [13.290365ms]
Dec  3 16:28:26.578: INFO: Created: latency-svc-wgftf
Dec  3 16:28:26.581: INFO: Got endpoints: latency-svc-wgftf [16.116082ms]
Dec  3 16:28:26.581: INFO: Created: latency-svc-mtx6q
Dec  3 16:28:26.583: INFO: Got endpoints: latency-svc-mtx6q [18.075246ms]
Dec  3 16:28:26.586: INFO: Created: latency-svc-nj2hm
Dec  3 16:28:26.589: INFO: Got endpoints: latency-svc-nj2hm [24.077773ms]
Dec  3 16:28:26.589: INFO: Created: latency-svc-d22wb
Dec  3 16:28:26.592: INFO: Got endpoints: latency-svc-d22wb [27.592966ms]
Dec  3 16:28:26.592: INFO: Created: latency-svc-lz5pl
Dec  3 16:28:26.594: INFO: Got endpoints: latency-svc-lz5pl [29.222679ms]
Dec  3 16:28:26.596: INFO: Created: latency-svc-z5pml
Dec  3 16:28:26.599: INFO: Got endpoints: latency-svc-z5pml [33.885896ms]
Dec  3 16:28:26.612: INFO: Created: latency-svc-65mp9
Dec  3 16:28:26.612: INFO: Created: latency-svc-jsqns
Dec  3 16:28:26.612: INFO: Got endpoints: latency-svc-65mp9 [46.808357ms]
Dec  3 16:28:26.613: INFO: Got endpoints: latency-svc-jsqns [19.445302ms]
Dec  3 16:28:26.616: INFO: Created: latency-svc-lghlq
Dec  3 16:28:26.619: INFO: Got endpoints: latency-svc-lghlq [54.383855ms]
Dec  3 16:28:26.620: INFO: Created: latency-svc-pt8xk
Dec  3 16:28:26.622: INFO: Got endpoints: latency-svc-pt8xk [57.372547ms]
Dec  3 16:28:26.624: INFO: Created: latency-svc-qktrl
Dec  3 16:28:26.632: INFO: Got endpoints: latency-svc-qktrl [66.974258ms]
Dec  3 16:28:26.633: INFO: Created: latency-svc-mgrpd
Dec  3 16:28:26.637: INFO: Created: latency-svc-g4dlq
Dec  3 16:28:26.640: INFO: Created: latency-svc-ddwxm
Dec  3 16:28:26.644: INFO: Created: latency-svc-cfz5l
Dec  3 16:28:26.647: INFO: Created: latency-svc-hm4tf
Dec  3 16:28:26.650: INFO: Created: latency-svc-pfzgg
Dec  3 16:28:26.681: INFO: Got endpoints: latency-svc-pfzgg [100.310895ms]
Dec  3 16:28:26.682: INFO: Got endpoints: latency-svc-hm4tf [104.062265ms]
Dec  3 16:28:26.682: INFO: Got endpoints: latency-svc-cfz5l [117.061216ms]
Dec  3 16:28:26.682: INFO: Got endpoints: latency-svc-g4dlq [117.336186ms]
Dec  3 16:28:26.682: INFO: Got endpoints: latency-svc-mgrpd [117.480241ms]
Dec  3 16:28:26.683: INFO: Got endpoints: latency-svc-ddwxm [117.682873ms]
Dec  3 16:28:26.683: INFO: Created: latency-svc-8x8qg
Dec  3 16:28:26.686: INFO: Got endpoints: latency-svc-8x8qg [103.04458ms]
Dec  3 16:28:26.688: INFO: Created: latency-svc-cdxps
Dec  3 16:28:26.691: INFO: Got endpoints: latency-svc-cdxps [102.265449ms]
Dec  3 16:28:26.691: INFO: Created: latency-svc-m5cg8
Dec  3 16:28:26.693: INFO: Got endpoints: latency-svc-m5cg8 [100.556536ms]
Dec  3 16:28:26.696: INFO: Created: latency-svc-ql8b9
Dec  3 16:28:26.698: INFO: Got endpoints: latency-svc-ql8b9 [99.36195ms]
Dec  3 16:28:26.699: INFO: Created: latency-svc-ct4wp
Dec  3 16:28:26.700: INFO: Got endpoints: latency-svc-ct4wp [88.247019ms]
Dec  3 16:28:26.703: INFO: Created: latency-svc-fx6t7
Dec  3 16:28:26.704: INFO: Got endpoints: latency-svc-fx6t7 [90.278606ms]
Dec  3 16:28:26.707: INFO: Created: latency-svc-c8lhs
Dec  3 16:28:26.709: INFO: Got endpoints: latency-svc-c8lhs [89.588055ms]
Dec  3 16:28:26.711: INFO: Created: latency-svc-lhvmr
Dec  3 16:28:26.712: INFO: Got endpoints: latency-svc-lhvmr [90.456753ms]
Dec  3 16:28:26.714: INFO: Created: latency-svc-sq2x8
Dec  3 16:28:26.717: INFO: Got endpoints: latency-svc-sq2x8 [85.169158ms]
Dec  3 16:28:26.718: INFO: Created: latency-svc-bpq7p
Dec  3 16:28:26.723: INFO: Created: latency-svc-g9bh5
Dec  3 16:28:26.724: INFO: Created: latency-svc-ctjmw
Dec  3 16:28:26.727: INFO: Created: latency-svc-wvknq
Dec  3 16:28:26.731: INFO: Created: latency-svc-w5zgz
Dec  3 16:28:26.741: INFO: Created: latency-svc-j7k5b
Dec  3 16:28:26.746: INFO: Created: latency-svc-hxxpl
Dec  3 16:28:26.748: INFO: Created: latency-svc-nhvw9
Dec  3 16:28:26.752: INFO: Created: latency-svc-shcxm
Dec  3 16:28:26.755: INFO: Created: latency-svc-h4dm6
Dec  3 16:28:26.759: INFO: Created: latency-svc-jkr79
Dec  3 16:28:26.763: INFO: Created: latency-svc-bq9pb
Dec  3 16:28:26.766: INFO: Created: latency-svc-9nnff
Dec  3 16:28:26.771: INFO: Created: latency-svc-7754r
Dec  3 16:28:26.773: INFO: Created: latency-svc-wrlvh
Dec  3 16:28:26.775: INFO: Got endpoints: latency-svc-ctjmw [93.272892ms]
Dec  3 16:28:26.776: INFO: Got endpoints: latency-svc-bpq7p [93.587871ms]
Dec  3 16:28:26.776: INFO: Got endpoints: latency-svc-wvknq [94.391544ms]
Dec  3 16:28:26.776: INFO: Got endpoints: latency-svc-w5zgz [94.992805ms]
Dec  3 16:28:26.777: INFO: Got endpoints: latency-svc-g9bh5 [94.17922ms]
Dec  3 16:28:26.777: INFO: Got endpoints: latency-svc-j7k5b [94.569936ms]
Dec  3 16:28:26.784: INFO: Created: latency-svc-jw2kz
Dec  3 16:28:26.788: INFO: Created: latency-svc-bw8qb
Dec  3 16:28:26.792: INFO: Created: latency-svc-2vbhw
Dec  3 16:28:26.797: INFO: Created: latency-svc-zz9p7
Dec  3 16:28:26.801: INFO: Created: latency-svc-7q7xh
Dec  3 16:28:26.805: INFO: Created: latency-svc-2fnbc
Dec  3 16:28:26.813: INFO: Got endpoints: latency-svc-hxxpl [126.894994ms]
Dec  3 16:28:26.821: INFO: Created: latency-svc-vvwfq
Dec  3 16:28:26.864: INFO: Got endpoints: latency-svc-nhvw9 [172.746361ms]
Dec  3 16:28:26.874: INFO: Created: latency-svc-v775j
Dec  3 16:28:26.914: INFO: Got endpoints: latency-svc-shcxm [220.721212ms]
Dec  3 16:28:26.922: INFO: Created: latency-svc-6x685
Dec  3 16:28:26.964: INFO: Got endpoints: latency-svc-h4dm6 [265.510264ms]
Dec  3 16:28:26.972: INFO: Created: latency-svc-pktnn
Dec  3 16:28:27.014: INFO: Got endpoints: latency-svc-jkr79 [313.868487ms]
Dec  3 16:28:27.023: INFO: Created: latency-svc-dx76x
Dec  3 16:28:27.064: INFO: Got endpoints: latency-svc-bq9pb [360.126904ms]
Dec  3 16:28:27.073: INFO: Created: latency-svc-qvnn7
Dec  3 16:28:27.114: INFO: Got endpoints: latency-svc-9nnff [405.098909ms]
Dec  3 16:28:27.123: INFO: Created: latency-svc-98x27
Dec  3 16:28:27.164: INFO: Got endpoints: latency-svc-7754r [451.358051ms]
Dec  3 16:28:27.172: INFO: Created: latency-svc-l2qn5
Dec  3 16:28:27.214: INFO: Got endpoints: latency-svc-wrlvh [496.515647ms]
Dec  3 16:28:27.234: INFO: Created: latency-svc-b4nvg
Dec  3 16:28:27.264: INFO: Got endpoints: latency-svc-jw2kz [488.330932ms]
Dec  3 16:28:27.272: INFO: Created: latency-svc-srghz
Dec  3 16:28:27.314: INFO: Got endpoints: latency-svc-bw8qb [537.64274ms]
Dec  3 16:28:27.322: INFO: Created: latency-svc-mn65b
Dec  3 16:28:27.376: INFO: Got endpoints: latency-svc-2vbhw [599.587789ms]
Dec  3 16:28:27.384: INFO: Created: latency-svc-x7w4f
Dec  3 16:28:27.413: INFO: Got endpoints: latency-svc-zz9p7 [636.646009ms]
Dec  3 16:28:27.423: INFO: Created: latency-svc-sjhzz
Dec  3 16:28:27.464: INFO: Got endpoints: latency-svc-7q7xh [687.747346ms]
Dec  3 16:28:27.473: INFO: Created: latency-svc-5cbsg
Dec  3 16:28:27.514: INFO: Got endpoints: latency-svc-2fnbc [736.220364ms]
Dec  3 16:28:27.522: INFO: Created: latency-svc-z9gkv
Dec  3 16:28:27.564: INFO: Got endpoints: latency-svc-vvwfq [751.443896ms]
Dec  3 16:28:27.573: INFO: Created: latency-svc-xx4h6
Dec  3 16:28:27.613: INFO: Got endpoints: latency-svc-v775j [749.673356ms]
Dec  3 16:28:27.625: INFO: Created: latency-svc-9f9rg
Dec  3 16:28:27.666: INFO: Got endpoints: latency-svc-6x685 [751.900004ms]
Dec  3 16:28:27.690: INFO: Created: latency-svc-hrtzv
Dec  3 16:28:27.713: INFO: Got endpoints: latency-svc-pktnn [749.766666ms]
Dec  3 16:28:27.722: INFO: Created: latency-svc-776hh
Dec  3 16:28:27.765: INFO: Got endpoints: latency-svc-dx76x [750.711982ms]
Dec  3 16:28:27.773: INFO: Created: latency-svc-vxcg5
Dec  3 16:28:27.814: INFO: Got endpoints: latency-svc-qvnn7 [749.478441ms]
Dec  3 16:28:27.823: INFO: Created: latency-svc-g2vnt
Dec  3 16:28:27.864: INFO: Got endpoints: latency-svc-98x27 [749.440757ms]
Dec  3 16:28:27.873: INFO: Created: latency-svc-wgrv9
Dec  3 16:28:27.914: INFO: Got endpoints: latency-svc-l2qn5 [750.346597ms]
Dec  3 16:28:27.926: INFO: Created: latency-svc-8jgz2
Dec  3 16:28:27.964: INFO: Got endpoints: latency-svc-b4nvg [750.072594ms]
Dec  3 16:28:27.973: INFO: Created: latency-svc-jvgr7
Dec  3 16:28:28.013: INFO: Got endpoints: latency-svc-srghz [749.530901ms]
Dec  3 16:28:28.022: INFO: Created: latency-svc-xtdnc
Dec  3 16:28:28.085: INFO: Got endpoints: latency-svc-mn65b [771.349681ms]
Dec  3 16:28:28.095: INFO: Created: latency-svc-r4gq5
Dec  3 16:28:28.113: INFO: Got endpoints: latency-svc-x7w4f [737.182149ms]
Dec  3 16:28:28.121: INFO: Created: latency-svc-mh2cd
Dec  3 16:28:28.166: INFO: Got endpoints: latency-svc-sjhzz [752.562478ms]
Dec  3 16:28:28.175: INFO: Created: latency-svc-7ttql
Dec  3 16:28:28.275: INFO: Got endpoints: latency-svc-z9gkv [761.925695ms]
Dec  3 16:28:28.276: INFO: Got endpoints: latency-svc-5cbsg [811.69543ms]
Dec  3 16:28:28.283: INFO: Created: latency-svc-wf9cc
Dec  3 16:28:28.286: INFO: Created: latency-svc-p9vv9
Dec  3 16:28:28.313: INFO: Got endpoints: latency-svc-xx4h6 [748.814444ms]
Dec  3 16:28:28.322: INFO: Created: latency-svc-bwqt6
Dec  3 16:28:28.363: INFO: Got endpoints: latency-svc-9f9rg [749.822245ms]
Dec  3 16:28:28.371: INFO: Created: latency-svc-rxcwv
Dec  3 16:28:28.413: INFO: Got endpoints: latency-svc-hrtzv [747.794218ms]
Dec  3 16:28:28.423: INFO: Created: latency-svc-zh8dm
Dec  3 16:28:28.463: INFO: Got endpoints: latency-svc-776hh [749.86852ms]
Dec  3 16:28:28.472: INFO: Created: latency-svc-pdr4r
Dec  3 16:28:28.575: INFO: Got endpoints: latency-svc-g2vnt [761.837554ms]
Dec  3 16:28:28.576: INFO: Got endpoints: latency-svc-vxcg5 [811.364885ms]
Dec  3 16:28:28.584: INFO: Created: latency-svc-r72rq
Dec  3 16:28:28.587: INFO: Created: latency-svc-br5rr
Dec  3 16:28:28.677: INFO: Got endpoints: latency-svc-jvgr7 [713.218114ms]
Dec  3 16:28:28.678: INFO: Got endpoints: latency-svc-wgrv9 [814.233711ms]
Dec  3 16:28:28.685: INFO: Created: latency-svc-sw4bj
Dec  3 16:28:28.689: INFO: Created: latency-svc-jrl7z
Dec  3 16:28:28.776: INFO: Got endpoints: latency-svc-8jgz2 [862.144768ms]
Dec  3 16:28:28.777: INFO: Got endpoints: latency-svc-xtdnc [763.13654ms]
Dec  3 16:28:28.785: INFO: Created: latency-svc-v2945
Dec  3 16:28:28.789: INFO: Created: latency-svc-sn44s
Dec  3 16:28:28.815: INFO: Got endpoints: latency-svc-r4gq5 [729.55488ms]
Dec  3 16:28:28.824: INFO: Created: latency-svc-rgzck
Dec  3 16:28:28.864: INFO: Got endpoints: latency-svc-mh2cd [750.262419ms]
Dec  3 16:28:28.872: INFO: Created: latency-svc-sc2pf
Dec  3 16:28:28.913: INFO: Got endpoints: latency-svc-7ttql [747.348566ms]
Dec  3 16:28:28.922: INFO: Created: latency-svc-hctl2
Dec  3 16:28:28.963: INFO: Got endpoints: latency-svc-wf9cc [687.900808ms]
Dec  3 16:28:28.972: INFO: Created: latency-svc-v2b99
Dec  3 16:28:29.076: INFO: Got endpoints: latency-svc-bwqt6 [762.122489ms]
Dec  3 16:28:29.076: INFO: Got endpoints: latency-svc-p9vv9 [799.940637ms]
Dec  3 16:28:29.084: INFO: Created: latency-svc-8gjhg
Dec  3 16:28:29.088: INFO: Created: latency-svc-w8jw6
Dec  3 16:28:29.113: INFO: Got endpoints: latency-svc-rxcwv [749.822529ms]
Dec  3 16:28:29.124: INFO: Created: latency-svc-dqqc8
Dec  3 16:28:29.165: INFO: Got endpoints: latency-svc-zh8dm [751.542536ms]
Dec  3 16:28:29.174: INFO: Created: latency-svc-t2w98
Dec  3 16:28:29.214: INFO: Got endpoints: latency-svc-pdr4r [750.499177ms]
Dec  3 16:28:29.223: INFO: Created: latency-svc-gjbbv
Dec  3 16:28:29.263: INFO: Got endpoints: latency-svc-r72rq [687.942652ms]
Dec  3 16:28:29.273: INFO: Created: latency-svc-f24hv
Dec  3 16:28:29.376: INFO: Got endpoints: latency-svc-sw4bj [699.107174ms]
Dec  3 16:28:29.377: INFO: Got endpoints: latency-svc-br5rr [800.550164ms]
Dec  3 16:28:29.385: INFO: Created: latency-svc-mgfb6
Dec  3 16:28:29.389: INFO: Created: latency-svc-xqgkn
Dec  3 16:28:29.413: INFO: Got endpoints: latency-svc-jrl7z [735.244413ms]
Dec  3 16:28:29.421: INFO: Created: latency-svc-lgg9c
Dec  3 16:28:29.464: INFO: Got endpoints: latency-svc-v2945 [686.914014ms]
Dec  3 16:28:29.474: INFO: Created: latency-svc-sqvp4
Dec  3 16:28:29.514: INFO: Got endpoints: latency-svc-sn44s [736.863058ms]
Dec  3 16:28:29.522: INFO: Created: latency-svc-d54f2
Dec  3 16:28:29.563: INFO: Got endpoints: latency-svc-rgzck [748.533082ms]
Dec  3 16:28:29.571: INFO: Created: latency-svc-vhs49
Dec  3 16:28:29.613: INFO: Got endpoints: latency-svc-sc2pf [749.7233ms]
Dec  3 16:28:29.627: INFO: Created: latency-svc-jxvzc
Dec  3 16:28:29.663: INFO: Got endpoints: latency-svc-hctl2 [749.849684ms]
Dec  3 16:28:29.672: INFO: Created: latency-svc-4q92h
Dec  3 16:28:29.714: INFO: Got endpoints: latency-svc-v2b99 [750.153653ms]
Dec  3 16:28:29.722: INFO: Created: latency-svc-qnv6v
Dec  3 16:28:29.763: INFO: Got endpoints: latency-svc-8gjhg [687.28426ms]
Dec  3 16:28:29.772: INFO: Created: latency-svc-vvrvj
Dec  3 16:28:29.813: INFO: Got endpoints: latency-svc-w8jw6 [737.696474ms]
Dec  3 16:28:29.822: INFO: Created: latency-svc-hjwk6
Dec  3 16:28:29.863: INFO: Got endpoints: latency-svc-dqqc8 [750.013251ms]
Dec  3 16:28:29.872: INFO: Created: latency-svc-8wx92
Dec  3 16:28:29.913: INFO: Got endpoints: latency-svc-t2w98 [747.947271ms]
Dec  3 16:28:29.922: INFO: Created: latency-svc-vj58j
Dec  3 16:28:29.963: INFO: Got endpoints: latency-svc-gjbbv [749.041108ms]
Dec  3 16:28:29.971: INFO: Created: latency-svc-cs4qz
Dec  3 16:28:30.013: INFO: Got endpoints: latency-svc-f24hv [749.569455ms]
Dec  3 16:28:30.021: INFO: Created: latency-svc-7n8pk
Dec  3 16:28:30.068: INFO: Got endpoints: latency-svc-mgfb6 [691.365213ms]
Dec  3 16:28:30.089: INFO: Created: latency-svc-5fdc8
Dec  3 16:28:30.113: INFO: Got endpoints: latency-svc-xqgkn [736.550661ms]
Dec  3 16:28:30.122: INFO: Created: latency-svc-hjmfs
Dec  3 16:28:30.164: INFO: Got endpoints: latency-svc-lgg9c [750.365447ms]
Dec  3 16:28:30.172: INFO: Created: latency-svc-fgh6d
Dec  3 16:28:30.263: INFO: Got endpoints: latency-svc-d54f2 [749.619468ms]
Dec  3 16:28:30.272: INFO: Created: latency-svc-hkcvc
Dec  3 16:28:30.275: INFO: Got endpoints: latency-svc-sqvp4 [811.709405ms]
Dec  3 16:28:30.285: INFO: Created: latency-svc-vdk6c
Dec  3 16:28:30.313: INFO: Got endpoints: latency-svc-vhs49 [749.599363ms]
Dec  3 16:28:30.321: INFO: Created: latency-svc-dxq8f
Dec  3 16:28:30.363: INFO: Got endpoints: latency-svc-jxvzc [749.895803ms]
Dec  3 16:28:30.384: INFO: Created: latency-svc-ztkjf
Dec  3 16:28:30.413: INFO: Got endpoints: latency-svc-4q92h [749.861326ms]
Dec  3 16:28:30.425: INFO: Created: latency-svc-2dtgj
Dec  3 16:28:30.475: INFO: Got endpoints: latency-svc-qnv6v [761.472838ms]
Dec  3 16:28:30.484: INFO: Created: latency-svc-n6swx
Dec  3 16:28:30.513: INFO: Got endpoints: latency-svc-vvrvj [749.661703ms]
Dec  3 16:28:30.532: INFO: Created: latency-svc-nwmp2
Dec  3 16:28:30.565: INFO: Got endpoints: latency-svc-hjwk6 [751.961727ms]
Dec  3 16:28:30.580: INFO: Created: latency-svc-2zkzf
Dec  3 16:28:30.613: INFO: Got endpoints: latency-svc-8wx92 [749.88639ms]
Dec  3 16:28:30.622: INFO: Created: latency-svc-6q2fl
Dec  3 16:28:30.664: INFO: Got endpoints: latency-svc-vj58j [750.500583ms]
Dec  3 16:28:30.672: INFO: Created: latency-svc-mm4hp
Dec  3 16:28:30.713: INFO: Got endpoints: latency-svc-cs4qz [750.240022ms]
Dec  3 16:28:30.723: INFO: Created: latency-svc-cgbt7
Dec  3 16:28:30.763: INFO: Got endpoints: latency-svc-7n8pk [750.105785ms]
Dec  3 16:28:30.772: INFO: Created: latency-svc-rq8wd
Dec  3 16:28:30.813: INFO: Got endpoints: latency-svc-5fdc8 [745.177117ms]
Dec  3 16:28:30.826: INFO: Created: latency-svc-rm8gc
Dec  3 16:28:30.863: INFO: Got endpoints: latency-svc-fgh6d [699.65381ms]
Dec  3 16:28:30.873: INFO: Created: latency-svc-8gttw
Dec  3 16:28:30.913: INFO: Got endpoints: latency-svc-hjmfs [799.606791ms]
Dec  3 16:28:30.925: INFO: Created: latency-svc-csjdx
Dec  3 16:28:30.963: INFO: Got endpoints: latency-svc-hkcvc [699.982592ms]
Dec  3 16:28:30.974: INFO: Created: latency-svc-cfstk
Dec  3 16:28:31.014: INFO: Got endpoints: latency-svc-vdk6c [736.667526ms]
Dec  3 16:28:31.022: INFO: Created: latency-svc-sn7gw
Dec  3 16:28:31.064: INFO: Got endpoints: latency-svc-dxq8f [751.389101ms]
Dec  3 16:28:31.164: INFO: Got endpoints: latency-svc-2dtgj [750.293972ms]
Dec  3 16:28:31.177: INFO: Got endpoints: latency-svc-ztkjf [802.297752ms]
Dec  3 16:28:31.178: INFO: Created: latency-svc-4xmbr
Dec  3 16:28:31.178: INFO: Created: latency-svc-8gdgj
Dec  3 16:28:31.186: INFO: Created: latency-svc-lh96j
Dec  3 16:28:31.213: INFO: Got endpoints: latency-svc-n6swx [737.682962ms]
Dec  3 16:28:31.222: INFO: Created: latency-svc-mdgm6
Dec  3 16:28:31.265: INFO: Got endpoints: latency-svc-nwmp2 [752.086352ms]
Dec  3 16:28:31.273: INFO: Created: latency-svc-5mz8s
Dec  3 16:28:31.315: INFO: Got endpoints: latency-svc-2zkzf [742.965672ms]
Dec  3 16:28:31.324: INFO: Created: latency-svc-wd5rm
Dec  3 16:28:31.363: INFO: Got endpoints: latency-svc-6q2fl [749.975339ms]
Dec  3 16:28:31.382: INFO: Created: latency-svc-wkrvt
Dec  3 16:28:31.421: INFO: Got endpoints: latency-svc-mm4hp [756.962452ms]
Dec  3 16:28:31.430: INFO: Created: latency-svc-jnlcq
Dec  3 16:28:31.463: INFO: Got endpoints: latency-svc-cgbt7 [749.941952ms]
Dec  3 16:28:31.473: INFO: Created: latency-svc-9wpdp
Dec  3 16:28:31.513: INFO: Got endpoints: latency-svc-rq8wd [750.037735ms]
Dec  3 16:28:31.522: INFO: Created: latency-svc-wxvsv
Dec  3 16:28:31.564: INFO: Got endpoints: latency-svc-rm8gc [747.158052ms]
Dec  3 16:28:31.572: INFO: Created: latency-svc-8qgl5
Dec  3 16:28:31.613: INFO: Got endpoints: latency-svc-8gttw [749.739098ms]
Dec  3 16:28:31.622: INFO: Created: latency-svc-6k9dj
Dec  3 16:28:31.663: INFO: Got endpoints: latency-svc-csjdx [750.143841ms]
Dec  3 16:28:31.673: INFO: Created: latency-svc-zq9vk
Dec  3 16:28:31.713: INFO: Got endpoints: latency-svc-cfstk [749.958734ms]
Dec  3 16:28:31.721: INFO: Created: latency-svc-kfmjx
Dec  3 16:28:31.763: INFO: Got endpoints: latency-svc-sn7gw [749.533396ms]
Dec  3 16:28:31.793: INFO: Created: latency-svc-wsltb
Dec  3 16:28:31.813: INFO: Got endpoints: latency-svc-4xmbr [650.297704ms]
Dec  3 16:28:31.822: INFO: Created: latency-svc-txlk2
Dec  3 16:28:31.863: INFO: Got endpoints: latency-svc-8gdgj [699.802273ms]
Dec  3 16:28:31.873: INFO: Created: latency-svc-mffg7
Dec  3 16:28:31.913: INFO: Got endpoints: latency-svc-lh96j [736.331923ms]
Dec  3 16:28:31.922: INFO: Created: latency-svc-ntz4r
Dec  3 16:28:31.964: INFO: Got endpoints: latency-svc-mdgm6 [749.966595ms]
Dec  3 16:28:31.973: INFO: Created: latency-svc-q4njh
Dec  3 16:28:32.014: INFO: Got endpoints: latency-svc-5mz8s [748.542524ms]
Dec  3 16:28:32.022: INFO: Created: latency-svc-242wt
Dec  3 16:28:32.063: INFO: Got endpoints: latency-svc-wd5rm [748.568426ms]
Dec  3 16:28:32.073: INFO: Created: latency-svc-jf7gc
Dec  3 16:28:32.114: INFO: Got endpoints: latency-svc-wkrvt [750.055147ms]
Dec  3 16:28:32.124: INFO: Created: latency-svc-x47mm
Dec  3 16:28:32.164: INFO: Got endpoints: latency-svc-jnlcq [742.824621ms]
Dec  3 16:28:32.172: INFO: Created: latency-svc-h898l
Dec  3 16:28:32.263: INFO: Got endpoints: latency-svc-wxvsv [749.93849ms]
Dec  3 16:28:32.274: INFO: Created: latency-svc-pswqf
Dec  3 16:28:32.275: INFO: Got endpoints: latency-svc-9wpdp [811.569866ms]
Dec  3 16:28:32.284: INFO: Created: latency-svc-2n95g
Dec  3 16:28:32.313: INFO: Got endpoints: latency-svc-8qgl5 [749.600019ms]
Dec  3 16:28:32.323: INFO: Created: latency-svc-pcmcr
Dec  3 16:28:32.363: INFO: Got endpoints: latency-svc-6k9dj [750.278328ms]
Dec  3 16:28:32.372: INFO: Created: latency-svc-lqzq9
Dec  3 16:28:32.413: INFO: Got endpoints: latency-svc-zq9vk [749.980982ms]
Dec  3 16:28:32.423: INFO: Created: latency-svc-2bkwz
Dec  3 16:28:32.463: INFO: Got endpoints: latency-svc-kfmjx [749.992322ms]
Dec  3 16:28:32.472: INFO: Created: latency-svc-g59db
Dec  3 16:28:32.513: INFO: Got endpoints: latency-svc-wsltb [750.139424ms]
Dec  3 16:28:32.522: INFO: Created: latency-svc-lrw9n
Dec  3 16:28:32.564: INFO: Got endpoints: latency-svc-txlk2 [750.837383ms]
Dec  3 16:28:32.573: INFO: Created: latency-svc-qxkpc
Dec  3 16:28:32.615: INFO: Got endpoints: latency-svc-mffg7 [751.773318ms]
Dec  3 16:28:32.627: INFO: Created: latency-svc-snp6z
Dec  3 16:28:32.664: INFO: Got endpoints: latency-svc-ntz4r [749.956719ms]
Dec  3 16:28:32.672: INFO: Created: latency-svc-569dk
Dec  3 16:28:32.776: INFO: Got endpoints: latency-svc-q4njh [812.787791ms]
Dec  3 16:28:32.777: INFO: Got endpoints: latency-svc-242wt [763.045944ms]
Dec  3 16:28:32.785: INFO: Created: latency-svc-g4qjr
Dec  3 16:28:32.789: INFO: Created: latency-svc-mp46w
Dec  3 16:28:32.876: INFO: Got endpoints: latency-svc-jf7gc [812.322985ms]
Dec  3 16:28:32.876: INFO: Got endpoints: latency-svc-x47mm [762.835312ms]
Dec  3 16:28:32.885: INFO: Created: latency-svc-8ng25
Dec  3 16:28:32.889: INFO: Created: latency-svc-9zc95
Dec  3 16:28:32.976: INFO: Got endpoints: latency-svc-pswqf [712.66957ms]
Dec  3 16:28:32.985: INFO: Created: latency-svc-79ll8
Dec  3 16:28:33.076: INFO: Got endpoints: latency-svc-2n95g [800.389211ms]
Dec  3 16:28:33.076: INFO: Got endpoints: latency-svc-h898l [912.076347ms]
Dec  3 16:28:33.084: INFO: Created: latency-svc-fbr8q
Dec  3 16:28:33.088: INFO: Created: latency-svc-t5qh5
Dec  3 16:28:33.178: INFO: Got endpoints: latency-svc-lqzq9 [814.188118ms]
Dec  3 16:28:33.178: INFO: Got endpoints: latency-svc-pcmcr [864.798283ms]
Dec  3 16:28:33.186: INFO: Created: latency-svc-25zgm
Dec  3 16:28:33.190: INFO: Created: latency-svc-pkr5j
Dec  3 16:28:33.276: INFO: Got endpoints: latency-svc-2bkwz [862.482644ms]
Dec  3 16:28:33.276: INFO: Got endpoints: latency-svc-snp6z [661.036449ms]
Dec  3 16:28:33.277: INFO: Got endpoints: latency-svc-g59db [813.2599ms]
Dec  3 16:28:33.284: INFO: Created: latency-svc-z787p
Dec  3 16:28:33.289: INFO: Created: latency-svc-4lbjd
Dec  3 16:28:33.291: INFO: Created: latency-svc-7qvv5
Dec  3 16:28:33.313: INFO: Got endpoints: latency-svc-lrw9n [799.723302ms]
Dec  3 16:28:33.321: INFO: Created: latency-svc-db6tx
Dec  3 16:28:33.364: INFO: Got endpoints: latency-svc-qxkpc [799.697344ms]
Dec  3 16:28:33.373: INFO: Created: latency-svc-kbzz5
Dec  3 16:28:33.576: INFO: Got endpoints: latency-svc-g4qjr [799.415103ms]
Dec  3 16:28:33.577: INFO: Got endpoints: latency-svc-8ng25 [700.527689ms]
Dec  3 16:28:33.577: INFO: Got endpoints: latency-svc-mp46w [799.820731ms]
Dec  3 16:28:33.577: INFO: Got endpoints: latency-svc-569dk [913.42605ms]
Dec  3 16:28:33.585: INFO: Created: latency-svc-5z6rk
Dec  3 16:28:33.589: INFO: Created: latency-svc-pzv7h
Dec  3 16:28:33.592: INFO: Created: latency-svc-7vctn
Dec  3 16:28:33.596: INFO: Created: latency-svc-gl9x7
Dec  3 16:28:33.613: INFO: Got endpoints: latency-svc-9zc95 [736.887359ms]
Dec  3 16:28:33.624: INFO: Created: latency-svc-8fdsl
Dec  3 16:28:33.677: INFO: Got endpoints: latency-svc-79ll8 [700.521073ms]
Dec  3 16:28:33.714: INFO: Got endpoints: latency-svc-fbr8q [638.173644ms]
Dec  3 16:28:33.724: INFO: Created: latency-svc-8c27j
Dec  3 16:28:33.726: INFO: Created: latency-svc-dh6b5
Dec  3 16:28:33.763: INFO: Got endpoints: latency-svc-t5qh5 [687.544803ms]
Dec  3 16:28:33.772: INFO: Created: latency-svc-lr4rx
Dec  3 16:28:33.814: INFO: Got endpoints: latency-svc-25zgm [636.434375ms]
Dec  3 16:28:33.827: INFO: Created: latency-svc-w8z5g
Dec  3 16:28:33.863: INFO: Got endpoints: latency-svc-pkr5j [685.185043ms]
Dec  3 16:28:33.872: INFO: Created: latency-svc-lx4kd
Dec  3 16:28:33.913: INFO: Got endpoints: latency-svc-z787p [637.320034ms]
Dec  3 16:28:33.922: INFO: Created: latency-svc-6bhp6
Dec  3 16:28:33.964: INFO: Got endpoints: latency-svc-4lbjd [687.063923ms]
Dec  3 16:28:33.972: INFO: Created: latency-svc-pdjx4
Dec  3 16:28:34.013: INFO: Got endpoints: latency-svc-7qvv5 [736.77689ms]
Dec  3 16:28:34.023: INFO: Created: latency-svc-d62t9
Dec  3 16:28:34.064: INFO: Got endpoints: latency-svc-db6tx [750.440365ms]
Dec  3 16:28:34.072: INFO: Created: latency-svc-j98bq
Dec  3 16:28:34.114: INFO: Got endpoints: latency-svc-kbzz5 [749.953181ms]
Dec  3 16:28:34.139: INFO: Created: latency-svc-whc5x
Dec  3 16:28:34.164: INFO: Got endpoints: latency-svc-5z6rk [587.591926ms]
Dec  3 16:28:34.177: INFO: Created: latency-svc-vh5d6
Dec  3 16:28:34.263: INFO: Got endpoints: latency-svc-7vctn [686.447638ms]
Dec  3 16:28:34.271: INFO: Created: latency-svc-2vvwc
Dec  3 16:28:34.275: INFO: Got endpoints: latency-svc-pzv7h [698.509857ms]
Dec  3 16:28:34.284: INFO: Created: latency-svc-m5894
Dec  3 16:28:34.314: INFO: Got endpoints: latency-svc-gl9x7 [736.548222ms]
Dec  3 16:28:34.322: INFO: Created: latency-svc-ljp9f
Dec  3 16:28:34.376: INFO: Got endpoints: latency-svc-8fdsl [760.110671ms]
Dec  3 16:28:34.386: INFO: Created: latency-svc-69skl
Dec  3 16:28:34.465: INFO: Got endpoints: latency-svc-dh6b5 [750.108982ms]
Dec  3 16:28:34.475: INFO: Got endpoints: latency-svc-8c27j [761.275866ms]
Dec  3 16:28:34.576: INFO: Got endpoints: latency-svc-w8z5g [761.867503ms]
Dec  3 16:28:34.576: INFO: Got endpoints: latency-svc-lr4rx [812.804476ms]
Dec  3 16:28:34.614: INFO: Got endpoints: latency-svc-lx4kd [750.281171ms]
Dec  3 16:28:34.676: INFO: Got endpoints: latency-svc-6bhp6 [762.827371ms]
Dec  3 16:28:34.714: INFO: Got endpoints: latency-svc-pdjx4 [749.993928ms]
Dec  3 16:28:34.764: INFO: Got endpoints: latency-svc-d62t9 [750.036501ms]
Dec  3 16:28:34.814: INFO: Got endpoints: latency-svc-j98bq [749.711927ms]
Dec  3 16:28:34.864: INFO: Got endpoints: latency-svc-whc5x [733.54683ms]
Dec  3 16:28:34.914: INFO: Got endpoints: latency-svc-vh5d6 [750.068986ms]
Dec  3 16:28:34.963: INFO: Got endpoints: latency-svc-2vvwc [700.070494ms]
Dec  3 16:28:35.014: INFO: Got endpoints: latency-svc-m5894 [738.625268ms]
Dec  3 16:28:35.064: INFO: Got endpoints: latency-svc-ljp9f [750.103712ms]
Dec  3 16:28:35.114: INFO: Got endpoints: latency-svc-69skl [737.980268ms]
Dec  3 16:28:35.114: INFO: Latencies: [13.290365ms 16.116082ms 18.075246ms 19.445302ms 24.077773ms 27.592966ms 29.222679ms 33.885896ms 46.808357ms 54.383855ms 57.372547ms 66.974258ms 85.169158ms 88.247019ms 89.588055ms 90.278606ms 90.456753ms 93.272892ms 93.587871ms 94.17922ms 94.391544ms 94.569936ms 94.992805ms 99.36195ms 100.310895ms 100.556536ms 102.265449ms 103.04458ms 104.062265ms 117.061216ms 117.336186ms 117.480241ms 117.682873ms 126.894994ms 172.746361ms 220.721212ms 265.510264ms 313.868487ms 360.126904ms 405.098909ms 451.358051ms 488.330932ms 496.515647ms 537.64274ms 587.591926ms 599.587789ms 636.434375ms 636.646009ms 637.320034ms 638.173644ms 650.297704ms 661.036449ms 685.185043ms 686.447638ms 686.914014ms 687.063923ms 687.28426ms 687.544803ms 687.747346ms 687.900808ms 687.942652ms 691.365213ms 698.509857ms 699.107174ms 699.65381ms 699.802273ms 699.982592ms 700.070494ms 700.521073ms 700.527689ms 712.66957ms 713.218114ms 729.55488ms 733.54683ms 735.244413ms 736.220364ms 736.331923ms 736.548222ms 736.550661ms 736.667526ms 736.77689ms 736.863058ms 736.887359ms 737.182149ms 737.682962ms 737.696474ms 737.980268ms 738.625268ms 742.824621ms 742.965672ms 745.177117ms 747.158052ms 747.348566ms 747.794218ms 747.947271ms 748.533082ms 748.542524ms 748.568426ms 748.814444ms 749.041108ms 749.440757ms 749.478441ms 749.530901ms 749.533396ms 749.569455ms 749.599363ms 749.600019ms 749.619468ms 749.661703ms 749.673356ms 749.711927ms 749.7233ms 749.739098ms 749.766666ms 749.822245ms 749.822529ms 749.849684ms 749.861326ms 749.86852ms 749.88639ms 749.895803ms 749.93849ms 749.941952ms 749.953181ms 749.956719ms 749.958734ms 749.966595ms 749.975339ms 749.980982ms 749.992322ms 749.993928ms 750.013251ms 750.036501ms 750.037735ms 750.055147ms 750.068986ms 750.072594ms 750.103712ms 750.105785ms 750.108982ms 750.139424ms 750.143841ms 750.153653ms 750.240022ms 750.262419ms 750.278328ms 750.281171ms 750.293972ms 750.346597ms 750.365447ms 750.440365ms 750.499177ms 750.500583ms 750.711982ms 750.837383ms 751.389101ms 751.443896ms 751.542536ms 751.773318ms 751.900004ms 751.961727ms 752.086352ms 752.562478ms 756.962452ms 760.110671ms 761.275866ms 761.472838ms 761.837554ms 761.867503ms 761.925695ms 762.122489ms 762.827371ms 762.835312ms 763.045944ms 763.13654ms 771.349681ms 799.415103ms 799.606791ms 799.697344ms 799.723302ms 799.820731ms 799.940637ms 800.389211ms 800.550164ms 802.297752ms 811.364885ms 811.569866ms 811.69543ms 811.709405ms 812.322985ms 812.787791ms 812.804476ms 813.2599ms 814.188118ms 814.233711ms 862.144768ms 862.482644ms 864.798283ms 912.076347ms 913.42605ms]
Dec  3 16:28:35.114: INFO: 50 %ile: 749.440757ms
Dec  3 16:28:35.114: INFO: 90 %ile: 799.820731ms
Dec  3 16:28:35.114: INFO: 99 %ile: 912.076347ms
Dec  3 16:28:35.114: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:28:35.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-2517" for this suite.
Dec  3 16:28:45.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:28:45.279: INFO: namespace svc-latency-2517 deletion completed in 10.160260274s
•S
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:28:45.280: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-128
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec  3 16:28:46.119: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-128 /api/v1/namespaces/watch-128/configmaps/e2e-watch-test-resource-version 3f80444c-84d4-4463-90f3-31ec64bbc6e3 34743 0 2019-12-03 16:28:46 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 16:28:46.119: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-128 /api/v1/namespaces/watch-128/configmaps/e2e-watch-test-resource-version 3f80444c-84d4-4463-90f3-31ec64bbc6e3 34744 0 2019-12-03 16:28:46 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:28:46.119: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-128" for this suite.
Dec  3 16:28:52.140: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:28:52.299: INFO: namespace watch-128 deletion completed in 6.172701603s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:28:52.300: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2946
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:28:52.832: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec  3 16:28:52.845: INFO: Number of nodes with available pods: 0
Dec  3 16:28:52.845: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec  3 16:28:52.863: INFO: Number of nodes with available pods: 0
Dec  3 16:28:52.863: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 16:28:53.869: INFO: Number of nodes with available pods: 0
Dec  3 16:28:53.869: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 16:28:54.869: INFO: Number of nodes with available pods: 1
Dec  3 16:28:54.949: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec  3 16:28:54.969: INFO: Number of nodes with available pods: 1
Dec  3 16:28:54.969: INFO: Number of running nodes: 0, number of available pods: 1
Dec  3 16:28:55.977: INFO: Number of nodes with available pods: 0
Dec  3 16:28:55.977: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec  3 16:28:55.987: INFO: Number of nodes with available pods: 0
Dec  3 16:28:56.001: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 16:28:57.006: INFO: Number of nodes with available pods: 0
Dec  3 16:28:57.006: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 16:28:58.006: INFO: Number of nodes with available pods: 0
Dec  3 16:28:58.006: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 16:28:59.006: INFO: Number of nodes with available pods: 0
Dec  3 16:28:59.006: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 16:29:00.007: INFO: Number of nodes with available pods: 0
Dec  3 16:29:00.007: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 16:29:01.006: INFO: Number of nodes with available pods: 0
Dec  3 16:29:01.006: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 16:29:02.007: INFO: Number of nodes with available pods: 0
Dec  3 16:29:02.007: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 16:29:03.006: INFO: Number of nodes with available pods: 0
Dec  3 16:29:03.006: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 16:29:04.006: INFO: Number of nodes with available pods: 0
Dec  3 16:29:04.006: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 16:29:05.006: INFO: Number of nodes with available pods: 0
Dec  3 16:29:05.006: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 16:29:06.006: INFO: Number of nodes with available pods: 0
Dec  3 16:29:06.006: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 16:29:07.006: INFO: Number of nodes with available pods: 0
Dec  3 16:29:07.006: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 16:29:08.006: INFO: Number of nodes with available pods: 0
Dec  3 16:29:08.006: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 16:29:09.006: INFO: Number of nodes with available pods: 1
Dec  3 16:29:09.006: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2946, will wait for the garbage collector to delete the pods
Dec  3 16:29:09.075: INFO: Deleting DaemonSet.extensions daemon-set took: 6.288024ms
Dec  3 16:29:09.575: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.316814ms
Dec  3 16:29:16.480: INFO: Number of nodes with available pods: 0
Dec  3 16:29:16.480: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 16:29:16.484: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2946/daemonsets","resourceVersion":"34886"},"items":null}

Dec  3 16:29:16.488: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2946/pods","resourceVersion":"34886"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:29:16.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2946" for this suite.
Dec  3 16:29:24.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:29:24.671: INFO: namespace daemonsets-2946 deletion completed in 8.157381265s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:29:24.672: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-8300
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec  3 16:29:25.666: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 16:29:28.691: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:29:28.696: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:29:29.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-8300" for this suite.
Dec  3 16:29:37.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:29:37.688: INFO: namespace crd-webhook-8300 deletion completed in 8.209207235s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137
•SSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:29:37.706: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7988
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 16:29:38.007: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6c1fa194-6c8f-4a64-a046-c85f1e9d38b7" in namespace "downward-api-7988" to be "success or failure"
Dec  3 16:29:38.012: INFO: Pod "downwardapi-volume-6c1fa194-6c8f-4a64-a046-c85f1e9d38b7": Phase="Pending", Reason="", readiness=false. Elapsed: 4.370598ms
Dec  3 16:29:40.017: INFO: Pod "downwardapi-volume-6c1fa194-6c8f-4a64-a046-c85f1e9d38b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009598976s
STEP: Saw pod success
Dec  3 16:29:40.017: INFO: Pod "downwardapi-volume-6c1fa194-6c8f-4a64-a046-c85f1e9d38b7" satisfied condition "success or failure"
Dec  3 16:29:40.023: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod downwardapi-volume-6c1fa194-6c8f-4a64-a046-c85f1e9d38b7 container client-container: <nil>
STEP: delete the pod
Dec  3 16:29:40.185: INFO: Waiting for pod downwardapi-volume-6c1fa194-6c8f-4a64-a046-c85f1e9d38b7 to disappear
Dec  3 16:29:40.193: INFO: Pod downwardapi-volume-6c1fa194-6c8f-4a64-a046-c85f1e9d38b7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:29:40.193: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7988" for this suite.
Dec  3 16:29:46.219: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:29:46.371: INFO: namespace downward-api-7988 deletion completed in 6.169504464s
•SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:29:46.371: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-406
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  3 16:29:50.740: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 16:29:50.746: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 16:29:52.747: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 16:29:52.752: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 16:29:54.750: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 16:29:54.755: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 16:29:56.747: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 16:29:56.752: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 16:29:58.749: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 16:29:58.754: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:29:58.768: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-406" for this suite.
Dec  3 16:30:10.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:30:10.932: INFO: namespace container-lifecycle-hook-406 deletion completed in 12.157202816s
•SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:30:10.933: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-1397
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec  3 16:30:11.289: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 16:30:11.307: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 16:30:11.311: INFO: 
Logging pods the kubelet thinks is on node izgw88vcbd5x6ev7zbjg8vz before test
Dec  3 16:30:11.438: INFO: addons-nginx-ingress-controller-7c75bb76db-8qn7n from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 16:30:11.438: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec  3 16:30:11.438: INFO: csi-disk-plugin-alicloud-55sss from kube-system started at 2019-12-03 14:26:56 +0000 UTC (2 container statuses recorded)
Dec  3 16:30:11.438: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec  3 16:30:11.438: INFO: 	Container driver-registrar ready: true, restart count 0
Dec  3 16:30:11.438: INFO: calico-kube-controllers-79bcd784b6-vbln2 from kube-system started at 2019-12-03 15:47:45 +0000 UTC (1 container statuses recorded)
Dec  3 16:30:11.438: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  3 16:30:11.438: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-95f65778d-6v4hg from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 16:30:11.438: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec  3 16:30:11.438: INFO: node-problem-detector-jj8gj from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 16:30:11.438: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 16:30:11.438: INFO: coredns-59c969ffb8-xnfvv from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 16:30:11.438: INFO: 	Container coredns ready: true, restart count 0
Dec  3 16:30:11.439: INFO: metrics-server-69dcc87559-8j9rx from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 16:30:11.439: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 16:30:11.439: INFO: calico-typha-vertical-autoscaler-847d859f8c-6xhsp from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 16:30:11.439: INFO: 	Container autoscaler ready: true, restart count 2
Dec  3 16:30:11.439: INFO: coredns-59c969ffb8-9mq2d from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 16:30:11.439: INFO: 	Container coredns ready: true, restart count 0
Dec  3 16:30:11.439: INFO: calico-typha-deploy-9f6b455c4-zqh59 from kube-system started at 2019-12-03 15:47:45 +0000 UTC (1 container statuses recorded)
Dec  3 16:30:11.439: INFO: 	Container calico-typha ready: true, restart count 0
Dec  3 16:30:11.439: INFO: vpn-shoot-76845cddf7-dh4gs from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 16:30:11.439: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec  3 16:30:11.439: INFO: addons-kubernetes-dashboard-78954cc66b-mh5g8 from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 16:30:11.439: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  3 16:30:11.439: INFO: calico-node-rx7sf from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 16:30:11.439: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 16:30:11.439: INFO: node-exporter-xwww8 from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 16:30:11.439: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 16:30:11.439: INFO: kube-proxy-frcrz from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 16:30:11.439: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 16:30:11.439: INFO: calico-typha-horizontal-autoscaler-69df649c59-wrrxb from kube-system started at 2019-12-03 14:26:56 +0000 UTC (1 container statuses recorded)
Dec  3 16:30:11.439: INFO: 	Container autoscaler ready: true, restart count 0
Dec  3 16:30:11.439: INFO: blackbox-exporter-7bd7b55dfc-jjbg2 from kube-system started at 2019-12-03 14:26:16 +0000 UTC (1 container statuses recorded)
Dec  3 16:30:11.439: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec  3 16:30:11.439: INFO: 
Logging pods the kubelet thinks is on node izgw8fisrtg04goc4t8tqaz before test
Dec  3 16:30:11.489: INFO: kube-proxy-dgc7z from kube-system started at 2019-12-03 14:26:18 +0000 UTC (1 container statuses recorded)
Dec  3 16:30:11.489: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 16:30:11.489: INFO: csi-disk-plugin-alicloud-sdzcv from kube-system started at 2019-12-03 15:53:14 +0000 UTC (2 container statuses recorded)
Dec  3 16:30:11.489: INFO: 	Container csi-diskplugin ready: true, restart count 0
Dec  3 16:30:11.489: INFO: 	Container driver-registrar ready: true, restart count 0
Dec  3 16:30:11.490: INFO: node-problem-detector-g8scm from kube-system started at 2019-12-03 14:26:18 +0000 UTC (1 container statuses recorded)
Dec  3 16:30:11.490: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 16:30:11.490: INFO: calico-node-8d72b from kube-system started at 2019-12-03 14:26:18 +0000 UTC (1 container statuses recorded)
Dec  3 16:30:11.490: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 16:30:11.490: INFO: node-exporter-2jhhv from kube-system started at 2019-12-03 14:26:18 +0000 UTC (1 container statuses recorded)
Dec  3 16:30:11.490: INFO: 	Container node-exporter ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-6bd85a25-b5e1-409e-aa38-ef8cc61bb738 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-6bd85a25-b5e1-409e-aa38-ef8cc61bb738 off the node izgw8fisrtg04goc4t8tqaz
STEP: verifying the node doesn't have the label kubernetes.io/e2e-6bd85a25-b5e1-409e-aa38-ef8cc61bb738
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:35:15.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-1397" for this suite.
Dec  3 16:35:31.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:35:31.744: INFO: namespace sched-pred-1397 deletion completed in 16.161899155s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:320.811 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:35:31.744: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-2739
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:35:32.417: INFO: Create a RollingUpdate DaemonSet
Dec  3 16:35:32.423: INFO: Check that daemon pods launch on every node of the cluster
Dec  3 16:35:32.432: INFO: Number of nodes with available pods: 0
Dec  3 16:35:32.432: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 16:35:33.444: INFO: Number of nodes with available pods: 0
Dec  3 16:35:33.444: INFO: Node izgw88vcbd5x6ev7zbjg8vz is running more than one daemon pod
Dec  3 16:35:34.444: INFO: Number of nodes with available pods: 2
Dec  3 16:35:34.444: INFO: Number of running nodes: 2, number of available pods: 2
Dec  3 16:35:34.444: INFO: Update the DaemonSet to trigger a rollout
Dec  3 16:35:34.453: INFO: Updating DaemonSet daemon-set
Dec  3 16:35:47.475: INFO: Roll back the DaemonSet before rollout is complete
Dec  3 16:35:47.484: INFO: Updating DaemonSet daemon-set
Dec  3 16:35:47.484: INFO: Make sure DaemonSet rollback is complete
Dec  3 16:35:47.488: INFO: Wrong image for pod: daemon-set-5vkvm. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec  3 16:35:47.488: INFO: Pod daemon-set-5vkvm is not available
Dec  3 16:35:48.498: INFO: Wrong image for pod: daemon-set-5vkvm. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec  3 16:35:48.498: INFO: Pod daemon-set-5vkvm is not available
Dec  3 16:35:49.498: INFO: Pod daemon-set-br8ws is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-2739, will wait for the garbage collector to delete the pods
Dec  3 16:35:49.574: INFO: Deleting DaemonSet.extensions daemon-set took: 6.22072ms
Dec  3 16:35:49.674: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.280255ms
Dec  3 16:35:57.979: INFO: Number of nodes with available pods: 0
Dec  3 16:35:57.979: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 16:35:57.983: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-2739/daemonsets","resourceVersion":"36351"},"items":null}

Dec  3 16:35:57.987: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-2739/pods","resourceVersion":"36351"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:35:58.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-2739" for this suite.
Dec  3 16:36:04.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:36:04.178: INFO: namespace daemonsets-2739 deletion completed in 6.169722934s
•SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:36:04.178: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9079
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec  3 16:36:04.589: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-9079'
Dec  3 16:36:05.065: INFO: stderr: ""
Dec  3 16:36:05.065: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  3 16:36:06.071: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 16:36:06.071: INFO: Found 0 / 1
Dec  3 16:36:07.071: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 16:36:07.071: INFO: Found 1 / 1
Dec  3 16:36:07.071: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec  3 16:36:07.076: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 16:36:07.076: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 16:36:07.076: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmb31-0sj.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config patch pod redis-master-nfpxs --namespace=kubectl-9079 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec  3 16:36:07.328: INFO: stderr: ""
Dec  3 16:36:07.328: INFO: stdout: "pod/redis-master-nfpxs patched\n"
STEP: checking annotations
Dec  3 16:36:07.333: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 16:36:07.333: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:36:07.333: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9079" for this suite.
Dec  3 16:36:19.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:36:19.499: INFO: namespace kubectl-9079 deletion completed in 12.158658205s
•SSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:36:19.499: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-9415
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-9415
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9415 to expose endpoints map[]
Dec  3 16:36:19.807: INFO: successfully validated that service endpoint-test2 in namespace services-9415 exposes endpoints map[] (4.034822ms elapsed)
STEP: Creating pod pod1 in namespace services-9415
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9415 to expose endpoints map[pod1:[80]]
Dec  3 16:36:21.841: INFO: successfully validated that service endpoint-test2 in namespace services-9415 exposes endpoints map[pod1:[80]] (2.026733062s elapsed)
STEP: Creating pod pod2 in namespace services-9415
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9415 to expose endpoints map[pod1:[80] pod2:[80]]
Dec  3 16:36:24.902: INFO: successfully validated that service endpoint-test2 in namespace services-9415 exposes endpoints map[pod1:[80] pod2:[80]] (3.052651957s elapsed)
STEP: Deleting pod pod1 in namespace services-9415
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9415 to expose endpoints map[pod2:[80]]
Dec  3 16:36:24.915: INFO: successfully validated that service endpoint-test2 in namespace services-9415 exposes endpoints map[pod2:[80]] (7.696061ms elapsed)
STEP: Deleting pod pod2 in namespace services-9415
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-9415 to expose endpoints map[]
Dec  3 16:36:24.924: INFO: successfully validated that service endpoint-test2 in namespace services-9415 exposes endpoints map[] (3.69255ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:36:24.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-9415" for this suite.
Dec  3 16:36:32.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:36:33.112: INFO: namespace services-9415 deletion completed in 8.170579129s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:36:33.113: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8166
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8166.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-8166.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8166.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-8166.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8166.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8166.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8166.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-8166.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8166.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-8166.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8166.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 51.137.110.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.110.137.51_udp@PTR;check="$$(dig +tcp +noall +answer +search 51.137.110.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.110.137.51_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-8166.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-8166.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-8166.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-8166.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-8166.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-8166.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-8166.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-8166.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-8166.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-8166.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8166.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 51.137.110.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.110.137.51_udp@PTR;check="$$(dig +tcp +noall +answer +search 51.137.110.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.110.137.51_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 16:36:37.533: INFO: Unable to read wheezy_udp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:37.578: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:37.586: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:37.594: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:38.003: INFO: Unable to read jessie_udp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:38.011: INFO: Unable to read jessie_tcp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:38.018: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:38.025: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:38.343: INFO: Lookups using dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be failed for: [wheezy_udp@dns-test-service.dns-8166.svc.cluster.local wheezy_tcp@dns-test-service.dns-8166.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local jessie_udp@dns-test-service.dns-8166.svc.cluster.local jessie_tcp@dns-test-service.dns-8166.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local]

Dec  3 16:36:43.351: INFO: Unable to read wheezy_udp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:43.359: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:43.366: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:43.374: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:43.786: INFO: Unable to read jessie_udp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:43.794: INFO: Unable to read jessie_tcp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:43.802: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:43.809: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:44.171: INFO: Lookups using dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be failed for: [wheezy_udp@dns-test-service.dns-8166.svc.cluster.local wheezy_tcp@dns-test-service.dns-8166.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local jessie_udp@dns-test-service.dns-8166.svc.cluster.local jessie_tcp@dns-test-service.dns-8166.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local]

Dec  3 16:36:48.351: INFO: Unable to read wheezy_udp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:48.358: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:48.366: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:48.373: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:48.703: INFO: Unable to read jessie_udp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:48.711: INFO: Unable to read jessie_tcp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:48.718: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:48.725: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:49.088: INFO: Lookups using dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be failed for: [wheezy_udp@dns-test-service.dns-8166.svc.cluster.local wheezy_tcp@dns-test-service.dns-8166.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local jessie_udp@dns-test-service.dns-8166.svc.cluster.local jessie_tcp@dns-test-service.dns-8166.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local]

Dec  3 16:36:53.356: INFO: Unable to read wheezy_udp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:53.363: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:53.370: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:53.377: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:53.787: INFO: Unable to read jessie_udp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:53.795: INFO: Unable to read jessie_tcp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:53.802: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:53.809: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:54.174: INFO: Lookups using dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be failed for: [wheezy_udp@dns-test-service.dns-8166.svc.cluster.local wheezy_tcp@dns-test-service.dns-8166.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local jessie_udp@dns-test-service.dns-8166.svc.cluster.local jessie_tcp@dns-test-service.dns-8166.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local]

Dec  3 16:36:58.351: INFO: Unable to read wheezy_udp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:58.359: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:58.367: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:58.374: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:58.782: INFO: Unable to read jessie_udp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:58.789: INFO: Unable to read jessie_tcp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:58.797: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:58.804: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:36:59.171: INFO: Lookups using dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be failed for: [wheezy_udp@dns-test-service.dns-8166.svc.cluster.local wheezy_tcp@dns-test-service.dns-8166.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local jessie_udp@dns-test-service.dns-8166.svc.cluster.local jessie_tcp@dns-test-service.dns-8166.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local]

Dec  3 16:37:03.352: INFO: Unable to read wheezy_udp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:37:03.360: INFO: Unable to read wheezy_tcp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:37:03.367: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:37:03.374: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:37:03.782: INFO: Unable to read jessie_udp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:37:03.794: INFO: Unable to read jessie_tcp@dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:37:03.802: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:37:03.809: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local from pod dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be: the server could not find the requested resource (get pods dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be)
Dec  3 16:37:04.173: INFO: Lookups using dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be failed for: [wheezy_udp@dns-test-service.dns-8166.svc.cluster.local wheezy_tcp@dns-test-service.dns-8166.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local jessie_udp@dns-test-service.dns-8166.svc.cluster.local jessie_tcp@dns-test-service.dns-8166.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-8166.svc.cluster.local]

Dec  3 16:37:09.608: INFO: DNS probes using dns-8166/dns-test-d9082ba7-fb45-40e5-b961-c6b2c1e226be succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:37:09.636: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8166" for this suite.
Dec  3 16:37:15.655: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:37:15.799: INFO: namespace dns-8166 deletion completed in 6.158418721s
•SSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:37:15.799: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2431
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-385b4cf1-b71e-455e-931b-aba51bfa6a8c
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:37:16.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2431" for this suite.
Dec  3 16:37:24.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:37:24.666: INFO: namespace secrets-2431 deletion completed in 8.162031131s
•SSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:37:24.666: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-7395
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:37:24.996: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating first CR 
Dec  3 16:37:25.127: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-03T16:37:25Z generation:1 name:name1 resourceVersion:36759 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:419052bc-1528-47c6-8187-9ba1b1c6ae09] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Dec  3 16:37:35.133: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-03T16:37:35Z generation:1 name:name2 resourceVersion:36790 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:496de5f3-4f03-4e18-a227-ed8050d61852] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Dec  3 16:37:45.140: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-03T16:37:25Z generation:2 name:name1 resourceVersion:36823 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:419052bc-1528-47c6-8187-9ba1b1c6ae09] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Dec  3 16:37:55.148: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-03T16:37:35Z generation:2 name:name2 resourceVersion:36855 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:496de5f3-4f03-4e18-a227-ed8050d61852] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Dec  3 16:38:05.156: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-03T16:37:25Z generation:2 name:name1 resourceVersion:36888 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:419052bc-1528-47c6-8187-9ba1b1c6ae09] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Dec  3 16:38:15.166: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-03T16:37:35Z generation:2 name:name2 resourceVersion:36921 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:496de5f3-4f03-4e18-a227-ed8050d61852] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:38:25.680: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-7395" for this suite.
Dec  3 16:38:31.705: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:38:31.890: INFO: namespace crd-watch-7395 deletion completed in 6.202532077s
•SSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:38:31.890: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4951
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Dec  3 16:38:34.219: INFO: Pod pod-hostip-2b084394-8607-4b71-99b6-f982dec36bb2 has hostIP: 10.250.2.117
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:38:34.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4951" for this suite.
Dec  3 16:39:04.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:39:04.386: INFO: namespace pods-4951 deletion completed in 30.159454258s
•SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:39:04.387: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-283
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:39:04.793: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:39:04.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-283" for this suite.
Dec  3 16:39:10.862: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:39:11.054: INFO: namespace custom-resource-definition-283 deletion completed in 6.206380008s
•SSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:39:11.054: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-9084
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  3 16:39:15.694: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 16:39:15.699: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 16:39:17.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 16:39:17.705: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 16:39:19.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 16:39:19.704: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 16:39:21.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 16:39:21.704: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 16:39:23.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 16:39:23.704: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 16:39:25.701: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 16:39:25.706: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 16:39:27.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 16:39:27.705: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 16:39:29.699: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 16:39:29.704: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:39:29.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-9084" for this suite.
Dec  3 16:39:59.726: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:39:59.871: INFO: namespace container-lifecycle-hook-9084 deletion completed in 30.159244647s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:39:59.872: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7399
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec  3 16:40:00.201: INFO: Waiting up to 5m0s for pod "pod-b12c79fb-521c-4ece-bff3-054716e15bf3" in namespace "emptydir-7399" to be "success or failure"
Dec  3 16:40:00.205: INFO: Pod "pod-b12c79fb-521c-4ece-bff3-054716e15bf3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.076329ms
Dec  3 16:40:02.213: INFO: Pod "pod-b12c79fb-521c-4ece-bff3-054716e15bf3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.012449956s
STEP: Saw pod success
Dec  3 16:40:02.214: INFO: Pod "pod-b12c79fb-521c-4ece-bff3-054716e15bf3" satisfied condition "success or failure"
Dec  3 16:40:02.222: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-b12c79fb-521c-4ece-bff3-054716e15bf3 container test-container: <nil>
STEP: delete the pod
Dec  3 16:40:02.264: INFO: Waiting for pod pod-b12c79fb-521c-4ece-bff3-054716e15bf3 to disappear
Dec  3 16:40:02.272: INFO: Pod pod-b12c79fb-521c-4ece-bff3-054716e15bf3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:40:02.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7399" for this suite.
Dec  3 16:40:08.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:40:08.455: INFO: namespace emptydir-7399 deletion completed in 6.167880504s
•SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:40:08.456: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2827
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-c6115133-b2d5-4d23-af7a-9003f87335e7
STEP: Creating a pod to test consume configMaps
Dec  3 16:40:08.799: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-84c4330c-7bc6-4cf9-b117-967e6a653812" in namespace "projected-2827" to be "success or failure"
Dec  3 16:40:08.803: INFO: Pod "pod-projected-configmaps-84c4330c-7bc6-4cf9-b117-967e6a653812": Phase="Pending", Reason="", readiness=false. Elapsed: 3.955957ms
Dec  3 16:40:10.808: INFO: Pod "pod-projected-configmaps-84c4330c-7bc6-4cf9-b117-967e6a653812": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00874803s
STEP: Saw pod success
Dec  3 16:40:10.808: INFO: Pod "pod-projected-configmaps-84c4330c-7bc6-4cf9-b117-967e6a653812" satisfied condition "success or failure"
Dec  3 16:40:10.813: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-projected-configmaps-84c4330c-7bc6-4cf9-b117-967e6a653812 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 16:40:10.833: INFO: Waiting for pod pod-projected-configmaps-84c4330c-7bc6-4cf9-b117-967e6a653812 to disappear
Dec  3 16:40:10.837: INFO: Pod pod-projected-configmaps-84c4330c-7bc6-4cf9-b117-967e6a653812 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:40:10.837: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2827" for this suite.
Dec  3 16:40:16.857: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:40:16.999: INFO: namespace projected-2827 deletion completed in 6.155202141s
•SSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:40:16.999: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-1626
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec  3 16:40:21.333: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1626 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 16:40:21.333: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 16:40:21.769: INFO: Exec stderr: ""
Dec  3 16:40:21.769: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1626 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 16:40:21.769: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 16:40:22.214: INFO: Exec stderr: ""
Dec  3 16:40:22.214: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1626 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 16:40:22.214: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 16:40:22.715: INFO: Exec stderr: ""
Dec  3 16:40:22.716: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1626 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 16:40:22.716: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 16:40:23.190: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec  3 16:40:23.190: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1626 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 16:40:23.190: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 16:40:23.655: INFO: Exec stderr: ""
Dec  3 16:40:23.655: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1626 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 16:40:23.655: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 16:40:24.165: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec  3 16:40:24.165: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1626 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 16:40:24.165: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 16:40:24.619: INFO: Exec stderr: ""
Dec  3 16:40:24.619: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1626 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 16:40:24.619: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 16:40:25.093: INFO: Exec stderr: ""
Dec  3 16:40:25.093: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-1626 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 16:40:25.093: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 16:40:25.529: INFO: Exec stderr: ""
Dec  3 16:40:25.529: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-1626 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 16:40:25.529: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 16:40:25.961: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:40:25.961: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-1626" for this suite.
Dec  3 16:41:11.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:41:12.129: INFO: namespace e2e-kubelet-etc-hosts-1626 deletion completed in 46.160191012s
•SSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:41:12.130: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-91
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-5d7d46ae-c73f-4888-9dfa-70d4b36c2dc4
STEP: Creating a pod to test consume secrets
Dec  3 16:41:12.600: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ddf45c89-0c84-44ad-9683-3cda10d438d8" in namespace "projected-91" to be "success or failure"
Dec  3 16:41:12.605: INFO: Pod "pod-projected-secrets-ddf45c89-0c84-44ad-9683-3cda10d438d8": Phase="Pending", Reason="", readiness=false. Elapsed: 4.194169ms
Dec  3 16:41:14.609: INFO: Pod "pod-projected-secrets-ddf45c89-0c84-44ad-9683-3cda10d438d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009169674s
STEP: Saw pod success
Dec  3 16:41:14.610: INFO: Pod "pod-projected-secrets-ddf45c89-0c84-44ad-9683-3cda10d438d8" satisfied condition "success or failure"
Dec  3 16:41:14.614: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-projected-secrets-ddf45c89-0c84-44ad-9683-3cda10d438d8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:41:14.636: INFO: Waiting for pod pod-projected-secrets-ddf45c89-0c84-44ad-9683-3cda10d438d8 to disappear
Dec  3 16:41:14.640: INFO: Pod pod-projected-secrets-ddf45c89-0c84-44ad-9683-3cda10d438d8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:41:14.640: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-91" for this suite.
Dec  3 16:41:20.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:41:20.797: INFO: namespace projected-91 deletion completed in 6.14951775s
•
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:41:20.797: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-5332
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 16:41:21.527: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 16:41:24.553: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:41:24.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-5332" for this suite.
Dec  3 16:41:32.752: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:41:32.935: INFO: namespace webhook-5332 deletion completed in 8.198545913s
STEP: Destroying namespace "webhook-5332-markers" for this suite.
Dec  3 16:41:38.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:41:39.090: INFO: namespace webhook-5332-markers deletion completed in 6.154768332s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:41:39.108: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-856
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:41:39.500: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-5a83b624-7e20-4d7d-bdf2-bef877ea70b8" in namespace "security-context-test-856" to be "success or failure"
Dec  3 16:41:39.504: INFO: Pod "busybox-privileged-false-5a83b624-7e20-4d7d-bdf2-bef877ea70b8": Phase="Pending", Reason="", readiness=false. Elapsed: 3.949815ms
Dec  3 16:41:41.509: INFO: Pod "busybox-privileged-false-5a83b624-7e20-4d7d-bdf2-bef877ea70b8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.008977097s
Dec  3 16:41:41.510: INFO: Pod "busybox-privileged-false-5a83b624-7e20-4d7d-bdf2-bef877ea70b8" satisfied condition "success or failure"
Dec  3 16:41:41.523: INFO: Got logs for pod "busybox-privileged-false-5a83b624-7e20-4d7d-bdf2-bef877ea70b8": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:41:41.523: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-856" for this suite.
Dec  3 16:41:49.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:41:49.728: INFO: namespace security-context-test-856 deletion completed in 8.197144189s
•SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:41:49.728: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2681
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2681
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-2681
Dec  3 16:41:50.102: INFO: Found 0 stateful pods, waiting for 1
Dec  3 16:42:00.108: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  3 16:42:00.131: INFO: Deleting all statefulset in ns statefulset-2681
Dec  3 16:42:00.135: INFO: Scaling statefulset ss to 0
Dec  3 16:42:20.153: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 16:42:20.157: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:42:20.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2681" for this suite.
Dec  3 16:42:28.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:42:28.331: INFO: namespace statefulset-2681 deletion completed in 8.152792252s
•SSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:42:28.332: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1260
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-701f964e-8118-4568-beb8-1a5d4e7a6f1a
STEP: Creating a pod to test consume secrets
Dec  3 16:42:28.607: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-fb5ab002-f81d-4bdb-b5f0-61d78b0c13c3" in namespace "projected-1260" to be "success or failure"
Dec  3 16:42:28.611: INFO: Pod "pod-projected-secrets-fb5ab002-f81d-4bdb-b5f0-61d78b0c13c3": Phase="Pending", Reason="", readiness=false. Elapsed: 4.073321ms
Dec  3 16:42:30.616: INFO: Pod "pod-projected-secrets-fb5ab002-f81d-4bdb-b5f0-61d78b0c13c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.00870457s
STEP: Saw pod success
Dec  3 16:42:30.616: INFO: Pod "pod-projected-secrets-fb5ab002-f81d-4bdb-b5f0-61d78b0c13c3" satisfied condition "success or failure"
Dec  3 16:42:30.620: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-projected-secrets-fb5ab002-f81d-4bdb-b5f0-61d78b0c13c3 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:42:30.646: INFO: Waiting for pod pod-projected-secrets-fb5ab002-f81d-4bdb-b5f0-61d78b0c13c3 to disappear
Dec  3 16:42:30.650: INFO: Pod pod-projected-secrets-fb5ab002-f81d-4bdb-b5f0-61d78b0c13c3 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:42:30.650: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1260" for this suite.
Dec  3 16:42:36.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:42:36.851: INFO: namespace projected-1260 deletion completed in 6.194504616s
•SSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:42:36.851: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2143
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  3 16:42:37.296: INFO: Waiting up to 5m0s for pod "pod-9a0bb211-7d87-42ce-9422-9c5cbcba8236" in namespace "emptydir-2143" to be "success or failure"
Dec  3 16:42:37.300: INFO: Pod "pod-9a0bb211-7d87-42ce-9422-9c5cbcba8236": Phase="Pending", Reason="", readiness=false. Elapsed: 4.696973ms
Dec  3 16:42:39.305: INFO: Pod "pod-9a0bb211-7d87-42ce-9422-9c5cbcba8236": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.009776073s
STEP: Saw pod success
Dec  3 16:42:39.305: INFO: Pod "pod-9a0bb211-7d87-42ce-9422-9c5cbcba8236" satisfied condition "success or failure"
Dec  3 16:42:39.310: INFO: Trying to get logs from node izgw8fisrtg04goc4t8tqaz pod pod-9a0bb211-7d87-42ce-9422-9c5cbcba8236 container test-container: <nil>
STEP: delete the pod
Dec  3 16:42:39.331: INFO: Waiting for pod pod-9a0bb211-7d87-42ce-9422-9c5cbcba8236 to disappear
Dec  3 16:42:39.335: INFO: Pod pod-9a0bb211-7d87-42ce-9422-9c5cbcba8236 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:42:39.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2143" for this suite.
Dec  3 16:42:47.356: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:42:47.497: INFO: namespace emptydir-2143 deletion completed in 8.155075179s
•SSSSSSSSSDec  3 16:42:47.497: INFO: Running AfterSuite actions on all nodes
Dec  3 16:42:47.498: INFO: Running AfterSuite actions on node 1
Dec  3 16:42:47.498: INFO: Skipping dumping logs from cluster

Ran 276 of 4732 Specs in 7423.420 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Flaked | 0 Pending | 4456 Skipped
PASS

Ginkgo ran 1 suite in 2h3m45.088647586s
Test Suite Passed
