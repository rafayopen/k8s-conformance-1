Conformance test: not doing test setup.
I1203 14:49:19.171945    5095 e2e.go:92] Starting e2e run "bc4eecb9-790a-4046-90f5-c1793f709680" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1575384557 - Will randomize all specs
Will run 276 of 4732 specs

Dec  3 14:49:19.392: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Deleting namespaces
STEP: Waiting for namespaces to vanish
I1203 14:49:19.485514    5095 suites.go:70] Waiting for deletion of the following namespaces: []
Dec  3 14:49:21.507: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec  3 14:49:21.572: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec  3 14:49:21.684: INFO: 20 / 20 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec  3 14:49:21.684: INFO: expected 12 pod replicas in namespace 'kube-system', 12 are Running and Ready.
Dec  3 14:49:21.684: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec  3 14:49:21.714: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Dec  3 14:49:21.714: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec  3 14:49:21.714: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Dec  3 14:49:21.714: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-problem-detector' (0 seconds elapsed)
Dec  3 14:49:21.714: INFO: e2e test version: v1.16.3
Dec  3 14:49:21.734: INFO: kube-apiserver version: v1.16.3
Dec  3 14:49:21.734: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 14:49:21.758: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:49:21.759: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
Dec  3 14:49:21.870: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Dec  3 14:49:21.935: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2678
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  3 14:49:22.146: INFO: Waiting up to 5m0s for pod "pod-004085fb-d0cd-409c-8624-3713cc435160" in namespace "emptydir-2678" to be "success or failure"
Dec  3 14:49:22.167: INFO: Pod "pod-004085fb-d0cd-409c-8624-3713cc435160": Phase="Pending", Reason="", readiness=false. Elapsed: 20.431384ms
Dec  3 14:49:24.188: INFO: Pod "pod-004085fb-d0cd-409c-8624-3713cc435160": Phase="Pending", Reason="", readiness=false. Elapsed: 2.041935138s
Dec  3 14:49:26.212: INFO: Pod "pod-004085fb-d0cd-409c-8624-3713cc435160": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.065001589s
STEP: Saw pod success
Dec  3 14:49:26.212: INFO: Pod "pod-004085fb-d0cd-409c-8624-3713cc435160" satisfied condition "success or failure"
Dec  3 14:49:26.233: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-004085fb-d0cd-409c-8624-3713cc435160 container test-container: <nil>
STEP: delete the pod
Dec  3 14:49:26.435: INFO: Waiting for pod pod-004085fb-d0cd-409c-8624-3713cc435160 to disappear
Dec  3 14:49:26.459: INFO: Pod pod-004085fb-d0cd-409c-8624-3713cc435160 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:49:26.459: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2678" for this suite.
Dec  3 14:49:32.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:49:33.398: INFO: namespace emptydir-2678 deletion completed in 6.898631817s
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:49:33.398: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8199
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-7f34e212-28d9-4421-854f-95b24243bfdd
STEP: Creating a pod to test consume secrets
Dec  3 14:49:33.685: INFO: Waiting up to 5m0s for pod "pod-secrets-1cc6346b-278f-495d-ad7f-0bf53d8f4868" in namespace "secrets-8199" to be "success or failure"
Dec  3 14:49:33.705: INFO: Pod "pod-secrets-1cc6346b-278f-495d-ad7f-0bf53d8f4868": Phase="Pending", Reason="", readiness=false. Elapsed: 20.756398ms
Dec  3 14:49:35.727: INFO: Pod "pod-secrets-1cc6346b-278f-495d-ad7f-0bf53d8f4868": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042733837s
Dec  3 14:49:37.749: INFO: Pod "pod-secrets-1cc6346b-278f-495d-ad7f-0bf53d8f4868": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.064781337s
STEP: Saw pod success
Dec  3 14:49:37.750: INFO: Pod "pod-secrets-1cc6346b-278f-495d-ad7f-0bf53d8f4868" satisfied condition "success or failure"
Dec  3 14:49:37.771: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-secrets-1cc6346b-278f-495d-ad7f-0bf53d8f4868 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:49:37.845: INFO: Waiting for pod pod-secrets-1cc6346b-278f-495d-ad7f-0bf53d8f4868 to disappear
Dec  3 14:49:37.866: INFO: Pod pod-secrets-1cc6346b-278f-495d-ad7f-0bf53d8f4868 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:49:37.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8199" for this suite.
Dec  3 14:49:43.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:49:44.861: INFO: namespace secrets-8199 deletion completed in 6.954361306s
•SSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:49:44.861: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8644
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-cp8s
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 14:49:45.175: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-cp8s" in namespace "subpath-8644" to be "success or failure"
Dec  3 14:49:45.196: INFO: Pod "pod-subpath-test-secret-cp8s": Phase="Pending", Reason="", readiness=false. Elapsed: 20.955339ms
Dec  3 14:49:47.218: INFO: Pod "pod-subpath-test-secret-cp8s": Phase="Running", Reason="", readiness=true. Elapsed: 2.042674926s
Dec  3 14:49:49.239: INFO: Pod "pod-subpath-test-secret-cp8s": Phase="Running", Reason="", readiness=true. Elapsed: 4.064484854s
Dec  3 14:49:51.339: INFO: Pod "pod-subpath-test-secret-cp8s": Phase="Running", Reason="", readiness=true. Elapsed: 6.16400383s
Dec  3 14:49:53.361: INFO: Pod "pod-subpath-test-secret-cp8s": Phase="Running", Reason="", readiness=true. Elapsed: 8.185956993s
Dec  3 14:49:55.383: INFO: Pod "pod-subpath-test-secret-cp8s": Phase="Running", Reason="", readiness=true. Elapsed: 10.207863283s
Dec  3 14:49:57.404: INFO: Pod "pod-subpath-test-secret-cp8s": Phase="Running", Reason="", readiness=true. Elapsed: 12.229070143s
Dec  3 14:49:59.425: INFO: Pod "pod-subpath-test-secret-cp8s": Phase="Running", Reason="", readiness=true. Elapsed: 14.250595473s
Dec  3 14:50:01.447: INFO: Pod "pod-subpath-test-secret-cp8s": Phase="Running", Reason="", readiness=true. Elapsed: 16.272079357s
Dec  3 14:50:03.468: INFO: Pod "pod-subpath-test-secret-cp8s": Phase="Running", Reason="", readiness=true. Elapsed: 18.293513703s
Dec  3 14:50:05.490: INFO: Pod "pod-subpath-test-secret-cp8s": Phase="Running", Reason="", readiness=true. Elapsed: 20.31506536s
Dec  3 14:50:07.512: INFO: Pod "pod-subpath-test-secret-cp8s": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.337192157s
STEP: Saw pod success
Dec  3 14:50:07.512: INFO: Pod "pod-subpath-test-secret-cp8s" satisfied condition "success or failure"
Dec  3 14:50:07.533: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-subpath-test-secret-cp8s container test-container-subpath-secret-cp8s: <nil>
STEP: delete the pod
Dec  3 14:50:07.619: INFO: Waiting for pod pod-subpath-test-secret-cp8s to disappear
Dec  3 14:50:07.640: INFO: Pod pod-subpath-test-secret-cp8s no longer exists
STEP: Deleting pod pod-subpath-test-secret-cp8s
Dec  3 14:50:07.640: INFO: Deleting pod "pod-subpath-test-secret-cp8s" in namespace "subpath-8644"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:50:07.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8644" for this suite.
Dec  3 14:50:13.767: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:14.538: INFO: namespace subpath-8644 deletion completed in 6.837146717s
•SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:50:14.539: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1848
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 14:50:14.817: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  3 14:50:24.868: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec  3 14:50:26.890: INFO: Creating deployment "test-rollover-deployment"
Dec  3 14:50:26.938: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec  3 14:50:28.980: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec  3 14:50:29.022: INFO: Ensure that both replica sets have 1 created replica
Dec  3 14:50:29.066: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec  3 14:50:29.108: INFO: Updating deployment test-rollover-deployment
Dec  3 14:50:29.108: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec  3 14:50:31.154: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec  3 14:50:31.197: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec  3 14:50:31.241: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:50:31.242: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981426, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981426, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981429, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981426, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:50:33.290: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:50:33.290: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981426, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981426, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981429, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981426, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:50:35.284: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:50:35.284: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981426, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981426, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981435, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981426, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:50:37.289: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:50:37.289: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981426, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981426, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981435, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981426, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:50:39.286: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:50:39.286: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981426, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981426, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981435, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981426, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:50:41.286: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:50:41.286: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981426, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981426, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981435, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981426, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:50:43.284: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:50:43.284: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981426, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981426, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981435, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981426, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:50:45.285: INFO: 
Dec  3 14:50:45.285: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec  3 14:50:45.356: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-1848 /apis/apps/v1/namespaces/deployment-1848/deployments/test-rollover-deployment b507cc96-704b-4a33-a9b0-408006877461 2929 2 2019-12-03 14:50:26 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003b2c028 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-03 14:50:26 +0000 UTC,LastTransitionTime:2019-12-03 14:50:26 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2019-12-03 14:50:45 +0000 UTC,LastTransitionTime:2019-12-03 14:50:26 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 14:50:45.378: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-1848 /apis/apps/v1/namespaces/deployment-1848/replicasets/test-rollover-deployment-7d7dc6548c 50e731cc-acdd-4051-8127-82c6621c6d7a 2922 2 2019-12-03 14:50:29 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment b507cc96-704b-4a33-a9b0-408006877461 0xc003766967 0xc003766968}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0037669c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec  3 14:50:45.378: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec  3 14:50:45.378: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-1848 /apis/apps/v1/namespaces/deployment-1848/replicasets/test-rollover-controller 6259abdc-e8c5-4c95-afd7-7fdbe4cf4011 2928 2 2019-12-03 14:50:14 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment b507cc96-704b-4a33-a9b0-408006877461 0xc00376688f 0xc0037668a0}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003766908 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 14:50:45.379: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-1848 /apis/apps/v1/namespaces/deployment-1848/replicasets/test-rollover-deployment-f6c94f66c 26270e2b-8aef-4145-84e7-9663b0491e81 2878 2 2019-12-03 14:50:26 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment b507cc96-704b-4a33-a9b0-408006877461 0xc003766a20 0xc003766a21}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003766a98 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 14:50:45.400: INFO: Pod "test-rollover-deployment-7d7dc6548c-59fkw" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-59fkw test-rollover-deployment-7d7dc6548c- deployment-1848 /api/v1/namespaces/deployment-1848/pods/test-rollover-deployment-7d7dc6548c-59fkw e22a672b-1d59-411c-bf52-e89a27aaa59e 2895 0 2019-12-03 14:50:29 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[cni.projectcalico.org/podIP:100.64.1.8/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c 50e731cc-acdd-4051-8127-82c6621c6d7a 0xc003766fd7 0xc003766fd8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-m9nx9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-m9nx9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-m9nx9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 14:50:29 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 14:50:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 14:50:35 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 14:50:29 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.1.8,StartTime:2019-12-03 14:50:29 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 14:50:34 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://1bfe876af2e245a5923ed4f70d2264d038dcc81717538b86e21569d0b31d0550,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.8,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:50:45.400: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1848" for this suite.
Dec  3 14:50:51.506: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:52.237: INFO: namespace deployment-1848 deletion completed in 6.795997863s
•
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:50:52.237: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9372
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-f4260be3-3db7-4590-9728-4382252086b3
STEP: Creating a pod to test consume secrets
Dec  3 14:50:52.532: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-da309423-d63f-4d0e-8d33-42507470adfa" in namespace "projected-9372" to be "success or failure"
Dec  3 14:50:52.553: INFO: Pod "pod-projected-secrets-da309423-d63f-4d0e-8d33-42507470adfa": Phase="Pending", Reason="", readiness=false. Elapsed: 20.47993ms
Dec  3 14:50:54.574: INFO: Pod "pod-projected-secrets-da309423-d63f-4d0e-8d33-42507470adfa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.04200255s
STEP: Saw pod success
Dec  3 14:50:54.575: INFO: Pod "pod-projected-secrets-da309423-d63f-4d0e-8d33-42507470adfa" satisfied condition "success or failure"
Dec  3 14:50:54.595: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-projected-secrets-da309423-d63f-4d0e-8d33-42507470adfa container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:50:54.652: INFO: Waiting for pod pod-projected-secrets-da309423-d63f-4d0e-8d33-42507470adfa to disappear
Dec  3 14:50:54.673: INFO: Pod pod-projected-secrets-da309423-d63f-4d0e-8d33-42507470adfa no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:50:54.673: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9372" for this suite.
Dec  3 14:51:00.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:01.580: INFO: namespace projected-9372 deletion completed in 6.866940906s
•SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:51:01.581: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9566
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 14:51:02.408: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981462, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981462, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981462, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981462, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:51:04.429: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981462, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981462, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981462, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981462, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:51:06.430: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981462, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981462, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981462, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981462, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:51:08.429: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981462, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981462, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981462, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981462, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 14:51:11.477: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:51:12.126: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9566" for this suite.
Dec  3 14:51:18.211: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:18.948: INFO: namespace webhook-9566 deletion completed in 6.801570245s
STEP: Destroying namespace "webhook-9566-markers" for this suite.
Dec  3 14:51:25.011: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:25.735: INFO: namespace webhook-9566-markers deletion completed in 6.786193042s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:51:25.822: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4833
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 14:51:26.223: INFO: Create a RollingUpdate DaemonSet
Dec  3 14:51:26.244: INFO: Check that daemon pods launch on every node of the cluster
Dec  3 14:51:26.316: INFO: Number of nodes with available pods: 0
Dec  3 14:51:26.316: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 14:51:27.381: INFO: Number of nodes with available pods: 0
Dec  3 14:51:27.382: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 14:51:28.379: INFO: Number of nodes with available pods: 1
Dec  3 14:51:28.379: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v is running more than one daemon pod
Dec  3 14:51:29.384: INFO: Number of nodes with available pods: 1
Dec  3 14:51:29.385: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v is running more than one daemon pod
Dec  3 14:51:30.377: INFO: Number of nodes with available pods: 1
Dec  3 14:51:30.377: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v is running more than one daemon pod
Dec  3 14:51:31.378: INFO: Number of nodes with available pods: 1
Dec  3 14:51:31.378: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v is running more than one daemon pod
Dec  3 14:51:32.389: INFO: Number of nodes with available pods: 1
Dec  3 14:51:32.389: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v is running more than one daemon pod
Dec  3 14:51:33.378: INFO: Number of nodes with available pods: 1
Dec  3 14:51:33.378: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v is running more than one daemon pod
Dec  3 14:51:34.385: INFO: Number of nodes with available pods: 1
Dec  3 14:51:34.385: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v is running more than one daemon pod
Dec  3 14:51:35.385: INFO: Number of nodes with available pods: 2
Dec  3 14:51:35.385: INFO: Number of running nodes: 2, number of available pods: 2
Dec  3 14:51:35.386: INFO: Update the DaemonSet to trigger a rollout
Dec  3 14:51:35.431: INFO: Updating DaemonSet daemon-set
Dec  3 14:51:46.549: INFO: Roll back the DaemonSet before rollout is complete
Dec  3 14:51:46.595: INFO: Updating DaemonSet daemon-set
Dec  3 14:51:46.595: INFO: Make sure DaemonSet rollback is complete
Dec  3 14:51:46.622: INFO: Wrong image for pod: daemon-set-hml7f. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec  3 14:51:46.622: INFO: Pod daemon-set-hml7f is not available
Dec  3 14:51:47.670: INFO: Wrong image for pod: daemon-set-hml7f. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec  3 14:51:47.670: INFO: Pod daemon-set-hml7f is not available
Dec  3 14:51:48.681: INFO: Pod daemon-set-hjrxs is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4833, will wait for the garbage collector to delete the pods
Dec  3 14:51:48.871: INFO: Deleting DaemonSet.extensions daemon-set took: 25.054545ms
Dec  3 14:51:49.272: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.41568ms
Dec  3 14:51:51.595: INFO: Number of nodes with available pods: 0
Dec  3 14:51:51.595: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 14:51:51.620: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4833/daemonsets","resourceVersion":"3255"},"items":null}

Dec  3 14:51:51.643: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4833/pods","resourceVersion":"3255"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:51:51.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4833" for this suite.
Dec  3 14:51:57.830: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:58.635: INFO: namespace daemonsets-4833 deletion completed in 6.877151138s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:51:58.635: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4709
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-4709
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-4709
Dec  3 14:51:58.959: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Dec  3 14:52:08.984: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  3 14:52:09.102: INFO: Deleting all statefulset in ns statefulset-4709
Dec  3 14:52:09.125: INFO: Scaling statefulset ss to 0
Dec  3 14:52:39.225: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 14:52:39.248: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:52:39.320: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4709" for this suite.
Dec  3 14:52:45.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:52:46.238: INFO: namespace statefulset-4709 deletion completed in 6.874412713s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:52:46.239: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9311
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  3 14:52:46.496: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-9311'
Dec  3 14:52:46.692: INFO: stderr: ""
Dec  3 14:52:46.692: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Dec  3 14:52:51.743: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod e2e-test-httpd-pod --namespace=kubectl-9311 -o json'
Dec  3 14:52:51.901: INFO: stderr: ""
Dec  3 14:52:51.901: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"100.64.1.13/32\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-12-03T14:52:46Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-9311\",\n        \"resourceVersion\": \"3461\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-9311/pods/e2e-test-httpd-pod\",\n        \"uid\": \"2b56b082-1aa4-4b1f-b53e-68e197e38991\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-dlqxr\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-dlqxr\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-dlqxr\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-03T14:52:46Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-03T14:52:48Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-03T14:52:48Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-03T14:52:46Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://0230145f0eaad84fc33563df8b2feed99b3505cb2b72ce1f348861b781e47e5b\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-12-03T14:52:48Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.0.4\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.64.1.13\",\n        \"podIPs\": [\n            {\n                \"ip\": \"100.64.1.13\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-12-03T14:52:46Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec  3 14:52:51.901: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config replace -f - --namespace=kubectl-9311'
Dec  3 14:52:53.307: INFO: stderr: ""
Dec  3 14:52:53.307: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Dec  3 14:52:53.330: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pods e2e-test-httpd-pod --namespace=kubectl-9311'
Dec  3 14:52:57.331: INFO: stderr: ""
Dec  3 14:52:57.331: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:52:57.331: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9311" for this suite.
Dec  3 14:53:03.445: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:53:04.266: INFO: namespace kubectl-9311 deletion completed in 6.890762019s
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:53:04.267: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2978
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 14:53:04.524: INFO: Creating deployment "test-recreate-deployment"
Dec  3 14:53:04.547: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec  3 14:53:04.609: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec  3 14:53:04.637: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981584, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981584, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981584, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981584, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:53:06.661: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec  3 14:53:06.707: INFO: Updating deployment test-recreate-deployment
Dec  3 14:53:06.707: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec  3 14:53:06.785: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-2978 /apis/apps/v1/namespaces/deployment-2978/deployments/test-recreate-deployment 03e7ca4d-ccf9-48b7-9922-fc26b9549412 3554 2 2019-12-03 14:53:04 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003e30e88 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-12-03 14:53:06 +0000 UTC,LastTransitionTime:2019-12-03 14:53:06 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2019-12-03 14:53:06 +0000 UTC,LastTransitionTime:2019-12-03 14:53:04 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Dec  3 14:53:06.816: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-2978 /apis/apps/v1/namespaces/deployment-2978/replicasets/test-recreate-deployment-5f94c574ff c49bd0c4-8e0a-4ab9-b1c0-adfddb3aa878 3553 1 2019-12-03 14:53:06 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 03e7ca4d-ccf9-48b7-9922-fc26b9549412 0xc003e31247 0xc003e31248}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003e312a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 14:53:06.816: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec  3 14:53:06.816: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-2978 /apis/apps/v1/namespaces/deployment-2978/replicasets/test-recreate-deployment-68fc85c7bb 995fc54a-292f-4da3-9116-d3616d3ccf5e 3546 2 2019-12-03 14:53:04 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 03e7ca4d-ccf9-48b7-9922-fc26b9549412 0xc003e31307 0xc003e31308}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003e31368 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 14:53:06.840: INFO: Pod "test-recreate-deployment-5f94c574ff-ltqk8" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-ltqk8 test-recreate-deployment-5f94c574ff- deployment-2978 /api/v1/namespaces/deployment-2978/pods/test-recreate-deployment-5f94c574ff-ltqk8 e78f74ff-f177-4fa4-9972-3563ac57dade 3555 0 2019-12-03 14:53:06 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff c49bd0c4-8e0a-4ab9-b1c0-adfddb3aa878 0xc003e318e7 0xc003e318e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-qb487,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-qb487,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-qb487,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 14:53:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 14:53:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 14:53:06 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 14:53:06 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-12-03 14:53:06 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:53:06.840: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2978" for this suite.
Dec  3 14:53:12.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:53:13.756: INFO: namespace deployment-2978 deletion completed in 6.870583326s
•SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:53:13.756: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6127
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec  3 14:53:14.009: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:53:19.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6127" for this suite.
Dec  3 14:53:47.517: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:53:48.334: INFO: namespace init-container-6127 deletion completed in 28.907338173s
•SSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:53:48.334: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-4365
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3707
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-5881
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:53:55.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-4365" for this suite.
Dec  3 14:54:01.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:54:02.136: INFO: namespace namespaces-4365 deletion completed in 6.878492795s
STEP: Destroying namespace "nsdeletetest-3707" for this suite.
Dec  3 14:54:02.159: INFO: Namespace nsdeletetest-3707 was already deleted
STEP: Destroying namespace "nsdeletetest-5881" for this suite.
Dec  3 14:54:08.230: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:54:09.056: INFO: namespace nsdeletetest-5881 deletion completed in 6.89690929s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:54:09.056: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3534
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:54:09.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3534" for this suite.
Dec  3 14:54:15.543: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:54:16.367: INFO: namespace resourcequota-3534 deletion completed in 6.89466741s
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:54:16.368: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2113
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-3627918c-da61-42a6-900b-8b7e205dc565
STEP: Creating a pod to test consume configMaps
Dec  3 14:54:16.679: INFO: Waiting up to 5m0s for pod "pod-configmaps-0870ab22-661c-4666-a01d-f05b674afb2a" in namespace "configmap-2113" to be "success or failure"
Dec  3 14:54:16.702: INFO: Pod "pod-configmaps-0870ab22-661c-4666-a01d-f05b674afb2a": Phase="Pending", Reason="", readiness=false. Elapsed: 23.045728ms
Dec  3 14:54:18.726: INFO: Pod "pod-configmaps-0870ab22-661c-4666-a01d-f05b674afb2a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047144448s
Dec  3 14:54:20.749: INFO: Pod "pod-configmaps-0870ab22-661c-4666-a01d-f05b674afb2a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.070790264s
STEP: Saw pod success
Dec  3 14:54:20.750: INFO: Pod "pod-configmaps-0870ab22-661c-4666-a01d-f05b674afb2a" satisfied condition "success or failure"
Dec  3 14:54:20.773: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-configmaps-0870ab22-661c-4666-a01d-f05b674afb2a container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 14:54:20.970: INFO: Waiting for pod pod-configmaps-0870ab22-661c-4666-a01d-f05b674afb2a to disappear
Dec  3 14:54:21.001: INFO: Pod pod-configmaps-0870ab22-661c-4666-a01d-f05b674afb2a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:54:21.001: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2113" for this suite.
Dec  3 14:54:27.115: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:54:27.917: INFO: namespace configmap-2113 deletion completed in 6.871852879s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:54:27.918: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7395
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:54:28.202: INFO: Waiting up to 5m0s for pod "downwardapi-volume-dc88d78f-cecb-4cbb-8e36-829d20834e37" in namespace "projected-7395" to be "success or failure"
Dec  3 14:54:28.225: INFO: Pod "downwardapi-volume-dc88d78f-cecb-4cbb-8e36-829d20834e37": Phase="Pending", Reason="", readiness=false. Elapsed: 23.2549ms
Dec  3 14:54:30.249: INFO: Pod "downwardapi-volume-dc88d78f-cecb-4cbb-8e36-829d20834e37": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.04726957s
STEP: Saw pod success
Dec  3 14:54:30.249: INFO: Pod "downwardapi-volume-dc88d78f-cecb-4cbb-8e36-829d20834e37" satisfied condition "success or failure"
Dec  3 14:54:30.273: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downwardapi-volume-dc88d78f-cecb-4cbb-8e36-829d20834e37 container client-container: <nil>
STEP: delete the pod
Dec  3 14:54:30.351: INFO: Waiting for pod downwardapi-volume-dc88d78f-cecb-4cbb-8e36-829d20834e37 to disappear
Dec  3 14:54:30.374: INFO: Pod downwardapi-volume-dc88d78f-cecb-4cbb-8e36-829d20834e37 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:54:30.374: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7395" for this suite.
Dec  3 14:54:36.488: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:54:37.286: INFO: namespace projected-7395 deletion completed in 6.867586488s
•SS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:54:37.286: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5401
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  3 14:54:39.660: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:54:39.710: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5401" for this suite.
Dec  3 14:54:45.825: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:54:46.631: INFO: namespace container-runtime-5401 deletion completed in 6.876438061s
•SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:54:46.631: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2856
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Dec  3 14:54:46.886: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config cluster-info'
Dec  3 14:54:47.043: INFO: stderr: ""
Dec  3 14:54:47.044: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:54:47.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2856" for this suite.
Dec  3 14:54:53.138: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:54:53.965: INFO: namespace kubectl-2856 deletion completed in 6.896916444s
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:54:53.965: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-64
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-bab2d4ac-80fb-45a1-91c2-111af9b3d205
STEP: Creating a pod to test consume secrets
Dec  3 14:54:54.272: INFO: Waiting up to 5m0s for pod "pod-secrets-f52de0f0-710c-4db9-ae1e-10d4e5695e23" in namespace "secrets-64" to be "success or failure"
Dec  3 14:54:54.296: INFO: Pod "pod-secrets-f52de0f0-710c-4db9-ae1e-10d4e5695e23": Phase="Pending", Reason="", readiness=false. Elapsed: 23.650342ms
Dec  3 14:54:56.320: INFO: Pod "pod-secrets-f52de0f0-710c-4db9-ae1e-10d4e5695e23": Phase="Pending", Reason="", readiness=false. Elapsed: 2.047378557s
Dec  3 14:54:58.343: INFO: Pod "pod-secrets-f52de0f0-710c-4db9-ae1e-10d4e5695e23": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.071043362s
STEP: Saw pod success
Dec  3 14:54:58.343: INFO: Pod "pod-secrets-f52de0f0-710c-4db9-ae1e-10d4e5695e23" satisfied condition "success or failure"
Dec  3 14:54:58.366: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-secrets-f52de0f0-710c-4db9-ae1e-10d4e5695e23 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:54:58.426: INFO: Waiting for pod pod-secrets-f52de0f0-710c-4db9-ae1e-10d4e5695e23 to disappear
Dec  3 14:54:58.449: INFO: Pod pod-secrets-f52de0f0-710c-4db9-ae1e-10d4e5695e23 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:54:58.449: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-64" for this suite.
Dec  3 14:55:04.564: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:55:05.363: INFO: namespace secrets-64 deletion completed in 6.869099444s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:55:05.364: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7047
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  3 14:55:08.768: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:55:08.819: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7047" for this suite.
Dec  3 14:55:14.934: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:55:15.767: INFO: namespace container-runtime-7047 deletion completed in 6.904046858s
•SSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:55:15.768: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-7691
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  3 14:55:20.245: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:55:20.271: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:55:22.271: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:55:22.296: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:55:24.271: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:55:24.295: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:55:26.271: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:55:26.295: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:55:28.271: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:55:28.295: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:55:30.271: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:55:30.295: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 14:55:32.271: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 14:55:32.295: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:55:32.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-7691" for this suite.
Dec  3 14:55:44.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:55:45.245: INFO: namespace container-lifecycle-hook-7691 deletion completed in 12.871952903s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:55:45.246: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6510
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Dec  3 14:55:45.502: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Dec  3 14:56:00.574: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 14:56:04.187: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:56:19.590: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6510" for this suite.
Dec  3 14:56:25.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:56:26.278: INFO: namespace crd-publish-openapi-6510 deletion completed in 6.654198192s
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:56:26.278: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8146
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8146.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-8146.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8146.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-8146.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-8146.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8146.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 14:56:45.169: INFO: DNS probes using dns-8146/dns-test-6943dd51-066d-4ab6-ae1d-5395b5d48f13 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:56:45.203: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8146" for this suite.
Dec  3 14:56:51.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:56:51.890: INFO: namespace dns-8146 deletion completed in 6.654364014s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:56:51.891: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6569
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  3 14:56:52.113: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-6569'
Dec  3 14:56:52.279: INFO: stderr: ""
Dec  3 14:56:52.279: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Dec  3 14:56:52.296: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pods e2e-test-httpd-pod --namespace=kubectl-6569'
Dec  3 14:57:00.737: INFO: stderr: ""
Dec  3 14:57:00.737: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:57:00.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6569" for this suite.
Dec  3 14:57:06.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:57:07.417: INFO: namespace kubectl-6569 deletion completed in 6.647521723s
•SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:57:07.417: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-284
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Dec  3 14:57:09.745: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec pod-sharedvolume-b0cc80fd-d381-4828-8036-9bc61aef7d62 -c busybox-main-container --namespace=emptydir-284 -- cat /usr/share/volumeshare/shareddata.txt'
Dec  3 14:57:10.391: INFO: stderr: ""
Dec  3 14:57:10.391: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:57:10.391: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-284" for this suite.
Dec  3 14:57:16.477: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:57:17.113: INFO: namespace emptydir-284 deletion completed in 6.688656253s
•S
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:57:17.113: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-9047
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 14:57:17.331: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:57:21.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-9047" for this suite.
Dec  3 14:58:05.717: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:58:06.320: INFO: namespace pods-9047 deletion completed in 44.656305257s
•SSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:58:06.320: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8725
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:58:06.562: INFO: Waiting up to 5m0s for pod "downwardapi-volume-40f8b657-7114-4aca-b506-ba364510db07" in namespace "projected-8725" to be "success or failure"
Dec  3 14:58:06.579: INFO: Pod "downwardapi-volume-40f8b657-7114-4aca-b506-ba364510db07": Phase="Pending", Reason="", readiness=false. Elapsed: 16.876901ms
Dec  3 14:58:08.597: INFO: Pod "downwardapi-volume-40f8b657-7114-4aca-b506-ba364510db07": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034963762s
Dec  3 14:58:10.615: INFO: Pod "downwardapi-volume-40f8b657-7114-4aca-b506-ba364510db07": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052982508s
STEP: Saw pod success
Dec  3 14:58:10.615: INFO: Pod "downwardapi-volume-40f8b657-7114-4aca-b506-ba364510db07" satisfied condition "success or failure"
Dec  3 14:58:10.632: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downwardapi-volume-40f8b657-7114-4aca-b506-ba364510db07 container client-container: <nil>
STEP: delete the pod
Dec  3 14:58:10.687: INFO: Waiting for pod downwardapi-volume-40f8b657-7114-4aca-b506-ba364510db07 to disappear
Dec  3 14:58:10.704: INFO: Pod downwardapi-volume-40f8b657-7114-4aca-b506-ba364510db07 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:58:10.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8725" for this suite.
Dec  3 14:58:16.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:58:17.377: INFO: namespace projected-8725 deletion completed in 6.640549014s
•SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:58:17.378: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5321
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:58:17.631: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0ecb0a40-bd55-4977-b506-03d22cc3a7c6" in namespace "downward-api-5321" to be "success or failure"
Dec  3 14:58:17.649: INFO: Pod "downwardapi-volume-0ecb0a40-bd55-4977-b506-03d22cc3a7c6": Phase="Pending", Reason="", readiness=false. Elapsed: 17.042659ms
Dec  3 14:58:19.667: INFO: Pod "downwardapi-volume-0ecb0a40-bd55-4977-b506-03d22cc3a7c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035456418s
STEP: Saw pod success
Dec  3 14:58:19.667: INFO: Pod "downwardapi-volume-0ecb0a40-bd55-4977-b506-03d22cc3a7c6" satisfied condition "success or failure"
Dec  3 14:58:19.684: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downwardapi-volume-0ecb0a40-bd55-4977-b506-03d22cc3a7c6 container client-container: <nil>
STEP: delete the pod
Dec  3 14:58:19.745: INFO: Waiting for pod downwardapi-volume-0ecb0a40-bd55-4977-b506-03d22cc3a7c6 to disappear
Dec  3 14:58:19.762: INFO: Pod downwardapi-volume-0ecb0a40-bd55-4977-b506-03d22cc3a7c6 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:58:19.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5321" for this suite.
Dec  3 14:58:25.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:58:26.496: INFO: namespace downward-api-5321 deletion completed in 6.692625807s
•SSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:58:26.497: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3591
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 14:58:26.799: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec  3 14:58:26.836: INFO: Number of nodes with available pods: 0
Dec  3 14:58:26.836: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec  3 14:58:26.911: INFO: Number of nodes with available pods: 0
Dec  3 14:58:26.911: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 14:58:27.929: INFO: Number of nodes with available pods: 0
Dec  3 14:58:27.929: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 14:58:28.930: INFO: Number of nodes with available pods: 0
Dec  3 14:58:28.930: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 14:58:29.930: INFO: Number of nodes with available pods: 1
Dec  3 14:58:29.930: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec  3 14:58:30.012: INFO: Number of nodes with available pods: 0
Dec  3 14:58:30.012: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec  3 14:58:30.049: INFO: Number of nodes with available pods: 0
Dec  3 14:58:30.049: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 14:58:31.067: INFO: Number of nodes with available pods: 0
Dec  3 14:58:31.067: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 14:58:32.067: INFO: Number of nodes with available pods: 0
Dec  3 14:58:32.067: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 14:58:33.066: INFO: Number of nodes with available pods: 0
Dec  3 14:58:33.067: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 14:58:34.069: INFO: Number of nodes with available pods: 0
Dec  3 14:58:34.069: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 14:58:35.066: INFO: Number of nodes with available pods: 1
Dec  3 14:58:35.066: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3591, will wait for the garbage collector to delete the pods
Dec  3 14:58:35.187: INFO: Deleting DaemonSet.extensions daemon-set took: 19.645124ms
Dec  3 14:58:35.288: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.325912ms
Dec  3 14:58:39.205: INFO: Number of nodes with available pods: 0
Dec  3 14:58:39.205: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 14:58:39.222: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3591/daemonsets","resourceVersion":"4768"},"items":null}

Dec  3 14:58:39.239: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3591/pods","resourceVersion":"4768"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:58:39.327: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3591" for this suite.
Dec  3 14:58:45.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:58:46.040: INFO: namespace daemonsets-3591 deletion completed in 6.695254609s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:58:46.040: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3610
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec  3 14:58:46.294: INFO: Waiting up to 5m0s for pod "downward-api-908f8d0a-a505-4c9c-896b-00db8261e7b0" in namespace "downward-api-3610" to be "success or failure"
Dec  3 14:58:46.312: INFO: Pod "downward-api-908f8d0a-a505-4c9c-896b-00db8261e7b0": Phase="Pending", Reason="", readiness=false. Elapsed: 17.633236ms
Dec  3 14:58:48.330: INFO: Pod "downward-api-908f8d0a-a505-4c9c-896b-00db8261e7b0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035136821s
STEP: Saw pod success
Dec  3 14:58:48.330: INFO: Pod "downward-api-908f8d0a-a505-4c9c-896b-00db8261e7b0" satisfied condition "success or failure"
Dec  3 14:58:48.347: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downward-api-908f8d0a-a505-4c9c-896b-00db8261e7b0 container dapi-container: <nil>
STEP: delete the pod
Dec  3 14:58:48.402: INFO: Waiting for pod downward-api-908f8d0a-a505-4c9c-896b-00db8261e7b0 to disappear
Dec  3 14:58:48.418: INFO: Pod downward-api-908f8d0a-a505-4c9c-896b-00db8261e7b0 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:58:48.419: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3610" for this suite.
Dec  3 14:58:54.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:58:55.126: INFO: namespace downward-api-3610 deletion completed in 6.675432435s
•SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:58:55.127: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9809
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-e7a0a0bb-a6b7-42ef-bebc-427fc88ee051
STEP: Creating a pod to test consume configMaps
Dec  3 14:58:55.380: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-79e204ab-bdf0-4b1f-9983-429751d01786" in namespace "projected-9809" to be "success or failure"
Dec  3 14:58:55.398: INFO: Pod "pod-projected-configmaps-79e204ab-bdf0-4b1f-9983-429751d01786": Phase="Pending", Reason="", readiness=false. Elapsed: 17.187375ms
Dec  3 14:58:57.508: INFO: Pod "pod-projected-configmaps-79e204ab-bdf0-4b1f-9983-429751d01786": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.127262057s
STEP: Saw pod success
Dec  3 14:58:57.508: INFO: Pod "pod-projected-configmaps-79e204ab-bdf0-4b1f-9983-429751d01786" satisfied condition "success or failure"
Dec  3 14:58:57.525: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-projected-configmaps-79e204ab-bdf0-4b1f-9983-429751d01786 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 14:58:57.581: INFO: Waiting for pod pod-projected-configmaps-79e204ab-bdf0-4b1f-9983-429751d01786 to disappear
Dec  3 14:58:57.599: INFO: Pod pod-projected-configmaps-79e204ab-bdf0-4b1f-9983-429751d01786 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:58:57.599: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9809" for this suite.
Dec  3 14:59:03.684: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:59:04.278: INFO: namespace projected-9809 deletion completed in 6.646040831s
•SSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:59:04.278: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1551
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:59:06.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1551" for this suite.
Dec  3 14:59:52.697: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:59:53.344: INFO: namespace kubelet-test-1551 deletion completed in 46.705344749s
•S
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:59:53.344: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-638
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:00:09.647: INFO: Container started at 2019-12-03 14:59:54 +0000 UTC, pod became ready at 2019-12-03 15:00:09 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:00:09.648: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-638" for this suite.
Dec  3 15:00:21.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:00:22.333: INFO: namespace container-probe-638 deletion completed in 12.652179045s
•SSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:00:22.333: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-275
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-275
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-275
STEP: creating replication controller externalsvc in namespace services-275
I1203 15:00:22.642621    5095 runners.go:184] Created replication controller with name: externalsvc, namespace: services-275, replica count: 2
I1203 15:00:25.693192    5095 runners.go:184] externalsvc Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 15:00:28.693401    5095 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Dec  3 15:00:28.759: INFO: Creating new exec pod
Dec  3 15:00:30.812: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-275 execpodk9mbj -- /bin/sh -x -c nslookup clusterip-service'
Dec  3 15:00:31.813: INFO: stderr: "+ nslookup clusterip-service\n"
Dec  3 15:00:31.813: INFO: stdout: "Server:\t\t100.104.0.10\nAddress:\t100.104.0.10#53\n\nclusterip-service.services-275.svc.cluster.local\tcanonical name = externalsvc.services-275.svc.cluster.local.\nName:\texternalsvc.services-275.svc.cluster.local\nAddress: 100.108.52.31\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-275, will wait for the garbage collector to delete the pods
Dec  3 15:00:31.901: INFO: Deleting ReplicationController externalsvc took: 19.804973ms
Dec  3 15:00:32.001: INFO: Terminating ReplicationController externalsvc pods took: 100.380408ms
Dec  3 15:00:46.034: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:00:46.066: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-275" for this suite.
Dec  3 15:00:52.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:00:52.777: INFO: namespace services-275 deletion completed in 6.677426029s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:00:52.777: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-5721
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-676
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9359
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:01:06.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-5721" for this suite.
Dec  3 15:01:12.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:01:13.255: INFO: namespace namespaces-5721 deletion completed in 6.694883561s
STEP: Destroying namespace "nsdeletetest-676" for this suite.
Dec  3 15:01:13.273: INFO: Namespace nsdeletetest-676 was already deleted
STEP: Destroying namespace "nsdeletetest-9359" for this suite.
Dec  3 15:01:19.332: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:01:19.930: INFO: namespace nsdeletetest-9359 deletion completed in 6.65773759s
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:01:19.931: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4247
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Dec  3 15:01:20.153: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:01:23.533: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:01:36.764: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4247" for this suite.
Dec  3 15:01:42.853: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:01:43.492: INFO: namespace crd-publish-openapi-4247 deletion completed in 6.694102368s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:01:43.493: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2861
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:01:43.737: INFO: Waiting up to 5m0s for pod "downwardapi-volume-55f7f080-513c-4147-84a6-76aaaf5040c2" in namespace "downward-api-2861" to be "success or failure"
Dec  3 15:01:43.754: INFO: Pod "downwardapi-volume-55f7f080-513c-4147-84a6-76aaaf5040c2": Phase="Pending", Reason="", readiness=false. Elapsed: 17.506509ms
Dec  3 15:01:45.773: INFO: Pod "downwardapi-volume-55f7f080-513c-4147-84a6-76aaaf5040c2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036511983s
STEP: Saw pod success
Dec  3 15:01:45.773: INFO: Pod "downwardapi-volume-55f7f080-513c-4147-84a6-76aaaf5040c2" satisfied condition "success or failure"
Dec  3 15:01:45.790: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downwardapi-volume-55f7f080-513c-4147-84a6-76aaaf5040c2 container client-container: <nil>
STEP: delete the pod
Dec  3 15:01:45.982: INFO: Waiting for pod downwardapi-volume-55f7f080-513c-4147-84a6-76aaaf5040c2 to disappear
Dec  3 15:01:46.000: INFO: Pod downwardapi-volume-55f7f080-513c-4147-84a6-76aaaf5040c2 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:01:46.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2861" for this suite.
Dec  3 15:01:52.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:01:52.700: INFO: namespace downward-api-2861 deletion completed in 6.666834915s
•SSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:01:52.700: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8042
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-8042
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-8042
STEP: creating replication controller externalsvc in namespace services-8042
I1203 15:01:53.025405    5095 runners.go:184] Created replication controller with name: externalsvc, namespace: services-8042, replica count: 2
I1203 15:01:56.076089    5095 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Dec  3 15:01:56.463: INFO: Creating new exec pod
Dec  3 15:01:58.518: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-8042 execpodbh5rx -- /bin/sh -x -c nslookup nodeport-service'
Dec  3 15:01:59.164: INFO: stderr: "+ nslookup nodeport-service\n"
Dec  3 15:01:59.164: INFO: stdout: "Server:\t\t100.104.0.10\nAddress:\t100.104.0.10#53\n\nnodeport-service.services-8042.svc.cluster.local\tcanonical name = externalsvc.services-8042.svc.cluster.local.\nName:\texternalsvc.services-8042.svc.cluster.local\nAddress: 100.104.43.207\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-8042, will wait for the garbage collector to delete the pods
Dec  3 15:01:59.252: INFO: Deleting ReplicationController externalsvc took: 20.207826ms
Dec  3 15:01:59.353: INFO: Terminating ReplicationController externalsvc pods took: 100.407775ms
Dec  3 15:02:06.084: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:02:06.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8042" for this suite.
Dec  3 15:02:12.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:02:12.803: INFO: namespace services-8042 deletion completed in 6.661276173s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:02:12.803: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2815
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec  3 15:02:13.023: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:02:34.222: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2815" for this suite.
Dec  3 15:02:40.309: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:02:40.899: INFO: namespace crd-publish-openapi-2815 deletion completed in 6.643166107s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:02:40.900: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-3089
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-3089
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 15:02:41.123: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 15:03:05.453: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.43:8080/dial?request=hostName&protocol=http&host=100.64.0.20&port=8080&tries=1'] Namespace:pod-network-test-3089 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:03:05.453: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:03:05.935: INFO: Waiting for endpoints: map[]
Dec  3 15:03:05.953: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.43:8080/dial?request=hostName&protocol=http&host=100.64.1.42&port=8080&tries=1'] Namespace:pod-network-test-3089 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:03:05.953: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:03:06.424: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:03:06.424: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-3089" for this suite.
Dec  3 15:03:18.510: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:03:19.124: INFO: namespace pod-network-test-3089 deletion completed in 12.666099653s
•SSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:03:19.124: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6401
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Dec  3 15:03:19.353: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6401 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec  3 15:03:22.672: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec  3 15:03:22.672: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:03:24.707: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6401" for this suite.
Dec  3 15:03:32.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:03:33.389: INFO: namespace kubectl-6401 deletion completed in 8.649977723s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:03:33.390: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-7538
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Dec  3 15:03:33.622: INFO: Waiting up to 1m0s for all nodes to be ready
Dec  3 15:04:33.771: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:04:33.788: INFO: Starting informer...
STEP: Starting pods...
Dec  3 15:04:33.842: INFO: Pod1 is running on shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk. Tainting Node
Dec  3 15:04:37.930: INFO: Pod2 is running on shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Dec  3 15:04:45.074: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Dec  3 15:05:05.326: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:05:05.380: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-7538" for this suite.
Dec  3 15:05:11.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:05:12.060: INFO: namespace taint-multiple-pods-7538 deletion completed in 6.663372144s
•S
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:05:12.060: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5965
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec  3 15:05:12.310: INFO: Waiting up to 5m0s for pod "downward-api-d19bb324-4aeb-4a4f-9900-c833d428241b" in namespace "downward-api-5965" to be "success or failure"
Dec  3 15:05:12.328: INFO: Pod "downward-api-d19bb324-4aeb-4a4f-9900-c833d428241b": Phase="Pending", Reason="", readiness=false. Elapsed: 17.132079ms
Dec  3 15:05:14.346: INFO: Pod "downward-api-d19bb324-4aeb-4a4f-9900-c833d428241b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03561418s
Dec  3 15:05:16.363: INFO: Pod "downward-api-d19bb324-4aeb-4a4f-9900-c833d428241b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052969476s
STEP: Saw pod success
Dec  3 15:05:16.364: INFO: Pod "downward-api-d19bb324-4aeb-4a4f-9900-c833d428241b" satisfied condition "success or failure"
Dec  3 15:05:16.380: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downward-api-d19bb324-4aeb-4a4f-9900-c833d428241b container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:05:16.562: INFO: Waiting for pod downward-api-d19bb324-4aeb-4a4f-9900-c833d428241b to disappear
Dec  3 15:05:16.578: INFO: Pod downward-api-d19bb324-4aeb-4a4f-9900-c833d428241b no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:05:16.579: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5965" for this suite.
Dec  3 15:05:22.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:05:23.341: INFO: namespace downward-api-5965 deletion completed in 6.730514325s
•SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:05:23.342: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9041
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec  3 15:05:23.609: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:05:23.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9041" for this suite.
Dec  3 15:05:29.740: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:05:30.349: INFO: namespace replication-controller-9041 deletion completed in 6.664052697s
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:05:30.350: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3139
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-x5nv
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 15:05:30.627: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-x5nv" in namespace "subpath-3139" to be "success or failure"
Dec  3 15:05:30.644: INFO: Pod "pod-subpath-test-configmap-x5nv": Phase="Pending", Reason="", readiness=false. Elapsed: 17.486614ms
Dec  3 15:05:32.667: INFO: Pod "pod-subpath-test-configmap-x5nv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.040170367s
Dec  3 15:05:34.685: INFO: Pod "pod-subpath-test-configmap-x5nv": Phase="Running", Reason="", readiness=true. Elapsed: 4.058754077s
Dec  3 15:05:36.703: INFO: Pod "pod-subpath-test-configmap-x5nv": Phase="Running", Reason="", readiness=true. Elapsed: 6.076533843s
Dec  3 15:05:38.721: INFO: Pod "pod-subpath-test-configmap-x5nv": Phase="Running", Reason="", readiness=true. Elapsed: 8.094552389s
Dec  3 15:05:40.740: INFO: Pod "pod-subpath-test-configmap-x5nv": Phase="Running", Reason="", readiness=true. Elapsed: 10.112959824s
Dec  3 15:05:42.758: INFO: Pod "pod-subpath-test-configmap-x5nv": Phase="Running", Reason="", readiness=true. Elapsed: 12.130964513s
Dec  3 15:05:44.775: INFO: Pod "pod-subpath-test-configmap-x5nv": Phase="Running", Reason="", readiness=true. Elapsed: 14.148739815s
Dec  3 15:05:46.794: INFO: Pod "pod-subpath-test-configmap-x5nv": Phase="Running", Reason="", readiness=true. Elapsed: 16.166840765s
Dec  3 15:05:48.812: INFO: Pod "pod-subpath-test-configmap-x5nv": Phase="Running", Reason="", readiness=true. Elapsed: 18.184862297s
Dec  3 15:05:50.830: INFO: Pod "pod-subpath-test-configmap-x5nv": Phase="Running", Reason="", readiness=true. Elapsed: 20.202835875s
Dec  3 15:05:52.848: INFO: Pod "pod-subpath-test-configmap-x5nv": Phase="Running", Reason="", readiness=true. Elapsed: 22.221057316s
Dec  3 15:05:54.865: INFO: Pod "pod-subpath-test-configmap-x5nv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.238750106s
STEP: Saw pod success
Dec  3 15:05:54.866: INFO: Pod "pod-subpath-test-configmap-x5nv" satisfied condition "success or failure"
Dec  3 15:05:54.883: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-subpath-test-configmap-x5nv container test-container-subpath-configmap-x5nv: <nil>
STEP: delete the pod
Dec  3 15:05:54.932: INFO: Waiting for pod pod-subpath-test-configmap-x5nv to disappear
Dec  3 15:05:54.949: INFO: Pod pod-subpath-test-configmap-x5nv no longer exists
STEP: Deleting pod pod-subpath-test-configmap-x5nv
Dec  3 15:05:54.949: INFO: Deleting pod "pod-subpath-test-configmap-x5nv" in namespace "subpath-3139"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:05:54.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3139" for this suite.
Dec  3 15:06:01.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:06:01.664: INFO: namespace subpath-3139 deletion completed in 6.661368615s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:06:01.665: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-8114
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-8114
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-8114
I1203 15:06:01.970769    5095 runners.go:184] Created replication controller with name: externalname-service, namespace: services-8114, replica count: 2
I1203 15:06:05.021409    5095 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 15:06:05.021: INFO: Creating new exec pod
Dec  3 15:06:08.077: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-8114 execpodsf8hz -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec  3 15:06:08.745: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec  3 15:06:08.745: INFO: stdout: ""
Dec  3 15:06:08.745: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-8114 execpodsf8hz -- /bin/sh -x -c nc -zv -t -w 2 100.108.186.210 80'
Dec  3 15:06:09.398: INFO: stderr: "+ nc -zv -t -w 2 100.108.186.210 80\nConnection to 100.108.186.210 80 port [tcp/http] succeeded!\n"
Dec  3 15:06:09.399: INFO: stdout: ""
Dec  3 15:06:09.399: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:06:09.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-8114" for this suite.
Dec  3 15:06:15.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:06:16.132: INFO: namespace services-8114 deletion completed in 6.670017364s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:06:16.132: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-6287
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Dec  3 15:06:16.965: INFO: created pod pod-service-account-defaultsa
Dec  3 15:06:16.965: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec  3 15:06:16.983: INFO: created pod pod-service-account-mountsa
Dec  3 15:06:16.983: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec  3 15:06:17.001: INFO: created pod pod-service-account-nomountsa
Dec  3 15:06:17.001: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec  3 15:06:17.019: INFO: created pod pod-service-account-defaultsa-mountspec
Dec  3 15:06:17.019: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec  3 15:06:17.037: INFO: created pod pod-service-account-mountsa-mountspec
Dec  3 15:06:17.037: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec  3 15:06:17.055: INFO: created pod pod-service-account-nomountsa-mountspec
Dec  3 15:06:17.055: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec  3 15:06:17.073: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec  3 15:06:17.073: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec  3 15:06:17.091: INFO: created pod pod-service-account-mountsa-nomountspec
Dec  3 15:06:17.091: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec  3 15:06:17.109: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec  3 15:06:17.109: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:06:17.109: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-6287" for this suite.
Dec  3 15:07:01.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:01.808: INFO: namespace svcaccounts-6287 deletion completed in 44.665783421s
•
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:07:01.808: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-314
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-314
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 15:07:02.035: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 15:07:24.341: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.62:8080/dial?request=hostName&protocol=udp&host=100.64.0.22&port=8081&tries=1'] Namespace:pod-network-test-314 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:07:24.341: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:07:24.787: INFO: Waiting for endpoints: map[]
Dec  3 15:07:24.805: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.62:8080/dial?request=hostName&protocol=udp&host=100.64.1.61&port=8081&tries=1'] Namespace:pod-network-test-314 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:07:24.805: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:07:25.314: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:07:25.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-314" for this suite.
Dec  3 15:07:37.400: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:37.997: INFO: namespace pod-network-test-314 deletion completed in 12.650204617s
•SSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:07:37.997: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1589
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Dec  3 15:07:38.239: INFO: Waiting up to 5m0s for pod "var-expansion-d8a9de27-6c65-46d1-8356-f95ee1e5783e" in namespace "var-expansion-1589" to be "success or failure"
Dec  3 15:07:38.257: INFO: Pod "var-expansion-d8a9de27-6c65-46d1-8356-f95ee1e5783e": Phase="Pending", Reason="", readiness=false. Elapsed: 17.618707ms
Dec  3 15:07:40.276: INFO: Pod "var-expansion-d8a9de27-6c65-46d1-8356-f95ee1e5783e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03655145s
STEP: Saw pod success
Dec  3 15:07:40.276: INFO: Pod "var-expansion-d8a9de27-6c65-46d1-8356-f95ee1e5783e" satisfied condition "success or failure"
Dec  3 15:07:40.293: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod var-expansion-d8a9de27-6c65-46d1-8356-f95ee1e5783e container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:07:40.485: INFO: Waiting for pod var-expansion-d8a9de27-6c65-46d1-8356-f95ee1e5783e to disappear
Dec  3 15:07:40.502: INFO: Pod var-expansion-d8a9de27-6c65-46d1-8356-f95ee1e5783e no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:07:40.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1589" for this suite.
Dec  3 15:07:46.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:47.188: INFO: namespace var-expansion-1589 deletion completed in 6.653556935s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:07:47.189: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3759
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:07:47.415: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-3759'
Dec  3 15:07:47.752: INFO: stderr: ""
Dec  3 15:07:47.752: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec  3 15:07:47.752: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-3759'
Dec  3 15:07:48.083: INFO: stderr: ""
Dec  3 15:07:48.083: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  3 15:07:49.102: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:07:49.102: INFO: Found 0 / 1
Dec  3 15:07:50.101: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:07:50.102: INFO: Found 1 / 1
Dec  3 15:07:50.102: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  3 15:07:50.119: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:07:50.119: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 15:07:50.119: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe pod redis-master-rkvlm --namespace=kubectl-3759'
Dec  3 15:07:50.306: INFO: stderr: ""
Dec  3 15:07:50.306: INFO: stdout: "Name:         redis-master-rkvlm\nNamespace:    kubectl-3759\nPriority:     0\nNode:         shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk/10.250.0.4\nStart Time:   Tue, 03 Dec 2019 15:07:47 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  cni.projectcalico.org/podIP: 100.64.1.64/32\n              kubernetes.io/psp: e2e-test-privileged-psp\nStatus:       Running\nIP:           100.64.1.64\nIPs:\n  IP:           100.64.1.64\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://1ece7a2ad1db1d3de3542310701f16c99261e9348f9f9b95e24b34a1455195a2\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 03 Dec 2019 15:07:49 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-fgcj4 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-fgcj4:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-fgcj4\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                                                     Message\n  ----    ------     ----       ----                                                     -------\n  Normal  Scheduled  <unknown>  default-scheduler                                        Successfully assigned kubectl-3759/redis-master-rkvlm to shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk\n  Normal  Pulled     2s         kubelet, shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    2s         kubelet, shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Created container redis-master\n  Normal  Started    1s         kubelet, shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Started container redis-master\n"
Dec  3 15:07:50.306: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe rc redis-master --namespace=kubectl-3759'
Dec  3 15:07:50.524: INFO: stderr: ""
Dec  3 15:07:50.525: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-3759\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  3s    replication-controller  Created pod: redis-master-rkvlm\n"
Dec  3 15:07:50.525: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe service redis-master --namespace=kubectl-3759'
Dec  3 15:07:50.724: INFO: stderr: ""
Dec  3 15:07:50.724: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-3759\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                100.104.97.31\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         100.64.1.64:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec  3 15:07:50.757: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk'
Dec  3 15:07:51.018: INFO: stderr: ""
Dec  3 15:07:51.018: INFO: stdout: "Name:               shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=Standard_D2_v3\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=westeurope\n                    failure-domain.beta.kubernetes.io/zone=1\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/role=node\n                    worker.garden.sapcloud.io/group=worker-1\n                    worker.gardener.cloud/pool=worker-1\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4IPIPTunnelAddr: 100.64.1.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 03 Dec 2019 14:41:40 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                          Status  LastHeartbeatTime                 LastTransitionTime                Reason                          Message\n  ----                          ------  -----------------                 ------------------                ------                          -------\n  FrequentUnregisterNetDevice   False   Tue, 03 Dec 2019 15:07:27 +0000   Tue, 03 Dec 2019 14:42:13 +0000   NoFrequentUnregisterNetDevice   node is functioning properly\n  FrequentKubeletRestart        False   Tue, 03 Dec 2019 15:07:27 +0000   Tue, 03 Dec 2019 14:42:13 +0000   NoFrequentKubeletRestart        kubelet is functioning properly\n  FrequentDockerRestart         False   Tue, 03 Dec 2019 15:07:27 +0000   Tue, 03 Dec 2019 14:42:13 +0000   NoFrequentDockerRestart         docker is functioning properly\n  FrequentContainerdRestart     False   Tue, 03 Dec 2019 15:07:27 +0000   Tue, 03 Dec 2019 14:42:13 +0000   NoFrequentContainerdRestart     containerd is functioning properly\n  KernelDeadlock                False   Tue, 03 Dec 2019 15:07:27 +0000   Tue, 03 Dec 2019 14:42:13 +0000   KernelHasNoDeadlock             kernel has no deadlock\n  ReadonlyFilesystem            False   Tue, 03 Dec 2019 15:07:27 +0000   Tue, 03 Dec 2019 14:42:13 +0000   FilesystemIsNotReadOnly         Filesystem is not read-only\n  CorruptDockerOverlay2         False   Tue, 03 Dec 2019 15:07:27 +0000   Tue, 03 Dec 2019 14:42:13 +0000   NoCorruptDockerOverlay2         docker overlay2 is functioning properly\n  NetworkUnavailable            False   Tue, 03 Dec 2019 14:41:56 +0000   Tue, 03 Dec 2019 14:41:56 +0000   RouteCreated                    RouteController created a route\n  MemoryPressure                False   Tue, 03 Dec 2019 15:07:43 +0000   Tue, 03 Dec 2019 14:41:40 +0000   KubeletHasSufficientMemory      kubelet has sufficient memory available\n  DiskPressure                  False   Tue, 03 Dec 2019 15:07:43 +0000   Tue, 03 Dec 2019 14:41:40 +0000   KubeletHasNoDiskPressure        kubelet has no disk pressure\n  PIDPressure                   False   Tue, 03 Dec 2019 15:07:43 +0000   Tue, 03 Dec 2019 14:41:40 +0000   KubeletHasSufficientPID         kubelet has sufficient PID available\n  Ready                         True    Tue, 03 Dec 2019 15:07:43 +0000   Tue, 03 Dec 2019 14:42:00 +0000   KubeletReady                    kubelet is posting ready status\nAddresses:\n  Hostname:    shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk\n  InternalIP:  10.250.0.4\nCapacity:\n attachable-volumes-azure-disk:  4\n cpu:                            2\n ephemeral-storage:              33136428Ki\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         8145236Ki\n pods:                           110\nAllocatable:\n attachable-volumes-azure-disk:  4\n cpu:                            1920m\n ephemeral-storage:              32235117134\n hugepages-1Gi:                  0\n hugepages-2Mi:                  0\n memory:                         6849943751\n pods:                           110\nSystem Info:\n Machine ID:                 8e4db2f94c2945629e4de0a5bc495be7\n System UUID:                c3d9cdca-6d2c-5c4d-add9-1c55784f234a\n Boot ID:                    3be4ae57-9687-428e-9781-8d2aaebf18c6\n Kernel Version:             4.19.56-coreos-r1\n OS Image:                   Container Linux by CoreOS 2135.6.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.16.3\n Kube-Proxy Version:         v1.16.3\nPodCIDR:                     100.64.1.0/24\nPodCIDRs:                    100.64.1.0/24\nProviderID:                  azure:///subscriptions/0b9904be-2a50-4fda-a947-c5f1b1d07666/resourceGroups/shoot--it--tmp1w-0ph/providers/Microsoft.Compute/virtualMachines/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk\nNon-terminated Pods:         (5 in total)\n  Namespace                  Name                           CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                           ------------  ----------  ---------------  -------------  ---\n  kube-system                calico-node-v7kgq              100m (5%)     500m (26%)  100Mi (1%)       700Mi (10%)    26m\n  kube-system                kube-proxy-9gxg8               20m (1%)      0 (0%)      64Mi (0%)        0 (0%)         26m\n  kube-system                node-exporter-99hck            5m (0%)       25m (1%)    10Mi (0%)        100Mi (1%)     26m\n  kube-system                node-problem-detector-sjm82    20m (1%)      200m (10%)  20Mi (0%)        100Mi (1%)     26m\n  kubectl-3759               redis-master-rkvlm             0 (0%)        0 (0%)      0 (0%)           0 (0%)         4s\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                       Requests    Limits\n  --------                       --------    ------\n  cpu                            145m (7%)   725m (37%)\n  memory                         194Mi (2%)  900Mi (13%)\n  ephemeral-storage              0 (0%)      0 (0%)\n  attachable-volumes-azure-disk  0           0\nEvents:\n  Type     Reason                   Age                From                                                             Message\n  ----     ------                   ----               ----                                                             -------\n  Normal   Starting                 26m                kubelet, shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk          Starting kubelet.\n  Normal   NodeHasSufficientMemory  26m                kubelet, shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk          Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    26m                kubelet, shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk          Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     26m                kubelet, shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk          Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  26m                kubelet, shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk          Updated Node Allocatable limit across pods\n  Normal   Starting                 26m                kube-proxy, shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk       Starting kube-proxy.\n  Normal   NodeReady                25m                kubelet, shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk          Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk status is now: NodeReady\n  Warning  DockerStart              25m (x3 over 25m)  systemd-monitor, shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Starting Docker Application Container Engine...\n"
Dec  3 15:07:51.018: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe namespace kubectl-3759'
Dec  3 15:07:51.216: INFO: stderr: ""
Dec  3 15:07:51.216: INFO: stdout: "Name:         kubectl-3759\nLabels:       e2e-framework=kubectl\n              e2e-run=bc4eecb9-790a-4046-90f5-c1793f709680\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:07:51.216: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3759" for this suite.
Dec  3 15:08:03.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:08:03.900: INFO: namespace kubectl-3759 deletion completed in 12.65049778s
•SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:08:03.901: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1447
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:08:06.234: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1447" for this suite.
Dec  3 15:08:50.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:08:50.929: INFO: namespace kubelet-test-1447 deletion completed in 44.662807239s
•SSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:08:50.930: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1293
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-7df085ea-b58d-4f48-ae9c-6e9c7df32e92
STEP: Creating a pod to test consume configMaps
Dec  3 15:08:51.204: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-89df3738-4e16-4037-883a-e73dad7127ec" in namespace "projected-1293" to be "success or failure"
Dec  3 15:08:51.221: INFO: Pod "pod-projected-configmaps-89df3738-4e16-4037-883a-e73dad7127ec": Phase="Pending", Reason="", readiness=false. Elapsed: 16.843245ms
Dec  3 15:08:53.239: INFO: Pod "pod-projected-configmaps-89df3738-4e16-4037-883a-e73dad7127ec": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0347632s
Dec  3 15:08:55.257: INFO: Pod "pod-projected-configmaps-89df3738-4e16-4037-883a-e73dad7127ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05278899s
STEP: Saw pod success
Dec  3 15:08:55.257: INFO: Pod "pod-projected-configmaps-89df3738-4e16-4037-883a-e73dad7127ec" satisfied condition "success or failure"
Dec  3 15:08:55.275: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-projected-configmaps-89df3738-4e16-4037-883a-e73dad7127ec container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:08:55.323: INFO: Waiting for pod pod-projected-configmaps-89df3738-4e16-4037-883a-e73dad7127ec to disappear
Dec  3 15:08:55.339: INFO: Pod pod-projected-configmaps-89df3738-4e16-4037-883a-e73dad7127ec no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:08:55.339: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1293" for this suite.
Dec  3 15:09:01.424: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:09:02.039: INFO: namespace projected-1293 deletion completed in 6.667315223s
•S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:09:02.040: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9670
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  3 15:09:02.294: INFO: Waiting up to 5m0s for pod "pod-8ca85d14-4e17-4b61-aaf6-8c1c51e68429" in namespace "emptydir-9670" to be "success or failure"
Dec  3 15:09:02.311: INFO: Pod "pod-8ca85d14-4e17-4b61-aaf6-8c1c51e68429": Phase="Pending", Reason="", readiness=false. Elapsed: 17.092265ms
Dec  3 15:09:04.329: INFO: Pod "pod-8ca85d14-4e17-4b61-aaf6-8c1c51e68429": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035285592s
Dec  3 15:09:06.347: INFO: Pod "pod-8ca85d14-4e17-4b61-aaf6-8c1c51e68429": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052826731s
STEP: Saw pod success
Dec  3 15:09:06.347: INFO: Pod "pod-8ca85d14-4e17-4b61-aaf6-8c1c51e68429" satisfied condition "success or failure"
Dec  3 15:09:06.364: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-8ca85d14-4e17-4b61-aaf6-8c1c51e68429 container test-container: <nil>
STEP: delete the pod
Dec  3 15:09:06.425: INFO: Waiting for pod pod-8ca85d14-4e17-4b61-aaf6-8c1c51e68429 to disappear
Dec  3 15:09:06.441: INFO: Pod pod-8ca85d14-4e17-4b61-aaf6-8c1c51e68429 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:09:06.441: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9670" for this suite.
Dec  3 15:09:12.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:09:13.169: INFO: namespace emptydir-9670 deletion completed in 6.695643001s
•SSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:09:13.170: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2200
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Dec  3 15:09:23.518: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1203 15:09:23.518459    5095 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:09:23.518: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2200" for this suite.
Dec  3 15:09:29.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:09:30.179: INFO: namespace gc-2200 deletion completed in 6.643576257s
•SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:09:30.180: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7299
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  3 15:09:30.410: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-7299'
Dec  3 15:09:30.564: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 15:09:30.564: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: rolling-update to same image controller
Dec  3 15:09:30.600: INFO: scanned /root for discovery docs: <nil>
Dec  3 15:09:30.600: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-7299'
Dec  3 15:09:41.821: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  3 15:09:41.821: INFO: stdout: "Created e2e-test-httpd-rc-d8694a7a5caff60a4140916a9bbf28f7\nScaling up e2e-test-httpd-rc-d8694a7a5caff60a4140916a9bbf28f7 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-d8694a7a5caff60a4140916a9bbf28f7 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-d8694a7a5caff60a4140916a9bbf28f7 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Dec  3 15:09:41.821: INFO: stdout: "Created e2e-test-httpd-rc-d8694a7a5caff60a4140916a9bbf28f7\nScaling up e2e-test-httpd-rc-d8694a7a5caff60a4140916a9bbf28f7 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-d8694a7a5caff60a4140916a9bbf28f7 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-d8694a7a5caff60a4140916a9bbf28f7 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Dec  3 15:09:41.821: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-7299'
Dec  3 15:09:41.970: INFO: stderr: ""
Dec  3 15:09:41.970: INFO: stdout: "e2e-test-httpd-rc-d8694a7a5caff60a4140916a9bbf28f7-fxrql "
Dec  3 15:09:41.970: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods e2e-test-httpd-rc-d8694a7a5caff60a4140916a9bbf28f7-fxrql -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-7299'
Dec  3 15:09:42.111: INFO: stderr: ""
Dec  3 15:09:42.111: INFO: stdout: "true"
Dec  3 15:09:42.111: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods e2e-test-httpd-rc-d8694a7a5caff60a4140916a9bbf28f7-fxrql -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-7299'
Dec  3 15:09:42.255: INFO: stderr: ""
Dec  3 15:09:42.255: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Dec  3 15:09:42.255: INFO: e2e-test-httpd-rc-d8694a7a5caff60a4140916a9bbf28f7-fxrql is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Dec  3 15:09:42.256: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete rc e2e-test-httpd-rc --namespace=kubectl-7299'
Dec  3 15:09:42.417: INFO: stderr: ""
Dec  3 15:09:42.417: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:09:42.417: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7299" for this suite.
Dec  3 15:09:54.504: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:09:55.114: INFO: namespace kubectl-7299 deletion completed in 12.664459269s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:09:55.115: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3045
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:10:06.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3045" for this suite.
Dec  3 15:10:12.557: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:10:13.158: INFO: namespace resourcequota-3045 deletion completed in 6.654292063s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:10:13.158: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5048
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:10:13.408: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6f748969-7a40-4bf9-bdcc-f49ab4d3b8e3" in namespace "projected-5048" to be "success or failure"
Dec  3 15:10:13.433: INFO: Pod "downwardapi-volume-6f748969-7a40-4bf9-bdcc-f49ab4d3b8e3": Phase="Pending", Reason="", readiness=false. Elapsed: 24.494777ms
Dec  3 15:10:15.451: INFO: Pod "downwardapi-volume-6f748969-7a40-4bf9-bdcc-f49ab4d3b8e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042874691s
Dec  3 15:10:17.469: INFO: Pod "downwardapi-volume-6f748969-7a40-4bf9-bdcc-f49ab4d3b8e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061055962s
STEP: Saw pod success
Dec  3 15:10:17.470: INFO: Pod "downwardapi-volume-6f748969-7a40-4bf9-bdcc-f49ab4d3b8e3" satisfied condition "success or failure"
Dec  3 15:10:17.487: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downwardapi-volume-6f748969-7a40-4bf9-bdcc-f49ab4d3b8e3 container client-container: <nil>
STEP: delete the pod
Dec  3 15:10:17.541: INFO: Waiting for pod downwardapi-volume-6f748969-7a40-4bf9-bdcc-f49ab4d3b8e3 to disappear
Dec  3 15:10:17.558: INFO: Pod downwardapi-volume-6f748969-7a40-4bf9-bdcc-f49ab4d3b8e3 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:10:17.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5048" for this suite.
Dec  3 15:10:23.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:10:24.257: INFO: namespace projected-5048 deletion completed in 6.656119471s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:10:24.258: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-8810
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Dec  3 15:10:24.485: INFO: Waiting up to 1m0s for all nodes to be ready
Dec  3 15:11:24.638: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:11:24.656: INFO: Starting informer...
STEP: Starting pod...
Dec  3 15:11:24.693: INFO: Pod is running on shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Dec  3 15:11:24.746: INFO: Pod wasn't evicted. Proceeding
Dec  3 15:11:24.746: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Dec  3 15:12:39.800: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:12:39.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-8810" for this suite.
Dec  3 15:12:51.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:12:52.495: INFO: namespace taint-single-pod-8810 deletion completed in 12.661611885s
•SSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:12:52.495: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-911
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Dec  3 15:12:52.744: INFO: Waiting up to 5m0s for pod "var-expansion-a1e4c0d0-a85b-49e1-a9e4-7ea115bdaf74" in namespace "var-expansion-911" to be "success or failure"
Dec  3 15:12:52.761: INFO: Pod "var-expansion-a1e4c0d0-a85b-49e1-a9e4-7ea115bdaf74": Phase="Pending", Reason="", readiness=false. Elapsed: 16.874335ms
Dec  3 15:12:54.779: INFO: Pod "var-expansion-a1e4c0d0-a85b-49e1-a9e4-7ea115bdaf74": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.03481463s
STEP: Saw pod success
Dec  3 15:12:54.779: INFO: Pod "var-expansion-a1e4c0d0-a85b-49e1-a9e4-7ea115bdaf74" satisfied condition "success or failure"
Dec  3 15:12:54.796: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod var-expansion-a1e4c0d0-a85b-49e1-a9e4-7ea115bdaf74 container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:12:54.972: INFO: Waiting for pod var-expansion-a1e4c0d0-a85b-49e1-a9e4-7ea115bdaf74 to disappear
Dec  3 15:12:54.989: INFO: Pod var-expansion-a1e4c0d0-a85b-49e1-a9e4-7ea115bdaf74 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:12:54.989: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-911" for this suite.
Dec  3 15:13:01.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:13:01.695: INFO: namespace var-expansion-911 deletion completed in 6.674133663s
•S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:13:01.696: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5937
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Dec  3 15:13:01.919: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:13:05.287: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:13:19.565: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5937" for this suite.
Dec  3 15:13:25.658: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:13:26.266: INFO: namespace crd-publish-openapi-5937 deletion completed in 6.667276334s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:13:26.266: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4546
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Dec  3 15:13:26.492: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config api-versions'
Dec  3 15:13:26.674: INFO: stderr: ""
Dec  3 15:13:26.674: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncert.gardener.cloud/v1alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:13:26.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4546" for this suite.
Dec  3 15:13:32.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:13:33.342: INFO: namespace kubectl-4546 deletion completed in 6.648058325s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:13:33.343: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2381
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:13:34.034: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982813, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982813, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982814, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982813, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:13:37.080: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:13:37.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2381" for this suite.
Dec  3 15:13:43.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:13:44.204: INFO: namespace webhook-2381 deletion completed in 6.658788653s
STEP: Destroying namespace "webhook-2381-markers" for this suite.
Dec  3 15:13:50.264: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:13:50.860: INFO: namespace webhook-2381-markers deletion completed in 6.65550017s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:13:50.930: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7478
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:14:02.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7478" for this suite.
Dec  3 15:14:08.402: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:14:08.996: INFO: namespace resourcequota-7478 deletion completed in 6.648416188s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:14:08.997: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-937
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:14:09.249: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1197f572-65d6-4ffd-93f4-cd2e982c8baf" in namespace "projected-937" to be "success or failure"
Dec  3 15:14:09.266: INFO: Pod "downwardapi-volume-1197f572-65d6-4ffd-93f4-cd2e982c8baf": Phase="Pending", Reason="", readiness=false. Elapsed: 16.861434ms
Dec  3 15:14:11.286: INFO: Pod "downwardapi-volume-1197f572-65d6-4ffd-93f4-cd2e982c8baf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036747432s
STEP: Saw pod success
Dec  3 15:14:11.286: INFO: Pod "downwardapi-volume-1197f572-65d6-4ffd-93f4-cd2e982c8baf" satisfied condition "success or failure"
Dec  3 15:14:11.303: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downwardapi-volume-1197f572-65d6-4ffd-93f4-cd2e982c8baf container client-container: <nil>
STEP: delete the pod
Dec  3 15:14:11.358: INFO: Waiting for pod downwardapi-volume-1197f572-65d6-4ffd-93f4-cd2e982c8baf to disappear
Dec  3 15:14:11.375: INFO: Pod downwardapi-volume-1197f572-65d6-4ffd-93f4-cd2e982c8baf no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:14:11.375: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-937" for this suite.
Dec  3 15:14:17.482: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:14:18.374: INFO: namespace projected-937 deletion completed in 6.965529936s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:14:18.375: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4050
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-4050
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4050 to expose endpoints map[]
Dec  3 15:14:18.654: INFO: successfully validated that service multi-endpoint-test in namespace services-4050 exposes endpoints map[] (17.067803ms elapsed)
STEP: Creating pod pod1 in namespace services-4050
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4050 to expose endpoints map[pod1:[100]]
Dec  3 15:14:21.813: INFO: successfully validated that service multi-endpoint-test in namespace services-4050 exposes endpoints map[pod1:[100]] (3.139315283s elapsed)
STEP: Creating pod pod2 in namespace services-4050
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4050 to expose endpoints map[pod1:[100] pod2:[101]]
Dec  3 15:14:23.987: INFO: successfully validated that service multi-endpoint-test in namespace services-4050 exposes endpoints map[pod1:[100] pod2:[101]] (2.154786912s elapsed)
STEP: Deleting pod pod1 in namespace services-4050
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4050 to expose endpoints map[pod2:[101]]
Dec  3 15:14:24.040: INFO: successfully validated that service multi-endpoint-test in namespace services-4050 exposes endpoints map[pod2:[101]] (33.971734ms elapsed)
STEP: Deleting pod pod2 in namespace services-4050
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-4050 to expose endpoints map[]
Dec  3 15:14:24.075: INFO: successfully validated that service multi-endpoint-test in namespace services-4050 exposes endpoints map[] (16.969908ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:14:24.105: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4050" for this suite.
Dec  3 15:14:52.190: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:14:52.801: INFO: namespace services-4050 deletion completed in 28.662985223s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:14:52.802: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5451
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-4c508ea7-166b-428e-851c-34f6f4460502
STEP: Creating a pod to test consume configMaps
Dec  3 15:14:53.064: INFO: Waiting up to 5m0s for pod "pod-configmaps-833d73da-0745-4d92-924d-b270acd93994" in namespace "configmap-5451" to be "success or failure"
Dec  3 15:14:53.081: INFO: Pod "pod-configmaps-833d73da-0745-4d92-924d-b270acd93994": Phase="Pending", Reason="", readiness=false. Elapsed: 17.043736ms
Dec  3 15:14:55.099: INFO: Pod "pod-configmaps-833d73da-0745-4d92-924d-b270acd93994": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035059599s
Dec  3 15:14:57.116: INFO: Pod "pod-configmaps-833d73da-0745-4d92-924d-b270acd93994": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052561697s
STEP: Saw pod success
Dec  3 15:14:57.117: INFO: Pod "pod-configmaps-833d73da-0745-4d92-924d-b270acd93994" satisfied condition "success or failure"
Dec  3 15:14:57.134: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-configmaps-833d73da-0745-4d92-924d-b270acd93994 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:14:57.191: INFO: Waiting for pod pod-configmaps-833d73da-0745-4d92-924d-b270acd93994 to disappear
Dec  3 15:14:57.208: INFO: Pod pod-configmaps-833d73da-0745-4d92-924d-b270acd93994 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:14:57.208: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5451" for this suite.
Dec  3 15:15:03.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:15:03.903: INFO: namespace configmap-5451 deletion completed in 6.662510236s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:15:03.904: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3458
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:15:04.147: INFO: Waiting up to 5m0s for pod "downwardapi-volume-4db5a171-e0fd-40f4-bae1-bb49a6770347" in namespace "downward-api-3458" to be "success or failure"
Dec  3 15:15:04.164: INFO: Pod "downwardapi-volume-4db5a171-e0fd-40f4-bae1-bb49a6770347": Phase="Pending", Reason="", readiness=false. Elapsed: 16.866333ms
Dec  3 15:15:06.182: INFO: Pod "downwardapi-volume-4db5a171-e0fd-40f4-bae1-bb49a6770347": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034718111s
Dec  3 15:15:08.200: INFO: Pod "downwardapi-volume-4db5a171-e0fd-40f4-bae1-bb49a6770347": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052724892s
STEP: Saw pod success
Dec  3 15:15:08.200: INFO: Pod "downwardapi-volume-4db5a171-e0fd-40f4-bae1-bb49a6770347" satisfied condition "success or failure"
Dec  3 15:15:08.217: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downwardapi-volume-4db5a171-e0fd-40f4-bae1-bb49a6770347 container client-container: <nil>
STEP: delete the pod
Dec  3 15:15:08.274: INFO: Waiting for pod downwardapi-volume-4db5a171-e0fd-40f4-bae1-bb49a6770347 to disappear
Dec  3 15:15:08.291: INFO: Pod downwardapi-volume-4db5a171-e0fd-40f4-bae1-bb49a6770347 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:15:08.291: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3458" for this suite.
Dec  3 15:15:14.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:15:14.987: INFO: namespace downward-api-3458 deletion completed in 6.662434857s
•S
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:15:14.987: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-3739
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Dec  3 15:15:19.823: INFO: Successfully updated pod "adopt-release-frn6m"
STEP: Checking that the Job readopts the Pod
Dec  3 15:15:19.823: INFO: Waiting up to 15m0s for pod "adopt-release-frn6m" in namespace "job-3739" to be "adopted"
Dec  3 15:15:19.840: INFO: Pod "adopt-release-frn6m": Phase="Running", Reason="", readiness=true. Elapsed: 16.911427ms
Dec  3 15:15:19.840: INFO: Pod "adopt-release-frn6m" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Dec  3 15:15:20.377: INFO: Successfully updated pod "adopt-release-frn6m"
STEP: Checking that the Job releases the Pod
Dec  3 15:15:20.377: INFO: Waiting up to 15m0s for pod "adopt-release-frn6m" in namespace "job-3739" to be "released"
Dec  3 15:15:20.402: INFO: Pod "adopt-release-frn6m": Phase="Running", Reason="", readiness=true. Elapsed: 24.633618ms
Dec  3 15:15:20.402: INFO: Pod "adopt-release-frn6m" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:15:20.402: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-3739" for this suite.
Dec  3 15:16:16.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:16:17.085: INFO: namespace job-3739 deletion completed in 56.643635931s
•S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:16:17.086: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7510
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:16:17.328: INFO: Waiting up to 5m0s for pod "downwardapi-volume-550ee9de-04ca-4d46-bc93-acc5d326a6ec" in namespace "projected-7510" to be "success or failure"
Dec  3 15:16:17.345: INFO: Pod "downwardapi-volume-550ee9de-04ca-4d46-bc93-acc5d326a6ec": Phase="Pending", Reason="", readiness=false. Elapsed: 17.173784ms
Dec  3 15:16:19.363: INFO: Pod "downwardapi-volume-550ee9de-04ca-4d46-bc93-acc5d326a6ec": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034887003s
STEP: Saw pod success
Dec  3 15:16:19.363: INFO: Pod "downwardapi-volume-550ee9de-04ca-4d46-bc93-acc5d326a6ec" satisfied condition "success or failure"
Dec  3 15:16:19.381: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downwardapi-volume-550ee9de-04ca-4d46-bc93-acc5d326a6ec container client-container: <nil>
STEP: delete the pod
Dec  3 15:16:19.434: INFO: Waiting for pod downwardapi-volume-550ee9de-04ca-4d46-bc93-acc5d326a6ec to disappear
Dec  3 15:16:19.451: INFO: Pod downwardapi-volume-550ee9de-04ca-4d46-bc93-acc5d326a6ec no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:16:19.451: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7510" for this suite.
Dec  3 15:16:25.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:16:26.158: INFO: namespace projected-7510 deletion completed in 6.674282608s
•S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:16:26.158: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8679
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec  3 15:16:26.445: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:16:59.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8679" for this suite.
Dec  3 15:17:05.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:17:06.566: INFO: namespace crd-publish-openapi-8679 deletion completed in 6.663096864s
•
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:17:06.566: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-4287
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  3 15:17:14.986: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 15:17:15.003: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 15:17:17.003: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 15:17:17.021: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 15:17:19.003: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 15:17:19.021: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:17:19.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4287" for this suite.
Dec  3 15:17:31.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:17:31.710: INFO: namespace container-lifecycle-hook-4287 deletion completed in 12.655002066s
•SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:17:31.710: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7644
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:17:31.960: INFO: Waiting up to 5m0s for pod "downwardapi-volume-bdd1c294-165f-463e-9794-9205dfba9aba" in namespace "projected-7644" to be "success or failure"
Dec  3 15:17:31.977: INFO: Pod "downwardapi-volume-bdd1c294-165f-463e-9794-9205dfba9aba": Phase="Pending", Reason="", readiness=false. Elapsed: 16.970129ms
Dec  3 15:17:33.996: INFO: Pod "downwardapi-volume-bdd1c294-165f-463e-9794-9205dfba9aba": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035227825s
Dec  3 15:17:36.014: INFO: Pod "downwardapi-volume-bdd1c294-165f-463e-9794-9205dfba9aba": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053973591s
STEP: Saw pod success
Dec  3 15:17:36.015: INFO: Pod "downwardapi-volume-bdd1c294-165f-463e-9794-9205dfba9aba" satisfied condition "success or failure"
Dec  3 15:17:36.032: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downwardapi-volume-bdd1c294-165f-463e-9794-9205dfba9aba container client-container: <nil>
STEP: delete the pod
Dec  3 15:17:36.080: INFO: Waiting for pod downwardapi-volume-bdd1c294-165f-463e-9794-9205dfba9aba to disappear
Dec  3 15:17:36.097: INFO: Pod downwardapi-volume-bdd1c294-165f-463e-9794-9205dfba9aba no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:17:36.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7644" for this suite.
Dec  3 15:17:42.186: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:17:42.785: INFO: namespace projected-7644 deletion completed in 6.654577608s
•SSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:17:42.785: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-623
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:17:43.052: INFO: (0) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 23.896701ms)
Dec  3 15:17:43.096: INFO: (1) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 44.66792ms)
Dec  3 15:17:43.117: INFO: (2) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.737707ms)
Dec  3 15:17:43.138: INFO: (3) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.458758ms)
Dec  3 15:17:43.158: INFO: (4) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.470537ms)
Dec  3 15:17:43.178: INFO: (5) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 19.839343ms)
Dec  3 15:17:43.199: INFO: (6) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.937073ms)
Dec  3 15:17:43.220: INFO: (7) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.413478ms)
Dec  3 15:17:43.240: INFO: (8) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 19.878591ms)
Dec  3 15:17:43.260: INFO: (9) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.09183ms)
Dec  3 15:17:43.280: INFO: (10) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.042444ms)
Dec  3 15:17:43.300: INFO: (11) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 19.912648ms)
Dec  3 15:17:43.320: INFO: (12) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.094631ms)
Dec  3 15:17:43.341: INFO: (13) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.79817ms)
Dec  3 15:17:43.361: INFO: (14) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 19.908709ms)
Dec  3 15:17:43.381: INFO: (15) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.127296ms)
Dec  3 15:17:43.401: INFO: (16) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 19.761544ms)
Dec  3 15:17:43.421: INFO: (17) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.023466ms)
Dec  3 15:17:43.442: INFO: (18) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.907029ms)
Dec  3 15:17:43.462: INFO: (19) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk:10250/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 19.876515ms)
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:17:43.462: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-623" for this suite.
Dec  3 15:17:49.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:17:50.166: INFO: namespace proxy-623 deletion completed in 6.685955514s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:17:50.167: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-421
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-14ca9d61-84ee-4718-96f9-177c20c8296e
STEP: Creating a pod to test consume configMaps
Dec  3 15:17:50.443: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-e7739783-d80d-4824-9097-f292de667210" in namespace "projected-421" to be "success or failure"
Dec  3 15:17:50.460: INFO: Pod "pod-projected-configmaps-e7739783-d80d-4824-9097-f292de667210": Phase="Pending", Reason="", readiness=false. Elapsed: 16.766686ms
Dec  3 15:17:52.477: INFO: Pod "pod-projected-configmaps-e7739783-d80d-4824-9097-f292de667210": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03449858s
Dec  3 15:17:54.495: INFO: Pod "pod-projected-configmaps-e7739783-d80d-4824-9097-f292de667210": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052473698s
STEP: Saw pod success
Dec  3 15:17:54.495: INFO: Pod "pod-projected-configmaps-e7739783-d80d-4824-9097-f292de667210" satisfied condition "success or failure"
Dec  3 15:17:54.512: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-projected-configmaps-e7739783-d80d-4824-9097-f292de667210 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:17:54.559: INFO: Waiting for pod pod-projected-configmaps-e7739783-d80d-4824-9097-f292de667210 to disappear
Dec  3 15:17:54.576: INFO: Pod pod-projected-configmaps-e7739783-d80d-4824-9097-f292de667210 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:17:54.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-421" for this suite.
Dec  3 15:18:00.663: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:18:01.296: INFO: namespace projected-421 deletion completed in 6.687281889s
•SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:18:01.297: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5706
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:18:01.545: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7a89fc3f-a58f-4c94-aaf7-61fcc7621686" in namespace "downward-api-5706" to be "success or failure"
Dec  3 15:18:01.562: INFO: Pod "downwardapi-volume-7a89fc3f-a58f-4c94-aaf7-61fcc7621686": Phase="Pending", Reason="", readiness=false. Elapsed: 17.185371ms
Dec  3 15:18:03.580: INFO: Pod "downwardapi-volume-7a89fc3f-a58f-4c94-aaf7-61fcc7621686": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035457156s
Dec  3 15:18:05.598: INFO: Pod "downwardapi-volume-7a89fc3f-a58f-4c94-aaf7-61fcc7621686": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053367982s
STEP: Saw pod success
Dec  3 15:18:05.598: INFO: Pod "downwardapi-volume-7a89fc3f-a58f-4c94-aaf7-61fcc7621686" satisfied condition "success or failure"
Dec  3 15:18:05.615: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downwardapi-volume-7a89fc3f-a58f-4c94-aaf7-61fcc7621686 container client-container: <nil>
STEP: delete the pod
Dec  3 15:18:05.670: INFO: Waiting for pod downwardapi-volume-7a89fc3f-a58f-4c94-aaf7-61fcc7621686 to disappear
Dec  3 15:18:05.686: INFO: Pod downwardapi-volume-7a89fc3f-a58f-4c94-aaf7-61fcc7621686 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:18:05.686: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5706" for this suite.
Dec  3 15:18:11.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:18:12.390: INFO: namespace downward-api-5706 deletion completed in 6.667035493s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:18:12.390: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-3286
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:18:12.614: INFO: Creating ReplicaSet my-hostname-basic-4c5ff5cb-1d31-4d50-9682-cd4661929c3e
Dec  3 15:18:12.655: INFO: Pod name my-hostname-basic-4c5ff5cb-1d31-4d50-9682-cd4661929c3e: Found 1 pods out of 1
Dec  3 15:18:12.655: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-4c5ff5cb-1d31-4d50-9682-cd4661929c3e" is running
Dec  3 15:18:16.691: INFO: Pod "my-hostname-basic-4c5ff5cb-1d31-4d50-9682-cd4661929c3e-dsbmg" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 15:18:12 +0000 UTC Reason: Message:}])
Dec  3 15:18:16.692: INFO: Trying to dial the pod
Dec  3 15:18:21.835: INFO: Controller my-hostname-basic-4c5ff5cb-1d31-4d50-9682-cd4661929c3e: Got expected result from replica 1 [my-hostname-basic-4c5ff5cb-1d31-4d50-9682-cd4661929c3e-dsbmg]: "my-hostname-basic-4c5ff5cb-1d31-4d50-9682-cd4661929c3e-dsbmg", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:18:21.835: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3286" for this suite.
Dec  3 15:18:27.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:18:28.534: INFO: namespace replicaset-3286 deletion completed in 6.66240506s
•SS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:18:28.534: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7325
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:18:28.775: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6be8b9d9-401d-44cf-8fe5-60d93e401dfb" in namespace "downward-api-7325" to be "success or failure"
Dec  3 15:18:28.792: INFO: Pod "downwardapi-volume-6be8b9d9-401d-44cf-8fe5-60d93e401dfb": Phase="Pending", Reason="", readiness=false. Elapsed: 16.82034ms
Dec  3 15:18:30.810: INFO: Pod "downwardapi-volume-6be8b9d9-401d-44cf-8fe5-60d93e401dfb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035061478s
Dec  3 15:18:32.828: INFO: Pod "downwardapi-volume-6be8b9d9-401d-44cf-8fe5-60d93e401dfb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053168969s
STEP: Saw pod success
Dec  3 15:18:32.828: INFO: Pod "downwardapi-volume-6be8b9d9-401d-44cf-8fe5-60d93e401dfb" satisfied condition "success or failure"
Dec  3 15:18:32.845: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downwardapi-volume-6be8b9d9-401d-44cf-8fe5-60d93e401dfb container client-container: <nil>
STEP: delete the pod
Dec  3 15:18:32.893: INFO: Waiting for pod downwardapi-volume-6be8b9d9-401d-44cf-8fe5-60d93e401dfb to disappear
Dec  3 15:18:32.909: INFO: Pod downwardapi-volume-6be8b9d9-401d-44cf-8fe5-60d93e401dfb no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:18:32.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7325" for this suite.
Dec  3 15:18:39.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:18:39.608: INFO: namespace downward-api-7325 deletion completed in 6.665783701s
•SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:18:39.608: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-3975
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-eb4facfa-1a03-447f-8361-4ef2ac125de7 in namespace container-probe-3975
Dec  3 15:18:43.887: INFO: Started pod busybox-eb4facfa-1a03-447f-8361-4ef2ac125de7 in namespace container-probe-3975
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 15:18:43.904: INFO: Initial restart count of pod busybox-eb4facfa-1a03-447f-8361-4ef2ac125de7 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:22:44.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-3975" for this suite.
Dec  3 15:22:50.202: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:22:50.816: INFO: namespace container-probe-3975 deletion completed in 6.674672077s
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:22:50.817: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5897
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  3 15:22:51.066: INFO: Waiting up to 5m0s for pod "pod-a0e1ab8b-e5af-46c1-95ea-6d975856ad1f" in namespace "emptydir-5897" to be "success or failure"
Dec  3 15:22:51.083: INFO: Pod "pod-a0e1ab8b-e5af-46c1-95ea-6d975856ad1f": Phase="Pending", Reason="", readiness=false. Elapsed: 17.104061ms
Dec  3 15:22:53.109: INFO: Pod "pod-a0e1ab8b-e5af-46c1-95ea-6d975856ad1f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042393731s
Dec  3 15:22:55.127: INFO: Pod "pod-a0e1ab8b-e5af-46c1-95ea-6d975856ad1f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.060727793s
STEP: Saw pod success
Dec  3 15:22:55.127: INFO: Pod "pod-a0e1ab8b-e5af-46c1-95ea-6d975856ad1f" satisfied condition "success or failure"
Dec  3 15:22:55.144: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-a0e1ab8b-e5af-46c1-95ea-6d975856ad1f container test-container: <nil>
STEP: delete the pod
Dec  3 15:22:55.331: INFO: Waiting for pod pod-a0e1ab8b-e5af-46c1-95ea-6d975856ad1f to disappear
Dec  3 15:22:55.348: INFO: Pod pod-a0e1ab8b-e5af-46c1-95ea-6d975856ad1f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:22:55.348: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5897" for this suite.
Dec  3 15:23:01.438: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:23:02.053: INFO: namespace emptydir-5897 deletion completed in 6.669232869s
•SSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:23:02.054: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5171
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-715bf607-de22-43f8-894f-2982d2e03620
STEP: Creating a pod to test consume secrets
Dec  3 15:23:02.313: INFO: Waiting up to 5m0s for pod "pod-secrets-a0aedf57-3ab9-4722-94c6-eca84a9f89da" in namespace "secrets-5171" to be "success or failure"
Dec  3 15:23:02.330: INFO: Pod "pod-secrets-a0aedf57-3ab9-4722-94c6-eca84a9f89da": Phase="Pending", Reason="", readiness=false. Elapsed: 16.660415ms
Dec  3 15:23:04.348: INFO: Pod "pod-secrets-a0aedf57-3ab9-4722-94c6-eca84a9f89da": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034325836s
Dec  3 15:23:06.370: INFO: Pod "pod-secrets-a0aedf57-3ab9-4722-94c6-eca84a9f89da": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056436124s
STEP: Saw pod success
Dec  3 15:23:06.370: INFO: Pod "pod-secrets-a0aedf57-3ab9-4722-94c6-eca84a9f89da" satisfied condition "success or failure"
Dec  3 15:23:06.388: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-secrets-a0aedf57-3ab9-4722-94c6-eca84a9f89da container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:23:06.440: INFO: Waiting for pod pod-secrets-a0aedf57-3ab9-4722-94c6-eca84a9f89da to disappear
Dec  3 15:23:06.464: INFO: Pod pod-secrets-a0aedf57-3ab9-4722-94c6-eca84a9f89da no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:23:06.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5171" for this suite.
Dec  3 15:23:12.556: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:23:13.200: INFO: namespace secrets-5171 deletion completed in 6.703644085s
•SSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:23:13.201: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-1080
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:23:15.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-1080" for this suite.
Dec  3 15:23:21.687: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:23:22.290: INFO: namespace emptydir-wrapper-1080 deletion completed in 6.661204948s
•SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:23:22.290: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6977
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:23:22.937: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983402, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983402, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983402, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983402, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:23:24.955: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983402, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983402, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983402, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983402, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:23:27.983: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:23:28.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6977" for this suite.
Dec  3 15:23:34.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:23:34.902: INFO: namespace webhook-6977 deletion completed in 6.658276163s
STEP: Destroying namespace "webhook-6977-markers" for this suite.
Dec  3 15:23:40.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:23:41.563: INFO: namespace webhook-6977-markers deletion completed in 6.660975557s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:23:41.634: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1689
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Dec  3 15:23:41.876: INFO: Waiting up to 5m0s for pod "client-containers-9a897804-6f5a-47b1-97a9-7158facc0ce6" in namespace "containers-1689" to be "success or failure"
Dec  3 15:23:41.893: INFO: Pod "client-containers-9a897804-6f5a-47b1-97a9-7158facc0ce6": Phase="Pending", Reason="", readiness=false. Elapsed: 17.133597ms
Dec  3 15:23:43.911: INFO: Pod "client-containers-9a897804-6f5a-47b1-97a9-7158facc0ce6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034517762s
Dec  3 15:23:45.929: INFO: Pod "client-containers-9a897804-6f5a-47b1-97a9-7158facc0ce6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052380076s
STEP: Saw pod success
Dec  3 15:23:45.929: INFO: Pod "client-containers-9a897804-6f5a-47b1-97a9-7158facc0ce6" satisfied condition "success or failure"
Dec  3 15:23:45.946: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod client-containers-9a897804-6f5a-47b1-97a9-7158facc0ce6 container test-container: <nil>
STEP: delete the pod
Dec  3 15:23:45.999: INFO: Waiting for pod client-containers-9a897804-6f5a-47b1-97a9-7158facc0ce6 to disappear
Dec  3 15:23:46.017: INFO: Pod client-containers-9a897804-6f5a-47b1-97a9-7158facc0ce6 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:23:46.017: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1689" for this suite.
Dec  3 15:23:52.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:23:52.706: INFO: namespace containers-1689 deletion completed in 6.655907349s
•S
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:23:52.706: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4531
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-9252a2e9-591c-456c-83d3-3583ba8c6d99
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:23:52.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4531" for this suite.
Dec  3 15:23:59.015: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:23:59.613: INFO: namespace secrets-4531 deletion completed in 6.650297298s
•SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:23:59.613: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1567
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:24:00.508: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983440, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983440, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983440, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983440, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:24:02.531: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983440, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983440, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983440, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983440, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:24:05.556: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:24:05.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1567" for this suite.
Dec  3 15:24:12.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:24:12.705: INFO: namespace webhook-1567 deletion completed in 6.689409534s
STEP: Destroying namespace "webhook-1567-markers" for this suite.
Dec  3 15:24:18.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:24:19.363: INFO: namespace webhook-1567-markers deletion completed in 6.658347912s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:24:19.432: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-8552
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:24:23.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-8552" for this suite.
Dec  3 15:24:29.799: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:24:30.410: INFO: namespace kubelet-test-8552 deletion completed in 6.663257504s
•SSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:24:30.410: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1602
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-a3a81bac-c212-4c78-86fb-f75597ae93dd
STEP: Creating a pod to test consume secrets
Dec  3 15:24:30.672: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-2cdccd66-2e83-4592-80af-f3125944ac8d" in namespace "projected-1602" to be "success or failure"
Dec  3 15:24:30.690: INFO: Pod "pod-projected-secrets-2cdccd66-2e83-4592-80af-f3125944ac8d": Phase="Pending", Reason="", readiness=false. Elapsed: 17.865496ms
Dec  3 15:24:32.708: INFO: Pod "pod-projected-secrets-2cdccd66-2e83-4592-80af-f3125944ac8d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036016482s
STEP: Saw pod success
Dec  3 15:24:32.708: INFO: Pod "pod-projected-secrets-2cdccd66-2e83-4592-80af-f3125944ac8d" satisfied condition "success or failure"
Dec  3 15:24:32.725: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-projected-secrets-2cdccd66-2e83-4592-80af-f3125944ac8d container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:24:32.780: INFO: Waiting for pod pod-projected-secrets-2cdccd66-2e83-4592-80af-f3125944ac8d to disappear
Dec  3 15:24:32.797: INFO: Pod pod-projected-secrets-2cdccd66-2e83-4592-80af-f3125944ac8d no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:24:32.797: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1602" for this suite.
Dec  3 15:24:38.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:24:39.508: INFO: namespace projected-1602 deletion completed in 6.668906646s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:24:39.510: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3485
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  3 15:24:39.759: INFO: Waiting up to 5m0s for pod "pod-43e1c24b-5be5-40f6-b2af-da355a595d76" in namespace "emptydir-3485" to be "success or failure"
Dec  3 15:24:39.776: INFO: Pod "pod-43e1c24b-5be5-40f6-b2af-da355a595d76": Phase="Pending", Reason="", readiness=false. Elapsed: 16.855256ms
Dec  3 15:24:41.793: INFO: Pod "pod-43e1c24b-5be5-40f6-b2af-da355a595d76": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.034646291s
STEP: Saw pod success
Dec  3 15:24:41.793: INFO: Pod "pod-43e1c24b-5be5-40f6-b2af-da355a595d76" satisfied condition "success or failure"
Dec  3 15:24:41.810: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-43e1c24b-5be5-40f6-b2af-da355a595d76 container test-container: <nil>
STEP: delete the pod
Dec  3 15:24:41.865: INFO: Waiting for pod pod-43e1c24b-5be5-40f6-b2af-da355a595d76 to disappear
Dec  3 15:24:41.884: INFO: Pod pod-43e1c24b-5be5-40f6-b2af-da355a595d76 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:24:41.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3485" for this suite.
Dec  3 15:24:47.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:24:48.576: INFO: namespace emptydir-3485 deletion completed in 6.658926572s
•SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:24:48.576: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9197
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:24:48.891: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec  3 15:24:48.949: INFO: Number of nodes with available pods: 0
Dec  3 15:24:48.949: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 15:24:50.000: INFO: Number of nodes with available pods: 0
Dec  3 15:24:50.000: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 15:24:51.000: INFO: Number of nodes with available pods: 2
Dec  3 15:24:51.000: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec  3 15:24:51.132: INFO: Wrong image for pod: daemon-set-85mw7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:24:51.132: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:24:52.168: INFO: Wrong image for pod: daemon-set-85mw7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:24:52.168: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:24:53.168: INFO: Wrong image for pod: daemon-set-85mw7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:24:53.168: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:24:54.176: INFO: Wrong image for pod: daemon-set-85mw7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:24:54.176: INFO: Pod daemon-set-85mw7 is not available
Dec  3 15:24:54.176: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:24:55.168: INFO: Wrong image for pod: daemon-set-85mw7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:24:55.168: INFO: Pod daemon-set-85mw7 is not available
Dec  3 15:24:55.168: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:24:56.168: INFO: Wrong image for pod: daemon-set-85mw7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:24:56.168: INFO: Pod daemon-set-85mw7 is not available
Dec  3 15:24:56.168: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:24:57.168: INFO: Wrong image for pod: daemon-set-85mw7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:24:57.168: INFO: Pod daemon-set-85mw7 is not available
Dec  3 15:24:57.168: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:24:58.168: INFO: Wrong image for pod: daemon-set-85mw7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:24:58.168: INFO: Pod daemon-set-85mw7 is not available
Dec  3 15:24:58.168: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:24:59.172: INFO: Wrong image for pod: daemon-set-85mw7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:24:59.172: INFO: Pod daemon-set-85mw7 is not available
Dec  3 15:24:59.172: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:25:00.168: INFO: Wrong image for pod: daemon-set-85mw7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:25:00.168: INFO: Pod daemon-set-85mw7 is not available
Dec  3 15:25:00.168: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:25:01.174: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:25:01.174: INFO: Pod daemon-set-xjx5m is not available
Dec  3 15:25:02.168: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:25:02.168: INFO: Pod daemon-set-xjx5m is not available
Dec  3 15:25:03.168: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:25:04.167: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:25:04.167: INFO: Pod daemon-set-tdvc7 is not available
Dec  3 15:25:05.167: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:25:05.168: INFO: Pod daemon-set-tdvc7 is not available
Dec  3 15:25:06.168: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:25:06.168: INFO: Pod daemon-set-tdvc7 is not available
Dec  3 15:25:07.168: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:25:07.168: INFO: Pod daemon-set-tdvc7 is not available
Dec  3 15:25:08.168: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:25:08.168: INFO: Pod daemon-set-tdvc7 is not available
Dec  3 15:25:09.168: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:25:09.168: INFO: Pod daemon-set-tdvc7 is not available
Dec  3 15:25:10.168: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:25:10.168: INFO: Pod daemon-set-tdvc7 is not available
Dec  3 15:25:11.168: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:25:11.168: INFO: Pod daemon-set-tdvc7 is not available
Dec  3 15:25:12.168: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:25:12.168: INFO: Pod daemon-set-tdvc7 is not available
Dec  3 15:25:13.168: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:25:13.168: INFO: Pod daemon-set-tdvc7 is not available
Dec  3 15:25:14.168: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:25:14.168: INFO: Pod daemon-set-tdvc7 is not available
Dec  3 15:25:15.168: INFO: Wrong image for pod: daemon-set-tdvc7. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:25:15.168: INFO: Pod daemon-set-tdvc7 is not available
Dec  3 15:25:16.167: INFO: Pod daemon-set-gf9gk is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Dec  3 15:25:16.238: INFO: Number of nodes with available pods: 1
Dec  3 15:25:16.238: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v is running more than one daemon pod
Dec  3 15:25:17.289: INFO: Number of nodes with available pods: 1
Dec  3 15:25:17.289: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v is running more than one daemon pod
Dec  3 15:25:18.289: INFO: Number of nodes with available pods: 1
Dec  3 15:25:18.290: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v is running more than one daemon pod
Dec  3 15:25:19.289: INFO: Number of nodes with available pods: 1
Dec  3 15:25:19.290: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v is running more than one daemon pod
Dec  3 15:25:20.293: INFO: Number of nodes with available pods: 1
Dec  3 15:25:20.293: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v is running more than one daemon pod
Dec  3 15:25:21.290: INFO: Number of nodes with available pods: 1
Dec  3 15:25:21.290: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v is running more than one daemon pod
Dec  3 15:25:22.290: INFO: Number of nodes with available pods: 2
Dec  3 15:25:22.290: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9197, will wait for the garbage collector to delete the pods
Dec  3 15:25:22.463: INFO: Deleting DaemonSet.extensions daemon-set took: 19.167624ms
Dec  3 15:25:22.863: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.368556ms
Dec  3 15:25:36.081: INFO: Number of nodes with available pods: 0
Dec  3 15:25:36.081: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 15:25:36.098: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9197/daemonsets","resourceVersion":"10392"},"items":null}

Dec  3 15:25:36.116: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9197/pods","resourceVersion":"10392"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:25:36.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9197" for this suite.
Dec  3 15:25:42.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:25:42.851: INFO: namespace daemonsets-9197 deletion completed in 6.650663526s
•SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:25:42.852: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4964
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Dec  3 15:25:43.077: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-4964 -- logs-generator --log-lines-total 100 --run-duration 20s'
Dec  3 15:25:43.490: INFO: stderr: ""
Dec  3 15:25:43.490: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Dec  3 15:25:43.490: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Dec  3 15:25:43.490: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-4964" to be "running and ready, or succeeded"
Dec  3 15:25:43.507: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 17.302527ms
Dec  3 15:25:45.526: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.035932491s
Dec  3 15:25:45.526: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Dec  3 15:25:45.526: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Dec  3 15:25:45.526: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-4964'
Dec  3 15:25:45.847: INFO: stderr: ""
Dec  3 15:25:45.847: INFO: stdout: "I1203 15:25:44.716567       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/nvd 422\nI1203 15:25:44.916727       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/sltt 220\nI1203 15:25:45.116787       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/vzm6 507\nI1203 15:25:45.316866       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/92g 391\nI1203 15:25:45.516823       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/z7w 502\nI1203 15:25:45.716917       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/gfl 568\n"
STEP: limiting log lines
Dec  3 15:25:45.847: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-4964 --tail=1'
Dec  3 15:25:46.159: INFO: stderr: ""
Dec  3 15:25:46.159: INFO: stdout: "I1203 15:25:45.916734       1 logs_generator.go:76] 6 GET /api/v1/namespaces/kube-system/pods/nxh 511\n"
STEP: limiting log bytes
Dec  3 15:25:46.159: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-4964 --limit-bytes=1'
Dec  3 15:25:46.338: INFO: stderr: ""
Dec  3 15:25:46.338: INFO: stdout: "I"
STEP: exposing timestamps
Dec  3 15:25:46.338: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-4964 --tail=1 --timestamps'
Dec  3 15:25:46.517: INFO: stderr: ""
Dec  3 15:25:46.517: INFO: stdout: "2019-12-03T15:25:46.31696079Z I1203 15:25:46.316778       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/xhw 239\n"
STEP: restricting to a time range
Dec  3 15:25:49.017: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-4964 --since=1s'
Dec  3 15:25:49.195: INFO: stderr: ""
Dec  3 15:25:49.195: INFO: stdout: "I1203 15:25:48.316762       1 logs_generator.go:76] 18 GET /api/v1/namespaces/kube-system/pods/lkz 208\nI1203 15:25:48.516744       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/56v2 413\nI1203 15:25:48.716784       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/xj9 368\nI1203 15:25:48.916808       1 logs_generator.go:76] 21 GET /api/v1/namespaces/ns/pods/vjj 383\nI1203 15:25:49.116749       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/kube-system/pods/xmsd 333\n"
Dec  3 15:25:49.195: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-4964 --since=24h'
Dec  3 15:25:49.372: INFO: stderr: ""
Dec  3 15:25:49.372: INFO: stdout: "I1203 15:25:44.716567       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/kube-system/pods/nvd 422\nI1203 15:25:44.916727       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/sltt 220\nI1203 15:25:45.116787       1 logs_generator.go:76] 2 GET /api/v1/namespaces/ns/pods/vzm6 507\nI1203 15:25:45.316866       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/92g 391\nI1203 15:25:45.516823       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/z7w 502\nI1203 15:25:45.716917       1 logs_generator.go:76] 5 PUT /api/v1/namespaces/kube-system/pods/gfl 568\nI1203 15:25:45.916734       1 logs_generator.go:76] 6 GET /api/v1/namespaces/kube-system/pods/nxh 511\nI1203 15:25:46.116800       1 logs_generator.go:76] 7 GET /api/v1/namespaces/kube-system/pods/v56 475\nI1203 15:25:46.316778       1 logs_generator.go:76] 8 PUT /api/v1/namespaces/kube-system/pods/xhw 239\nI1203 15:25:46.516733       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/t5w 222\nI1203 15:25:46.716809       1 logs_generator.go:76] 10 GET /api/v1/namespaces/kube-system/pods/6pg8 378\nI1203 15:25:46.916823       1 logs_generator.go:76] 11 PUT /api/v1/namespaces/ns/pods/7lmg 400\nI1203 15:25:47.116751       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/ns/pods/z7ts 548\nI1203 15:25:47.316754       1 logs_generator.go:76] 13 PUT /api/v1/namespaces/ns/pods/fbjs 340\nI1203 15:25:47.516807       1 logs_generator.go:76] 14 GET /api/v1/namespaces/kube-system/pods/rnp8 516\nI1203 15:25:47.716744       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/hct 469\nI1203 15:25:47.916724       1 logs_generator.go:76] 16 PUT /api/v1/namespaces/kube-system/pods/74l 420\nI1203 15:25:48.116737       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/sg5w 232\nI1203 15:25:48.316762       1 logs_generator.go:76] 18 GET /api/v1/namespaces/kube-system/pods/lkz 208\nI1203 15:25:48.516744       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/default/pods/56v2 413\nI1203 15:25:48.716784       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/kube-system/pods/xj9 368\nI1203 15:25:48.916808       1 logs_generator.go:76] 21 GET /api/v1/namespaces/ns/pods/vjj 383\nI1203 15:25:49.116749       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/kube-system/pods/xmsd 333\nI1203 15:25:49.316732       1 logs_generator.go:76] 23 PUT /api/v1/namespaces/default/pods/bdhq 250\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Dec  3 15:25:49.372: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pod logs-generator --namespace=kubectl-4964'
Dec  3 15:26:00.730: INFO: stderr: ""
Dec  3 15:26:00.730: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:26:00.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4964" for this suite.
Dec  3 15:26:06.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:26:07.413: INFO: namespace kubectl-4964 deletion completed in 6.64801321s
•SSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:26:07.413: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1062
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:26:23.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1062" for this suite.
Dec  3 15:26:30.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:26:30.676: INFO: namespace resourcequota-1062 deletion completed in 6.705247848s
•SSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:26:30.677: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9467
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:27:30.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9467" for this suite.
Dec  3 15:27:43.028: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:27:43.619: INFO: namespace container-probe-9467 deletion completed in 12.649859572s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:27:43.620: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4148
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-v2hp
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 15:27:43.902: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-v2hp" in namespace "subpath-4148" to be "success or failure"
Dec  3 15:27:43.919: INFO: Pod "pod-subpath-test-projected-v2hp": Phase="Pending", Reason="", readiness=false. Elapsed: 17.048347ms
Dec  3 15:27:45.937: INFO: Pod "pod-subpath-test-projected-v2hp": Phase="Running", Reason="", readiness=true. Elapsed: 2.03479686s
Dec  3 15:27:47.956: INFO: Pod "pod-subpath-test-projected-v2hp": Phase="Running", Reason="", readiness=true. Elapsed: 4.053325767s
Dec  3 15:27:49.973: INFO: Pod "pod-subpath-test-projected-v2hp": Phase="Running", Reason="", readiness=true. Elapsed: 6.070924961s
Dec  3 15:27:51.991: INFO: Pod "pod-subpath-test-projected-v2hp": Phase="Running", Reason="", readiness=true. Elapsed: 8.088750924s
Dec  3 15:27:54.009: INFO: Pod "pod-subpath-test-projected-v2hp": Phase="Running", Reason="", readiness=true. Elapsed: 10.1064354s
Dec  3 15:27:56.026: INFO: Pod "pod-subpath-test-projected-v2hp": Phase="Running", Reason="", readiness=true. Elapsed: 12.123993204s
Dec  3 15:27:58.044: INFO: Pod "pod-subpath-test-projected-v2hp": Phase="Running", Reason="", readiness=true. Elapsed: 14.142035739s
Dec  3 15:28:00.062: INFO: Pod "pod-subpath-test-projected-v2hp": Phase="Running", Reason="", readiness=true. Elapsed: 16.159822424s
Dec  3 15:28:02.080: INFO: Pod "pod-subpath-test-projected-v2hp": Phase="Running", Reason="", readiness=true. Elapsed: 18.177925067s
Dec  3 15:28:04.098: INFO: Pod "pod-subpath-test-projected-v2hp": Phase="Running", Reason="", readiness=true. Elapsed: 20.195518496s
Dec  3 15:28:06.116: INFO: Pod "pod-subpath-test-projected-v2hp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.213507029s
STEP: Saw pod success
Dec  3 15:28:06.119: INFO: Pod "pod-subpath-test-projected-v2hp" satisfied condition "success or failure"
Dec  3 15:28:06.136: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-subpath-test-projected-v2hp container test-container-subpath-projected-v2hp: <nil>
STEP: delete the pod
Dec  3 15:28:06.295: INFO: Waiting for pod pod-subpath-test-projected-v2hp to disappear
Dec  3 15:28:06.312: INFO: Pod pod-subpath-test-projected-v2hp no longer exists
STEP: Deleting pod pod-subpath-test-projected-v2hp
Dec  3 15:28:06.312: INFO: Deleting pod "pod-subpath-test-projected-v2hp" in namespace "subpath-4148"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:28:06.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4148" for this suite.
Dec  3 15:28:12.418: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:28:13.049: INFO: namespace subpath-4148 deletion completed in 6.687079239s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:28:13.050: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2678
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:28:13.761: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983693, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983693, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983693, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983693, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:28:16.807: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Dec  3 15:28:19.058: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config attach --namespace=webhook-2678 to-be-attached-pod -i -c=container1'
Dec  3 15:28:19.428: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:28:19.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2678" for this suite.
Dec  3 15:28:31.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:28:32.140: INFO: namespace webhook-2678 deletion completed in 12.654711465s
STEP: Destroying namespace "webhook-2678-markers" for this suite.
Dec  3 15:28:38.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:28:38.800: INFO: namespace webhook-2678-markers deletion completed in 6.659912645s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:28:38.869: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6203
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec  3 15:28:39.119: INFO: Waiting up to 5m0s for pod "pod-47d3727e-1718-4737-9c73-997ffdf81729" in namespace "emptydir-6203" to be "success or failure"
Dec  3 15:28:39.136: INFO: Pod "pod-47d3727e-1718-4737-9c73-997ffdf81729": Phase="Pending", Reason="", readiness=false. Elapsed: 16.981873ms
Dec  3 15:28:41.157: INFO: Pod "pod-47d3727e-1718-4737-9c73-997ffdf81729": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.037648209s
STEP: Saw pod success
Dec  3 15:28:41.157: INFO: Pod "pod-47d3727e-1718-4737-9c73-997ffdf81729" satisfied condition "success or failure"
Dec  3 15:28:41.174: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-47d3727e-1718-4737-9c73-997ffdf81729 container test-container: <nil>
STEP: delete the pod
Dec  3 15:28:41.233: INFO: Waiting for pod pod-47d3727e-1718-4737-9c73-997ffdf81729 to disappear
Dec  3 15:28:41.250: INFO: Pod pod-47d3727e-1718-4737-9c73-997ffdf81729 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:28:41.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6203" for this suite.
Dec  3 15:28:47.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:28:47.957: INFO: namespace emptydir-6203 deletion completed in 6.674957957s
•SSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:28:47.957: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-6995
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-6995
I1203 15:28:48.195688    5095 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-6995, replica count: 1
I1203 15:28:49.246244    5095 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 15:28:50.246605    5095 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 15:28:50.374: INFO: Created: latency-svc-sgrwf
Dec  3 15:28:50.377: INFO: Got endpoints: latency-svc-sgrwf [30.846414ms]
Dec  3 15:28:50.404: INFO: Created: latency-svc-7q47j
Dec  3 15:28:50.415: INFO: Created: latency-svc-p9t2r
Dec  3 15:28:50.415: INFO: Got endpoints: latency-svc-7q47j [37.474921ms]
Dec  3 15:28:50.417: INFO: Got endpoints: latency-svc-p9t2r [39.837981ms]
Dec  3 15:28:50.426: INFO: Created: latency-svc-ddcf9
Dec  3 15:28:50.437: INFO: Got endpoints: latency-svc-ddcf9 [59.282466ms]
Dec  3 15:28:50.437: INFO: Created: latency-svc-dg477
Dec  3 15:28:50.440: INFO: Got endpoints: latency-svc-dg477 [62.620268ms]
Dec  3 15:28:50.472: INFO: Created: latency-svc-tpbhb
Dec  3 15:28:50.482: INFO: Got endpoints: latency-svc-tpbhb [104.513159ms]
Dec  3 15:28:50.482: INFO: Created: latency-svc-687bj
Dec  3 15:28:50.516: INFO: Got endpoints: latency-svc-687bj [138.136765ms]
Dec  3 15:28:50.528: INFO: Created: latency-svc-9f7j8
Dec  3 15:28:50.538: INFO: Created: latency-svc-jmqxk
Dec  3 15:28:50.538: INFO: Got endpoints: latency-svc-9f7j8 [160.678083ms]
Dec  3 15:28:50.541: INFO: Got endpoints: latency-svc-jmqxk [163.02203ms]
Dec  3 15:28:50.565: INFO: Created: latency-svc-4cqcr
Dec  3 15:28:50.567: INFO: Got endpoints: latency-svc-4cqcr [189.216229ms]
Dec  3 15:28:50.621: INFO: Created: latency-svc-fbjjl
Dec  3 15:28:50.623: INFO: Got endpoints: latency-svc-fbjjl [244.863365ms]
Dec  3 15:28:50.635: INFO: Created: latency-svc-wkhbc
Dec  3 15:28:50.645: INFO: Created: latency-svc-9rzj5
Dec  3 15:28:50.645: INFO: Got endpoints: latency-svc-wkhbc [267.079994ms]
Dec  3 15:28:50.663: INFO: Created: latency-svc-dsb5d
Dec  3 15:28:50.663: INFO: Got endpoints: latency-svc-9rzj5 [285.615986ms]
Dec  3 15:28:50.671: INFO: Got endpoints: latency-svc-dsb5d [293.706412ms]
Dec  3 15:28:50.680: INFO: Created: latency-svc-nft2q
Dec  3 15:28:50.683: INFO: Got endpoints: latency-svc-nft2q [305.46514ms]
Dec  3 15:28:50.691: INFO: Created: latency-svc-qm4bg
Dec  3 15:28:50.716: INFO: Got endpoints: latency-svc-qm4bg [338.665229ms]
Dec  3 15:28:50.717: INFO: Created: latency-svc-9wljq
Dec  3 15:28:50.765: INFO: Got endpoints: latency-svc-9wljq [350.314789ms]
Dec  3 15:28:50.766: INFO: Created: latency-svc-xh9js
Dec  3 15:28:50.775: INFO: Got endpoints: latency-svc-xh9js [357.892062ms]
Dec  3 15:28:50.775: INFO: Created: latency-svc-k2h5s
Dec  3 15:28:50.785: INFO: Got endpoints: latency-svc-k2h5s [348.467072ms]
Dec  3 15:28:50.786: INFO: Created: latency-svc-qq8l8
Dec  3 15:28:50.788: INFO: Got endpoints: latency-svc-qq8l8 [347.858769ms]
Dec  3 15:28:50.820: INFO: Created: latency-svc-c9shg
Dec  3 15:28:50.827: INFO: Got endpoints: latency-svc-c9shg [345.074683ms]
Dec  3 15:28:50.836: INFO: Created: latency-svc-bt8v6
Dec  3 15:28:50.863: INFO: Got endpoints: latency-svc-bt8v6 [346.808016ms]
Dec  3 15:28:50.863: INFO: Created: latency-svc-8r2zs
Dec  3 15:28:50.913: INFO: Got endpoints: latency-svc-8r2zs [374.812973ms]
Dec  3 15:28:50.914: INFO: Created: latency-svc-r6mlq
Dec  3 15:28:50.917: INFO: Got endpoints: latency-svc-r6mlq [375.965618ms]
Dec  3 15:28:50.929: INFO: Created: latency-svc-nx6wl
Dec  3 15:28:50.939: INFO: Created: latency-svc-m9j2j
Dec  3 15:28:50.939: INFO: Got endpoints: latency-svc-nx6wl [372.368524ms]
Dec  3 15:28:50.963: INFO: Created: latency-svc-jwwxj
Dec  3 15:28:50.964: INFO: Got endpoints: latency-svc-m9j2j [340.88766ms]
Dec  3 15:28:50.974: INFO: Got endpoints: latency-svc-jwwxj [329.432117ms]
Dec  3 15:28:50.974: INFO: Created: latency-svc-r82d4
Dec  3 15:28:50.985: INFO: Created: latency-svc-jsw8b
Dec  3 15:28:50.985: INFO: Got endpoints: latency-svc-r82d4 [321.84615ms]
Dec  3 15:28:50.993: INFO: Got endpoints: latency-svc-jsw8b [321.698851ms]
Dec  3 15:28:51.023: INFO: Created: latency-svc-jjtlb
Dec  3 15:28:51.073: INFO: Created: latency-svc-f5x8l
Dec  3 15:28:51.073: INFO: Got endpoints: latency-svc-jjtlb [389.602056ms]
Dec  3 15:28:51.084: INFO: Created: latency-svc-kgp9s
Dec  3 15:28:51.084: INFO: Got endpoints: latency-svc-f5x8l [367.443611ms]
Dec  3 15:28:51.095: INFO: Got endpoints: latency-svc-kgp9s [329.410276ms]
Dec  3 15:28:51.095: INFO: Created: latency-svc-mzdc8
Dec  3 15:28:51.119: INFO: Created: latency-svc-sb8qp
Dec  3 15:28:51.119: INFO: Got endpoints: latency-svc-mzdc8 [344.097593ms]
Dec  3 15:28:51.163: INFO: Created: latency-svc-fmsxg
Dec  3 15:28:51.164: INFO: Got endpoints: latency-svc-sb8qp [378.008839ms]
Dec  3 15:28:51.175: INFO: Created: latency-svc-z44ht
Dec  3 15:28:51.176: INFO: Got endpoints: latency-svc-fmsxg [387.271399ms]
Dec  3 15:28:51.187: INFO: Created: latency-svc-dt4fc
Dec  3 15:28:51.187: INFO: Got endpoints: latency-svc-z44ht [359.252668ms]
Dec  3 15:28:51.194: INFO: Got endpoints: latency-svc-dt4fc [331.113019ms]
Dec  3 15:28:51.219: INFO: Created: latency-svc-dv4f9
Dec  3 15:28:51.230: INFO: Created: latency-svc-zxbdw
Dec  3 15:28:51.230: INFO: Got endpoints: latency-svc-dv4f9 [316.382234ms]
Dec  3 15:28:51.241: INFO: Got endpoints: latency-svc-zxbdw [323.89848ms]
Dec  3 15:28:51.241: INFO: Created: latency-svc-xjbxw
Dec  3 15:28:51.243: INFO: Got endpoints: latency-svc-xjbxw [303.467349ms]
Dec  3 15:28:51.314: INFO: Created: latency-svc-xfqjc
Dec  3 15:28:51.325: INFO: Created: latency-svc-csfhx
Dec  3 15:28:51.325: INFO: Got endpoints: latency-svc-xfqjc [360.992819ms]
Dec  3 15:28:51.335: INFO: Got endpoints: latency-svc-csfhx [360.462357ms]
Dec  3 15:28:51.335: INFO: Created: latency-svc-bbjqt
Dec  3 15:28:51.337: INFO: Got endpoints: latency-svc-bbjqt [352.148396ms]
Dec  3 15:28:51.346: INFO: Created: latency-svc-btl5r
Dec  3 15:28:51.363: INFO: Got endpoints: latency-svc-btl5r [369.369598ms]
Dec  3 15:28:51.371: INFO: Created: latency-svc-7kdj4
Dec  3 15:28:51.378: INFO: Got endpoints: latency-svc-7kdj4 [305.542059ms]
Dec  3 15:28:51.386: INFO: Created: latency-svc-9wsxd
Dec  3 15:28:51.431: INFO: Created: latency-svc-z2hgs
Dec  3 15:28:51.431: INFO: Got endpoints: latency-svc-9wsxd [347.446225ms]
Dec  3 15:28:51.465: INFO: Created: latency-svc-nknpz
Dec  3 15:28:51.465: INFO: Got endpoints: latency-svc-z2hgs [369.959986ms]
Dec  3 15:28:51.475: INFO: Got endpoints: latency-svc-nknpz [355.379012ms]
Dec  3 15:28:51.475: INFO: Created: latency-svc-g79l6
Dec  3 15:28:51.487: INFO: Created: latency-svc-wl9lb
Dec  3 15:28:51.487: INFO: Got endpoints: latency-svc-g79l6 [323.769471ms]
Dec  3 15:28:51.516: INFO: Created: latency-svc-dhfps
Dec  3 15:28:51.516: INFO: Got endpoints: latency-svc-wl9lb [340.124884ms]
Dec  3 15:28:51.526: INFO: Created: latency-svc-fblzz
Dec  3 15:28:51.527: INFO: Got endpoints: latency-svc-dhfps [339.735027ms]
Dec  3 15:28:51.568: INFO: Got endpoints: latency-svc-fblzz [374.033714ms]
Dec  3 15:28:51.568: INFO: Created: latency-svc-zxdqc
Dec  3 15:28:51.574: INFO: Got endpoints: latency-svc-zxdqc [344.488089ms]
Dec  3 15:28:51.584: INFO: Created: latency-svc-f672b
Dec  3 15:28:51.616: INFO: Created: latency-svc-hqtqj
Dec  3 15:28:51.616: INFO: Got endpoints: latency-svc-f672b [375.717098ms]
Dec  3 15:28:51.629: INFO: Created: latency-svc-llk9t
Dec  3 15:28:51.630: INFO: Got endpoints: latency-svc-hqtqj [386.504912ms]
Dec  3 15:28:51.641: INFO: Created: latency-svc-wxwgz
Dec  3 15:28:51.667: INFO: Created: latency-svc-lhjk2
Dec  3 15:28:51.698: INFO: Got endpoints: latency-svc-llk9t [373.532979ms]
Dec  3 15:28:51.714: INFO: Created: latency-svc-jwvpb
Dec  3 15:28:51.725: INFO: Created: latency-svc-hggwg
Dec  3 15:28:51.736: INFO: Created: latency-svc-tsbf9
Dec  3 15:28:51.736: INFO: Got endpoints: latency-svc-wxwgz [400.582005ms]
Dec  3 15:28:51.763: INFO: Created: latency-svc-nfkrc
Dec  3 15:28:51.774: INFO: Created: latency-svc-8bkgh
Dec  3 15:28:51.784: INFO: Created: latency-svc-cmxch
Dec  3 15:28:51.784: INFO: Got endpoints: latency-svc-lhjk2 [446.225181ms]
Dec  3 15:28:51.824: INFO: Created: latency-svc-8rtvh
Dec  3 15:28:51.863: INFO: Created: latency-svc-7nj4l
Dec  3 15:28:51.863: INFO: Got endpoints: latency-svc-jwvpb [499.979983ms]
Dec  3 15:28:51.873: INFO: Created: latency-svc-d29tz
Dec  3 15:28:51.884: INFO: Created: latency-svc-r89pn
Dec  3 15:28:51.884: INFO: Got endpoints: latency-svc-hggwg [505.166371ms]
Dec  3 15:28:51.914: INFO: Created: latency-svc-dwc8m
Dec  3 15:28:51.966: INFO: Created: latency-svc-vthr5
Dec  3 15:28:51.966: INFO: Got endpoints: latency-svc-tsbf9 [534.87606ms]
Dec  3 15:28:51.976: INFO: Created: latency-svc-mvkwn
Dec  3 15:28:51.978: INFO: Got endpoints: latency-svc-nfkrc [513.384719ms]
Dec  3 15:28:51.986: INFO: Created: latency-svc-htbqr
Dec  3 15:28:52.016: INFO: Created: latency-svc-7ghbg
Dec  3 15:28:52.027: INFO: Created: latency-svc-tnfss
Dec  3 15:28:52.029: INFO: Got endpoints: latency-svc-8bkgh [554.453568ms]
Dec  3 15:28:52.041: INFO: Created: latency-svc-zkmtn
Dec  3 15:28:52.113: INFO: Got endpoints: latency-svc-cmxch [625.090098ms]
Dec  3 15:28:52.113: INFO: Created: latency-svc-b295t
Dec  3 15:28:52.124: INFO: Created: latency-svc-2tbjr
Dec  3 15:28:52.134: INFO: Created: latency-svc-vdf8s
Dec  3 15:28:52.134: INFO: Got endpoints: latency-svc-8rtvh [618.661468ms]
Dec  3 15:28:52.145: INFO: Created: latency-svc-lmf8z
Dec  3 15:28:52.173: INFO: Created: latency-svc-f64qj
Dec  3 15:28:52.177: INFO: Got endpoints: latency-svc-7nj4l [650.848071ms]
Dec  3 15:28:52.206: INFO: Created: latency-svc-tfttn
Dec  3 15:28:52.228: INFO: Got endpoints: latency-svc-d29tz [660.16131ms]
Dec  3 15:28:52.267: INFO: Created: latency-svc-8flvp
Dec  3 15:28:52.277: INFO: Got endpoints: latency-svc-r89pn [703.118697ms]
Dec  3 15:28:52.306: INFO: Created: latency-svc-lx6tg
Dec  3 15:28:52.327: INFO: Got endpoints: latency-svc-dwc8m [710.698217ms]
Dec  3 15:28:52.357: INFO: Created: latency-svc-qhp7c
Dec  3 15:28:52.377: INFO: Got endpoints: latency-svc-vthr5 [747.624773ms]
Dec  3 15:28:52.405: INFO: Created: latency-svc-cnsbb
Dec  3 15:28:52.427: INFO: Got endpoints: latency-svc-mvkwn [729.070406ms]
Dec  3 15:28:52.460: INFO: Created: latency-svc-9fm84
Dec  3 15:28:52.477: INFO: Got endpoints: latency-svc-htbqr [741.296165ms]
Dec  3 15:28:52.506: INFO: Created: latency-svc-xkffm
Dec  3 15:28:52.528: INFO: Got endpoints: latency-svc-7ghbg [743.656596ms]
Dec  3 15:28:52.575: INFO: Created: latency-svc-kjqkm
Dec  3 15:28:52.577: INFO: Got endpoints: latency-svc-tnfss [714.133267ms]
Dec  3 15:28:52.606: INFO: Created: latency-svc-44ncm
Dec  3 15:28:52.627: INFO: Got endpoints: latency-svc-zkmtn [743.806458ms]
Dec  3 15:28:52.655: INFO: Created: latency-svc-47knb
Dec  3 15:28:52.693: INFO: Got endpoints: latency-svc-b295t [726.451101ms]
Dec  3 15:28:52.721: INFO: Created: latency-svc-4r2j5
Dec  3 15:28:52.728: INFO: Got endpoints: latency-svc-2tbjr [749.200044ms]
Dec  3 15:28:52.755: INFO: Created: latency-svc-vdw2g
Dec  3 15:28:52.778: INFO: Got endpoints: latency-svc-vdf8s [748.014834ms]
Dec  3 15:28:52.815: INFO: Created: latency-svc-xjhb2
Dec  3 15:28:52.827: INFO: Got endpoints: latency-svc-lmf8z [714.776619ms]
Dec  3 15:28:52.855: INFO: Created: latency-svc-lpt77
Dec  3 15:28:52.877: INFO: Got endpoints: latency-svc-f64qj [742.919763ms]
Dec  3 15:28:52.905: INFO: Created: latency-svc-whh4f
Dec  3 15:28:52.928: INFO: Got endpoints: latency-svc-tfttn [750.118756ms]
Dec  3 15:28:52.954: INFO: Created: latency-svc-xgtjn
Dec  3 15:28:52.977: INFO: Got endpoints: latency-svc-8flvp [748.778398ms]
Dec  3 15:28:53.005: INFO: Created: latency-svc-qxn4v
Dec  3 15:28:53.036: INFO: Got endpoints: latency-svc-lx6tg [757.935814ms]
Dec  3 15:28:53.064: INFO: Created: latency-svc-jh5mq
Dec  3 15:28:53.077: INFO: Got endpoints: latency-svc-qhp7c [749.778172ms]
Dec  3 15:28:53.105: INFO: Created: latency-svc-5vktr
Dec  3 15:28:53.127: INFO: Got endpoints: latency-svc-cnsbb [749.821174ms]
Dec  3 15:28:53.163: INFO: Created: latency-svc-v98qr
Dec  3 15:28:53.179: INFO: Got endpoints: latency-svc-9fm84 [751.047716ms]
Dec  3 15:28:53.206: INFO: Created: latency-svc-zl7sx
Dec  3 15:28:53.227: INFO: Got endpoints: latency-svc-xkffm [750.204496ms]
Dec  3 15:28:53.263: INFO: Created: latency-svc-qfsgh
Dec  3 15:28:53.277: INFO: Got endpoints: latency-svc-kjqkm [749.766752ms]
Dec  3 15:28:53.306: INFO: Created: latency-svc-8x959
Dec  3 15:28:53.328: INFO: Got endpoints: latency-svc-44ncm [750.657661ms]
Dec  3 15:28:53.356: INFO: Created: latency-svc-zcr74
Dec  3 15:28:53.380: INFO: Got endpoints: latency-svc-47knb [752.089734ms]
Dec  3 15:28:53.411: INFO: Created: latency-svc-8hxc5
Dec  3 15:28:53.427: INFO: Got endpoints: latency-svc-4r2j5 [734.106565ms]
Dec  3 15:28:53.455: INFO: Created: latency-svc-htjwj
Dec  3 15:28:53.477: INFO: Got endpoints: latency-svc-vdw2g [749.432179ms]
Dec  3 15:28:53.504: INFO: Created: latency-svc-6b9kc
Dec  3 15:28:53.528: INFO: Got endpoints: latency-svc-xjhb2 [749.906103ms]
Dec  3 15:28:53.555: INFO: Created: latency-svc-ht9ts
Dec  3 15:28:53.577: INFO: Got endpoints: latency-svc-lpt77 [749.828543ms]
Dec  3 15:28:53.621: INFO: Created: latency-svc-mz8mp
Dec  3 15:28:53.628: INFO: Got endpoints: latency-svc-whh4f [750.865933ms]
Dec  3 15:28:53.655: INFO: Created: latency-svc-5dvg2
Dec  3 15:28:53.677: INFO: Got endpoints: latency-svc-xgtjn [749.725287ms]
Dec  3 15:28:53.705: INFO: Created: latency-svc-dtxwt
Dec  3 15:28:53.729: INFO: Got endpoints: latency-svc-qxn4v [751.55416ms]
Dec  3 15:28:53.757: INFO: Created: latency-svc-48f7m
Dec  3 15:28:53.777: INFO: Got endpoints: latency-svc-jh5mq [741.417628ms]
Dec  3 15:28:53.805: INFO: Created: latency-svc-7629x
Dec  3 15:28:53.827: INFO: Got endpoints: latency-svc-5vktr [750.27082ms]
Dec  3 15:28:53.856: INFO: Created: latency-svc-blnv4
Dec  3 15:28:53.877: INFO: Got endpoints: latency-svc-v98qr [749.979529ms]
Dec  3 15:28:53.905: INFO: Created: latency-svc-lclx9
Dec  3 15:28:53.927: INFO: Got endpoints: latency-svc-zl7sx [748.725135ms]
Dec  3 15:28:53.961: INFO: Created: latency-svc-cwrbd
Dec  3 15:28:53.977: INFO: Got endpoints: latency-svc-qfsgh [749.804852ms]
Dec  3 15:28:54.005: INFO: Created: latency-svc-bkg6p
Dec  3 15:28:54.027: INFO: Got endpoints: latency-svc-8x959 [749.848115ms]
Dec  3 15:28:54.056: INFO: Created: latency-svc-z66tl
Dec  3 15:28:54.080: INFO: Got endpoints: latency-svc-zcr74 [752.276922ms]
Dec  3 15:28:54.107: INFO: Created: latency-svc-f8tft
Dec  3 15:28:54.127: INFO: Got endpoints: latency-svc-8hxc5 [746.866886ms]
Dec  3 15:28:54.154: INFO: Created: latency-svc-z9hn5
Dec  3 15:28:54.177: INFO: Got endpoints: latency-svc-htjwj [749.954609ms]
Dec  3 15:28:54.216: INFO: Created: latency-svc-gzx4h
Dec  3 15:28:54.227: INFO: Got endpoints: latency-svc-6b9kc [750.088534ms]
Dec  3 15:28:54.258: INFO: Created: latency-svc-mm6lq
Dec  3 15:28:54.277: INFO: Got endpoints: latency-svc-ht9ts [749.617156ms]
Dec  3 15:28:54.313: INFO: Created: latency-svc-r26lq
Dec  3 15:28:54.327: INFO: Got endpoints: latency-svc-mz8mp [749.8649ms]
Dec  3 15:28:54.355: INFO: Created: latency-svc-xx9lr
Dec  3 15:28:54.377: INFO: Got endpoints: latency-svc-5dvg2 [748.434184ms]
Dec  3 15:28:54.404: INFO: Created: latency-svc-vb2jx
Dec  3 15:28:54.428: INFO: Got endpoints: latency-svc-dtxwt [750.046264ms]
Dec  3 15:28:54.456: INFO: Created: latency-svc-p7tsn
Dec  3 15:28:54.478: INFO: Got endpoints: latency-svc-48f7m [749.314329ms]
Dec  3 15:28:54.507: INFO: Created: latency-svc-pj5mq
Dec  3 15:28:54.538: INFO: Got endpoints: latency-svc-7629x [761.197762ms]
Dec  3 15:28:54.566: INFO: Created: latency-svc-vcmhz
Dec  3 15:28:54.577: INFO: Got endpoints: latency-svc-blnv4 [749.854205ms]
Dec  3 15:28:54.606: INFO: Created: latency-svc-zsfcl
Dec  3 15:28:54.628: INFO: Got endpoints: latency-svc-lclx9 [750.146802ms]
Dec  3 15:28:54.666: INFO: Created: latency-svc-86f6d
Dec  3 15:28:54.677: INFO: Got endpoints: latency-svc-cwrbd [749.82176ms]
Dec  3 15:28:54.706: INFO: Created: latency-svc-bkxvt
Dec  3 15:28:54.727: INFO: Got endpoints: latency-svc-bkg6p [750.04218ms]
Dec  3 15:28:54.755: INFO: Created: latency-svc-rr7nq
Dec  3 15:28:54.777: INFO: Got endpoints: latency-svc-z66tl [750.048391ms]
Dec  3 15:28:54.810: INFO: Created: latency-svc-6nqrh
Dec  3 15:28:54.827: INFO: Got endpoints: latency-svc-f8tft [747.072102ms]
Dec  3 15:28:54.858: INFO: Created: latency-svc-ptctf
Dec  3 15:28:54.888: INFO: Got endpoints: latency-svc-z9hn5 [761.825476ms]
Dec  3 15:28:54.917: INFO: Created: latency-svc-jbqbs
Dec  3 15:28:54.927: INFO: Got endpoints: latency-svc-gzx4h [749.753227ms]
Dec  3 15:28:54.955: INFO: Created: latency-svc-cm4sw
Dec  3 15:28:54.977: INFO: Got endpoints: latency-svc-mm6lq [749.937815ms]
Dec  3 15:28:55.022: INFO: Created: latency-svc-fb9p5
Dec  3 15:28:55.030: INFO: Got endpoints: latency-svc-r26lq [752.828322ms]
Dec  3 15:28:55.062: INFO: Created: latency-svc-nkndg
Dec  3 15:28:55.077: INFO: Got endpoints: latency-svc-xx9lr [749.682196ms]
Dec  3 15:28:55.105: INFO: Created: latency-svc-49jlh
Dec  3 15:28:55.128: INFO: Got endpoints: latency-svc-vb2jx [750.960868ms]
Dec  3 15:28:55.157: INFO: Created: latency-svc-g429w
Dec  3 15:28:55.177: INFO: Got endpoints: latency-svc-p7tsn [749.785065ms]
Dec  3 15:28:55.206: INFO: Created: latency-svc-wkrs6
Dec  3 15:28:55.227: INFO: Got endpoints: latency-svc-pj5mq [748.732235ms]
Dec  3 15:28:55.255: INFO: Created: latency-svc-qvvz9
Dec  3 15:28:55.277: INFO: Got endpoints: latency-svc-vcmhz [738.70436ms]
Dec  3 15:28:55.306: INFO: Created: latency-svc-6v24b
Dec  3 15:28:55.327: INFO: Got endpoints: latency-svc-zsfcl [749.650617ms]
Dec  3 15:28:55.367: INFO: Created: latency-svc-bwsh6
Dec  3 15:28:55.377: INFO: Got endpoints: latency-svc-86f6d [749.510936ms]
Dec  3 15:28:55.406: INFO: Created: latency-svc-l5k8p
Dec  3 15:28:55.427: INFO: Got endpoints: latency-svc-bkxvt [749.95205ms]
Dec  3 15:28:55.471: INFO: Created: latency-svc-ht4zf
Dec  3 15:28:55.477: INFO: Got endpoints: latency-svc-rr7nq [749.617544ms]
Dec  3 15:28:55.505: INFO: Created: latency-svc-77h45
Dec  3 15:28:55.527: INFO: Got endpoints: latency-svc-6nqrh [749.943101ms]
Dec  3 15:28:55.558: INFO: Created: latency-svc-fb5s4
Dec  3 15:28:55.588: INFO: Got endpoints: latency-svc-ptctf [760.642647ms]
Dec  3 15:28:55.619: INFO: Created: latency-svc-kgnkk
Dec  3 15:28:55.628: INFO: Got endpoints: latency-svc-jbqbs [739.938182ms]
Dec  3 15:28:55.660: INFO: Created: latency-svc-mq7cj
Dec  3 15:28:55.677: INFO: Got endpoints: latency-svc-cm4sw [750.211565ms]
Dec  3 15:28:55.718: INFO: Created: latency-svc-rqqzs
Dec  3 15:28:55.727: INFO: Got endpoints: latency-svc-fb9p5 [749.656507ms]
Dec  3 15:28:55.756: INFO: Created: latency-svc-wkp5d
Dec  3 15:28:55.777: INFO: Got endpoints: latency-svc-nkndg [746.959429ms]
Dec  3 15:28:55.827: INFO: Created: latency-svc-qnlhd
Dec  3 15:28:55.827: INFO: Got endpoints: latency-svc-49jlh [749.997409ms]
Dec  3 15:28:55.855: INFO: Created: latency-svc-z5twn
Dec  3 15:28:55.877: INFO: Got endpoints: latency-svc-g429w [749.241948ms]
Dec  3 15:28:55.905: INFO: Created: latency-svc-ckw54
Dec  3 15:28:55.927: INFO: Got endpoints: latency-svc-wkrs6 [748.997981ms]
Dec  3 15:28:55.954: INFO: Created: latency-svc-pbdbw
Dec  3 15:28:55.979: INFO: Got endpoints: latency-svc-qvvz9 [751.49359ms]
Dec  3 15:28:56.007: INFO: Created: latency-svc-zgwhh
Dec  3 15:28:56.027: INFO: Got endpoints: latency-svc-6v24b [750.12472ms]
Dec  3 15:28:56.085: INFO: Got endpoints: latency-svc-bwsh6 [757.368873ms]
Dec  3 15:28:56.095: INFO: Created: latency-svc-sjzsz
Dec  3 15:28:56.112: INFO: Created: latency-svc-snj7m
Dec  3 15:28:56.127: INFO: Got endpoints: latency-svc-l5k8p [749.755993ms]
Dec  3 15:28:56.156: INFO: Created: latency-svc-k62cm
Dec  3 15:28:56.177: INFO: Got endpoints: latency-svc-ht4zf [749.923665ms]
Dec  3 15:28:56.211: INFO: Created: latency-svc-k5fxq
Dec  3 15:28:56.228: INFO: Got endpoints: latency-svc-77h45 [750.369653ms]
Dec  3 15:28:56.255: INFO: Created: latency-svc-fd4h6
Dec  3 15:28:56.278: INFO: Got endpoints: latency-svc-fb5s4 [750.053595ms]
Dec  3 15:28:56.321: INFO: Created: latency-svc-rqx4r
Dec  3 15:28:56.327: INFO: Got endpoints: latency-svc-kgnkk [738.983184ms]
Dec  3 15:28:56.354: INFO: Created: latency-svc-gtnjj
Dec  3 15:28:56.377: INFO: Got endpoints: latency-svc-mq7cj [748.596975ms]
Dec  3 15:28:56.408: INFO: Created: latency-svc-thprh
Dec  3 15:28:56.436: INFO: Got endpoints: latency-svc-rqqzs [758.277251ms]
Dec  3 15:28:56.464: INFO: Created: latency-svc-klwn9
Dec  3 15:28:56.477: INFO: Got endpoints: latency-svc-wkp5d [750.006099ms]
Dec  3 15:28:56.506: INFO: Created: latency-svc-w7xwb
Dec  3 15:28:56.527: INFO: Got endpoints: latency-svc-qnlhd [749.727438ms]
Dec  3 15:28:56.562: INFO: Created: latency-svc-vxpbg
Dec  3 15:28:56.577: INFO: Got endpoints: latency-svc-z5twn [749.816037ms]
Dec  3 15:28:56.605: INFO: Created: latency-svc-dfpfx
Dec  3 15:28:56.628: INFO: Got endpoints: latency-svc-ckw54 [750.107438ms]
Dec  3 15:28:56.672: INFO: Created: latency-svc-tx4zs
Dec  3 15:28:56.678: INFO: Got endpoints: latency-svc-pbdbw [750.86633ms]
Dec  3 15:28:56.705: INFO: Created: latency-svc-qr8rx
Dec  3 15:28:56.727: INFO: Got endpoints: latency-svc-zgwhh [748.3819ms]
Dec  3 15:28:56.755: INFO: Created: latency-svc-hgmw7
Dec  3 15:28:56.788: INFO: Got endpoints: latency-svc-sjzsz [760.849993ms]
Dec  3 15:28:56.816: INFO: Created: latency-svc-svzpz
Dec  3 15:28:56.827: INFO: Got endpoints: latency-svc-snj7m [742.56174ms]
Dec  3 15:28:56.858: INFO: Created: latency-svc-hjk2p
Dec  3 15:28:56.877: INFO: Got endpoints: latency-svc-k62cm [749.810822ms]
Dec  3 15:28:56.917: INFO: Created: latency-svc-ltm2c
Dec  3 15:28:56.928: INFO: Got endpoints: latency-svc-k5fxq [750.162534ms]
Dec  3 15:28:56.956: INFO: Created: latency-svc-k9f6g
Dec  3 15:28:56.977: INFO: Got endpoints: latency-svc-fd4h6 [749.078429ms]
Dec  3 15:28:57.004: INFO: Created: latency-svc-pkssz
Dec  3 15:28:57.027: INFO: Got endpoints: latency-svc-rqx4r [749.089388ms]
Dec  3 15:28:57.054: INFO: Created: latency-svc-gsb4d
Dec  3 15:28:57.077: INFO: Got endpoints: latency-svc-gtnjj [749.79448ms]
Dec  3 15:28:57.105: INFO: Created: latency-svc-hw9vf
Dec  3 15:28:57.134: INFO: Got endpoints: latency-svc-thprh [757.070562ms]
Dec  3 15:28:57.161: INFO: Created: latency-svc-zssgr
Dec  3 15:28:57.177: INFO: Got endpoints: latency-svc-klwn9 [741.696438ms]
Dec  3 15:28:57.205: INFO: Created: latency-svc-2xrwh
Dec  3 15:28:57.227: INFO: Got endpoints: latency-svc-w7xwb [749.983241ms]
Dec  3 15:28:57.267: INFO: Created: latency-svc-6sbxv
Dec  3 15:28:57.277: INFO: Got endpoints: latency-svc-vxpbg [750.125825ms]
Dec  3 15:28:57.305: INFO: Created: latency-svc-cnwb8
Dec  3 15:28:57.327: INFO: Got endpoints: latency-svc-dfpfx [750.102422ms]
Dec  3 15:28:57.360: INFO: Created: latency-svc-5cvbb
Dec  3 15:28:57.377: INFO: Got endpoints: latency-svc-tx4zs [749.808165ms]
Dec  3 15:28:57.405: INFO: Created: latency-svc-7v5gw
Dec  3 15:28:57.427: INFO: Got endpoints: latency-svc-qr8rx [749.801361ms]
Dec  3 15:28:57.456: INFO: Created: latency-svc-9cf47
Dec  3 15:28:57.477: INFO: Got endpoints: latency-svc-hgmw7 [749.922613ms]
Dec  3 15:28:57.505: INFO: Created: latency-svc-g7g2g
Dec  3 15:28:57.527: INFO: Got endpoints: latency-svc-svzpz [738.694671ms]
Dec  3 15:28:57.555: INFO: Created: latency-svc-82zx4
Dec  3 15:28:57.619: INFO: Got endpoints: latency-svc-hjk2p [791.314063ms]
Dec  3 15:28:57.627: INFO: Got endpoints: latency-svc-ltm2c [750.10841ms]
Dec  3 15:28:57.646: INFO: Created: latency-svc-jp6df
Dec  3 15:28:57.657: INFO: Created: latency-svc-88d87
Dec  3 15:28:57.677: INFO: Got endpoints: latency-svc-k9f6g [749.635436ms]
Dec  3 15:28:57.705: INFO: Created: latency-svc-7zx84
Dec  3 15:28:57.731: INFO: Got endpoints: latency-svc-pkssz [754.47046ms]
Dec  3 15:28:57.760: INFO: Created: latency-svc-99nr6
Dec  3 15:28:57.777: INFO: Got endpoints: latency-svc-gsb4d [750.382517ms]
Dec  3 15:28:57.805: INFO: Created: latency-svc-h5wdb
Dec  3 15:28:57.830: INFO: Got endpoints: latency-svc-hw9vf [753.504781ms]
Dec  3 15:28:57.858: INFO: Created: latency-svc-mt95j
Dec  3 15:28:57.878: INFO: Got endpoints: latency-svc-zssgr [743.114494ms]
Dec  3 15:28:57.915: INFO: Created: latency-svc-tz2ft
Dec  3 15:28:57.927: INFO: Got endpoints: latency-svc-2xrwh [749.579227ms]
Dec  3 15:28:57.959: INFO: Created: latency-svc-ctftm
Dec  3 15:28:57.978: INFO: Got endpoints: latency-svc-6sbxv [750.344445ms]
Dec  3 15:28:58.024: INFO: Created: latency-svc-zvggg
Dec  3 15:28:58.031: INFO: Got endpoints: latency-svc-cnwb8 [753.991938ms]
Dec  3 15:28:58.071: INFO: Created: latency-svc-nwd5f
Dec  3 15:28:58.077: INFO: Got endpoints: latency-svc-5cvbb [749.681832ms]
Dec  3 15:28:58.105: INFO: Created: latency-svc-7phqx
Dec  3 15:28:58.128: INFO: Got endpoints: latency-svc-7v5gw [750.231591ms]
Dec  3 15:28:58.158: INFO: Created: latency-svc-spsms
Dec  3 15:28:58.186: INFO: Got endpoints: latency-svc-9cf47 [758.852983ms]
Dec  3 15:28:58.214: INFO: Created: latency-svc-v25r7
Dec  3 15:28:58.227: INFO: Got endpoints: latency-svc-g7g2g [749.324207ms]
Dec  3 15:28:58.279: INFO: Got endpoints: latency-svc-82zx4 [751.884653ms]
Dec  3 15:28:58.327: INFO: Got endpoints: latency-svc-jp6df [708.650663ms]
Dec  3 15:28:58.377: INFO: Got endpoints: latency-svc-88d87 [750.011699ms]
Dec  3 15:28:58.428: INFO: Got endpoints: latency-svc-7zx84 [750.089451ms]
Dec  3 15:28:58.478: INFO: Got endpoints: latency-svc-99nr6 [746.415569ms]
Dec  3 15:28:58.528: INFO: Got endpoints: latency-svc-h5wdb [750.141888ms]
Dec  3 15:28:58.582: INFO: Got endpoints: latency-svc-mt95j [751.023989ms]
Dec  3 15:28:58.639: INFO: Got endpoints: latency-svc-tz2ft [761.891839ms]
Dec  3 15:28:58.677: INFO: Got endpoints: latency-svc-ctftm [750.18544ms]
Dec  3 15:28:58.727: INFO: Got endpoints: latency-svc-zvggg [749.531204ms]
Dec  3 15:28:58.777: INFO: Got endpoints: latency-svc-nwd5f [745.924724ms]
Dec  3 15:28:58.827: INFO: Got endpoints: latency-svc-7phqx [750.248569ms]
Dec  3 15:28:58.877: INFO: Got endpoints: latency-svc-spsms [749.532662ms]
Dec  3 15:28:58.927: INFO: Got endpoints: latency-svc-v25r7 [741.013336ms]
Dec  3 15:28:58.928: INFO: Latencies: [37.474921ms 39.837981ms 59.282466ms 62.620268ms 104.513159ms 138.136765ms 160.678083ms 163.02203ms 189.216229ms 244.863365ms 267.079994ms 285.615986ms 293.706412ms 303.467349ms 305.46514ms 305.542059ms 316.382234ms 321.698851ms 321.84615ms 323.769471ms 323.89848ms 329.410276ms 329.432117ms 331.113019ms 338.665229ms 339.735027ms 340.124884ms 340.88766ms 344.097593ms 344.488089ms 345.074683ms 346.808016ms 347.446225ms 347.858769ms 348.467072ms 350.314789ms 352.148396ms 355.379012ms 357.892062ms 359.252668ms 360.462357ms 360.992819ms 367.443611ms 369.369598ms 369.959986ms 372.368524ms 373.532979ms 374.033714ms 374.812973ms 375.717098ms 375.965618ms 378.008839ms 386.504912ms 387.271399ms 389.602056ms 400.582005ms 446.225181ms 499.979983ms 505.166371ms 513.384719ms 534.87606ms 554.453568ms 618.661468ms 625.090098ms 650.848071ms 660.16131ms 703.118697ms 708.650663ms 710.698217ms 714.133267ms 714.776619ms 726.451101ms 729.070406ms 734.106565ms 738.694671ms 738.70436ms 738.983184ms 739.938182ms 741.013336ms 741.296165ms 741.417628ms 741.696438ms 742.56174ms 742.919763ms 743.114494ms 743.656596ms 743.806458ms 745.924724ms 746.415569ms 746.866886ms 746.959429ms 747.072102ms 747.624773ms 748.014834ms 748.3819ms 748.434184ms 748.596975ms 748.725135ms 748.732235ms 748.778398ms 748.997981ms 749.078429ms 749.089388ms 749.200044ms 749.241948ms 749.314329ms 749.324207ms 749.432179ms 749.510936ms 749.531204ms 749.532662ms 749.579227ms 749.617156ms 749.617544ms 749.635436ms 749.650617ms 749.656507ms 749.681832ms 749.682196ms 749.725287ms 749.727438ms 749.753227ms 749.755993ms 749.766752ms 749.778172ms 749.785065ms 749.79448ms 749.801361ms 749.804852ms 749.808165ms 749.810822ms 749.816037ms 749.821174ms 749.82176ms 749.828543ms 749.848115ms 749.854205ms 749.8649ms 749.906103ms 749.922613ms 749.923665ms 749.937815ms 749.943101ms 749.95205ms 749.954609ms 749.979529ms 749.983241ms 749.997409ms 750.006099ms 750.011699ms 750.04218ms 750.046264ms 750.048391ms 750.053595ms 750.088534ms 750.089451ms 750.102422ms 750.107438ms 750.10841ms 750.118756ms 750.12472ms 750.125825ms 750.141888ms 750.146802ms 750.162534ms 750.18544ms 750.204496ms 750.211565ms 750.231591ms 750.248569ms 750.27082ms 750.344445ms 750.369653ms 750.382517ms 750.657661ms 750.865933ms 750.86633ms 750.960868ms 751.023989ms 751.047716ms 751.49359ms 751.55416ms 751.884653ms 752.089734ms 752.276922ms 752.828322ms 753.504781ms 753.991938ms 754.47046ms 757.070562ms 757.368873ms 757.935814ms 758.277251ms 758.852983ms 760.642647ms 760.849993ms 761.197762ms 761.825476ms 761.891839ms 791.314063ms]
Dec  3 15:28:58.928: INFO: 50 %ile: 748.997981ms
Dec  3 15:28:58.928: INFO: 90 %ile: 751.49359ms
Dec  3 15:28:58.928: INFO: 99 %ile: 761.891839ms
Dec  3 15:28:58.928: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:28:58.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-6995" for this suite.
Dec  3 15:29:11.006: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:29:11.600: INFO: namespace svc-latency-6995 deletion completed in 12.654011195s
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:29:11.600: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4929
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec  3 15:29:11.822: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:29:16.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4929" for this suite.
Dec  3 15:29:22.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:29:22.896: INFO: namespace init-container-4929 deletion completed in 6.678253064s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:29:22.897: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-569
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Dec  3 15:29:23.232: INFO: Waiting up to 5m0s for pod "var-expansion-e27eca52-8f09-4282-aaa6-5abb059e67d1" in namespace "var-expansion-569" to be "success or failure"
Dec  3 15:29:23.249: INFO: Pod "var-expansion-e27eca52-8f09-4282-aaa6-5abb059e67d1": Phase="Pending", Reason="", readiness=false. Elapsed: 16.844586ms
Dec  3 15:29:25.267: INFO: Pod "var-expansion-e27eca52-8f09-4282-aaa6-5abb059e67d1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034858641s
Dec  3 15:29:27.285: INFO: Pod "var-expansion-e27eca52-8f09-4282-aaa6-5abb059e67d1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05266918s
STEP: Saw pod success
Dec  3 15:29:27.285: INFO: Pod "var-expansion-e27eca52-8f09-4282-aaa6-5abb059e67d1" satisfied condition "success or failure"
Dec  3 15:29:27.302: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod var-expansion-e27eca52-8f09-4282-aaa6-5abb059e67d1 container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:29:27.355: INFO: Waiting for pod var-expansion-e27eca52-8f09-4282-aaa6-5abb059e67d1 to disappear
Dec  3 15:29:27.372: INFO: Pod var-expansion-e27eca52-8f09-4282-aaa6-5abb059e67d1 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:29:27.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-569" for this suite.
Dec  3 15:29:33.456: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:29:34.057: INFO: namespace var-expansion-569 deletion completed in 6.652543824s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:29:34.057: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6890
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-5bd276e4-c28f-4509-9d11-b123beaa20ec
Dec  3 15:29:34.326: INFO: Pod name my-hostname-basic-5bd276e4-c28f-4509-9d11-b123beaa20ec: Found 1 pods out of 1
Dec  3 15:29:34.326: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-5bd276e4-c28f-4509-9d11-b123beaa20ec" are running
Dec  3 15:29:38.360: INFO: Pod "my-hostname-basic-5bd276e4-c28f-4509-9d11-b123beaa20ec-gsptv" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 15:29:34 +0000 UTC Reason: Message:}])
Dec  3 15:29:38.360: INFO: Trying to dial the pod
Dec  3 15:29:43.502: INFO: Controller my-hostname-basic-5bd276e4-c28f-4509-9d11-b123beaa20ec: Got expected result from replica 1 [my-hostname-basic-5bd276e4-c28f-4509-9d11-b123beaa20ec-gsptv]: "my-hostname-basic-5bd276e4-c28f-4509-9d11-b123beaa20ec-gsptv", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:29:43.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6890" for this suite.
Dec  3 15:29:49.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:29:50.246: INFO: namespace replication-controller-6890 deletion completed in 6.710219466s
•SSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:29:50.246: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-319
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:30:07.634: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-319" for this suite.
Dec  3 15:30:13.720: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:30:14.332: INFO: namespace resourcequota-319 deletion completed in 6.665554759s
•SSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:30:14.333: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1574
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-2d2cdad1-a80a-435c-b022-63b6bf7f77ad
STEP: Creating configMap with name cm-test-opt-upd-166bfb00-1c05-4981-b72f-dee7a4644e62
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-2d2cdad1-a80a-435c-b022-63b6bf7f77ad
STEP: Updating configmap cm-test-opt-upd-166bfb00-1c05-4981-b72f-dee7a4644e62
STEP: Creating configMap with name cm-test-opt-create-5f8ae7bf-2763-4916-9ecd-1c7657751e64
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:31:38.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1574" for this suite.
Dec  3 15:31:50.295: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:31:50.902: INFO: namespace configmap-1574 deletion completed in 12.664118336s
•SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:31:50.902: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5725
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Dec  3 15:31:51.129: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy --unix-socket=/tmp/kubectl-proxy-unix150051475/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:31:51.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5725" for this suite.
Dec  3 15:31:57.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:31:57.858: INFO: namespace kubectl-5725 deletion completed in 6.643532178s
•SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:31:57.858: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9347
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec  3 15:31:58.074: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 15:31:58.126: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 15:31:58.144: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk before test
Dec  3 15:31:58.175: INFO: node-exporter-99hck from kube-system started at 2019-12-03 14:41:41 +0000 UTC (1 container statuses recorded)
Dec  3 15:31:58.175: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:31:58.175: INFO: calico-node-v7kgq from kube-system started at 2019-12-03 14:41:41 +0000 UTC (1 container statuses recorded)
Dec  3 15:31:58.175: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:31:58.175: INFO: kube-proxy-9gxg8 from kube-system started at 2019-12-03 14:41:41 +0000 UTC (1 container statuses recorded)
Dec  3 15:31:58.175: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:31:58.175: INFO: node-problem-detector-sjm82 from kube-system started at 2019-12-03 14:41:41 +0000 UTC (1 container statuses recorded)
Dec  3 15:31:58.175: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:31:58.175: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v before test
Dec  3 15:31:58.246: INFO: node-exporter-f5c97 from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 15:31:58.246: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:31:58.246: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-95f65778d-gxfs2 from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 15:31:58.246: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec  3 15:31:58.246: INFO: calico-kube-controllers-79bcd784b6-kz756 from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 15:31:58.246: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  3 15:31:58.246: INFO: addons-nginx-ingress-controller-7c75bb76db-42ck9 from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 15:31:58.246: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec  3 15:31:58.246: INFO: calico-typha-horizontal-autoscaler-69df649c59-c4drn from kube-system started at 2019-12-03 14:39:52 +0000 UTC (1 container statuses recorded)
Dec  3 15:31:58.246: INFO: 	Container autoscaler ready: true, restart count 0
Dec  3 15:31:58.246: INFO: calico-typha-vertical-autoscaler-847d859f8c-vcs4n from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 15:31:58.246: INFO: 	Container autoscaler ready: true, restart count 4
Dec  3 15:31:58.246: INFO: metrics-server-898dc9876-hqcdm from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 15:31:58.246: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 15:31:58.246: INFO: coredns-59c969ffb8-jg798 from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 15:31:58.246: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:31:58.246: INFO: calico-node-db7rh from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 15:31:58.246: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:31:58.246: INFO: blackbox-exporter-7bd7b55dfc-s569k from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 15:31:58.246: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec  3 15:31:58.246: INFO: kube-proxy-mjx4w from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 15:31:58.246: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:31:58.246: INFO: node-problem-detector-l8d9w from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 15:31:58.246: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:31:58.246: INFO: coredns-59c969ffb8-ldh2q from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 15:31:58.246: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:31:58.246: INFO: calico-typha-deploy-9f6b455c4-6sv6p from kube-system started at 2019-12-03 15:04:38 +0000 UTC (1 container statuses recorded)
Dec  3 15:31:58.246: INFO: 	Container calico-typha ready: true, restart count 0
Dec  3 15:31:58.246: INFO: vpn-shoot-67b54fb-qrrtn from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 15:31:58.246: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec  3 15:31:58.246: INFO: addons-kubernetes-dashboard-78954cc66b-tpjhb from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 15:31:58.246: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15dce63cc35b9a23], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:31:59.345: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9347" for this suite.
Dec  3 15:32:05.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:32:06.087: INFO: namespace sched-pred-9347 deletion completed in 6.709975236s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
•SSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:32:06.088: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2906
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-zzcx
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 15:32:06.382: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-zzcx" in namespace "subpath-2906" to be "success or failure"
Dec  3 15:32:06.400: INFO: Pod "pod-subpath-test-downwardapi-zzcx": Phase="Pending", Reason="", readiness=false. Elapsed: 16.992647ms
Dec  3 15:32:08.418: INFO: Pod "pod-subpath-test-downwardapi-zzcx": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034977644s
Dec  3 15:32:10.435: INFO: Pod "pod-subpath-test-downwardapi-zzcx": Phase="Running", Reason="", readiness=true. Elapsed: 4.052921056s
Dec  3 15:32:12.453: INFO: Pod "pod-subpath-test-downwardapi-zzcx": Phase="Running", Reason="", readiness=true. Elapsed: 6.070907743s
Dec  3 15:32:14.471: INFO: Pod "pod-subpath-test-downwardapi-zzcx": Phase="Running", Reason="", readiness=true. Elapsed: 8.088913101s
Dec  3 15:32:16.489: INFO: Pod "pod-subpath-test-downwardapi-zzcx": Phase="Running", Reason="", readiness=true. Elapsed: 10.10668405s
Dec  3 15:32:18.507: INFO: Pod "pod-subpath-test-downwardapi-zzcx": Phase="Running", Reason="", readiness=true. Elapsed: 12.124831752s
Dec  3 15:32:20.525: INFO: Pod "pod-subpath-test-downwardapi-zzcx": Phase="Running", Reason="", readiness=true. Elapsed: 14.142601324s
Dec  3 15:32:22.543: INFO: Pod "pod-subpath-test-downwardapi-zzcx": Phase="Running", Reason="", readiness=true. Elapsed: 16.160247482s
Dec  3 15:32:24.561: INFO: Pod "pod-subpath-test-downwardapi-zzcx": Phase="Running", Reason="", readiness=true. Elapsed: 18.17828223s
Dec  3 15:32:26.579: INFO: Pod "pod-subpath-test-downwardapi-zzcx": Phase="Running", Reason="", readiness=true. Elapsed: 20.196106187s
Dec  3 15:32:28.597: INFO: Pod "pod-subpath-test-downwardapi-zzcx": Phase="Running", Reason="", readiness=true. Elapsed: 22.214312829s
Dec  3 15:32:30.615: INFO: Pod "pod-subpath-test-downwardapi-zzcx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.23267861s
STEP: Saw pod success
Dec  3 15:32:30.615: INFO: Pod "pod-subpath-test-downwardapi-zzcx" satisfied condition "success or failure"
Dec  3 15:32:30.633: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-subpath-test-downwardapi-zzcx container test-container-subpath-downwardapi-zzcx: <nil>
STEP: delete the pod
Dec  3 15:32:30.686: INFO: Waiting for pod pod-subpath-test-downwardapi-zzcx to disappear
Dec  3 15:32:30.703: INFO: Pod pod-subpath-test-downwardapi-zzcx no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-zzcx
Dec  3 15:32:30.703: INFO: Deleting pod "pod-subpath-test-downwardapi-zzcx" in namespace "subpath-2906"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:32:30.720: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2906" for this suite.
Dec  3 15:32:36.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:32:37.419: INFO: namespace subpath-2906 deletion completed in 6.666213875s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:32:37.420: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-2933
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec  3 15:32:47.788: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2933 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:32:47.788: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:32:48.291: INFO: Exec stderr: ""
Dec  3 15:32:48.291: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2933 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:32:48.291: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:32:48.778: INFO: Exec stderr: ""
Dec  3 15:32:48.778: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2933 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:32:48.778: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:32:49.302: INFO: Exec stderr: ""
Dec  3 15:32:49.302: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2933 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:32:49.303: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:32:49.835: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec  3 15:32:49.835: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2933 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:32:49.835: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:32:50.358: INFO: Exec stderr: ""
Dec  3 15:32:50.358: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2933 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:32:50.358: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:32:50.839: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec  3 15:32:50.839: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2933 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:32:50.839: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:32:51.340: INFO: Exec stderr: ""
Dec  3 15:32:51.340: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2933 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:32:51.340: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:32:51.902: INFO: Exec stderr: ""
Dec  3 15:32:51.902: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-2933 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:32:51.902: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:32:52.427: INFO: Exec stderr: ""
Dec  3 15:32:52.427: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-2933 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:32:52.427: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:32:52.940: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:32:52.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-2933" for this suite.
Dec  3 15:33:43.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:33:43.624: INFO: namespace e2e-kubelet-etc-hosts-2933 deletion completed in 50.651388614s
•SS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:33:43.624: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3002
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:33:43.884: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3002" for this suite.
Dec  3 15:33:55.958: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:33:56.561: INFO: namespace pods-3002 deletion completed in 12.656111662s
•SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:33:56.561: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9894
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:33:57.342: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec  3 15:33:59.393: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984037, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984037, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984037, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984037, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:34:02.451: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:34:02.469: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4767-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:34:03.513: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9894" for this suite.
Dec  3 15:34:09.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:34:10.204: INFO: namespace webhook-9894 deletion completed in 6.658188351s
STEP: Destroying namespace "webhook-9894-markers" for this suite.
Dec  3 15:34:16.262: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:34:16.870: INFO: namespace webhook-9894-markers deletion completed in 6.666075337s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:34:16.940: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-809
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-2479
STEP: Creating secret with name secret-test-13c55a10-9095-47be-aadf-e3b5c47b848f
STEP: Creating a pod to test consume secrets
Dec  3 15:34:17.415: INFO: Waiting up to 5m0s for pod "pod-secrets-53ceabaa-6962-4641-a039-7a0a10b07ad8" in namespace "secrets-809" to be "success or failure"
Dec  3 15:34:17.432: INFO: Pod "pod-secrets-53ceabaa-6962-4641-a039-7a0a10b07ad8": Phase="Pending", Reason="", readiness=false. Elapsed: 17.161563ms
Dec  3 15:34:19.450: INFO: Pod "pod-secrets-53ceabaa-6962-4641-a039-7a0a10b07ad8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035258885s
Dec  3 15:34:21.468: INFO: Pod "pod-secrets-53ceabaa-6962-4641-a039-7a0a10b07ad8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053335041s
STEP: Saw pod success
Dec  3 15:34:21.468: INFO: Pod "pod-secrets-53ceabaa-6962-4641-a039-7a0a10b07ad8" satisfied condition "success or failure"
Dec  3 15:34:21.492: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-secrets-53ceabaa-6962-4641-a039-7a0a10b07ad8 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:34:21.685: INFO: Waiting for pod pod-secrets-53ceabaa-6962-4641-a039-7a0a10b07ad8 to disappear
Dec  3 15:34:21.702: INFO: Pod pod-secrets-53ceabaa-6962-4641-a039-7a0a10b07ad8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:34:21.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-809" for this suite.
Dec  3 15:34:27.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:34:28.396: INFO: namespace secrets-809 deletion completed in 6.660310602s
STEP: Destroying namespace "secret-namespace-2479" for this suite.
Dec  3 15:34:34.448: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:34:35.068: INFO: namespace secret-namespace-2479 deletion completed in 6.671690296s
•SSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:34:35.068: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3344
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:34:51.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3344" for this suite.
Dec  3 15:34:57.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:34:58.273: INFO: namespace resourcequota-3344 deletion completed in 6.66245699s
•
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:34:58.274: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8591
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  3 15:34:58.640: INFO: Number of nodes with available pods: 0
Dec  3 15:34:58.640: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 15:34:59.701: INFO: Number of nodes with available pods: 0
Dec  3 15:34:59.701: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 15:35:00.691: INFO: Number of nodes with available pods: 1
Dec  3 15:35:00.691: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 15:35:01.694: INFO: Number of nodes with available pods: 2
Dec  3 15:35:01.695: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec  3 15:35:01.784: INFO: Number of nodes with available pods: 1
Dec  3 15:35:01.784: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v is running more than one daemon pod
Dec  3 15:35:02.836: INFO: Number of nodes with available pods: 1
Dec  3 15:35:02.836: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v is running more than one daemon pod
Dec  3 15:35:03.835: INFO: Number of nodes with available pods: 1
Dec  3 15:35:03.835: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v is running more than one daemon pod
Dec  3 15:35:04.855: INFO: Number of nodes with available pods: 1
Dec  3 15:35:04.855: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v is running more than one daemon pod
Dec  3 15:35:05.835: INFO: Number of nodes with available pods: 1
Dec  3 15:35:05.835: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v is running more than one daemon pod
Dec  3 15:35:06.835: INFO: Number of nodes with available pods: 2
Dec  3 15:35:06.835: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8591, will wait for the garbage collector to delete the pods
Dec  3 15:35:06.939: INFO: Deleting DaemonSet.extensions daemon-set took: 19.252178ms
Dec  3 15:35:07.339: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.391736ms
Dec  3 15:35:16.057: INFO: Number of nodes with available pods: 0
Dec  3 15:35:16.057: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 15:35:16.074: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8591/daemonsets","resourceVersion":"13589"},"items":null}

Dec  3 15:35:16.094: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8591/pods","resourceVersion":"13590"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:35:16.162: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8591" for this suite.
Dec  3 15:35:22.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:35:22.833: INFO: namespace daemonsets-8591 deletion completed in 6.653738801s
•SS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:35:22.833: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5464
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-5464
STEP: creating replication controller nodeport-test in namespace services-5464
I1203 15:35:23.122899    5095 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-5464, replica count: 2
Dec  3 15:35:26.173: INFO: Creating new exec pod
I1203 15:35:26.173475    5095 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 15:35:31.261: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-5464 execpodc7vvv -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Dec  3 15:35:31.928: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec  3 15:35:31.928: INFO: stdout: ""
Dec  3 15:35:31.929: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-5464 execpodc7vvv -- /bin/sh -x -c nc -zv -t -w 2 100.106.104.225 80'
Dec  3 15:35:32.556: INFO: stderr: "+ nc -zv -t -w 2 100.106.104.225 80\nConnection to 100.106.104.225 80 port [tcp/http] succeeded!\n"
Dec  3 15:35:32.556: INFO: stdout: ""
Dec  3 15:35:32.556: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-5464 execpodc7vvv -- /bin/sh -x -c nc -zv -t -w 2 10.250.0.4 30935'
Dec  3 15:35:33.187: INFO: stderr: "+ nc -zv -t -w 2 10.250.0.4 30935\nConnection to 10.250.0.4 30935 port [tcp/30935] succeeded!\n"
Dec  3 15:35:33.187: INFO: stdout: ""
Dec  3 15:35:33.187: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-5464 execpodc7vvv -- /bin/sh -x -c nc -zv -t -w 2 10.250.0.5 30935'
Dec  3 15:35:33.886: INFO: stderr: "+ nc -zv -t -w 2 10.250.0.5 30935\nConnection to 10.250.0.5 30935 port [tcp/30935] succeeded!\n"
Dec  3 15:35:33.886: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:35:33.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5464" for this suite.
Dec  3 15:35:39.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:35:40.578: INFO: namespace services-5464 deletion completed in 6.659430248s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:35:40.578: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6032
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-6032
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 15:35:40.795: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 15:36:07.111: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.1.125:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6032 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:36:07.111: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:36:07.635: INFO: Found all expected endpoints: [netserver-0]
Dec  3 15:36:07.653: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.0.30:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-6032 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:36:07.653: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:36:08.151: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:36:08.151: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6032" for this suite.
Dec  3 15:36:20.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:36:20.834: INFO: namespace pod-network-test-6032 deletion completed in 12.650551155s
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:36:20.835: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6639
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:36:21.691: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984181, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984181, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984181, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984181, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:36:23.709: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984181, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984181, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984181, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984181, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:36:26.737: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:36:26.755: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:36:27.987: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6639" for this suite.
Dec  3 15:36:34.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:36:34.683: INFO: namespace webhook-6639 deletion completed in 6.663140099s
STEP: Destroying namespace "webhook-6639-markers" for this suite.
Dec  3 15:36:40.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:36:41.337: INFO: namespace webhook-6639-markers deletion completed in 6.654166388s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:36:41.407: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-2658
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Dec  3 15:36:46.235: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-2658 pod-service-account-34bd6ee8-bcb7-462b-b597-b1be5d1d3bf5 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Dec  3 15:36:47.146: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-2658 pod-service-account-34bd6ee8-bcb7-462b-b597-b1be5d1d3bf5 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Dec  3 15:36:47.768: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-2658 pod-service-account-34bd6ee8-bcb7-462b-b597-b1be5d1d3bf5 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:36:48.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-2658" for this suite.
Dec  3 15:36:54.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:36:55.117: INFO: namespace svcaccounts-2658 deletion completed in 6.670592544s
•SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:36:55.118: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4817
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec  3 15:36:55.490: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4817 /api/v1/namespaces/watch-4817/configmaps/e2e-watch-test-resource-version 2da7e52e-ab38-4e05-b270-190424189c19 14018 0 2019-12-03 15:36:55 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 15:36:55.490: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-4817 /api/v1/namespaces/watch-4817/configmaps/e2e-watch-test-resource-version 2da7e52e-ab38-4e05-b270-190424189c19 14019 0 2019-12-03 15:36:55 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:36:55.490: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4817" for this suite.
Dec  3 15:37:01.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:37:02.181: INFO: namespace watch-4817 deletion completed in 6.671085891s
•SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:37:02.181: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1774
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec  3 15:37:02.462: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1774 /api/v1/namespaces/watch-1774/configmaps/e2e-watch-test-configmap-a ff269337-a620-4d43-96c2-57161258e6cd 14049 0 2019-12-03 15:37:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:37:02.463: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1774 /api/v1/namespaces/watch-1774/configmaps/e2e-watch-test-configmap-a ff269337-a620-4d43-96c2-57161258e6cd 14049 0 2019-12-03 15:37:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec  3 15:37:12.499: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1774 /api/v1/namespaces/watch-1774/configmaps/e2e-watch-test-configmap-a ff269337-a620-4d43-96c2-57161258e6cd 14073 0 2019-12-03 15:37:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  3 15:37:12.499: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1774 /api/v1/namespaces/watch-1774/configmaps/e2e-watch-test-configmap-a ff269337-a620-4d43-96c2-57161258e6cd 14073 0 2019-12-03 15:37:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec  3 15:37:22.535: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1774 /api/v1/namespaces/watch-1774/configmaps/e2e-watch-test-configmap-a ff269337-a620-4d43-96c2-57161258e6cd 14098 0 2019-12-03 15:37:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 15:37:22.536: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1774 /api/v1/namespaces/watch-1774/configmaps/e2e-watch-test-configmap-a ff269337-a620-4d43-96c2-57161258e6cd 14098 0 2019-12-03 15:37:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec  3 15:37:32.557: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1774 /api/v1/namespaces/watch-1774/configmaps/e2e-watch-test-configmap-a ff269337-a620-4d43-96c2-57161258e6cd 14123 0 2019-12-03 15:37:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 15:37:32.557: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-1774 /api/v1/namespaces/watch-1774/configmaps/e2e-watch-test-configmap-a ff269337-a620-4d43-96c2-57161258e6cd 14123 0 2019-12-03 15:37:02 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec  3 15:37:42.577: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1774 /api/v1/namespaces/watch-1774/configmaps/e2e-watch-test-configmap-b 2c65ea45-1405-42b4-842f-d759e3bd6460 14147 0 2019-12-03 15:37:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:37:42.577: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1774 /api/v1/namespaces/watch-1774/configmaps/e2e-watch-test-configmap-b 2c65ea45-1405-42b4-842f-d759e3bd6460 14147 0 2019-12-03 15:37:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec  3 15:37:52.598: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1774 /api/v1/namespaces/watch-1774/configmaps/e2e-watch-test-configmap-b 2c65ea45-1405-42b4-842f-d759e3bd6460 14172 0 2019-12-03 15:37:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:37:52.598: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-1774 /api/v1/namespaces/watch-1774/configmaps/e2e-watch-test-configmap-b 2c65ea45-1405-42b4-842f-d759e3bd6460 14172 0 2019-12-03 15:37:42 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:38:02.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1774" for this suite.
Dec  3 15:38:08.686: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:38:09.289: INFO: namespace watch-1774 deletion completed in 6.656178653s
•SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:38:09.290: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3572
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec  3 15:38:09.512: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-3572'
Dec  3 15:38:09.852: INFO: stderr: ""
Dec  3 15:38:09.852: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 15:38:09.852: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3572'
Dec  3 15:38:09.999: INFO: stderr: ""
Dec  3 15:38:09.999: INFO: stdout: "update-demo-nautilus-6x7vk update-demo-nautilus-j8f8f "
Dec  3 15:38:09.999: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-6x7vk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3572'
Dec  3 15:38:10.149: INFO: stderr: ""
Dec  3 15:38:10.150: INFO: stdout: ""
Dec  3 15:38:10.150: INFO: update-demo-nautilus-6x7vk is created but not running
Dec  3 15:38:15.150: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3572'
Dec  3 15:38:15.297: INFO: stderr: ""
Dec  3 15:38:15.297: INFO: stdout: "update-demo-nautilus-6x7vk update-demo-nautilus-j8f8f "
Dec  3 15:38:15.297: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-6x7vk -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3572'
Dec  3 15:38:15.451: INFO: stderr: ""
Dec  3 15:38:15.451: INFO: stdout: "true"
Dec  3 15:38:15.452: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-6x7vk -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3572'
Dec  3 15:38:15.695: INFO: stderr: ""
Dec  3 15:38:15.695: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:38:15.695: INFO: validating pod update-demo-nautilus-6x7vk
Dec  3 15:38:15.803: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:38:15.804: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:38:15.804: INFO: update-demo-nautilus-6x7vk is verified up and running
Dec  3 15:38:15.804: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-j8f8f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3572'
Dec  3 15:38:15.963: INFO: stderr: ""
Dec  3 15:38:15.963: INFO: stdout: "true"
Dec  3 15:38:15.963: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-j8f8f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3572'
Dec  3 15:38:16.110: INFO: stderr: ""
Dec  3 15:38:16.110: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:38:16.110: INFO: validating pod update-demo-nautilus-j8f8f
Dec  3 15:38:16.215: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:38:16.216: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:38:16.216: INFO: update-demo-nautilus-j8f8f is verified up and running
STEP: scaling down the replication controller
Dec  3 15:38:16.218: INFO: scanned /root for discovery docs: <nil>
Dec  3 15:38:16.218: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-3572'
Dec  3 15:38:16.417: INFO: stderr: ""
Dec  3 15:38:16.417: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 15:38:16.418: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3572'
Dec  3 15:38:16.562: INFO: stderr: ""
Dec  3 15:38:16.562: INFO: stdout: "update-demo-nautilus-6x7vk update-demo-nautilus-j8f8f "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  3 15:38:21.563: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3572'
Dec  3 15:38:21.719: INFO: stderr: ""
Dec  3 15:38:21.719: INFO: stdout: "update-demo-nautilus-j8f8f "
Dec  3 15:38:21.719: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-j8f8f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3572'
Dec  3 15:38:21.859: INFO: stderr: ""
Dec  3 15:38:21.859: INFO: stdout: "true"
Dec  3 15:38:21.859: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-j8f8f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3572'
Dec  3 15:38:21.996: INFO: stderr: ""
Dec  3 15:38:21.996: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:38:21.996: INFO: validating pod update-demo-nautilus-j8f8f
Dec  3 15:38:22.018: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:38:22.018: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:38:22.018: INFO: update-demo-nautilus-j8f8f is verified up and running
STEP: scaling up the replication controller
Dec  3 15:38:22.020: INFO: scanned /root for discovery docs: <nil>
Dec  3 15:38:22.020: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-3572'
Dec  3 15:38:22.213: INFO: stderr: ""
Dec  3 15:38:22.213: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 15:38:22.214: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3572'
Dec  3 15:38:22.360: INFO: stderr: ""
Dec  3 15:38:22.360: INFO: stdout: "update-demo-nautilus-j5w8b update-demo-nautilus-j8f8f "
Dec  3 15:38:22.360: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-j5w8b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3572'
Dec  3 15:38:22.500: INFO: stderr: ""
Dec  3 15:38:22.500: INFO: stdout: ""
Dec  3 15:38:22.500: INFO: update-demo-nautilus-j5w8b is created but not running
Dec  3 15:38:27.500: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-3572'
Dec  3 15:38:27.648: INFO: stderr: ""
Dec  3 15:38:27.649: INFO: stdout: "update-demo-nautilus-j5w8b update-demo-nautilus-j8f8f "
Dec  3 15:38:27.649: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-j5w8b -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3572'
Dec  3 15:38:27.787: INFO: stderr: ""
Dec  3 15:38:27.787: INFO: stdout: "true"
Dec  3 15:38:27.787: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-j5w8b -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3572'
Dec  3 15:38:27.932: INFO: stderr: ""
Dec  3 15:38:27.932: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:38:27.932: INFO: validating pod update-demo-nautilus-j5w8b
Dec  3 15:38:28.042: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:38:28.042: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:38:28.042: INFO: update-demo-nautilus-j5w8b is verified up and running
Dec  3 15:38:28.042: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-j8f8f -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-3572'
Dec  3 15:38:28.183: INFO: stderr: ""
Dec  3 15:38:28.183: INFO: stdout: "true"
Dec  3 15:38:28.183: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-j8f8f -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-3572'
Dec  3 15:38:28.332: INFO: stderr: ""
Dec  3 15:38:28.332: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:38:28.332: INFO: validating pod update-demo-nautilus-j8f8f
Dec  3 15:38:28.354: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:38:28.354: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:38:28.354: INFO: update-demo-nautilus-j8f8f is verified up and running
STEP: using delete to clean up resources
Dec  3 15:38:28.354: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-3572'
Dec  3 15:38:28.518: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:38:28.518: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  3 15:38:28.518: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3572'
Dec  3 15:38:28.683: INFO: stderr: "No resources found in kubectl-3572 namespace.\n"
Dec  3 15:38:28.683: INFO: stdout: ""
Dec  3 15:38:28.683: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-3572 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 15:38:28.835: INFO: stderr: ""
Dec  3 15:38:28.835: INFO: stdout: "update-demo-nautilus-j5w8b\nupdate-demo-nautilus-j8f8f\n"
Dec  3 15:38:29.335: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-3572'
Dec  3 15:38:29.505: INFO: stderr: "No resources found in kubectl-3572 namespace.\n"
Dec  3 15:38:29.505: INFO: stdout: ""
Dec  3 15:38:29.506: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-3572 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 15:38:29.655: INFO: stderr: ""
Dec  3 15:38:29.655: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:38:29.655: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3572" for this suite.
Dec  3 15:38:41.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:38:42.361: INFO: namespace kubectl-3572 deletion completed in 12.671681173s
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:38:42.361: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-8557
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Dec  3 15:38:46.674: INFO: Pod pod-hostip-78c0905e-2ffd-4d1c-a5b5-00bc0c9f0ab6 has hostIP: 10.250.0.4
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:38:46.674: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-8557" for this suite.
Dec  3 15:39:14.759: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:39:15.379: INFO: namespace pods-8557 deletion completed in 28.672875099s
•SS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:39:15.379: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-547
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec  3 15:39:15.609: INFO: PodSpec: initContainers in spec.initContainers
Dec  3 15:40:05.805: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-26de95f9-63f7-4e9a-bfae-bf96975748d0", GenerateName:"", Namespace:"init-container-547", SelfLink:"/api/v1/namespaces/init-container-547/pods/pod-init-26de95f9-63f7-4e9a-bfae-bf96975748d0", UID:"51d99aa4-d18c-4631-b4b1-7b5eaee13208", ResourceVersion:"14584", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63710984355, loc:(*time.Location)(0x84bfb00)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"609325257"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.64.1.132/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-gd8q6", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc002991900), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gd8q6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gd8q6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-gd8q6", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc003dfee78), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc0028314a0), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003dfeef0)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc003dfef10)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc003dfef18), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc003dfef1c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984355, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984355, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984355, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984355, loc:(*time.Location)(0x84bfb00)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.0.4", PodIP:"100.64.1.132", PodIPs:[]v1.PodIP{v1.PodIP{IP:"100.64.1.132"}}, StartTime:(*v1.Time)(0xc001f18e80), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc002562770)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0025627e0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://62c69671d06b4f49e1aa9daa5c0a54ec62a6801a51136e3ee890a9201b61900b", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001f18ec0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001f18ea0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc003dfef9f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:40:05.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-547" for this suite.
Dec  3 15:40:33.898: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:40:34.515: INFO: namespace init-container-547 deletion completed in 28.669299279s
•SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:40:34.515: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5880
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Dec  3 15:40:34.758: INFO: Waiting up to 5m0s for pod "client-containers-37290bea-3e8d-4758-9f0c-5d71c917c1ce" in namespace "containers-5880" to be "success or failure"
Dec  3 15:40:34.775: INFO: Pod "client-containers-37290bea-3e8d-4758-9f0c-5d71c917c1ce": Phase="Pending", Reason="", readiness=false. Elapsed: 16.683527ms
Dec  3 15:40:36.793: INFO: Pod "client-containers-37290bea-3e8d-4758-9f0c-5d71c917c1ce": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034662366s
Dec  3 15:40:38.811: INFO: Pod "client-containers-37290bea-3e8d-4758-9f0c-5d71c917c1ce": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052601031s
STEP: Saw pod success
Dec  3 15:40:38.811: INFO: Pod "client-containers-37290bea-3e8d-4758-9f0c-5d71c917c1ce" satisfied condition "success or failure"
Dec  3 15:40:38.828: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod client-containers-37290bea-3e8d-4758-9f0c-5d71c917c1ce container test-container: <nil>
STEP: delete the pod
Dec  3 15:40:39.014: INFO: Waiting for pod client-containers-37290bea-3e8d-4758-9f0c-5d71c917c1ce to disappear
Dec  3 15:40:39.031: INFO: Pod client-containers-37290bea-3e8d-4758-9f0c-5d71c917c1ce no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:40:39.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5880" for this suite.
Dec  3 15:40:45.118: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:40:45.726: INFO: namespace containers-5880 deletion completed in 6.661600895s
•SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:40:45.727: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1258
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:40:46.818: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984446, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984446, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984446, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984446, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:40:48.837: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984446, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984446, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984446, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984446, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:40:50.837: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984446, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984446, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984446, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984446, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:40:53.866: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:40:53.884: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7519-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:40:54.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1258" for this suite.
Dec  3 15:41:00.909: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:41:01.509: INFO: namespace webhook-1258 deletion completed in 6.65276209s
STEP: Destroying namespace "webhook-1258-markers" for this suite.
Dec  3 15:41:07.562: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:41:08.157: INFO: namespace webhook-1258-markers deletion completed in 6.648297275s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:41:08.227: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-8243
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:41:08.453: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating first CR 
Dec  3 15:41:08.662: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-03T15:41:08Z generation:1 name:name1 resourceVersion:14838 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:2878af16-1b72-4c8a-98a1-d7d64aaefa21] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Dec  3 15:41:18.683: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-03T15:41:18Z generation:1 name:name2 resourceVersion:14864 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:941ee7a0-5c92-4da5-8497-d5ac37cb1456] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Dec  3 15:41:28.703: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-03T15:41:08Z generation:2 name:name1 resourceVersion:14888 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:2878af16-1b72-4c8a-98a1-d7d64aaefa21] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Dec  3 15:41:38.721: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-03T15:41:18Z generation:2 name:name2 resourceVersion:14912 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:941ee7a0-5c92-4da5-8497-d5ac37cb1456] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Dec  3 15:41:48.742: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-03T15:41:08Z generation:2 name:name1 resourceVersion:14937 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:2878af16-1b72-4c8a-98a1-d7d64aaefa21] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Dec  3 15:41:58.763: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-03T15:41:18Z generation:2 name:name2 resourceVersion:14962 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:941ee7a0-5c92-4da5-8497-d5ac37cb1456] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:42:08.800: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-8243" for this suite.
Dec  3 15:42:14.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:42:15.502: INFO: namespace crd-watch-8243 deletion completed in 6.668335386s
•SSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:42:15.502: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4267
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  3 15:42:20.379: INFO: Successfully updated pod "pod-update-activedeadlineseconds-c08b35f6-9922-4739-b4ce-ac5dbfaa1947"
Dec  3 15:42:20.379: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-c08b35f6-9922-4739-b4ce-ac5dbfaa1947" in namespace "pods-4267" to be "terminated due to deadline exceeded"
Dec  3 15:42:20.396: INFO: Pod "pod-update-activedeadlineseconds-c08b35f6-9922-4739-b4ce-ac5dbfaa1947": Phase="Running", Reason="", readiness=true. Elapsed: 17.144124ms
Dec  3 15:42:22.414: INFO: Pod "pod-update-activedeadlineseconds-c08b35f6-9922-4739-b4ce-ac5dbfaa1947": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.035405795s
Dec  3 15:42:22.414: INFO: Pod "pod-update-activedeadlineseconds-c08b35f6-9922-4739-b4ce-ac5dbfaa1947" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:42:22.414: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4267" for this suite.
Dec  3 15:42:28.503: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:42:29.111: INFO: namespace pods-4267 deletion completed in 6.664079996s
•SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:42:29.112: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9679
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:42:29.980: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984549, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984549, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984549, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984549, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:42:31.998: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984549, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984549, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984549, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984549, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:42:35.027: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:42:35.096: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9679" for this suite.
Dec  3 15:42:41.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:42:41.791: INFO: namespace webhook-9679 deletion completed in 6.661855493s
STEP: Destroying namespace "webhook-9679-markers" for this suite.
Dec  3 15:42:47.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:42:48.437: INFO: namespace webhook-9679-markers deletion completed in 6.646045531s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:42:48.506: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-8074
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:42:49.366: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984569, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984569, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984569, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984569, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:42:51.385: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984569, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984569, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984569, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984569, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:42:54.412: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:42:54.430: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:42:55.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-8074" for this suite.
Dec  3 15:43:01.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:43:02.211: INFO: namespace crd-webhook-8074 deletion completed in 6.666165757s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:43:02.281: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5733
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  3 15:43:02.524: INFO: Waiting up to 5m0s for pod "pod-d88b99b1-11cd-4c22-a0b1-4814277ac065" in namespace "emptydir-5733" to be "success or failure"
Dec  3 15:43:02.541: INFO: Pod "pod-d88b99b1-11cd-4c22-a0b1-4814277ac065": Phase="Pending", Reason="", readiness=false. Elapsed: 17.05347ms
Dec  3 15:43:04.559: INFO: Pod "pod-d88b99b1-11cd-4c22-a0b1-4814277ac065": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035286123s
Dec  3 15:43:06.577: INFO: Pod "pod-d88b99b1-11cd-4c22-a0b1-4814277ac065": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053527141s
STEP: Saw pod success
Dec  3 15:43:06.578: INFO: Pod "pod-d88b99b1-11cd-4c22-a0b1-4814277ac065" satisfied condition "success or failure"
Dec  3 15:43:06.595: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-d88b99b1-11cd-4c22-a0b1-4814277ac065 container test-container: <nil>
STEP: delete the pod
Dec  3 15:43:06.781: INFO: Waiting for pod pod-d88b99b1-11cd-4c22-a0b1-4814277ac065 to disappear
Dec  3 15:43:06.803: INFO: Pod pod-d88b99b1-11cd-4c22-a0b1-4814277ac065 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:43:06.803: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5733" for this suite.
Dec  3 15:43:12.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:43:13.535: INFO: namespace emptydir-5733 deletion completed in 6.699034527s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:43:13.536: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5237
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:43:13.760: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:43:18.098: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5237" for this suite.
Dec  3 15:44:02.197: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:44:03.289: INFO: namespace pods-5237 deletion completed in 45.158518855s
•SSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:44:03.290: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7756
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:44:03.666: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d5f6bcf9-425a-4227-b92b-56577c2bc385" in namespace "projected-7756" to be "success or failure"
Dec  3 15:44:03.704: INFO: Pod "downwardapi-volume-d5f6bcf9-425a-4227-b92b-56577c2bc385": Phase="Pending", Reason="", readiness=false. Elapsed: 37.075586ms
Dec  3 15:44:05.771: INFO: Pod "downwardapi-volume-d5f6bcf9-425a-4227-b92b-56577c2bc385": Phase="Pending", Reason="", readiness=false. Elapsed: 2.104032571s
Dec  3 15:44:07.832: INFO: Pod "downwardapi-volume-d5f6bcf9-425a-4227-b92b-56577c2bc385": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.16524033s
STEP: Saw pod success
Dec  3 15:44:07.832: INFO: Pod "downwardapi-volume-d5f6bcf9-425a-4227-b92b-56577c2bc385" satisfied condition "success or failure"
Dec  3 15:44:07.890: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downwardapi-volume-d5f6bcf9-425a-4227-b92b-56577c2bc385 container client-container: <nil>
STEP: delete the pod
Dec  3 15:44:08.042: INFO: Waiting for pod downwardapi-volume-d5f6bcf9-425a-4227-b92b-56577c2bc385 to disappear
Dec  3 15:44:08.107: INFO: Pod downwardapi-volume-d5f6bcf9-425a-4227-b92b-56577c2bc385 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:44:08.108: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7756" for this suite.
Dec  3 15:44:14.344: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:44:15.014: INFO: namespace projected-7756 deletion completed in 6.798192593s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:44:15.015: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-5662
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-b12d3c03-7155-41c4-91fb-fd76dd145736 in namespace container-probe-5662
Dec  3 15:44:19.315: INFO: Started pod liveness-b12d3c03-7155-41c4-91fb-fd76dd145736 in namespace container-probe-5662
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 15:44:19.333: INFO: Initial restart count of pod liveness-b12d3c03-7155-41c4-91fb-fd76dd145736 is 0
Dec  3 15:44:31.457: INFO: Restart count of pod container-probe-5662/liveness-b12d3c03-7155-41c4-91fb-fd76dd145736 is now 1 (12.123801452s elapsed)
Dec  3 15:44:51.636: INFO: Restart count of pod container-probe-5662/liveness-b12d3c03-7155-41c4-91fb-fd76dd145736 is now 2 (32.303057767s elapsed)
Dec  3 15:45:11.818: INFO: Restart count of pod container-probe-5662/liveness-b12d3c03-7155-41c4-91fb-fd76dd145736 is now 3 (52.485698971s elapsed)
Dec  3 15:45:32.122: INFO: Restart count of pod container-probe-5662/liveness-b12d3c03-7155-41c4-91fb-fd76dd145736 is now 4 (1m12.789216021s elapsed)
Dec  3 15:46:42.785: INFO: Restart count of pod container-probe-5662/liveness-b12d3c03-7155-41c4-91fb-fd76dd145736 is now 5 (2m23.452661919s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:46:42.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-5662" for this suite.
Dec  3 15:46:48.899: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:46:49.502: INFO: namespace container-probe-5662 deletion completed in 6.654976775s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:46:49.503: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4083
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-dd984108-afa3-463d-b141-a1c6c74523e8 in namespace container-probe-4083
Dec  3 15:46:53.921: INFO: Started pod busybox-dd984108-afa3-463d-b141-a1c6c74523e8 in namespace container-probe-4083
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 15:46:53.939: INFO: Initial restart count of pod busybox-dd984108-afa3-463d-b141-a1c6c74523e8 is 0
Dec  3 15:47:48.450: INFO: Restart count of pod container-probe-4083/busybox-dd984108-afa3-463d-b141-a1c6c74523e8 is now 1 (54.511545419s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:47:48.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4083" for this suite.
Dec  3 15:47:54.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:47:55.187: INFO: namespace container-probe-4083 deletion completed in 6.675576217s
•SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:47:55.188: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-4510
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:47:55.416: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:47:55.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-4510" for this suite.
Dec  3 15:48:01.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:48:02.241: INFO: namespace custom-resource-definition-4510 deletion completed in 6.647182227s
•SSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:48:02.241: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-6262
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:48:02.463: INFO: Creating deployment "webserver-deployment"
Dec  3 15:48:02.481: INFO: Waiting for observed generation 1
Dec  3 15:48:04.517: INFO: Waiting for all required pods to come up
Dec  3 15:48:04.552: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec  3 15:48:08.602: INFO: Waiting for deployment "webserver-deployment" to complete
Dec  3 15:48:08.637: INFO: Updating deployment "webserver-deployment" with a non-existent image
Dec  3 15:48:08.673: INFO: Updating deployment webserver-deployment
Dec  3 15:48:08.673: INFO: Waiting for observed generation 2
Dec  3 15:48:10.718: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec  3 15:48:10.736: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec  3 15:48:10.753: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec  3 15:48:10.805: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec  3 15:48:10.805: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec  3 15:48:10.821: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec  3 15:48:10.856: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Dec  3 15:48:10.856: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Dec  3 15:48:10.891: INFO: Updating deployment webserver-deployment
Dec  3 15:48:10.891: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Dec  3 15:48:10.935: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec  3 15:48:10.983: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec  3 15:48:11.033: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-6262 /apis/apps/v1/namespaces/deployment-6262/deployments/webserver-deployment faf1c785-989a-47fb-bab9-ca2160eeb0dc 16276 3 2019-12-03 15:48:02 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003d58bd8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-12-03 15:48:10 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2019-12-03 15:48:10 +0000 UTC,LastTransitionTime:2019-12-03 15:48:02 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Dec  3 15:48:11.058: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-6262 /apis/apps/v1/namespaces/deployment-6262/replicasets/webserver-deployment-c7997dcc8 f0875145-8199-48c8-bb83-e561f2eb2a63 16275 3 2019-12-03 15:48:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment faf1c785-989a-47fb-bab9-ca2160eeb0dc 0xc003d59557 0xc003d59558}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003d595c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 15:48:11.058: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Dec  3 15:48:11.058: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-6262 /apis/apps/v1/namespaces/deployment-6262/replicasets/webserver-deployment-595b5b9587 1d556b96-f215-4a6c-b029-00785ca00ff7 16274 3 2019-12-03 15:48:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment faf1c785-989a-47fb-bab9-ca2160eeb0dc 0xc003d59497 0xc003d59498}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003d594f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Dec  3 15:48:11.118: INFO: Pod "webserver-deployment-595b5b9587-2f95d" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2f95d webserver-deployment-595b5b9587- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-595b5b9587-2f95d 0fedf4ce-50da-4178-b05a-71aeaf267229 16271 0 2019-12-03 15:48:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d556b96-f215-4a6c-b029-00785ca00ff7 0xc003d59a97 0xc003d59a98}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.118: INFO: Pod "webserver-deployment-595b5b9587-4fk4t" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-4fk4t webserver-deployment-595b5b9587- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-595b5b9587-4fk4t caff254c-0857-4d93-910b-0d64cc0edd50 16273 0 2019-12-03 15:48:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d556b96-f215-4a6c-b029-00785ca00ff7 0xc003d59ba0 0xc003d59ba1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.118: INFO: Pod "webserver-deployment-595b5b9587-69qjn" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-69qjn webserver-deployment-595b5b9587- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-595b5b9587-69qjn 3c74774a-fb0c-40c0-ab40-09dd3bd1f08a 16170 0 2019-12-03 15:48:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.1.147/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d556b96-f215-4a6c-b029-00785ca00ff7 0xc003d59cb0 0xc003d59cb1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.1.147,StartTime:2019-12-03 15:48:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 15:48:06 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://2e64dca2482178cbc7adb1346ede1e385de33e482710a0ae8a8b47f331244f25,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.147,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.118: INFO: Pod "webserver-deployment-595b5b9587-6s6gl" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-6s6gl webserver-deployment-595b5b9587- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-595b5b9587-6s6gl fad483a6-62b2-4a29-914a-f90dbb70ece5 16150 0 2019-12-03 15:48:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.0.32/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d556b96-f215-4a6c-b029-00785ca00ff7 0xc003d59e20 0xc003d59e21}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.32,StartTime:2019-12-03 15:48:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 15:48:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://58e13e7741116e263ccd7d0edcb2ce4d5dccee41744d0367f63f96eb9fea7dc7,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.32,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.118: INFO: Pod "webserver-deployment-595b5b9587-8ml9w" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-8ml9w webserver-deployment-595b5b9587- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-595b5b9587-8ml9w 6e68b8ec-97e1-470c-afbd-96f25a22e7db 16270 0 2019-12-03 15:48:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d556b96-f215-4a6c-b029-00785ca00ff7 0xc003d59f80 0xc003d59f81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.119: INFO: Pod "webserver-deployment-595b5b9587-9ltbk" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9ltbk webserver-deployment-595b5b9587- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-595b5b9587-9ltbk bf17ce88-c076-49b1-87c0-a8dbf4957b7a 16147 0 2019-12-03 15:48:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.0.35/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d556b96-f215-4a6c-b029-00785ca00ff7 0xc004bb2090 0xc004bb2091}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.35,StartTime:2019-12-03 15:48:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 15:48:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://9aa379f432b289be93a98e71ae95f20365d5b19c2120fff95ddb46a4792d5e84,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.35,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.119: INFO: Pod "webserver-deployment-595b5b9587-9xk5t" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9xk5t webserver-deployment-595b5b9587- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-595b5b9587-9xk5t 2e7c5ba4-3358-4302-b935-43938ff2be59 16260 0 2019-12-03 15:48:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d556b96-f215-4a6c-b029-00785ca00ff7 0xc004bb21f0 0xc004bb21f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.119: INFO: Pod "webserver-deployment-595b5b9587-gvzsv" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gvzsv webserver-deployment-595b5b9587- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-595b5b9587-gvzsv 4263d7cb-cf3e-4043-ab22-b39d153ae6a7 16266 0 2019-12-03 15:48:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d556b96-f215-4a6c-b029-00785ca00ff7 0xc004bb22f0 0xc004bb22f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.119: INFO: Pod "webserver-deployment-595b5b9587-mbg8j" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mbg8j webserver-deployment-595b5b9587- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-595b5b9587-mbg8j cde4691e-9967-4445-9779-253c91af71b1 16277 0 2019-12-03 15:48:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d556b96-f215-4a6c-b029-00785ca00ff7 0xc004bb23f0 0xc004bb23f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-12-03 15:48:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.119: INFO: Pod "webserver-deployment-595b5b9587-pdssq" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pdssq webserver-deployment-595b5b9587- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-595b5b9587-pdssq 9841d5a1-32f2-4c66-bf38-1aac243d819c 16164 0 2019-12-03 15:48:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.1.146/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d556b96-f215-4a6c-b029-00785ca00ff7 0xc004bb2540 0xc004bb2541}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.1.146,StartTime:2019-12-03 15:48:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 15:48:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://54ebdfb5f68fb00b0f8b31cc315e43d4b9868f3f56356c09febf68024a8721a8,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.146,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.119: INFO: Pod "webserver-deployment-595b5b9587-qrmlc" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-qrmlc webserver-deployment-595b5b9587- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-595b5b9587-qrmlc 50759fc6-e0b9-4041-b5d3-d2305bf5c27d 16173 0 2019-12-03 15:48:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.1.145/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d556b96-f215-4a6c-b029-00785ca00ff7 0xc004bb26b0 0xc004bb26b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:06 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.1.145,StartTime:2019-12-03 15:48:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 15:48:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://40d4168a8d0e1d71548584f0c5277c8f4eeb08b99a0cb1211eb9aaf7a360343a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.145,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.119: INFO: Pod "webserver-deployment-595b5b9587-r7kmk" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-r7kmk webserver-deployment-595b5b9587- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-595b5b9587-r7kmk 88d84616-818b-42d1-ad8f-7836d13a7222 16272 0 2019-12-03 15:48:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d556b96-f215-4a6c-b029-00785ca00ff7 0xc004bb2810 0xc004bb2811}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.120: INFO: Pod "webserver-deployment-595b5b9587-rc6pl" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-rc6pl webserver-deployment-595b5b9587- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-595b5b9587-rc6pl dd2e701f-6796-4b19-987a-ae7248cdd0e1 16144 0 2019-12-03 15:48:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.1.144/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d556b96-f215-4a6c-b029-00785ca00ff7 0xc004bb2920 0xc004bb2921}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.1.144,StartTime:2019-12-03 15:48:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 15:48:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://c0d8ecea605d0cd6adbbc3d7f163e873b7d2f2c9332df590842247c2135addb9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.144,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.120: INFO: Pod "webserver-deployment-595b5b9587-t8cxr" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-t8cxr webserver-deployment-595b5b9587- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-595b5b9587-t8cxr 3446b6a5-39f2-411b-80e1-8b5f65ee609f 16261 0 2019-12-03 15:48:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d556b96-f215-4a6c-b029-00785ca00ff7 0xc004bb2a80 0xc004bb2a81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.120: INFO: Pod "webserver-deployment-595b5b9587-vnhh4" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-vnhh4 webserver-deployment-595b5b9587- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-595b5b9587-vnhh4 406e5b48-c999-4f00-bf6e-5b9f5b4f2f16 16153 0 2019-12-03 15:48:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.0.33/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d556b96-f215-4a6c-b029-00785ca00ff7 0xc004bb2b90 0xc004bb2b91}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.33,StartTime:2019-12-03 15:48:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 15:48:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://c223e1a77bf2af6481237c1c622a7e918fc1b691338d926d1f1bb0cba55c9d3c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.33,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.120: INFO: Pod "webserver-deployment-595b5b9587-vwpf6" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-vwpf6 webserver-deployment-595b5b9587- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-595b5b9587-vwpf6 493f0ebc-9652-43e9-bb03-f74b9ab7a18b 16264 0 2019-12-03 15:48:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d556b96-f215-4a6c-b029-00785ca00ff7 0xc004bb2d00 0xc004bb2d01}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.120: INFO: Pod "webserver-deployment-595b5b9587-wnhh6" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-wnhh6 webserver-deployment-595b5b9587- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-595b5b9587-wnhh6 8e0ea1ac-9087-4ea9-9920-700c1b90337d 16280 0 2019-12-03 15:48:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d556b96-f215-4a6c-b029-00785ca00ff7 0xc004bb2e00 0xc004bb2e01}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-12-03 15:48:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.121: INFO: Pod "webserver-deployment-595b5b9587-zcshk" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zcshk webserver-deployment-595b5b9587- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-595b5b9587-zcshk bce9369e-6f67-4bb7-a9fe-f69966e4cb72 16284 0 2019-12-03 15:48:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d556b96-f215-4a6c-b029-00785ca00ff7 0xc004bb2f50 0xc004bb2f51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-12-03 15:48:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.121: INFO: Pod "webserver-deployment-595b5b9587-zklxx" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zklxx webserver-deployment-595b5b9587- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-595b5b9587-zklxx e554e3e1-94dc-413d-ba4c-a55eee4f49ee 16281 0 2019-12-03 15:48:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d556b96-f215-4a6c-b029-00785ca00ff7 0xc004bb3090 0xc004bb3091}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-12-03 15:48:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.121: INFO: Pod "webserver-deployment-595b5b9587-zwnc5" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-zwnc5 webserver-deployment-595b5b9587- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-595b5b9587-zwnc5 bf64a767-1a76-416e-8d81-4e436954c02a 16154 0 2019-12-03 15:48:02 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.0.34/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 1d556b96-f215-4a6c-b029-00785ca00ff7 0xc004bb31e0 0xc004bb31e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:100.64.0.34,StartTime:2019-12-03 15:48:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 15:48:04 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://3325f9b30567ef868e6434763eea888862ebb8bf55e5800c736bf3873819768c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.34,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.121: INFO: Pod "webserver-deployment-c7997dcc8-4kh5l" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-4kh5l webserver-deployment-c7997dcc8- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-c7997dcc8-4kh5l 50735af1-6a67-46f6-b64b-7821517a6c69 16225 0 2019-12-03 15:48:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:100.64.1.150/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f0875145-8199-48c8-bb83-e561f2eb2a63 0xc004bb3350 0xc004bb3351}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:08 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:08 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-12-03 15:48:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.121: INFO: Pod "webserver-deployment-c7997dcc8-ghztk" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-ghztk webserver-deployment-c7997dcc8- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-c7997dcc8-ghztk ca577bca-cd72-4bfb-a3ef-315b43116b67 16267 0 2019-12-03 15:48:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f0875145-8199-48c8-bb83-e561f2eb2a63 0xc004bb34b0 0xc004bb34b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.122: INFO: Pod "webserver-deployment-c7997dcc8-gssvj" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-gssvj webserver-deployment-c7997dcc8- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-c7997dcc8-gssvj 95b0965a-efa0-4bf2-aca6-f643ac09aaff 16283 0 2019-12-03 15:48:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f0875145-8199-48c8-bb83-e561f2eb2a63 0xc004bb35c0 0xc004bb35c1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-12-03 15:48:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.122: INFO: Pod "webserver-deployment-c7997dcc8-kv665" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-kv665 webserver-deployment-c7997dcc8- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-c7997dcc8-kv665 44763436-776f-4095-8561-59a07b01b56c 16220 0 2019-12-03 15:48:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:100.64.0.36/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f0875145-8199-48c8-bb83-e561f2eb2a63 0xc004bb3730 0xc004bb3731}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:08 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:08 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-12-03 15:48:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.122: INFO: Pod "webserver-deployment-c7997dcc8-lk5s9" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-lk5s9 webserver-deployment-c7997dcc8- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-c7997dcc8-lk5s9 da8e912e-328e-4c59-b9cd-8379a9019dcb 16263 0 2019-12-03 15:48:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f0875145-8199-48c8-bb83-e561f2eb2a63 0xc004bb3890 0xc004bb3891}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.122: INFO: Pod "webserver-deployment-c7997dcc8-lq96z" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-lq96z webserver-deployment-c7997dcc8- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-c7997dcc8-lq96z ffc05473-075e-4039-8fa1-0a236241f96e 16216 0 2019-12-03 15:48:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f0875145-8199-48c8-bb83-e561f2eb2a63 0xc004bb39a0 0xc004bb39a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:08 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:08 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-12-03 15:48:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.122: INFO: Pod "webserver-deployment-c7997dcc8-mdprx" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-mdprx webserver-deployment-c7997dcc8- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-c7997dcc8-mdprx e8a24f4c-0abd-465c-b0ce-789305af7043 16279 0 2019-12-03 15:48:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f0875145-8199-48c8-bb83-e561f2eb2a63 0xc004bb3b00 0xc004bb3b01}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-12-03 15:48:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.123: INFO: Pod "webserver-deployment-c7997dcc8-r69j5" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-r69j5 webserver-deployment-c7997dcc8- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-c7997dcc8-r69j5 b4a0de87-1ec7-41c7-a0e9-6ec5c4be7268 16221 0 2019-12-03 15:48:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:100.64.0.37/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f0875145-8199-48c8-bb83-e561f2eb2a63 0xc004bb3c70 0xc004bb3c71}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:08 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:08 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-12-03 15:48:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.123: INFO: Pod "webserver-deployment-c7997dcc8-r8gxq" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-r8gxq webserver-deployment-c7997dcc8- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-c7997dcc8-r8gxq 78e7a867-1fa0-4cc0-9e26-7d61bc28459e 16278 0 2019-12-03 15:48:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f0875145-8199-48c8-bb83-e561f2eb2a63 0xc004bb3dd0 0xc004bb3dd1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.5,PodIP:,StartTime:2019-12-03 15:48:10 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.123: INFO: Pod "webserver-deployment-c7997dcc8-rrtkm" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-rrtkm webserver-deployment-c7997dcc8- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-c7997dcc8-rrtkm 3c8ed45f-6ee6-4739-88a4-2e6b0b722e73 16262 0 2019-12-03 15:48:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f0875145-8199-48c8-bb83-e561f2eb2a63 0xc004bb3f40 0xc004bb3f41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.123: INFO: Pod "webserver-deployment-c7997dcc8-txrsg" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-txrsg webserver-deployment-c7997dcc8- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-c7997dcc8-txrsg a89637b4-7458-4a15-a345-7554370e0205 16282 0 2019-12-03 15:48:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f0875145-8199-48c8-bb83-e561f2eb2a63 0xc005056050 0xc005056051}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:11 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-12-03 15:48:11 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.123: INFO: Pod "webserver-deployment-c7997dcc8-x6sc4" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-x6sc4 webserver-deployment-c7997dcc8- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-c7997dcc8-x6sc4 cc4717f1-fbaf-4665-88a1-fd039d640923 16265 0 2019-12-03 15:48:10 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f0875145-8199-48c8-bb83-e561f2eb2a63 0xc0050561b0 0xc0050561b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:10 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:48:11.123: INFO: Pod "webserver-deployment-c7997dcc8-zgzzx" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-zgzzx webserver-deployment-c7997dcc8- deployment-6262 /api/v1/namespaces/deployment-6262/pods/webserver-deployment-c7997dcc8-zgzzx 2356b617-040d-4340-8560-f575c74ea0aa 16224 0 2019-12-03 15:48:08 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:100.64.1.149/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 f0875145-8199-48c8-bb83-e561f2eb2a63 0xc0050562d0 0xc0050562d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8rk6v,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8rk6v,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8rk6v,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:08 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:08 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:48:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:,StartTime:2019-12-03 15:48:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:48:11.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-6262" for this suite.
Dec  3 15:48:19.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:48:19.872: INFO: namespace deployment-6262 deletion completed in 8.73128565s
•S
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:48:19.873: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-7648
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:48:20.166: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"9b05a30c-41c7-42ea-8b2e-91cbc212556b", Controller:(*bool)(0xc004796a9a), BlockOwnerDeletion:(*bool)(0xc004796a9b)}}
Dec  3 15:48:20.184: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"2e399637-5e76-427b-a0ed-99a7243c7460", Controller:(*bool)(0xc0025decaa), BlockOwnerDeletion:(*bool)(0xc0025decab)}}
Dec  3 15:48:20.202: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"579f0d7f-ce7c-4967-8091-de7825715137", Controller:(*bool)(0xc005376976), BlockOwnerDeletion:(*bool)(0xc005376977)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:48:25.238: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-7648" for this suite.
Dec  3 15:48:31.323: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:48:31.928: INFO: namespace gc-7648 deletion completed in 6.6578934s
•SSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:48:31.928: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8905
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec  3 15:48:32.249: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8905 /api/v1/namespaces/watch-8905/configmaps/e2e-watch-test-label-changed f5ecff7a-f576-49a7-8f43-1d06db216cbb 16527 0 2019-12-03 15:48:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:48:32.249: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8905 /api/v1/namespaces/watch-8905/configmaps/e2e-watch-test-label-changed f5ecff7a-f576-49a7-8f43-1d06db216cbb 16528 0 2019-12-03 15:48:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  3 15:48:32.249: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8905 /api/v1/namespaces/watch-8905/configmaps/e2e-watch-test-label-changed f5ecff7a-f576-49a7-8f43-1d06db216cbb 16529 0 2019-12-03 15:48:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec  3 15:48:42.372: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8905 /api/v1/namespaces/watch-8905/configmaps/e2e-watch-test-label-changed f5ecff7a-f576-49a7-8f43-1d06db216cbb 16556 0 2019-12-03 15:48:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 15:48:42.373: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8905 /api/v1/namespaces/watch-8905/configmaps/e2e-watch-test-label-changed f5ecff7a-f576-49a7-8f43-1d06db216cbb 16557 0 2019-12-03 15:48:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec  3 15:48:42.373: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-8905 /api/v1/namespaces/watch-8905/configmaps/e2e-watch-test-label-changed f5ecff7a-f576-49a7-8f43-1d06db216cbb 16558 0 2019-12-03 15:48:32 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:48:42.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8905" for this suite.
Dec  3 15:48:48.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:48:49.063: INFO: namespace watch-8905 deletion completed in 6.655383065s
•SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:48:49.063: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-368
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:48:49.291: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec  3 15:48:52.546: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-368 create -f -'
Dec  3 15:48:53.371: INFO: stderr: ""
Dec  3 15:48:53.371: INFO: stdout: "e2e-test-crd-publish-openapi-8494-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec  3 15:48:53.371: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-368 delete e2e-test-crd-publish-openapi-8494-crds test-cr'
Dec  3 15:48:53.587: INFO: stderr: ""
Dec  3 15:48:53.587: INFO: stdout: "e2e-test-crd-publish-openapi-8494-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Dec  3 15:48:53.587: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-368 apply -f -'
Dec  3 15:48:53.998: INFO: stderr: ""
Dec  3 15:48:53.998: INFO: stdout: "e2e-test-crd-publish-openapi-8494-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec  3 15:48:53.999: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-368 delete e2e-test-crd-publish-openapi-8494-crds test-cr'
Dec  3 15:48:54.162: INFO: stderr: ""
Dec  3 15:48:54.162: INFO: stdout: "e2e-test-crd-publish-openapi-8494-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Dec  3 15:48:54.162: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-8494-crds'
Dec  3 15:48:54.485: INFO: stderr: ""
Dec  3 15:48:54.486: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-8494-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:48:58.199: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-368" for this suite.
Dec  3 15:49:04.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:49:05.769: INFO: namespace crd-publish-openapi-368 deletion completed in 7.537281872s
•SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:49:05.770: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-570
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-3acc46f4-9930-44e7-88d7-fd2fa787ea08 in namespace container-probe-570
Dec  3 15:49:08.288: INFO: Started pod test-webserver-3acc46f4-9930-44e7-88d7-fd2fa787ea08 in namespace container-probe-570
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 15:49:08.326: INFO: Initial restart count of pod test-webserver-3acc46f4-9930-44e7-88d7-fd2fa787ea08 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:53:08.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-570" for this suite.
Dec  3 15:53:14.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:53:15.283: INFO: namespace container-probe-570 deletion completed in 6.67018888s
•SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:53:15.284: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7928
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec  3 15:53:18.301: INFO: Successfully updated pod "annotationupdate289718fc-f967-4f39-809d-548e1a1a0f2d"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:53:22.382: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7928" for this suite.
Dec  3 15:53:50.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:53:51.085: INFO: namespace downward-api-7928 deletion completed in 28.669379105s
•SSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:53:51.085: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8252
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8252.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-8252.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8252.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-8252.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8252.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-8252.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-8252.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-8252.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-8252.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8252.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:53:55.548: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:53:55.593: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:53:55.612: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:53:55.632: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:53:55.786: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:53:55.806: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:53:55.832: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:53:55.853: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:53:55.960: INFO: Lookups using dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8252.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8252.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local jessie_udp@dns-test-service-2.dns-8252.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8252.svc.cluster.local]

Dec  3 15:54:00.987: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:01.008: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:01.028: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:01.048: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:01.200: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:01.220: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:01.242: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:01.263: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:01.372: INFO: Lookups using dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8252.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8252.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local jessie_udp@dns-test-service-2.dns-8252.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8252.svc.cluster.local]

Dec  3 15:54:05.984: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:06.006: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:06.027: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:06.048: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:06.201: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:06.221: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:06.241: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:06.262: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:06.412: INFO: Lookups using dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8252.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8252.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local jessie_udp@dns-test-service-2.dns-8252.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8252.svc.cluster.local]

Dec  3 15:54:10.981: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:11.026: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:11.046: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:11.066: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:11.220: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:11.242: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:11.262: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:11.284: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:11.437: INFO: Lookups using dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8252.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8252.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local jessie_udp@dns-test-service-2.dns-8252.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8252.svc.cluster.local]

Dec  3 15:54:15.981: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:16.026: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:16.046: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:16.070: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:16.224: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:16.245: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:16.265: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:16.286: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:16.395: INFO: Lookups using dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8252.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8252.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local jessie_udp@dns-test-service-2.dns-8252.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8252.svc.cluster.local]

Dec  3 15:54:20.982: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:21.002: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:21.022: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:21.043: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:21.200: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:21.221: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:21.241: INFO: Unable to read jessie_udp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:21.261: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-8252.svc.cluster.local from pod dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958: the server could not find the requested resource (get pods dns-test-8fea315c-e65d-4982-9714-4b5759f3c958)
Dec  3 15:54:21.369: INFO: Lookups using dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local wheezy_udp@dns-test-service-2.dns-8252.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-8252.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-8252.svc.cluster.local jessie_udp@dns-test-service-2.dns-8252.svc.cluster.local jessie_tcp@dns-test-service-2.dns-8252.svc.cluster.local]

Dec  3 15:54:26.735: INFO: DNS probes using dns-8252/dns-test-8fea315c-e65d-4982-9714-4b5759f3c958 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:54:26.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8252" for this suite.
Dec  3 15:54:32.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:54:33.477: INFO: namespace dns-8252 deletion completed in 6.665359868s
•S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:54:33.477: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4451
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  3 15:54:33.719: INFO: Waiting up to 5m0s for pod "pod-a3d09782-2d4c-4a77-9be5-4d8f2f90df46" in namespace "emptydir-4451" to be "success or failure"
Dec  3 15:54:33.737: INFO: Pod "pod-a3d09782-2d4c-4a77-9be5-4d8f2f90df46": Phase="Pending", Reason="", readiness=false. Elapsed: 17.378207ms
Dec  3 15:54:35.755: INFO: Pod "pod-a3d09782-2d4c-4a77-9be5-4d8f2f90df46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035435741s
STEP: Saw pod success
Dec  3 15:54:35.755: INFO: Pod "pod-a3d09782-2d4c-4a77-9be5-4d8f2f90df46" satisfied condition "success or failure"
Dec  3 15:54:35.772: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-a3d09782-2d4c-4a77-9be5-4d8f2f90df46 container test-container: <nil>
STEP: delete the pod
Dec  3 15:54:35.819: INFO: Waiting for pod pod-a3d09782-2d4c-4a77-9be5-4d8f2f90df46 to disappear
Dec  3 15:54:35.842: INFO: Pod pod-a3d09782-2d4c-4a77-9be5-4d8f2f90df46 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:54:35.842: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4451" for this suite.
Dec  3 15:54:41.927: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:54:42.569: INFO: namespace emptydir-4451 deletion completed in 6.694420142s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:54:42.570: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5022
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-0be62c67-e368-480e-98c9-346a0425b5ba
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-0be62c67-e368-480e-98c9-346a0425b5ba
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:54:47.059: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5022" for this suite.
Dec  3 15:55:15.147: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:55:15.757: INFO: namespace projected-5022 deletion completed in 28.665121856s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:55:15.758: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-854
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  3 15:55:24.161: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:55:24.179: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 15:55:26.179: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:55:26.197: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 15:55:28.179: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:55:28.197: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 15:55:30.179: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:55:30.197: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 15:55:32.179: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:55:32.197: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:55:32.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-854" for this suite.
Dec  3 15:55:44.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:55:44.910: INFO: namespace container-lifecycle-hook-854 deletion completed in 12.65329539s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:55:44.911: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8862
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:55:45.811: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985345, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985345, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985345, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985345, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:55:47.829: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985345, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985345, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985345, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985345, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:55:50.870: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:55:50.888: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-7284-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:55:51.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8862" for this suite.
Dec  3 15:55:57.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:55:58.581: INFO: namespace webhook-8862 deletion completed in 6.656392338s
STEP: Destroying namespace "webhook-8862-markers" for this suite.
Dec  3 15:56:04.633: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:56:05.230: INFO: namespace webhook-8862-markers deletion completed in 6.648892858s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:56:05.300: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-3510
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Dec  3 15:56:05.545: INFO: Waiting up to 5m0s for pod "client-containers-05423fd4-9282-4540-b16c-7b4e6bda1b48" in namespace "containers-3510" to be "success or failure"
Dec  3 15:56:05.562: INFO: Pod "client-containers-05423fd4-9282-4540-b16c-7b4e6bda1b48": Phase="Pending", Reason="", readiness=false. Elapsed: 16.726865ms
Dec  3 15:56:07.580: INFO: Pod "client-containers-05423fd4-9282-4540-b16c-7b4e6bda1b48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035402636s
Dec  3 15:56:09.598: INFO: Pod "client-containers-05423fd4-9282-4540-b16c-7b4e6bda1b48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053413726s
STEP: Saw pod success
Dec  3 15:56:09.598: INFO: Pod "client-containers-05423fd4-9282-4540-b16c-7b4e6bda1b48" satisfied condition "success or failure"
Dec  3 15:56:09.616: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod client-containers-05423fd4-9282-4540-b16c-7b4e6bda1b48 container test-container: <nil>
STEP: delete the pod
Dec  3 15:56:09.672: INFO: Waiting for pod client-containers-05423fd4-9282-4540-b16c-7b4e6bda1b48 to disappear
Dec  3 15:56:09.689: INFO: Pod client-containers-05423fd4-9282-4540-b16c-7b4e6bda1b48 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:56:09.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-3510" for this suite.
Dec  3 15:56:15.776: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:56:16.384: INFO: namespace containers-3510 deletion completed in 6.660984315s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:56:16.415: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-4074
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:56:16.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-4074" for this suite.
Dec  3 15:56:22.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:56:23.359: INFO: namespace tables-4074 deletion completed in 6.663688178s
•SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:56:23.359: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-3436
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec  3 15:56:33.861: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W1203 15:56:33.861795    5095 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  3 15:56:33.861: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-3436" for this suite.
Dec  3 15:56:39.935: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:56:40.545: INFO: namespace gc-3436 deletion completed in 6.666392784s
•SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:56:40.546: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-8092
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Dec  3 15:56:40.765: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Dec  3 15:56:41.516: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:56:43.534: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:56:45.534: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:56:47.534: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:56:49.534: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:56:51.536: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:56:53.534: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:56:55.536: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985401, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:56:58.450: INFO: Waited 896.000844ms for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:56:59.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-8092" for this suite.
Dec  3 15:57:05.606: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:57:06.214: INFO: namespace aggregator-8092 deletion completed in 6.660629275s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:57:06.215: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1538
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:57:06.459: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b965bbc7-ea9b-4ba0-bf31-a4724a882078" in namespace "projected-1538" to be "success or failure"
Dec  3 15:57:06.476: INFO: Pod "downwardapi-volume-b965bbc7-ea9b-4ba0-bf31-a4724a882078": Phase="Pending", Reason="", readiness=false. Elapsed: 17.057035ms
Dec  3 15:57:08.495: INFO: Pod "downwardapi-volume-b965bbc7-ea9b-4ba0-bf31-a4724a882078": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035274744s
STEP: Saw pod success
Dec  3 15:57:08.495: INFO: Pod "downwardapi-volume-b965bbc7-ea9b-4ba0-bf31-a4724a882078" satisfied condition "success or failure"
Dec  3 15:57:08.512: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downwardapi-volume-b965bbc7-ea9b-4ba0-bf31-a4724a882078 container client-container: <nil>
STEP: delete the pod
Dec  3 15:57:08.569: INFO: Waiting for pod downwardapi-volume-b965bbc7-ea9b-4ba0-bf31-a4724a882078 to disappear
Dec  3 15:57:08.585: INFO: Pod downwardapi-volume-b965bbc7-ea9b-4ba0-bf31-a4724a882078 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:57:08.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1538" for this suite.
Dec  3 15:57:14.674: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:57:15.305: INFO: namespace projected-1538 deletion completed in 6.683042571s
•SS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:57:15.305: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3363
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:57:17.661: INFO: Waiting up to 5m0s for pod "client-envvars-6595068b-0f0b-4e20-9f99-40720f63858e" in namespace "pods-3363" to be "success or failure"
Dec  3 15:57:17.680: INFO: Pod "client-envvars-6595068b-0f0b-4e20-9f99-40720f63858e": Phase="Pending", Reason="", readiness=false. Elapsed: 18.194132ms
Dec  3 15:57:19.698: INFO: Pod "client-envvars-6595068b-0f0b-4e20-9f99-40720f63858e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036500537s
STEP: Saw pod success
Dec  3 15:57:19.698: INFO: Pod "client-envvars-6595068b-0f0b-4e20-9f99-40720f63858e" satisfied condition "success or failure"
Dec  3 15:57:19.716: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod client-envvars-6595068b-0f0b-4e20-9f99-40720f63858e container env3cont: <nil>
STEP: delete the pod
Dec  3 15:57:19.771: INFO: Waiting for pod client-envvars-6595068b-0f0b-4e20-9f99-40720f63858e to disappear
Dec  3 15:57:19.789: INFO: Pod client-envvars-6595068b-0f0b-4e20-9f99-40720f63858e no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:57:19.789: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3363" for this suite.
Dec  3 15:57:31.895: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:57:32.492: INFO: namespace pods-3363 deletion completed in 12.671004866s
•SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:57:32.493: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9717
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:57:45.934: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9717" for this suite.
Dec  3 15:57:52.027: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:57:52.626: INFO: namespace resourcequota-9717 deletion completed in 6.658068861s
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:57:52.627: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3077
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-1ed9b4c7-5589-4b82-805d-39fa23fd06f3
STEP: Creating a pod to test consume configMaps
Dec  3 15:57:52.890: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-60d6d3a3-d872-48ad-bf62-e153edc94476" in namespace "projected-3077" to be "success or failure"
Dec  3 15:57:52.907: INFO: Pod "pod-projected-configmaps-60d6d3a3-d872-48ad-bf62-e153edc94476": Phase="Pending", Reason="", readiness=false. Elapsed: 17.489924ms
Dec  3 15:57:54.926: INFO: Pod "pod-projected-configmaps-60d6d3a3-d872-48ad-bf62-e153edc94476": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035821616s
Dec  3 15:57:56.944: INFO: Pod "pod-projected-configmaps-60d6d3a3-d872-48ad-bf62-e153edc94476": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054282448s
STEP: Saw pod success
Dec  3 15:57:57.139: INFO: Pod "pod-projected-configmaps-60d6d3a3-d872-48ad-bf62-e153edc94476" satisfied condition "success or failure"
Dec  3 15:57:57.156: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-projected-configmaps-60d6d3a3-d872-48ad-bf62-e153edc94476 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:57:57.212: INFO: Waiting for pod pod-projected-configmaps-60d6d3a3-d872-48ad-bf62-e153edc94476 to disappear
Dec  3 15:57:57.232: INFO: Pod pod-projected-configmaps-60d6d3a3-d872-48ad-bf62-e153edc94476 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:57:57.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3077" for this suite.
Dec  3 15:58:03.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:58:03.941: INFO: namespace projected-3077 deletion completed in 6.675606718s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:58:03.942: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5705
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-5705.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-5705.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5705.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-5705.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-5705.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5705.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:58:08.860: INFO: DNS probes using dns-5705/dns-test-04d1a1fc-3fe1-472a-bd61-d41570ce287f succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:58:08.912: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5705" for this suite.
Dec  3 15:58:14.998: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:58:15.654: INFO: namespace dns-5705 deletion completed in 6.709256835s
•SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:58:15.655: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4107
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec  3 15:58:15.880: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:58:19.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4107" for this suite.
Dec  3 15:58:25.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:58:26.195: INFO: namespace init-container-4107 deletion completed in 6.688961339s
•SSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:58:26.195: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7602
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:58:30.508: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7602" for this suite.
Dec  3 15:58:44.594: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:58:45.189: INFO: namespace containers-7602 deletion completed in 14.647999065s
•S
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:58:45.189: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-628
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:58:45.461: INFO: (0) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 24.354063ms)
Dec  3 15:58:45.506: INFO: (1) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 44.955606ms)
Dec  3 15:58:45.526: INFO: (2) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.186853ms)
Dec  3 15:58:45.547: INFO: (3) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.441866ms)
Dec  3 15:58:45.567: INFO: (4) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.439004ms)
Dec  3 15:58:45.588: INFO: (5) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.88058ms)
Dec  3 15:58:45.610: INFO: (6) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 21.589116ms)
Dec  3 15:58:45.631: INFO: (7) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 21.162548ms)
Dec  3 15:58:45.651: INFO: (8) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.04448ms)
Dec  3 15:58:45.671: INFO: (9) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 19.906777ms)
Dec  3 15:58:45.691: INFO: (10) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 19.998742ms)
Dec  3 15:58:45.715: INFO: (11) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 24.063513ms)
Dec  3 15:58:45.736: INFO: (12) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.776454ms)
Dec  3 15:58:45.757: INFO: (13) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 21.011486ms)
Dec  3 15:58:45.778: INFO: (14) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.585179ms)
Dec  3 15:58:45.799: INFO: (15) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.731057ms)
Dec  3 15:58:45.819: INFO: (16) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.395112ms)
Dec  3 15:58:45.840: INFO: (17) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.368132ms)
Dec  3 15:58:45.860: INFO: (18) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.566191ms)
Dec  3 15:58:45.881: INFO: (19) /api/v1/nodes/shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk/proxy/logs/: <pre>
<a href="azure/">azure/</a>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<... (200; 20.254587ms)
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:58:45.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-628" for this suite.
Dec  3 15:58:51.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:58:52.545: INFO: namespace proxy-628 deletion completed in 6.646153158s
•SSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:58:52.545: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2793
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec  3 15:58:52.768: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-2793'
Dec  3 15:58:59.605: INFO: stderr: ""
Dec  3 15:58:59.605: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  3 15:59:00.624: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:59:00.624: INFO: Found 0 / 1
Dec  3 15:59:01.624: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:59:01.625: INFO: Found 1 / 1
Dec  3 15:59:01.625: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec  3 15:59:01.642: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:59:01.642: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 15:59:01.642: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config patch pod redis-master-jrvhl --namespace=kubectl-2793 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec  3 15:59:01.811: INFO: stderr: ""
Dec  3 15:59:01.811: INFO: stdout: "pod/redis-master-jrvhl patched\n"
STEP: checking annotations
Dec  3 15:59:01.833: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:59:01.834: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:59:01.834: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2793" for this suite.
Dec  3 15:59:13.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:59:14.517: INFO: namespace kubectl-2793 deletion completed in 12.65092324s
•SS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:59:14.518: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-9486
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:59:14.836: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-b47e978b-41e3-4f57-a7e4-eb8c8d0a6601" in namespace "security-context-test-9486" to be "success or failure"
Dec  3 15:59:14.853: INFO: Pod "busybox-readonly-false-b47e978b-41e3-4f57-a7e4-eb8c8d0a6601": Phase="Pending", Reason="", readiness=false. Elapsed: 17.202807ms
Dec  3 15:59:16.872: INFO: Pod "busybox-readonly-false-b47e978b-41e3-4f57-a7e4-eb8c8d0a6601": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035376824s
Dec  3 15:59:16.872: INFO: Pod "busybox-readonly-false-b47e978b-41e3-4f57-a7e4-eb8c8d0a6601" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:59:16.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9486" for this suite.
Dec  3 15:59:22.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:59:23.557: INFO: namespace security-context-test-9486 deletion completed in 6.651841153s
•SSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:59:23.557: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2701
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-673dd5a4-4183-46d9-89d0-b3122a84a2f6
STEP: Creating a pod to test consume configMaps
Dec  3 15:59:23.824: INFO: Waiting up to 5m0s for pod "pod-configmaps-1833b9c5-4b29-442c-b7a1-92bdc3baf4f1" in namespace "configmap-2701" to be "success or failure"
Dec  3 15:59:23.841: INFO: Pod "pod-configmaps-1833b9c5-4b29-442c-b7a1-92bdc3baf4f1": Phase="Pending", Reason="", readiness=false. Elapsed: 17.302869ms
Dec  3 15:59:25.859: INFO: Pod "pod-configmaps-1833b9c5-4b29-442c-b7a1-92bdc3baf4f1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035289735s
STEP: Saw pod success
Dec  3 15:59:25.860: INFO: Pod "pod-configmaps-1833b9c5-4b29-442c-b7a1-92bdc3baf4f1" satisfied condition "success or failure"
Dec  3 15:59:25.877: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-configmaps-1833b9c5-4b29-442c-b7a1-92bdc3baf4f1 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:59:25.925: INFO: Waiting for pod pod-configmaps-1833b9c5-4b29-442c-b7a1-92bdc3baf4f1 to disappear
Dec  3 15:59:25.951: INFO: Pod pod-configmaps-1833b9c5-4b29-442c-b7a1-92bdc3baf4f1 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:59:25.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2701" for this suite.
Dec  3 15:59:32.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:59:32.631: INFO: namespace configmap-2701 deletion completed in 6.646464068s
•SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:59:32.631: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3104
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-7de7d851-4174-4255-8f00-baceca54a761
STEP: Creating a pod to test consume configMaps
Dec  3 15:59:32.900: INFO: Waiting up to 5m0s for pod "pod-configmaps-29d3b5c5-dd6e-46c8-bcb4-8b7da1213e30" in namespace "configmap-3104" to be "success or failure"
Dec  3 15:59:32.917: INFO: Pod "pod-configmaps-29d3b5c5-dd6e-46c8-bcb4-8b7da1213e30": Phase="Pending", Reason="", readiness=false. Elapsed: 16.829449ms
Dec  3 15:59:34.936: INFO: Pod "pod-configmaps-29d3b5c5-dd6e-46c8-bcb4-8b7da1213e30": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036035246s
STEP: Saw pod success
Dec  3 15:59:34.936: INFO: Pod "pod-configmaps-29d3b5c5-dd6e-46c8-bcb4-8b7da1213e30" satisfied condition "success or failure"
Dec  3 15:59:34.954: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-configmaps-29d3b5c5-dd6e-46c8-bcb4-8b7da1213e30 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:59:35.014: INFO: Waiting for pod pod-configmaps-29d3b5c5-dd6e-46c8-bcb4-8b7da1213e30 to disappear
Dec  3 15:59:35.030: INFO: Pod pod-configmaps-29d3b5c5-dd6e-46c8-bcb4-8b7da1213e30 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:59:35.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3104" for this suite.
Dec  3 15:59:41.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:59:41.720: INFO: namespace configmap-3104 deletion completed in 6.656190916s
•SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:59:41.720: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7601
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  3 15:59:41.963: INFO: Waiting up to 5m0s for pod "pod-5d11cc9f-6e6b-4db9-8dcc-375d01618a85" in namespace "emptydir-7601" to be "success or failure"
Dec  3 15:59:41.980: INFO: Pod "pod-5d11cc9f-6e6b-4db9-8dcc-375d01618a85": Phase="Pending", Reason="", readiness=false. Elapsed: 16.929355ms
Dec  3 15:59:43.998: INFO: Pod "pod-5d11cc9f-6e6b-4db9-8dcc-375d01618a85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035256661s
STEP: Saw pod success
Dec  3 15:59:43.998: INFO: Pod "pod-5d11cc9f-6e6b-4db9-8dcc-375d01618a85" satisfied condition "success or failure"
Dec  3 15:59:44.019: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-5d11cc9f-6e6b-4db9-8dcc-375d01618a85 container test-container: <nil>
STEP: delete the pod
Dec  3 15:59:44.067: INFO: Waiting for pod pod-5d11cc9f-6e6b-4db9-8dcc-375d01618a85 to disappear
Dec  3 15:59:44.084: INFO: Pod pod-5d11cc9f-6e6b-4db9-8dcc-375d01618a85 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:59:44.084: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7601" for this suite.
Dec  3 15:59:50.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:59:50.776: INFO: namespace emptydir-7601 deletion completed in 6.65860903s
•SSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:59:50.776: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1696
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1696.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1696.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1696.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1696.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:59:55.286: INFO: DNS probes using dns-test-264b3223-c948-40f0-abae-6404f8a7a407 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1696.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-1696.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1696.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-1696.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:59:59.532: INFO: File wheezy_udp@dns-test-service-3.dns-1696.svc.cluster.local from pod  dns-1696/dns-test-47edf50b-1baf-494d-9c44-2ae7f09e65a5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:59:59.619: INFO: File jessie_udp@dns-test-service-3.dns-1696.svc.cluster.local from pod  dns-1696/dns-test-47edf50b-1baf-494d-9c44-2ae7f09e65a5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:59:59.619: INFO: Lookups using dns-1696/dns-test-47edf50b-1baf-494d-9c44-2ae7f09e65a5 failed for: [wheezy_udp@dns-test-service-3.dns-1696.svc.cluster.local jessie_udp@dns-test-service-3.dns-1696.svc.cluster.local]

Dec  3 16:00:04.643: INFO: File wheezy_udp@dns-test-service-3.dns-1696.svc.cluster.local from pod  dns-1696/dns-test-47edf50b-1baf-494d-9c44-2ae7f09e65a5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 16:00:04.728: INFO: File jessie_udp@dns-test-service-3.dns-1696.svc.cluster.local from pod  dns-1696/dns-test-47edf50b-1baf-494d-9c44-2ae7f09e65a5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 16:00:04.728: INFO: Lookups using dns-1696/dns-test-47edf50b-1baf-494d-9c44-2ae7f09e65a5 failed for: [wheezy_udp@dns-test-service-3.dns-1696.svc.cluster.local jessie_udp@dns-test-service-3.dns-1696.svc.cluster.local]

Dec  3 16:00:09.644: INFO: File wheezy_udp@dns-test-service-3.dns-1696.svc.cluster.local from pod  dns-1696/dns-test-47edf50b-1baf-494d-9c44-2ae7f09e65a5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 16:00:09.690: INFO: File jessie_udp@dns-test-service-3.dns-1696.svc.cluster.local from pod  dns-1696/dns-test-47edf50b-1baf-494d-9c44-2ae7f09e65a5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 16:00:09.690: INFO: Lookups using dns-1696/dns-test-47edf50b-1baf-494d-9c44-2ae7f09e65a5 failed for: [wheezy_udp@dns-test-service-3.dns-1696.svc.cluster.local jessie_udp@dns-test-service-3.dns-1696.svc.cluster.local]

Dec  3 16:00:14.642: INFO: File wheezy_udp@dns-test-service-3.dns-1696.svc.cluster.local from pod  dns-1696/dns-test-47edf50b-1baf-494d-9c44-2ae7f09e65a5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 16:00:14.730: INFO: File jessie_udp@dns-test-service-3.dns-1696.svc.cluster.local from pod  dns-1696/dns-test-47edf50b-1baf-494d-9c44-2ae7f09e65a5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 16:00:14.730: INFO: Lookups using dns-1696/dns-test-47edf50b-1baf-494d-9c44-2ae7f09e65a5 failed for: [wheezy_udp@dns-test-service-3.dns-1696.svc.cluster.local jessie_udp@dns-test-service-3.dns-1696.svc.cluster.local]

Dec  3 16:00:19.643: INFO: File wheezy_udp@dns-test-service-3.dns-1696.svc.cluster.local from pod  dns-1696/dns-test-47edf50b-1baf-494d-9c44-2ae7f09e65a5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 16:00:19.728: INFO: File jessie_udp@dns-test-service-3.dns-1696.svc.cluster.local from pod  dns-1696/dns-test-47edf50b-1baf-494d-9c44-2ae7f09e65a5 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 16:00:19.729: INFO: Lookups using dns-1696/dns-test-47edf50b-1baf-494d-9c44-2ae7f09e65a5 failed for: [wheezy_udp@dns-test-service-3.dns-1696.svc.cluster.local jessie_udp@dns-test-service-3.dns-1696.svc.cluster.local]

Dec  3 16:00:24.688: INFO: DNS probes using dns-test-47edf50b-1baf-494d-9c44-2ae7f09e65a5 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1696.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-1696.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-1696.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-1696.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 16:00:29.048: INFO: DNS probes using dns-test-6bd65ac3-6abf-4fb2-bbe4-a4fb8c6d8eb4 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:00:29.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1696" for this suite.
Dec  3 16:00:35.188: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:00:35.793: INFO: namespace dns-1696 deletion completed in 6.658540845s
•SSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:00:35.794: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4689
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Dec  3 16:01:06.197: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1203 16:01:06.197777    5095 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:01:06.198: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4689" for this suite.
Dec  3 16:01:12.277: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:01:12.878: INFO: namespace gc-4689 deletion completed in 6.657170718s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:01:12.878: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9502
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-484c7c70-9a17-408a-912b-240d910a05d7
STEP: Creating a pod to test consume secrets
Dec  3 16:01:13.139: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f13f170e-2d28-4ff6-90e6-e8b74176c494" in namespace "projected-9502" to be "success or failure"
Dec  3 16:01:13.156: INFO: Pod "pod-projected-secrets-f13f170e-2d28-4ff6-90e6-e8b74176c494": Phase="Pending", Reason="", readiness=false. Elapsed: 17.153656ms
Dec  3 16:01:15.174: INFO: Pod "pod-projected-secrets-f13f170e-2d28-4ff6-90e6-e8b74176c494": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035161194s
STEP: Saw pod success
Dec  3 16:01:15.174: INFO: Pod "pod-projected-secrets-f13f170e-2d28-4ff6-90e6-e8b74176c494" satisfied condition "success or failure"
Dec  3 16:01:15.191: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-projected-secrets-f13f170e-2d28-4ff6-90e6-e8b74176c494 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:01:15.391: INFO: Waiting for pod pod-projected-secrets-f13f170e-2d28-4ff6-90e6-e8b74176c494 to disappear
Dec  3 16:01:15.408: INFO: Pod pod-projected-secrets-f13f170e-2d28-4ff6-90e6-e8b74176c494 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:01:15.408: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9502" for this suite.
Dec  3 16:01:21.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:01:22.100: INFO: namespace projected-9502 deletion completed in 6.65895143s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:01:22.101: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5494
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:01:33.467: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5494" for this suite.
Dec  3 16:01:39.552: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:01:40.161: INFO: namespace resourcequota-5494 deletion completed in 6.661393466s
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:01:40.161: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-691
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:01:40.384: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Dec  3 16:01:41.514: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:01:41.543: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-691" for this suite.
Dec  3 16:01:47.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:01:48.248: INFO: namespace replication-controller-691 deletion completed in 6.671475121s
•SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:01:48.248: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-107
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec  3 16:01:48.472: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-107'
Dec  3 16:01:48.737: INFO: stderr: ""
Dec  3 16:01:48.737: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 16:01:48.738: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-107'
Dec  3 16:01:48.884: INFO: stderr: ""
Dec  3 16:01:48.884: INFO: stdout: "update-demo-nautilus-gdpkg update-demo-nautilus-qmrsx "
Dec  3 16:01:48.884: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-gdpkg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-107'
Dec  3 16:01:49.039: INFO: stderr: ""
Dec  3 16:01:49.039: INFO: stdout: ""
Dec  3 16:01:49.039: INFO: update-demo-nautilus-gdpkg is created but not running
Dec  3 16:01:54.040: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-107'
Dec  3 16:01:54.181: INFO: stderr: ""
Dec  3 16:01:54.181: INFO: stdout: "update-demo-nautilus-gdpkg update-demo-nautilus-qmrsx "
Dec  3 16:01:54.181: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-gdpkg -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-107'
Dec  3 16:01:54.322: INFO: stderr: ""
Dec  3 16:01:54.322: INFO: stdout: "true"
Dec  3 16:01:54.322: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-gdpkg -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-107'
Dec  3 16:01:54.464: INFO: stderr: ""
Dec  3 16:01:54.464: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 16:01:54.464: INFO: validating pod update-demo-nautilus-gdpkg
Dec  3 16:01:54.570: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 16:01:54.570: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 16:01:54.570: INFO: update-demo-nautilus-gdpkg is verified up and running
Dec  3 16:01:54.570: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-qmrsx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-107'
Dec  3 16:01:54.720: INFO: stderr: ""
Dec  3 16:01:54.720: INFO: stdout: "true"
Dec  3 16:01:54.720: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-qmrsx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-107'
Dec  3 16:01:54.858: INFO: stderr: ""
Dec  3 16:01:54.858: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 16:01:54.858: INFO: validating pod update-demo-nautilus-qmrsx
Dec  3 16:01:54.966: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 16:01:54.966: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 16:01:54.966: INFO: update-demo-nautilus-qmrsx is verified up and running
STEP: using delete to clean up resources
Dec  3 16:01:54.966: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-107'
Dec  3 16:01:55.132: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 16:01:55.132: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  3 16:01:55.132: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-107'
Dec  3 16:01:55.301: INFO: stderr: "No resources found in kubectl-107 namespace.\n"
Dec  3 16:01:55.301: INFO: stdout: ""
Dec  3 16:01:55.301: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-107 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 16:01:55.450: INFO: stderr: ""
Dec  3 16:01:55.450: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:01:55.450: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-107" for this suite.
Dec  3 16:02:01.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:02:02.134: INFO: namespace kubectl-107 deletion completed in 6.650917742s
•SSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:02:02.134: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2211
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:02:02.357: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec  3 16:02:02.396: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  3 16:02:04.438: INFO: Creating deployment "test-rolling-update-deployment"
Dec  3 16:02:04.456: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec  3 16:02:04.492: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec  3 16:02:04.528: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985724, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985724, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985724, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985724, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 16:02:06.547: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec  3 16:02:06.598: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-2211 /apis/apps/v1/namespaces/deployment-2211/deployments/test-rolling-update-deployment adc0e83a-a1ed-4c48-90ec-bf5481968ae4 19417 1 2019-12-03 16:02:04 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0059e16b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-03 16:02:04 +0000 UTC,LastTransitionTime:2019-12-03 16:02:04 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2019-12-03 16:02:05 +0000 UTC,LastTransitionTime:2019-12-03 16:02:04 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 16:02:06.616: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-2211 /apis/apps/v1/namespaces/deployment-2211/replicasets/test-rolling-update-deployment-55d946486 dad5fb4d-f90c-42ee-a444-9c8b5a0868a5 19410 1 2019-12-03 16:02:04 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment adc0e83a-a1ed-4c48-90ec-bf5481968ae4 0xc003cce3a0 0xc003cce3a1}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003cce408 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec  3 16:02:06.616: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec  3 16:02:06.617: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-2211 /apis/apps/v1/namespaces/deployment-2211/replicasets/test-rolling-update-controller 8bb2f102-2a3a-4f50-aebc-3ae410a717c5 19416 2 2019-12-03 16:02:02 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment adc0e83a-a1ed-4c48-90ec-bf5481968ae4 0xc003cce2d7 0xc003cce2d8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003cce338 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 16:02:06.635: INFO: Pod "test-rolling-update-deployment-55d946486-8cqpb" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-8cqpb test-rolling-update-deployment-55d946486- deployment-2211 /api/v1/namespaces/deployment-2211/pods/test-rolling-update-deployment-55d946486-8cqpb 8ce13fbf-6002-4919-bcb6-a3fe9560444d 19409 0 2019-12-03 16:02:04 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[cni.projectcalico.org/podIP:100.64.1.197/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 dad5fb4d-f90c-42ee-a444-9c8b5a0868a5 0xc003cce870 0xc003cce871}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-j29cb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-j29cb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-j29cb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:02:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:02:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:02:05 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:02:04 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.1.197,StartTime:2019-12-03 16:02:04 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 16:02:05 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://a65f4b9bb72a5bfa682ebdde5b7f4294e01101c926c2834cc6ab1e7e2b9d1e84,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.197,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:02:06.635: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2211" for this suite.
Dec  3 16:02:12.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:02:13.321: INFO: namespace deployment-2211 deletion completed in 6.653874758s
•SSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:02:13.322: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2724
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Dec  3 16:02:17.651: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec  3 16:02:32.830: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:02:32.848: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2724" for this suite.
Dec  3 16:02:38.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:02:39.527: INFO: namespace pods-2724 deletion completed in 6.661778867s
•SSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:02:39.527: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-1407
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-1407/secret-test-3430cf14-61a5-43dd-b536-6f6a91445546
STEP: Creating a pod to test consume secrets
Dec  3 16:02:39.787: INFO: Waiting up to 5m0s for pod "pod-configmaps-b66f518e-edab-4852-bf68-6e53a4bff7dc" in namespace "secrets-1407" to be "success or failure"
Dec  3 16:02:39.806: INFO: Pod "pod-configmaps-b66f518e-edab-4852-bf68-6e53a4bff7dc": Phase="Pending", Reason="", readiness=false. Elapsed: 18.229714ms
Dec  3 16:02:41.825: INFO: Pod "pod-configmaps-b66f518e-edab-4852-bf68-6e53a4bff7dc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.036953911s
STEP: Saw pod success
Dec  3 16:02:41.825: INFO: Pod "pod-configmaps-b66f518e-edab-4852-bf68-6e53a4bff7dc" satisfied condition "success or failure"
Dec  3 16:02:41.842: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-configmaps-b66f518e-edab-4852-bf68-6e53a4bff7dc container env-test: <nil>
STEP: delete the pod
Dec  3 16:02:41.896: INFO: Waiting for pod pod-configmaps-b66f518e-edab-4852-bf68-6e53a4bff7dc to disappear
Dec  3 16:02:41.913: INFO: Pod pod-configmaps-b66f518e-edab-4852-bf68-6e53a4bff7dc no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:02:41.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-1407" for this suite.
Dec  3 16:02:47.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:02:48.657: INFO: namespace secrets-1407 deletion completed in 6.710104468s
•SSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:02:48.657: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-5752
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-q5jf5 in namespace proxy-5752
I1203 16:02:48.931098    5095 runners.go:184] Created replication controller with name: proxy-service-q5jf5, namespace: proxy-5752, replica count: 1
I1203 16:02:49.981910    5095 runners.go:184] proxy-service-q5jf5 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 16:02:50.982259    5095 runners.go:184] proxy-service-q5jf5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 16:02:51.982550    5095 runners.go:184] proxy-service-q5jf5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 16:02:52.983022    5095 runners.go:184] proxy-service-q5jf5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 16:02:53.983336    5095 runners.go:184] proxy-service-q5jf5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 16:02:54.983671    5095 runners.go:184] proxy-service-q5jf5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 16:02:55.983965    5095 runners.go:184] proxy-service-q5jf5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 16:02:56.984281    5095 runners.go:184] proxy-service-q5jf5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 16:02:57.984636    5095 runners.go:184] proxy-service-q5jf5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 16:02:58.984911    5095 runners.go:184] proxy-service-q5jf5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 16:02:59.985164    5095 runners.go:184] proxy-service-q5jf5 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 16:03:00.985395    5095 runners.go:184] proxy-service-q5jf5 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 16:03:01.002: INFO: setup took 12.118157699s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec  3 16:03:01.035: INFO: (0) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 32.302741ms)
Dec  3 16:03:01.035: INFO: (0) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname2/proxy/: bar (200; 32.481376ms)
Dec  3 16:03:01.036: INFO: (0) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname2/proxy/: bar (200; 32.941025ms)
Dec  3 16:03:01.036: INFO: (0) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 32.898957ms)
Dec  3 16:03:01.036: INFO: (0) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">... (200; 32.789226ms)
Dec  3 16:03:01.036: INFO: (0) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 33.441364ms)
Dec  3 16:03:01.045: INFO: (0) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 42.552418ms)
Dec  3 16:03:01.045: INFO: (0) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">test<... (200; 42.586382ms)
Dec  3 16:03:01.051: INFO: (0) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname1/proxy/: foo (200; 47.687624ms)
Dec  3 16:03:01.051: INFO: (0) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:462/proxy/: tls qux (200; 47.777868ms)
Dec  3 16:03:01.051: INFO: (0) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname1/proxy/: foo (200; 47.756783ms)
Dec  3 16:03:01.051: INFO: (0) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/tlsrewritem... (200; 47.95619ms)
Dec  3 16:03:01.051: INFO: (0) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/rewriteme">test</a> (200; 47.812296ms)
Dec  3 16:03:01.051: INFO: (0) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:460/proxy/: tls baz (200; 47.833968ms)
Dec  3 16:03:01.052: INFO: (0) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname2/proxy/: tls qux (200; 49.251792ms)
Dec  3 16:03:01.063: INFO: (0) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname1/proxy/: tls baz (200; 60.606631ms)
Dec  3 16:03:01.084: INFO: (1) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">test<... (200; 20.685551ms)
Dec  3 16:03:01.086: INFO: (1) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 22.371846ms)
Dec  3 16:03:01.086: INFO: (1) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 22.244118ms)
Dec  3 16:03:01.087: INFO: (1) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/rewriteme">test</a> (200; 23.92454ms)
Dec  3 16:03:01.087: INFO: (1) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname1/proxy/: foo (200; 23.749716ms)
Dec  3 16:03:01.088: INFO: (1) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">... (200; 23.752202ms)
Dec  3 16:03:01.087: INFO: (1) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname1/proxy/: tls baz (200; 23.802308ms)
Dec  3 16:03:01.090: INFO: (1) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname2/proxy/: tls qux (200; 25.888577ms)
Dec  3 16:03:01.090: INFO: (1) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname2/proxy/: bar (200; 25.969328ms)
Dec  3 16:03:01.090: INFO: (1) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:460/proxy/: tls baz (200; 25.985155ms)
Dec  3 16:03:01.091: INFO: (1) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/tlsrewritem... (200; 26.952269ms)
Dec  3 16:03:01.091: INFO: (1) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:462/proxy/: tls qux (200; 26.809058ms)
Dec  3 16:03:01.092: INFO: (1) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 27.921323ms)
Dec  3 16:03:01.092: INFO: (1) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 27.83514ms)
Dec  3 16:03:01.093: INFO: (1) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname1/proxy/: foo (200; 29.513154ms)
Dec  3 16:03:01.095: INFO: (1) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname2/proxy/: bar (200; 31.52221ms)
Dec  3 16:03:01.118: INFO: (2) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">... (200; 22.119861ms)
Dec  3 16:03:01.118: INFO: (2) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 22.204131ms)
Dec  3 16:03:01.118: INFO: (2) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:460/proxy/: tls baz (200; 22.200849ms)
Dec  3 16:03:01.118: INFO: (2) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 22.057603ms)
Dec  3 16:03:01.118: INFO: (2) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/rewriteme">test</a> (200; 22.142325ms)
Dec  3 16:03:01.118: INFO: (2) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname2/proxy/: tls qux (200; 22.927538ms)
Dec  3 16:03:01.118: INFO: (2) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname1/proxy/: tls baz (200; 22.858622ms)
Dec  3 16:03:01.118: INFO: (2) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">test<... (200; 23.071203ms)
Dec  3 16:03:01.118: INFO: (2) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/tlsrewritem... (200; 22.935203ms)
Dec  3 16:03:01.118: INFO: (2) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 22.996723ms)
Dec  3 16:03:01.118: INFO: (2) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 22.90405ms)
Dec  3 16:03:01.118: INFO: (2) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:462/proxy/: tls qux (200; 23.118212ms)
Dec  3 16:03:01.121: INFO: (2) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname1/proxy/: foo (200; 24.933865ms)
Dec  3 16:03:01.163: INFO: (2) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname1/proxy/: foo (200; 67.661374ms)
Dec  3 16:03:01.163: INFO: (2) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname2/proxy/: bar (200; 67.838488ms)
Dec  3 16:03:01.163: INFO: (2) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname2/proxy/: bar (200; 67.87585ms)
Dec  3 16:03:01.185: INFO: (3) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 20.958798ms)
Dec  3 16:03:01.185: INFO: (3) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 21.001071ms)
Dec  3 16:03:01.185: INFO: (3) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/rewriteme">test</a> (200; 21.091554ms)
Dec  3 16:03:01.185: INFO: (3) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">test<... (200; 21.067338ms)
Dec  3 16:03:01.185: INFO: (3) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:460/proxy/: tls baz (200; 21.084122ms)
Dec  3 16:03:01.185: INFO: (3) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">... (200; 21.057154ms)
Dec  3 16:03:01.185: INFO: (3) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:462/proxy/: tls qux (200; 21.22425ms)
Dec  3 16:03:01.185: INFO: (3) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/tlsrewritem... (200; 21.050463ms)
Dec  3 16:03:01.187: INFO: (3) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 23.285458ms)
Dec  3 16:03:01.187: INFO: (3) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 23.134582ms)
Dec  3 16:03:01.187: INFO: (3) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname1/proxy/: tls baz (200; 23.171756ms)
Dec  3 16:03:01.187: INFO: (3) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname2/proxy/: tls qux (200; 23.255486ms)
Dec  3 16:03:01.194: INFO: (3) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname2/proxy/: bar (200; 30.199947ms)
Dec  3 16:03:01.194: INFO: (3) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname1/proxy/: foo (200; 30.264987ms)
Dec  3 16:03:01.195: INFO: (3) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname1/proxy/: foo (200; 31.680448ms)
Dec  3 16:03:01.199: INFO: (3) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname2/proxy/: bar (200; 35.716804ms)
Dec  3 16:03:01.220: INFO: (4) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">test<... (200; 20.628452ms)
Dec  3 16:03:01.220: INFO: (4) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/rewriteme">test</a> (200; 20.817846ms)
Dec  3 16:03:01.220: INFO: (4) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/tlsrewritem... (200; 20.822792ms)
Dec  3 16:03:01.220: INFO: (4) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:462/proxy/: tls qux (200; 20.656746ms)
Dec  3 16:03:01.220: INFO: (4) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">... (200; 20.736902ms)
Dec  3 16:03:01.220: INFO: (4) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 20.727814ms)
Dec  3 16:03:01.220: INFO: (4) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 20.695952ms)
Dec  3 16:03:01.222: INFO: (4) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 22.611619ms)
Dec  3 16:03:01.222: INFO: (4) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname2/proxy/: tls qux (200; 22.618804ms)
Dec  3 16:03:01.222: INFO: (4) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:460/proxy/: tls baz (200; 22.711069ms)
Dec  3 16:03:01.222: INFO: (4) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname1/proxy/: tls baz (200; 22.639526ms)
Dec  3 16:03:01.222: INFO: (4) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 22.7193ms)
Dec  3 16:03:01.225: INFO: (4) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname2/proxy/: bar (200; 25.946528ms)
Dec  3 16:03:01.267: INFO: (4) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname2/proxy/: bar (200; 67.321448ms)
Dec  3 16:03:01.267: INFO: (4) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname1/proxy/: foo (200; 67.340167ms)
Dec  3 16:03:01.267: INFO: (4) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname1/proxy/: foo (200; 67.313418ms)
Dec  3 16:03:01.288: INFO: (5) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 21.09712ms)
Dec  3 16:03:01.288: INFO: (5) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">... (200; 21.108135ms)
Dec  3 16:03:01.288: INFO: (5) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/rewriteme">test</a> (200; 21.288771ms)
Dec  3 16:03:01.288: INFO: (5) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 21.189427ms)
Dec  3 16:03:01.289: INFO: (5) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 21.284465ms)
Dec  3 16:03:01.289: INFO: (5) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 21.223637ms)
Dec  3 16:03:01.290: INFO: (5) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">test<... (200; 22.597221ms)
Dec  3 16:03:01.290: INFO: (5) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:460/proxy/: tls baz (200; 22.773218ms)
Dec  3 16:03:01.290: INFO: (5) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/tlsrewritem... (200; 22.59686ms)
Dec  3 16:03:01.291: INFO: (5) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:462/proxy/: tls qux (200; 24.004013ms)
Dec  3 16:03:01.291: INFO: (5) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname1/proxy/: tls baz (200; 24.122642ms)
Dec  3 16:03:01.291: INFO: (5) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname1/proxy/: foo (200; 24.031287ms)
Dec  3 16:03:01.291: INFO: (5) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname2/proxy/: tls qux (200; 24.09373ms)
Dec  3 16:03:01.293: INFO: (5) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname2/proxy/: bar (200; 25.742439ms)
Dec  3 16:03:01.293: INFO: (5) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname2/proxy/: bar (200; 25.672486ms)
Dec  3 16:03:01.293: INFO: (5) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname1/proxy/: foo (200; 25.712041ms)
Dec  3 16:03:01.314: INFO: (6) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 20.874442ms)
Dec  3 16:03:01.314: INFO: (6) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/rewriteme">test</a> (200; 20.747887ms)
Dec  3 16:03:01.314: INFO: (6) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:460/proxy/: tls baz (200; 20.835724ms)
Dec  3 16:03:01.314: INFO: (6) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 20.85814ms)
Dec  3 16:03:01.315: INFO: (6) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 21.472477ms)
Dec  3 16:03:01.315: INFO: (6) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname1/proxy/: tls baz (200; 21.591734ms)
Dec  3 16:03:01.315: INFO: (6) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/tlsrewritem... (200; 21.453559ms)
Dec  3 16:03:01.315: INFO: (6) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 21.555821ms)
Dec  3 16:03:01.315: INFO: (6) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">test<... (200; 21.608105ms)
Dec  3 16:03:01.315: INFO: (6) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">... (200; 21.628887ms)
Dec  3 16:03:01.315: INFO: (6) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:462/proxy/: tls qux (200; 21.740658ms)
Dec  3 16:03:01.315: INFO: (6) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname2/proxy/: tls qux (200; 21.798387ms)
Dec  3 16:03:01.318: INFO: (6) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname2/proxy/: bar (200; 25.084959ms)
Dec  3 16:03:01.318: INFO: (6) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname1/proxy/: foo (200; 25.110989ms)
Dec  3 16:03:01.318: INFO: (6) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname1/proxy/: foo (200; 25.076255ms)
Dec  3 16:03:01.320: INFO: (6) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname2/proxy/: bar (200; 26.882567ms)
Dec  3 16:03:01.341: INFO: (7) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">... (200; 21.116333ms)
Dec  3 16:03:01.342: INFO: (7) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/rewriteme">test</a> (200; 21.229699ms)
Dec  3 16:03:01.341: INFO: (7) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 21.064464ms)
Dec  3 16:03:01.342: INFO: (7) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname1/proxy/: tls baz (200; 21.059989ms)
Dec  3 16:03:01.342: INFO: (7) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 21.047566ms)
Dec  3 16:03:01.342: INFO: (7) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:460/proxy/: tls baz (200; 21.116434ms)
Dec  3 16:03:01.343: INFO: (7) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname2/proxy/: tls qux (200; 22.325953ms)
Dec  3 16:03:01.343: INFO: (7) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">test<... (200; 22.215057ms)
Dec  3 16:03:01.343: INFO: (7) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname1/proxy/: foo (200; 22.321519ms)
Dec  3 16:03:01.343: INFO: (7) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:462/proxy/: tls qux (200; 22.491737ms)
Dec  3 16:03:01.343: INFO: (7) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname2/proxy/: bar (200; 22.308281ms)
Dec  3 16:03:01.343: INFO: (7) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/tlsrewritem... (200; 22.424214ms)
Dec  3 16:03:01.345: INFO: (7) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname2/proxy/: bar (200; 24.642961ms)
Dec  3 16:03:01.345: INFO: (7) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname1/proxy/: foo (200; 24.57223ms)
Dec  3 16:03:01.387: INFO: (7) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 67.113868ms)
Dec  3 16:03:01.387: INFO: (7) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 66.968411ms)
Dec  3 16:03:01.410: INFO: (8) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 22.272089ms)
Dec  3 16:03:01.410: INFO: (8) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">... (200; 22.389016ms)
Dec  3 16:03:01.410: INFO: (8) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname2/proxy/: bar (200; 22.526302ms)
Dec  3 16:03:01.410: INFO: (8) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">test<... (200; 22.425199ms)
Dec  3 16:03:01.410: INFO: (8) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/rewriteme">test</a> (200; 22.434661ms)
Dec  3 16:03:01.410: INFO: (8) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 22.604073ms)
Dec  3 16:03:01.410: INFO: (8) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname2/proxy/: tls qux (200; 22.44068ms)
Dec  3 16:03:01.410: INFO: (8) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 22.452405ms)
Dec  3 16:03:01.410: INFO: (8) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:462/proxy/: tls qux (200; 22.489833ms)
Dec  3 16:03:01.411: INFO: (8) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/tlsrewritem... (200; 23.664179ms)
Dec  3 16:03:01.413: INFO: (8) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname1/proxy/: tls baz (200; 25.504227ms)
Dec  3 16:03:01.413: INFO: (8) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:460/proxy/: tls baz (200; 25.636599ms)
Dec  3 16:03:01.415: INFO: (8) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 27.342264ms)
Dec  3 16:03:01.415: INFO: (8) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname1/proxy/: foo (200; 27.4707ms)
Dec  3 16:03:01.415: INFO: (8) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname1/proxy/: foo (200; 27.410037ms)
Dec  3 16:03:01.415: INFO: (8) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname2/proxy/: bar (200; 27.441485ms)
Dec  3 16:03:01.437: INFO: (9) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname1/proxy/: foo (200; 21.82049ms)
Dec  3 16:03:01.437: INFO: (9) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname2/proxy/: bar (200; 21.746144ms)
Dec  3 16:03:01.437: INFO: (9) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname1/proxy/: tls baz (200; 21.699284ms)
Dec  3 16:03:01.438: INFO: (9) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/rewriteme">test</a> (200; 22.830777ms)
Dec  3 16:03:01.438: INFO: (9) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">test<... (200; 22.994291ms)
Dec  3 16:03:01.438: INFO: (9) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 23.065573ms)
Dec  3 16:03:01.438: INFO: (9) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:462/proxy/: tls qux (200; 22.949746ms)
Dec  3 16:03:01.438: INFO: (9) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:460/proxy/: tls baz (200; 22.899471ms)
Dec  3 16:03:01.438: INFO: (9) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname2/proxy/: bar (200; 22.97316ms)
Dec  3 16:03:01.438: INFO: (9) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname2/proxy/: tls qux (200; 22.924528ms)
Dec  3 16:03:01.438: INFO: (9) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/tlsrewritem... (200; 22.939005ms)
Dec  3 16:03:01.438: INFO: (9) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">... (200; 23.155336ms)
Dec  3 16:03:01.442: INFO: (9) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 26.248945ms)
Dec  3 16:03:01.442: INFO: (9) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 26.324311ms)
Dec  3 16:03:01.442: INFO: (9) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 26.380673ms)
Dec  3 16:03:01.442: INFO: (9) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname1/proxy/: foo (200; 26.408098ms)
Dec  3 16:03:01.463: INFO: (10) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">test<... (200; 20.733681ms)
Dec  3 16:03:01.463: INFO: (10) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/tlsrewritem... (200; 20.745344ms)
Dec  3 16:03:01.463: INFO: (10) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:460/proxy/: tls baz (200; 20.800226ms)
Dec  3 16:03:01.463: INFO: (10) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 20.802889ms)
Dec  3 16:03:01.463: INFO: (10) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">... (200; 20.723838ms)
Dec  3 16:03:01.464: INFO: (10) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/rewriteme">test</a> (200; 21.875802ms)
Dec  3 16:03:01.464: INFO: (10) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 21.957356ms)
Dec  3 16:03:01.464: INFO: (10) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:462/proxy/: tls qux (200; 22.111625ms)
Dec  3 16:03:01.464: INFO: (10) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 21.848999ms)
Dec  3 16:03:01.466: INFO: (10) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname2/proxy/: tls qux (200; 23.557068ms)
Dec  3 16:03:01.466: INFO: (10) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 23.775638ms)
Dec  3 16:03:01.466: INFO: (10) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname1/proxy/: tls baz (200; 23.775319ms)
Dec  3 16:03:01.468: INFO: (10) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname1/proxy/: foo (200; 26.350458ms)
Dec  3 16:03:01.471: INFO: (10) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname2/proxy/: bar (200; 28.656022ms)
Dec  3 16:03:01.471: INFO: (10) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname2/proxy/: bar (200; 28.494727ms)
Dec  3 16:03:01.472: INFO: (10) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname1/proxy/: foo (200; 30.410974ms)
Dec  3 16:03:01.497: INFO: (11) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname1/proxy/: foo (200; 24.560698ms)
Dec  3 16:03:01.497: INFO: (11) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname2/proxy/: tls qux (200; 24.763232ms)
Dec  3 16:03:01.497: INFO: (11) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname1/proxy/: foo (200; 24.828287ms)
Dec  3 16:03:01.497: INFO: (11) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname1/proxy/: tls baz (200; 24.621766ms)
Dec  3 16:03:01.497: INFO: (11) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname2/proxy/: bar (200; 24.744087ms)
Dec  3 16:03:01.499: INFO: (11) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:462/proxy/: tls qux (200; 26.438511ms)
Dec  3 16:03:01.499: INFO: (11) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/rewriteme">test</a> (200; 26.579425ms)
Dec  3 16:03:01.499: INFO: (11) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">... (200; 26.465121ms)
Dec  3 16:03:01.499: INFO: (11) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:460/proxy/: tls baz (200; 26.720007ms)
Dec  3 16:03:01.499: INFO: (11) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname2/proxy/: bar (200; 26.425428ms)
Dec  3 16:03:01.499: INFO: (11) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">test<... (200; 26.663566ms)
Dec  3 16:03:01.499: INFO: (11) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/tlsrewritem... (200; 26.594456ms)
Dec  3 16:03:01.500: INFO: (11) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 27.564671ms)
Dec  3 16:03:01.504: INFO: (11) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 31.44808ms)
Dec  3 16:03:01.504: INFO: (11) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 31.535563ms)
Dec  3 16:03:01.504: INFO: (11) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 31.402276ms)
Dec  3 16:03:01.525: INFO: (12) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:460/proxy/: tls baz (200; 21.010199ms)
Dec  3 16:03:01.527: INFO: (12) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:462/proxy/: tls qux (200; 23.017687ms)
Dec  3 16:03:01.527: INFO: (12) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname2/proxy/: bar (200; 22.92268ms)
Dec  3 16:03:01.527: INFO: (12) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/rewriteme">test</a> (200; 22.935803ms)
Dec  3 16:03:01.527: INFO: (12) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname1/proxy/: foo (200; 22.995778ms)
Dec  3 16:03:01.529: INFO: (12) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname2/proxy/: tls qux (200; 24.990023ms)
Dec  3 16:03:01.529: INFO: (12) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 24.892449ms)
Dec  3 16:03:01.529: INFO: (12) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">... (200; 24.944305ms)
Dec  3 16:03:01.529: INFO: (12) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 25.063777ms)
Dec  3 16:03:01.529: INFO: (12) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname1/proxy/: tls baz (200; 25.009843ms)
Dec  3 16:03:01.529: INFO: (12) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">test<... (200; 24.959622ms)
Dec  3 16:03:01.529: INFO: (12) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/tlsrewritem... (200; 24.910205ms)
Dec  3 16:03:01.531: INFO: (12) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname2/proxy/: bar (200; 26.423503ms)
Dec  3 16:03:01.531: INFO: (12) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 26.480882ms)
Dec  3 16:03:01.532: INFO: (12) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 27.913814ms)
Dec  3 16:03:01.532: INFO: (12) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname1/proxy/: foo (200; 28.009084ms)
Dec  3 16:03:01.556: INFO: (13) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 23.004641ms)
Dec  3 16:03:01.556: INFO: (13) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">... (200; 23.070347ms)
Dec  3 16:03:01.556: INFO: (13) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">test<... (200; 23.143777ms)
Dec  3 16:03:01.556: INFO: (13) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:460/proxy/: tls baz (200; 23.181365ms)
Dec  3 16:03:01.556: INFO: (13) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 23.220226ms)
Dec  3 16:03:01.556: INFO: (13) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:462/proxy/: tls qux (200; 23.050354ms)
Dec  3 16:03:01.556: INFO: (13) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/tlsrewritem... (200; 23.162069ms)
Dec  3 16:03:01.556: INFO: (13) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 23.274738ms)
Dec  3 16:03:01.557: INFO: (13) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/rewriteme">test</a> (200; 24.583597ms)
Dec  3 16:03:01.557: INFO: (13) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 24.630046ms)
Dec  3 16:03:01.559: INFO: (13) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname2/proxy/: tls qux (200; 26.763353ms)
Dec  3 16:03:01.559: INFO: (13) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname1/proxy/: tls baz (200; 26.871382ms)
Dec  3 16:03:01.562: INFO: (13) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname1/proxy/: foo (200; 28.971631ms)
Dec  3 16:03:01.563: INFO: (13) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname1/proxy/: foo (200; 30.689651ms)
Dec  3 16:03:01.563: INFO: (13) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname2/proxy/: bar (200; 30.677244ms)
Dec  3 16:03:01.565: INFO: (13) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname2/proxy/: bar (200; 32.655544ms)
Dec  3 16:03:01.586: INFO: (14) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/rewriteme">test</a> (200; 20.99695ms)
Dec  3 16:03:01.587: INFO: (14) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:460/proxy/: tls baz (200; 21.80496ms)
Dec  3 16:03:01.587: INFO: (14) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/tlsrewritem... (200; 21.86564ms)
Dec  3 16:03:01.587: INFO: (14) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">test<... (200; 22.085509ms)
Dec  3 16:03:01.587: INFO: (14) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 21.890467ms)
Dec  3 16:03:01.587: INFO: (14) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 21.851169ms)
Dec  3 16:03:01.589: INFO: (14) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 23.368562ms)
Dec  3 16:03:01.589: INFO: (14) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:462/proxy/: tls qux (200; 23.405021ms)
Dec  3 16:03:01.589: INFO: (14) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">... (200; 23.318547ms)
Dec  3 16:03:01.589: INFO: (14) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname1/proxy/: tls baz (200; 23.327075ms)
Dec  3 16:03:01.589: INFO: (14) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 23.339431ms)
Dec  3 16:03:01.589: INFO: (14) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname2/proxy/: tls qux (200; 23.683416ms)
Dec  3 16:03:01.634: INFO: (14) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname1/proxy/: foo (200; 69.096405ms)
Dec  3 16:03:01.634: INFO: (14) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname2/proxy/: bar (200; 68.937855ms)
Dec  3 16:03:01.634: INFO: (14) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname1/proxy/: foo (200; 69.117447ms)
Dec  3 16:03:01.634: INFO: (14) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname2/proxy/: bar (200; 69.062249ms)
Dec  3 16:03:01.655: INFO: (15) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">test<... (200; 19.855226ms)
Dec  3 16:03:01.656: INFO: (15) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/rewriteme">test</a> (200; 21.562876ms)
Dec  3 16:03:01.656: INFO: (15) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:460/proxy/: tls baz (200; 21.660278ms)
Dec  3 16:03:01.656: INFO: (15) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">... (200; 21.622601ms)
Dec  3 16:03:01.656: INFO: (15) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 21.63935ms)
Dec  3 16:03:01.656: INFO: (15) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/tlsrewritem... (200; 21.699ms)
Dec  3 16:03:01.657: INFO: (15) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:462/proxy/: tls qux (200; 22.175872ms)
Dec  3 16:03:01.657: INFO: (15) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 22.09104ms)
Dec  3 16:03:01.657: INFO: (15) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname2/proxy/: tls qux (200; 22.007266ms)
Dec  3 16:03:01.657: INFO: (15) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 22.079477ms)
Dec  3 16:03:01.657: INFO: (15) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname1/proxy/: tls baz (200; 22.183054ms)
Dec  3 16:03:01.657: INFO: (15) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 22.029981ms)
Dec  3 16:03:01.660: INFO: (15) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname1/proxy/: foo (200; 25.539366ms)
Dec  3 16:03:01.702: INFO: (15) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname2/proxy/: bar (200; 67.587255ms)
Dec  3 16:03:01.702: INFO: (15) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname1/proxy/: foo (200; 67.59965ms)
Dec  3 16:03:01.702: INFO: (15) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname2/proxy/: bar (200; 67.666972ms)
Dec  3 16:03:01.723: INFO: (16) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/rewriteme">test</a> (200; 20.912609ms)
Dec  3 16:03:01.724: INFO: (16) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 20.809581ms)
Dec  3 16:03:01.724: INFO: (16) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 20.905232ms)
Dec  3 16:03:01.724: INFO: (16) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:462/proxy/: tls qux (200; 20.820956ms)
Dec  3 16:03:01.724: INFO: (16) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">... (200; 20.882111ms)
Dec  3 16:03:01.724: INFO: (16) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 21.061573ms)
Dec  3 16:03:01.724: INFO: (16) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">test<... (200; 21.152301ms)
Dec  3 16:03:01.724: INFO: (16) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 21.348503ms)
Dec  3 16:03:01.725: INFO: (16) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname2/proxy/: tls qux (200; 22.352896ms)
Dec  3 16:03:01.725: INFO: (16) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:460/proxy/: tls baz (200; 22.42288ms)
Dec  3 16:03:01.725: INFO: (16) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/tlsrewritem... (200; 22.57808ms)
Dec  3 16:03:01.727: INFO: (16) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname1/proxy/: tls baz (200; 23.959837ms)
Dec  3 16:03:01.727: INFO: (16) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname1/proxy/: foo (200; 24.038563ms)
Dec  3 16:03:01.727: INFO: (16) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname2/proxy/: bar (200; 23.940081ms)
Dec  3 16:03:01.731: INFO: (16) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname2/proxy/: bar (200; 28.000246ms)
Dec  3 16:03:01.731: INFO: (16) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname1/proxy/: foo (200; 28.058933ms)
Dec  3 16:03:01.752: INFO: (17) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 20.899257ms)
Dec  3 16:03:01.752: INFO: (17) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:460/proxy/: tls baz (200; 21.05281ms)
Dec  3 16:03:01.752: INFO: (17) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/rewriteme">test</a> (200; 20.926548ms)
Dec  3 16:03:01.752: INFO: (17) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 21.006414ms)
Dec  3 16:03:01.752: INFO: (17) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 21.265335ms)
Dec  3 16:03:01.753: INFO: (17) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:462/proxy/: tls qux (200; 22.166245ms)
Dec  3 16:03:01.753: INFO: (17) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 22.304201ms)
Dec  3 16:03:01.753: INFO: (17) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/tlsrewritem... (200; 22.328907ms)
Dec  3 16:03:01.753: INFO: (17) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">test<... (200; 22.225296ms)
Dec  3 16:03:01.753: INFO: (17) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">... (200; 22.417125ms)
Dec  3 16:03:01.755: INFO: (17) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname1/proxy/: tls baz (200; 23.887431ms)
Dec  3 16:03:01.755: INFO: (17) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname2/proxy/: tls qux (200; 23.812325ms)
Dec  3 16:03:01.755: INFO: (17) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname1/proxy/: foo (200; 24.038993ms)
Dec  3 16:03:01.755: INFO: (17) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname2/proxy/: bar (200; 23.971117ms)
Dec  3 16:03:01.757: INFO: (17) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname1/proxy/: foo (200; 25.571592ms)
Dec  3 16:03:01.758: INFO: (17) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname2/proxy/: bar (200; 27.226342ms)
Dec  3 16:03:01.779: INFO: (18) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">... (200; 20.896478ms)
Dec  3 16:03:01.779: INFO: (18) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/rewriteme">test</a> (200; 21.075628ms)
Dec  3 16:03:01.779: INFO: (18) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 20.792245ms)
Dec  3 16:03:01.779: INFO: (18) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/tlsrewritem... (200; 20.799131ms)
Dec  3 16:03:01.779: INFO: (18) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:462/proxy/: tls qux (200; 20.830158ms)
Dec  3 16:03:01.779: INFO: (18) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 20.884931ms)
Dec  3 16:03:01.780: INFO: (18) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">test<... (200; 21.901403ms)
Dec  3 16:03:01.780: INFO: (18) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 21.932664ms)
Dec  3 16:03:01.780: INFO: (18) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 22.027126ms)
Dec  3 16:03:01.780: INFO: (18) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:460/proxy/: tls baz (200; 21.894773ms)
Dec  3 16:03:01.780: INFO: (18) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname1/proxy/: tls baz (200; 22.058789ms)
Dec  3 16:03:01.782: INFO: (18) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname2/proxy/: tls qux (200; 23.696236ms)
Dec  3 16:03:01.783: INFO: (18) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname2/proxy/: bar (200; 24.618307ms)
Dec  3 16:03:01.783: INFO: (18) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname1/proxy/: foo (200; 24.784415ms)
Dec  3 16:03:01.783: INFO: (18) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname1/proxy/: foo (200; 24.756422ms)
Dec  3 16:03:01.786: INFO: (18) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname2/proxy/: bar (200; 27.139094ms)
Dec  3 16:03:01.807: INFO: (19) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 20.615392ms)
Dec  3 16:03:01.807: INFO: (19) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">test<... (200; 21.373435ms)
Dec  3 16:03:01.807: INFO: (19) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:160/proxy/: foo (200; 21.248781ms)
Dec  3 16:03:01.807: INFO: (19) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 21.469622ms)
Dec  3 16:03:01.807: INFO: (19) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:443/proxy/tlsrewritem... (200; 21.211133ms)
Dec  3 16:03:01.807: INFO: (19) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx/proxy/rewriteme">test</a> (200; 21.471536ms)
Dec  3 16:03:01.807: INFO: (19) /api/v1/namespaces/proxy-5752/pods/proxy-service-q5jf5-fb2kx:162/proxy/: bar (200; 21.366302ms)
Dec  3 16:03:01.809: INFO: (19) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname1/proxy/: tls baz (200; 22.888371ms)
Dec  3 16:03:01.809: INFO: (19) /api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/: <a href="/api/v1/namespaces/proxy-5752/pods/http:proxy-service-q5jf5-fb2kx:1080/proxy/rewriteme">... (200; 22.897948ms)
Dec  3 16:03:01.809: INFO: (19) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:462/proxy/: tls qux (200; 22.984779ms)
Dec  3 16:03:01.809: INFO: (19) /api/v1/namespaces/proxy-5752/pods/https:proxy-service-q5jf5-fb2kx:460/proxy/: tls baz (200; 22.955197ms)
Dec  3 16:03:01.809: INFO: (19) /api/v1/namespaces/proxy-5752/services/https:proxy-service-q5jf5:tlsportname2/proxy/: tls qux (200; 23.035577ms)
Dec  3 16:03:01.810: INFO: (19) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname1/proxy/: foo (200; 24.436349ms)
Dec  3 16:03:01.810: INFO: (19) /api/v1/namespaces/proxy-5752/services/http:proxy-service-q5jf5:portname2/proxy/: bar (200; 24.405063ms)
Dec  3 16:03:01.810: INFO: (19) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname1/proxy/: foo (200; 24.479515ms)
Dec  3 16:03:01.812: INFO: (19) /api/v1/namespaces/proxy-5752/services/proxy-service-q5jf5:portname2/proxy/: bar (200; 25.942738ms)
STEP: deleting ReplicationController proxy-service-q5jf5 in namespace proxy-5752, will wait for the garbage collector to delete the pods
Dec  3 16:03:01.898: INFO: Deleting ReplicationController proxy-service-q5jf5 took: 19.33583ms
Dec  3 16:03:01.999: INFO: Terminating ReplicationController proxy-service-q5jf5 pods took: 100.354219ms
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:03:10.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5752" for this suite.
Dec  3 16:03:16.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:03:17.487: INFO: namespace proxy-5752 deletion completed in 6.653226572s
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:03:17.487: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3402
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  3 16:03:17.716: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-3402'
Dec  3 16:03:17.891: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 16:03:17.891: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Dec  3 16:03:17.908: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete jobs e2e-test-httpd-job --namespace=kubectl-3402'
Dec  3 16:03:18.084: INFO: stderr: ""
Dec  3 16:03:18.084: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:03:18.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3402" for this suite.
Dec  3 16:03:24.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:03:24.760: INFO: namespace kubectl-3402 deletion completed in 6.658174581s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:03:24.761: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3628
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 16:03:25.678: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985805, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985805, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985805, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985805, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 16:03:27.696: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985805, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985805, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985805, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985805, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 16:03:30.725: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:03:31.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3628" for this suite.
Dec  3 16:03:37.170: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:03:37.774: INFO: namespace webhook-3628 deletion completed in 6.656211791s
STEP: Destroying namespace "webhook-3628-markers" for this suite.
Dec  3 16:03:43.827: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:03:44.416: INFO: namespace webhook-3628-markers deletion completed in 6.642171918s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:03:44.486: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9252
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-c64f4bc7-2c11-44ca-8ad4-e220259fa400
STEP: Creating secret with name secret-projected-all-test-volume-ab916915-295f-402e-926d-18d4ae20a5f6
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec  3 16:03:44.772: INFO: Waiting up to 5m0s for pod "projected-volume-dd77ce47-24ff-4f85-a763-c07dd5904e8a" in namespace "projected-9252" to be "success or failure"
Dec  3 16:03:44.789: INFO: Pod "projected-volume-dd77ce47-24ff-4f85-a763-c07dd5904e8a": Phase="Pending", Reason="", readiness=false. Elapsed: 17.010426ms
Dec  3 16:03:46.807: INFO: Pod "projected-volume-dd77ce47-24ff-4f85-a763-c07dd5904e8a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035138617s
STEP: Saw pod success
Dec  3 16:03:46.807: INFO: Pod "projected-volume-dd77ce47-24ff-4f85-a763-c07dd5904e8a" satisfied condition "success or failure"
Dec  3 16:03:46.825: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod projected-volume-dd77ce47-24ff-4f85-a763-c07dd5904e8a container projected-all-volume-test: <nil>
STEP: delete the pod
Dec  3 16:03:46.876: INFO: Waiting for pod projected-volume-dd77ce47-24ff-4f85-a763-c07dd5904e8a to disappear
Dec  3 16:03:46.893: INFO: Pod projected-volume-dd77ce47-24ff-4f85-a763-c07dd5904e8a no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:03:46.893: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9252" for this suite.
Dec  3 16:03:52.979: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:03:53.614: INFO: namespace projected-9252 deletion completed in 6.687606774s
•S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:03:53.614: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8214
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  3 16:03:53.859: INFO: Waiting up to 5m0s for pod "pod-7607880f-7fb5-4412-8b59-da1a76ab69e3" in namespace "emptydir-8214" to be "success or failure"
Dec  3 16:03:53.876: INFO: Pod "pod-7607880f-7fb5-4412-8b59-da1a76ab69e3": Phase="Pending", Reason="", readiness=false. Elapsed: 17.226628ms
Dec  3 16:03:55.894: INFO: Pod "pod-7607880f-7fb5-4412-8b59-da1a76ab69e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.035319259s
STEP: Saw pod success
Dec  3 16:03:55.894: INFO: Pod "pod-7607880f-7fb5-4412-8b59-da1a76ab69e3" satisfied condition "success or failure"
Dec  3 16:03:55.911: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-7607880f-7fb5-4412-8b59-da1a76ab69e3 container test-container: <nil>
STEP: delete the pod
Dec  3 16:03:55.966: INFO: Waiting for pod pod-7607880f-7fb5-4412-8b59-da1a76ab69e3 to disappear
Dec  3 16:03:55.982: INFO: Pod pod-7607880f-7fb5-4412-8b59-da1a76ab69e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:03:55.982: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8214" for this suite.
Dec  3 16:04:02.083: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:04:02.682: INFO: namespace emptydir-8214 deletion completed in 6.654104671s
•SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:04:02.682: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-8632
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-8632
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-8632
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-8632
Dec  3 16:04:02.970: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Dec  3 16:04:12.991: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec  3 16:04:13.009: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:04:13.646: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:04:13.646: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:04:13.646: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 16:04:13.663: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  3 16:04:23.683: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 16:04:23.683: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 16:04:23.752: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Dec  3 16:04:23.752: INFO: ss-0  shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:14 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  }]
Dec  3 16:04:23.752: INFO: ss-1                                                  Pending         []
Dec  3 16:04:23.752: INFO: 
Dec  3 16:04:23.752: INFO: StatefulSet ss has not reached scale 3, at 2
Dec  3 16:04:24.773: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.982489153s
Dec  3 16:04:25.792: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.961860679s
Dec  3 16:04:26.810: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.943307217s
Dec  3 16:04:27.829: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.924690165s
Dec  3 16:04:28.847: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.906038999s
Dec  3 16:04:29.866: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.887741865s
Dec  3 16:04:30.884: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.869005099s
Dec  3 16:04:31.902: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.850742372s
Dec  3 16:04:32.921: INFO: Verifying statefulset ss doesn't scale past 3 for another 832.504585ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-8632
Dec  3 16:04:33.939: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:04:34.644: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 16:04:34.644: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 16:04:34.644: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 16:04:34.644: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:04:35.290: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec  3 16:04:35.290: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 16:04:35.290: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 16:04:35.290: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:04:35.924: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec  3 16:04:35.924: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 16:04:35.924: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 16:04:35.945: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:04:35.945: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:04:35.945: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec  3 16:04:35.963: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:04:36.644: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:04:36.644: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:04:36.644: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 16:04:36.644: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:04:37.299: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:04:37.299: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:04:37.299: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 16:04:37.299: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:04:37.921: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:04:37.921: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:04:37.921: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 16:04:37.921: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 16:04:37.938: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 2
Dec  3 16:04:47.979: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 16:04:47.979: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 16:04:47.979: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 16:04:48.041: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Dec  3 16:04:48.041: INFO: ss-0  shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  }]
Dec  3 16:04:48.041: INFO: ss-1  shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  }]
Dec  3 16:04:48.041: INFO: ss-2  shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  }]
Dec  3 16:04:48.042: INFO: 
Dec  3 16:04:48.042: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 16:04:49.061: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Dec  3 16:04:49.061: INFO: ss-0  shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  }]
Dec  3 16:04:49.061: INFO: ss-1  shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  }]
Dec  3 16:04:49.061: INFO: ss-2  shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  }]
Dec  3 16:04:49.061: INFO: 
Dec  3 16:04:49.061: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 16:04:50.084: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Dec  3 16:04:50.084: INFO: ss-0  shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  }]
Dec  3 16:04:50.084: INFO: ss-1  shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  }]
Dec  3 16:04:50.084: INFO: ss-2  shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  }]
Dec  3 16:04:50.084: INFO: 
Dec  3 16:04:50.084: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 16:04:51.103: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Dec  3 16:04:51.103: INFO: ss-0  shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  }]
Dec  3 16:04:51.103: INFO: ss-1  shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  }]
Dec  3 16:04:51.103: INFO: ss-2  shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  }]
Dec  3 16:04:51.103: INFO: 
Dec  3 16:04:51.103: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 16:04:52.122: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Dec  3 16:04:52.122: INFO: ss-0  shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  }]
Dec  3 16:04:52.122: INFO: ss-1  shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  }]
Dec  3 16:04:52.122: INFO: ss-2  shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  }]
Dec  3 16:04:52.122: INFO: 
Dec  3 16:04:52.122: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 16:04:53.141: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Dec  3 16:04:53.141: INFO: ss-0  shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  }]
Dec  3 16:04:53.141: INFO: ss-1  shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  }]
Dec  3 16:04:53.141: INFO: ss-2  shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  }]
Dec  3 16:04:53.141: INFO: 
Dec  3 16:04:53.141: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 16:04:54.159: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Dec  3 16:04:54.159: INFO: ss-0  shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  }]
Dec  3 16:04:54.159: INFO: ss-1  shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  }]
Dec  3 16:04:54.159: INFO: ss-2  shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  }]
Dec  3 16:04:54.159: INFO: 
Dec  3 16:04:54.159: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 16:04:55.178: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Dec  3 16:04:55.178: INFO: ss-0  shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  }]
Dec  3 16:04:55.178: INFO: ss-1  shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  }]
Dec  3 16:04:55.178: INFO: ss-2  shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  }]
Dec  3 16:04:55.178: INFO: 
Dec  3 16:04:55.178: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 16:04:56.196: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Dec  3 16:04:56.196: INFO: ss-0  shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  }]
Dec  3 16:04:56.196: INFO: ss-2  shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  }]
Dec  3 16:04:56.196: INFO: 
Dec  3 16:04:56.196: INFO: StatefulSet ss has not reached scale 0, at 2
Dec  3 16:04:57.215: INFO: POD   NODE                                            PHASE    GRACE  CONDITIONS
Dec  3 16:04:57.215: INFO: ss-0  shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:37 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:02 +0000 UTC  }]
Dec  3 16:04:57.215: INFO: ss-2  shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:38 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:04:23 +0000 UTC  }]
Dec  3 16:04:57.215: INFO: 
Dec  3 16:04:57.215: INFO: StatefulSet ss has not reached scale 0, at 2
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-8632
Dec  3 16:04:58.234: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:04:58.592: INFO: rc: 1
Dec  3 16:04:58.592: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  error: unable to upgrade connection: container not found ("webserver")
 [] <nil> 0xc0032a3410 exit status 1 <nil> <nil> true [0xc002de22f0 0xc002de2308 0xc002de2320] [0xc002de22f0 0xc002de2308 0xc002de2320] [0xc002de2300 0xc002de2318] [0x10efe30 0x10efe30] 0xc000ef0b40 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Dec  3 16:05:08.593: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:05:08.759: INFO: rc: 1
Dec  3 16:05:08.759: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037d6c60 exit status 1 <nil> <nil> true [0xc000010100 0xc0000102f8 0xc0000e8d40] [0xc000010100 0xc0000102f8 0xc0000e8d40] [0xc000010240 0xc0000e89b0] [0x10efe30 0x10efe30] 0xc002a682a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:05:18.760: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:05:18.919: INFO: rc: 1
Dec  3 16:05:18.919: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00408e600 exit status 1 <nil> <nil> true [0xc0002da018 0xc0002db468 0xc0002db578] [0xc0002da018 0xc0002db468 0xc0002db578] [0xc0002db430 0xc0002db4f8] [0x10efe30 0x10efe30] 0xc00542a240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:05:28.919: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:05:29.081: INFO: rc: 1
Dec  3 16:05:29.081: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0030e45d0 exit status 1 <nil> <nil> true [0xc000fd6158 0xc000fd6270 0xc000fd64f8] [0xc000fd6158 0xc000fd6270 0xc000fd64f8] [0xc000fd6250 0xc000fd63c0] [0x10efe30 0x10efe30] 0xc003e06c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:05:39.081: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:05:39.255: INFO: rc: 1
Dec  3 16:05:39.255: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037d72c0 exit status 1 <nil> <nil> true [0xc0000e8dd0 0xc0000e9520 0xc0000e99f0] [0xc0000e8dd0 0xc0000e9520 0xc0000e99f0] [0xc0000e9168 0xc0000e98e0] [0x10efe30 0x10efe30] 0xc002a68660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:05:49.255: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:05:49.418: INFO: rc: 1
Dec  3 16:05:49.418: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0030e4c00 exit status 1 <nil> <nil> true [0xc000fd6540 0xc000fd6b08 0xc000fd70c0] [0xc000fd6540 0xc000fd6b08 0xc000fd70c0] [0xc000fd68d0 0xc000fd7060] [0x10efe30 0x10efe30] 0xc003e06f00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:05:59.419: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:05:59.594: INFO: rc: 1
Dec  3 16:05:59.595: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002dd06c0 exit status 1 <nil> <nil> true [0xc000fbe488 0xc000fbe560 0xc000fbe700] [0xc000fbe488 0xc000fbe560 0xc000fbe700] [0xc000fbe4d0 0xc000fbe660] [0x10efe30 0x10efe30] 0xc000aa04e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:06:09.595: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:06:09.754: INFO: rc: 1
Dec  3 16:06:09.754: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00408ec00 exit status 1 <nil> <nil> true [0xc0002db5a0 0xc0002db6d0 0xc0002db6f8] [0xc0002db5a0 0xc0002db6d0 0xc0002db6f8] [0xc0002db618 0xc0002db6e8] [0x10efe30 0x10efe30] 0xc00542a540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:06:19.754: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:06:19.925: INFO: rc: 1
Dec  3 16:06:19.925: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002dd0cc0 exit status 1 <nil> <nil> true [0xc000fbe790 0xc000fbe8c8 0xc000fbeb70] [0xc000fbe790 0xc000fbe8c8 0xc000fbeb70] [0xc000fbe860 0xc000fbeab0] [0x10efe30 0x10efe30] 0xc002cd0000 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:06:29.925: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:06:30.088: INFO: rc: 1
Dec  3 16:06:30.088: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0030e5290 exit status 1 <nil> <nil> true [0xc000fd71c0 0xc000fd73c8 0xc000fd7620] [0xc000fd71c0 0xc000fd73c8 0xc000fd7620] [0xc000fd7338 0xc000fd7590] [0x10efe30 0x10efe30] 0xc003e07200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:06:40.088: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:06:40.249: INFO: rc: 1
Dec  3 16:06:40.249: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00408f1d0 exit status 1 <nil> <nil> true [0xc0002db718 0xc0002db798 0xc0002db810] [0xc0002db718 0xc0002db798 0xc0002db810] [0xc0002db750 0xc0002db7f0] [0x10efe30 0x10efe30] 0xc00542a840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:06:50.249: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:06:50.426: INFO: rc: 1
Dec  3 16:06:50.426: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002dd1320 exit status 1 <nil> <nil> true [0xc000fbec78 0xc000fbef50 0xc000fbf1f8] [0xc000fbec78 0xc000fbef50 0xc000fbf1f8] [0xc000fbee70 0xc000fbf0d0] [0x10efe30 0x10efe30] 0xc002cd0780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:07:00.426: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:07:00.621: INFO: rc: 1
Dec  3 16:07:00.621: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00408f7a0 exit status 1 <nil> <nil> true [0xc0002db828 0xc0002db870 0xc0002db898] [0xc0002db828 0xc0002db870 0xc0002db898] [0xc0002db858 0xc0002db890] [0x10efe30 0x10efe30] 0xc00542ab40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:07:10.621: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:07:10.788: INFO: rc: 1
Dec  3 16:07:10.788: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00408e630 exit status 1 <nil> <nil> true [0xc000010100 0xc0000102f8 0xc0002db430] [0xc000010100 0xc0000102f8 0xc0002db430] [0xc000010240 0xc0002da070] [0x10efe30 0x10efe30] 0xc00542a240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:07:20.788: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:07:20.946: INFO: rc: 1
Dec  3 16:07:20.946: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037d67b0 exit status 1 <nil> <nil> true [0xc000fd6158 0xc000fd6270 0xc000fd64f8] [0xc000fd6158 0xc000fd6270 0xc000fd64f8] [0xc000fd6250 0xc000fd63c0] [0x10efe30 0x10efe30] 0xc000aa0420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:07:30.946: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:07:31.108: INFO: rc: 1
Dec  3 16:07:31.108: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002dd0600 exit status 1 <nil> <nil> true [0xc0000e8588 0xc0000e8dd0 0xc0000e9520] [0xc0000e8588 0xc0000e8dd0 0xc0000e9520] [0xc0000e8d40 0xc0000e9168] [0x10efe30 0x10efe30] 0xc003e06c00 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:07:41.109: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:07:41.273: INFO: rc: 1
Dec  3 16:07:41.273: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037d7260 exit status 1 <nil> <nil> true [0xc000fd6540 0xc000fd6b08 0xc000fd70c0] [0xc000fd6540 0xc000fd6b08 0xc000fd70c0] [0xc000fd68d0 0xc000fd7060] [0x10efe30 0x10efe30] 0xc000aa0ea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:07:51.273: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:07:51.464: INFO: rc: 1
Dec  3 16:07:51.465: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037d7aa0 exit status 1 <nil> <nil> true [0xc000fd71c0 0xc000fd73c8 0xc000fd7620] [0xc000fd71c0 0xc000fd73c8 0xc000fd7620] [0xc000fd7338 0xc000fd7590] [0x10efe30 0x10efe30] 0xc002a682a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:08:01.465: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:08:01.642: INFO: rc: 1
Dec  3 16:08:01.642: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021ba090 exit status 1 <nil> <nil> true [0xc000fd7728 0xc000fd7940 0xc000fd79d8] [0xc000fd7728 0xc000fd7940 0xc000fd79d8] [0xc000fd7910 0xc000fd79c8] [0x10efe30 0x10efe30] 0xc002a68660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:08:11.643: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:08:11.809: INFO: rc: 1
Dec  3 16:08:11.809: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00408ec90 exit status 1 <nil> <nil> true [0xc0002db468 0xc0002db578 0xc0002db618] [0xc0002db468 0xc0002db578 0xc0002db618] [0xc0002db4f8 0xc0002db5d0] [0x10efe30 0x10efe30] 0xc00542a540 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:08:21.810: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:08:21.975: INFO: rc: 1
Dec  3 16:08:21.975: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00408f290 exit status 1 <nil> <nil> true [0xc0002db6d0 0xc0002db6f8 0xc0002db750] [0xc0002db6d0 0xc0002db6f8 0xc0002db750] [0xc0002db6e8 0xc0002db738] [0x10efe30 0x10efe30] 0xc00542a840 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:08:31.975: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:08:32.140: INFO: rc: 1
Dec  3 16:08:32.140: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021ba720 exit status 1 <nil> <nil> true [0xc000fd7a28 0xc000fd7d00 0xc000fd7da8] [0xc000fd7a28 0xc000fd7d00 0xc000fd7da8] [0xc000fd7c80 0xc000fd7d78] [0x10efe30 0x10efe30] 0xc002a68960 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:08:42.140: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:08:42.306: INFO: rc: 1
Dec  3 16:08:42.306: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00408f890 exit status 1 <nil> <nil> true [0xc0002db798 0xc0002db810 0xc0002db858] [0xc0002db798 0xc0002db810 0xc0002db858] [0xc0002db7f0 0xc0002db848] [0x10efe30 0x10efe30] 0xc00542ab40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:08:52.306: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:08:52.465: INFO: rc: 1
Dec  3 16:08:52.465: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00408fe90 exit status 1 <nil> <nil> true [0xc0002db870 0xc0002db898 0xc0002db8e8] [0xc0002db870 0xc0002db898 0xc0002db8e8] [0xc0002db890 0xc0002db8c8] [0x10efe30 0x10efe30] 0xc00542afc0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:09:02.465: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:09:02.888: INFO: rc: 1
Dec  3 16:09:02.888: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021bacf0 exit status 1 <nil> <nil> true [0xc000fd7dc8 0xc000fd7f50 0xc000fbe1c0] [0xc000fd7dc8 0xc000fd7f50 0xc000fbe1c0] [0xc000fd7ef8 0xc000fbe0f8] [0x10efe30 0x10efe30] 0xc002a68c60 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:09:12.889: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:09:13.048: INFO: rc: 1
Dec  3 16:09:13.048: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037d6bd0 exit status 1 <nil> <nil> true [0xc000fd6188 0xc000fd6340 0xc000fd6540] [0xc000fd6188 0xc000fd6340 0xc000fd6540] [0xc000fd6270 0xc000fd64f8] [0x10efe30 0x10efe30] 0xc000aa0420 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:09:23.048: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:09:28.213: INFO: rc: 1
Dec  3 16:09:28.213: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037d7230 exit status 1 <nil> <nil> true [0xc000fd66d0 0xc000fd6e28 0xc000fd71c0] [0xc000fd66d0 0xc000fd6e28 0xc000fd71c0] [0xc000fd6b08 0xc000fd70c0] [0x10efe30 0x10efe30] 0xc000aa0ea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:09:38.214: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:09:38.414: INFO: rc: 1
Dec  3 16:09:38.414: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002dd05d0 exit status 1 <nil> <nil> true [0xc0000100c8 0xc000010240 0xc0002da070] [0xc0000100c8 0xc000010240 0xc0002da070] [0xc000010138 0xc0002da018] [0x10efe30 0x10efe30] 0xc00542a240 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:09:48.415: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:09:48.625: INFO: rc: 1
Dec  3 16:09:48.625: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0037d7a70 exit status 1 <nil> <nil> true [0xc000fd7290 0xc000fd7508 0xc000fd7728] [0xc000fd7290 0xc000fd7508 0xc000fd7728] [0xc000fd73c8 0xc000fd7620] [0x10efe30 0x10efe30] 0xc002a682a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec  3 16:09:58.627: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-8632 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:09:58.812: INFO: rc: 1
Dec  3 16:09:58.812: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: 
Dec  3 16:09:58.812: INFO: Scaling statefulset ss to 0
Dec  3 16:09:58.865: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  3 16:09:58.882: INFO: Deleting all statefulset in ns statefulset-8632
Dec  3 16:09:58.899: INFO: Scaling statefulset ss to 0
Dec  3 16:09:58.950: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 16:09:58.968: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:09:59.030: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-8632" for this suite.
Dec  3 16:10:05.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:10:05.714: INFO: namespace statefulset-8632 deletion completed in 6.649923365s

• [SLOW TEST:363.031 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:10:05.714: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2614
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec  3 16:10:05.961: INFO: Waiting up to 5m0s for pod "downward-api-82e52859-e8aa-4397-9adb-5960092950b2" in namespace "downward-api-2614" to be "success or failure"
Dec  3 16:10:05.978: INFO: Pod "downward-api-82e52859-e8aa-4397-9adb-5960092950b2": Phase="Pending", Reason="", readiness=false. Elapsed: 16.945369ms
Dec  3 16:10:07.995: INFO: Pod "downward-api-82e52859-e8aa-4397-9adb-5960092950b2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034829729s
Dec  3 16:10:10.014: INFO: Pod "downward-api-82e52859-e8aa-4397-9adb-5960092950b2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05287573s
STEP: Saw pod success
Dec  3 16:10:10.014: INFO: Pod "downward-api-82e52859-e8aa-4397-9adb-5960092950b2" satisfied condition "success or failure"
Dec  3 16:10:10.030: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downward-api-82e52859-e8aa-4397-9adb-5960092950b2 container dapi-container: <nil>
STEP: delete the pod
Dec  3 16:10:10.202: INFO: Waiting for pod downward-api-82e52859-e8aa-4397-9adb-5960092950b2 to disappear
Dec  3 16:10:10.225: INFO: Pod downward-api-82e52859-e8aa-4397-9adb-5960092950b2 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:10:10.225: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2614" for this suite.
Dec  3 16:10:16.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:10:16.929: INFO: namespace downward-api-2614 deletion completed in 6.671481054s
•SSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:10:16.930: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-4706
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:10:17.181: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-21196016-5c1c-4d9a-b4b7-a8354e519772" in namespace "security-context-test-4706" to be "success or failure"
Dec  3 16:10:17.202: INFO: Pod "busybox-privileged-false-21196016-5c1c-4d9a-b4b7-a8354e519772": Phase="Pending", Reason="", readiness=false. Elapsed: 21.396102ms
Dec  3 16:10:19.220: INFO: Pod "busybox-privileged-false-21196016-5c1c-4d9a-b4b7-a8354e519772": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.039567232s
Dec  3 16:10:19.221: INFO: Pod "busybox-privileged-false-21196016-5c1c-4d9a-b4b7-a8354e519772" satisfied condition "success or failure"
Dec  3 16:10:19.248: INFO: Got logs for pod "busybox-privileged-false-21196016-5c1c-4d9a-b4b7-a8354e519772": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:10:19.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-4706" for this suite.
Dec  3 16:10:25.335: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:10:25.933: INFO: namespace security-context-test-4706 deletion completed in 6.651052813s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:10:25.934: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-4009
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  3 16:10:34.360: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 16:10:34.377: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 16:10:36.378: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 16:10:36.396: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 16:10:38.378: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 16:10:38.396: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 16:10:40.378: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 16:10:40.396: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 16:10:42.378: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 16:10:42.397: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:10:42.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-4009" for this suite.
Dec  3 16:11:10.483: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:11:11.079: INFO: namespace container-lifecycle-hook-4009 deletion completed in 28.649435342s
•SSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:11:11.079: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-7557
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:11:21.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7557" for this suite.
Dec  3 16:11:27.429: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:11:28.021: INFO: namespace job-7557 deletion completed in 6.644963661s
•SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:11:28.021: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7921
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  3 16:11:28.266: INFO: Waiting up to 5m0s for pod "pod-6587068f-4ae6-4bc3-b239-1e9b0c5c28cb" in namespace "emptydir-7921" to be "success or failure"
Dec  3 16:11:28.283: INFO: Pod "pod-6587068f-4ae6-4bc3-b239-1e9b0c5c28cb": Phase="Pending", Reason="", readiness=false. Elapsed: 17.224405ms
Dec  3 16:11:30.302: INFO: Pod "pod-6587068f-4ae6-4bc3-b239-1e9b0c5c28cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03541086s
Dec  3 16:11:32.320: INFO: Pod "pod-6587068f-4ae6-4bc3-b239-1e9b0c5c28cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053366334s
STEP: Saw pod success
Dec  3 16:11:32.320: INFO: Pod "pod-6587068f-4ae6-4bc3-b239-1e9b0c5c28cb" satisfied condition "success or failure"
Dec  3 16:11:32.337: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-6587068f-4ae6-4bc3-b239-1e9b0c5c28cb container test-container: <nil>
STEP: delete the pod
Dec  3 16:11:32.386: INFO: Waiting for pod pod-6587068f-4ae6-4bc3-b239-1e9b0c5c28cb to disappear
Dec  3 16:11:32.403: INFO: Pod pod-6587068f-4ae6-4bc3-b239-1e9b0c5c28cb no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:11:32.403: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7921" for this suite.
Dec  3 16:11:38.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:11:39.092: INFO: namespace emptydir-7921 deletion completed in 6.655281809s
•SSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:11:39.092: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2754
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-2754
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2754 to expose endpoints map[]
Dec  3 16:11:39.372: INFO: successfully validated that service endpoint-test2 in namespace services-2754 exposes endpoints map[] (17.261065ms elapsed)
STEP: Creating pod pod1 in namespace services-2754
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2754 to expose endpoints map[pod1:[80]]
Dec  3 16:11:42.540: INFO: successfully validated that service endpoint-test2 in namespace services-2754 exposes endpoints map[pod1:[80]] (3.147827326s elapsed)
STEP: Creating pod pod2 in namespace services-2754
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2754 to expose endpoints map[pod1:[80] pod2:[80]]
Dec  3 16:11:45.769: INFO: successfully validated that service endpoint-test2 in namespace services-2754 exposes endpoints map[pod1:[80] pod2:[80]] (3.210052678s elapsed)
STEP: Deleting pod pod1 in namespace services-2754
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2754 to expose endpoints map[pod2:[80]]
Dec  3 16:11:45.820: INFO: successfully validated that service endpoint-test2 in namespace services-2754 exposes endpoints map[pod2:[80]] (33.65495ms elapsed)
STEP: Deleting pod pod2 in namespace services-2754
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-2754 to expose endpoints map[]
Dec  3 16:11:45.856: INFO: successfully validated that service endpoint-test2 in namespace services-2754 exposes endpoints map[] (16.82866ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:11:45.886: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2754" for this suite.
Dec  3 16:11:57.971: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:11:58.583: INFO: namespace services-2754 deletion completed in 12.663835385s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:11:58.583: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4823
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 16:11:59.371: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986319, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986319, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986319, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986319, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 16:12:01.390: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986319, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986319, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986319, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986319, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 16:12:04.419: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:12:04.701: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4823" for this suite.
Dec  3 16:12:16.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:12:17.379: INFO: namespace webhook-4823 deletion completed in 12.648612232s
STEP: Destroying namespace "webhook-4823-markers" for this suite.
Dec  3 16:12:23.431: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:12:24.064: INFO: namespace webhook-4823-markers deletion completed in 6.685069702s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•S
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:12:24.147: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8343
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-594cb181-6946-41ce-ad75-1f3ce9dd2398
STEP: Creating a pod to test consume secrets
Dec  3 16:12:24.412: INFO: Waiting up to 5m0s for pod "pod-secrets-974f1909-40ed-46db-8146-e69484e1f1c7" in namespace "secrets-8343" to be "success or failure"
Dec  3 16:12:24.429: INFO: Pod "pod-secrets-974f1909-40ed-46db-8146-e69484e1f1c7": Phase="Pending", Reason="", readiness=false. Elapsed: 16.790462ms
Dec  3 16:12:26.447: INFO: Pod "pod-secrets-974f1909-40ed-46db-8146-e69484e1f1c7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034654929s
Dec  3 16:12:28.465: INFO: Pod "pod-secrets-974f1909-40ed-46db-8146-e69484e1f1c7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053067611s
STEP: Saw pod success
Dec  3 16:12:28.465: INFO: Pod "pod-secrets-974f1909-40ed-46db-8146-e69484e1f1c7" satisfied condition "success or failure"
Dec  3 16:12:28.483: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-secrets-974f1909-40ed-46db-8146-e69484e1f1c7 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:12:28.533: INFO: Waiting for pod pod-secrets-974f1909-40ed-46db-8146-e69484e1f1c7 to disappear
Dec  3 16:12:28.550: INFO: Pod pod-secrets-974f1909-40ed-46db-8146-e69484e1f1c7 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:12:28.550: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8343" for this suite.
Dec  3 16:12:34.636: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:12:35.245: INFO: namespace secrets-8343 deletion completed in 6.661434864s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:12:35.245: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1344
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-1344
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 16:12:35.488: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 16:13:01.812: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.1.221 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1344 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 16:13:01.812: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 16:13:03.316: INFO: Found all expected endpoints: [netserver-0]
Dec  3 16:13:03.335: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.0.56 8081 | grep -v '^\s*$'] Namespace:pod-network-test-1344 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 16:13:03.335: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 16:13:04.814: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:13:04.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1344" for this suite.
Dec  3 16:13:16.901: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:13:17.522: INFO: namespace pod-network-test-1344 deletion completed in 12.674108371s
•SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:13:17.522: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-5127
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:13:17.758: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:13:18.372: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-5127" for this suite.
Dec  3 16:13:24.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:13:25.055: INFO: namespace custom-resource-definition-5127 deletion completed in 6.6507507s
•SS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:13:25.056: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-6182
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec  3 16:13:29.415: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:13:29.468: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6182" for this suite.
Dec  3 16:13:57.560: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:13:58.165: INFO: namespace replicaset-6182 deletion completed in 28.661075272s
•SSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:13:58.165: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4463
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:13:58.440: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  3 16:14:02.476: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec  3 16:14:04.624: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-4463 /apis/apps/v1/namespaces/deployment-4463/deployments/test-cleanup-deployment f8fa3649-0fe5-4868-8bc5-ac8b8a309c35 21816 1 2019-12-03 16:14:02 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002bf7088 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-03 16:14:02 +0000 UTC,LastTransitionTime:2019-12-03 16:14:02 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-65db99849b" has successfully progressed.,LastUpdateTime:2019-12-03 16:14:04 +0000 UTC,LastTransitionTime:2019-12-03 16:14:02 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 16:14:04.642: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-4463 /apis/apps/v1/namespaces/deployment-4463/replicasets/test-cleanup-deployment-65db99849b 3ec0b6ef-83fc-45ba-a018-90ff4732fb78 21808 1 2019-12-03 16:14:02 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment f8fa3649-0fe5-4868-8bc5-ac8b8a309c35 0xc002bf7487 0xc002bf7488}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002bf74e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec  3 16:14:04.662: INFO: Pod "test-cleanup-deployment-65db99849b-wwvw9" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-65db99849b-wwvw9 test-cleanup-deployment-65db99849b- deployment-4463 /api/v1/namespaces/deployment-4463/pods/test-cleanup-deployment-65db99849b-wwvw9 7c133e3d-f283-401b-b320-c8a926e700b9 21807 0 2019-12-03 16:14:02 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[cni.projectcalico.org/podIP:100.64.1.226/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-cleanup-deployment-65db99849b 3ec0b6ef-83fc-45ba-a018-90ff4732fb78 0xc002bf7887 0xc002bf7888}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-zsxsb,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-zsxsb,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-zsxsb,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:14:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:14:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:14:04 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:14:02 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.1.226,StartTime:2019-12-03 16:14:02 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 16:14:03 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://22daebb0717e87ccb9808a22d933e6702786aacc7d1822c599353d622a3d11df,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.226,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:14:04.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4463" for this suite.
Dec  3 16:14:10.748: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:14:11.413: INFO: namespace deployment-4463 deletion completed in 6.717339169s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:14:11.413: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-1814
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-1814, will wait for the garbage collector to delete the pods
Dec  3 16:14:15.761: INFO: Deleting Job.batch foo took: 19.027781ms
Dec  3 16:14:15.861: INFO: Terminating Job.batch foo pods took: 100.346749ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:14:50.778: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1814" for this suite.
Dec  3 16:14:56.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:14:57.464: INFO: namespace job-1814 deletion completed in 6.65327275s
•SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:14:57.465: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8270
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 16:14:58.511: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986498, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986498, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986498, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986498, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 16:15:00.529: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986498, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986498, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986498, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986498, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 16:15:03.557: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:15:03.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8270" for this suite.
Dec  3 16:15:09.990: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:15:10.606: INFO: namespace webhook-8270 deletion completed in 6.668211342s
STEP: Destroying namespace "webhook-8270-markers" for this suite.
Dec  3 16:15:16.662: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:15:17.265: INFO: namespace webhook-8270-markers deletion completed in 6.658379376s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:15:17.335: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8360
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:15:17.556: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec  3 16:15:20.868: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-8360 create -f -'
Dec  3 16:15:21.510: INFO: stderr: ""
Dec  3 16:15:21.510: INFO: stdout: "e2e-test-crd-publish-openapi-148-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec  3 16:15:21.510: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-8360 delete e2e-test-crd-publish-openapi-148-crds test-cr'
Dec  3 16:15:21.728: INFO: stderr: ""
Dec  3 16:15:21.728: INFO: stdout: "e2e-test-crd-publish-openapi-148-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Dec  3 16:15:21.728: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-8360 apply -f -'
Dec  3 16:15:22.086: INFO: stderr: ""
Dec  3 16:15:22.086: INFO: stdout: "e2e-test-crd-publish-openapi-148-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec  3 16:15:22.087: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-8360 delete e2e-test-crd-publish-openapi-148-crds test-cr'
Dec  3 16:15:22.251: INFO: stderr: ""
Dec  3 16:15:22.251: INFO: stdout: "e2e-test-crd-publish-openapi-148-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec  3 16:15:22.252: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-148-crds'
Dec  3 16:15:22.550: INFO: stderr: ""
Dec  3 16:15:22.550: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-148-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:15:26.307: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8360" for this suite.
Dec  3 16:15:32.392: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:15:32.996: INFO: namespace crd-publish-openapi-8360 deletion completed in 6.656128747s
•SSSSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:15:32.996: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-7618
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-7618
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-7618
STEP: Deleting pre-stop pod
Dec  3 16:15:42.481: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:15:42.499: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-7618" for this suite.
Dec  3 16:16:26.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:16:27.215: INFO: namespace prestop-7618 deletion completed in 44.682680984s
•
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:16:27.215: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4414
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec  3 16:16:32.231: INFO: Successfully updated pod "labelsupdate681f63c1-db2c-4cec-b348-0de50f311de5"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:16:34.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4414" for this suite.
Dec  3 16:17:02.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:17:02.967: INFO: namespace projected-4414 deletion completed in 28.650583462s
•SSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:17:02.967: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6201
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 16:17:03.955: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986623, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986623, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986623, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986623, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 16:17:05.973: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986623, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986623, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986623, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986623, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 16:17:09.002: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:17:21.820: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6201" for this suite.
Dec  3 16:17:27.910: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:17:28.519: INFO: namespace webhook-6201 deletion completed in 6.665567793s
STEP: Destroying namespace "webhook-6201-markers" for this suite.
Dec  3 16:17:34.571: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:17:35.187: INFO: namespace webhook-6201-markers deletion completed in 6.668358993s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:17:35.258: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7858
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-de6e7162-d4bc-4840-b219-e15cf5cc2b1b
STEP: Creating a pod to test consume secrets
Dec  3 16:17:35.521: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f0b4bd75-834a-4151-9f78-43f2eda41429" in namespace "projected-7858" to be "success or failure"
Dec  3 16:17:35.538: INFO: Pod "pod-projected-secrets-f0b4bd75-834a-4151-9f78-43f2eda41429": Phase="Pending", Reason="", readiness=false. Elapsed: 16.978777ms
Dec  3 16:17:37.557: INFO: Pod "pod-projected-secrets-f0b4bd75-834a-4151-9f78-43f2eda41429": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035112247s
Dec  3 16:17:39.575: INFO: Pod "pod-projected-secrets-f0b4bd75-834a-4151-9f78-43f2eda41429": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053048787s
STEP: Saw pod success
Dec  3 16:17:39.575: INFO: Pod "pod-projected-secrets-f0b4bd75-834a-4151-9f78-43f2eda41429" satisfied condition "success or failure"
Dec  3 16:17:39.592: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-projected-secrets-f0b4bd75-834a-4151-9f78-43f2eda41429 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:17:39.640: INFO: Waiting for pod pod-projected-secrets-f0b4bd75-834a-4151-9f78-43f2eda41429 to disappear
Dec  3 16:17:39.657: INFO: Pod pod-projected-secrets-f0b4bd75-834a-4151-9f78-43f2eda41429 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:17:39.657: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7858" for this suite.
Dec  3 16:17:45.743: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:17:46.353: INFO: namespace projected-7858 deletion completed in 6.66216809s
•SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:17:46.353: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3063
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-1399a193-1694-4e48-8eb7-6f50d924f67f
STEP: Creating a pod to test consume configMaps
Dec  3 16:17:46.613: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-7bcabc04-243b-41ce-b47d-db25a1cd0f32" in namespace "projected-3063" to be "success or failure"
Dec  3 16:17:46.630: INFO: Pod "pod-projected-configmaps-7bcabc04-243b-41ce-b47d-db25a1cd0f32": Phase="Pending", Reason="", readiness=false. Elapsed: 16.930755ms
Dec  3 16:17:48.652: INFO: Pod "pod-projected-configmaps-7bcabc04-243b-41ce-b47d-db25a1cd0f32": Phase="Pending", Reason="", readiness=false. Elapsed: 2.039082585s
Dec  3 16:17:50.670: INFO: Pod "pod-projected-configmaps-7bcabc04-243b-41ce-b47d-db25a1cd0f32": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.057174189s
STEP: Saw pod success
Dec  3 16:17:50.670: INFO: Pod "pod-projected-configmaps-7bcabc04-243b-41ce-b47d-db25a1cd0f32" satisfied condition "success or failure"
Dec  3 16:17:50.687: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-projected-configmaps-7bcabc04-243b-41ce-b47d-db25a1cd0f32 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 16:17:50.738: INFO: Waiting for pod pod-projected-configmaps-7bcabc04-243b-41ce-b47d-db25a1cd0f32 to disappear
Dec  3 16:17:50.754: INFO: Pod pod-projected-configmaps-7bcabc04-243b-41ce-b47d-db25a1cd0f32 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:17:50.755: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3063" for this suite.
Dec  3 16:17:56.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:17:57.486: INFO: namespace projected-3063 deletion completed in 6.699027947s
•SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:17:57.487: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3726
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3726
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec  3 16:17:57.778: INFO: Found 1 stateful pods, waiting for 3
Dec  3 16:18:07.799: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:18:07.799: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:18:07.799: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:18:07.851: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-3726 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:18:08.559: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:18:08.559: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:18:08.559: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec  3 16:18:18.677: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec  3 16:18:28.766: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-3726 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:18:29.437: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 16:18:29.437: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 16:18:29.437: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 16:18:39.543: INFO: Waiting for StatefulSet statefulset-3726/ss2 to complete update
Dec  3 16:18:39.543: INFO: Waiting for Pod statefulset-3726/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  3 16:18:39.543: INFO: Waiting for Pod statefulset-3726/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  3 16:18:39.543: INFO: Waiting for Pod statefulset-3726/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  3 16:18:49.579: INFO: Waiting for StatefulSet statefulset-3726/ss2 to complete update
Dec  3 16:18:49.579: INFO: Waiting for Pod statefulset-3726/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  3 16:18:49.579: INFO: Waiting for Pod statefulset-3726/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  3 16:18:59.578: INFO: Waiting for StatefulSet statefulset-3726/ss2 to complete update
Dec  3 16:18:59.578: INFO: Waiting for Pod statefulset-3726/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  3 16:18:59.578: INFO: Waiting for Pod statefulset-3726/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  3 16:19:09.578: INFO: Waiting for StatefulSet statefulset-3726/ss2 to complete update
Dec  3 16:19:09.578: INFO: Waiting for Pod statefulset-3726/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  3 16:19:19.579: INFO: Waiting for StatefulSet statefulset-3726/ss2 to complete update
Dec  3 16:19:19.579: INFO: Waiting for Pod statefulset-3726/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Dec  3 16:19:29.579: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-3726 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:19:30.244: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:19:30.244: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:19:30.244: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 16:19:40.361: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec  3 16:19:40.413: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-3726 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:19:41.079: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 16:19:41.079: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 16:19:41.079: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 16:20:01.194: INFO: Waiting for StatefulSet statefulset-3726/ss2 to complete update
Dec  3 16:20:01.194: INFO: Waiting for Pod statefulset-3726/ss2-0 to have revision ss2-65c7964b94 update revision ss2-84f9d6bf57
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  3 16:20:11.230: INFO: Deleting all statefulset in ns statefulset-3726
Dec  3 16:20:11.248: INFO: Scaling statefulset ss2 to 0
Dec  3 16:20:31.319: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 16:20:31.336: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:20:31.390: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3726" for this suite.
Dec  3 16:20:37.489: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:20:38.124: INFO: namespace statefulset-3726 deletion completed in 6.701033501s
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:20:38.124: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9064
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-bc962224-fc8a-4ac9-b187-3c7651d890ee
STEP: Creating a pod to test consume configMaps
Dec  3 16:20:38.415: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-6751fb94-76e3-4653-aace-848878c2293e" in namespace "projected-9064" to be "success or failure"
Dec  3 16:20:38.435: INFO: Pod "pod-projected-configmaps-6751fb94-76e3-4653-aace-848878c2293e": Phase="Pending", Reason="", readiness=false. Elapsed: 19.577758ms
Dec  3 16:20:40.458: INFO: Pod "pod-projected-configmaps-6751fb94-76e3-4653-aace-848878c2293e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.042997388s
Dec  3 16:20:42.477: INFO: Pod "pod-projected-configmaps-6751fb94-76e3-4653-aace-848878c2293e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061510308s
STEP: Saw pod success
Dec  3 16:20:42.477: INFO: Pod "pod-projected-configmaps-6751fb94-76e3-4653-aace-848878c2293e" satisfied condition "success or failure"
Dec  3 16:20:42.494: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-projected-configmaps-6751fb94-76e3-4653-aace-848878c2293e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 16:20:42.699: INFO: Waiting for pod pod-projected-configmaps-6751fb94-76e3-4653-aace-848878c2293e to disappear
Dec  3 16:20:42.716: INFO: Pod pod-projected-configmaps-6751fb94-76e3-4653-aace-848878c2293e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:20:42.716: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9064" for this suite.
Dec  3 16:20:48.803: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:20:49.402: INFO: namespace projected-9064 deletion completed in 6.653216505s
•SSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:20:49.402: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-3934
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Dec  3 16:20:49.646: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-3934" to be "success or failure"
Dec  3 16:20:49.663: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 16.64609ms
Dec  3 16:20:51.680: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034105274s
Dec  3 16:20:53.698: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 4.051833094s
Dec  3 16:20:55.716: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.070337347s
STEP: Saw pod success
Dec  3 16:20:55.716: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec  3 16:20:55.733: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec  3 16:20:55.781: INFO: Waiting for pod pod-host-path-test to disappear
Dec  3 16:20:55.798: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:20:55.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-3934" for this suite.
Dec  3 16:21:01.886: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:21:02.511: INFO: namespace hostpath-3934 deletion completed in 6.677156557s
•
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:21:02.511: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5838
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 16:21:02.764: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ab69c164-d0b0-4974-95f3-7c69e0913cd6" in namespace "projected-5838" to be "success or failure"
Dec  3 16:21:02.781: INFO: Pod "downwardapi-volume-ab69c164-d0b0-4974-95f3-7c69e0913cd6": Phase="Pending", Reason="", readiness=false. Elapsed: 17.052008ms
Dec  3 16:21:04.799: INFO: Pod "downwardapi-volume-ab69c164-d0b0-4974-95f3-7c69e0913cd6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034808526s
Dec  3 16:21:06.817: INFO: Pod "downwardapi-volume-ab69c164-d0b0-4974-95f3-7c69e0913cd6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053197845s
STEP: Saw pod success
Dec  3 16:21:06.817: INFO: Pod "downwardapi-volume-ab69c164-d0b0-4974-95f3-7c69e0913cd6" satisfied condition "success or failure"
Dec  3 16:21:06.834: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downwardapi-volume-ab69c164-d0b0-4974-95f3-7c69e0913cd6 container client-container: <nil>
STEP: delete the pod
Dec  3 16:21:06.883: INFO: Waiting for pod downwardapi-volume-ab69c164-d0b0-4974-95f3-7c69e0913cd6 to disappear
Dec  3 16:21:06.904: INFO: Pod downwardapi-volume-ab69c164-d0b0-4974-95f3-7c69e0913cd6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:21:06.904: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5838" for this suite.
Dec  3 16:21:12.989: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:21:13.581: INFO: namespace projected-5838 deletion completed in 6.644176797s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:21:13.582: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5515
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5515.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-5515.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5515.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-5515.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5515.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5515.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5515.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-5515.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5515.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-5515.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5515.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 116.208.110.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.110.208.116_udp@PTR;check="$$(dig +tcp +noall +answer +search 116.208.110.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.110.208.116_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-5515.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-5515.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-5515.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-5515.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-5515.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-5515.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-5515.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-5515.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-5515.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-5515.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5515.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 116.208.110.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.110.208.116_udp@PTR;check="$$(dig +tcp +noall +answer +search 116.208.110.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.110.208.116_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 16:21:18.115: INFO: Unable to read wheezy_udp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:18.160: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:18.180: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:18.201: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:18.628: INFO: Unable to read jessie_udp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:18.650: INFO: Unable to read jessie_tcp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:18.670: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:18.691: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:19.064: INFO: Lookups using dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd failed for: [wheezy_udp@dns-test-service.dns-5515.svc.cluster.local wheezy_tcp@dns-test-service.dns-5515.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local jessie_udp@dns-test-service.dns-5515.svc.cluster.local jessie_tcp@dns-test-service.dns-5515.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local]

Dec  3 16:21:24.085: INFO: Unable to read wheezy_udp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:24.105: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:24.127: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:24.146: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:24.572: INFO: Unable to read jessie_udp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:24.593: INFO: Unable to read jessie_tcp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:24.613: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:24.633: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:25.005: INFO: Lookups using dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd failed for: [wheezy_udp@dns-test-service.dns-5515.svc.cluster.local wheezy_tcp@dns-test-service.dns-5515.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local jessie_udp@dns-test-service.dns-5515.svc.cluster.local jessie_tcp@dns-test-service.dns-5515.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local]

Dec  3 16:21:29.100: INFO: Unable to read wheezy_udp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:29.121: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:29.141: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:29.161: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:29.580: INFO: Unable to read jessie_udp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:29.600: INFO: Unable to read jessie_tcp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:29.620: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:29.640: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:30.059: INFO: Lookups using dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd failed for: [wheezy_udp@dns-test-service.dns-5515.svc.cluster.local wheezy_tcp@dns-test-service.dns-5515.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local jessie_udp@dns-test-service.dns-5515.svc.cluster.local jessie_tcp@dns-test-service.dns-5515.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local]

Dec  3 16:21:34.085: INFO: Unable to read wheezy_udp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:34.130: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:34.149: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:34.170: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:34.591: INFO: Unable to read jessie_udp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:34.611: INFO: Unable to read jessie_tcp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:34.632: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:34.652: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:35.067: INFO: Lookups using dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd failed for: [wheezy_udp@dns-test-service.dns-5515.svc.cluster.local wheezy_tcp@dns-test-service.dns-5515.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local jessie_udp@dns-test-service.dns-5515.svc.cluster.local jessie_tcp@dns-test-service.dns-5515.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local]

Dec  3 16:21:39.088: INFO: Unable to read wheezy_udp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:39.134: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:39.154: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:39.176: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:39.595: INFO: Unable to read jessie_udp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:39.616: INFO: Unable to read jessie_tcp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:39.636: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:39.657: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:40.031: INFO: Lookups using dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd failed for: [wheezy_udp@dns-test-service.dns-5515.svc.cluster.local wheezy_tcp@dns-test-service.dns-5515.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local jessie_udp@dns-test-service.dns-5515.svc.cluster.local jessie_tcp@dns-test-service.dns-5515.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local]

Dec  3 16:21:44.087: INFO: Unable to read wheezy_udp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:44.107: INFO: Unable to read wheezy_tcp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:44.127: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:44.149: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:44.608: INFO: Unable to read jessie_udp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:44.629: INFO: Unable to read jessie_tcp@dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:44.649: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:44.669: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local from pod dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd: the server could not find the requested resource (get pods dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd)
Dec  3 16:21:45.045: INFO: Lookups using dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd failed for: [wheezy_udp@dns-test-service.dns-5515.svc.cluster.local wheezy_tcp@dns-test-service.dns-5515.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local jessie_udp@dns-test-service.dns-5515.svc.cluster.local jessie_tcp@dns-test-service.dns-5515.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-5515.svc.cluster.local]

Dec  3 16:21:50.454: INFO: DNS probes using dns-5515/dns-test-7daf6af0-c4d6-4e2d-977d-ce7750c3bfcd succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:21:50.537: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5515" for this suite.
Dec  3 16:21:56.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:21:57.198: INFO: namespace dns-5515 deletion completed in 6.643045969s
•SSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:21:57.199: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6887
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 16:21:57.456: INFO: Waiting up to 5m0s for pod "downwardapi-volume-01f8325e-b38c-4702-a9b5-5807cc6ad80b" in namespace "downward-api-6887" to be "success or failure"
Dec  3 16:21:57.472: INFO: Pod "downwardapi-volume-01f8325e-b38c-4702-a9b5-5807cc6ad80b": Phase="Pending", Reason="", readiness=false. Elapsed: 16.867004ms
Dec  3 16:21:59.491: INFO: Pod "downwardapi-volume-01f8325e-b38c-4702-a9b5-5807cc6ad80b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03492017s
Dec  3 16:22:01.510: INFO: Pod "downwardapi-volume-01f8325e-b38c-4702-a9b5-5807cc6ad80b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054146902s
STEP: Saw pod success
Dec  3 16:22:01.510: INFO: Pod "downwardapi-volume-01f8325e-b38c-4702-a9b5-5807cc6ad80b" satisfied condition "success or failure"
Dec  3 16:22:01.527: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downwardapi-volume-01f8325e-b38c-4702-a9b5-5807cc6ad80b container client-container: <nil>
STEP: delete the pod
Dec  3 16:22:01.595: INFO: Waiting for pod downwardapi-volume-01f8325e-b38c-4702-a9b5-5807cc6ad80b to disappear
Dec  3 16:22:01.612: INFO: Pod downwardapi-volume-01f8325e-b38c-4702-a9b5-5807cc6ad80b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:22:01.612: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6887" for this suite.
Dec  3 16:22:07.699: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:22:08.321: INFO: namespace downward-api-6887 deletion completed in 6.675688999s
•SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:22:08.322: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5829
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-88ce03ef-4314-46f7-a073-1f430929fa59
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-88ce03ef-4314-46f7-a073-1f430929fa59
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:23:13.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5829" for this suite.
Dec  3 16:23:25.694: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:23:26.314: INFO: namespace configmap-5829 deletion completed in 12.672724913s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:23:26.314: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3810
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  3 16:23:26.691: INFO: Number of nodes with available pods: 0
Dec  3 16:23:26.691: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 16:23:27.749: INFO: Number of nodes with available pods: 0
Dec  3 16:23:27.749: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 16:23:28.743: INFO: Number of nodes with available pods: 0
Dec  3 16:23:28.743: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 16:23:29.742: INFO: Number of nodes with available pods: 1
Dec  3 16:23:29.742: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 16:23:30.742: INFO: Number of nodes with available pods: 2
Dec  3 16:23:30.742: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec  3 16:23:30.837: INFO: Number of nodes with available pods: 1
Dec  3 16:23:30.837: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 16:23:31.892: INFO: Number of nodes with available pods: 1
Dec  3 16:23:31.892: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 16:23:32.888: INFO: Number of nodes with available pods: 1
Dec  3 16:23:32.888: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 16:23:33.887: INFO: Number of nodes with available pods: 1
Dec  3 16:23:33.887: INFO: Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk is running more than one daemon pod
Dec  3 16:23:34.888: INFO: Number of nodes with available pods: 2
Dec  3 16:23:34.888: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3810, will wait for the garbage collector to delete the pods
Dec  3 16:23:35.009: INFO: Deleting DaemonSet.extensions daemon-set took: 19.387149ms
Dec  3 16:23:35.109: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.462161ms
Dec  3 16:23:46.127: INFO: Number of nodes with available pods: 0
Dec  3 16:23:46.127: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 16:23:46.144: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3810/daemonsets","resourceVersion":"23877"},"items":null}

Dec  3 16:23:46.161: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3810/pods","resourceVersion":"23877"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:23:46.232: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3810" for this suite.
Dec  3 16:23:52.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:23:52.923: INFO: namespace daemonsets-3810 deletion completed in 6.667019983s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:23:52.924: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6609
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-a77f8a72-189c-4c13-9592-20041cc34677
STEP: Creating a pod to test consume secrets
Dec  3 16:23:53.211: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-843dd011-664c-4965-bdd8-5c7dd1e76932" in namespace "projected-6609" to be "success or failure"
Dec  3 16:23:53.229: INFO: Pod "pod-projected-secrets-843dd011-664c-4965-bdd8-5c7dd1e76932": Phase="Pending", Reason="", readiness=false. Elapsed: 17.404217ms
Dec  3 16:23:55.247: INFO: Pod "pod-projected-secrets-843dd011-664c-4965-bdd8-5c7dd1e76932": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035965936s
Dec  3 16:23:57.265: INFO: Pod "pod-projected-secrets-843dd011-664c-4965-bdd8-5c7dd1e76932": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053874973s
STEP: Saw pod success
Dec  3 16:23:57.265: INFO: Pod "pod-projected-secrets-843dd011-664c-4965-bdd8-5c7dd1e76932" satisfied condition "success or failure"
Dec  3 16:23:57.282: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-projected-secrets-843dd011-664c-4965-bdd8-5c7dd1e76932 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:23:57.345: INFO: Waiting for pod pod-projected-secrets-843dd011-664c-4965-bdd8-5c7dd1e76932 to disappear
Dec  3 16:23:57.362: INFO: Pod pod-projected-secrets-843dd011-664c-4965-bdd8-5c7dd1e76932 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:23:57.362: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6609" for this suite.
Dec  3 16:24:03.447: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:24:04.057: INFO: namespace projected-6609 deletion completed in 6.662474508s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:24:04.058: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5111
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  3 16:24:08.458: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:24:08.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5111" for this suite.
Dec  3 16:24:14.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:24:15.201: INFO: namespace container-runtime-5111 deletion completed in 6.663444182s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:24:15.203: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-4777
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-2j5g
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 16:24:15.498: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-2j5g" in namespace "subpath-4777" to be "success or failure"
Dec  3 16:24:15.515: INFO: Pod "pod-subpath-test-configmap-2j5g": Phase="Pending", Reason="", readiness=false. Elapsed: 17.13151ms
Dec  3 16:24:17.533: INFO: Pod "pod-subpath-test-configmap-2j5g": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035500181s
Dec  3 16:24:19.552: INFO: Pod "pod-subpath-test-configmap-2j5g": Phase="Running", Reason="", readiness=true. Elapsed: 4.054030883s
Dec  3 16:24:21.570: INFO: Pod "pod-subpath-test-configmap-2j5g": Phase="Running", Reason="", readiness=true. Elapsed: 6.072109685s
Dec  3 16:24:23.588: INFO: Pod "pod-subpath-test-configmap-2j5g": Phase="Running", Reason="", readiness=true. Elapsed: 8.090299611s
Dec  3 16:24:25.606: INFO: Pod "pod-subpath-test-configmap-2j5g": Phase="Running", Reason="", readiness=true. Elapsed: 10.108294786s
Dec  3 16:24:27.624: INFO: Pod "pod-subpath-test-configmap-2j5g": Phase="Running", Reason="", readiness=true. Elapsed: 12.126102933s
Dec  3 16:24:29.642: INFO: Pod "pod-subpath-test-configmap-2j5g": Phase="Running", Reason="", readiness=true. Elapsed: 14.144413845s
Dec  3 16:24:31.661: INFO: Pod "pod-subpath-test-configmap-2j5g": Phase="Running", Reason="", readiness=true. Elapsed: 16.162847916s
Dec  3 16:24:33.679: INFO: Pod "pod-subpath-test-configmap-2j5g": Phase="Running", Reason="", readiness=true. Elapsed: 18.181092132s
Dec  3 16:24:35.697: INFO: Pod "pod-subpath-test-configmap-2j5g": Phase="Running", Reason="", readiness=true. Elapsed: 20.199062032s
Dec  3 16:24:37.715: INFO: Pod "pod-subpath-test-configmap-2j5g": Phase="Running", Reason="", readiness=true. Elapsed: 22.217010096s
Dec  3 16:24:39.733: INFO: Pod "pod-subpath-test-configmap-2j5g": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.23483882s
STEP: Saw pod success
Dec  3 16:24:39.733: INFO: Pod "pod-subpath-test-configmap-2j5g" satisfied condition "success or failure"
Dec  3 16:24:39.750: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-subpath-test-configmap-2j5g container test-container-subpath-configmap-2j5g: <nil>
STEP: delete the pod
Dec  3 16:24:39.805: INFO: Waiting for pod pod-subpath-test-configmap-2j5g to disappear
Dec  3 16:24:39.822: INFO: Pod pod-subpath-test-configmap-2j5g no longer exists
STEP: Deleting pod pod-subpath-test-configmap-2j5g
Dec  3 16:24:39.822: INFO: Deleting pod "pod-subpath-test-configmap-2j5g" in namespace "subpath-4777"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:24:39.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-4777" for this suite.
Dec  3 16:24:45.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:24:46.541: INFO: namespace subpath-4777 deletion completed in 6.669224661s
•SS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:24:46.541: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-3105
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec  3 16:24:46.847: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3105 /api/v1/namespaces/watch-3105/configmaps/e2e-watch-test-watch-closed ec231b8d-7136-4800-9d9f-1cf3d3012a92 24096 0 2019-12-03 16:24:46 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 16:24:46.847: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3105 /api/v1/namespaces/watch-3105/configmaps/e2e-watch-test-watch-closed ec231b8d-7136-4800-9d9f-1cf3d3012a92 24097 0 2019-12-03 16:24:46 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec  3 16:24:47.013: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3105 /api/v1/namespaces/watch-3105/configmaps/e2e-watch-test-watch-closed ec231b8d-7136-4800-9d9f-1cf3d3012a92 24098 0 2019-12-03 16:24:46 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 16:24:47.014: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-3105 /api/v1/namespaces/watch-3105/configmaps/e2e-watch-test-watch-closed ec231b8d-7136-4800-9d9f-1cf3d3012a92 24099 0 2019-12-03 16:24:46 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:24:47.014: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-3105" for this suite.
Dec  3 16:24:53.086: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:24:53.675: INFO: namespace watch-3105 deletion completed in 6.643576885s
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:24:53.676: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7215
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  3 16:24:53.892: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-7215'
Dec  3 16:24:54.084: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 16:24:54.084: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Dec  3 16:24:54.121: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-ndqnw]
Dec  3 16:24:54.121: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-ndqnw" in namespace "kubectl-7215" to be "running and ready"
Dec  3 16:24:54.138: INFO: Pod "e2e-test-httpd-rc-ndqnw": Phase="Pending", Reason="", readiness=false. Elapsed: 16.939693ms
Dec  3 16:24:56.156: INFO: Pod "e2e-test-httpd-rc-ndqnw": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034931254s
Dec  3 16:24:58.276: INFO: Pod "e2e-test-httpd-rc-ndqnw": Phase="Running", Reason="", readiness=true. Elapsed: 4.154688558s
Dec  3 16:24:58.276: INFO: Pod "e2e-test-httpd-rc-ndqnw" satisfied condition "running and ready"
Dec  3 16:24:58.276: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-ndqnw]
Dec  3 16:24:58.276: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs rc/e2e-test-httpd-rc --namespace=kubectl-7215'
Dec  3 16:24:58.515: INFO: stderr: ""
Dec  3 16:24:58.515: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 100.64.1.253. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 100.64.1.253. Set the 'ServerName' directive globally to suppress this message\n[Tue Dec 03 16:24:56.650938 2019] [mpm_event:notice] [pid 1:tid 139856560098152] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Tue Dec 03 16:24:56.651019 2019] [core:notice] [pid 1:tid 139856560098152] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Dec  3 16:24:58.515: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete rc e2e-test-httpd-rc --namespace=kubectl-7215'
Dec  3 16:24:58.708: INFO: stderr: ""
Dec  3 16:24:58.728: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:24:58.728: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7215" for this suite.
Dec  3 16:25:26.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:25:27.417: INFO: namespace kubectl-7215 deletion completed in 28.647619721s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:25:27.418: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4019
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec  3 16:25:32.293: INFO: Successfully updated pod "annotationupdate6af93e2d-0c76-4711-bbeb-627753652105"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:25:34.356: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4019" for this suite.
Dec  3 16:26:02.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:26:03.047: INFO: namespace projected-4019 deletion completed in 28.657179311s
•SS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:26:03.047: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-2559
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec  3 16:26:04.274: INFO: Pod name wrapped-volume-race-5343f35d-7b9b-4664-9217-7f8856a08ec0: Found 1 pods out of 5
Dec  3 16:26:09.310: INFO: Pod name wrapped-volume-race-5343f35d-7b9b-4664-9217-7f8856a08ec0: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-5343f35d-7b9b-4664-9217-7f8856a08ec0 in namespace emptydir-wrapper-2559, will wait for the garbage collector to delete the pods
Dec  3 16:26:11.507: INFO: Deleting ReplicationController wrapped-volume-race-5343f35d-7b9b-4664-9217-7f8856a08ec0 took: 20.388639ms
Dec  3 16:26:11.907: INFO: Terminating ReplicationController wrapped-volume-race-5343f35d-7b9b-4664-9217-7f8856a08ec0 pods took: 400.340933ms
STEP: Creating RC which spawns configmap-volume pods
Dec  3 16:26:50.871: INFO: Pod name wrapped-volume-race-d99414e5-d0f0-43c2-94bd-452182992874: Found 1 pods out of 5
Dec  3 16:26:55.906: INFO: Pod name wrapped-volume-race-d99414e5-d0f0-43c2-94bd-452182992874: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-d99414e5-d0f0-43c2-94bd-452182992874 in namespace emptydir-wrapper-2559, will wait for the garbage collector to delete the pods
Dec  3 16:26:58.104: INFO: Deleting ReplicationController wrapped-volume-race-d99414e5-d0f0-43c2-94bd-452182992874 took: 19.842758ms
Dec  3 16:26:58.504: INFO: Terminating ReplicationController wrapped-volume-race-d99414e5-d0f0-43c2-94bd-452182992874 pods took: 400.353802ms
STEP: Creating RC which spawns configmap-volume pods
Dec  3 16:27:40.964: INFO: Pod name wrapped-volume-race-a3aee7ef-e328-4d52-a8f3-5686049dc925: Found 1 pods out of 5
Dec  3 16:27:46.000: INFO: Pod name wrapped-volume-race-a3aee7ef-e328-4d52-a8f3-5686049dc925: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-a3aee7ef-e328-4d52-a8f3-5686049dc925 in namespace emptydir-wrapper-2559, will wait for the garbage collector to delete the pods
Dec  3 16:27:48.195: INFO: Deleting ReplicationController wrapped-volume-race-a3aee7ef-e328-4d52-a8f3-5686049dc925 took: 19.251118ms
Dec  3 16:27:48.695: INFO: Terminating ReplicationController wrapped-volume-race-a3aee7ef-e328-4d52-a8f3-5686049dc925 pods took: 500.412082ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:28:31.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-2559" for this suite.
Dec  3 16:28:37.906: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:28:38.493: INFO: namespace emptydir-wrapper-2559 deletion completed in 6.639809372s
•S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:28:38.493: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2616
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:28:38.721: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Dec  3 16:28:42.187: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2616 create -f -'
Dec  3 16:28:42.870: INFO: stderr: ""
Dec  3 16:28:42.870: INFO: stdout: "e2e-test-crd-publish-openapi-1950-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec  3 16:28:42.870: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2616 delete e2e-test-crd-publish-openapi-1950-crds test-foo'
Dec  3 16:28:43.055: INFO: stderr: ""
Dec  3 16:28:43.056: INFO: stdout: "e2e-test-crd-publish-openapi-1950-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Dec  3 16:28:43.056: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2616 apply -f -'
Dec  3 16:28:43.478: INFO: stderr: ""
Dec  3 16:28:43.478: INFO: stdout: "e2e-test-crd-publish-openapi-1950-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec  3 16:28:43.478: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2616 delete e2e-test-crd-publish-openapi-1950-crds test-foo'
Dec  3 16:28:43.668: INFO: stderr: ""
Dec  3 16:28:43.668: INFO: stdout: "e2e-test-crd-publish-openapi-1950-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Dec  3 16:28:43.668: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2616 create -f -'
Dec  3 16:28:43.998: INFO: rc: 1
Dec  3 16:28:43.999: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2616 apply -f -'
Dec  3 16:28:44.270: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Dec  3 16:28:44.271: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2616 create -f -'
Dec  3 16:28:44.619: INFO: rc: 1
Dec  3 16:28:44.619: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2616 apply -f -'
Dec  3 16:28:44.999: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Dec  3 16:28:44.999: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-1950-crds'
Dec  3 16:28:45.350: INFO: stderr: ""
Dec  3 16:28:45.351: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1950-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Dec  3 16:28:45.351: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-1950-crds.metadata'
Dec  3 16:28:45.645: INFO: stderr: ""
Dec  3 16:28:45.645: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1950-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Dec  3 16:28:45.645: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-1950-crds.spec'
Dec  3 16:28:45.992: INFO: stderr: ""
Dec  3 16:28:45.992: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1950-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Dec  3 16:28:45.993: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-1950-crds.spec.bars'
Dec  3 16:28:46.372: INFO: stderr: ""
Dec  3 16:28:46.372: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-1950-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Dec  3 16:28:46.373: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-1950-crds.spec.bars2'
Dec  3 16:28:46.667: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:28:50.582: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2616" for this suite.
Dec  3 16:28:56.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:28:57.273: INFO: namespace crd-publish-openapi-2616 deletion completed in 6.658639319s
•SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:28:57.274: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9538
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:29:01.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9538" for this suite.
Dec  3 16:29:13.698: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:29:14.316: INFO: namespace replication-controller-9538 deletion completed in 12.671144343s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:29:14.317: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4205
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec  3 16:29:14.560: INFO: Waiting up to 5m0s for pod "downward-api-84789c9a-b03b-4508-aa17-add08b75e191" in namespace "downward-api-4205" to be "success or failure"
Dec  3 16:29:14.577: INFO: Pod "downward-api-84789c9a-b03b-4508-aa17-add08b75e191": Phase="Pending", Reason="", readiness=false. Elapsed: 16.842596ms
Dec  3 16:29:16.595: INFO: Pod "downward-api-84789c9a-b03b-4508-aa17-add08b75e191": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034534181s
Dec  3 16:29:18.613: INFO: Pod "downward-api-84789c9a-b03b-4508-aa17-add08b75e191": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052292448s
STEP: Saw pod success
Dec  3 16:29:18.613: INFO: Pod "downward-api-84789c9a-b03b-4508-aa17-add08b75e191" satisfied condition "success or failure"
Dec  3 16:29:18.630: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downward-api-84789c9a-b03b-4508-aa17-add08b75e191 container dapi-container: <nil>
STEP: delete the pod
Dec  3 16:29:18.787: INFO: Waiting for pod downward-api-84789c9a-b03b-4508-aa17-add08b75e191 to disappear
Dec  3 16:29:18.804: INFO: Pod downward-api-84789c9a-b03b-4508-aa17-add08b75e191 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:29:18.804: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4205" for this suite.
Dec  3 16:29:24.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:29:25.492: INFO: namespace downward-api-4205 deletion completed in 6.655220941s
•SSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:29:25.492: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-269
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-ad18b135-9e7e-45e3-8a32-a830cf534753
STEP: Creating a pod to test consume secrets
Dec  3 16:29:25.765: INFO: Waiting up to 5m0s for pod "pod-secrets-50f9ba93-4ff4-424c-841d-f515589a5f6c" in namespace "secrets-269" to be "success or failure"
Dec  3 16:29:25.782: INFO: Pod "pod-secrets-50f9ba93-4ff4-424c-841d-f515589a5f6c": Phase="Pending", Reason="", readiness=false. Elapsed: 16.688116ms
Dec  3 16:29:27.800: INFO: Pod "pod-secrets-50f9ba93-4ff4-424c-841d-f515589a5f6c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034555042s
Dec  3 16:29:29.818: INFO: Pod "pod-secrets-50f9ba93-4ff4-424c-841d-f515589a5f6c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05297237s
STEP: Saw pod success
Dec  3 16:29:29.818: INFO: Pod "pod-secrets-50f9ba93-4ff4-424c-841d-f515589a5f6c" satisfied condition "success or failure"
Dec  3 16:29:29.835: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-secrets-50f9ba93-4ff4-424c-841d-f515589a5f6c container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:29:29.885: INFO: Waiting for pod pod-secrets-50f9ba93-4ff4-424c-841d-f515589a5f6c to disappear
Dec  3 16:29:29.901: INFO: Pod pod-secrets-50f9ba93-4ff4-424c-841d-f515589a5f6c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:29:29.902: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-269" for this suite.
Dec  3 16:29:35.987: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:29:36.579: INFO: namespace secrets-269 deletion completed in 6.644367236s
•SSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:29:36.580: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6181
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-8df65591-7172-4a68-9a7a-f19591865136
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:29:41.031: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6181" for this suite.
Dec  3 16:29:53.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:29:53.758: INFO: namespace configmap-6181 deletion completed in 12.69434205s
•SS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:29:53.758: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3609
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-63995981-179f-418d-a89d-aff0c7d39899
STEP: Creating a pod to test consume secrets
Dec  3 16:29:54.018: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-de151b20-433f-4e50-880a-155c51cccc6a" in namespace "projected-3609" to be "success or failure"
Dec  3 16:29:54.035: INFO: Pod "pod-projected-secrets-de151b20-433f-4e50-880a-155c51cccc6a": Phase="Pending", Reason="", readiness=false. Elapsed: 17.136883ms
Dec  3 16:29:56.054: INFO: Pod "pod-projected-secrets-de151b20-433f-4e50-880a-155c51cccc6a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035608208s
Dec  3 16:29:58.072: INFO: Pod "pod-projected-secrets-de151b20-433f-4e50-880a-155c51cccc6a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053606723s
STEP: Saw pod success
Dec  3 16:29:58.072: INFO: Pod "pod-projected-secrets-de151b20-433f-4e50-880a-155c51cccc6a" satisfied condition "success or failure"
Dec  3 16:29:58.092: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-projected-secrets-de151b20-433f-4e50-880a-155c51cccc6a container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:29:58.147: INFO: Waiting for pod pod-projected-secrets-de151b20-433f-4e50-880a-155c51cccc6a to disappear
Dec  3 16:29:58.165: INFO: Pod pod-projected-secrets-de151b20-433f-4e50-880a-155c51cccc6a no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:29:58.165: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3609" for this suite.
Dec  3 16:30:04.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:30:04.887: INFO: namespace projected-3609 deletion completed in 6.681362215s
•SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:30:04.888: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5255
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-39e09c2a-08c1-4ef5-9d50-7f009f702958
STEP: Creating a pod to test consume configMaps
Dec  3 16:30:05.159: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-10d0a640-16a9-4f75-b43d-35f99ae82f48" in namespace "projected-5255" to be "success or failure"
Dec  3 16:30:05.177: INFO: Pod "pod-projected-configmaps-10d0a640-16a9-4f75-b43d-35f99ae82f48": Phase="Pending", Reason="", readiness=false. Elapsed: 18.02259ms
Dec  3 16:30:07.195: INFO: Pod "pod-projected-configmaps-10d0a640-16a9-4f75-b43d-35f99ae82f48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035885139s
Dec  3 16:30:09.213: INFO: Pod "pod-projected-configmaps-10d0a640-16a9-4f75-b43d-35f99ae82f48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053857539s
STEP: Saw pod success
Dec  3 16:30:09.213: INFO: Pod "pod-projected-configmaps-10d0a640-16a9-4f75-b43d-35f99ae82f48" satisfied condition "success or failure"
Dec  3 16:30:09.230: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-projected-configmaps-10d0a640-16a9-4f75-b43d-35f99ae82f48 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 16:30:09.283: INFO: Waiting for pod pod-projected-configmaps-10d0a640-16a9-4f75-b43d-35f99ae82f48 to disappear
Dec  3 16:30:09.300: INFO: Pod pod-projected-configmaps-10d0a640-16a9-4f75-b43d-35f99ae82f48 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:30:09.300: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5255" for this suite.
Dec  3 16:30:15.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:30:16.015: INFO: namespace projected-5255 deletion completed in 6.680795866s
•SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:30:16.016: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-7121
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:30:23.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-7121" for this suite.
Dec  3 16:30:29.388: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:30:29.985: INFO: namespace resourcequota-7121 deletion completed in 6.658340308s
•SSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:30:29.985: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-1576
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:30:30.233: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-d23fbf73-2e82-403d-986b-07bb3ada9587" in namespace "security-context-test-1576" to be "success or failure"
Dec  3 16:30:30.250: INFO: Pod "alpine-nnp-false-d23fbf73-2e82-403d-986b-07bb3ada9587": Phase="Pending", Reason="", readiness=false. Elapsed: 16.901584ms
Dec  3 16:30:32.268: INFO: Pod "alpine-nnp-false-d23fbf73-2e82-403d-986b-07bb3ada9587": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034839979s
Dec  3 16:30:34.286: INFO: Pod "alpine-nnp-false-d23fbf73-2e82-403d-986b-07bb3ada9587": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052912836s
Dec  3 16:30:34.287: INFO: Pod "alpine-nnp-false-d23fbf73-2e82-403d-986b-07bb3ada9587" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:30:34.313: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1576" for this suite.
Dec  3 16:30:40.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:30:41.000: INFO: namespace security-context-test-1576 deletion completed in 6.654160852s
•SS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:30:41.000: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7504
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  3 16:30:41.222: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-7504'
Dec  3 16:30:41.427: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 16:30:41.427: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Dec  3 16:30:41.444: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete deployment e2e-test-httpd-deployment --namespace=kubectl-7504'
Dec  3 16:30:41.629: INFO: stderr: ""
Dec  3 16:30:41.629: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:30:41.629: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7504" for this suite.
Dec  3 16:30:47.700: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:30:48.289: INFO: namespace kubectl-7504 deletion completed in 6.642271347s
•S
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:30:48.289: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7048
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Dec  3 16:30:48.546: INFO: Waiting up to 5m0s for pod "pod-ab7896a1-3a9d-42de-860c-96a16187c076" in namespace "emptydir-7048" to be "success or failure"
Dec  3 16:30:48.566: INFO: Pod "pod-ab7896a1-3a9d-42de-860c-96a16187c076": Phase="Pending", Reason="", readiness=false. Elapsed: 19.986051ms
Dec  3 16:30:50.584: INFO: Pod "pod-ab7896a1-3a9d-42de-860c-96a16187c076": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038307874s
Dec  3 16:30:52.602: INFO: Pod "pod-ab7896a1-3a9d-42de-860c-96a16187c076": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056620061s
STEP: Saw pod success
Dec  3 16:30:52.602: INFO: Pod "pod-ab7896a1-3a9d-42de-860c-96a16187c076" satisfied condition "success or failure"
Dec  3 16:30:52.620: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-ab7896a1-3a9d-42de-860c-96a16187c076 container test-container: <nil>
STEP: delete the pod
Dec  3 16:30:52.673: INFO: Waiting for pod pod-ab7896a1-3a9d-42de-860c-96a16187c076 to disappear
Dec  3 16:30:52.694: INFO: Pod pod-ab7896a1-3a9d-42de-860c-96a16187c076 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:30:52.694: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7048" for this suite.
Dec  3 16:30:58.779: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:30:59.372: INFO: namespace emptydir-7048 deletion completed in 6.645198677s
•S
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:30:59.373: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-2650
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec  3 16:31:00.168: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987460, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987460, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987460, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987460, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 16:31:02.187: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987460, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987460, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987460, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987460, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 16:31:04.187: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987460, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987460, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987460, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987460, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 16:31:07.214: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:31:07.231: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:31:08.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-2650" for this suite.
Dec  3 16:31:14.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:31:14.895: INFO: namespace crd-webhook-2650 deletion completed in 6.648956641s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137
•SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:31:14.965: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9654
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec  3 16:31:15.194: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 16:31:15.247: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 16:31:15.264: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk before test
Dec  3 16:31:15.292: INFO: node-exporter-99hck from kube-system started at 2019-12-03 14:41:41 +0000 UTC (1 container statuses recorded)
Dec  3 16:31:15.292: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 16:31:15.292: INFO: calico-node-v7kgq from kube-system started at 2019-12-03 14:41:41 +0000 UTC (1 container statuses recorded)
Dec  3 16:31:15.292: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 16:31:15.292: INFO: kube-proxy-9gxg8 from kube-system started at 2019-12-03 14:41:41 +0000 UTC (1 container statuses recorded)
Dec  3 16:31:15.292: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 16:31:15.292: INFO: node-problem-detector-sjm82 from kube-system started at 2019-12-03 14:41:41 +0000 UTC (1 container statuses recorded)
Dec  3 16:31:15.292: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 16:31:15.292: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v before test
Dec  3 16:31:15.376: INFO: addons-nginx-ingress-controller-7c75bb76db-42ck9 from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:31:15.376: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec  3 16:31:15.376: INFO: node-exporter-f5c97 from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 16:31:15.376: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 16:31:15.376: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-95f65778d-gxfs2 from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:31:15.376: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec  3 16:31:15.376: INFO: calico-kube-controllers-79bcd784b6-kz756 from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:31:15.376: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  3 16:31:15.376: INFO: calico-typha-vertical-autoscaler-847d859f8c-vcs4n from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:31:15.376: INFO: 	Container autoscaler ready: true, restart count 4
Dec  3 16:31:15.376: INFO: metrics-server-898dc9876-hqcdm from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:31:15.376: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 16:31:15.376: INFO: coredns-59c969ffb8-jg798 from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:31:15.376: INFO: 	Container coredns ready: true, restart count 0
Dec  3 16:31:15.376: INFO: calico-node-db7rh from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 16:31:15.376: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 16:31:15.376: INFO: kube-proxy-mjx4w from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 16:31:15.376: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 16:31:15.376: INFO: calico-typha-deploy-9f6b455c4-6sv6p from kube-system started at 2019-12-03 15:04:38 +0000 UTC (1 container statuses recorded)
Dec  3 16:31:15.376: INFO: 	Container calico-typha ready: true, restart count 0
Dec  3 16:31:15.376: INFO: calico-typha-horizontal-autoscaler-69df649c59-c4drn from kube-system started at 2019-12-03 14:39:52 +0000 UTC (1 container statuses recorded)
Dec  3 16:31:15.376: INFO: 	Container autoscaler ready: true, restart count 0
Dec  3 16:31:15.376: INFO: blackbox-exporter-7bd7b55dfc-s569k from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 16:31:15.376: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec  3 16:31:15.376: INFO: node-problem-detector-l8d9w from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 16:31:15.376: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 16:31:15.376: INFO: coredns-59c969ffb8-ldh2q from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:31:15.376: INFO: 	Container coredns ready: true, restart count 0
Dec  3 16:31:15.376: INFO: vpn-shoot-67b54fb-qrrtn from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:31:15.376: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec  3 16:31:15.376: INFO: addons-kubernetes-dashboard-78954cc66b-tpjhb from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:31:15.376: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk
STEP: verifying the node has the label node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v
Dec  3 16:31:15.492: INFO: Pod addons-kubernetes-dashboard-78954cc66b-tpjhb requesting resource cpu=50m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v
Dec  3 16:31:15.492: INFO: Pod addons-nginx-ingress-controller-7c75bb76db-42ck9 requesting resource cpu=100m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v
Dec  3 16:31:15.492: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-95f65778d-gxfs2 requesting resource cpu=0m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v
Dec  3 16:31:15.492: INFO: Pod blackbox-exporter-7bd7b55dfc-s569k requesting resource cpu=5m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v
Dec  3 16:31:15.492: INFO: Pod calico-kube-controllers-79bcd784b6-kz756 requesting resource cpu=0m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v
Dec  3 16:31:15.492: INFO: Pod calico-node-db7rh requesting resource cpu=100m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v
Dec  3 16:31:15.492: INFO: Pod calico-node-v7kgq requesting resource cpu=100m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk
Dec  3 16:31:15.492: INFO: Pod calico-typha-deploy-9f6b455c4-6sv6p requesting resource cpu=0m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v
Dec  3 16:31:15.492: INFO: Pod calico-typha-horizontal-autoscaler-69df649c59-c4drn requesting resource cpu=10m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v
Dec  3 16:31:15.492: INFO: Pod calico-typha-vertical-autoscaler-847d859f8c-vcs4n requesting resource cpu=0m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v
Dec  3 16:31:15.492: INFO: Pod coredns-59c969ffb8-jg798 requesting resource cpu=50m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v
Dec  3 16:31:15.492: INFO: Pod coredns-59c969ffb8-ldh2q requesting resource cpu=50m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v
Dec  3 16:31:15.492: INFO: Pod kube-proxy-9gxg8 requesting resource cpu=20m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk
Dec  3 16:31:15.492: INFO: Pod kube-proxy-mjx4w requesting resource cpu=20m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v
Dec  3 16:31:15.492: INFO: Pod metrics-server-898dc9876-hqcdm requesting resource cpu=20m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v
Dec  3 16:31:15.492: INFO: Pod node-exporter-99hck requesting resource cpu=5m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk
Dec  3 16:31:15.492: INFO: Pod node-exporter-f5c97 requesting resource cpu=5m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v
Dec  3 16:31:15.492: INFO: Pod node-problem-detector-l8d9w requesting resource cpu=20m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v
Dec  3 16:31:15.492: INFO: Pod node-problem-detector-sjm82 requesting resource cpu=20m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk
Dec  3 16:31:15.492: INFO: Pod vpn-shoot-67b54fb-qrrtn requesting resource cpu=100m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v
STEP: Starting Pods to consume most of the cluster CPU.
Dec  3 16:31:15.492: INFO: Creating a pod which consumes cpu=1242m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk
Dec  3 16:31:15.512: INFO: Creating a pod which consumes cpu=973m on Node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-07f55628-9d6b-49ee-b1e6-1f629b21cd9f.15dce978fd78f804], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9654/filler-pod-07f55628-9d6b-49ee-b1e6-1f629b21cd9f to shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-07f55628-9d6b-49ee-b1e6-1f629b21cd9f.15dce97938a4a5a4], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-07f55628-9d6b-49ee-b1e6-1f629b21cd9f.15dce9795c4c3933], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-07f55628-9d6b-49ee-b1e6-1f629b21cd9f.15dce9797cfa2401], Reason = [Created], Message = [Created container filler-pod-07f55628-9d6b-49ee-b1e6-1f629b21cd9f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-07f55628-9d6b-49ee-b1e6-1f629b21cd9f.15dce9798d2d51be], Reason = [Started], Message = [Started container filler-pod-07f55628-9d6b-49ee-b1e6-1f629b21cd9f]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-95ecc991-b49d-4b2c-9373-4056524487b0.15dce978fc57469b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-9654/filler-pod-95ecc991-b49d-4b2c-9373-4056524487b0 to shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-95ecc991-b49d-4b2c-9373-4056524487b0.15dce97966ed5d51], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-95ecc991-b49d-4b2c-9373-4056524487b0.15dce9797130399d], Reason = [Created], Message = [Created container filler-pod-95ecc991-b49d-4b2c-9373-4056524487b0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-95ecc991-b49d-4b2c-9373-4056524487b0.15dce9797b9f08d0], Reason = [Started], Message = [Started container filler-pod-95ecc991-b49d-4b2c-9373-4056524487b0]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15dce979f21c254c], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:31:20.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9654" for this suite.
Dec  3 16:31:26.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:31:27.430: INFO: namespace sched-pred-9654 deletion completed in 6.650909701s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
•S
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:31:27.431: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1660
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 16:31:27.673: INFO: Waiting up to 5m0s for pod "downwardapi-volume-529c5432-6319-4228-b323-df8a36b095ef" in namespace "downward-api-1660" to be "success or failure"
Dec  3 16:31:27.691: INFO: Pod "downwardapi-volume-529c5432-6319-4228-b323-df8a36b095ef": Phase="Pending", Reason="", readiness=false. Elapsed: 17.911738ms
Dec  3 16:31:29.709: INFO: Pod "downwardapi-volume-529c5432-6319-4228-b323-df8a36b095ef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035844908s
Dec  3 16:31:31.727: INFO: Pod "downwardapi-volume-529c5432-6319-4228-b323-df8a36b095ef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054034851s
STEP: Saw pod success
Dec  3 16:31:31.727: INFO: Pod "downwardapi-volume-529c5432-6319-4228-b323-df8a36b095ef" satisfied condition "success or failure"
Dec  3 16:31:31.745: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downwardapi-volume-529c5432-6319-4228-b323-df8a36b095ef container client-container: <nil>
STEP: delete the pod
Dec  3 16:31:31.800: INFO: Waiting for pod downwardapi-volume-529c5432-6319-4228-b323-df8a36b095ef to disappear
Dec  3 16:31:31.817: INFO: Pod downwardapi-volume-529c5432-6319-4228-b323-df8a36b095ef no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:31:31.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1660" for this suite.
Dec  3 16:31:37.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:31:38.518: INFO: namespace downward-api-1660 deletion completed in 6.667443735s
•SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:31:38.518: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9022
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec  3 16:31:44.889: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:31:44.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1203 16:31:44.889641    5095 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-9022" for this suite.
Dec  3 16:31:50.960: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:31:51.601: INFO: namespace gc-9022 deletion completed in 6.694594789s
•SSSSS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:31:51.602: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8329
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-f7e590c3-7545-413b-85d6-11f037eaaddc
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:31:51.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8329" for this suite.
Dec  3 16:31:57.921: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:31:58.519: INFO: namespace configmap-8329 deletion completed in 6.649623798s
•
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:31:58.519: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7860
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-4c5c86bc-6eea-4c52-8ebe-a3e9ffa7e599
STEP: Creating configMap with name cm-test-opt-upd-ce1cf616-ed92-48bf-9ecc-065f295a8dfb
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-4c5c86bc-6eea-4c52-8ebe-a3e9ffa7e599
STEP: Updating configmap cm-test-opt-upd-ce1cf616-ed92-48bf-9ecc-065f295a8dfb
STEP: Creating configMap with name cm-test-opt-create-d0e8b1fd-603f-4cd3-ac3a-ba6807b58204
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:33:18.286: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7860" for this suite.
Dec  3 16:33:32.384: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:33:32.982: INFO: namespace projected-7860 deletion completed in 14.663610851s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:33:32.983: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-1681
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:33:33.229: INFO: Waiting up to 5m0s for pod "busybox-user-65534-f7694346-d2e6-4a5f-863e-a3bd6f203a05" in namespace "security-context-test-1681" to be "success or failure"
Dec  3 16:33:33.246: INFO: Pod "busybox-user-65534-f7694346-d2e6-4a5f-863e-a3bd6f203a05": Phase="Pending", Reason="", readiness=false. Elapsed: 16.99926ms
Dec  3 16:33:35.264: INFO: Pod "busybox-user-65534-f7694346-d2e6-4a5f-863e-a3bd6f203a05": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035026517s
Dec  3 16:33:37.283: INFO: Pod "busybox-user-65534-f7694346-d2e6-4a5f-863e-a3bd6f203a05": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053123837s
Dec  3 16:33:37.283: INFO: Pod "busybox-user-65534-f7694346-d2e6-4a5f-863e-a3bd6f203a05" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:33:37.283: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1681" for this suite.
Dec  3 16:33:43.369: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:33:43.985: INFO: namespace security-context-test-1681 deletion completed in 6.669244433s
•SS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:33:43.985: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6619
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  3 16:33:44.228: INFO: Waiting up to 5m0s for pod "pod-f8f888c8-dd5e-4be1-b167-001d52f74360" in namespace "emptydir-6619" to be "success or failure"
Dec  3 16:33:44.245: INFO: Pod "pod-f8f888c8-dd5e-4be1-b167-001d52f74360": Phase="Pending", Reason="", readiness=false. Elapsed: 17.402355ms
Dec  3 16:33:46.263: INFO: Pod "pod-f8f888c8-dd5e-4be1-b167-001d52f74360": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035384224s
Dec  3 16:33:48.281: INFO: Pod "pod-f8f888c8-dd5e-4be1-b167-001d52f74360": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053193524s
STEP: Saw pod success
Dec  3 16:33:48.281: INFO: Pod "pod-f8f888c8-dd5e-4be1-b167-001d52f74360" satisfied condition "success or failure"
Dec  3 16:33:48.298: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-f8f888c8-dd5e-4be1-b167-001d52f74360 container test-container: <nil>
STEP: delete the pod
Dec  3 16:33:48.356: INFO: Waiting for pod pod-f8f888c8-dd5e-4be1-b167-001d52f74360 to disappear
Dec  3 16:33:48.373: INFO: Pod pod-f8f888c8-dd5e-4be1-b167-001d52f74360 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:33:48.373: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6619" for this suite.
Dec  3 16:33:54.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:33:55.075: INFO: namespace emptydir-6619 deletion completed in 6.657614609s
•SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:33:55.075: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-2458
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec  3 16:33:55.374: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 16:33:55.427: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 16:33:55.444: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk before test
Dec  3 16:33:55.514: INFO: node-exporter-99hck from kube-system started at 2019-12-03 14:41:41 +0000 UTC (1 container statuses recorded)
Dec  3 16:33:55.514: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 16:33:55.514: INFO: calico-node-v7kgq from kube-system started at 2019-12-03 14:41:41 +0000 UTC (1 container statuses recorded)
Dec  3 16:33:55.514: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 16:33:55.514: INFO: kube-proxy-9gxg8 from kube-system started at 2019-12-03 14:41:41 +0000 UTC (1 container statuses recorded)
Dec  3 16:33:55.514: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 16:33:55.514: INFO: node-problem-detector-sjm82 from kube-system started at 2019-12-03 14:41:41 +0000 UTC (1 container statuses recorded)
Dec  3 16:33:55.514: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 16:33:55.514: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v before test
Dec  3 16:33:55.659: INFO: addons-nginx-ingress-controller-7c75bb76db-42ck9 from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:33:55.659: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec  3 16:33:55.659: INFO: node-exporter-f5c97 from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 16:33:55.659: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 16:33:55.659: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-95f65778d-gxfs2 from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:33:55.659: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec  3 16:33:55.659: INFO: calico-kube-controllers-79bcd784b6-kz756 from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:33:55.659: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  3 16:33:55.659: INFO: calico-typha-vertical-autoscaler-847d859f8c-vcs4n from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:33:55.659: INFO: 	Container autoscaler ready: true, restart count 4
Dec  3 16:33:55.659: INFO: metrics-server-898dc9876-hqcdm from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:33:55.659: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 16:33:55.659: INFO: coredns-59c969ffb8-jg798 from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:33:55.659: INFO: 	Container coredns ready: true, restart count 0
Dec  3 16:33:55.659: INFO: calico-node-db7rh from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 16:33:55.659: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 16:33:55.659: INFO: kube-proxy-mjx4w from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 16:33:55.659: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 16:33:55.659: INFO: calico-typha-deploy-9f6b455c4-6sv6p from kube-system started at 2019-12-03 15:04:38 +0000 UTC (1 container statuses recorded)
Dec  3 16:33:55.659: INFO: 	Container calico-typha ready: true, restart count 0
Dec  3 16:33:55.659: INFO: calico-typha-horizontal-autoscaler-69df649c59-c4drn from kube-system started at 2019-12-03 14:39:52 +0000 UTC (1 container statuses recorded)
Dec  3 16:33:55.659: INFO: 	Container autoscaler ready: true, restart count 0
Dec  3 16:33:55.659: INFO: blackbox-exporter-7bd7b55dfc-s569k from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 16:33:55.659: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec  3 16:33:55.659: INFO: node-problem-detector-l8d9w from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 16:33:55.659: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 16:33:55.659: INFO: coredns-59c969ffb8-ldh2q from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:33:55.659: INFO: 	Container coredns ready: true, restart count 0
Dec  3 16:33:55.659: INFO: vpn-shoot-67b54fb-qrrtn from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:33:55.659: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec  3 16:33:55.659: INFO: addons-kubernetes-dashboard-78954cc66b-tpjhb from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:33:55.659: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-ccd5e800-b738-4a21-b546-a1e12e2633de 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-ccd5e800-b738-4a21-b546-a1e12e2633de off the node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk
STEP: verifying the node doesn't have the label kubernetes.io/e2e-ccd5e800-b738-4a21-b546-a1e12e2633de
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:34:12.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-2458" for this suite.
Dec  3 16:34:42.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:34:42.680: INFO: namespace sched-pred-2458 deletion completed in 30.650385293s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
•SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:34:42.681: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-167
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 16:34:43.592: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987683, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987683, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987683, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987683, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 16:34:45.610: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987683, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987683, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987683, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987683, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 16:34:48.639: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Dec  3 16:34:48.833: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:34:48.917: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-167" for this suite.
Dec  3 16:34:55.008: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:34:55.611: INFO: namespace webhook-167 deletion completed in 6.660361576s
STEP: Destroying namespace "webhook-167-markers" for this suite.
Dec  3 16:35:01.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:35:02.275: INFO: namespace webhook-167-markers deletion completed in 6.663968605s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:35:02.345: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-419
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 16:35:03.262: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec  3 16:35:05.324: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987703, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987703, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987703, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987703, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 16:35:08.376: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:35:08.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-419" for this suite.
Dec  3 16:35:14.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:35:15.546: INFO: namespace webhook-419 deletion completed in 6.649254174s
STEP: Destroying namespace "webhook-419-markers" for this suite.
Dec  3 16:35:21.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:35:22.192: INFO: namespace webhook-419-markers deletion completed in 6.645756518s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:35:22.261: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-176
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:35:22.547: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-176" for this suite.
Dec  3 16:35:28.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:35:29.254: INFO: namespace custom-resource-definition-176 deletion completed in 6.689084205s
•SSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:35:29.254: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5851
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec  3 16:35:29.481: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 16:35:29.534: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 16:35:29.551: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk before test
Dec  3 16:35:29.686: INFO: kube-proxy-9gxg8 from kube-system started at 2019-12-03 14:41:41 +0000 UTC (1 container statuses recorded)
Dec  3 16:35:29.686: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 16:35:29.686: INFO: node-problem-detector-sjm82 from kube-system started at 2019-12-03 14:41:41 +0000 UTC (1 container statuses recorded)
Dec  3 16:35:29.686: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 16:35:29.686: INFO: node-exporter-99hck from kube-system started at 2019-12-03 14:41:41 +0000 UTC (1 container statuses recorded)
Dec  3 16:35:29.686: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 16:35:29.686: INFO: calico-node-v7kgq from kube-system started at 2019-12-03 14:41:41 +0000 UTC (1 container statuses recorded)
Dec  3 16:35:29.686: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 16:35:29.686: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v before test
Dec  3 16:35:29.768: INFO: blackbox-exporter-7bd7b55dfc-s569k from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 16:35:29.768: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec  3 16:35:29.768: INFO: node-problem-detector-l8d9w from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 16:35:29.768: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 16:35:29.768: INFO: coredns-59c969ffb8-ldh2q from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:35:29.768: INFO: 	Container coredns ready: true, restart count 0
Dec  3 16:35:29.768: INFO: vpn-shoot-67b54fb-qrrtn from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:35:29.768: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec  3 16:35:29.768: INFO: addons-kubernetes-dashboard-78954cc66b-tpjhb from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:35:29.768: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
Dec  3 16:35:29.768: INFO: node-exporter-f5c97 from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 16:35:29.768: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 16:35:29.768: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-95f65778d-gxfs2 from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:35:29.768: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec  3 16:35:29.768: INFO: calico-kube-controllers-79bcd784b6-kz756 from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:35:29.768: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  3 16:35:29.768: INFO: addons-nginx-ingress-controller-7c75bb76db-42ck9 from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:35:29.768: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec  3 16:35:29.768: INFO: calico-typha-vertical-autoscaler-847d859f8c-vcs4n from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:35:29.768: INFO: 	Container autoscaler ready: true, restart count 4
Dec  3 16:35:29.768: INFO: metrics-server-898dc9876-hqcdm from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:35:29.768: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 16:35:29.768: INFO: calico-node-db7rh from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 16:35:29.768: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 16:35:29.768: INFO: kube-proxy-mjx4w from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 16:35:29.768: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 16:35:29.768: INFO: calico-typha-deploy-9f6b455c4-6sv6p from kube-system started at 2019-12-03 15:04:38 +0000 UTC (1 container statuses recorded)
Dec  3 16:35:29.768: INFO: 	Container calico-typha ready: true, restart count 0
Dec  3 16:35:29.768: INFO: coredns-59c969ffb8-jg798 from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:35:29.768: INFO: 	Container coredns ready: true, restart count 0
Dec  3 16:35:29.768: INFO: calico-typha-horizontal-autoscaler-69df649c59-c4drn from kube-system started at 2019-12-03 14:39:52 +0000 UTC (1 container statuses recorded)
Dec  3 16:35:29.768: INFO: 	Container autoscaler ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-2cf37f11-eadc-4d3e-84b9-d006891ba9b3 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-2cf37f11-eadc-4d3e-84b9-d006891ba9b3 off the node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk
STEP: verifying the node doesn't have the label kubernetes.io/e2e-2cf37f11-eadc-4d3e-84b9-d006891ba9b3
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:35:36.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5851" for this suite.
Dec  3 16:35:44.101: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:35:44.698: INFO: namespace sched-pred-5851 deletion completed in 8.657280515s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:35:44.699: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4383
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 16:35:44.940: INFO: Waiting up to 5m0s for pod "downwardapi-volume-28a7b0bd-5816-4399-abe1-3ab0f7f99195" in namespace "downward-api-4383" to be "success or failure"
Dec  3 16:35:44.957: INFO: Pod "downwardapi-volume-28a7b0bd-5816-4399-abe1-3ab0f7f99195": Phase="Pending", Reason="", readiness=false. Elapsed: 16.98409ms
Dec  3 16:35:46.976: INFO: Pod "downwardapi-volume-28a7b0bd-5816-4399-abe1-3ab0f7f99195": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035275269s
Dec  3 16:35:48.994: INFO: Pod "downwardapi-volume-28a7b0bd-5816-4399-abe1-3ab0f7f99195": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053861746s
STEP: Saw pod success
Dec  3 16:35:48.994: INFO: Pod "downwardapi-volume-28a7b0bd-5816-4399-abe1-3ab0f7f99195" satisfied condition "success or failure"
Dec  3 16:35:49.011: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downwardapi-volume-28a7b0bd-5816-4399-abe1-3ab0f7f99195 container client-container: <nil>
STEP: delete the pod
Dec  3 16:35:49.060: INFO: Waiting for pod downwardapi-volume-28a7b0bd-5816-4399-abe1-3ab0f7f99195 to disappear
Dec  3 16:35:49.077: INFO: Pod downwardapi-volume-28a7b0bd-5816-4399-abe1-3ab0f7f99195 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:35:49.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4383" for this suite.
Dec  3 16:35:55.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:35:55.760: INFO: namespace downward-api-4383 deletion completed in 6.650062149s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:35:55.761: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5183
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-5183
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-5183
I1203 16:35:56.069318    5095 runners.go:184] Created replication controller with name: externalname-service, namespace: services-5183, replica count: 2
Dec  3 16:35:59.119: INFO: Creating new exec pod
I1203 16:35:59.119924    5095 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 16:36:04.209: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-5183 execpodj7m68 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec  3 16:36:04.889: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec  3 16:36:04.889: INFO: stdout: ""
Dec  3 16:36:04.890: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-5183 execpodj7m68 -- /bin/sh -x -c nc -zv -t -w 2 100.106.105.68 80'
Dec  3 16:36:05.529: INFO: stderr: "+ nc -zv -t -w 2 100.106.105.68 80\nConnection to 100.106.105.68 80 port [tcp/http] succeeded!\n"
Dec  3 16:36:05.529: INFO: stdout: ""
Dec  3 16:36:05.529: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-5183 execpodj7m68 -- /bin/sh -x -c nc -zv -t -w 2 10.250.0.4 31213'
Dec  3 16:36:06.173: INFO: stderr: "+ nc -zv -t -w 2 10.250.0.4 31213\nConnection to 10.250.0.4 31213 port [tcp/31213] succeeded!\n"
Dec  3 16:36:06.173: INFO: stdout: ""
Dec  3 16:36:06.173: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-5183 execpodj7m68 -- /bin/sh -x -c nc -zv -t -w 2 10.250.0.5 31213'
Dec  3 16:36:06.834: INFO: stderr: "+ nc -zv -t -w 2 10.250.0.5 31213\nConnection to 10.250.0.5 31213 port [tcp/31213] succeeded!\n"
Dec  3 16:36:06.834: INFO: stdout: ""
Dec  3 16:36:06.834: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:36:06.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5183" for this suite.
Dec  3 16:36:12.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:36:13.566: INFO: namespace services-5183 deletion completed in 6.644260129s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:36:13.566: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4102
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-22bb86de-908c-4fbd-b33e-16da3ecbc993
STEP: Creating a pod to test consume secrets
Dec  3 16:36:13.827: INFO: Waiting up to 5m0s for pod "pod-secrets-6339a4cc-78ce-4baf-9a88-72dd3205f08c" in namespace "secrets-4102" to be "success or failure"
Dec  3 16:36:13.846: INFO: Pod "pod-secrets-6339a4cc-78ce-4baf-9a88-72dd3205f08c": Phase="Pending", Reason="", readiness=false. Elapsed: 18.61108ms
Dec  3 16:36:15.864: INFO: Pod "pod-secrets-6339a4cc-78ce-4baf-9a88-72dd3205f08c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036452686s
Dec  3 16:36:17.882: INFO: Pod "pod-secrets-6339a4cc-78ce-4baf-9a88-72dd3205f08c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054842881s
STEP: Saw pod success
Dec  3 16:36:17.882: INFO: Pod "pod-secrets-6339a4cc-78ce-4baf-9a88-72dd3205f08c" satisfied condition "success or failure"
Dec  3 16:36:17.899: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-secrets-6339a4cc-78ce-4baf-9a88-72dd3205f08c container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:36:17.953: INFO: Waiting for pod pod-secrets-6339a4cc-78ce-4baf-9a88-72dd3205f08c to disappear
Dec  3 16:36:17.971: INFO: Pod pod-secrets-6339a4cc-78ce-4baf-9a88-72dd3205f08c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:36:17.971: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4102" for this suite.
Dec  3 16:36:24.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:36:24.658: INFO: namespace secrets-4102 deletion completed in 6.65395487s
•S
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:36:24.658: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1112
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-1112/configmap-test-81d8b262-b103-45d3-b45b-686f38092569
STEP: Creating a pod to test consume configMaps
Dec  3 16:36:24.915: INFO: Waiting up to 5m0s for pod "pod-configmaps-93d8cc50-a0cc-425a-84f3-499fd4b51a5a" in namespace "configmap-1112" to be "success or failure"
Dec  3 16:36:24.941: INFO: Pod "pod-configmaps-93d8cc50-a0cc-425a-84f3-499fd4b51a5a": Phase="Pending", Reason="", readiness=false. Elapsed: 25.956171ms
Dec  3 16:36:26.959: INFO: Pod "pod-configmaps-93d8cc50-a0cc-425a-84f3-499fd4b51a5a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.043605321s
Dec  3 16:36:28.977: INFO: Pod "pod-configmaps-93d8cc50-a0cc-425a-84f3-499fd4b51a5a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.061617326s
STEP: Saw pod success
Dec  3 16:36:28.977: INFO: Pod "pod-configmaps-93d8cc50-a0cc-425a-84f3-499fd4b51a5a" satisfied condition "success or failure"
Dec  3 16:36:28.998: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-configmaps-93d8cc50-a0cc-425a-84f3-499fd4b51a5a container env-test: <nil>
STEP: delete the pod
Dec  3 16:36:29.052: INFO: Waiting for pod pod-configmaps-93d8cc50-a0cc-425a-84f3-499fd4b51a5a to disappear
Dec  3 16:36:29.069: INFO: Pod pod-configmaps-93d8cc50-a0cc-425a-84f3-499fd4b51a5a no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:36:29.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1112" for this suite.
Dec  3 16:36:35.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:36:35.744: INFO: namespace configmap-1112 deletion completed in 6.642085272s
•SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:36:35.744: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6720
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-54d0ca4f-21a9-4de2-85af-c6bbc60f78a9
STEP: Creating a pod to test consume configMaps
Dec  3 16:36:36.005: INFO: Waiting up to 5m0s for pod "pod-configmaps-cf35391f-28e6-4b89-8ccc-a0c54050721a" in namespace "configmap-6720" to be "success or failure"
Dec  3 16:36:36.022: INFO: Pod "pod-configmaps-cf35391f-28e6-4b89-8ccc-a0c54050721a": Phase="Pending", Reason="", readiness=false. Elapsed: 17.107409ms
Dec  3 16:36:38.040: INFO: Pod "pod-configmaps-cf35391f-28e6-4b89-8ccc-a0c54050721a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035124916s
Dec  3 16:36:40.059: INFO: Pod "pod-configmaps-cf35391f-28e6-4b89-8ccc-a0c54050721a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054182617s
STEP: Saw pod success
Dec  3 16:36:40.059: INFO: Pod "pod-configmaps-cf35391f-28e6-4b89-8ccc-a0c54050721a" satisfied condition "success or failure"
Dec  3 16:36:40.076: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-configmaps-cf35391f-28e6-4b89-8ccc-a0c54050721a container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 16:36:40.127: INFO: Waiting for pod pod-configmaps-cf35391f-28e6-4b89-8ccc-a0c54050721a to disappear
Dec  3 16:36:40.144: INFO: Pod pod-configmaps-cf35391f-28e6-4b89-8ccc-a0c54050721a no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:36:40.144: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6720" for this suite.
Dec  3 16:36:46.229: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:36:46.823: INFO: namespace configmap-6720 deletion completed in 6.646197409s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:36:46.824: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3066
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3066
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec  3 16:36:47.106: INFO: Found 1 stateful pods, waiting for 3
Dec  3 16:36:57.128: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:36:57.129: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:36:57.129: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec  3 16:36:57.226: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec  3 16:36:57.306: INFO: Updating stateful set ss2
Dec  3 16:36:57.342: INFO: Waiting for Pod statefulset-3066/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  3 16:37:07.379: INFO: Waiting for Pod statefulset-3066/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Dec  3 16:37:17.459: INFO: Found 2 stateful pods, waiting for 3
Dec  3 16:37:27.478: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:37:27.478: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:37:27.478: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec  3 16:37:27.559: INFO: Updating stateful set ss2
Dec  3 16:37:27.595: INFO: Waiting for Pod statefulset-3066/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  3 16:37:37.676: INFO: Updating stateful set ss2
Dec  3 16:37:37.711: INFO: Waiting for StatefulSet statefulset-3066/ss2 to complete update
Dec  3 16:37:37.711: INFO: Waiting for Pod statefulset-3066/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  3 16:37:47.747: INFO: Waiting for StatefulSet statefulset-3066/ss2 to complete update
Dec  3 16:37:47.747: INFO: Waiting for Pod statefulset-3066/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  3 16:37:57.747: INFO: Deleting all statefulset in ns statefulset-3066
Dec  3 16:37:57.764: INFO: Scaling statefulset ss2 to 0
Dec  3 16:38:27.840: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 16:38:27.857: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:38:27.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3066" for this suite.
Dec  3 16:38:34.005: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:38:34.603: INFO: namespace statefulset-3066 deletion completed in 6.650859907s
•SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:38:34.604: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-1274
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-c85c95d8-07eb-4770-a428-c8731c95c7fd in namespace container-probe-1274
Dec  3 16:38:38.911: INFO: Started pod liveness-c85c95d8-07eb-4770-a428-c8731c95c7fd in namespace container-probe-1274
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 16:38:38.928: INFO: Initial restart count of pod liveness-c85c95d8-07eb-4770-a428-c8731c95c7fd is 0
Dec  3 16:39:01.146: INFO: Restart count of pod container-probe-1274/liveness-c85c95d8-07eb-4770-a428-c8731c95c7fd is now 1 (22.218154198s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:39:01.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-1274" for this suite.
Dec  3 16:39:07.256: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:39:07.850: INFO: namespace container-probe-1274 deletion completed in 6.646750744s
•SSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:39:07.851: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-9706
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec  3 16:39:12.164: INFO: &Pod{ObjectMeta:{send-events-f47149a9-663b-43ff-b5d1-302626cf8011  events-9706 /api/v1/namespaces/events-9706/pods/send-events-f47149a9-663b-43ff-b5d1-302626cf8011 3f250f59-9209-4064-a0cb-592d98735733 27582 0 2019-12-03 16:39:08 +0000 UTC <nil> <nil> map[name:foo time:74175766] map[cni.projectcalico.org/podIP:100.64.1.60/32 kubernetes.io/psp:e2e-test-privileged-psp] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-dslh9,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-dslh9,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-dslh9,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:39:08 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:39:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:39:11 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:39:08 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.4,PodIP:100.64.1.60,StartTime:2019-12-03 16:39:08 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 16:39:09 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:docker://70cd403f47ef300ccc76aaea26a1186d752f0b4ac29bc0dbd8e5ffaf1ed65b8f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.60,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Dec  3 16:39:14.184: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec  3 16:39:16.203: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:39:16.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-9706" for this suite.
Dec  3 16:40:00.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:40:00.913: INFO: namespace events-9706 deletion completed in 44.658269603s
•SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:40:00.913: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2984
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Dec  3 16:40:01.136: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:40:01.275: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2984" for this suite.
Dec  3 16:40:07.357: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:40:07.944: INFO: namespace kubectl-2984 deletion completed in 6.651241538s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:40:07.945: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3686
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 16:40:08.180: INFO: Waiting up to 5m0s for pod "downwardapi-volume-54d7cf13-5afa-4551-aa73-0b209a4423c1" in namespace "downward-api-3686" to be "success or failure"
Dec  3 16:40:08.198: INFO: Pod "downwardapi-volume-54d7cf13-5afa-4551-aa73-0b209a4423c1": Phase="Pending", Reason="", readiness=false. Elapsed: 17.142648ms
Dec  3 16:40:10.216: INFO: Pod "downwardapi-volume-54d7cf13-5afa-4551-aa73-0b209a4423c1": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035323087s
Dec  3 16:40:12.234: INFO: Pod "downwardapi-volume-54d7cf13-5afa-4551-aa73-0b209a4423c1": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.053558189s
STEP: Saw pod success
Dec  3 16:40:12.234: INFO: Pod "downwardapi-volume-54d7cf13-5afa-4551-aa73-0b209a4423c1" satisfied condition "success or failure"
Dec  3 16:40:12.251: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downwardapi-volume-54d7cf13-5afa-4551-aa73-0b209a4423c1 container client-container: <nil>
STEP: delete the pod
Dec  3 16:40:12.447: INFO: Waiting for pod downwardapi-volume-54d7cf13-5afa-4551-aa73-0b209a4423c1 to disappear
Dec  3 16:40:12.464: INFO: Pod downwardapi-volume-54d7cf13-5afa-4551-aa73-0b209a4423c1 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:40:12.464: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3686" for this suite.
Dec  3 16:40:18.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:40:19.186: INFO: namespace downward-api-3686 deletion completed in 6.688642725s
•
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:40:19.186: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-2440
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:40:19.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-2440" for this suite.
Dec  3 16:40:25.522: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:40:26.136: INFO: namespace kubelet-test-2440 deletion completed in 6.673632724s
•SSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:40:26.137: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6046
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-1d42f5df-9287-4387-9bff-7008a7e29bcb
STEP: Creating secret with name s-test-opt-upd-129a2bda-7cdf-425e-91a4-d33e88f54b86
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-1d42f5df-9287-4387-9bff-7008a7e29bcb
STEP: Updating secret s-test-opt-upd-129a2bda-7cdf-425e-91a4-d33e88f54b86
STEP: Creating secret with name s-test-opt-create-bac7b286-b5b4-4a4f-b1ca-091598c6bd72
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:41:41.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6046" for this suite.
Dec  3 16:42:09.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:42:10.480: INFO: namespace secrets-6046 deletion completed in 28.648430402s
•SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:42:10.481: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-323
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-323
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-323
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-323
Dec  3 16:42:10.790: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Dec  3 16:42:20.809: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec  3 16:42:20.827: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-323 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:42:21.754: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:42:21.754: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:42:21.754: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 16:42:21.772: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  3 16:42:31.791: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 16:42:31.791: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 16:42:31.862: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999514s
Dec  3 16:42:32.883: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.982136527s
Dec  3 16:42:33.901: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.960966629s
Dec  3 16:42:34.920: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.943002377s
Dec  3 16:42:35.938: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.924051433s
Dec  3 16:42:36.957: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.90583855s
Dec  3 16:42:37.975: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.887513326s
Dec  3 16:42:38.993: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.869506517s
Dec  3 16:42:40.011: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.851038593s
Dec  3 16:42:41.029: INFO: Verifying statefulset ss doesn't scale past 1 for another 833.004986ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-323
Dec  3 16:42:42.052: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-323 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:42:42.712: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 16:42:42.712: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 16:42:42.712: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 16:42:42.730: INFO: Found 1 stateful pods, waiting for 3
Dec  3 16:42:52.749: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:42:52.749: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:42:52.749: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec  3 16:42:52.783: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-323 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:42:53.443: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:42:53.443: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:42:53.443: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 16:42:53.443: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-323 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:42:54.141: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:42:54.141: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:42:54.141: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 16:42:54.141: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-323 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:42:54.837: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:42:54.837: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:42:54.837: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 16:42:54.837: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 16:42:54.855: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Dec  3 16:43:04.892: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 16:43:04.892: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 16:43:04.892: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 16:43:04.945: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999431s
Dec  3 16:43:05.963: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.982288933s
Dec  3 16:43:06.981: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.963826767s
Dec  3 16:43:07.999: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.945541209s
Dec  3 16:43:09.018: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.927428009s
Dec  3 16:43:10.039: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.908998763s
Dec  3 16:43:11.058: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.887567998s
Dec  3 16:43:12.076: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.868793011s
Dec  3 16:43:13.095: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.850552862s
Dec  3 16:43:14.113: INFO: Verifying statefulset ss doesn't scale past 3 for another 832.072134ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-323
Dec  3 16:43:15.132: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-323 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:43:15.755: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 16:43:15.756: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 16:43:15.756: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 16:43:15.756: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-323 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:43:16.385: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 16:43:16.385: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 16:43:16.385: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 16:43:16.386: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-323 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:43:17.013: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 16:43:17.013: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 16:43:17.013: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 16:43:17.013: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  3 16:43:47.093: INFO: Deleting all statefulset in ns statefulset-323
Dec  3 16:43:47.110: INFO: Scaling statefulset ss to 0
Dec  3 16:43:47.162: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 16:43:47.179: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:43:47.233: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-323" for this suite.
Dec  3 16:43:53.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:43:53.927: INFO: namespace statefulset-323 deletion completed in 6.66134249s
•SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:43:53.927: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9673
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec  3 16:43:54.179: INFO: Waiting up to 5m0s for pod "downward-api-59ee2e2e-156e-4e73-aa7a-b9b2693eb410" in namespace "downward-api-9673" to be "success or failure"
Dec  3 16:43:54.196: INFO: Pod "downward-api-59ee2e2e-156e-4e73-aa7a-b9b2693eb410": Phase="Pending", Reason="", readiness=false. Elapsed: 17.28343ms
Dec  3 16:43:56.214: INFO: Pod "downward-api-59ee2e2e-156e-4e73-aa7a-b9b2693eb410": Phase="Pending", Reason="", readiness=false. Elapsed: 2.035409397s
Dec  3 16:43:58.232: INFO: Pod "downward-api-59ee2e2e-156e-4e73-aa7a-b9b2693eb410": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05343333s
STEP: Saw pod success
Dec  3 16:43:58.232: INFO: Pod "downward-api-59ee2e2e-156e-4e73-aa7a-b9b2693eb410" satisfied condition "success or failure"
Dec  3 16:43:58.250: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod downward-api-59ee2e2e-156e-4e73-aa7a-b9b2693eb410 container dapi-container: <nil>
STEP: delete the pod
Dec  3 16:43:58.420: INFO: Waiting for pod downward-api-59ee2e2e-156e-4e73-aa7a-b9b2693eb410 to disappear
Dec  3 16:43:58.437: INFO: Pod downward-api-59ee2e2e-156e-4e73-aa7a-b9b2693eb410 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:43:58.437: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9673" for this suite.
Dec  3 16:44:04.536: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:44:05.133: INFO: namespace downward-api-9673 deletion completed in 6.65400935s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:44:05.134: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2325
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: Gathering metrics
Dec  3 16:44:05.544: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1203 16:44:05.544837    5095 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:44:05.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2325" for this suite.
Dec  3 16:44:11.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:44:12.221: INFO: namespace gc-2325 deletion completed in 6.659584624s
•SSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:44:12.222: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3053
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Dec  3 16:44:12.480: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:44:30.752: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3053" for this suite.
Dec  3 16:44:36.836: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:44:37.432: INFO: namespace pods-3053 deletion completed in 6.647756911s
•SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:44:37.432: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-3964
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:44:53.817: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-3964" for this suite.
Dec  3 16:44:59.902: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:45:00.498: INFO: namespace resourcequota-3964 deletion completed in 6.648246832s
•S
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:45:00.498: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-7257
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-7257
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-7257
STEP: Creating statefulset with conflicting port in namespace statefulset-7257
STEP: Waiting until pod test-pod will start running in namespace statefulset-7257
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-7257
Dec  3 16:45:02.850: INFO: Observed stateful pod in namespace: statefulset-7257, name: ss-0, uid: 9a3c00bc-2ad6-4cda-999d-5187994948a9, status phase: Pending. Waiting for statefulset controller to delete.
Dec  3 16:45:10.701: INFO: Observed stateful pod in namespace: statefulset-7257, name: ss-0, uid: 9a3c00bc-2ad6-4cda-999d-5187994948a9, status phase: Failed. Waiting for statefulset controller to delete.
Dec  3 16:45:10.705: INFO: Observed stateful pod in namespace: statefulset-7257, name: ss-0, uid: 9a3c00bc-2ad6-4cda-999d-5187994948a9, status phase: Failed. Waiting for statefulset controller to delete.
Dec  3 16:45:10.714: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-7257
STEP: Removing pod with conflicting port in namespace statefulset-7257
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-7257 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  3 16:45:22.874: INFO: Deleting all statefulset in ns statefulset-7257
Dec  3 16:45:22.891: INFO: Scaling statefulset ss to 0
Dec  3 16:45:32.963: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 16:45:32.980: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:45:33.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7257" for this suite.
Dec  3 16:45:39.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:45:39.712: INFO: namespace statefulset-7257 deletion completed in 6.644410993s
•S
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:45:39.712: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6432
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-6432/configmap-test-cb6f4b07-5b57-44d3-aea6-bac093978ab1
STEP: Creating a pod to test consume configMaps
Dec  3 16:45:39.977: INFO: Waiting up to 5m0s for pod "pod-configmaps-c1648a46-20ba-45e0-b617-1ab736c1be4a" in namespace "configmap-6432" to be "success or failure"
Dec  3 16:45:39.995: INFO: Pod "pod-configmaps-c1648a46-20ba-45e0-b617-1ab736c1be4a": Phase="Pending", Reason="", readiness=false. Elapsed: 18.36232ms
Dec  3 16:45:42.013: INFO: Pod "pod-configmaps-c1648a46-20ba-45e0-b617-1ab736c1be4a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.036244599s
Dec  3 16:45:44.031: INFO: Pod "pod-configmaps-c1648a46-20ba-45e0-b617-1ab736c1be4a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.054197229s
STEP: Saw pod success
Dec  3 16:45:44.031: INFO: Pod "pod-configmaps-c1648a46-20ba-45e0-b617-1ab736c1be4a" satisfied condition "success or failure"
Dec  3 16:45:44.048: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-configmaps-c1648a46-20ba-45e0-b617-1ab736c1be4a container env-test: <nil>
STEP: delete the pod
Dec  3 16:45:44.106: INFO: Waiting for pod pod-configmaps-c1648a46-20ba-45e0-b617-1ab736c1be4a to disappear
Dec  3 16:45:44.123: INFO: Pod pod-configmaps-c1648a46-20ba-45e0-b617-1ab736c1be4a no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:45:44.123: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6432" for this suite.
Dec  3 16:45:50.210: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:45:50.849: INFO: namespace configmap-6432 deletion completed in 6.693300022s
•SSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:45:50.849: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7946
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:45:56.261: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7946" for this suite.
Dec  3 16:46:02.428: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:46:03.020: INFO: namespace watch-7946 deletion completed in 6.710277264s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:46:03.021: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1956
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Dec  3 16:46:43.397: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1203 16:46:43.397309    5095 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:46:43.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1956" for this suite.
Dec  3 16:46:49.473: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:46:50.143: INFO: namespace gc-1956 deletion completed in 6.72203737s
•SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:46:50.143: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9963
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Dec  3 16:46:50.367: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-9963'
Dec  3 16:46:50.716: INFO: stderr: ""
Dec  3 16:46:50.716: INFO: stdout: "pod/pause created\n"
Dec  3 16:46:50.716: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec  3 16:46:50.716: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9963" to be "running and ready"
Dec  3 16:46:50.733: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 17.019986ms
Dec  3 16:46:52.751: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03503106s
Dec  3 16:46:54.769: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.053034791s
Dec  3 16:46:54.769: INFO: Pod "pause" satisfied condition "running and ready"
Dec  3 16:46:54.769: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Dec  3 16:46:54.769: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config label pods pause testing-label=testing-label-value --namespace=kubectl-9963'
Dec  3 16:46:54.935: INFO: stderr: ""
Dec  3 16:46:54.935: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec  3 16:46:54.935: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod pause -L testing-label --namespace=kubectl-9963'
Dec  3 16:46:55.086: INFO: stderr: ""
Dec  3 16:46:55.086: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec  3 16:46:55.086: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config label pods pause testing-label- --namespace=kubectl-9963'
Dec  3 16:46:55.254: INFO: stderr: ""
Dec  3 16:46:55.254: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec  3 16:46:55.254: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod pause -L testing-label --namespace=kubectl-9963'
Dec  3 16:46:55.399: INFO: stderr: ""
Dec  3 16:46:55.399: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Dec  3 16:46:55.399: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-9963'
Dec  3 16:46:55.576: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 16:46:55.576: INFO: stdout: "pod \"pause\" force deleted\n"
Dec  3 16:46:55.576: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=pause --no-headers --namespace=kubectl-9963'
Dec  3 16:46:55.735: INFO: stderr: "No resources found in kubectl-9963 namespace.\n"
Dec  3 16:46:55.735: INFO: stdout: ""
Dec  3 16:46:55.736: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=pause --namespace=kubectl-9963 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 16:46:55.896: INFO: stderr: ""
Dec  3 16:46:55.896: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:46:55.896: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9963" for this suite.
Dec  3 16:47:01.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:47:02.569: INFO: namespace kubectl-9963 deletion completed in 6.639601786s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:47:02.570: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7115
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:47:02.800: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config version'
Dec  3 16:47:02.944: INFO: stderr: ""
Dec  3 16:47:02.944: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.3\", GitCommit:\"b3cbbae08ec52a7fc73d334838e18d17e8512749\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:23:11Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.3\", GitCommit:\"b3cbbae08ec52a7fc73d334838e18d17e8512749\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:13:49Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:47:02.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7115" for this suite.
Dec  3 16:47:09.014: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:47:09.617: INFO: namespace kubectl-7115 deletion completed in 6.65470654s
•SSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:47:09.617: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3126
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-0074c720-608b-451a-93f6-a186af12aa5d
STEP: Creating a pod to test consume secrets
Dec  3 16:47:09.878: INFO: Waiting up to 5m0s for pod "pod-secrets-e441627a-954f-428b-86be-38795299ab05" in namespace "secrets-3126" to be "success or failure"
Dec  3 16:47:09.895: INFO: Pod "pod-secrets-e441627a-954f-428b-86be-38795299ab05": Phase="Pending", Reason="", readiness=false. Elapsed: 16.759887ms
Dec  3 16:47:11.913: INFO: Pod "pod-secrets-e441627a-954f-428b-86be-38795299ab05": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034985673s
Dec  3 16:47:13.931: INFO: Pod "pod-secrets-e441627a-954f-428b-86be-38795299ab05": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05305583s
STEP: Saw pod success
Dec  3 16:47:13.931: INFO: Pod "pod-secrets-e441627a-954f-428b-86be-38795299ab05" satisfied condition "success or failure"
Dec  3 16:47:13.948: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-secrets-e441627a-954f-428b-86be-38795299ab05 container secret-env-test: <nil>
STEP: delete the pod
Dec  3 16:47:14.009: INFO: Waiting for pod pod-secrets-e441627a-954f-428b-86be-38795299ab05 to disappear
Dec  3 16:47:14.026: INFO: Pod pod-secrets-e441627a-954f-428b-86be-38795299ab05 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:47:14.026: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3126" for this suite.
Dec  3 16:47:20.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:47:20.743: INFO: namespace secrets-3126 deletion completed in 6.683441205s
•SSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:47:20.744: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9356
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  3 16:47:24.090: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:47:24.131: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9356" for this suite.
Dec  3 16:47:30.217: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:47:30.822: INFO: namespace container-runtime-9356 deletion completed in 6.657984571s
•
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:47:30.823: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-2987
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:47:31.042: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec  3 16:47:34.343: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2987 create -f -'
Dec  3 16:47:34.980: INFO: stderr: ""
Dec  3 16:47:34.980: INFO: stdout: "e2e-test-crd-publish-openapi-248-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec  3 16:47:34.980: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2987 delete e2e-test-crd-publish-openapi-248-crds test-cr'
Dec  3 16:47:35.197: INFO: stderr: ""
Dec  3 16:47:35.197: INFO: stdout: "e2e-test-crd-publish-openapi-248-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Dec  3 16:47:35.197: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2987 apply -f -'
Dec  3 16:47:35.618: INFO: stderr: ""
Dec  3 16:47:35.618: INFO: stdout: "e2e-test-crd-publish-openapi-248-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec  3 16:47:35.618: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-2987 delete e2e-test-crd-publish-openapi-248-crds test-cr'
Dec  3 16:47:35.782: INFO: stderr: ""
Dec  3 16:47:35.783: INFO: stdout: "e2e-test-crd-publish-openapi-248-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec  3 16:47:35.783: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-248-crds'
Dec  3 16:47:36.100: INFO: stderr: ""
Dec  3 16:47:36.100: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-248-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:47:39.877: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-2987" for this suite.
Dec  3 16:47:45.962: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:47:46.565: INFO: namespace crd-publish-openapi-2987 deletion completed in 6.655078582s
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:47:46.565: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8349
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-71493bd8-ed91-4087-82e7-3064ab7aac16
STEP: Creating secret with name s-test-opt-upd-b1b92155-3db0-47be-9314-0ca0a784c0cf
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-71493bd8-ed91-4087-82e7-3064ab7aac16
STEP: Updating secret s-test-opt-upd-b1b92155-3db0-47be-9314-0ca0a784c0cf
STEP: Creating secret with name s-test-opt-create-13b6e135-1550-46c6-8a4e-f08b9240ed2c
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:47:53.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8349" for this suite.
Dec  3 16:48:11.467: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:48:12.060: INFO: namespace projected-8349 deletion completed in 18.655635562s
•S
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:48:12.060: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7115
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  3 16:48:12.288: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-7115'
Dec  3 16:48:12.436: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 16:48:12.436: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Dec  3 16:48:14.477: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete deployment e2e-test-httpd-deployment --namespace=kubectl-7115'
Dec  3 16:48:14.644: INFO: stderr: ""
Dec  3 16:48:14.644: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:48:14.644: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7115" for this suite.
Dec  3 16:48:26.732: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:48:27.337: INFO: namespace kubectl-7115 deletion completed in 12.659118736s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:48:27.338: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-3786
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec  3 16:48:27.573: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 16:48:27.630: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 16:48:27.647: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk before test
Dec  3 16:48:27.673: INFO: node-exporter-99hck from kube-system started at 2019-12-03 14:41:41 +0000 UTC (1 container statuses recorded)
Dec  3 16:48:27.673: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 16:48:27.673: INFO: calico-node-v7kgq from kube-system started at 2019-12-03 14:41:41 +0000 UTC (1 container statuses recorded)
Dec  3 16:48:27.673: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 16:48:27.673: INFO: kube-proxy-9gxg8 from kube-system started at 2019-12-03 14:41:41 +0000 UTC (1 container statuses recorded)
Dec  3 16:48:27.673: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 16:48:27.673: INFO: node-problem-detector-sjm82 from kube-system started at 2019-12-03 14:41:41 +0000 UTC (1 container statuses recorded)
Dec  3 16:48:27.673: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 16:48:27.673: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmp1w-0ph-worker-1-869986d578-xwg6v before test
Dec  3 16:48:27.733: INFO: vpn-shoot-67b54fb-qrrtn from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:48:27.733: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec  3 16:48:27.733: INFO: addons-kubernetes-dashboard-78954cc66b-tpjhb from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:48:27.733: INFO: 	Container kubernetes-dashboard ready: true, restart count 1
Dec  3 16:48:27.733: INFO: node-exporter-f5c97 from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 16:48:27.733: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 16:48:27.733: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-95f65778d-gxfs2 from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:48:27.733: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec  3 16:48:27.733: INFO: calico-kube-controllers-79bcd784b6-kz756 from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:48:27.733: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  3 16:48:27.733: INFO: addons-nginx-ingress-controller-7c75bb76db-42ck9 from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:48:27.733: INFO: 	Container nginx-ingress-controller ready: true, restart count 0
Dec  3 16:48:27.733: INFO: calico-typha-vertical-autoscaler-847d859f8c-vcs4n from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:48:27.733: INFO: 	Container autoscaler ready: true, restart count 4
Dec  3 16:48:27.733: INFO: metrics-server-898dc9876-hqcdm from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:48:27.733: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 16:48:27.733: INFO: calico-node-db7rh from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 16:48:27.733: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 16:48:27.733: INFO: kube-proxy-mjx4w from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 16:48:27.733: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 16:48:27.733: INFO: calico-typha-deploy-9f6b455c4-6sv6p from kube-system started at 2019-12-03 15:04:38 +0000 UTC (1 container statuses recorded)
Dec  3 16:48:27.733: INFO: 	Container calico-typha ready: true, restart count 0
Dec  3 16:48:27.733: INFO: coredns-59c969ffb8-jg798 from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:48:27.733: INFO: 	Container coredns ready: true, restart count 0
Dec  3 16:48:27.733: INFO: calico-typha-horizontal-autoscaler-69df649c59-c4drn from kube-system started at 2019-12-03 14:39:52 +0000 UTC (1 container statuses recorded)
Dec  3 16:48:27.733: INFO: 	Container autoscaler ready: true, restart count 0
Dec  3 16:48:27.733: INFO: blackbox-exporter-7bd7b55dfc-s569k from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 16:48:27.733: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec  3 16:48:27.733: INFO: node-problem-detector-l8d9w from kube-system started at 2019-12-03 14:39:29 +0000 UTC (1 container statuses recorded)
Dec  3 16:48:27.733: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 16:48:27.733: INFO: coredns-59c969ffb8-ldh2q from kube-system started at 2019-12-03 14:39:49 +0000 UTC (1 container statuses recorded)
Dec  3 16:48:27.733: INFO: 	Container coredns ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-14505d8d-45ff-46fd-a795-a46cafdfd585 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-14505d8d-45ff-46fd-a795-a46cafdfd585 off the node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk
STEP: verifying the node doesn't have the label kubernetes.io/e2e-14505d8d-45ff-46fd-a795-a46cafdfd585
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:53:36.038: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-3786" for this suite.
Dec  3 16:53:44.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:53:44.703: INFO: namespace sched-pred-3786 deletion completed in 8.646474967s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:317.365 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:53:44.703: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3184
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-38b209a9-97f6-4d1b-8d4a-df5faab8cce6
STEP: Creating a pod to test consume configMaps
Dec  3 16:53:44.962: INFO: Waiting up to 5m0s for pod "pod-configmaps-edf5c75b-1965-46a5-9626-466776b811c4" in namespace "configmap-3184" to be "success or failure"
Dec  3 16:53:44.979: INFO: Pod "pod-configmaps-edf5c75b-1965-46a5-9626-466776b811c4": Phase="Pending", Reason="", readiness=false. Elapsed: 16.596057ms
Dec  3 16:53:46.997: INFO: Pod "pod-configmaps-edf5c75b-1965-46a5-9626-466776b811c4": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034483571s
Dec  3 16:53:49.014: INFO: Pod "pod-configmaps-edf5c75b-1965-46a5-9626-466776b811c4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052072925s
STEP: Saw pod success
Dec  3 16:53:49.014: INFO: Pod "pod-configmaps-edf5c75b-1965-46a5-9626-466776b811c4" satisfied condition "success or failure"
Dec  3 16:53:49.031: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-configmaps-edf5c75b-1965-46a5-9626-466776b811c4 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 16:53:49.225: INFO: Waiting for pod pod-configmaps-edf5c75b-1965-46a5-9626-466776b811c4 to disappear
Dec  3 16:53:49.242: INFO: Pod pod-configmaps-edf5c75b-1965-46a5-9626-466776b811c4 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:53:49.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3184" for this suite.
Dec  3 16:53:55.327: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:53:55.924: INFO: namespace configmap-3184 deletion completed in 6.648338626s
•
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:53:55.924: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7716
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec  3 16:54:00.784: INFO: Successfully updated pod "labelsupdatedf001a82-fd84-490d-8758-9697066966af"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:54:02.841: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7716" for this suite.
Dec  3 16:54:26.926: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:54:27.530: INFO: namespace downward-api-7716 deletion completed in 24.65628732s
•SSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:54:27.531: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2337
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  3 16:54:27.773: INFO: Waiting up to 5m0s for pod "pod-0cccd008-3392-4634-9fee-bd0263850b12" in namespace "emptydir-2337" to be "success or failure"
Dec  3 16:54:27.793: INFO: Pod "pod-0cccd008-3392-4634-9fee-bd0263850b12": Phase="Pending", Reason="", readiness=false. Elapsed: 19.89176ms
Dec  3 16:54:29.811: INFO: Pod "pod-0cccd008-3392-4634-9fee-bd0263850b12": Phase="Pending", Reason="", readiness=false. Elapsed: 2.038295562s
Dec  3 16:54:31.829: INFO: Pod "pod-0cccd008-3392-4634-9fee-bd0263850b12": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.05568163s
STEP: Saw pod success
Dec  3 16:54:31.829: INFO: Pod "pod-0cccd008-3392-4634-9fee-bd0263850b12" satisfied condition "success or failure"
Dec  3 16:54:31.845: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-0cccd008-3392-4634-9fee-bd0263850b12 container test-container: <nil>
STEP: delete the pod
Dec  3 16:54:31.892: INFO: Waiting for pod pod-0cccd008-3392-4634-9fee-bd0263850b12 to disappear
Dec  3 16:54:31.910: INFO: Pod pod-0cccd008-3392-4634-9fee-bd0263850b12 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:54:31.910: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2337" for this suite.
Dec  3 16:54:37.993: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:54:38.588: INFO: namespace emptydir-2337 deletion completed in 6.646091765s
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:54:38.589: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-6547
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6547.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-6547.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 16:54:45.481: INFO: DNS probes using dns-6547/dns-test-1079fd52-1148-43ef-9e9e-c01d5f8b31c7 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:54:45.510: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-6547" for this suite.
Dec  3 16:54:51.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:54:52.187: INFO: namespace dns-6547 deletion completed in 6.643956521s
•SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:54:52.188: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-379
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:54:56.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-379" for this suite.
Dec  3 16:55:42.592: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:55:43.182: INFO: namespace kubelet-test-379 deletion completed in 46.641296195s
•
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:55:43.182: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7733
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  3 16:55:43.436: INFO: Waiting up to 5m0s for pod "pod-c6a92348-c6d2-48c2-a69e-a0e49dd440a7" in namespace "emptydir-7733" to be "success or failure"
Dec  3 16:55:43.457: INFO: Pod "pod-c6a92348-c6d2-48c2-a69e-a0e49dd440a7": Phase="Pending", Reason="", readiness=false. Elapsed: 21.010915ms
Dec  3 16:55:45.475: INFO: Pod "pod-c6a92348-c6d2-48c2-a69e-a0e49dd440a7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.03913214s
Dec  3 16:55:47.493: INFO: Pod "pod-c6a92348-c6d2-48c2-a69e-a0e49dd440a7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.056909824s
STEP: Saw pod success
Dec  3 16:55:47.493: INFO: Pod "pod-c6a92348-c6d2-48c2-a69e-a0e49dd440a7" satisfied condition "success or failure"
Dec  3 16:55:47.510: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-c6a92348-c6d2-48c2-a69e-a0e49dd440a7 container test-container: <nil>
STEP: delete the pod
Dec  3 16:55:47.566: INFO: Waiting for pod pod-c6a92348-c6d2-48c2-a69e-a0e49dd440a7 to disappear
Dec  3 16:55:47.583: INFO: Pod pod-c6a92348-c6d2-48c2-a69e-a0e49dd440a7 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:55:47.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7733" for this suite.
Dec  3 16:55:53.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:55:54.283: INFO: namespace emptydir-7733 deletion completed in 6.667614966s
•SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:55:54.284: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2990
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:55:54.506: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:55:55.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2990" for this suite.
Dec  3 16:56:02.068: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:56:02.652: INFO: namespace custom-resource-definition-2990 deletion completed in 6.636669586s
•SSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:56:02.652: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-8854
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:56:34.890: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-8854" for this suite.
Dec  3 16:56:40.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:56:41.561: INFO: namespace container-runtime-8854 deletion completed in 6.638330875s
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:56:41.562: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6384
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 16:56:42.524: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710989002, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710989002, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710989002, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710989002, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 16:56:44.542: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710989002, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710989002, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710989002, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710989002, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 16:56:47.571: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:56:58.551: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6384" for this suite.
Dec  3 16:57:04.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:57:05.234: INFO: namespace webhook-6384 deletion completed in 6.64409277s
STEP: Destroying namespace "webhook-6384-markers" for this suite.
Dec  3 16:57:11.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:57:11.881: INFO: namespace webhook-6384-markers deletion completed in 6.646951493s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:57:11.952: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6528
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Dec  3 16:57:12.181: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-6528'
Dec  3 16:57:12.512: INFO: stderr: ""
Dec  3 16:57:12.513: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 16:57:12.513: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6528'
Dec  3 16:57:12.664: INFO: stderr: ""
Dec  3 16:57:12.664: INFO: stdout: "update-demo-nautilus-4s9lw update-demo-nautilus-lvsqd "
Dec  3 16:57:12.664: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-4s9lw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6528'
Dec  3 16:57:12.804: INFO: stderr: ""
Dec  3 16:57:12.804: INFO: stdout: ""
Dec  3 16:57:12.804: INFO: update-demo-nautilus-4s9lw is created but not running
Dec  3 16:57:17.804: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6528'
Dec  3 16:57:17.952: INFO: stderr: ""
Dec  3 16:57:17.952: INFO: stdout: "update-demo-nautilus-4s9lw update-demo-nautilus-lvsqd "
Dec  3 16:57:17.952: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-4s9lw -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6528'
Dec  3 16:57:18.095: INFO: stderr: ""
Dec  3 16:57:18.095: INFO: stdout: "true"
Dec  3 16:57:18.095: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-4s9lw -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6528'
Dec  3 16:57:18.236: INFO: stderr: ""
Dec  3 16:57:18.236: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 16:57:18.236: INFO: validating pod update-demo-nautilus-4s9lw
Dec  3 16:57:18.344: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 16:57:18.344: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 16:57:18.344: INFO: update-demo-nautilus-4s9lw is verified up and running
Dec  3 16:57:18.344: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-lvsqd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6528'
Dec  3 16:57:18.492: INFO: stderr: ""
Dec  3 16:57:18.492: INFO: stdout: "true"
Dec  3 16:57:18.492: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-lvsqd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6528'
Dec  3 16:57:18.633: INFO: stderr: ""
Dec  3 16:57:18.633: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 16:57:18.633: INFO: validating pod update-demo-nautilus-lvsqd
Dec  3 16:57:18.740: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 16:57:18.740: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 16:57:18.740: INFO: update-demo-nautilus-lvsqd is verified up and running
STEP: rolling-update to new replication controller
Dec  3 16:57:18.743: INFO: scanned /root for discovery docs: <nil>
Dec  3 16:57:18.743: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-6528'
Dec  3 16:57:35.786: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  3 16:57:35.786: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 16:57:35.786: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-6528'
Dec  3 16:57:36.191: INFO: stderr: ""
Dec  3 16:57:36.192: INFO: stdout: "update-demo-kitten-p866p update-demo-kitten-vsn2t "
Dec  3 16:57:36.192: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-p866p -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6528'
Dec  3 16:57:36.338: INFO: stderr: ""
Dec  3 16:57:36.338: INFO: stdout: "true"
Dec  3 16:57:36.338: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-p866p -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6528'
Dec  3 16:57:36.473: INFO: stderr: ""
Dec  3 16:57:36.473: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  3 16:57:36.473: INFO: validating pod update-demo-kitten-p866p
Dec  3 16:57:36.581: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  3 16:57:36.581: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  3 16:57:36.581: INFO: update-demo-kitten-p866p is verified up and running
Dec  3 16:57:36.581: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-vsn2t -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-6528'
Dec  3 16:57:36.721: INFO: stderr: ""
Dec  3 16:57:36.721: INFO: stdout: "true"
Dec  3 16:57:36.721: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-vsn2t -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-6528'
Dec  3 16:57:36.863: INFO: stderr: ""
Dec  3 16:57:36.863: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  3 16:57:36.863: INFO: validating pod update-demo-kitten-vsn2t
Dec  3 16:57:36.968: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  3 16:57:36.968: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  3 16:57:36.968: INFO: update-demo-kitten-vsn2t is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:57:36.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6528" for this suite.
Dec  3 16:58:05.063: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:58:05.649: INFO: namespace kubectl-6528 deletion completed in 28.64729641s
•SSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:58:05.649: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4377
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:58:05.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4377" for this suite.
Dec  3 16:58:11.969: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:58:12.567: INFO: namespace services-4377 deletion completed in 6.649684092s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:58:12.567: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8039
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Dec  3 16:58:12.808: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec  3 16:58:12.808: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-8039'
Dec  3 16:58:13.172: INFO: stderr: ""
Dec  3 16:58:13.172: INFO: stdout: "service/redis-slave created\n"
Dec  3 16:58:13.173: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec  3 16:58:13.173: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-8039'
Dec  3 16:58:13.555: INFO: stderr: ""
Dec  3 16:58:13.555: INFO: stdout: "service/redis-master created\n"
Dec  3 16:58:13.555: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec  3 16:58:13.555: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-8039'
Dec  3 16:58:13.921: INFO: stderr: ""
Dec  3 16:58:13.921: INFO: stdout: "service/frontend created\n"
Dec  3 16:58:13.921: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec  3 16:58:13.921: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-8039'
Dec  3 16:58:14.268: INFO: stderr: ""
Dec  3 16:58:14.268: INFO: stdout: "deployment.apps/frontend created\n"
Dec  3 16:58:14.268: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec  3 16:58:14.268: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-8039'
Dec  3 16:58:14.603: INFO: stderr: ""
Dec  3 16:58:14.603: INFO: stdout: "deployment.apps/redis-master created\n"
Dec  3 16:58:14.604: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec  3 16:58:14.604: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-8039'
Dec  3 16:58:14.932: INFO: stderr: ""
Dec  3 16:58:14.932: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Dec  3 16:58:14.933: INFO: Waiting for all frontend pods to be Running.
Dec  3 16:58:44.984: INFO: Waiting for frontend to serve content.
Dec  3 16:58:45.093: INFO: Trying to add a new entry to the guestbook.
Dec  3 16:58:45.225: INFO: Verifying that added entry can be retrieved.
Dec  3 16:58:45.277: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  3 16:58:50.386: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  3 16:58:55.494: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  3 16:59:00.604: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  3 16:59:05.716: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  3 16:59:10.828: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  3 16:59:15.940: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Dec  3 16:59:21.050: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-8039'
Dec  3 16:59:21.257: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 16:59:21.257: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 16:59:21.258: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-8039'
Dec  3 16:59:21.437: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 16:59:21.437: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 16:59:21.437: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-8039'
Dec  3 16:59:21.630: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 16:59:21.630: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 16:59:21.631: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-8039'
Dec  3 16:59:21.822: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 16:59:21.822: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 16:59:21.822: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-8039'
Dec  3 16:59:21.979: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 16:59:21.979: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 16:59:21.979: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-8039'
Dec  3 16:59:22.142: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 16:59:22.142: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:59:22.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8039" for this suite.
Dec  3 16:59:34.227: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:59:34.832: INFO: namespace kubectl-8039 deletion completed in 12.656956802s
•SSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:59:34.832: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1169
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  3 16:59:39.685: INFO: Successfully updated pod "pod-update-444cddb6-4e6b-49ba-b074-333f8b55aa6b"
STEP: verifying the updated pod is in kubernetes
Dec  3 16:59:39.719: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:59:39.719: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1169" for this suite.
Dec  3 17:00:07.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 17:00:08.387: INFO: namespace pods-1169 deletion completed in 28.636039441s
•SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 17:00:08.387: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7135
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-d916cf80-56db-4798-b4ce-2570ff654e83
STEP: Creating a pod to test consume configMaps
Dec  3 17:00:08.647: INFO: Waiting up to 5m0s for pod "pod-configmaps-260296a5-bd7e-4748-bf32-c1894be4dd40" in namespace "configmap-7135" to be "success or failure"
Dec  3 17:00:08.664: INFO: Pod "pod-configmaps-260296a5-bd7e-4748-bf32-c1894be4dd40": Phase="Pending", Reason="", readiness=false. Elapsed: 17.075194ms
Dec  3 17:00:10.682: INFO: Pod "pod-configmaps-260296a5-bd7e-4748-bf32-c1894be4dd40": Phase="Pending", Reason="", readiness=false. Elapsed: 2.034932881s
Dec  3 17:00:12.699: INFO: Pod "pod-configmaps-260296a5-bd7e-4748-bf32-c1894be4dd40": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.052557219s
STEP: Saw pod success
Dec  3 17:00:12.699: INFO: Pod "pod-configmaps-260296a5-bd7e-4748-bf32-c1894be4dd40" satisfied condition "success or failure"
Dec  3 17:00:12.716: INFO: Trying to get logs from node shoot--it--tmp1w-0ph-worker-1-869986d578-fn8zk pod pod-configmaps-260296a5-bd7e-4748-bf32-c1894be4dd40 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 17:00:12.910: INFO: Waiting for pod pod-configmaps-260296a5-bd7e-4748-bf32-c1894be4dd40 to disappear
Dec  3 17:00:12.927: INFO: Pod pod-configmaps-260296a5-bd7e-4748-bf32-c1894be4dd40 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 17:00:12.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7135" for this suite.
Dec  3 17:00:19.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 17:00:19.612: INFO: namespace configmap-7135 deletion completed in 6.651217651s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 17:00:19.612: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7966
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec  3 17:00:19.924: INFO: namespace kubectl-7966
Dec  3 17:00:19.924: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-7966'
Dec  3 17:00:20.213: INFO: stderr: ""
Dec  3 17:00:20.213: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  3 17:00:21.231: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 17:00:21.231: INFO: Found 0 / 1
Dec  3 17:00:22.231: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 17:00:22.231: INFO: Found 0 / 1
Dec  3 17:00:23.231: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 17:00:23.231: INFO: Found 1 / 1
Dec  3 17:00:23.231: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  3 17:00:23.249: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 17:00:23.249: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 17:00:23.249: INFO: wait on redis-master startup in kubectl-7966 
Dec  3 17:00:23.249: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs redis-master-kqqgh redis-master --namespace=kubectl-7966'
Dec  3 17:00:23.520: INFO: stderr: ""
Dec  3 17:00:23.520: INFO: stdout: "1:C 03 Dec 2019 17:00:21.528 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 03 Dec 2019 17:00:21.528 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 03 Dec 2019 17:00:21.528 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 03 Dec 2019 17:00:21.533 * Running mode=standalone, port=6379.\n1:M 03 Dec 2019 17:00:21.533 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Dec 2019 17:00:21.533 # Server initialized\n1:M 03 Dec 2019 17:00:21.534 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Dec 2019 17:00:21.534 * Ready to accept connections\n"
STEP: exposing RC
Dec  3 17:00:23.520: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-7966'
Dec  3 17:00:23.704: INFO: stderr: ""
Dec  3 17:00:23.704: INFO: stdout: "service/rm2 exposed\n"
Dec  3 17:00:23.721: INFO: Service rm2 in namespace kubectl-7966 found.
STEP: exposing service
Dec  3 17:00:25.756: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmp1w-0ph.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-7966'
Dec  3 17:00:25.965: INFO: stderr: ""
Dec  3 17:00:25.965: INFO: stdout: "service/rm3 exposed\n"
Dec  3 17:00:25.982: INFO: Service rm3 in namespace kubectl-7966 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 17:00:28.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7966" for this suite.
Dec  3 17:00:56.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 17:00:56.690: INFO: namespace kubectl-7966 deletion completed in 28.640607973s
•SSSSSDec  3 17:00:56.690: INFO: Running AfterSuite actions on all nodes
Dec  3 17:00:56.690: INFO: Running AfterSuite actions on node 1
Dec  3 17:00:56.690: INFO: Skipping dumping logs from cluster

Ran 276 of 4732 Specs in 7897.305 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Flaked | 0 Pending | 4456 Skipped
PASS

Ginkgo ran 1 suite in 2h11m39.200473143s
Test Suite Passed
