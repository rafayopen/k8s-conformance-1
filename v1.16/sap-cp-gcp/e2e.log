Conformance test: not doing test setup.
I1203 14:36:39.576528    5064 e2e.go:92] Starting e2e run "ecd78362-af97-4f4c-8860-165e7b020457" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1575383797 - Will randomize all specs
Will run 276 of 4732 specs

Dec  3 14:36:39.848: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Deleting namespaces
STEP: Waiting for namespaces to vanish
I1203 14:36:39.895369    5064 suites.go:70] Waiting for deletion of the following namespaces: []
Dec  3 14:36:41.906: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec  3 14:36:41.938: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec  3 14:36:42.110: INFO: 20 / 20 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec  3 14:36:42.111: INFO: expected 12 pod replicas in namespace 'kube-system', 12 are Running and Ready.
Dec  3 14:36:42.111: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec  3 14:36:42.129: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'calico-node' (0 seconds elapsed)
Dec  3 14:36:42.129: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec  3 14:36:42.129: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-exporter' (0 seconds elapsed)
Dec  3 14:36:42.129: INFO: 2 / 2 pods ready in namespace 'kube-system' in daemonset 'node-problem-detector' (0 seconds elapsed)
Dec  3 14:36:42.129: INFO: e2e test version: v1.16.3
Dec  3 14:36:42.138: INFO: kube-apiserver version: v1.16.3
Dec  3 14:36:42.138: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 14:36:42.151: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:36:42.152: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
Dec  3 14:36:42.216: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Dec  3 14:36:42.250: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3260
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 14:36:42.392: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec  3 14:36:45.773: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3260 create -f -'
Dec  3 14:37:09.189: INFO: stderr: ""
Dec  3 14:37:09.189: INFO: stdout: "e2e-test-crd-publish-openapi-7678-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec  3 14:37:09.189: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3260 delete e2e-test-crd-publish-openapi-7678-crds test-cr'
Dec  3 14:37:09.412: INFO: stderr: ""
Dec  3 14:37:09.412: INFO: stdout: "e2e-test-crd-publish-openapi-7678-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Dec  3 14:37:09.413: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3260 apply -f -'
Dec  3 14:37:11.032: INFO: stderr: ""
Dec  3 14:37:11.032: INFO: stdout: "e2e-test-crd-publish-openapi-7678-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec  3 14:37:11.032: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3260 delete e2e-test-crd-publish-openapi-7678-crds test-cr'
Dec  3 14:37:11.176: INFO: stderr: ""
Dec  3 14:37:11.176: INFO: stdout: "e2e-test-crd-publish-openapi-7678-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec  3 14:37:11.176: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-7678-crds'
Dec  3 14:37:11.804: INFO: stderr: ""
Dec  3 14:37:11.804: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7678-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:37:14.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3260" for this suite.
Dec  3 14:37:20.195: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:37:20.540: INFO: namespace crd-publish-openapi-3260 deletion completed in 6.376114151s
•S
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:37:20.540: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-4536
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:37:25.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-4536" for this suite.
Dec  3 14:37:32.127: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:37:32.477: INFO: namespace watch-4536 deletion completed in 6.458875586s
•S
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:37:32.477: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7141
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Dec  3 14:37:32.711: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec  3 14:37:32.711: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-7141'
Dec  3 14:37:33.121: INFO: stderr: ""
Dec  3 14:37:33.121: INFO: stdout: "service/redis-slave created\n"
Dec  3 14:37:33.121: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec  3 14:37:33.121: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-7141'
Dec  3 14:37:33.636: INFO: stderr: ""
Dec  3 14:37:33.636: INFO: stdout: "service/redis-master created\n"
Dec  3 14:37:33.637: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec  3 14:37:33.637: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-7141'
Dec  3 14:37:34.129: INFO: stderr: ""
Dec  3 14:37:34.129: INFO: stdout: "service/frontend created\n"
Dec  3 14:37:34.130: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec  3 14:37:34.130: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-7141'
Dec  3 14:37:34.701: INFO: stderr: ""
Dec  3 14:37:34.701: INFO: stdout: "deployment.apps/frontend created\n"
Dec  3 14:37:34.701: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec  3 14:37:34.701: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-7141'
Dec  3 14:37:35.270: INFO: stderr: ""
Dec  3 14:37:35.270: INFO: stdout: "deployment.apps/redis-master created\n"
Dec  3 14:37:35.271: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec  3 14:37:35.271: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-7141'
Dec  3 14:37:35.830: INFO: stderr: ""
Dec  3 14:37:35.830: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Dec  3 14:37:35.830: INFO: Waiting for all frontend pods to be Running.
Dec  3 14:37:55.881: INFO: Waiting for frontend to serve content.
Dec  3 14:37:55.977: INFO: Trying to add a new entry to the guestbook.
Dec  3 14:37:56.026: INFO: Verifying that added entry can be retrieved.
Dec  3 14:37:56.126: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  3 14:38:01.222: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  3 14:38:06.318: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  3 14:38:11.413: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
Dec  3 14:38:16.508: INFO: Failed to get response from guestbook. err: <nil>, response: {"data": ""}
STEP: using delete to clean up resources
Dec  3 14:38:21.605: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-7141'
Dec  3 14:38:21.916: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 14:38:21.917: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 14:38:21.917: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-7141'
Dec  3 14:38:22.205: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 14:38:22.277: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 14:38:22.277: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-7141'
Dec  3 14:38:22.635: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 14:38:22.635: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 14:38:22.635: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-7141'
Dec  3 14:38:22.812: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 14:38:22.812: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 14:38:22.812: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-7141'
Dec  3 14:38:23.075: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 14:38:23.075: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec  3 14:38:23.075: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-7141'
Dec  3 14:38:23.323: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 14:38:23.323: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:38:23.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7141" for this suite.
Dec  3 14:38:51.379: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:38:51.879: INFO: namespace kubectl-7141 deletion completed in 28.534476648s
•S
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:38:51.879: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-8915
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:39:03.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-8915" for this suite.
Dec  3 14:39:09.942: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:39:10.281: INFO: namespace resourcequota-8915 deletion completed in 6.382986475s
•SSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:39:10.282: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-7705
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Dec  3 14:39:17.017: INFO: Successfully updated pod "adopt-release-nbgdz"
STEP: Checking that the Job readopts the Pod
Dec  3 14:39:17.017: INFO: Waiting up to 15m0s for pod "adopt-release-nbgdz" in namespace "job-7705" to be "adopted"
Dec  3 14:39:17.027: INFO: Pod "adopt-release-nbgdz": Phase="Running", Reason="", readiness=true. Elapsed: 9.774412ms
Dec  3 14:39:17.027: INFO: Pod "adopt-release-nbgdz" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Dec  3 14:39:17.549: INFO: Successfully updated pod "adopt-release-nbgdz"
STEP: Checking that the Job releases the Pod
Dec  3 14:39:17.549: INFO: Waiting up to 15m0s for pod "adopt-release-nbgdz" in namespace "job-7705" to be "released"
Dec  3 14:39:17.559: INFO: Pod "adopt-release-nbgdz": Phase="Running", Reason="", readiness=true. Elapsed: 9.921938ms
Dec  3 14:39:17.559: INFO: Pod "adopt-release-nbgdz" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:39:17.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7705" for this suite.
Dec  3 14:40:07.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:40:07.955: INFO: namespace job-7705 deletion completed in 50.378217359s
•SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:40:07.955: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5686
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-a07a4f8b-3f80-4872-9087-0a88ce49f660
STEP: Creating a pod to test consume configMaps
Dec  3 14:40:08.157: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-79dc3db7-1313-436e-bae6-5d9e2b04d051" in namespace "projected-5686" to be "success or failure"
Dec  3 14:40:08.167: INFO: Pod "pod-projected-configmaps-79dc3db7-1313-436e-bae6-5d9e2b04d051": Phase="Pending", Reason="", readiness=false. Elapsed: 9.627225ms
Dec  3 14:40:10.177: INFO: Pod "pod-projected-configmaps-79dc3db7-1313-436e-bae6-5d9e2b04d051": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020057278s
Dec  3 14:40:12.188: INFO: Pod "pod-projected-configmaps-79dc3db7-1313-436e-bae6-5d9e2b04d051": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.030666194s
STEP: Saw pod success
Dec  3 14:40:12.188: INFO: Pod "pod-projected-configmaps-79dc3db7-1313-436e-bae6-5d9e2b04d051" satisfied condition "success or failure"
Dec  3 14:40:12.199: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-projected-configmaps-79dc3db7-1313-436e-bae6-5d9e2b04d051 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 14:40:12.361: INFO: Waiting for pod pod-projected-configmaps-79dc3db7-1313-436e-bae6-5d9e2b04d051 to disappear
Dec  3 14:40:12.371: INFO: Pod pod-projected-configmaps-79dc3db7-1313-436e-bae6-5d9e2b04d051 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:40:12.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5686" for this suite.
Dec  3 14:40:18.419: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:40:18.757: INFO: namespace projected-5686 deletion completed in 6.368888825s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:40:18.758: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-5071
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:40:23.036: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-5071" for this suite.
Dec  3 14:40:29.093: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:40:29.431: INFO: namespace emptydir-wrapper-5071 deletion completed in 6.369392826s
•SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:40:29.431: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1952
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:40:42.734: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1952" for this suite.
Dec  3 14:40:48.783: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:40:49.159: INFO: namespace resourcequota-1952 deletion completed in 6.40678551s
•SSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:40:49.159: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-868
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec  3 14:40:50.123: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980850, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980850, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980850, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980850, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:40:52.133: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980850, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980850, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980850, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980850, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:40:54.133: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980850, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980850, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980850, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980850, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 14:40:57.148: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 14:40:57.159: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:40:57.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-868" for this suite.
Dec  3 14:41:04.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:41:04.413: INFO: namespace crd-webhook-868 deletion completed in 6.409160095s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:41:04.455: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-102
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec  3 14:41:10.714: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:41:10.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1203 14:41:10.714204    5064 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-102" for this suite.
Dec  3 14:41:16.755: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:41:17.094: INFO: namespace gc-102 deletion completed in 6.36924155s
•S
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:41:17.094: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9840
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-5699
STEP: Creating secret with name secret-test-26dec76d-7419-45e5-b75a-dce86d952fd4
STEP: Creating a pod to test consume secrets
Dec  3 14:41:17.742: INFO: Waiting up to 5m0s for pod "pod-secrets-2faafe3e-6020-4283-9125-c8ce7d6ea6d6" in namespace "secrets-9840" to be "success or failure"
Dec  3 14:41:17.752: INFO: Pod "pod-secrets-2faafe3e-6020-4283-9125-c8ce7d6ea6d6": Phase="Pending", Reason="", readiness=false. Elapsed: 9.806437ms
Dec  3 14:41:19.762: INFO: Pod "pod-secrets-2faafe3e-6020-4283-9125-c8ce7d6ea6d6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020330242s
STEP: Saw pod success
Dec  3 14:41:19.762: INFO: Pod "pod-secrets-2faafe3e-6020-4283-9125-c8ce7d6ea6d6" satisfied condition "success or failure"
Dec  3 14:41:19.772: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-secrets-2faafe3e-6020-4283-9125-c8ce7d6ea6d6 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:41:19.805: INFO: Waiting for pod pod-secrets-2faafe3e-6020-4283-9125-c8ce7d6ea6d6 to disappear
Dec  3 14:41:19.814: INFO: Pod pod-secrets-2faafe3e-6020-4283-9125-c8ce7d6ea6d6 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:41:19.814: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9840" for this suite.
Dec  3 14:41:25.864: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:41:26.205: INFO: namespace secrets-9840 deletion completed in 6.372759768s
STEP: Destroying namespace "secret-namespace-5699" for this suite.
Dec  3 14:41:32.237: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:41:32.586: INFO: namespace secret-namespace-5699 deletion completed in 6.380295421s
•SSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:41:32.586: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4560
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 14:41:32.791: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  3 14:41:42.815: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec  3 14:41:44.826: INFO: Creating deployment "test-rollover-deployment"
Dec  3 14:41:44.847: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec  3 14:41:46.867: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec  3 14:41:46.887: INFO: Ensure that both replica sets have 1 created replica
Dec  3 14:41:46.907: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec  3 14:41:46.927: INFO: Updating deployment test-rollover-deployment
Dec  3 14:41:46.927: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec  3 14:41:48.947: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec  3 14:41:48.967: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec  3 14:41:48.987: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:41:48.987: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980904, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980904, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980907, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980904, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:41:51.008: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:41:51.008: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980904, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980904, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980907, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980904, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:41:53.011: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:41:53.011: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980904, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980904, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980907, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980904, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:41:55.011: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:41:55.011: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980904, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980904, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980907, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980904, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:41:57.008: INFO: all replica sets need to contain the pod-template-hash label
Dec  3 14:41:57.008: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980904, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980904, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980907, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980904, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:41:59.008: INFO: 
Dec  3 14:41:59.008: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec  3 14:41:59.038: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-4560 /apis/apps/v1/namespaces/deployment-4560/deployments/test-rollover-deployment e6307c04-09de-4714-a699-e6d6fbb67d65 3789 2 2019-12-03 14:41:44 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002e56f78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-03 14:41:44 +0000 UTC,LastTransitionTime:2019-12-03 14:41:44 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2019-12-03 14:41:57 +0000 UTC,LastTransitionTime:2019-12-03 14:41:44 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 14:41:59.049: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-4560 /apis/apps/v1/namespaces/deployment-4560/replicasets/test-rollover-deployment-7d7dc6548c d1e433ec-69d5-44a3-9adb-e7ce3dfff568 3782 2 2019-12-03 14:41:46 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment e6307c04-09de-4714-a699-e6d6fbb67d65 0xc002e57407 0xc002e57408}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002e57468 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec  3 14:41:59.049: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec  3 14:41:59.049: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-4560 /apis/apps/v1/namespaces/deployment-4560/replicasets/test-rollover-controller 6e9ea440-c3ab-47ae-869b-5228c015a745 3788 2 2019-12-03 14:41:32 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment e6307c04-09de-4714-a699-e6d6fbb67d65 0xc002e5732f 0xc002e57340}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc002e573a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 14:41:59.049: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-4560 /apis/apps/v1/namespaces/deployment-4560/replicasets/test-rollover-deployment-f6c94f66c 41512ee5-b3a3-405e-ac52-42c273f6aa67 3751 2 2019-12-03 14:41:44 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment e6307c04-09de-4714-a699-e6d6fbb67d65 0xc002e574c0 0xc002e574c1}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc002e57538 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 14:41:59.059: INFO: Pod "test-rollover-deployment-7d7dc6548c-fvd2f" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-fvd2f test-rollover-deployment-7d7dc6548c- deployment-4560 /api/v1/namespaces/deployment-4560/pods/test-rollover-deployment-7d7dc6548c-fvd2f 2881227c-62b3-46a8-90c8-f1694f9d3ed2 3757 0 2019-12-03 14:41:46 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[cni.projectcalico.org/podIP:100.64.1.23/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c d1e433ec-69d5-44a3-9adb-e7ce3dfff568 0xc002e57a87 0xc002e57a88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-5cmzr,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-5cmzr,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-5cmzr,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 14:41:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 14:41:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 14:41:47 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 14:41:46 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.2,PodIP:100.64.1.23,StartTime:2019-12-03 14:41:46 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 14:41:47 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://0d1e3095854fb273fbed4ff4ed9ffe9e7678b0cdcd5acf0b7d3fda824863c05e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.23,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:41:59.060: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4560" for this suite.
Dec  3 14:42:05.110: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:42:05.452: INFO: namespace deployment-4560 deletion completed in 6.373695964s
•SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:42:05.453: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6776
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:42:07.691: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6776" for this suite.
Dec  3 14:42:57.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:42:58.085: INFO: namespace kubelet-test-6776 deletion completed in 50.376215691s
•SSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:42:58.085: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-6714
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:43:00.318: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-6714" for this suite.
Dec  3 14:43:08.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:43:08.739: INFO: namespace containers-6714 deletion completed in 8.400868564s
•SSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:43:08.739: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-424
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec  3 14:43:08.919: INFO: PodSpec: initContainers in spec.initContainers
Dec  3 14:43:48.572: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-b3bf883e-f0ef-41c2-a8c4-2fa4deb22f20", GenerateName:"", Namespace:"init-container-424", SelfLink:"/api/v1/namespaces/init-container-424/pods/pod-init-b3bf883e-f0ef-41c2-a8c4-2fa4deb22f20", UID:"751836b7-9161-48fe-aa6c-a7a530f265f5", ResourceVersion:"4111", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63710980988, loc:(*time.Location)(0x84bfb00)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"919975142"}, Annotations:map[string]string{"cni.projectcalico.org/podIP":"100.64.1.26/32", "kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-jt9rf", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc003e675c0), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jt9rf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jt9rf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-jt9rf", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc005bf9df8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc003e6f800), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc005bf9e70)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc005bf9e90)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc005bf9e98), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc005bf9e9c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980988, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980988, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980988, loc:(*time.Location)(0x84bfb00)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710980988, loc:(*time.Location)(0x84bfb00)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.250.0.2", PodIP:"100.64.1.26", PodIPs:[]v1.PodIP{v1.PodIP{IP:"100.64.1.26"}}, StartTime:(*v1.Time)(0xc001c26920), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000fcc460)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc000fcc4d0)}, Ready:false, RestartCount:3, Image:"busybox:1.29", ImageID:"docker-pullable://busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"docker://af117130ac7d57bf2d0685c593dffb368577179a74319acd57823a8e4811b089", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001c26960), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc001c26940), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc005bf9f1f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:43:48.573: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-424" for this suite.
Dec  3 14:44:16.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:44:16.975: INFO: namespace init-container-424 deletion completed in 28.383866557s
•SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:44:16.976: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3206
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  3 14:44:17.158: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-3206'
Dec  3 14:44:17.288: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 14:44:17.288: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Dec  3 14:44:17.309: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-zrptf]
Dec  3 14:44:17.309: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-zrptf" in namespace "kubectl-3206" to be "running and ready"
Dec  3 14:44:17.319: INFO: Pod "e2e-test-httpd-rc-zrptf": Phase="Pending", Reason="", readiness=false. Elapsed: 10.350741ms
Dec  3 14:44:19.330: INFO: Pod "e2e-test-httpd-rc-zrptf": Phase="Running", Reason="", readiness=true. Elapsed: 2.021135251s
Dec  3 14:44:19.330: INFO: Pod "e2e-test-httpd-rc-zrptf" satisfied condition "running and ready"
Dec  3 14:44:19.330: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-zrptf]
Dec  3 14:44:19.330: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs rc/e2e-test-httpd-rc --namespace=kubectl-3206'
Dec  3 14:44:19.490: INFO: stderr: ""
Dec  3 14:44:19.491: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 100.64.1.27. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 100.64.1.27. Set the 'ServerName' directive globally to suppress this message\n[Tue Dec 03 14:44:18.209695 2019] [mpm_event:notice] [pid 1:tid 140585355266920] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Tue Dec 03 14:44:18.209787 2019] [core:notice] [pid 1:tid 140585355266920] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Dec  3 14:44:19.491: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete rc e2e-test-httpd-rc --namespace=kubectl-3206'
Dec  3 14:44:19.626: INFO: stderr: ""
Dec  3 14:44:19.626: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:44:19.626: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3206" for this suite.
Dec  3 14:44:25.677: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:44:26.038: INFO: namespace kubectl-3206 deletion completed in 6.393025219s
•SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:44:26.038: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6196
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:44:42.389: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6196" for this suite.
Dec  3 14:44:48.449: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:44:48.813: INFO: namespace resourcequota-6196 deletion completed in 6.405119448s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:44:48.813: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-521
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Dec  3 14:45:19.092: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1203 14:45:19.091995    5064 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:45:19.092: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-521" for this suite.
Dec  3 14:45:25.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:45:25.531: INFO: namespace gc-521 deletion completed in 6.428655712s
•SSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:45:25.531: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5012
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-d94acf5d-d9af-4272-a237-3ec60a78d791
STEP: Creating a pod to test consume configMaps
Dec  3 14:45:25.736: INFO: Waiting up to 5m0s for pod "pod-configmaps-5bedb3eb-b9f2-4fb8-ab19-b089954fa66d" in namespace "configmap-5012" to be "success or failure"
Dec  3 14:45:25.748: INFO: Pod "pod-configmaps-5bedb3eb-b9f2-4fb8-ab19-b089954fa66d": Phase="Pending", Reason="", readiness=false. Elapsed: 11.520001ms
Dec  3 14:45:27.759: INFO: Pod "pod-configmaps-5bedb3eb-b9f2-4fb8-ab19-b089954fa66d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02232852s
STEP: Saw pod success
Dec  3 14:45:27.759: INFO: Pod "pod-configmaps-5bedb3eb-b9f2-4fb8-ab19-b089954fa66d" satisfied condition "success or failure"
Dec  3 14:45:27.769: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-configmaps-5bedb3eb-b9f2-4fb8-ab19-b089954fa66d container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 14:45:27.803: INFO: Waiting for pod pod-configmaps-5bedb3eb-b9f2-4fb8-ab19-b089954fa66d to disappear
Dec  3 14:45:27.821: INFO: Pod pod-configmaps-5bedb3eb-b9f2-4fb8-ab19-b089954fa66d no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:45:27.821: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5012" for this suite.
Dec  3 14:45:33.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:45:34.259: INFO: namespace configmap-5012 deletion completed in 6.419896376s
•
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:45:34.260: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-808
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 14:45:35.461: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981135, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981135, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981135, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981135, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 14:45:38.487: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:45:38.685: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-808" for this suite.
Dec  3 14:45:44.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:45:45.069: INFO: namespace webhook-808 deletion completed in 6.372856043s
STEP: Destroying namespace "webhook-808-markers" for this suite.
Dec  3 14:45:51.100: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:45:51.462: INFO: namespace webhook-808-markers deletion completed in 6.393428501s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:45:51.508: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6726
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:45:51.705: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2437b85b-d67e-4a42-9a13-4360fb3e9cf6" in namespace "projected-6726" to be "success or failure"
Dec  3 14:45:51.716: INFO: Pod "downwardapi-volume-2437b85b-d67e-4a42-9a13-4360fb3e9cf6": Phase="Pending", Reason="", readiness=false. Elapsed: 10.670293ms
Dec  3 14:45:53.726: INFO: Pod "downwardapi-volume-2437b85b-d67e-4a42-9a13-4360fb3e9cf6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021414523s
STEP: Saw pod success
Dec  3 14:45:53.727: INFO: Pod "downwardapi-volume-2437b85b-d67e-4a42-9a13-4360fb3e9cf6" satisfied condition "success or failure"
Dec  3 14:45:53.737: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downwardapi-volume-2437b85b-d67e-4a42-9a13-4360fb3e9cf6 container client-container: <nil>
STEP: delete the pod
Dec  3 14:45:53.769: INFO: Waiting for pod downwardapi-volume-2437b85b-d67e-4a42-9a13-4360fb3e9cf6 to disappear
Dec  3 14:45:53.779: INFO: Pod downwardapi-volume-2437b85b-d67e-4a42-9a13-4360fb3e9cf6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:45:53.780: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6726" for this suite.
Dec  3 14:45:59.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:46:00.239: INFO: namespace projected-6726 deletion completed in 6.441149366s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:46:00.240: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-430
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  3 14:46:03.001: INFO: Successfully updated pod "pod-update-5c45934c-cd54-42fa-925d-36f8f071e70d"
STEP: verifying the updated pod is in kubernetes
Dec  3 14:46:03.023: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:46:03.023: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-430" for this suite.
Dec  3 14:46:31.075: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:46:31.461: INFO: namespace pods-430 deletion completed in 28.419281945s
•SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:46:31.461: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5616
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-d07c3eaa-2d64-4a16-94e8-093620394d56
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-d07c3eaa-2d64-4a16-94e8-093620394d56
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:46:35.823: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5616" for this suite.
Dec  3 14:46:47.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:46:48.262: INFO: namespace configmap-5616 deletion completed in 12.420806119s
•SSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:46:48.262: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1102
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec  3 14:46:48.443: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-1102'
Dec  3 14:46:48.748: INFO: stderr: ""
Dec  3 14:46:48.749: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 14:46:48.749: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1102'
Dec  3 14:46:48.885: INFO: stderr: ""
Dec  3 14:46:48.885: INFO: stdout: "update-demo-nautilus-7bds6 update-demo-nautilus-mc7rn "
Dec  3 14:46:48.885: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-7bds6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1102'
Dec  3 14:46:49.035: INFO: stderr: ""
Dec  3 14:46:49.035: INFO: stdout: ""
Dec  3 14:46:49.035: INFO: update-demo-nautilus-7bds6 is created but not running
Dec  3 14:46:54.036: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1102'
Dec  3 14:46:54.204: INFO: stderr: ""
Dec  3 14:46:54.204: INFO: stdout: "update-demo-nautilus-7bds6 update-demo-nautilus-mc7rn "
Dec  3 14:46:54.204: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-7bds6 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1102'
Dec  3 14:46:54.326: INFO: stderr: ""
Dec  3 14:46:54.327: INFO: stdout: "true"
Dec  3 14:46:54.327: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-7bds6 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1102'
Dec  3 14:46:54.442: INFO: stderr: ""
Dec  3 14:46:54.442: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:46:54.442: INFO: validating pod update-demo-nautilus-7bds6
Dec  3 14:46:54.538: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:46:54.538: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:46:54.538: INFO: update-demo-nautilus-7bds6 is verified up and running
Dec  3 14:46:54.538: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-mc7rn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1102'
Dec  3 14:46:54.650: INFO: stderr: ""
Dec  3 14:46:54.650: INFO: stdout: "true"
Dec  3 14:46:54.651: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-mc7rn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1102'
Dec  3 14:46:54.776: INFO: stderr: ""
Dec  3 14:46:54.776: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:46:54.776: INFO: validating pod update-demo-nautilus-mc7rn
Dec  3 14:46:54.872: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:46:54.872: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:46:54.872: INFO: update-demo-nautilus-mc7rn is verified up and running
STEP: scaling down the replication controller
Dec  3 14:46:54.874: INFO: scanned /root for discovery docs: <nil>
Dec  3 14:46:54.874: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-1102'
Dec  3 14:46:55.028: INFO: stderr: ""
Dec  3 14:46:55.028: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 14:46:55.028: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1102'
Dec  3 14:46:55.142: INFO: stderr: ""
Dec  3 14:46:55.142: INFO: stdout: "update-demo-nautilus-7bds6 update-demo-nautilus-mc7rn "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  3 14:47:00.143: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1102'
Dec  3 14:47:00.265: INFO: stderr: ""
Dec  3 14:47:00.265: INFO: stdout: "update-demo-nautilus-7bds6 update-demo-nautilus-mc7rn "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec  3 14:47:05.265: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1102'
Dec  3 14:47:05.418: INFO: stderr: ""
Dec  3 14:47:05.418: INFO: stdout: "update-demo-nautilus-mc7rn "
Dec  3 14:47:05.418: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-mc7rn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1102'
Dec  3 14:47:05.537: INFO: stderr: ""
Dec  3 14:47:05.537: INFO: stdout: "true"
Dec  3 14:47:05.537: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-mc7rn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1102'
Dec  3 14:47:05.663: INFO: stderr: ""
Dec  3 14:47:05.663: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:47:05.663: INFO: validating pod update-demo-nautilus-mc7rn
Dec  3 14:47:05.676: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:47:05.676: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:47:05.676: INFO: update-demo-nautilus-mc7rn is verified up and running
STEP: scaling up the replication controller
Dec  3 14:47:05.678: INFO: scanned /root for discovery docs: <nil>
Dec  3 14:47:05.678: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-1102'
Dec  3 14:47:05.834: INFO: stderr: ""
Dec  3 14:47:05.834: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 14:47:05.834: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1102'
Dec  3 14:47:05.953: INFO: stderr: ""
Dec  3 14:47:05.953: INFO: stdout: "update-demo-nautilus-h9swp update-demo-nautilus-mc7rn "
Dec  3 14:47:05.953: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-h9swp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1102'
Dec  3 14:47:06.078: INFO: stderr: ""
Dec  3 14:47:06.078: INFO: stdout: ""
Dec  3 14:47:06.078: INFO: update-demo-nautilus-h9swp is created but not running
Dec  3 14:47:11.079: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1102'
Dec  3 14:47:13.350: INFO: stderr: ""
Dec  3 14:47:13.350: INFO: stdout: "update-demo-nautilus-h9swp update-demo-nautilus-mc7rn "
Dec  3 14:47:13.350: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-h9swp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1102'
Dec  3 14:47:13.473: INFO: stderr: ""
Dec  3 14:47:13.473: INFO: stdout: "true"
Dec  3 14:47:13.473: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-h9swp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1102'
Dec  3 14:47:13.598: INFO: stderr: ""
Dec  3 14:47:13.598: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:47:13.598: INFO: validating pod update-demo-nautilus-h9swp
Dec  3 14:47:13.693: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:47:13.694: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:47:13.694: INFO: update-demo-nautilus-h9swp is verified up and running
Dec  3 14:47:13.694: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-mc7rn -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1102'
Dec  3 14:47:13.827: INFO: stderr: ""
Dec  3 14:47:13.827: INFO: stdout: "true"
Dec  3 14:47:13.827: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-mc7rn -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1102'
Dec  3 14:47:13.942: INFO: stderr: ""
Dec  3 14:47:13.943: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:47:13.943: INFO: validating pod update-demo-nautilus-mc7rn
Dec  3 14:47:13.955: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:47:13.955: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:47:13.955: INFO: update-demo-nautilus-mc7rn is verified up and running
STEP: using delete to clean up resources
Dec  3 14:47:13.955: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-1102'
Dec  3 14:47:14.111: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 14:47:14.111: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  3 14:47:14.111: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1102'
Dec  3 14:47:14.259: INFO: stderr: "No resources found in kubectl-1102 namespace.\n"
Dec  3 14:47:14.259: INFO: stdout: ""
Dec  3 14:47:14.259: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-1102 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 14:47:14.390: INFO: stderr: ""
Dec  3 14:47:14.390: INFO: stdout: "update-demo-nautilus-h9swp\nupdate-demo-nautilus-mc7rn\n"
Dec  3 14:47:14.890: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-1102'
Dec  3 14:47:15.057: INFO: stderr: "No resources found in kubectl-1102 namespace.\n"
Dec  3 14:47:15.057: INFO: stdout: ""
Dec  3 14:47:15.057: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-1102 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 14:47:15.206: INFO: stderr: ""
Dec  3 14:47:15.206: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:47:15.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1102" for this suite.
Dec  3 14:47:27.257: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:47:27.652: INFO: namespace kubectl-1102 deletion completed in 12.427650379s
•SSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:47:27.653: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2984
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:47:27.851: INFO: Waiting up to 5m0s for pod "downwardapi-volume-a4369755-3666-4a2b-9119-b292e4d8dd70" in namespace "projected-2984" to be "success or failure"
Dec  3 14:47:27.861: INFO: Pod "downwardapi-volume-a4369755-3666-4a2b-9119-b292e4d8dd70": Phase="Pending", Reason="", readiness=false. Elapsed: 9.667693ms
Dec  3 14:47:29.872: INFO: Pod "downwardapi-volume-a4369755-3666-4a2b-9119-b292e4d8dd70": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020446154s
STEP: Saw pod success
Dec  3 14:47:29.872: INFO: Pod "downwardapi-volume-a4369755-3666-4a2b-9119-b292e4d8dd70" satisfied condition "success or failure"
Dec  3 14:47:29.882: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downwardapi-volume-a4369755-3666-4a2b-9119-b292e4d8dd70 container client-container: <nil>
STEP: delete the pod
Dec  3 14:47:29.914: INFO: Waiting for pod downwardapi-volume-a4369755-3666-4a2b-9119-b292e4d8dd70 to disappear
Dec  3 14:47:29.924: INFO: Pod downwardapi-volume-a4369755-3666-4a2b-9119-b292e4d8dd70 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:47:29.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2984" for this suite.
Dec  3 14:47:35.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:47:36.326: INFO: namespace projected-2984 deletion completed in 6.38304626s
•SSSSSSSSSS
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:47:36.326: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-9120
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:47:44.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-9120" for this suite.
Dec  3 14:47:50.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:47:50.989: INFO: namespace job-9120 deletion completed in 6.442566216s
•SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:47:50.989: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9742
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  3 14:47:51.189: INFO: Waiting up to 5m0s for pod "pod-37fec30c-d715-49ef-8f5c-96b5eb633b75" in namespace "emptydir-9742" to be "success or failure"
Dec  3 14:47:51.199: INFO: Pod "pod-37fec30c-d715-49ef-8f5c-96b5eb633b75": Phase="Pending", Reason="", readiness=false. Elapsed: 10.383713ms
Dec  3 14:47:53.210: INFO: Pod "pod-37fec30c-d715-49ef-8f5c-96b5eb633b75": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020987341s
Dec  3 14:47:55.221: INFO: Pod "pod-37fec30c-d715-49ef-8f5c-96b5eb633b75": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031937414s
STEP: Saw pod success
Dec  3 14:47:55.221: INFO: Pod "pod-37fec30c-d715-49ef-8f5c-96b5eb633b75" satisfied condition "success or failure"
Dec  3 14:47:55.231: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-37fec30c-d715-49ef-8f5c-96b5eb633b75 container test-container: <nil>
STEP: delete the pod
Dec  3 14:47:55.264: INFO: Waiting for pod pod-37fec30c-d715-49ef-8f5c-96b5eb633b75 to disappear
Dec  3 14:47:55.274: INFO: Pod pod-37fec30c-d715-49ef-8f5c-96b5eb633b75 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:47:55.274: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9742" for this suite.
Dec  3 14:48:01.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:48:01.681: INFO: namespace emptydir-9742 deletion completed in 6.387122637s
•
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:48:01.681: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2739
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec  3 14:48:02.003: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2739 /api/v1/namespaces/watch-2739/configmaps/e2e-watch-test-resource-version 12aba157-2254-49f9-83b8-409f799cb146 5099 0 2019-12-03 14:48:01 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 14:48:02.003: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-2739 /api/v1/namespaces/watch-2739/configmaps/e2e-watch-test-resource-version 12aba157-2254-49f9-83b8-409f799cb146 5100 0 2019-12-03 14:48:01 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:48:02.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2739" for this suite.
Dec  3 14:48:08.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:48:08.413: INFO: namespace watch-2739 deletion completed in 6.395502468s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:48:08.414: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1637
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 14:48:09.617: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981289, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981289, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981289, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981289, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:48:11.628: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981289, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981289, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981289, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981289, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 14:48:14.645: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:48:14.939: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1637" for this suite.
Dec  3 14:48:20.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:48:21.357: INFO: namespace webhook-1637 deletion completed in 6.406697794s
STEP: Destroying namespace "webhook-1637-markers" for this suite.
Dec  3 14:48:27.389: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:48:27.736: INFO: namespace webhook-1637-markers deletion completed in 6.378970626s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:48:27.779: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3534
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  3 14:48:32.085: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 14:48:32.095: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 14:48:34.095: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 14:48:34.106: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 14:48:36.095: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 14:48:36.107: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 14:48:38.095: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 14:48:38.106: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 14:48:40.095: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 14:48:40.106: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 14:48:42.095: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 14:48:42.106: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 14:48:44.095: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 14:48:44.107: INFO: Pod pod-with-poststart-http-hook still exists
Dec  3 14:48:46.095: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec  3 14:48:46.106: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:48:46.106: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3534" for this suite.
Dec  3 14:48:58.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:48:58.553: INFO: namespace container-lifecycle-hook-3534 deletion completed in 12.42708415s
•SSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:48:58.553: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8015
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-56b0bfe7-ce0a-412b-8af7-b09cab00f9be
STEP: Creating a pod to test consume secrets
Dec  3 14:48:58.762: INFO: Waiting up to 5m0s for pod "pod-secrets-4840aede-7324-4323-a43b-6b662caec2d4" in namespace "secrets-8015" to be "success or failure"
Dec  3 14:48:58.772: INFO: Pod "pod-secrets-4840aede-7324-4323-a43b-6b662caec2d4": Phase="Pending", Reason="", readiness=false. Elapsed: 10.087454ms
Dec  3 14:49:00.784: INFO: Pod "pod-secrets-4840aede-7324-4323-a43b-6b662caec2d4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021946832s
STEP: Saw pod success
Dec  3 14:49:00.784: INFO: Pod "pod-secrets-4840aede-7324-4323-a43b-6b662caec2d4" satisfied condition "success or failure"
Dec  3 14:49:00.794: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-secrets-4840aede-7324-4323-a43b-6b662caec2d4 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:49:00.826: INFO: Waiting for pod pod-secrets-4840aede-7324-4323-a43b-6b662caec2d4 to disappear
Dec  3 14:49:00.836: INFO: Pod pod-secrets-4840aede-7324-4323-a43b-6b662caec2d4 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:49:00.836: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8015" for this suite.
Dec  3 14:49:06.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:49:07.243: INFO: namespace secrets-8015 deletion completed in 6.38702959s
•SSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:49:07.243: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3023
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:49:07.438: INFO: Waiting up to 5m0s for pod "downwardapi-volume-ace3819f-ae0d-4b75-b50e-2141e1277777" in namespace "downward-api-3023" to be "success or failure"
Dec  3 14:49:07.448: INFO: Pod "downwardapi-volume-ace3819f-ae0d-4b75-b50e-2141e1277777": Phase="Pending", Reason="", readiness=false. Elapsed: 9.827025ms
Dec  3 14:49:09.458: INFO: Pod "downwardapi-volume-ace3819f-ae0d-4b75-b50e-2141e1277777": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020138769s
STEP: Saw pod success
Dec  3 14:49:09.458: INFO: Pod "downwardapi-volume-ace3819f-ae0d-4b75-b50e-2141e1277777" satisfied condition "success or failure"
Dec  3 14:49:09.468: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downwardapi-volume-ace3819f-ae0d-4b75-b50e-2141e1277777 container client-container: <nil>
STEP: delete the pod
Dec  3 14:49:09.499: INFO: Waiting for pod downwardapi-volume-ace3819f-ae0d-4b75-b50e-2141e1277777 to disappear
Dec  3 14:49:09.509: INFO: Pod downwardapi-volume-ace3819f-ae0d-4b75-b50e-2141e1277777 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:49:09.509: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3023" for this suite.
Dec  3 14:49:15.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:49:15.915: INFO: namespace downward-api-3023 deletion completed in 6.388026881s
•SSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:49:15.916: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-6601
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec  3 14:49:18.177: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:49:18.210: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-6601" for this suite.
Dec  3 14:49:30.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:49:30.668: INFO: namespace replicaset-6601 deletion completed in 12.437711317s
•SSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:49:30.668: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5207
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-e8f8587a-4371-4ffb-9a2a-f52c5096fac5
STEP: Creating a pod to test consume configMaps
Dec  3 14:49:30.876: INFO: Waiting up to 5m0s for pod "pod-configmaps-d77fa9bf-1510-4eb8-b0cb-d570ab0048b7" in namespace "configmap-5207" to be "success or failure"
Dec  3 14:49:30.886: INFO: Pod "pod-configmaps-d77fa9bf-1510-4eb8-b0cb-d570ab0048b7": Phase="Pending", Reason="", readiness=false. Elapsed: 9.905986ms
Dec  3 14:49:32.897: INFO: Pod "pod-configmaps-d77fa9bf-1510-4eb8-b0cb-d570ab0048b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02094707s
STEP: Saw pod success
Dec  3 14:49:32.897: INFO: Pod "pod-configmaps-d77fa9bf-1510-4eb8-b0cb-d570ab0048b7" satisfied condition "success or failure"
Dec  3 14:49:32.908: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-configmaps-d77fa9bf-1510-4eb8-b0cb-d570ab0048b7 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 14:49:32.941: INFO: Waiting for pod pod-configmaps-d77fa9bf-1510-4eb8-b0cb-d570ab0048b7 to disappear
Dec  3 14:49:32.952: INFO: Pod pod-configmaps-d77fa9bf-1510-4eb8-b0cb-d570ab0048b7 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:49:32.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5207" for this suite.
Dec  3 14:49:39.004: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:49:39.359: INFO: namespace configmap-5207 deletion completed in 6.387536564s
•SSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:49:39.359: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6893
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec  3 14:49:39.542: INFO: namespace kubectl-6893
Dec  3 14:49:39.542: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-6893'
Dec  3 14:49:39.810: INFO: stderr: ""
Dec  3 14:49:39.810: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  3 14:49:40.821: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 14:49:40.822: INFO: Found 0 / 1
Dec  3 14:49:41.822: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 14:49:41.822: INFO: Found 1 / 1
Dec  3 14:49:41.822: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  3 14:49:41.832: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 14:49:41.832: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 14:49:41.832: INFO: wait on redis-master startup in kubectl-6893 
Dec  3 14:49:41.832: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs redis-master-4k98n redis-master --namespace=kubectl-6893'
Dec  3 14:49:42.061: INFO: stderr: ""
Dec  3 14:49:42.061: INFO: stdout: "1:C 03 Dec 2019 14:49:40.680 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 03 Dec 2019 14:49:40.680 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 03 Dec 2019 14:49:40.680 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 03 Dec 2019 14:49:40.682 * Running mode=standalone, port=6379.\n1:M 03 Dec 2019 14:49:40.682 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 03 Dec 2019 14:49:40.682 # Server initialized\n1:M 03 Dec 2019 14:49:40.682 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 03 Dec 2019 14:49:40.682 * Ready to accept connections\n"
STEP: exposing RC
Dec  3 14:49:42.061: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-6893'
Dec  3 14:49:42.197: INFO: stderr: ""
Dec  3 14:49:42.197: INFO: stdout: "service/rm2 exposed\n"
Dec  3 14:49:42.207: INFO: Service rm2 in namespace kubectl-6893 found.
STEP: exposing service
Dec  3 14:49:44.227: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-6893'
Dec  3 14:49:44.355: INFO: stderr: ""
Dec  3 14:49:44.355: INFO: stdout: "service/rm3 exposed\n"
Dec  3 14:49:44.365: INFO: Service rm3 in namespace kubectl-6893 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:49:46.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6893" for this suite.
Dec  3 14:49:58.435: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:49:58.799: INFO: namespace kubectl-6893 deletion completed in 12.395049863s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:49:58.800: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2477
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:49:58.997: INFO: Waiting up to 5m0s for pod "downwardapi-volume-d9fdd54f-b2ca-46a7-8a0a-81e03308606c" in namespace "projected-2477" to be "success or failure"
Dec  3 14:49:59.007: INFO: Pod "downwardapi-volume-d9fdd54f-b2ca-46a7-8a0a-81e03308606c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.980767ms
Dec  3 14:50:01.019: INFO: Pod "downwardapi-volume-d9fdd54f-b2ca-46a7-8a0a-81e03308606c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021320708s
STEP: Saw pod success
Dec  3 14:50:01.019: INFO: Pod "downwardapi-volume-d9fdd54f-b2ca-46a7-8a0a-81e03308606c" satisfied condition "success or failure"
Dec  3 14:50:01.029: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downwardapi-volume-d9fdd54f-b2ca-46a7-8a0a-81e03308606c container client-container: <nil>
STEP: delete the pod
Dec  3 14:50:01.063: INFO: Waiting for pod downwardapi-volume-d9fdd54f-b2ca-46a7-8a0a-81e03308606c to disappear
Dec  3 14:50:01.074: INFO: Pod downwardapi-volume-d9fdd54f-b2ca-46a7-8a0a-81e03308606c no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:50:01.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2477" for this suite.
Dec  3 14:50:07.126: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:07.474: INFO: namespace projected-2477 deletion completed in 6.381593502s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:50:07.475: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7006
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec  3 14:50:07.668: INFO: Waiting up to 5m0s for pod "downward-api-18813d21-2cf4-43c9-af7d-6d0bb4a87f68" in namespace "downward-api-7006" to be "success or failure"
Dec  3 14:50:07.678: INFO: Pod "downward-api-18813d21-2cf4-43c9-af7d-6d0bb4a87f68": Phase="Pending", Reason="", readiness=false. Elapsed: 9.991292ms
Dec  3 14:50:09.689: INFO: Pod "downward-api-18813d21-2cf4-43c9-af7d-6d0bb4a87f68": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020694788s
STEP: Saw pod success
Dec  3 14:50:09.689: INFO: Pod "downward-api-18813d21-2cf4-43c9-af7d-6d0bb4a87f68" satisfied condition "success or failure"
Dec  3 14:50:09.701: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downward-api-18813d21-2cf4-43c9-af7d-6d0bb4a87f68 container dapi-container: <nil>
STEP: delete the pod
Dec  3 14:50:09.736: INFO: Waiting for pod downward-api-18813d21-2cf4-43c9-af7d-6d0bb4a87f68 to disappear
Dec  3 14:50:09.746: INFO: Pod downward-api-18813d21-2cf4-43c9-af7d-6d0bb4a87f68 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:50:09.746: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7006" for this suite.
Dec  3 14:50:15.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:16.151: INFO: namespace downward-api-7006 deletion completed in 6.386035154s
•SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:50:16.151: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6408
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-43b411d9-1670-4e51-8987-68b9193d5442
STEP: Creating a pod to test consume secrets
Dec  3 14:50:16.360: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-5225db26-a0bb-415a-85c9-53af24fb3f85" in namespace "projected-6408" to be "success or failure"
Dec  3 14:50:16.370: INFO: Pod "pod-projected-secrets-5225db26-a0bb-415a-85c9-53af24fb3f85": Phase="Pending", Reason="", readiness=false. Elapsed: 10.41675ms
Dec  3 14:50:18.381: INFO: Pod "pod-projected-secrets-5225db26-a0bb-415a-85c9-53af24fb3f85": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021338137s
STEP: Saw pod success
Dec  3 14:50:18.381: INFO: Pod "pod-projected-secrets-5225db26-a0bb-415a-85c9-53af24fb3f85" satisfied condition "success or failure"
Dec  3 14:50:18.392: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-projected-secrets-5225db26-a0bb-415a-85c9-53af24fb3f85 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:50:18.453: INFO: Waiting for pod pod-projected-secrets-5225db26-a0bb-415a-85c9-53af24fb3f85 to disappear
Dec  3 14:50:18.463: INFO: Pod pod-projected-secrets-5225db26-a0bb-415a-85c9-53af24fb3f85 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:50:18.463: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6408" for this suite.
Dec  3 14:50:24.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:24.869: INFO: namespace projected-6408 deletion completed in 6.386154664s
•SSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:50:24.869: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4605
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-2ec67663-c978-4dbd-91f1-05fc8913e666
STEP: Creating a pod to test consume secrets
Dec  3 14:50:25.073: INFO: Waiting up to 5m0s for pod "pod-secrets-9c30f837-911a-4a31-b9be-ff4e47e870d8" in namespace "secrets-4605" to be "success or failure"
Dec  3 14:50:25.083: INFO: Pod "pod-secrets-9c30f837-911a-4a31-b9be-ff4e47e870d8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.602473ms
Dec  3 14:50:27.094: INFO: Pod "pod-secrets-9c30f837-911a-4a31-b9be-ff4e47e870d8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021225681s
STEP: Saw pod success
Dec  3 14:50:27.095: INFO: Pod "pod-secrets-9c30f837-911a-4a31-b9be-ff4e47e870d8" satisfied condition "success or failure"
Dec  3 14:50:27.105: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-secrets-9c30f837-911a-4a31-b9be-ff4e47e870d8 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 14:50:27.137: INFO: Waiting for pod pod-secrets-9c30f837-911a-4a31-b9be-ff4e47e870d8 to disappear
Dec  3 14:50:27.147: INFO: Pod pod-secrets-9c30f837-911a-4a31-b9be-ff4e47e870d8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:50:27.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4605" for this suite.
Dec  3 14:50:33.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:33.558: INFO: namespace secrets-4605 deletion completed in 6.391573166s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:50:33.558: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5986
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5986.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-5986.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5986.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-5986.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-5986.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5986.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 14:50:46.347: INFO: DNS probes using dns-5986/dns-test-1671baea-2ba9-4397-9cb9-4e134a9d31ea succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:50:46.363: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5986" for this suite.
Dec  3 14:50:52.412: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:50:52.762: INFO: namespace dns-5986 deletion completed in 6.380606624s
•SSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:50:52.762: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6851
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-6851
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-6851
I1203 14:50:53.005628    5064 runners.go:184] Created replication controller with name: externalname-service, namespace: services-6851, replica count: 2
I1203 14:50:56.056174    5064 runners.go:184] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 14:50:59.056: INFO: Creating new exec pod
I1203 14:50:59.056394    5064 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 14:51:02.109: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-6851 execpod99z6v -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec  3 14:51:02.707: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec  3 14:51:02.707: INFO: stdout: ""
Dec  3 14:51:02.707: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-6851 execpod99z6v -- /bin/sh -x -c nc -zv -t -w 2 100.111.12.182 80'
Dec  3 14:51:03.215: INFO: stderr: "+ nc -zv -t -w 2 100.111.12.182 80\nConnection to 100.111.12.182 80 port [tcp/http] succeeded!\n"
Dec  3 14:51:03.215: INFO: stdout: ""
Dec  3 14:51:03.215: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-6851 execpod99z6v -- /bin/sh -x -c nc -zv -t -w 2 10.250.0.3 32216'
Dec  3 14:51:03.807: INFO: stderr: "+ nc -zv -t -w 2 10.250.0.3 32216\nConnection to 10.250.0.3 32216 port [tcp/32216] succeeded!\n"
Dec  3 14:51:03.807: INFO: stdout: ""
Dec  3 14:51:03.807: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-6851 execpod99z6v -- /bin/sh -x -c nc -zv -t -w 2 10.250.0.2 32216'
Dec  3 14:51:04.377: INFO: stderr: "+ nc -zv -t -w 2 10.250.0.2 32216\nConnection to 10.250.0.2 32216 port [tcp/32216] succeeded!\n"
Dec  3 14:51:04.377: INFO: stdout: ""
Dec  3 14:51:04.377: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:51:04.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6851" for this suite.
Dec  3 14:51:10.450: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:10.803: INFO: namespace services-6851 deletion completed in 6.385059358s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:51:10.803: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-2933
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:51:11.000: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2597c24b-aaf5-4632-b589-563f50de603f" in namespace "downward-api-2933" to be "success or failure"
Dec  3 14:51:11.010: INFO: Pod "downwardapi-volume-2597c24b-aaf5-4632-b589-563f50de603f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.322285ms
Dec  3 14:51:13.021: INFO: Pod "downwardapi-volume-2597c24b-aaf5-4632-b589-563f50de603f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020989707s
STEP: Saw pod success
Dec  3 14:51:13.021: INFO: Pod "downwardapi-volume-2597c24b-aaf5-4632-b589-563f50de603f" satisfied condition "success or failure"
Dec  3 14:51:13.032: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downwardapi-volume-2597c24b-aaf5-4632-b589-563f50de603f container client-container: <nil>
STEP: delete the pod
Dec  3 14:51:13.065: INFO: Waiting for pod downwardapi-volume-2597c24b-aaf5-4632-b589-563f50de603f to disappear
Dec  3 14:51:13.075: INFO: Pod downwardapi-volume-2597c24b-aaf5-4632-b589-563f50de603f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:51:13.075: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-2933" for this suite.
Dec  3 14:51:19.136: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:19.486: INFO: namespace downward-api-2933 deletion completed in 6.381188185s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:51:19.487: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-8141
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-1983
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-4299
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:51:26.061: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8141" for this suite.
Dec  3 14:51:32.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:32.484: INFO: namespace namespaces-8141 deletion completed in 6.404703713s
STEP: Destroying namespace "nsdeletetest-1983" for this suite.
Dec  3 14:51:32.495: INFO: Namespace nsdeletetest-1983 was already deleted
STEP: Destroying namespace "nsdeletetest-4299" for this suite.
Dec  3 14:51:38.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:38.894: INFO: namespace nsdeletetest-4299 deletion completed in 6.399057633s
•S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:51:38.894: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9797
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 14:51:39.669: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981499, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981499, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981499, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981499, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 14:51:41.681: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981499, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981499, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981499, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710981499, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 14:51:44.697: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:51:45.095: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9797" for this suite.
Dec  3 14:51:51.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:51.491: INFO: namespace webhook-9797 deletion completed in 6.384884444s
STEP: Destroying namespace "webhook-9797-markers" for this suite.
Dec  3 14:51:57.523: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:51:57.905: INFO: namespace webhook-9797-markers deletion completed in 6.41379597s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:51:57.947: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1783
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Dec  3 14:51:58.129: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-1783'
Dec  3 14:51:58.395: INFO: stderr: ""
Dec  3 14:51:58.395: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 14:51:58.395: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1783'
Dec  3 14:51:58.507: INFO: stderr: ""
Dec  3 14:51:58.507: INFO: stdout: "update-demo-nautilus-2xpvx update-demo-nautilus-jsgcd "
Dec  3 14:51:58.507: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-2xpvx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1783'
Dec  3 14:51:58.612: INFO: stderr: ""
Dec  3 14:51:58.612: INFO: stdout: ""
Dec  3 14:51:58.612: INFO: update-demo-nautilus-2xpvx is created but not running
Dec  3 14:52:03.612: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1783'
Dec  3 14:52:03.768: INFO: stderr: ""
Dec  3 14:52:03.768: INFO: stdout: "update-demo-nautilus-2xpvx update-demo-nautilus-jsgcd "
Dec  3 14:52:03.768: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-2xpvx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1783'
Dec  3 14:52:03.875: INFO: stderr: ""
Dec  3 14:52:03.875: INFO: stdout: "true"
Dec  3 14:52:03.875: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-2xpvx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1783'
Dec  3 14:52:03.981: INFO: stderr: ""
Dec  3 14:52:03.981: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:52:03.981: INFO: validating pod update-demo-nautilus-2xpvx
Dec  3 14:52:04.075: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:52:04.075: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:52:04.075: INFO: update-demo-nautilus-2xpvx is verified up and running
Dec  3 14:52:04.075: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-jsgcd -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1783'
Dec  3 14:52:04.188: INFO: stderr: ""
Dec  3 14:52:04.188: INFO: stdout: "true"
Dec  3 14:52:04.188: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-jsgcd -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1783'
Dec  3 14:52:04.299: INFO: stderr: ""
Dec  3 14:52:04.299: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 14:52:04.299: INFO: validating pod update-demo-nautilus-jsgcd
Dec  3 14:52:04.395: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 14:52:04.395: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 14:52:04.395: INFO: update-demo-nautilus-jsgcd is verified up and running
STEP: rolling-update to new replication controller
Dec  3 14:52:04.396: INFO: scanned /root for discovery docs: <nil>
Dec  3 14:52:04.397: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-1783'
Dec  3 14:52:19.071: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  3 14:52:19.071: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 14:52:19.071: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1783'
Dec  3 14:52:19.193: INFO: stderr: ""
Dec  3 14:52:19.193: INFO: stdout: "update-demo-kitten-7cjq4 update-demo-kitten-g9kf9 update-demo-nautilus-2xpvx "
STEP: Replicas for name=update-demo: expected=2 actual=3
Dec  3 14:52:24.194: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-1783'
Dec  3 14:52:24.304: INFO: stderr: ""
Dec  3 14:52:24.304: INFO: stdout: "update-demo-kitten-7cjq4 update-demo-kitten-g9kf9 "
Dec  3 14:52:24.304: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-7cjq4 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1783'
Dec  3 14:52:24.415: INFO: stderr: ""
Dec  3 14:52:24.415: INFO: stdout: "true"
Dec  3 14:52:24.415: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-7cjq4 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1783'
Dec  3 14:52:24.526: INFO: stderr: ""
Dec  3 14:52:24.526: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  3 14:52:24.526: INFO: validating pod update-demo-kitten-7cjq4
Dec  3 14:52:24.621: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  3 14:52:24.621: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  3 14:52:24.621: INFO: update-demo-kitten-7cjq4 is verified up and running
Dec  3 14:52:24.621: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-g9kf9 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-1783'
Dec  3 14:52:24.725: INFO: stderr: ""
Dec  3 14:52:24.725: INFO: stdout: "true"
Dec  3 14:52:24.725: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-kitten-g9kf9 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-1783'
Dec  3 14:52:24.832: INFO: stderr: ""
Dec  3 14:52:24.832: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec  3 14:52:24.832: INFO: validating pod update-demo-kitten-g9kf9
Dec  3 14:52:24.926: INFO: got data: {
  "image": "kitten.jpg"
}

Dec  3 14:52:24.927: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec  3 14:52:24.927: INFO: update-demo-kitten-g9kf9 is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:52:24.927: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1783" for this suite.
Dec  3 14:52:36.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:52:37.326: INFO: namespace kubectl-1783 deletion completed in 12.380598158s
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:52:37.327: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5656
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-8029fa1b-c612-4458-8d72-73ab4f484edd
STEP: Creating a pod to test consume configMaps
Dec  3 14:52:37.533: INFO: Waiting up to 5m0s for pod "pod-configmaps-d1a82b67-3577-46c9-8fde-d86b5481d83c" in namespace "configmap-5656" to be "success or failure"
Dec  3 14:52:37.543: INFO: Pod "pod-configmaps-d1a82b67-3577-46c9-8fde-d86b5481d83c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.419651ms
Dec  3 14:52:39.553: INFO: Pod "pod-configmaps-d1a82b67-3577-46c9-8fde-d86b5481d83c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019790668s
STEP: Saw pod success
Dec  3 14:52:39.553: INFO: Pod "pod-configmaps-d1a82b67-3577-46c9-8fde-d86b5481d83c" satisfied condition "success or failure"
Dec  3 14:52:39.563: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-configmaps-d1a82b67-3577-46c9-8fde-d86b5481d83c container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 14:52:39.598: INFO: Waiting for pod pod-configmaps-d1a82b67-3577-46c9-8fde-d86b5481d83c to disappear
Dec  3 14:52:39.608: INFO: Pod pod-configmaps-d1a82b67-3577-46c9-8fde-d86b5481d83c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:52:39.608: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5656" for this suite.
Dec  3 14:52:45.659: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:52:46.046: INFO: namespace configmap-5656 deletion completed in 6.419696966s
•SSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:52:46.046: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-881
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec  3 14:52:50.348: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:52:50.359: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:52:52.359: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:52:52.369: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:52:54.359: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:52:54.370: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:52:56.359: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:52:56.370: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:52:58.359: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:52:58.370: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:53:00.359: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:53:00.370: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:53:02.359: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:53:02.370: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:53:04.359: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:53:04.370: INFO: Pod pod-with-poststart-exec-hook still exists
Dec  3 14:53:06.359: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec  3 14:53:06.370: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:53:06.370: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-881" for this suite.
Dec  3 14:53:18.421: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:53:18.774: INFO: namespace container-lifecycle-hook-881 deletion completed in 12.385718294s
•
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:53:18.774: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4104
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Dec  3 14:53:18.956: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 14:53:21.575: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:53:32.702: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4104" for this suite.
Dec  3 14:53:38.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:53:39.105: INFO: namespace crd-publish-openapi-4104 deletion completed in 6.383978566s
•SS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:53:39.106: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6270
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 14:53:39.288: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:53:41.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6270" for this suite.
Dec  3 14:54:25.637: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:54:25.987: INFO: namespace pods-6270 deletion completed in 44.381938285s
•SSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:54:25.988: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-9723
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-db856e4d-fa68-46de-9571-6aab7841d6c9 in namespace container-probe-9723
Dec  3 14:54:28.213: INFO: Started pod test-webserver-db856e4d-fa68-46de-9571-6aab7841d6c9 in namespace container-probe-9723
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 14:54:28.223: INFO: Initial restart count of pod test-webserver-db856e4d-fa68-46de-9571-6aab7841d6c9 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:58:29.540: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-9723" for this suite.
Dec  3 14:58:35.590: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:58:35.991: INFO: namespace container-probe-9723 deletion completed in 6.433202771s
•SSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:58:35.992: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-4090
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-7htl9 in namespace proxy-4090
I1203 14:58:36.202659    5064 runners.go:184] Created replication controller with name: proxy-service-7htl9, namespace: proxy-4090, replica count: 1
I1203 14:58:37.253283    5064 runners.go:184] proxy-service-7htl9 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1203 14:58:38.253645    5064 runners.go:184] proxy-service-7htl9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 14:58:39.253924    5064 runners.go:184] proxy-service-7htl9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 14:58:40.254230    5064 runners.go:184] proxy-service-7htl9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 14:58:41.254442    5064 runners.go:184] proxy-service-7htl9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 14:58:42.254758    5064 runners.go:184] proxy-service-7htl9 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1203 14:58:43.254965    5064 runners.go:184] proxy-service-7htl9 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 14:58:43.265: INFO: setup took 7.090350983s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec  3 14:58:43.280: INFO: (0) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 15.250902ms)
Dec  3 14:58:43.285: INFO: (0) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 20.299122ms)
Dec  3 14:58:43.286: INFO: (0) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 20.90515ms)
Dec  3 14:58:43.286: INFO: (0) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname2/proxy/: bar (200; 21.040985ms)
Dec  3 14:58:43.286: INFO: (0) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname2/proxy/: bar (200; 20.914442ms)
Dec  3 14:58:43.291: INFO: (0) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname1/proxy/: foo (200; 26.590386ms)
Dec  3 14:58:43.291: INFO: (0) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname1/proxy/: foo (200; 26.554699ms)
Dec  3 14:58:43.292: INFO: (0) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/rewriteme">test</a> (200; 26.832745ms)
Dec  3 14:58:43.292: INFO: (0) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">test<... (200; 26.884811ms)
Dec  3 14:58:43.292: INFO: (0) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">... (200; 26.938474ms)
Dec  3 14:58:43.292: INFO: (0) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 26.888848ms)
Dec  3 14:58:43.293: INFO: (0) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:462/proxy/: tls qux (200; 28.659161ms)
Dec  3 14:58:43.294: INFO: (0) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/tlsrewritem... (200; 29.323003ms)
Dec  3 14:58:43.295: INFO: (0) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname1/proxy/: tls baz (200; 30.156892ms)
Dec  3 14:58:43.296: INFO: (0) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:460/proxy/: tls baz (200; 30.649787ms)
Dec  3 14:58:43.302: INFO: (0) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname2/proxy/: tls qux (200; 37.221475ms)
Dec  3 14:58:43.314: INFO: (1) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.0281ms)
Dec  3 14:58:43.314: INFO: (1) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.112211ms)
Dec  3 14:58:43.314: INFO: (1) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:462/proxy/: tls qux (200; 12.323622ms)
Dec  3 14:58:43.315: INFO: (1) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.208835ms)
Dec  3 14:58:43.315: INFO: (1) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:460/proxy/: tls baz (200; 12.357136ms)
Dec  3 14:58:43.315: INFO: (1) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/tlsrewritem... (200; 12.319382ms)
Dec  3 14:58:43.315: INFO: (1) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">test<... (200; 12.342509ms)
Dec  3 14:58:43.315: INFO: (1) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.351153ms)
Dec  3 14:58:43.315: INFO: (1) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">... (200; 12.596757ms)
Dec  3 14:58:43.315: INFO: (1) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname1/proxy/: tls baz (200; 12.603057ms)
Dec  3 14:58:43.315: INFO: (1) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/rewriteme">test</a> (200; 12.745402ms)
Dec  3 14:58:43.315: INFO: (1) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname2/proxy/: tls qux (200; 12.567025ms)
Dec  3 14:58:43.315: INFO: (1) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname1/proxy/: foo (200; 13.185395ms)
Dec  3 14:58:43.316: INFO: (1) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname1/proxy/: foo (200; 13.678128ms)
Dec  3 14:58:43.316: INFO: (1) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname2/proxy/: bar (200; 13.835205ms)
Dec  3 14:58:43.316: INFO: (1) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname2/proxy/: bar (200; 13.783692ms)
Dec  3 14:58:43.329: INFO: (2) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname2/proxy/: bar (200; 12.360651ms)
Dec  3 14:58:43.329: INFO: (2) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.382051ms)
Dec  3 14:58:43.329: INFO: (2) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/rewriteme">test</a> (200; 12.59878ms)
Dec  3 14:58:43.329: INFO: (2) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:462/proxy/: tls qux (200; 12.553181ms)
Dec  3 14:58:43.329: INFO: (2) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.543255ms)
Dec  3 14:58:43.329: INFO: (2) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:460/proxy/: tls baz (200; 12.530161ms)
Dec  3 14:58:43.329: INFO: (2) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">... (200; 12.5434ms)
Dec  3 14:58:43.329: INFO: (2) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">test<... (200; 12.705557ms)
Dec  3 14:58:43.329: INFO: (2) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.612762ms)
Dec  3 14:58:43.329: INFO: (2) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/tlsrewritem... (200; 12.607058ms)
Dec  3 14:58:43.329: INFO: (2) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname1/proxy/: tls baz (200; 12.607777ms)
Dec  3 14:58:43.329: INFO: (2) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname2/proxy/: tls qux (200; 12.687455ms)
Dec  3 14:58:43.372: INFO: (2) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname2/proxy/: bar (200; 55.465826ms)
Dec  3 14:58:43.372: INFO: (2) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 55.466402ms)
Dec  3 14:58:43.372: INFO: (2) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname1/proxy/: foo (200; 55.387719ms)
Dec  3 14:58:43.372: INFO: (2) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname1/proxy/: foo (200; 55.470414ms)
Dec  3 14:58:43.384: INFO: (3) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">... (200; 12.292543ms)
Dec  3 14:58:43.384: INFO: (3) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.306291ms)
Dec  3 14:58:43.384: INFO: (3) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/rewriteme">test</a> (200; 12.566647ms)
Dec  3 14:58:43.385: INFO: (3) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">test<... (200; 12.627338ms)
Dec  3 14:58:43.385: INFO: (3) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.405525ms)
Dec  3 14:58:43.385: INFO: (3) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/tlsrewritem... (200; 12.581669ms)
Dec  3 14:58:43.385: INFO: (3) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.409032ms)
Dec  3 14:58:43.385: INFO: (3) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.976412ms)
Dec  3 14:58:43.385: INFO: (3) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:462/proxy/: tls qux (200; 13.088083ms)
Dec  3 14:58:43.386: INFO: (3) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:460/proxy/: tls baz (200; 13.937077ms)
Dec  3 14:58:43.386: INFO: (3) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname2/proxy/: tls qux (200; 13.849478ms)
Dec  3 14:58:43.386: INFO: (3) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname1/proxy/: tls baz (200; 13.84583ms)
Dec  3 14:58:43.386: INFO: (3) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname2/proxy/: bar (200; 14.014008ms)
Dec  3 14:58:43.386: INFO: (3) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname1/proxy/: foo (200; 14.092779ms)
Dec  3 14:58:43.386: INFO: (3) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname2/proxy/: bar (200; 14.136663ms)
Dec  3 14:58:43.386: INFO: (3) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname1/proxy/: foo (200; 14.203435ms)
Dec  3 14:58:43.404: INFO: (4) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname2/proxy/: tls qux (200; 17.924579ms)
Dec  3 14:58:43.404: INFO: (4) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 18.042144ms)
Dec  3 14:58:43.404: INFO: (4) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/rewriteme">test</a> (200; 17.998228ms)
Dec  3 14:58:43.405: INFO: (4) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">test<... (200; 18.175025ms)
Dec  3 14:58:43.405: INFO: (4) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:462/proxy/: tls qux (200; 18.399426ms)
Dec  3 14:58:43.405: INFO: (4) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 18.467881ms)
Dec  3 14:58:43.405: INFO: (4) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">... (200; 18.612857ms)
Dec  3 14:58:43.405: INFO: (4) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname1/proxy/: tls baz (200; 18.737891ms)
Dec  3 14:58:43.405: INFO: (4) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:460/proxy/: tls baz (200; 18.769486ms)
Dec  3 14:58:43.405: INFO: (4) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 18.851222ms)
Dec  3 14:58:43.405: INFO: (4) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/tlsrewritem... (200; 18.784237ms)
Dec  3 14:58:43.405: INFO: (4) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 18.745309ms)
Dec  3 14:58:43.447: INFO: (4) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname2/proxy/: bar (200; 60.184883ms)
Dec  3 14:58:43.447: INFO: (4) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname1/proxy/: foo (200; 60.195167ms)
Dec  3 14:58:43.447: INFO: (4) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname1/proxy/: foo (200; 60.17344ms)
Dec  3 14:58:43.447: INFO: (4) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname2/proxy/: bar (200; 60.185859ms)
Dec  3 14:58:43.462: INFO: (5) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 14.521485ms)
Dec  3 14:58:43.462: INFO: (5) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname1/proxy/: foo (200; 14.560508ms)
Dec  3 14:58:43.462: INFO: (5) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">... (200; 14.512824ms)
Dec  3 14:58:43.462: INFO: (5) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 14.512298ms)
Dec  3 14:58:43.462: INFO: (5) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 14.729487ms)
Dec  3 14:58:43.462: INFO: (5) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">test<... (200; 14.553428ms)
Dec  3 14:58:43.462: INFO: (5) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:462/proxy/: tls qux (200; 14.603202ms)
Dec  3 14:58:43.462: INFO: (5) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/rewriteme">test</a> (200; 14.851226ms)
Dec  3 14:58:43.462: INFO: (5) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/tlsrewritem... (200; 14.680979ms)
Dec  3 14:58:43.462: INFO: (5) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:460/proxy/: tls baz (200; 14.821601ms)
Dec  3 14:58:43.462: INFO: (5) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname1/proxy/: tls baz (200; 15.131346ms)
Dec  3 14:58:43.462: INFO: (5) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname2/proxy/: tls qux (200; 15.139361ms)
Dec  3 14:58:43.504: INFO: (5) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 56.737608ms)
Dec  3 14:58:43.504: INFO: (5) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname1/proxy/: foo (200; 56.818552ms)
Dec  3 14:58:43.504: INFO: (5) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname2/proxy/: bar (200; 56.953459ms)
Dec  3 14:58:43.504: INFO: (5) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname2/proxy/: bar (200; 56.81729ms)
Dec  3 14:58:43.516: INFO: (6) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/rewriteme">test</a> (200; 12.265733ms)
Dec  3 14:58:43.517: INFO: (6) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:462/proxy/: tls qux (200; 12.842202ms)
Dec  3 14:58:43.517: INFO: (6) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.642238ms)
Dec  3 14:58:43.517: INFO: (6) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">... (200; 12.833972ms)
Dec  3 14:58:43.517: INFO: (6) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.815371ms)
Dec  3 14:58:43.517: INFO: (6) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.781893ms)
Dec  3 14:58:43.517: INFO: (6) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">test<... (200; 12.79048ms)
Dec  3 14:58:43.517: INFO: (6) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/tlsrewritem... (200; 12.755018ms)
Dec  3 14:58:43.517: INFO: (6) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.734377ms)
Dec  3 14:58:43.517: INFO: (6) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:460/proxy/: tls baz (200; 12.738306ms)
Dec  3 14:58:43.517: INFO: (6) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname1/proxy/: tls baz (200; 12.872057ms)
Dec  3 14:58:43.517: INFO: (6) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname2/proxy/: tls qux (200; 12.89324ms)
Dec  3 14:58:43.518: INFO: (6) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname1/proxy/: foo (200; 13.774091ms)
Dec  3 14:58:43.519: INFO: (6) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname2/proxy/: bar (200; 14.526217ms)
Dec  3 14:58:43.519: INFO: (6) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname1/proxy/: foo (200; 14.728078ms)
Dec  3 14:58:43.519: INFO: (6) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname2/proxy/: bar (200; 14.560489ms)
Dec  3 14:58:43.531: INFO: (7) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.144771ms)
Dec  3 14:58:43.531: INFO: (7) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:460/proxy/: tls baz (200; 12.230198ms)
Dec  3 14:58:43.531: INFO: (7) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">test<... (200; 12.220452ms)
Dec  3 14:58:43.531: INFO: (7) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">... (200; 12.425326ms)
Dec  3 14:58:43.531: INFO: (7) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:462/proxy/: tls qux (200; 12.411808ms)
Dec  3 14:58:43.531: INFO: (7) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/rewriteme">test</a> (200; 12.312646ms)
Dec  3 14:58:43.531: INFO: (7) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/tlsrewritem... (200; 12.322004ms)
Dec  3 14:58:43.531: INFO: (7) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.325989ms)
Dec  3 14:58:43.531: INFO: (7) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.388212ms)
Dec  3 14:58:43.532: INFO: (7) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname1/proxy/: tls baz (200; 13.042819ms)
Dec  3 14:58:43.532: INFO: (7) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 13.059795ms)
Dec  3 14:58:43.532: INFO: (7) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname2/proxy/: tls qux (200; 13.074878ms)
Dec  3 14:58:43.533: INFO: (7) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname1/proxy/: foo (200; 13.782545ms)
Dec  3 14:58:43.574: INFO: (7) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname2/proxy/: bar (200; 55.263044ms)
Dec  3 14:58:43.574: INFO: (7) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname2/proxy/: bar (200; 55.188475ms)
Dec  3 14:58:43.574: INFO: (7) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname1/proxy/: foo (200; 55.17049ms)
Dec  3 14:58:43.587: INFO: (8) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/rewriteme">test</a> (200; 12.598553ms)
Dec  3 14:58:43.587: INFO: (8) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:460/proxy/: tls baz (200; 12.916099ms)
Dec  3 14:58:43.587: INFO: (8) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.944255ms)
Dec  3 14:58:43.587: INFO: (8) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">test<... (200; 13.05025ms)
Dec  3 14:58:43.587: INFO: (8) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.986363ms)
Dec  3 14:58:43.587: INFO: (8) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 13.034933ms)
Dec  3 14:58:43.587: INFO: (8) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">... (200; 13.084041ms)
Dec  3 14:58:43.588: INFO: (8) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname1/proxy/: tls baz (200; 13.366194ms)
Dec  3 14:58:43.588: INFO: (8) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:462/proxy/: tls qux (200; 13.388374ms)
Dec  3 14:58:43.588: INFO: (8) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 13.539706ms)
Dec  3 14:58:43.588: INFO: (8) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/tlsrewritem... (200; 13.445995ms)
Dec  3 14:58:43.588: INFO: (8) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname2/proxy/: tls qux (200; 13.585117ms)
Dec  3 14:58:43.630: INFO: (8) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname2/proxy/: bar (200; 55.368567ms)
Dec  3 14:58:43.630: INFO: (8) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname1/proxy/: foo (200; 55.312553ms)
Dec  3 14:58:43.630: INFO: (8) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname1/proxy/: foo (200; 55.254783ms)
Dec  3 14:58:43.630: INFO: (8) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname2/proxy/: bar (200; 55.235988ms)
Dec  3 14:58:43.642: INFO: (9) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">... (200; 12.418331ms)
Dec  3 14:58:43.642: INFO: (9) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.539654ms)
Dec  3 14:58:43.642: INFO: (9) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">test<... (200; 12.536228ms)
Dec  3 14:58:43.642: INFO: (9) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/rewriteme">test</a> (200; 12.458969ms)
Dec  3 14:58:43.642: INFO: (9) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.498878ms)
Dec  3 14:58:43.643: INFO: (9) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.696712ms)
Dec  3 14:58:43.643: INFO: (9) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/tlsrewritem... (200; 12.704769ms)
Dec  3 14:58:43.643: INFO: (9) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:462/proxy/: tls qux (200; 12.757039ms)
Dec  3 14:58:43.643: INFO: (9) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname2/proxy/: tls qux (200; 12.875729ms)
Dec  3 14:58:43.643: INFO: (9) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.859253ms)
Dec  3 14:58:43.643: INFO: (9) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname1/proxy/: tls baz (200; 12.665522ms)
Dec  3 14:58:43.643: INFO: (9) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:460/proxy/: tls baz (200; 12.754179ms)
Dec  3 14:58:43.644: INFO: (9) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname1/proxy/: foo (200; 13.860992ms)
Dec  3 14:58:43.644: INFO: (9) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname1/proxy/: foo (200; 14.517333ms)
Dec  3 14:58:43.645: INFO: (9) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname2/proxy/: bar (200; 15.145358ms)
Dec  3 14:58:43.645: INFO: (9) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname2/proxy/: bar (200; 14.766428ms)
Dec  3 14:58:43.658: INFO: (10) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.900253ms)
Dec  3 14:58:43.662: INFO: (10) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 16.837068ms)
Dec  3 14:58:43.662: INFO: (10) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/rewriteme">test</a> (200; 16.848774ms)
Dec  3 14:58:43.662: INFO: (10) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 16.932868ms)
Dec  3 14:58:43.662: INFO: (10) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:462/proxy/: tls qux (200; 17.097209ms)
Dec  3 14:58:43.662: INFO: (10) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname2/proxy/: tls qux (200; 17.124606ms)
Dec  3 14:58:43.662: INFO: (10) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 16.888542ms)
Dec  3 14:58:43.662: INFO: (10) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:460/proxy/: tls baz (200; 16.860674ms)
Dec  3 14:58:43.662: INFO: (10) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">test<... (200; 16.937513ms)
Dec  3 14:58:43.662: INFO: (10) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/tlsrewritem... (200; 16.872954ms)
Dec  3 14:58:43.662: INFO: (10) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">... (200; 16.980268ms)
Dec  3 14:58:43.663: INFO: (10) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname1/proxy/: tls baz (200; 17.673443ms)
Dec  3 14:58:43.663: INFO: (10) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname2/proxy/: bar (200; 17.978837ms)
Dec  3 14:58:43.668: INFO: (10) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname1/proxy/: foo (200; 22.893581ms)
Dec  3 14:58:43.672: INFO: (10) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname2/proxy/: bar (200; 27.217561ms)
Dec  3 14:58:43.672: INFO: (10) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname1/proxy/: foo (200; 27.275428ms)
Dec  3 14:58:43.687: INFO: (11) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 13.954805ms)
Dec  3 14:58:43.687: INFO: (11) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 14.03397ms)
Dec  3 14:58:43.687: INFO: (11) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 14.171099ms)
Dec  3 14:58:43.687: INFO: (11) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">test<... (200; 14.154819ms)
Dec  3 14:58:43.687: INFO: (11) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:462/proxy/: tls qux (200; 14.321656ms)
Dec  3 14:58:43.687: INFO: (11) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">... (200; 14.235195ms)
Dec  3 14:58:43.687: INFO: (11) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/rewriteme">test</a> (200; 14.317005ms)
Dec  3 14:58:43.687: INFO: (11) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 14.326334ms)
Dec  3 14:58:43.687: INFO: (11) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/tlsrewritem... (200; 14.344453ms)
Dec  3 14:58:43.687: INFO: (11) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:460/proxy/: tls baz (200; 14.361857ms)
Dec  3 14:58:43.693: INFO: (11) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname2/proxy/: tls qux (200; 20.789223ms)
Dec  3 14:58:43.693: INFO: (11) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname1/proxy/: tls baz (200; 20.940303ms)
Dec  3 14:58:43.693: INFO: (11) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname1/proxy/: foo (200; 20.776688ms)
Dec  3 14:58:43.693: INFO: (11) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname1/proxy/: foo (200; 20.760278ms)
Dec  3 14:58:43.694: INFO: (11) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname2/proxy/: bar (200; 20.906538ms)
Dec  3 14:58:43.694: INFO: (11) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname2/proxy/: bar (200; 20.973853ms)
Dec  3 14:58:43.706: INFO: (12) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">test<... (200; 12.262571ms)
Dec  3 14:58:43.706: INFO: (12) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.288425ms)
Dec  3 14:58:43.706: INFO: (12) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:462/proxy/: tls qux (200; 12.284992ms)
Dec  3 14:58:43.706: INFO: (12) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">... (200; 12.401759ms)
Dec  3 14:58:43.706: INFO: (12) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.48109ms)
Dec  3 14:58:43.706: INFO: (12) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.471099ms)
Dec  3 14:58:43.706: INFO: (12) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.48944ms)
Dec  3 14:58:43.706: INFO: (12) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/tlsrewritem... (200; 12.469289ms)
Dec  3 14:58:43.706: INFO: (12) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:460/proxy/: tls baz (200; 12.45579ms)
Dec  3 14:58:43.706: INFO: (12) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/rewriteme">test</a> (200; 12.637722ms)
Dec  3 14:58:43.707: INFO: (12) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname2/proxy/: tls qux (200; 13.090753ms)
Dec  3 14:58:43.707: INFO: (12) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname1/proxy/: foo (200; 13.406541ms)
Dec  3 14:58:43.707: INFO: (12) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname1/proxy/: tls baz (200; 13.406362ms)
Dec  3 14:58:43.708: INFO: (12) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname1/proxy/: foo (200; 14.242512ms)
Dec  3 14:58:43.708: INFO: (12) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname2/proxy/: bar (200; 14.152376ms)
Dec  3 14:58:43.708: INFO: (12) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname2/proxy/: bar (200; 14.622812ms)
Dec  3 14:58:43.721: INFO: (13) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.225548ms)
Dec  3 14:58:43.721: INFO: (13) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/rewriteme">test</a> (200; 12.229474ms)
Dec  3 14:58:43.721: INFO: (13) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">... (200; 12.143389ms)
Dec  3 14:58:43.721: INFO: (13) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.193662ms)
Dec  3 14:58:43.721: INFO: (13) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.185736ms)
Dec  3 14:58:43.721: INFO: (13) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">test<... (200; 12.343032ms)
Dec  3 14:58:43.721: INFO: (13) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:460/proxy/: tls baz (200; 12.345655ms)
Dec  3 14:58:43.721: INFO: (13) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.276864ms)
Dec  3 14:58:43.721: INFO: (13) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/tlsrewritem... (200; 12.264003ms)
Dec  3 14:58:43.721: INFO: (13) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:462/proxy/: tls qux (200; 12.353202ms)
Dec  3 14:58:43.722: INFO: (13) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname1/proxy/: tls baz (200; 13.212134ms)
Dec  3 14:58:43.722: INFO: (13) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname1/proxy/: foo (200; 13.134069ms)
Dec  3 14:58:43.722: INFO: (13) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname2/proxy/: bar (200; 13.218518ms)
Dec  3 14:58:43.722: INFO: (13) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname2/proxy/: tls qux (200; 13.259323ms)
Dec  3 14:58:43.722: INFO: (13) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname1/proxy/: foo (200; 13.455882ms)
Dec  3 14:58:43.722: INFO: (13) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname2/proxy/: bar (200; 13.952807ms)
Dec  3 14:58:43.735: INFO: (14) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.81344ms)
Dec  3 14:58:43.735: INFO: (14) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.899192ms)
Dec  3 14:58:43.736: INFO: (14) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/rewriteme">test</a> (200; 12.962476ms)
Dec  3 14:58:43.736: INFO: (14) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.921167ms)
Dec  3 14:58:43.735: INFO: (14) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">test<... (200; 12.892076ms)
Dec  3 14:58:43.736: INFO: (14) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/tlsrewritem... (200; 13.054811ms)
Dec  3 14:58:43.736: INFO: (14) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">... (200; 12.950419ms)
Dec  3 14:58:43.736: INFO: (14) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:462/proxy/: tls qux (200; 12.999802ms)
Dec  3 14:58:43.736: INFO: (14) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname1/proxy/: foo (200; 13.091847ms)
Dec  3 14:58:43.736: INFO: (14) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:460/proxy/: tls baz (200; 13.142603ms)
Dec  3 14:58:43.737: INFO: (14) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 14.397194ms)
Dec  3 14:58:43.737: INFO: (14) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname1/proxy/: tls baz (200; 14.312189ms)
Dec  3 14:58:43.737: INFO: (14) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname1/proxy/: foo (200; 14.270578ms)
Dec  3 14:58:43.737: INFO: (14) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname2/proxy/: bar (200; 14.646214ms)
Dec  3 14:58:43.737: INFO: (14) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname2/proxy/: tls qux (200; 14.670228ms)
Dec  3 14:58:43.737: INFO: (14) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname2/proxy/: bar (200; 14.799955ms)
Dec  3 14:58:43.750: INFO: (15) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">... (200; 12.26996ms)
Dec  3 14:58:43.750: INFO: (15) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:462/proxy/: tls qux (200; 12.336931ms)
Dec  3 14:58:43.750: INFO: (15) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.389421ms)
Dec  3 14:58:43.750: INFO: (15) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/tlsrewritem... (200; 12.473197ms)
Dec  3 14:58:43.750: INFO: (15) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">test<... (200; 12.576205ms)
Dec  3 14:58:43.750: INFO: (15) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:460/proxy/: tls baz (200; 12.451832ms)
Dec  3 14:58:43.750: INFO: (15) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname1/proxy/: tls baz (200; 12.416101ms)
Dec  3 14:58:43.750: INFO: (15) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.561691ms)
Dec  3 14:58:43.750: INFO: (15) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.538639ms)
Dec  3 14:58:43.750: INFO: (15) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.446648ms)
Dec  3 14:58:43.750: INFO: (15) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/rewriteme">test</a> (200; 12.63926ms)
Dec  3 14:58:43.751: INFO: (15) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname2/proxy/: tls qux (200; 13.215665ms)
Dec  3 14:58:43.751: INFO: (15) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname2/proxy/: bar (200; 13.519152ms)
Dec  3 14:58:43.751: INFO: (15) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname1/proxy/: foo (200; 13.541802ms)
Dec  3 14:58:43.751: INFO: (15) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname2/proxy/: bar (200; 13.538088ms)
Dec  3 14:58:43.751: INFO: (15) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname1/proxy/: foo (200; 13.754059ms)
Dec  3 14:58:43.764: INFO: (16) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.47881ms)
Dec  3 14:58:43.764: INFO: (16) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.334076ms)
Dec  3 14:58:43.764: INFO: (16) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/tlsrewritem... (200; 12.443423ms)
Dec  3 14:58:43.764: INFO: (16) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/rewriteme">test</a> (200; 12.364785ms)
Dec  3 14:58:43.764: INFO: (16) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">... (200; 12.369543ms)
Dec  3 14:58:43.764: INFO: (16) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.543415ms)
Dec  3 14:58:43.764: INFO: (16) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">test<... (200; 12.44851ms)
Dec  3 14:58:43.764: INFO: (16) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname2/proxy/: tls qux (200; 12.462299ms)
Dec  3 14:58:43.764: INFO: (16) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.38568ms)
Dec  3 14:58:43.764: INFO: (16) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:462/proxy/: tls qux (200; 12.51553ms)
Dec  3 14:58:43.764: INFO: (16) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:460/proxy/: tls baz (200; 12.552964ms)
Dec  3 14:58:43.764: INFO: (16) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname1/proxy/: tls baz (200; 12.848893ms)
Dec  3 14:58:43.806: INFO: (16) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname2/proxy/: bar (200; 54.618545ms)
Dec  3 14:58:43.806: INFO: (16) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname2/proxy/: bar (200; 54.666905ms)
Dec  3 14:58:43.806: INFO: (16) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname1/proxy/: foo (200; 54.698595ms)
Dec  3 14:58:43.806: INFO: (16) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname1/proxy/: foo (200; 54.790289ms)
Dec  3 14:58:43.819: INFO: (17) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">... (200; 12.677971ms)
Dec  3 14:58:43.819: INFO: (17) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.811328ms)
Dec  3 14:58:43.819: INFO: (17) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname2/proxy/: bar (200; 12.823156ms)
Dec  3 14:58:43.819: INFO: (17) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname1/proxy/: foo (200; 12.747435ms)
Dec  3 14:58:43.819: INFO: (17) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.732417ms)
Dec  3 14:58:43.819: INFO: (17) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/tlsrewritem... (200; 12.822101ms)
Dec  3 14:58:43.819: INFO: (17) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:462/proxy/: tls qux (200; 12.905186ms)
Dec  3 14:58:43.819: INFO: (17) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">test<... (200; 12.960176ms)
Dec  3 14:58:43.819: INFO: (17) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/rewriteme">test</a> (200; 12.864263ms)
Dec  3 14:58:43.820: INFO: (17) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname1/proxy/: tls baz (200; 13.159361ms)
Dec  3 14:58:43.820: INFO: (17) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname2/proxy/: tls qux (200; 13.202025ms)
Dec  3 14:58:43.820: INFO: (17) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:460/proxy/: tls baz (200; 13.339237ms)
Dec  3 14:58:43.820: INFO: (17) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname2/proxy/: bar (200; 13.67542ms)
Dec  3 14:58:43.821: INFO: (17) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname1/proxy/: foo (200; 14.242437ms)
Dec  3 14:58:43.821: INFO: (17) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 14.241291ms)
Dec  3 14:58:43.821: INFO: (17) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 14.342604ms)
Dec  3 14:58:43.833: INFO: (18) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname1/proxy/: tls baz (200; 12.27838ms)
Dec  3 14:58:43.833: INFO: (18) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.363356ms)
Dec  3 14:58:43.833: INFO: (18) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">... (200; 12.353063ms)
Dec  3 14:58:43.833: INFO: (18) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">test<... (200; 12.505787ms)
Dec  3 14:58:43.833: INFO: (18) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/tlsrewritem... (200; 12.289249ms)
Dec  3 14:58:43.833: INFO: (18) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:462/proxy/: tls qux (200; 12.413275ms)
Dec  3 14:58:43.833: INFO: (18) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:460/proxy/: tls baz (200; 12.535247ms)
Dec  3 14:58:43.833: INFO: (18) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.428672ms)
Dec  3 14:58:43.833: INFO: (18) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 12.358697ms)
Dec  3 14:58:43.833: INFO: (18) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname2/proxy/: tls qux (200; 12.276923ms)
Dec  3 14:58:43.833: INFO: (18) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/rewriteme">test</a> (200; 12.363111ms)
Dec  3 14:58:43.833: INFO: (18) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.365928ms)
Dec  3 14:58:43.834: INFO: (18) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname2/proxy/: bar (200; 12.898884ms)
Dec  3 14:58:43.875: INFO: (18) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname1/proxy/: foo (200; 54.026698ms)
Dec  3 14:58:43.875: INFO: (18) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname2/proxy/: bar (200; 54.021368ms)
Dec  3 14:58:43.875: INFO: (18) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname1/proxy/: foo (200; 54.1399ms)
Dec  3 14:58:43.887: INFO: (19) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">test<... (200; 11.25264ms)
Dec  3 14:58:43.887: INFO: (19) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:462/proxy/: tls qux (200; 11.509909ms)
Dec  3 14:58:43.887: INFO: (19) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:1080/proxy/rewriteme">... (200; 11.42052ms)
Dec  3 14:58:43.887: INFO: (19) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:443/proxy/tlsrewritem... (200; 11.455206ms)
Dec  3 14:58:43.887: INFO: (19) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 11.589372ms)
Dec  3 14:58:43.888: INFO: (19) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname2/proxy/: bar (200; 12.227419ms)
Dec  3 14:58:43.888: INFO: (19) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname1/proxy/: foo (200; 12.221815ms)
Dec  3 14:58:43.888: INFO: (19) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 12.243805ms)
Dec  3 14:58:43.888: INFO: (19) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/: <a href="/api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm/proxy/rewriteme">test</a> (200; 12.254259ms)
Dec  3 14:58:43.888: INFO: (19) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname1/proxy/: tls baz (200; 12.357552ms)
Dec  3 14:58:43.888: INFO: (19) /api/v1/namespaces/proxy-4090/pods/https:proxy-service-7htl9-8qnbm:460/proxy/: tls baz (200; 12.446914ms)
Dec  3 14:58:43.888: INFO: (19) /api/v1/namespaces/proxy-4090/services/https:proxy-service-7htl9:tlsportname2/proxy/: tls qux (200; 12.384631ms)
Dec  3 14:58:43.888: INFO: (19) /api/v1/namespaces/proxy-4090/services/http:proxy-service-7htl9:portname2/proxy/: bar (200; 12.859072ms)
Dec  3 14:58:43.889: INFO: (19) /api/v1/namespaces/proxy-4090/pods/http:proxy-service-7htl9-8qnbm:162/proxy/: bar (200; 13.679104ms)
Dec  3 14:58:43.889: INFO: (19) /api/v1/namespaces/proxy-4090/services/proxy-service-7htl9:portname1/proxy/: foo (200; 13.795623ms)
Dec  3 14:58:43.889: INFO: (19) /api/v1/namespaces/proxy-4090/pods/proxy-service-7htl9-8qnbm:160/proxy/: foo (200; 13.687494ms)
STEP: deleting ReplicationController proxy-service-7htl9 in namespace proxy-4090, will wait for the garbage collector to delete the pods
Dec  3 14:58:43.961: INFO: Deleting ReplicationController proxy-service-7htl9 took: 12.137258ms
Dec  3 14:58:44.362: INFO: Terminating ReplicationController proxy-service-7htl9 pods took: 400.331082ms
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:58:54.862: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-4090" for this suite.
Dec  3 14:59:00.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:59:01.270: INFO: namespace proxy-4090 deletion completed in 6.38892495s
•SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:59:01.271: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1668
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 14:59:01.466: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6e6e08df-aa33-4649-9190-bf70c72f3c4f" in namespace "downward-api-1668" to be "success or failure"
Dec  3 14:59:01.477: INFO: Pod "downwardapi-volume-6e6e08df-aa33-4649-9190-bf70c72f3c4f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.670563ms
Dec  3 14:59:03.487: INFO: Pod "downwardapi-volume-6e6e08df-aa33-4649-9190-bf70c72f3c4f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02097313s
Dec  3 14:59:05.498: INFO: Pod "downwardapi-volume-6e6e08df-aa33-4649-9190-bf70c72f3c4f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.031840668s
STEP: Saw pod success
Dec  3 14:59:05.498: INFO: Pod "downwardapi-volume-6e6e08df-aa33-4649-9190-bf70c72f3c4f" satisfied condition "success or failure"
Dec  3 14:59:05.509: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downwardapi-volume-6e6e08df-aa33-4649-9190-bf70c72f3c4f container client-container: <nil>
STEP: delete the pod
Dec  3 14:59:05.672: INFO: Waiting for pod downwardapi-volume-6e6e08df-aa33-4649-9190-bf70c72f3c4f to disappear
Dec  3 14:59:05.683: INFO: Pod downwardapi-volume-6e6e08df-aa33-4649-9190-bf70c72f3c4f no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:59:05.683: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1668" for this suite.
Dec  3 14:59:11.734: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:59:12.136: INFO: namespace downward-api-1668 deletion completed in 6.434293175s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:59:12.136: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4136
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec  3 14:59:14.916: INFO: Successfully updated pod "labelsupdate6fc41258-d89d-4cdc-8f8b-805ef2824ce9"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:59:18.973: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4136" for this suite.
Dec  3 14:59:37.024: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:59:37.373: INFO: namespace projected-4136 deletion completed in 18.382001296s
•SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:59:37.374: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7781
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec  3 14:59:37.571: INFO: Waiting up to 5m0s for pod "downward-api-18da1496-bdd4-4a88-90e2-da91b772fbc4" in namespace "downward-api-7781" to be "success or failure"
Dec  3 14:59:37.581: INFO: Pod "downward-api-18da1496-bdd4-4a88-90e2-da91b772fbc4": Phase="Pending", Reason="", readiness=false. Elapsed: 9.792109ms
Dec  3 14:59:39.592: INFO: Pod "downward-api-18da1496-bdd4-4a88-90e2-da91b772fbc4": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020897682s
STEP: Saw pod success
Dec  3 14:59:39.592: INFO: Pod "downward-api-18da1496-bdd4-4a88-90e2-da91b772fbc4" satisfied condition "success or failure"
Dec  3 14:59:39.603: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downward-api-18da1496-bdd4-4a88-90e2-da91b772fbc4 container dapi-container: <nil>
STEP: delete the pod
Dec  3 14:59:39.678: INFO: Waiting for pod downward-api-18da1496-bdd4-4a88-90e2-da91b772fbc4 to disappear
Dec  3 14:59:39.689: INFO: Pod downward-api-18da1496-bdd4-4a88-90e2-da91b772fbc4 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:59:39.689: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7781" for this suite.
Dec  3 14:59:45.741: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 14:59:46.106: INFO: namespace downward-api-7781 deletion completed in 6.398768927s
•SSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 14:59:46.107: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2853
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Dec  3 14:59:48.360: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec  3 14:59:58.496: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 14:59:58.507: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2853" for this suite.
Dec  3 15:00:04.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:00:04.901: INFO: namespace pods-2853 deletion completed in 6.382893196s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:00:04.901: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8842
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:00:05.084: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec  3 15:00:08.235: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-8842 create -f -'
Dec  3 15:00:08.811: INFO: stderr: ""
Dec  3 15:00:08.811: INFO: stdout: "e2e-test-crd-publish-openapi-3390-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec  3 15:00:08.811: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-8842 delete e2e-test-crd-publish-openapi-3390-crds test-cr'
Dec  3 15:00:08.966: INFO: stderr: ""
Dec  3 15:00:08.966: INFO: stdout: "e2e-test-crd-publish-openapi-3390-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Dec  3 15:00:08.967: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-8842 apply -f -'
Dec  3 15:00:09.192: INFO: stderr: ""
Dec  3 15:00:09.193: INFO: stdout: "e2e-test-crd-publish-openapi-3390-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec  3 15:00:09.193: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-8842 delete e2e-test-crd-publish-openapi-3390-crds test-cr'
Dec  3 15:00:09.315: INFO: stderr: ""
Dec  3 15:00:09.315: INFO: stdout: "e2e-test-crd-publish-openapi-3390-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec  3 15:00:09.315: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-3390-crds'
Dec  3 15:00:09.504: INFO: stderr: ""
Dec  3 15:00:09.504: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-3390-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:00:12.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8842" for this suite.
Dec  3 15:00:18.703: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:00:19.065: INFO: namespace crd-publish-openapi-8842 deletion completed in 6.393469043s
•SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:00:19.065: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-699
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-0b8bdd23-966f-4cdc-803f-4ce4a97268f2 in namespace container-probe-699
Dec  3 15:00:21.283: INFO: Started pod busybox-0b8bdd23-966f-4cdc-803f-4ce4a97268f2 in namespace container-probe-699
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 15:00:21.294: INFO: Initial restart count of pod busybox-0b8bdd23-966f-4cdc-803f-4ce4a97268f2 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:04:22.611: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-699" for this suite.
Dec  3 15:04:28.661: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:04:29.006: INFO: namespace container-probe-699 deletion completed in 6.376881423s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:04:29.006: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4664
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec  3 15:04:31.916: INFO: Successfully updated pod "annotationupdate933ea8e8-a246-4a24-8316-263772f1f847"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:04:35.970: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4664" for this suite.
Dec  3 15:04:48.021: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:04:48.373: INFO: namespace downward-api-4664 deletion completed in 12.384466093s
•SSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:04:48.373: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9928
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-dc2653ca-965d-4b3a-88c1-89a7644e6446
STEP: Creating secret with name s-test-opt-upd-f713fae9-0055-4cbb-addb-1caf85094355
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-dc2653ca-965d-4b3a-88c1-89a7644e6446
STEP: Updating secret s-test-opt-upd-f713fae9-0055-4cbb-addb-1caf85094355
STEP: Creating secret with name s-test-opt-create-3670d96e-bab4-4c95-9577-427ac1ac7a5b
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:04:55.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9928" for this suite.
Dec  3 15:05:07.070: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:05:07.419: INFO: namespace projected-9928 deletion completed in 12.381549338s
•SSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:05:07.419: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7246
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-01a4b92e-21f0-4509-9134-39133f1b75af in namespace container-probe-7246
Dec  3 15:05:09.639: INFO: Started pod liveness-01a4b92e-21f0-4509-9134-39133f1b75af in namespace container-probe-7246
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 15:05:09.649: INFO: Initial restart count of pod liveness-01a4b92e-21f0-4509-9134-39133f1b75af is 0
Dec  3 15:05:27.757: INFO: Restart count of pod container-probe-7246/liveness-01a4b92e-21f0-4509-9134-39133f1b75af is now 1 (18.107449672s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:05:27.774: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7246" for this suite.
Dec  3 15:05:33.823: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:05:34.164: INFO: namespace container-probe-7246 deletion completed in 6.371372907s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:05:34.164: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6423
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:05:35.008: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982334, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982334, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982334, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982334, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:05:37.018: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982334, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982334, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982334, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982334, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:05:40.035: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:05:40.072: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6423" for this suite.
Dec  3 15:05:46.124: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:05:46.510: INFO: namespace webhook-6423 deletion completed in 6.419086407s
STEP: Destroying namespace "webhook-6423-markers" for this suite.
Dec  3 15:05:52.542: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:05:52.907: INFO: namespace webhook-6423-markers deletion completed in 6.396850884s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:05:52.951: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3306
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-9f59
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 15:05:53.171: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-9f59" in namespace "subpath-3306" to be "success or failure"
Dec  3 15:05:53.182: INFO: Pod "pod-subpath-test-downwardapi-9f59": Phase="Pending", Reason="", readiness=false. Elapsed: 10.164259ms
Dec  3 15:05:55.193: INFO: Pod "pod-subpath-test-downwardapi-9f59": Phase="Running", Reason="", readiness=true. Elapsed: 2.021966427s
Dec  3 15:05:57.204: INFO: Pod "pod-subpath-test-downwardapi-9f59": Phase="Running", Reason="", readiness=true. Elapsed: 4.032355022s
Dec  3 15:05:59.214: INFO: Pod "pod-subpath-test-downwardapi-9f59": Phase="Running", Reason="", readiness=true. Elapsed: 6.042962237s
Dec  3 15:06:01.225: INFO: Pod "pod-subpath-test-downwardapi-9f59": Phase="Running", Reason="", readiness=true. Elapsed: 8.054012276s
Dec  3 15:06:03.237: INFO: Pod "pod-subpath-test-downwardapi-9f59": Phase="Running", Reason="", readiness=true. Elapsed: 10.065393634s
Dec  3 15:06:05.248: INFO: Pod "pod-subpath-test-downwardapi-9f59": Phase="Running", Reason="", readiness=true. Elapsed: 12.076272156s
Dec  3 15:06:07.258: INFO: Pod "pod-subpath-test-downwardapi-9f59": Phase="Running", Reason="", readiness=true. Elapsed: 14.08674495s
Dec  3 15:06:09.269: INFO: Pod "pod-subpath-test-downwardapi-9f59": Phase="Running", Reason="", readiness=true. Elapsed: 16.097588083s
Dec  3 15:06:11.280: INFO: Pod "pod-subpath-test-downwardapi-9f59": Phase="Running", Reason="", readiness=true. Elapsed: 18.108204936s
Dec  3 15:06:13.291: INFO: Pod "pod-subpath-test-downwardapi-9f59": Phase="Running", Reason="", readiness=true. Elapsed: 20.119253242s
Dec  3 15:06:15.302: INFO: Pod "pod-subpath-test-downwardapi-9f59": Phase="Running", Reason="", readiness=true. Elapsed: 22.130185198s
Dec  3 15:06:17.312: INFO: Pod "pod-subpath-test-downwardapi-9f59": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.14094451s
STEP: Saw pod success
Dec  3 15:06:17.312: INFO: Pod "pod-subpath-test-downwardapi-9f59" satisfied condition "success or failure"
Dec  3 15:06:17.324: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-subpath-test-downwardapi-9f59 container test-container-subpath-downwardapi-9f59: <nil>
STEP: delete the pod
Dec  3 15:06:17.358: INFO: Waiting for pod pod-subpath-test-downwardapi-9f59 to disappear
Dec  3 15:06:17.369: INFO: Pod pod-subpath-test-downwardapi-9f59 no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-9f59
Dec  3 15:06:17.369: INFO: Deleting pod "pod-subpath-test-downwardapi-9f59" in namespace "subpath-3306"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:06:17.379: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3306" for this suite.
Dec  3 15:06:23.430: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:06:23.810: INFO: namespace subpath-3306 deletion completed in 6.412683965s
•SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:06:23.811: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5783
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:06:23.992: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-5783'
Dec  3 15:06:24.260: INFO: stderr: ""
Dec  3 15:06:24.260: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec  3 15:06:24.260: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-5783'
Dec  3 15:06:24.462: INFO: stderr: ""
Dec  3 15:06:24.462: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  3 15:06:25.473: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:06:25.473: INFO: Found 1 / 1
Dec  3 15:06:25.473: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec  3 15:06:25.483: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:06:25.483: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 15:06:25.483: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe pod redis-master-7n8ps --namespace=kubectl-5783'
Dec  3 15:06:25.619: INFO: stderr: ""
Dec  3 15:06:25.620: INFO: stdout: "Name:         redis-master-7n8ps\nNamespace:    kubectl-5783\nPriority:     0\nNode:         shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz/10.250.0.2\nStart Time:   Tue, 03 Dec 2019 15:06:24 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  cni.projectcalico.org/podIP: 100.64.1.83/32\n              kubernetes.io/psp: e2e-test-privileged-psp\nStatus:       Running\nIP:           100.64.1.83\nIPs:\n  IP:           100.64.1.83\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   docker://dd4b71db60f8a09f786bdd8e1d4f5918f632ba669211d6d4a71cdcf39cb0f348\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Tue, 03 Dec 2019 15:06:25 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-pbjfw (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-pbjfw:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-pbjfw\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                                                       Message\n  ----    ------     ----       ----                                                       -------\n  Normal  Scheduled  <unknown>  default-scheduler                                          Successfully assigned kubectl-5783/redis-master-7n8ps to shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz\n  Normal  Pulled     1s         kubelet, shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    0s         kubelet, shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Created container redis-master\n  Normal  Started    0s         kubelet, shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Started container redis-master\n"
Dec  3 15:06:25.620: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe rc redis-master --namespace=kubectl-5783'
Dec  3 15:06:25.773: INFO: stderr: ""
Dec  3 15:06:25.773: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-5783\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  1s    replication-controller  Created pod: redis-master-7n8ps\n"
Dec  3 15:06:25.773: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe service redis-master --namespace=kubectl-5783'
Dec  3 15:06:25.916: INFO: stderr: ""
Dec  3 15:06:25.917: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-5783\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                100.109.129.249\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         100.64.1.83:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec  3 15:06:25.935: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6'
Dec  3 15:06:26.110: INFO: stderr: ""
Dec  3 15:06:26.110: INFO: stdout: "Name:               shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6\nRoles:              <none>\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/instance-type=n1-standard-2\n                    beta.kubernetes.io/os=linux\n                    failure-domain.beta.kubernetes.io/region=europe-west1\n                    failure-domain.beta.kubernetes.io/zone=europe-west1-b\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6\n                    kubernetes.io/os=linux\n                    node.kubernetes.io/role=node\n                    worker.garden.sapcloud.io/group=worker-1\n                    worker.gardener.cloud/pool=worker-1\nAnnotations:        node.alpha.kubernetes.io/ttl: 0\n                    projectcalico.org/IPv4Address: 10.250.0.3/32\n                    projectcalico.org/IPv4IPIPTunnelAddr: 100.64.0.1\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Tue, 03 Dec 2019 14:27:13 +0000\nTaints:             <none>\nUnschedulable:      false\nConditions:\n  Type                          Status  LastHeartbeatTime                 LastTransitionTime                Reason                          Message\n  ----                          ------  -----------------                 ------------------                ------                          -------\n  CorruptDockerOverlay2         False   Tue, 03 Dec 2019 15:05:38 +0000   Tue, 03 Dec 2019 14:28:13 +0000   NoCorruptDockerOverlay2         docker overlay2 is functioning properly\n  FrequentUnregisterNetDevice   False   Tue, 03 Dec 2019 15:05:38 +0000   Tue, 03 Dec 2019 14:28:13 +0000   NoFrequentUnregisterNetDevice   node is functioning properly\n  FrequentKubeletRestart        False   Tue, 03 Dec 2019 15:05:38 +0000   Tue, 03 Dec 2019 14:28:13 +0000   NoFrequentKubeletRestart        kubelet is functioning properly\n  FrequentDockerRestart         False   Tue, 03 Dec 2019 15:05:38 +0000   Tue, 03 Dec 2019 14:28:13 +0000   NoFrequentDockerRestart         docker is functioning properly\n  FrequentContainerdRestart     False   Tue, 03 Dec 2019 15:05:38 +0000   Tue, 03 Dec 2019 14:28:13 +0000   NoFrequentContainerdRestart     containerd is functioning properly\n  KernelDeadlock                False   Tue, 03 Dec 2019 15:05:38 +0000   Tue, 03 Dec 2019 14:28:13 +0000   KernelHasNoDeadlock             kernel has no deadlock\n  ReadonlyFilesystem            False   Tue, 03 Dec 2019 15:05:38 +0000   Tue, 03 Dec 2019 14:28:13 +0000   FilesystemIsNotReadOnly         Filesystem is not read-only\n  NetworkUnavailable            False   Tue, 03 Dec 2019 14:27:30 +0000   Tue, 03 Dec 2019 14:27:30 +0000   CalicoIsUp                      Calico is running on this node\n  MemoryPressure                False   Tue, 03 Dec 2019 15:06:17 +0000   Tue, 03 Dec 2019 14:27:13 +0000   KubeletHasSufficientMemory      kubelet has sufficient memory available\n  DiskPressure                  False   Tue, 03 Dec 2019 15:06:17 +0000   Tue, 03 Dec 2019 14:27:13 +0000   KubeletHasNoDiskPressure        kubelet has no disk pressure\n  PIDPressure                   False   Tue, 03 Dec 2019 15:06:17 +0000   Tue, 03 Dec 2019 14:27:13 +0000   KubeletHasSufficientPID         kubelet has sufficient PID available\n  Ready                         True    Tue, 03 Dec 2019 15:06:17 +0000   Tue, 03 Dec 2019 14:27:33 +0000   KubeletReady                    kubelet is posting ready status\nAddresses:\n  InternalIP:   10.250.0.3\n  ExternalIP:   \n  InternalDNS:  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6.c.sap-gcp-k8s-canary-custom.internal\n  Hostname:     shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6.c.sap-gcp-k8s-canary-custom.internal\nCapacity:\n attachable-volumes-gce-pd:  127\n cpu:                        2\n ephemeral-storage:          28056816Ki\n hugepages-1Gi:              0\n hugepages-2Mi:              0\n memory:                     7652436Ki\n pods:                       110\nAllocatable:\n attachable-volumes-gce-pd:  127\n cpu:                        1920m\n ephemeral-storage:          27293670584\n hugepages-1Gi:              0\n hugepages-2Mi:              0\n memory:                     6370547911\n pods:                       110\nSystem Info:\n Machine ID:                 9c36e48a8e5e419828e09642db3efea8\n System UUID:                9c36e48a-8e5e-4198-28e0-9642db3efea8\n Boot ID:                    848a6932-ae36-424b-b9fa-b01eff9b306b\n Kernel Version:             4.19.56-coreos-r1\n OS Image:                   Container Linux by CoreOS 2135.6.0 (Rhyolite)\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  docker://18.6.3\n Kubelet Version:            v1.16.3\n Kube-Proxy Version:         v1.16.3\nPodCIDR:                     100.64.0.0/24\nPodCIDRs:                    100.64.0.0/24\nProviderID:                  gce://sap-gcp-k8s-canary-custom/europe-west1-b/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6\nNon-terminated Pods:         (15 in total)\n  Namespace                  Name                                                              CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                              ------------  ----------  ---------------  -------------  ---\n  kube-system                addons-kubernetes-dashboard-78954cc66b-gjdxd                      50m (2%)      100m (5%)   50Mi (0%)        256Mi (4%)     40m\n  kube-system                addons-nginx-ingress-controller-7c75bb76db-zkqv8                  100m (5%)     2 (104%)    100Mi (1%)       1Gi (16%)      40m\n  kube-system                addons-nginx-ingress-nginx-ingress-k8s-backend-95f65778d-nb2sc    0 (0%)        0 (0%)      0 (0%)           0 (0%)         40m\n  kube-system                blackbox-exporter-7bd7b55dfc-7ktvk                                5m (0%)       10m (0%)    5Mi (0%)         35Mi (0%)      40m\n  kube-system                calico-kube-controllers-79bcd784b6-pkrdg                          0 (0%)        0 (0%)      0 (0%)           0 (0%)         40m\n  kube-system                calico-node-rc24j                                                 100m (5%)     500m (26%)  100Mi (1%)       700Mi (11%)    39m\n  kube-system                calico-typha-horizontal-autoscaler-69df649c59-7l6bk               10m (0%)      10m (0%)    0 (0%)           0 (0%)         40m\n  kube-system                calico-typha-vertical-autoscaler-847d859f8c-vfvq7                 0 (0%)        0 (0%)      0 (0%)           0 (0%)         40m\n  kube-system                coredns-59c969ffb8-jwpjr                                          50m (2%)      100m (5%)   15Mi (0%)        100Mi (1%)     39m\n  kube-system                coredns-59c969ffb8-p9rws                                          50m (2%)      100m (5%)   15Mi (0%)        100Mi (1%)     40m\n  kube-system                kube-proxy-qzrrc                                                  20m (1%)      0 (0%)      64Mi (1%)        0 (0%)         39m\n  kube-system                metrics-server-7df74c5758-hnsgs                                   20m (1%)      80m (4%)    100Mi (1%)       400Mi (6%)     40m\n  kube-system                node-exporter-pwl5b                                               5m (0%)       25m (1%)    10Mi (0%)        100Mi (1%)     39m\n  kube-system                node-problem-detector-xwvwh                                       20m (1%)      200m (10%)  20Mi (0%)        100Mi (1%)     39m\n  kube-system                vpn-shoot-5689b7f9b4-n47mb                                        100m (5%)     1 (52%)     100Mi (1%)       1000Mi (16%)   40m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource                   Requests    Limits\n  --------                   --------    ------\n  cpu                        530m (27%)  4125m (214%)\n  memory                     579Mi (9%)  3815Mi (62%)\n  ephemeral-storage          0 (0%)      0 (0%)\n  attachable-volumes-gce-pd  0           0\nEvents:\n  Type     Reason                   Age                From                                                               Message\n  ----     ------                   ----               ----                                                               -------\n  Normal   Starting                 39m                kubelet, shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6          Starting kubelet.\n  Normal   NodeHasSufficientMemory  39m                kubelet, shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6          Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 status is now: NodeHasSufficientMemory\n  Normal   NodeHasNoDiskPressure    39m                kubelet, shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6          Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 status is now: NodeHasNoDiskPressure\n  Normal   NodeHasSufficientPID     39m                kubelet, shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6          Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 status is now: NodeHasSufficientPID\n  Normal   NodeAllocatableEnforced  39m                kubelet, shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6          Updated Node Allocatable limit across pods\n  Normal   Starting                 39m                kube-proxy, shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6       Starting kube-proxy.\n  Normal   NodeReady                38m                kubelet, shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6          Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 status is now: NodeReady\n  Warning  DockerStart              38m (x3 over 38m)  systemd-monitor, shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6  Starting Docker Application Container Engine...\n"
Dec  3 15:06:26.111: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config describe namespace kubectl-5783'
Dec  3 15:06:26.250: INFO: stderr: ""
Dec  3 15:06:26.250: INFO: stdout: "Name:         kubectl-5783\nLabels:       e2e-framework=kubectl\n              e2e-run=ecd78362-af97-4f4c-8860-165e7b020457\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:06:26.250: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5783" for this suite.
Dec  3 15:06:38.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:06:38.660: INFO: namespace kubectl-5783 deletion completed in 12.391895452s
•SSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:06:38.661: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-5881
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:06:38.850: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:06:40.947: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-5881" for this suite.
Dec  3 15:07:26.997: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:27.391: INFO: namespace pods-5881 deletion completed in 46.425103788s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:07:27.391: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-9706
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9706.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-9706.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:07:30.239: INFO: DNS probes using dns-9706/dns-test-1169935a-2755-4c9e-b4b5-8035318b45c4 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:07:30.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-9706" for this suite.
Dec  3 15:07:36.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:36.692: INFO: namespace dns-9706 deletion completed in 6.415466118s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:07:36.692: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3304
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:07:37.656: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982457, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982457, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982457, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982457, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:07:39.667: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982457, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982457, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982457, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710982457, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:07:42.684: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:07:53.512: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3304" for this suite.
Dec  3 15:07:59.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:07:59.954: INFO: namespace webhook-3304 deletion completed in 6.390332492s
STEP: Destroying namespace "webhook-3304-markers" for this suite.
Dec  3 15:08:05.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:08:06.339: INFO: namespace webhook-3304-markers deletion completed in 6.384993128s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:08:06.383: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4186
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  3 15:08:06.564: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-4186'
Dec  3 15:08:06.691: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 15:08:06.691: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Dec  3 15:08:06.701: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete jobs e2e-test-httpd-job --namespace=kubectl-4186'
Dec  3 15:08:06.826: INFO: stderr: ""
Dec  3 15:08:06.826: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:08:06.826: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4186" for this suite.
Dec  3 15:08:18.869: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:08:19.227: INFO: namespace kubectl-4186 deletion completed in 12.390004762s
•
------------------------------
[sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial] 
  evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:08:19.227: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename taint-multiple-pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-multiple-pods-9567
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:345
Dec  3 15:08:19.409: INFO: Waiting up to 1m0s for all nodes to be ready
Dec  3 15:09:19.500: INFO: Waiting for terminating namespaces to be deleted...
[It] evicts pods with minTolerationSeconds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:09:19.511: INFO: Starting informer...
STEP: Starting pods...
Dec  3 15:09:19.544: INFO: Pod1 is running on shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz. Tainting Node
Dec  3 15:09:21.595: INFO: Pod2 is running on shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting for Pod1 and Pod2 to be deleted
Dec  3 15:09:34.771: INFO: Noticed Pod "taint-eviction-b1" gets evicted.
Dec  3 15:09:54.769: INFO: Noticed Pod "taint-eviction-b2" gets evicted.
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
[AfterEach] [sig-scheduling] NoExecuteTaintManager Multiple Pods [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:09:54.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-multiple-pods-9567" for this suite.
Dec  3 15:10:00.845: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:10:01.206: INFO: namespace taint-multiple-pods-9567 deletion completed in 6.393425931s
•SS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:10:01.207: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3855
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:10:01.449: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec  3 15:10:01.470: INFO: Number of nodes with available pods: 0
Dec  3 15:10:01.470: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec  3 15:10:01.513: INFO: Number of nodes with available pods: 0
Dec  3 15:10:01.513: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:02.524: INFO: Number of nodes with available pods: 0
Dec  3 15:10:02.524: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:03.524: INFO: Number of nodes with available pods: 0
Dec  3 15:10:03.524: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:04.524: INFO: Number of nodes with available pods: 0
Dec  3 15:10:04.524: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:05.524: INFO: Number of nodes with available pods: 0
Dec  3 15:10:05.524: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:06.524: INFO: Number of nodes with available pods: 0
Dec  3 15:10:06.524: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:07.524: INFO: Number of nodes with available pods: 0
Dec  3 15:10:07.524: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:08.524: INFO: Number of nodes with available pods: 0
Dec  3 15:10:08.524: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:09.524: INFO: Number of nodes with available pods: 0
Dec  3 15:10:09.524: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:10.524: INFO: Number of nodes with available pods: 1
Dec  3 15:10:10.524: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec  3 15:10:10.573: INFO: Number of nodes with available pods: 0
Dec  3 15:10:10.573: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec  3 15:10:10.597: INFO: Number of nodes with available pods: 0
Dec  3 15:10:10.597: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:11.608: INFO: Number of nodes with available pods: 0
Dec  3 15:10:11.608: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:12.608: INFO: Number of nodes with available pods: 0
Dec  3 15:10:12.608: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:13.608: INFO: Number of nodes with available pods: 0
Dec  3 15:10:13.608: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:14.608: INFO: Number of nodes with available pods: 0
Dec  3 15:10:14.608: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:15.609: INFO: Number of nodes with available pods: 0
Dec  3 15:10:15.609: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:16.608: INFO: Number of nodes with available pods: 0
Dec  3 15:10:16.608: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:17.608: INFO: Number of nodes with available pods: 0
Dec  3 15:10:17.608: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:18.608: INFO: Number of nodes with available pods: 0
Dec  3 15:10:18.608: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:19.608: INFO: Number of nodes with available pods: 0
Dec  3 15:10:19.608: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:20.609: INFO: Number of nodes with available pods: 0
Dec  3 15:10:20.609: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:21.608: INFO: Number of nodes with available pods: 0
Dec  3 15:10:21.608: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:22.609: INFO: Number of nodes with available pods: 0
Dec  3 15:10:22.609: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:23.608: INFO: Number of nodes with available pods: 0
Dec  3 15:10:23.608: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:24.608: INFO: Number of nodes with available pods: 0
Dec  3 15:10:24.608: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:10:25.608: INFO: Number of nodes with available pods: 1
Dec  3 15:10:25.608: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3855, will wait for the garbage collector to delete the pods
Dec  3 15:10:25.702: INFO: Deleting DaemonSet.extensions daemon-set took: 12.776146ms
Dec  3 15:10:26.103: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.466748ms
Dec  3 15:10:33.713: INFO: Number of nodes with available pods: 0
Dec  3 15:10:33.713: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 15:10:33.725: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3855/daemonsets","resourceVersion":"9471"},"items":null}

Dec  3 15:10:33.735: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3855/pods","resourceVersion":"9471"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:10:33.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3855" for this suite.
Dec  3 15:10:39.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:10:40.185: INFO: namespace daemonsets-3855 deletion completed in 6.387880957s
•S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:10:40.186: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-8082
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec  3 15:10:40.366: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 15:10:40.399: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 15:10:40.410: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 before test
Dec  3 15:10:40.438: INFO: calico-typha-deploy-9f6b455c4-6ntkq from kube-system started at 2019-12-03 15:09:21 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:40.438: INFO: 	Container calico-typha ready: true, restart count 0
Dec  3 15:10:40.438: INFO: node-exporter-pwl5b from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:40.438: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:10:40.438: INFO: kube-proxy-qzrrc from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:40.438: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:10:40.438: INFO: metrics-server-7df74c5758-hnsgs from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:40.438: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 15:10:40.438: INFO: calico-node-rc24j from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:40.438: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:10:40.438: INFO: coredns-59c969ffb8-jwpjr from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:40.438: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:10:40.438: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-95f65778d-nb2sc from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:40.438: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec  3 15:10:40.438: INFO: calico-kube-controllers-79bcd784b6-pkrdg from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:40.438: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  3 15:10:40.438: INFO: addons-kubernetes-dashboard-78954cc66b-gjdxd from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:40.438: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  3 15:10:40.438: INFO: calico-typha-horizontal-autoscaler-69df649c59-7l6bk from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:40.438: INFO: 	Container autoscaler ready: true, restart count 0
Dec  3 15:10:40.438: INFO: addons-nginx-ingress-controller-7c75bb76db-zkqv8 from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:40.438: INFO: 	Container nginx-ingress-controller ready: true, restart count 1
Dec  3 15:10:40.438: INFO: calico-typha-vertical-autoscaler-847d859f8c-vfvq7 from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:40.438: INFO: 	Container autoscaler ready: true, restart count 3
Dec  3 15:10:40.438: INFO: coredns-59c969ffb8-p9rws from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:40.438: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:10:40.438: INFO: vpn-shoot-5689b7f9b4-n47mb from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:40.438: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec  3 15:10:40.438: INFO: blackbox-exporter-7bd7b55dfc-7ktvk from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:40.438: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec  3 15:10:40.438: INFO: node-problem-detector-xwvwh from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:40.438: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:10:40.438: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz before test
Dec  3 15:10:40.576: INFO: node-problem-detector-4c7x7 from kube-system started at 2019-12-03 14:27:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:40.577: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:10:40.577: INFO: calico-node-zhw8c from kube-system started at 2019-12-03 14:27:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:40.577: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:10:40.577: INFO: node-exporter-fmmk4 from kube-system started at 2019-12-03 14:27:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:40.577: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:10:40.577: INFO: kube-proxy-n42lb from kube-system started at 2019-12-03 14:27:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:10:40.577: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-90e51a56-e3c2-49e9-bec1-317434afe719 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-90e51a56-e3c2-49e9-bec1-317434afe719 off the node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz
STEP: verifying the node doesn't have the label kubernetes.io/e2e-90e51a56-e3c2-49e9-bec1-317434afe719
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:10:44.730: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8082" for this suite.
Dec  3 15:10:52.772: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:10:53.122: INFO: namespace sched-pred-8082 deletion completed in 8.381907163s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:10:53.123: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4626
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  3 15:10:53.319: INFO: Waiting up to 5m0s for pod "pod-9c184ae3-0424-4a65-9a0f-092da0a0c760" in namespace "emptydir-4626" to be "success or failure"
Dec  3 15:10:53.329: INFO: Pod "pod-9c184ae3-0424-4a65-9a0f-092da0a0c760": Phase="Pending", Reason="", readiness=false. Elapsed: 9.599682ms
Dec  3 15:10:55.340: INFO: Pod "pod-9c184ae3-0424-4a65-9a0f-092da0a0c760": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02054637s
STEP: Saw pod success
Dec  3 15:10:55.340: INFO: Pod "pod-9c184ae3-0424-4a65-9a0f-092da0a0c760" satisfied condition "success or failure"
Dec  3 15:10:55.350: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-9c184ae3-0424-4a65-9a0f-092da0a0c760 container test-container: <nil>
STEP: delete the pod
Dec  3 15:10:55.383: INFO: Waiting for pod pod-9c184ae3-0424-4a65-9a0f-092da0a0c760 to disappear
Dec  3 15:10:55.393: INFO: Pod pod-9c184ae3-0424-4a65-9a0f-092da0a0c760 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:10:55.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4626" for this suite.
Dec  3 15:11:01.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:11:01.793: INFO: namespace emptydir-4626 deletion completed in 6.381256372s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:11:01.794: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-5647
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:11:01.973: INFO: Creating ReplicaSet my-hostname-basic-8e146051-0dbe-4171-93c8-8c43a50023ee
Dec  3 15:11:01.994: INFO: Pod name my-hostname-basic-8e146051-0dbe-4171-93c8-8c43a50023ee: Found 1 pods out of 1
Dec  3 15:11:01.994: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-8e146051-0dbe-4171-93c8-8c43a50023ee" is running
Dec  3 15:11:04.015: INFO: Pod "my-hostname-basic-8e146051-0dbe-4171-93c8-8c43a50023ee-gw6t5" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 15:11:01 +0000 UTC Reason: Message:}])
Dec  3 15:11:04.015: INFO: Trying to dial the pod
Dec  3 15:11:09.132: INFO: Controller my-hostname-basic-8e146051-0dbe-4171-93c8-8c43a50023ee: Got expected result from replica 1 [my-hostname-basic-8e146051-0dbe-4171-93c8-8c43a50023ee-gw6t5]: "my-hostname-basic-8e146051-0dbe-4171-93c8-8c43a50023ee-gw6t5", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:11:09.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-5647" for this suite.
Dec  3 15:11:15.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:11:15.569: INFO: namespace replicaset-5647 deletion completed in 6.417170939s
•SSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:11:15.569: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-8058
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8058.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-8058.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8058.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-8058.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-8058.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-8058.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:11:20.368: INFO: DNS probes using dns-8058/dns-test-5137cd29-5b76-456e-9d10-420d8150d7a4 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:11:20.401: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-8058" for this suite.
Dec  3 15:11:26.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:11:26.813: INFO: namespace dns-8058 deletion completed in 6.393881578s
•S
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:11:26.813: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4042
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-633720aa-6b96-4e05-8ded-ecec639d36ce
STEP: Creating configMap with name cm-test-opt-upd-ad816c9a-5a83-4c79-96b9-d4a7307f992a
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-633720aa-6b96-4e05-8ded-ecec639d36ce
STEP: Updating configmap cm-test-opt-upd-ad816c9a-5a83-4c79-96b9-d4a7307f992a
STEP: Creating configMap with name cm-test-opt-create-79089c99-7747-40e2-bfa8-7e40f67f13fe
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:12:48.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4042" for this suite.
Dec  3 15:13:00.094: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:13:00.440: INFO: namespace projected-4042 deletion completed in 12.377607342s
•SSSS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:13:00.440: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-3742
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec  3 15:13:02.672: INFO: &Pod{ObjectMeta:{send-events-2f33a9bd-0cc7-47ac-a7ae-31207225d34c  events-3742 /api/v1/namespaces/events-3742/pods/send-events-2f33a9bd-0cc7-47ac-a7ae-31207225d34c 2545e78d-a7f8-4ee6-b000-f5e3b5139bac 9956 0 2019-12-03 15:13:00 +0000 UTC <nil> <nil> map[name:foo time:620179034] map[cni.projectcalico.org/podIP:100.64.1.95/32 kubernetes.io/psp:e2e-test-privileged-psp] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8w74j,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8w74j,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8w74j,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:13:00 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:13:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:13:02 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:13:00 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.2,PodIP:100.64.1.95,StartTime:2019-12-03 15:13:00 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 15:13:01 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:docker-pullable://gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:docker://da2a62e23f28fae975ee79adb2d30f260dd0ae9c69a57b6819927617c17bfbb5,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.95,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Dec  3 15:13:04.683: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec  3 15:13:06.694: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:13:06.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-3742" for this suite.
Dec  3 15:13:50.754: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:13:51.135: INFO: namespace events-3742 deletion completed in 44.410870905s
•SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:13:51.135: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4281
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  3 15:13:53.369: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:13:53.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4281" for this suite.
Dec  3 15:13:59.443: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:13:59.783: INFO: namespace container-runtime-4281 deletion completed in 6.371500569s
•SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:13:59.783: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4876
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-c67f9d56-1ead-4b6b-8aa1-cf8899993d9c
STEP: Creating a pod to test consume secrets
Dec  3 15:13:59.986: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-dfce4612-e4e3-45d7-a17f-fd5cbb1cea5e" in namespace "projected-4876" to be "success or failure"
Dec  3 15:13:59.996: INFO: Pod "pod-projected-secrets-dfce4612-e4e3-45d7-a17f-fd5cbb1cea5e": Phase="Pending", Reason="", readiness=false. Elapsed: 9.755497ms
Dec  3 15:14:02.007: INFO: Pod "pod-projected-secrets-dfce4612-e4e3-45d7-a17f-fd5cbb1cea5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020359828s
STEP: Saw pod success
Dec  3 15:14:02.007: INFO: Pod "pod-projected-secrets-dfce4612-e4e3-45d7-a17f-fd5cbb1cea5e" satisfied condition "success or failure"
Dec  3 15:14:02.017: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-projected-secrets-dfce4612-e4e3-45d7-a17f-fd5cbb1cea5e container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:14:02.048: INFO: Waiting for pod pod-projected-secrets-dfce4612-e4e3-45d7-a17f-fd5cbb1cea5e to disappear
Dec  3 15:14:02.058: INFO: Pod pod-projected-secrets-dfce4612-e4e3-45d7-a17f-fd5cbb1cea5e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:14:02.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4876" for this suite.
Dec  3 15:14:08.107: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:14:08.442: INFO: namespace projected-4876 deletion completed in 6.365656907s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:14:08.442: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6649
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  3 15:14:08.702: INFO: Number of nodes with available pods: 0
Dec  3 15:14:08.702: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:14:09.731: INFO: Number of nodes with available pods: 0
Dec  3 15:14:09.731: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:14:10.730: INFO: Number of nodes with available pods: 2
Dec  3 15:14:10.730: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec  3 15:14:10.781: INFO: Number of nodes with available pods: 1
Dec  3 15:14:10.781: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz is running more than one daemon pod
Dec  3 15:14:11.810: INFO: Number of nodes with available pods: 1
Dec  3 15:14:11.810: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz is running more than one daemon pod
Dec  3 15:14:12.810: INFO: Number of nodes with available pods: 1
Dec  3 15:14:12.810: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz is running more than one daemon pod
Dec  3 15:14:13.815: INFO: Number of nodes with available pods: 1
Dec  3 15:14:13.815: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz is running more than one daemon pod
Dec  3 15:14:14.810: INFO: Number of nodes with available pods: 1
Dec  3 15:14:14.810: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz is running more than one daemon pod
Dec  3 15:14:15.810: INFO: Number of nodes with available pods: 1
Dec  3 15:14:15.810: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz is running more than one daemon pod
Dec  3 15:14:16.810: INFO: Number of nodes with available pods: 1
Dec  3 15:14:16.810: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz is running more than one daemon pod
Dec  3 15:14:17.811: INFO: Number of nodes with available pods: 1
Dec  3 15:14:17.811: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz is running more than one daemon pod
Dec  3 15:14:18.810: INFO: Number of nodes with available pods: 1
Dec  3 15:14:18.810: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz is running more than one daemon pod
Dec  3 15:14:19.812: INFO: Number of nodes with available pods: 1
Dec  3 15:14:19.812: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz is running more than one daemon pod
Dec  3 15:14:20.810: INFO: Number of nodes with available pods: 1
Dec  3 15:14:20.810: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz is running more than one daemon pod
Dec  3 15:14:21.810: INFO: Number of nodes with available pods: 1
Dec  3 15:14:21.810: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz is running more than one daemon pod
Dec  3 15:14:22.810: INFO: Number of nodes with available pods: 1
Dec  3 15:14:22.810: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz is running more than one daemon pod
Dec  3 15:14:23.810: INFO: Number of nodes with available pods: 1
Dec  3 15:14:23.810: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz is running more than one daemon pod
Dec  3 15:14:24.809: INFO: Number of nodes with available pods: 1
Dec  3 15:14:24.809: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz is running more than one daemon pod
Dec  3 15:14:25.809: INFO: Number of nodes with available pods: 1
Dec  3 15:14:25.810: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz is running more than one daemon pod
Dec  3 15:14:26.810: INFO: Number of nodes with available pods: 2
Dec  3 15:14:26.810: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6649, will wait for the garbage collector to delete the pods
Dec  3 15:14:26.892: INFO: Deleting DaemonSet.extensions daemon-set took: 11.934736ms
Dec  3 15:14:27.392: INFO: Terminating DaemonSet.extensions daemon-set pods took: 500.606819ms
Dec  3 15:14:33.803: INFO: Number of nodes with available pods: 0
Dec  3 15:14:33.803: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 15:14:33.813: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6649/daemonsets","resourceVersion":"10255"},"items":null}

Dec  3 15:14:33.823: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6649/pods","resourceVersion":"10255"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:14:33.863: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6649" for this suite.
Dec  3 15:14:39.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:14:40.243: INFO: namespace daemonsets-6649 deletion completed in 6.369255183s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:14:40.243: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4012
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Dec  3 15:14:40.423: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-4012 -- logs-generator --log-lines-total 100 --run-duration 20s'
Dec  3 15:14:40.795: INFO: stderr: ""
Dec  3 15:14:40.795: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Dec  3 15:14:40.795: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Dec  3 15:14:40.796: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-4012" to be "running and ready, or succeeded"
Dec  3 15:14:40.805: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 9.556385ms
Dec  3 15:14:42.815: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 2.019746182s
Dec  3 15:14:42.815: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Dec  3 15:14:42.815: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Dec  3 15:14:42.815: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-4012'
Dec  3 15:14:42.948: INFO: stderr: ""
Dec  3 15:14:42.948: INFO: stdout: "I1203 15:14:41.718798       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/gq4r 319\nI1203 15:14:41.918736       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/869k 248\nI1203 15:14:42.118731       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/2z5r 559\nI1203 15:14:42.318713       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/6292 522\nI1203 15:14:42.518649       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/6xs9 378\nI1203 15:14:42.718795       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/wjn 510\nI1203 15:14:42.918689       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/7b9v 491\n"
STEP: limiting log lines
Dec  3 15:14:42.948: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-4012 --tail=1'
Dec  3 15:14:43.208: INFO: stderr: ""
Dec  3 15:14:43.208: INFO: stdout: "I1203 15:14:43.118708       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/km4 349\n"
STEP: limiting log bytes
Dec  3 15:14:43.208: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-4012 --limit-bytes=1'
Dec  3 15:14:43.334: INFO: stderr: ""
Dec  3 15:14:43.334: INFO: stdout: "I"
STEP: exposing timestamps
Dec  3 15:14:43.334: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-4012 --tail=1 --timestamps'
Dec  3 15:14:43.460: INFO: stderr: ""
Dec  3 15:14:43.460: INFO: stdout: "2019-12-03T15:14:43.318867758Z I1203 15:14:43.318679       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/5g4 246\n"
STEP: restricting to a time range
Dec  3 15:14:45.960: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-4012 --since=1s'
Dec  3 15:14:46.094: INFO: stderr: ""
Dec  3 15:14:46.094: INFO: stdout: "I1203 15:14:45.118716       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/45v 527\nI1203 15:14:45.318732       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/5zt 384\nI1203 15:14:45.518727       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/ccjb 406\nI1203 15:14:45.718771       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/qzb 217\nI1203 15:14:45.918731       1 logs_generator.go:76] 21 POST /api/v1/namespaces/ns/pods/tcws 223\n"
Dec  3 15:14:46.094: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config logs logs-generator logs-generator --namespace=kubectl-4012 --since=24h'
Dec  3 15:14:46.226: INFO: stderr: ""
Dec  3 15:14:46.226: INFO: stdout: "I1203 15:14:41.718798       1 logs_generator.go:76] 0 PUT /api/v1/namespaces/default/pods/gq4r 319\nI1203 15:14:41.918736       1 logs_generator.go:76] 1 POST /api/v1/namespaces/kube-system/pods/869k 248\nI1203 15:14:42.118731       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/2z5r 559\nI1203 15:14:42.318713       1 logs_generator.go:76] 3 PUT /api/v1/namespaces/kube-system/pods/6292 522\nI1203 15:14:42.518649       1 logs_generator.go:76] 4 GET /api/v1/namespaces/default/pods/6xs9 378\nI1203 15:14:42.718795       1 logs_generator.go:76] 5 GET /api/v1/namespaces/kube-system/pods/wjn 510\nI1203 15:14:42.918689       1 logs_generator.go:76] 6 POST /api/v1/namespaces/ns/pods/7b9v 491\nI1203 15:14:43.118708       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/km4 349\nI1203 15:14:43.318679       1 logs_generator.go:76] 8 GET /api/v1/namespaces/ns/pods/5g4 246\nI1203 15:14:43.518700       1 logs_generator.go:76] 9 PUT /api/v1/namespaces/default/pods/kvct 252\nI1203 15:14:43.718716       1 logs_generator.go:76] 10 GET /api/v1/namespaces/default/pods/sgx 243\nI1203 15:14:43.918677       1 logs_generator.go:76] 11 POST /api/v1/namespaces/ns/pods/7667 420\nI1203 15:14:44.118723       1 logs_generator.go:76] 12 PUT /api/v1/namespaces/kube-system/pods/rf6 392\nI1203 15:14:44.318817       1 logs_generator.go:76] 13 GET /api/v1/namespaces/kube-system/pods/hgt 532\nI1203 15:14:44.518710       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/default/pods/snmv 492\nI1203 15:14:44.718725       1 logs_generator.go:76] 15 GET /api/v1/namespaces/default/pods/pt5 581\nI1203 15:14:44.918739       1 logs_generator.go:76] 16 POST /api/v1/namespaces/default/pods/j8pk 477\nI1203 15:14:45.118716       1 logs_generator.go:76] 17 GET /api/v1/namespaces/ns/pods/45v 527\nI1203 15:14:45.318732       1 logs_generator.go:76] 18 POST /api/v1/namespaces/default/pods/5zt 384\nI1203 15:14:45.518727       1 logs_generator.go:76] 19 POST /api/v1/namespaces/ns/pods/ccjb 406\nI1203 15:14:45.718771       1 logs_generator.go:76] 20 PUT /api/v1/namespaces/ns/pods/qzb 217\nI1203 15:14:45.918731       1 logs_generator.go:76] 21 POST /api/v1/namespaces/ns/pods/tcws 223\nI1203 15:14:46.118707       1 logs_generator.go:76] 22 PUT /api/v1/namespaces/kube-system/pods/mdm7 469\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Dec  3 15:14:46.226: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pod logs-generator --namespace=kubectl-4012'
Dec  3 15:14:54.772: INFO: stderr: ""
Dec  3 15:14:54.773: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:14:54.773: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4012" for this suite.
Dec  3 15:15:00.824: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:15:01.159: INFO: namespace kubectl-4012 deletion completed in 6.36747774s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:15:01.160: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4418
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec  3 15:15:11.497: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:15:11.497: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
W1203 15:15:11.497169    5064 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
STEP: Destroying namespace "gc-4418" for this suite.
Dec  3 15:15:17.537: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:15:17.883: INFO: namespace gc-4418 deletion completed in 6.376106686s
•SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:15:17.884: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9813
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-9813
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 15:15:18.063: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 15:15:36.249: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.1.109:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9813 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:15:36.249: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:15:36.781: INFO: Found all expected endpoints: [netserver-0]
Dec  3 15:15:36.792: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://100.64.0.30:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-9813 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:15:36.792: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:15:37.219: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:15:37.219: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9813" for this suite.
Dec  3 15:15:49.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:15:49.599: INFO: namespace pod-network-test-9813 deletion completed in 12.361395631s
•S
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:15:49.599: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-337
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-337/secret-test-004922da-2859-4412-986a-b6f0d516eaf8
STEP: Creating a pod to test consume secrets
Dec  3 15:15:49.802: INFO: Waiting up to 5m0s for pod "pod-configmaps-cbceaa05-bc23-4864-991c-9727f973c3aa" in namespace "secrets-337" to be "success or failure"
Dec  3 15:15:49.812: INFO: Pod "pod-configmaps-cbceaa05-bc23-4864-991c-9727f973c3aa": Phase="Pending", Reason="", readiness=false. Elapsed: 9.388619ms
Dec  3 15:15:51.822: INFO: Pod "pod-configmaps-cbceaa05-bc23-4864-991c-9727f973c3aa": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020304471s
STEP: Saw pod success
Dec  3 15:15:51.823: INFO: Pod "pod-configmaps-cbceaa05-bc23-4864-991c-9727f973c3aa" satisfied condition "success or failure"
Dec  3 15:15:51.832: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-configmaps-cbceaa05-bc23-4864-991c-9727f973c3aa container env-test: <nil>
STEP: delete the pod
Dec  3 15:15:51.865: INFO: Waiting for pod pod-configmaps-cbceaa05-bc23-4864-991c-9727f973c3aa to disappear
Dec  3 15:15:51.875: INFO: Pod pod-configmaps-cbceaa05-bc23-4864-991c-9727f973c3aa no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:15:51.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-337" for this suite.
Dec  3 15:15:57.924: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:15:58.255: INFO: namespace secrets-337 deletion completed in 6.36134817s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:15:58.255: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4493
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:16:09.520: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4493" for this suite.
Dec  3 15:16:15.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:16:15.906: INFO: namespace resourcequota-4493 deletion completed in 6.368015654s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:16:15.907: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-6517
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-6517
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 15:16:16.084: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 15:16:40.257: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.113:8080/dial?request=hostName&protocol=udp&host=100.64.0.31&port=8081&tries=1'] Namespace:pod-network-test-6517 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:16:40.258: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:16:40.713: INFO: Waiting for endpoints: map[]
Dec  3 15:16:40.723: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.113:8080/dial?request=hostName&protocol=udp&host=100.64.1.112&port=8081&tries=1'] Namespace:pod-network-test-6517 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:16:40.723: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:16:41.256: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:16:41.256: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-6517" for this suite.
Dec  3 15:16:53.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:16:53.682: INFO: namespace pod-network-test-6517 deletion completed in 12.408054189s
•SSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:16:53.682: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-361
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:16:53.860: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Dec  3 15:16:54.930: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:16:54.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-361" for this suite.
Dec  3 15:17:00.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:17:01.334: INFO: namespace replication-controller-361 deletion completed in 6.374267582s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:17:01.335: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-9271
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:17:01.525: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-6bb5f4d1-a441-4580-8ddb-4e62fb655905" in namespace "security-context-test-9271" to be "success or failure"
Dec  3 15:17:01.537: INFO: Pod "busybox-readonly-false-6bb5f4d1-a441-4580-8ddb-4e62fb655905": Phase="Pending", Reason="", readiness=false. Elapsed: 12.178918ms
Dec  3 15:17:03.548: INFO: Pod "busybox-readonly-false-6bb5f4d1-a441-4580-8ddb-4e62fb655905": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022735037s
Dec  3 15:17:03.548: INFO: Pod "busybox-readonly-false-6bb5f4d1-a441-4580-8ddb-4e62fb655905" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:17:03.548: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-9271" for this suite.
Dec  3 15:17:09.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:17:09.973: INFO: namespace security-context-test-9271 deletion completed in 6.406354567s
•SSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:17:09.973: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9160
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec  3 15:17:10.167: INFO: Waiting up to 5m0s for pod "downward-api-5661ae24-bf49-40e6-ac37-94ce9556d4cd" in namespace "downward-api-9160" to be "success or failure"
Dec  3 15:17:10.176: INFO: Pod "downward-api-5661ae24-bf49-40e6-ac37-94ce9556d4cd": Phase="Pending", Reason="", readiness=false. Elapsed: 9.754497ms
Dec  3 15:17:12.187: INFO: Pod "downward-api-5661ae24-bf49-40e6-ac37-94ce9556d4cd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020414527s
STEP: Saw pod success
Dec  3 15:17:12.187: INFO: Pod "downward-api-5661ae24-bf49-40e6-ac37-94ce9556d4cd" satisfied condition "success or failure"
Dec  3 15:17:12.197: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downward-api-5661ae24-bf49-40e6-ac37-94ce9556d4cd container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:17:12.229: INFO: Waiting for pod downward-api-5661ae24-bf49-40e6-ac37-94ce9556d4cd to disappear
Dec  3 15:17:12.239: INFO: Pod downward-api-5661ae24-bf49-40e6-ac37-94ce9556d4cd no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:17:12.239: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9160" for this suite.
Dec  3 15:17:18.289: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:17:18.624: INFO: namespace downward-api-9160 deletion completed in 6.367168554s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:17:18.625: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4129
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec  3 15:17:18.806: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:17:22.247: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4129" for this suite.
Dec  3 15:17:28.298: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:17:28.631: INFO: namespace init-container-4129 deletion completed in 6.36378098s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:17:28.633: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6155
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-e74be3a9-a40c-4c15-adae-ee2364370ccb
STEP: Creating a pod to test consume configMaps
Dec  3 15:17:28.844: INFO: Waiting up to 5m0s for pod "pod-configmaps-94124528-2097-4897-9105-da190da9dada" in namespace "configmap-6155" to be "success or failure"
Dec  3 15:17:28.854: INFO: Pod "pod-configmaps-94124528-2097-4897-9105-da190da9dada": Phase="Pending", Reason="", readiness=false. Elapsed: 9.542357ms
Dec  3 15:17:30.864: INFO: Pod "pod-configmaps-94124528-2097-4897-9105-da190da9dada": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020107586s
STEP: Saw pod success
Dec  3 15:17:30.864: INFO: Pod "pod-configmaps-94124528-2097-4897-9105-da190da9dada" satisfied condition "success or failure"
Dec  3 15:17:30.874: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-configmaps-94124528-2097-4897-9105-da190da9dada container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:17:30.905: INFO: Waiting for pod pod-configmaps-94124528-2097-4897-9105-da190da9dada to disappear
Dec  3 15:17:30.914: INFO: Pod pod-configmaps-94124528-2097-4897-9105-da190da9dada no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:17:30.914: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6155" for this suite.
Dec  3 15:17:36.965: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:17:37.331: INFO: namespace configmap-6155 deletion completed in 6.399036454s
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:17:37.331: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6018
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:17:44.539: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6018" for this suite.
Dec  3 15:17:50.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:17:50.955: INFO: namespace resourcequota-6018 deletion completed in 6.398314408s
•
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:17:50.955: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1306
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec  3 15:17:51.249: INFO: Waiting up to 5m0s for pod "downward-api-06594fc4-7b78-4fa3-934c-5afafc3291f8" in namespace "downward-api-1306" to be "success or failure"
Dec  3 15:17:51.259: INFO: Pod "downward-api-06594fc4-7b78-4fa3-934c-5afafc3291f8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.560834ms
Dec  3 15:17:53.270: INFO: Pod "downward-api-06594fc4-7b78-4fa3-934c-5afafc3291f8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019985502s
STEP: Saw pod success
Dec  3 15:17:53.270: INFO: Pod "downward-api-06594fc4-7b78-4fa3-934c-5afafc3291f8" satisfied condition "success or failure"
Dec  3 15:17:53.280: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downward-api-06594fc4-7b78-4fa3-934c-5afafc3291f8 container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:17:53.311: INFO: Waiting for pod downward-api-06594fc4-7b78-4fa3-934c-5afafc3291f8 to disappear
Dec  3 15:17:53.321: INFO: Pod downward-api-06594fc4-7b78-4fa3-934c-5afafc3291f8 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:17:53.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1306" for this suite.
Dec  3 15:17:59.371: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:17:59.743: INFO: namespace downward-api-1306 deletion completed in 6.403454789s
•SSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:17:59.745: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1789
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:18:01.997: INFO: Waiting up to 5m0s for pod "client-envvars-49283626-6969-4e95-a164-70c17ef5f031" in namespace "pods-1789" to be "success or failure"
Dec  3 15:18:02.007: INFO: Pod "client-envvars-49283626-6969-4e95-a164-70c17ef5f031": Phase="Pending", Reason="", readiness=false. Elapsed: 9.628868ms
Dec  3 15:18:04.017: INFO: Pod "client-envvars-49283626-6969-4e95-a164-70c17ef5f031": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020097425s
STEP: Saw pod success
Dec  3 15:18:04.017: INFO: Pod "client-envvars-49283626-6969-4e95-a164-70c17ef5f031" satisfied condition "success or failure"
Dec  3 15:18:04.027: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod client-envvars-49283626-6969-4e95-a164-70c17ef5f031 container env3cont: <nil>
STEP: delete the pod
Dec  3 15:18:04.059: INFO: Waiting for pod client-envvars-49283626-6969-4e95-a164-70c17ef5f031 to disappear
Dec  3 15:18:04.069: INFO: Pod client-envvars-49283626-6969-4e95-a164-70c17ef5f031 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:18:04.069: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1789" for this suite.
Dec  3 15:18:16.119: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:18:16.450: INFO: namespace pods-1789 deletion completed in 12.362983346s
•SSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:18:16.450: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-220
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:18:16.626: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:18:17.184: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-220" for this suite.
Dec  3 15:18:23.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:18:23.606: INFO: namespace custom-resource-definition-220 deletion completed in 6.403897521s
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:18:23.607: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-5747
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-55584e5f-40ec-4cba-903b-2e675d147d09
STEP: Creating secret with name s-test-opt-upd-56597a6a-19a2-4090-8e7c-bc3c9c43f1c3
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-55584e5f-40ec-4cba-903b-2e675d147d09
STEP: Updating secret s-test-opt-upd-56597a6a-19a2-4090-8e7c-bc3c9c43f1c3
STEP: Creating secret with name s-test-opt-create-4a425b78-4863-4cfc-96c9-ff88a4269a72
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:18:28.204: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-5747" for this suite.
W1203 15:18:31.460086    5064 reflector.go:299] k8s.io/kubernetes/test/e2e/scheduling/taints.go:146: watch of *v1.Pod ended with: too old resource version: 10640 (10829)
Dec  3 15:18:40.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:18:40.655: INFO: namespace secrets-5747 deletion completed in 12.432152822s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:18:40.655: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-600
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-600.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-600.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-600.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-600.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:18:43.072: INFO: DNS probes using dns-test-de95d24e-e657-496e-a096-7f53f9b9a464 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-600.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-600.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-600.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-600.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:18:45.248: INFO: File wheezy_udp@dns-test-service-3.dns-600.svc.cluster.local from pod  dns-600/dns-test-85bf58f2-07db-4322-8a72-3ca0251b80b4 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:18:45.332: INFO: File jessie_udp@dns-test-service-3.dns-600.svc.cluster.local from pod  dns-600/dns-test-85bf58f2-07db-4322-8a72-3ca0251b80b4 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:18:45.332: INFO: Lookups using dns-600/dns-test-85bf58f2-07db-4322-8a72-3ca0251b80b4 failed for: [wheezy_udp@dns-test-service-3.dns-600.svc.cluster.local jessie_udp@dns-test-service-3.dns-600.svc.cluster.local]

Dec  3 15:18:50.345: INFO: File wheezy_udp@dns-test-service-3.dns-600.svc.cluster.local from pod  dns-600/dns-test-85bf58f2-07db-4322-8a72-3ca0251b80b4 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:18:50.388: INFO: File jessie_udp@dns-test-service-3.dns-600.svc.cluster.local from pod  dns-600/dns-test-85bf58f2-07db-4322-8a72-3ca0251b80b4 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:18:50.388: INFO: Lookups using dns-600/dns-test-85bf58f2-07db-4322-8a72-3ca0251b80b4 failed for: [wheezy_udp@dns-test-service-3.dns-600.svc.cluster.local jessie_udp@dns-test-service-3.dns-600.svc.cluster.local]

Dec  3 15:18:55.386: INFO: File wheezy_udp@dns-test-service-3.dns-600.svc.cluster.local from pod  dns-600/dns-test-85bf58f2-07db-4322-8a72-3ca0251b80b4 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:18:55.429: INFO: File jessie_udp@dns-test-service-3.dns-600.svc.cluster.local from pod  dns-600/dns-test-85bf58f2-07db-4322-8a72-3ca0251b80b4 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:18:55.429: INFO: Lookups using dns-600/dns-test-85bf58f2-07db-4322-8a72-3ca0251b80b4 failed for: [wheezy_udp@dns-test-service-3.dns-600.svc.cluster.local jessie_udp@dns-test-service-3.dns-600.svc.cluster.local]

Dec  3 15:19:00.386: INFO: File wheezy_udp@dns-test-service-3.dns-600.svc.cluster.local from pod  dns-600/dns-test-85bf58f2-07db-4322-8a72-3ca0251b80b4 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:19:00.429: INFO: File jessie_udp@dns-test-service-3.dns-600.svc.cluster.local from pod  dns-600/dns-test-85bf58f2-07db-4322-8a72-3ca0251b80b4 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:19:00.429: INFO: Lookups using dns-600/dns-test-85bf58f2-07db-4322-8a72-3ca0251b80b4 failed for: [wheezy_udp@dns-test-service-3.dns-600.svc.cluster.local jessie_udp@dns-test-service-3.dns-600.svc.cluster.local]

Dec  3 15:19:05.386: INFO: File wheezy_udp@dns-test-service-3.dns-600.svc.cluster.local from pod  dns-600/dns-test-85bf58f2-07db-4322-8a72-3ca0251b80b4 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:19:05.429: INFO: File jessie_udp@dns-test-service-3.dns-600.svc.cluster.local from pod  dns-600/dns-test-85bf58f2-07db-4322-8a72-3ca0251b80b4 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:19:05.429: INFO: Lookups using dns-600/dns-test-85bf58f2-07db-4322-8a72-3ca0251b80b4 failed for: [wheezy_udp@dns-test-service-3.dns-600.svc.cluster.local jessie_udp@dns-test-service-3.dns-600.svc.cluster.local]

Dec  3 15:19:10.346: INFO: File wheezy_udp@dns-test-service-3.dns-600.svc.cluster.local from pod  dns-600/dns-test-85bf58f2-07db-4322-8a72-3ca0251b80b4 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:19:10.430: INFO: File jessie_udp@dns-test-service-3.dns-600.svc.cluster.local from pod  dns-600/dns-test-85bf58f2-07db-4322-8a72-3ca0251b80b4 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec  3 15:19:10.430: INFO: Lookups using dns-600/dns-test-85bf58f2-07db-4322-8a72-3ca0251b80b4 failed for: [wheezy_udp@dns-test-service-3.dns-600.svc.cluster.local jessie_udp@dns-test-service-3.dns-600.svc.cluster.local]

Dec  3 15:19:15.429: INFO: DNS probes using dns-test-85bf58f2-07db-4322-8a72-3ca0251b80b4 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-600.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-600.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-600.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-600.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:19:17.712: INFO: DNS probes using dns-test-2aa8e25d-6800-4b8f-81b8-64663e78bb76 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:19:17.744: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-600" for this suite.
Dec  3 15:19:23.796: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:19:24.185: INFO: namespace dns-600 deletion completed in 6.4224563s
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:19:24.186: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6039
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-050b3096-c3d3-4d58-8c80-a7afaade281f
STEP: Creating a pod to test consume configMaps
Dec  3 15:19:24.392: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-63937df3-7605-46d2-8f9f-02cb1c6935fb" in namespace "projected-6039" to be "success or failure"
Dec  3 15:19:24.402: INFO: Pod "pod-projected-configmaps-63937df3-7605-46d2-8f9f-02cb1c6935fb": Phase="Pending", Reason="", readiness=false. Elapsed: 9.948065ms
Dec  3 15:19:26.413: INFO: Pod "pod-projected-configmaps-63937df3-7605-46d2-8f9f-02cb1c6935fb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020785876s
STEP: Saw pod success
Dec  3 15:19:26.413: INFO: Pod "pod-projected-configmaps-63937df3-7605-46d2-8f9f-02cb1c6935fb" satisfied condition "success or failure"
Dec  3 15:19:26.424: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-projected-configmaps-63937df3-7605-46d2-8f9f-02cb1c6935fb container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:19:26.585: INFO: Waiting for pod pod-projected-configmaps-63937df3-7605-46d2-8f9f-02cb1c6935fb to disappear
Dec  3 15:19:26.595: INFO: Pod pod-projected-configmaps-63937df3-7605-46d2-8f9f-02cb1c6935fb no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:19:26.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6039" for this suite.
Dec  3 15:19:32.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:19:33.007: INFO: namespace projected-6039 deletion completed in 6.393709792s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:19:33.008: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-1829
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Dec  3 15:19:33.193: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Dec  3 15:19:33.968: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-apiserver-deployment-8447597c78\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:19:35.978: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:19:37.978: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:19:39.978: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:19:41.978: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:19:43.978: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983173, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:19:47.492: INFO: Waited 1.501703105s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:19:48.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1829" for this suite.
Dec  3 15:19:54.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:19:54.737: INFO: namespace aggregator-1829 deletion completed in 6.38808654s
•SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:19:54.738: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-443
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec  3 15:19:55.482: INFO: Pod name wrapped-volume-race-2bb655bc-3458-4254-bf27-069307ef599e: Found 1 pods out of 5
Dec  3 15:20:00.506: INFO: Pod name wrapped-volume-race-2bb655bc-3458-4254-bf27-069307ef599e: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-2bb655bc-3458-4254-bf27-069307ef599e in namespace emptydir-wrapper-443, will wait for the garbage collector to delete the pods
Dec  3 15:20:08.659: INFO: Deleting ReplicationController wrapped-volume-race-2bb655bc-3458-4254-bf27-069307ef599e took: 13.745162ms
Dec  3 15:20:08.759: INFO: Terminating ReplicationController wrapped-volume-race-2bb655bc-3458-4254-bf27-069307ef599e pods took: 100.3187ms
STEP: Creating RC which spawns configmap-volume pods
Dec  3 15:20:53.897: INFO: Pod name wrapped-volume-race-9492c3b5-3a85-4fba-afb7-dcdb6c0d4198: Found 1 pods out of 5
Dec  3 15:20:58.918: INFO: Pod name wrapped-volume-race-9492c3b5-3a85-4fba-afb7-dcdb6c0d4198: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-9492c3b5-3a85-4fba-afb7-dcdb6c0d4198 in namespace emptydir-wrapper-443, will wait for the garbage collector to delete the pods
Dec  3 15:20:59.045: INFO: Deleting ReplicationController wrapped-volume-race-9492c3b5-3a85-4fba-afb7-dcdb6c0d4198 took: 13.211052ms
Dec  3 15:20:59.445: INFO: Terminating ReplicationController wrapped-volume-race-9492c3b5-3a85-4fba-afb7-dcdb6c0d4198 pods took: 400.438803ms
STEP: Creating RC which spawns configmap-volume pods
Dec  3 15:21:43.884: INFO: Pod name wrapped-volume-race-0fd9aa83-bd61-4506-b96d-6c01e92a6a2e: Found 1 pods out of 5
Dec  3 15:21:48.904: INFO: Pod name wrapped-volume-race-0fd9aa83-bd61-4506-b96d-6c01e92a6a2e: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-0fd9aa83-bd61-4506-b96d-6c01e92a6a2e in namespace emptydir-wrapper-443, will wait for the garbage collector to delete the pods
Dec  3 15:21:49.033: INFO: Deleting ReplicationController wrapped-volume-race-0fd9aa83-bd61-4506-b96d-6c01e92a6a2e took: 13.615023ms
Dec  3 15:21:49.434: INFO: Terminating ReplicationController wrapped-volume-race-0fd9aa83-bd61-4506-b96d-6c01e92a6a2e pods took: 400.348829ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:22:34.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-443" for this suite.
Dec  3 15:22:40.598: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:22:40.993: INFO: namespace emptydir-wrapper-443 deletion completed in 6.427166635s
•SS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:22:40.994: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3770
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec  3 15:22:41.182: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-3770'
Dec  3 15:22:41.457: INFO: stderr: ""
Dec  3 15:22:41.458: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec  3 15:22:42.469: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:22:42.469: INFO: Found 0 / 1
Dec  3 15:22:43.469: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:22:43.469: INFO: Found 1 / 1
Dec  3 15:22:43.469: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec  3 15:22:43.479: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:22:43.479: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec  3 15:22:43.479: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config patch pod redis-master-4nxmw --namespace=kubectl-3770 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec  3 15:22:43.596: INFO: stderr: ""
Dec  3 15:22:43.596: INFO: stdout: "pod/redis-master-4nxmw patched\n"
STEP: checking annotations
Dec  3 15:22:43.606: INFO: Selector matched 1 pods for map[app:redis]
Dec  3 15:22:43.606: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:22:43.606: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3770" for this suite.
Dec  3 15:23:11.657: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:23:12.047: INFO: namespace kubectl-3770 deletion completed in 28.421882285s
•SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:23:12.047: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-3951
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:23:12.231: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:23:12.321: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3951" for this suite.
Dec  3 15:23:18.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:23:18.719: INFO: namespace custom-resource-definition-3951 deletion completed in 6.3874946s
•SSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:23:18.719: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5049
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:23:18.917: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9c553f0d-1a99-4b2f-976b-1e5e4654c85e" in namespace "projected-5049" to be "success or failure"
Dec  3 15:23:18.928: INFO: Pod "downwardapi-volume-9c553f0d-1a99-4b2f-976b-1e5e4654c85e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.211004ms
Dec  3 15:23:20.939: INFO: Pod "downwardapi-volume-9c553f0d-1a99-4b2f-976b-1e5e4654c85e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021950218s
STEP: Saw pod success
Dec  3 15:23:20.939: INFO: Pod "downwardapi-volume-9c553f0d-1a99-4b2f-976b-1e5e4654c85e" satisfied condition "success or failure"
Dec  3 15:23:20.950: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downwardapi-volume-9c553f0d-1a99-4b2f-976b-1e5e4654c85e container client-container: <nil>
STEP: delete the pod
Dec  3 15:23:21.111: INFO: Waiting for pod downwardapi-volume-9c553f0d-1a99-4b2f-976b-1e5e4654c85e to disappear
Dec  3 15:23:21.122: INFO: Pod downwardapi-volume-9c553f0d-1a99-4b2f-976b-1e5e4654c85e no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:23:21.122: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5049" for this suite.
Dec  3 15:23:27.173: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:23:27.527: INFO: namespace projected-5049 deletion completed in 6.386467684s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:23:27.528: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1563
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Dec  3 15:24:07.798: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W1203 15:24:07.798039    5064 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  3 15:24:07.798: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1563" for this suite.
Dec  3 15:24:13.841: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:24:14.199: INFO: namespace gc-1563 deletion completed in 6.39019304s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:24:14.199: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6252
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:24:18.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6252" for this suite.
Dec  3 15:25:02.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:25:02.865: INFO: namespace kubelet-test-6252 deletion completed in 44.394552952s
•SSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:25:02.865: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4525
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Dec  3 15:25:05.114: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec pod-sharedvolume-031d649c-6982-4f9a-8951-936c723f4ed7 -c busybox-main-container --namespace=emptydir-4525 -- cat /usr/share/volumeshare/shareddata.txt'
Dec  3 15:25:05.925: INFO: stderr: ""
Dec  3 15:25:05.925: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:25:05.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4525" for this suite.
Dec  3 15:25:11.977: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:25:12.333: INFO: namespace emptydir-4525 deletion completed in 6.388465761s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:25:12.334: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6057
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6057
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-6057
Dec  3 15:25:12.549: INFO: Found 0 stateful pods, waiting for 1
Dec  3 15:25:22.561: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  3 15:25:22.616: INFO: Deleting all statefulset in ns statefulset-6057
Dec  3 15:25:22.626: INFO: Scaling statefulset ss to 0
Dec  3 15:25:32.669: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:25:32.680: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:25:32.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6057" for this suite.
Dec  3 15:25:38.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:25:39.125: INFO: namespace statefulset-6057 deletion completed in 6.389613524s
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:25:39.125: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-3639
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-745878e5-ba18-489a-b295-b4a2c0514477
Dec  3 15:25:39.339: INFO: Pod name my-hostname-basic-745878e5-ba18-489a-b295-b4a2c0514477: Found 1 pods out of 1
Dec  3 15:25:39.339: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-745878e5-ba18-489a-b295-b4a2c0514477" are running
Dec  3 15:25:41.360: INFO: Pod "my-hostname-basic-745878e5-ba18-489a-b295-b4a2c0514477-lf9c7" is running (conditions: [{Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-03 15:25:39 +0000 UTC Reason: Message:}])
Dec  3 15:25:41.360: INFO: Trying to dial the pod
Dec  3 15:25:46.477: INFO: Controller my-hostname-basic-745878e5-ba18-489a-b295-b4a2c0514477: Got expected result from replica 1 [my-hostname-basic-745878e5-ba18-489a-b295-b4a2c0514477-lf9c7]: "my-hostname-basic-745878e5-ba18-489a-b295-b4a2c0514477-lf9c7", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:25:46.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-3639" for this suite.
Dec  3 15:25:52.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:25:52.893: INFO: namespace replication-controller-3639 deletion completed in 6.396615449s
•SSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:25:52.893: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-1919
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec  3 15:25:57.656: INFO: Successfully updated pod "pod-update-activedeadlineseconds-8b91ef5a-0890-4c15-8a87-2d5699d17ed0"
Dec  3 15:25:57.656: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-8b91ef5a-0890-4c15-8a87-2d5699d17ed0" in namespace "pods-1919" to be "terminated due to deadline exceeded"
Dec  3 15:25:57.666: INFO: Pod "pod-update-activedeadlineseconds-8b91ef5a-0890-4c15-8a87-2d5699d17ed0": Phase="Running", Reason="", readiness=true. Elapsed: 9.864251ms
Dec  3 15:25:59.677: INFO: Pod "pod-update-activedeadlineseconds-8b91ef5a-0890-4c15-8a87-2d5699d17ed0": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 2.020497849s
Dec  3 15:25:59.677: INFO: Pod "pod-update-activedeadlineseconds-8b91ef5a-0890-4c15-8a87-2d5699d17ed0" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:25:59.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-1919" for this suite.
Dec  3 15:26:05.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:26:06.084: INFO: namespace pods-1919 deletion completed in 6.388803233s
•SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:26:06.085: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6858
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-ae1a2e38-f1f2-43f6-9982-6b44d4cdd409
STEP: Creating a pod to test consume configMaps
Dec  3 15:26:06.290: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-079f2bb7-3c2f-456d-9853-fe9239470c8e" in namespace "projected-6858" to be "success or failure"
Dec  3 15:26:06.300: INFO: Pod "pod-projected-configmaps-079f2bb7-3c2f-456d-9853-fe9239470c8e": Phase="Pending", Reason="", readiness=false. Elapsed: 10.053881ms
Dec  3 15:26:08.312: INFO: Pod "pod-projected-configmaps-079f2bb7-3c2f-456d-9853-fe9239470c8e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021319623s
STEP: Saw pod success
Dec  3 15:26:08.312: INFO: Pod "pod-projected-configmaps-079f2bb7-3c2f-456d-9853-fe9239470c8e" satisfied condition "success or failure"
Dec  3 15:26:08.322: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-projected-configmaps-079f2bb7-3c2f-456d-9853-fe9239470c8e container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:26:08.484: INFO: Waiting for pod pod-projected-configmaps-079f2bb7-3c2f-456d-9853-fe9239470c8e to disappear
Dec  3 15:26:08.494: INFO: Pod pod-projected-configmaps-079f2bb7-3c2f-456d-9853-fe9239470c8e no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:26:08.494: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6858" for this suite.
Dec  3 15:26:14.545: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:26:14.931: INFO: namespace projected-6858 deletion completed in 6.417435043s
•SSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:26:14.931: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6679
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec  3 15:26:15.127: INFO: Waiting up to 5m0s for pod "pod-d6d9712b-bd3e-46ca-b528-c5fb5d972a46" in namespace "emptydir-6679" to be "success or failure"
Dec  3 15:26:15.137: INFO: Pod "pod-d6d9712b-bd3e-46ca-b528-c5fb5d972a46": Phase="Pending", Reason="", readiness=false. Elapsed: 9.937963ms
Dec  3 15:26:17.148: INFO: Pod "pod-d6d9712b-bd3e-46ca-b528-c5fb5d972a46": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02090582s
STEP: Saw pod success
Dec  3 15:26:17.148: INFO: Pod "pod-d6d9712b-bd3e-46ca-b528-c5fb5d972a46" satisfied condition "success or failure"
Dec  3 15:26:17.159: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-d6d9712b-bd3e-46ca-b528-c5fb5d972a46 container test-container: <nil>
STEP: delete the pod
Dec  3 15:26:17.190: INFO: Waiting for pod pod-d6d9712b-bd3e-46ca-b528-c5fb5d972a46 to disappear
Dec  3 15:26:17.200: INFO: Pod pod-d6d9712b-bd3e-46ca-b528-c5fb5d972a46 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:26:17.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6679" for this suite.
Dec  3 15:26:23.253: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:26:23.606: INFO: namespace emptydir-6679 deletion completed in 6.385420429s
•SS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:26:23.606: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-59
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:26:23.803: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-d6f90e23-5dcb-498a-a054-49831aa033cb" in namespace "security-context-test-59" to be "success or failure"
Dec  3 15:26:23.813: INFO: Pod "alpine-nnp-false-d6f90e23-5dcb-498a-a054-49831aa033cb": Phase="Pending", Reason="", readiness=false. Elapsed: 10.235695ms
Dec  3 15:26:25.824: INFO: Pod "alpine-nnp-false-d6f90e23-5dcb-498a-a054-49831aa033cb": Phase="Pending", Reason="", readiness=false. Elapsed: 2.02120011s
Dec  3 15:26:27.835: INFO: Pod "alpine-nnp-false-d6f90e23-5dcb-498a-a054-49831aa033cb": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.032091111s
Dec  3 15:26:27.835: INFO: Pod "alpine-nnp-false-d6f90e23-5dcb-498a-a054-49831aa033cb" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:26:27.854: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-59" for this suite.
Dec  3 15:26:33.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:26:34.258: INFO: namespace security-context-test-59 deletion completed in 6.385660457s
•
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:26:34.258: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2848
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-a2a21461-2678-49a1-acf2-5c73d90854cc
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:26:34.452: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2848" for this suite.
Dec  3 15:26:40.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:26:40.839: INFO: namespace configmap-2848 deletion completed in 6.376187806s
•SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:26:40.839: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4599
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:26:41.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4599" for this suite.
Dec  3 15:26:47.130: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:26:47.477: INFO: namespace resourcequota-4599 deletion completed in 6.378038526s
•SSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:26:47.478: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-5391
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:26:47.687: INFO: (0) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 14.42119ms)
Dec  3 15:26:47.729: INFO: (1) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 42.001632ms)
Dec  3 15:26:47.742: INFO: (2) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.830414ms)
Dec  3 15:26:47.755: INFO: (3) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.554262ms)
Dec  3 15:26:47.767: INFO: (4) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.227677ms)
Dec  3 15:26:47.779: INFO: (5) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.016342ms)
Dec  3 15:26:47.791: INFO: (6) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.90959ms)
Dec  3 15:26:47.803: INFO: (7) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.06724ms)
Dec  3 15:26:47.816: INFO: (8) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.092788ms)
Dec  3 15:26:47.828: INFO: (9) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.124563ms)
Dec  3 15:26:47.840: INFO: (10) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.294308ms)
Dec  3 15:26:47.852: INFO: (11) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.915802ms)
Dec  3 15:26:47.865: INFO: (12) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.584657ms)
Dec  3 15:26:47.876: INFO: (13) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.483229ms)
Dec  3 15:26:47.889: INFO: (14) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.089227ms)
Dec  3 15:26:47.902: INFO: (15) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.917641ms)
Dec  3 15:26:47.916: INFO: (16) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 14.26857ms)
Dec  3 15:26:47.928: INFO: (17) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.642064ms)
Dec  3 15:26:47.940: INFO: (18) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.059069ms)
Dec  3 15:26:47.952: INFO: (19) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6:10250/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.299608ms)
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:26:47.952: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5391" for this suite.
Dec  3 15:26:53.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:26:54.394: INFO: namespace proxy-5391 deletion completed in 6.431031873s
•SSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:26:54.394: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-655
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:26:55.196: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983615, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983615, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983615, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983615, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:26:57.207: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983615, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983615, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983615, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983615, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:27:00.224: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:27:00.235: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-5450-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:27:01.117: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-655" for this suite.
Dec  3 15:27:07.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:27:07.520: INFO: namespace webhook-655 deletion completed in 6.384423274s
STEP: Destroying namespace "webhook-655-markers" for this suite.
Dec  3 15:27:13.553: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:27:13.901: INFO: namespace webhook-655-markers deletion completed in 6.380780626s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•S
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:27:13.943: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2702
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:27:16.194: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2702" for this suite.
Dec  3 15:27:28.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:27:28.600: INFO: namespace replication-controller-2702 deletion completed in 12.387523278s
•SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:27:28.600: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-9536
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:27:30.851: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-9536" for this suite.
Dec  3 15:28:16.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:28:17.262: INFO: namespace kubelet-test-9536 deletion completed in 46.390904294s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:28:17.263: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-193
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-57cfecb6-0d8c-4ac5-8dc3-09837bf7f348
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:28:17.454: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-193" for this suite.
Dec  3 15:28:23.496: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:28:23.856: INFO: namespace secrets-193 deletion completed in 6.39188662s
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:28:23.857: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-309
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec  3 15:28:24.052: INFO: Waiting up to 5m0s for pod "pod-2c539bf9-b56d-44cd-a82a-8ecaf655d778" in namespace "emptydir-309" to be "success or failure"
Dec  3 15:28:24.062: INFO: Pod "pod-2c539bf9-b56d-44cd-a82a-8ecaf655d778": Phase="Pending", Reason="", readiness=false. Elapsed: 10.116815ms
Dec  3 15:28:26.074: INFO: Pod "pod-2c539bf9-b56d-44cd-a82a-8ecaf655d778": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021356116s
STEP: Saw pod success
Dec  3 15:28:26.074: INFO: Pod "pod-2c539bf9-b56d-44cd-a82a-8ecaf655d778" satisfied condition "success or failure"
Dec  3 15:28:26.084: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-2c539bf9-b56d-44cd-a82a-8ecaf655d778 container test-container: <nil>
STEP: delete the pod
Dec  3 15:28:26.117: INFO: Waiting for pod pod-2c539bf9-b56d-44cd-a82a-8ecaf655d778 to disappear
Dec  3 15:28:26.127: INFO: Pod pod-2c539bf9-b56d-44cd-a82a-8ecaf655d778 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:28:26.127: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-309" for this suite.
Dec  3 15:28:32.178: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:28:32.532: INFO: namespace emptydir-309 deletion completed in 6.386536574s
•SSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:28:32.533: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2194
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-4kmf
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 15:28:32.754: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-4kmf" in namespace "subpath-2194" to be "success or failure"
Dec  3 15:28:32.764: INFO: Pod "pod-subpath-test-projected-4kmf": Phase="Pending", Reason="", readiness=false. Elapsed: 9.912919ms
Dec  3 15:28:34.775: INFO: Pod "pod-subpath-test-projected-4kmf": Phase="Running", Reason="", readiness=true. Elapsed: 2.02169898s
Dec  3 15:28:36.786: INFO: Pod "pod-subpath-test-projected-4kmf": Phase="Running", Reason="", readiness=true. Elapsed: 4.032681136s
Dec  3 15:28:38.797: INFO: Pod "pod-subpath-test-projected-4kmf": Phase="Running", Reason="", readiness=true. Elapsed: 6.043648808s
Dec  3 15:28:40.808: INFO: Pod "pod-subpath-test-projected-4kmf": Phase="Running", Reason="", readiness=true. Elapsed: 8.054518444s
Dec  3 15:28:42.818: INFO: Pod "pod-subpath-test-projected-4kmf": Phase="Running", Reason="", readiness=true. Elapsed: 10.064566976s
Dec  3 15:28:44.829: INFO: Pod "pod-subpath-test-projected-4kmf": Phase="Running", Reason="", readiness=true. Elapsed: 12.075220054s
Dec  3 15:28:46.839: INFO: Pod "pod-subpath-test-projected-4kmf": Phase="Running", Reason="", readiness=true. Elapsed: 14.08581081s
Dec  3 15:28:48.850: INFO: Pod "pod-subpath-test-projected-4kmf": Phase="Running", Reason="", readiness=true. Elapsed: 16.096336967s
Dec  3 15:28:50.861: INFO: Pod "pod-subpath-test-projected-4kmf": Phase="Running", Reason="", readiness=true. Elapsed: 18.107458399s
Dec  3 15:28:52.872: INFO: Pod "pod-subpath-test-projected-4kmf": Phase="Running", Reason="", readiness=true. Elapsed: 20.118330913s
Dec  3 15:28:54.883: INFO: Pod "pod-subpath-test-projected-4kmf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.129074395s
STEP: Saw pod success
Dec  3 15:28:54.883: INFO: Pod "pod-subpath-test-projected-4kmf" satisfied condition "success or failure"
Dec  3 15:28:54.893: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-subpath-test-projected-4kmf container test-container-subpath-projected-4kmf: <nil>
STEP: delete the pod
Dec  3 15:28:54.924: INFO: Waiting for pod pod-subpath-test-projected-4kmf to disappear
Dec  3 15:28:54.935: INFO: Pod pod-subpath-test-projected-4kmf no longer exists
STEP: Deleting pod pod-subpath-test-projected-4kmf
Dec  3 15:28:54.935: INFO: Deleting pod "pod-subpath-test-projected-4kmf" in namespace "subpath-2194"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:28:54.945: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2194" for this suite.
Dec  3 15:29:00.995: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:29:01.390: INFO: namespace subpath-2194 deletion completed in 6.425817082s
•SSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:29:01.390: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-1106
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec  3 15:29:01.571: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:29:05.432: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-1106" for this suite.
Dec  3 15:29:17.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:29:17.841: INFO: namespace init-container-1106 deletion completed in 12.389648012s
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:29:17.842: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3019
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Dec  3 15:29:18.025: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config api-versions'
Dec  3 15:29:18.152: INFO: stderr: ""
Dec  3 15:29:18.152: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncert.gardener.cloud/v1alpha1\ncertificates.k8s.io/v1beta1\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ncrd.projectcalico.org/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nmetrics.k8s.io/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:29:18.152: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3019" for this suite.
Dec  3 15:29:24.196: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:29:24.590: INFO: namespace kubectl-3019 deletion completed in 6.426593464s
•SSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:29:24.591: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9211
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-9211/configmap-test-ebd818d5-a15b-41e7-8873-f75256083587
STEP: Creating a pod to test consume configMaps
Dec  3 15:29:24.802: INFO: Waiting up to 5m0s for pod "pod-configmaps-7cb6454d-d4fc-465b-8c2a-b95f109b8550" in namespace "configmap-9211" to be "success or failure"
Dec  3 15:29:24.812: INFO: Pod "pod-configmaps-7cb6454d-d4fc-465b-8c2a-b95f109b8550": Phase="Pending", Reason="", readiness=false. Elapsed: 10.069047ms
Dec  3 15:29:26.823: INFO: Pod "pod-configmaps-7cb6454d-d4fc-465b-8c2a-b95f109b8550": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020881757s
STEP: Saw pod success
Dec  3 15:29:26.823: INFO: Pod "pod-configmaps-7cb6454d-d4fc-465b-8c2a-b95f109b8550" satisfied condition "success or failure"
Dec  3 15:29:26.833: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-configmaps-7cb6454d-d4fc-465b-8c2a-b95f109b8550 container env-test: <nil>
STEP: delete the pod
Dec  3 15:29:26.869: INFO: Waiting for pod pod-configmaps-7cb6454d-d4fc-465b-8c2a-b95f109b8550 to disappear
Dec  3 15:29:26.879: INFO: Pod pod-configmaps-7cb6454d-d4fc-465b-8c2a-b95f109b8550 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:29:26.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9211" for this suite.
Dec  3 15:29:32.932: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:29:33.283: INFO: namespace configmap-9211 deletion completed in 6.385395231s
•SSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:29:33.284: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6401
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Dec  3 15:29:33.467: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=kubectl-6401 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec  3 15:29:35.550: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec  3 15:29:35.551: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:29:37.571: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6401" for this suite.
Dec  3 15:29:43.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:29:43.969: INFO: namespace kubectl-6401 deletion completed in 6.379223301s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:29:43.970: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-636
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:29:44.398: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983784, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983784, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983784, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983784, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:29:46.409: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983784, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983784, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983784, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710983784, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:29:49.426: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:29:49.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-636" for this suite.
Dec  3 15:29:55.835: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:29:56.190: INFO: namespace webhook-636 deletion completed in 6.388114517s
STEP: Destroying namespace "webhook-636-markers" for this suite.
Dec  3 15:30:02.222: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:30:02.580: INFO: namespace webhook-636-markers deletion completed in 6.3895472s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:30:02.623: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3769
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Dec  3 15:30:02.805: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-3769'
Dec  3 15:30:03.079: INFO: stderr: ""
Dec  3 15:30:03.079: INFO: stdout: "pod/pause created\n"
Dec  3 15:30:03.079: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec  3 15:30:03.079: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-3769" to be "running and ready"
Dec  3 15:30:03.089: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 10.239556ms
Dec  3 15:30:05.100: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 2.020639971s
Dec  3 15:30:05.100: INFO: Pod "pause" satisfied condition "running and ready"
Dec  3 15:30:05.100: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Dec  3 15:30:05.100: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config label pods pause testing-label=testing-label-value --namespace=kubectl-3769'
Dec  3 15:30:05.227: INFO: stderr: ""
Dec  3 15:30:05.227: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec  3 15:30:05.227: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod pause -L testing-label --namespace=kubectl-3769'
Dec  3 15:30:05.339: INFO: stderr: ""
Dec  3 15:30:05.339: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec  3 15:30:05.339: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config label pods pause testing-label- --namespace=kubectl-3769'
Dec  3 15:30:05.475: INFO: stderr: ""
Dec  3 15:30:05.476: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec  3 15:30:05.476: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod pause -L testing-label --namespace=kubectl-3769'
Dec  3 15:30:05.581: INFO: stderr: ""
Dec  3 15:30:05.581: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          2s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Dec  3 15:30:05.582: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-3769'
Dec  3 15:30:05.699: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:30:05.699: INFO: stdout: "pod \"pause\" force deleted\n"
Dec  3 15:30:05.699: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=pause --no-headers --namespace=kubectl-3769'
Dec  3 15:30:05.819: INFO: stderr: "No resources found in kubectl-3769 namespace.\n"
Dec  3 15:30:05.819: INFO: stdout: ""
Dec  3 15:30:05.819: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=pause --namespace=kubectl-3769 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 15:30:05.923: INFO: stderr: ""
Dec  3 15:30:05.923: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:30:05.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3769" for this suite.
Dec  3 15:30:11.975: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:30:12.331: INFO: namespace kubectl-3769 deletion completed in 6.388773395s
•SSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:30:12.331: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-3956
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:30:12.513: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating first CR 
Dec  3 15:30:12.654: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-03T15:30:12Z generation:1 name:name1 resourceVersion:14177 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:04956f45-243b-4daf-b90c-8f136fb9ec18] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Dec  3 15:30:22.666: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-03T15:30:22Z generation:1 name:name2 resourceVersion:14202 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:e7f607ab-facb-4f66-9d58-7b14523ebd6b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Dec  3 15:30:32.678: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-03T15:30:12Z generation:2 name:name1 resourceVersion:14226 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:04956f45-243b-4daf-b90c-8f136fb9ec18] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Dec  3 15:30:42.691: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-03T15:30:22Z generation:2 name:name2 resourceVersion:14250 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:e7f607ab-facb-4f66-9d58-7b14523ebd6b] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Dec  3 15:30:52.705: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-03T15:30:12Z generation:2 name:name1 resourceVersion:14276 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:04956f45-243b-4daf-b90c-8f136fb9ec18] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Dec  3 15:31:02.719: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-03T15:30:22Z generation:2 name:name2 resourceVersion:14302 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:e7f607ab-facb-4f66-9d58-7b14523ebd6b] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:31:13.251: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-3956" for this suite.
Dec  3 15:31:19.302: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:31:19.648: INFO: namespace crd-watch-3956 deletion completed in 6.378099354s
•SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:31:19.648: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-5315
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Dec  3 15:31:19.940: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:31:22.613: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:31:36.268: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-5315" for this suite.
Dec  3 15:31:42.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:31:42.669: INFO: namespace crd-publish-openapi-5315 deletion completed in 6.381746133s
•
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:31:42.669: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5411
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:31:42.867: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f5523e11-a7d5-4eb8-b522-a5f4ec3e57ff" in namespace "downward-api-5411" to be "success or failure"
Dec  3 15:31:42.878: INFO: Pod "downwardapi-volume-f5523e11-a7d5-4eb8-b522-a5f4ec3e57ff": Phase="Pending", Reason="", readiness=false. Elapsed: 10.094181ms
Dec  3 15:31:44.888: INFO: Pod "downwardapi-volume-f5523e11-a7d5-4eb8-b522-a5f4ec3e57ff": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020922104s
STEP: Saw pod success
Dec  3 15:31:44.888: INFO: Pod "downwardapi-volume-f5523e11-a7d5-4eb8-b522-a5f4ec3e57ff" satisfied condition "success or failure"
Dec  3 15:31:44.899: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downwardapi-volume-f5523e11-a7d5-4eb8-b522-a5f4ec3e57ff container client-container: <nil>
STEP: delete the pod
Dec  3 15:31:45.060: INFO: Waiting for pod downwardapi-volume-f5523e11-a7d5-4eb8-b522-a5f4ec3e57ff to disappear
Dec  3 15:31:45.070: INFO: Pod downwardapi-volume-f5523e11-a7d5-4eb8-b522-a5f4ec3e57ff no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:31:45.070: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5411" for this suite.
Dec  3 15:31:51.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:31:51.473: INFO: namespace downward-api-5411 deletion completed in 6.383813178s
•SSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:31:51.473: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4295
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-6d8fc259-26e5-4214-9401-727701a2638d
STEP: Creating a pod to test consume configMaps
Dec  3 15:31:51.683: INFO: Waiting up to 5m0s for pod "pod-configmaps-f6af3595-b043-4486-8f32-a4d7f8314739" in namespace "configmap-4295" to be "success or failure"
Dec  3 15:31:51.694: INFO: Pod "pod-configmaps-f6af3595-b043-4486-8f32-a4d7f8314739": Phase="Pending", Reason="", readiness=false. Elapsed: 10.134646ms
Dec  3 15:31:53.705: INFO: Pod "pod-configmaps-f6af3595-b043-4486-8f32-a4d7f8314739": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021233191s
STEP: Saw pod success
Dec  3 15:31:53.705: INFO: Pod "pod-configmaps-f6af3595-b043-4486-8f32-a4d7f8314739" satisfied condition "success or failure"
Dec  3 15:31:53.715: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-configmaps-f6af3595-b043-4486-8f32-a4d7f8314739 container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:31:53.747: INFO: Waiting for pod pod-configmaps-f6af3595-b043-4486-8f32-a4d7f8314739 to disappear
Dec  3 15:31:53.757: INFO: Pod pod-configmaps-f6af3595-b043-4486-8f32-a4d7f8314739 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:31:53.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4295" for this suite.
Dec  3 15:31:59.810: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:32:00.194: INFO: namespace configmap-4295 deletion completed in 6.417358887s
•S
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:32:00.194: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-6815
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
W1203 15:32:10.453529    5064 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  3 15:32:10.453: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:32:10.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-6815" for this suite.
Dec  3 15:32:16.498: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:32:16.892: INFO: namespace gc-6815 deletion completed in 6.427592861s
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:32:16.893: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6355
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:32:17.086: INFO: Waiting up to 5m0s for pod "downwardapi-volume-982d821a-52a1-4ba2-bebb-00029892d767" in namespace "projected-6355" to be "success or failure"
Dec  3 15:32:17.096: INFO: Pod "downwardapi-volume-982d821a-52a1-4ba2-bebb-00029892d767": Phase="Pending", Reason="", readiness=false. Elapsed: 9.808064ms
Dec  3 15:32:19.107: INFO: Pod "downwardapi-volume-982d821a-52a1-4ba2-bebb-00029892d767": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020668004s
STEP: Saw pod success
Dec  3 15:32:19.107: INFO: Pod "downwardapi-volume-982d821a-52a1-4ba2-bebb-00029892d767" satisfied condition "success or failure"
Dec  3 15:32:19.117: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downwardapi-volume-982d821a-52a1-4ba2-bebb-00029892d767 container client-container: <nil>
STEP: delete the pod
Dec  3 15:32:19.147: INFO: Waiting for pod downwardapi-volume-982d821a-52a1-4ba2-bebb-00029892d767 to disappear
Dec  3 15:32:19.156: INFO: Pod downwardapi-volume-982d821a-52a1-4ba2-bebb-00029892d767 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:32:19.157: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6355" for this suite.
Dec  3 15:32:25.207: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:32:25.605: INFO: namespace projected-6355 deletion completed in 6.429294708s
•SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:32:25.605: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-6138
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  3 15:32:27.842: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:32:27.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-6138" for this suite.
Dec  3 15:32:33.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:32:34.271: INFO: namespace container-runtime-6138 deletion completed in 6.386223238s
•SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:32:34.272: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2459
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:32:34.466: INFO: Waiting up to 5m0s for pod "downwardapi-volume-3ba4ce96-0c3d-4af8-a4f1-facfec96885f" in namespace "projected-2459" to be "success or failure"
Dec  3 15:32:34.476: INFO: Pod "downwardapi-volume-3ba4ce96-0c3d-4af8-a4f1-facfec96885f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.479622ms
Dec  3 15:32:36.487: INFO: Pod "downwardapi-volume-3ba4ce96-0c3d-4af8-a4f1-facfec96885f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021567874s
STEP: Saw pod success
Dec  3 15:32:36.487: INFO: Pod "downwardapi-volume-3ba4ce96-0c3d-4af8-a4f1-facfec96885f" satisfied condition "success or failure"
Dec  3 15:32:36.498: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downwardapi-volume-3ba4ce96-0c3d-4af8-a4f1-facfec96885f container client-container: <nil>
STEP: delete the pod
Dec  3 15:32:36.528: INFO: Waiting for pod downwardapi-volume-3ba4ce96-0c3d-4af8-a4f1-facfec96885f to disappear
Dec  3 15:32:36.538: INFO: Pod downwardapi-volume-3ba4ce96-0c3d-4af8-a4f1-facfec96885f no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:32:36.538: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2459" for this suite.
Dec  3 15:32:42.589: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:32:42.946: INFO: namespace projected-2459 deletion completed in 6.388918792s
•
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:32:42.946: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-1160
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:33:05.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-1160" for this suite.
Dec  3 15:33:11.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:33:12.066: INFO: namespace container-runtime-1160 deletion completed in 6.406607768s
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:33:12.067: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7251
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  3 15:33:14.312: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:33:14.336: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7251" for this suite.
Dec  3 15:33:20.387: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:33:20.736: INFO: namespace container-runtime-7251 deletion completed in 6.380852849s
•SSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:33:20.736: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-8945
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-8945
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-8945
STEP: Deleting pre-stop pod
Dec  3 15:33:30.104: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:33:30.116: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-8945" for this suite.
Dec  3 15:34:14.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:34:14.520: INFO: namespace prestop-8945 deletion completed in 44.38407046s
•SS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:34:14.520: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3776
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  3 15:34:14.705: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-3776'
Dec  3 15:34:14.841: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 15:34:14.841: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Dec  3 15:34:14.856: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete deployment e2e-test-httpd-deployment --namespace=kubectl-3776'
Dec  3 15:34:14.976: INFO: stderr: ""
Dec  3 15:34:14.976: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:34:14.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3776" for this suite.
Dec  3 15:34:21.019: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:34:21.406: INFO: namespace kubectl-3776 deletion completed in 6.418302853s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:34:21.407: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6739
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec  3 15:34:24.302: INFO: Successfully updated pod "labelsupdate5e3fe288-6360-4632-8ed2-09e75dac13a0"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:34:28.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6739" for this suite.
Dec  3 15:34:56.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:34:56.760: INFO: namespace downward-api-6739 deletion completed in 28.387099544s
•S
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:34:56.760: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4138
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec  3 15:34:56.943: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 15:34:56.975: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 15:34:56.986: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 before test
Dec  3 15:34:57.102: INFO: calico-typha-horizontal-autoscaler-69df649c59-7l6bk from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:34:57.102: INFO: 	Container autoscaler ready: true, restart count 0
Dec  3 15:34:57.102: INFO: addons-nginx-ingress-controller-7c75bb76db-zkqv8 from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:34:57.102: INFO: 	Container nginx-ingress-controller ready: true, restart count 1
Dec  3 15:34:57.102: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-95f65778d-nb2sc from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:34:57.102: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec  3 15:34:57.102: INFO: calico-kube-controllers-79bcd784b6-pkrdg from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:34:57.102: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  3 15:34:57.102: INFO: addons-kubernetes-dashboard-78954cc66b-gjdxd from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:34:57.102: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  3 15:34:57.102: INFO: blackbox-exporter-7bd7b55dfc-7ktvk from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 15:34:57.102: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec  3 15:34:57.102: INFO: node-problem-detector-xwvwh from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 15:34:57.102: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:34:57.102: INFO: calico-typha-vertical-autoscaler-847d859f8c-vfvq7 from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:34:57.102: INFO: 	Container autoscaler ready: true, restart count 3
Dec  3 15:34:57.102: INFO: coredns-59c969ffb8-p9rws from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:34:57.102: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:34:57.102: INFO: vpn-shoot-5689b7f9b4-n47mb from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:34:57.102: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec  3 15:34:57.102: INFO: node-exporter-pwl5b from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 15:34:57.102: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:34:57.102: INFO: kube-proxy-qzrrc from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 15:34:57.102: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:34:57.102: INFO: calico-typha-deploy-9f6b455c4-6ntkq from kube-system started at 2019-12-03 15:09:21 +0000 UTC (1 container statuses recorded)
Dec  3 15:34:57.102: INFO: 	Container calico-typha ready: true, restart count 0
Dec  3 15:34:57.102: INFO: calico-node-rc24j from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 15:34:57.102: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:34:57.102: INFO: coredns-59c969ffb8-jwpjr from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:34:57.102: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:34:57.102: INFO: metrics-server-7df74c5758-hnsgs from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:34:57.102: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 15:34:57.102: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz before test
Dec  3 15:34:57.147: INFO: node-problem-detector-4c7x7 from kube-system started at 2019-12-03 14:27:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:34:57.147: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:34:57.147: INFO: calico-node-zhw8c from kube-system started at 2019-12-03 14:27:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:34:57.147: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:34:57.147: INFO: node-exporter-fmmk4 from kube-system started at 2019-12-03 14:27:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:34:57.147: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:34:57.147: INFO: kube-proxy-n42lb from kube-system started at 2019-12-03 14:27:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:34:57.147: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15dce66668b5c718], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:34:58.206: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4138" for this suite.
Dec  3 15:35:04.258: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:35:04.616: INFO: namespace sched-pred-4138 deletion completed in 6.391748864s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:35:04.617: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6819
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:35:30.845: INFO: Container started at 2019-12-03 15:35:05 +0000 UTC, pod became ready at 2019-12-03 15:35:29 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:35:30.845: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6819" for this suite.
Dec  3 15:35:58.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:35:59.249: INFO: namespace container-probe-6819 deletion completed in 28.385858555s
•SSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:35:59.250: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-2442
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:35:59.449: INFO: Waiting up to 5m0s for pod "busybox-user-65534-2d8cd132-ac60-441c-9cc0-1f91043b5bef" in namespace "security-context-test-2442" to be "success or failure"
Dec  3 15:35:59.459: INFO: Pod "busybox-user-65534-2d8cd132-ac60-441c-9cc0-1f91043b5bef": Phase="Pending", Reason="", readiness=false. Elapsed: 10.515278ms
Dec  3 15:36:01.470: INFO: Pod "busybox-user-65534-2d8cd132-ac60-441c-9cc0-1f91043b5bef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021160418s
Dec  3 15:36:01.470: INFO: Pod "busybox-user-65534-2d8cd132-ac60-441c-9cc0-1f91043b5bef" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:36:01.470: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2442" for this suite.
Dec  3 15:36:07.521: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:36:07.874: INFO: namespace security-context-test-2442 deletion completed in 6.385607786s
•SS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:36:07.874: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5572
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:36:08.072: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7958fda1-eaa8-473c-a9bf-efa0801ada48" in namespace "downward-api-5572" to be "success or failure"
Dec  3 15:36:08.082: INFO: Pod "downwardapi-volume-7958fda1-eaa8-473c-a9bf-efa0801ada48": Phase="Pending", Reason="", readiness=false. Elapsed: 10.043998ms
Dec  3 15:36:10.093: INFO: Pod "downwardapi-volume-7958fda1-eaa8-473c-a9bf-efa0801ada48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021006555s
STEP: Saw pod success
Dec  3 15:36:10.093: INFO: Pod "downwardapi-volume-7958fda1-eaa8-473c-a9bf-efa0801ada48" satisfied condition "success or failure"
Dec  3 15:36:10.103: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downwardapi-volume-7958fda1-eaa8-473c-a9bf-efa0801ada48 container client-container: <nil>
STEP: delete the pod
Dec  3 15:36:10.137: INFO: Waiting for pod downwardapi-volume-7958fda1-eaa8-473c-a9bf-efa0801ada48 to disappear
Dec  3 15:36:10.147: INFO: Pod downwardapi-volume-7958fda1-eaa8-473c-a9bf-efa0801ada48 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:36:10.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5572" for this suite.
Dec  3 15:36:16.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:36:16.548: INFO: namespace downward-api-5572 deletion completed in 6.381774875s
•SSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:36:16.548: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-9185
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec  3 15:36:16.770: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9185 /api/v1/namespaces/watch-9185/configmaps/e2e-watch-test-configmap-a 17fbf5f2-f9af-45db-b98c-5eda945fe4a5 15424 0 2019-12-03 15:36:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:36:16.771: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9185 /api/v1/namespaces/watch-9185/configmaps/e2e-watch-test-configmap-a 17fbf5f2-f9af-45db-b98c-5eda945fe4a5 15424 0 2019-12-03 15:36:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec  3 15:36:26.793: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9185 /api/v1/namespaces/watch-9185/configmaps/e2e-watch-test-configmap-a 17fbf5f2-f9af-45db-b98c-5eda945fe4a5 15448 0 2019-12-03 15:36:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  3 15:36:26.793: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9185 /api/v1/namespaces/watch-9185/configmaps/e2e-watch-test-configmap-a 17fbf5f2-f9af-45db-b98c-5eda945fe4a5 15448 0 2019-12-03 15:36:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec  3 15:36:36.816: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9185 /api/v1/namespaces/watch-9185/configmaps/e2e-watch-test-configmap-a 17fbf5f2-f9af-45db-b98c-5eda945fe4a5 15473 0 2019-12-03 15:36:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 15:36:36.816: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9185 /api/v1/namespaces/watch-9185/configmaps/e2e-watch-test-configmap-a 17fbf5f2-f9af-45db-b98c-5eda945fe4a5 15473 0 2019-12-03 15:36:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec  3 15:36:46.829: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9185 /api/v1/namespaces/watch-9185/configmaps/e2e-watch-test-configmap-a 17fbf5f2-f9af-45db-b98c-5eda945fe4a5 15499 0 2019-12-03 15:36:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 15:36:46.829: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-9185 /api/v1/namespaces/watch-9185/configmaps/e2e-watch-test-configmap-a 17fbf5f2-f9af-45db-b98c-5eda945fe4a5 15499 0 2019-12-03 15:36:16 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec  3 15:36:56.843: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9185 /api/v1/namespaces/watch-9185/configmaps/e2e-watch-test-configmap-b 09616d62-384c-4ba3-aef0-52f2bc24973b 15525 0 2019-12-03 15:36:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:36:56.843: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9185 /api/v1/namespaces/watch-9185/configmaps/e2e-watch-test-configmap-b 09616d62-384c-4ba3-aef0-52f2bc24973b 15525 0 2019-12-03 15:36:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec  3 15:37:06.856: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9185 /api/v1/namespaces/watch-9185/configmaps/e2e-watch-test-configmap-b 09616d62-384c-4ba3-aef0-52f2bc24973b 15550 0 2019-12-03 15:36:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:37:06.856: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-9185 /api/v1/namespaces/watch-9185/configmaps/e2e-watch-test-configmap-b 09616d62-384c-4ba3-aef0-52f2bc24973b 15550 0 2019-12-03 15:36:56 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:37:16.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-9185" for this suite.
Dec  3 15:37:22.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:37:23.308: INFO: namespace watch-9185 deletion completed in 6.432092312s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:37:23.309: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7803
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:37:23.936: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984243, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984243, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984243, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984243, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:37:25.948: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984243, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984243, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984243, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984243, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:37:28.968: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:37:28.979: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-8604-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:37:29.839: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7803" for this suite.
Dec  3 15:37:35.891: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:37:36.292: INFO: namespace webhook-7803 deletion completed in 6.43404805s
STEP: Destroying namespace "webhook-7803-markers" for this suite.
Dec  3 15:37:42.325: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:37:42.678: INFO: namespace webhook-7803-markers deletion completed in 6.385942035s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:37:42.722: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7083
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  3 15:37:42.919: INFO: Waiting up to 5m0s for pod "pod-40074e1d-2a18-4cbb-a0d9-2fcbc2d6e8f0" in namespace "emptydir-7083" to be "success or failure"
Dec  3 15:37:42.929: INFO: Pod "pod-40074e1d-2a18-4cbb-a0d9-2fcbc2d6e8f0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.24576ms
Dec  3 15:37:44.940: INFO: Pod "pod-40074e1d-2a18-4cbb-a0d9-2fcbc2d6e8f0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020924936s
STEP: Saw pod success
Dec  3 15:37:44.940: INFO: Pod "pod-40074e1d-2a18-4cbb-a0d9-2fcbc2d6e8f0" satisfied condition "success or failure"
Dec  3 15:37:44.950: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-40074e1d-2a18-4cbb-a0d9-2fcbc2d6e8f0 container test-container: <nil>
STEP: delete the pod
Dec  3 15:37:45.110: INFO: Waiting for pod pod-40074e1d-2a18-4cbb-a0d9-2fcbc2d6e8f0 to disappear
Dec  3 15:37:45.120: INFO: Pod pod-40074e1d-2a18-4cbb-a0d9-2fcbc2d6e8f0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:37:45.120: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7083" for this suite.
Dec  3 15:37:51.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:37:51.525: INFO: namespace emptydir-7083 deletion completed in 6.385980614s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:37:51.525: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2449
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 15:37:51.722: INFO: Waiting up to 5m0s for pod "downwardapi-volume-108cec24-af54-4602-ae3c-92c6f0d31e18" in namespace "projected-2449" to be "success or failure"
Dec  3 15:37:51.732: INFO: Pod "downwardapi-volume-108cec24-af54-4602-ae3c-92c6f0d31e18": Phase="Pending", Reason="", readiness=false. Elapsed: 10.142235ms
Dec  3 15:37:53.743: INFO: Pod "downwardapi-volume-108cec24-af54-4602-ae3c-92c6f0d31e18": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020901708s
STEP: Saw pod success
Dec  3 15:37:53.743: INFO: Pod "downwardapi-volume-108cec24-af54-4602-ae3c-92c6f0d31e18" satisfied condition "success or failure"
Dec  3 15:37:53.753: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downwardapi-volume-108cec24-af54-4602-ae3c-92c6f0d31e18 container client-container: <nil>
STEP: delete the pod
Dec  3 15:37:53.788: INFO: Waiting for pod downwardapi-volume-108cec24-af54-4602-ae3c-92c6f0d31e18 to disappear
Dec  3 15:37:53.798: INFO: Pod downwardapi-volume-108cec24-af54-4602-ae3c-92c6f0d31e18 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:37:53.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2449" for this suite.
Dec  3 15:37:59.851: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:38:00.244: INFO: namespace projected-2449 deletion completed in 6.426427846s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:38:00.244: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6549
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:38:01.108: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984281, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984281, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984281, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984281, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:38:03.119: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984281, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984281, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984281, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984281, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:38:06.137: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Dec  3 15:38:08.334: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config attach --namespace=webhook-6549 to-be-attached-pod -i -c=container1'
Dec  3 15:38:08.891: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:38:08.905: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6549" for this suite.
Dec  3 15:38:20.956: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:38:21.370: INFO: namespace webhook-6549 deletion completed in 12.446110285s
STEP: Destroying namespace "webhook-6549-markers" for this suite.
Dec  3 15:38:27.403: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:38:27.757: INFO: namespace webhook-6549-markers deletion completed in 6.387470909s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:38:27.800: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8272
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:38:28.567: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984308, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984308, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984308, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984308, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:38:30.578: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984308, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984308, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984308, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984308, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:38:33.595: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:38:33.868: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8272" for this suite.
Dec  3 15:38:39.920: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:38:40.279: INFO: namespace webhook-8272 deletion completed in 6.392049177s
STEP: Destroying namespace "webhook-8272-markers" for this suite.
Dec  3 15:38:46.311: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:38:46.699: INFO: namespace webhook-8272-markers deletion completed in 6.420210935s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:38:46.742: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-6334
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec  3 15:38:46.923: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:38:50.306: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-6334" for this suite.
Dec  3 15:38:56.358: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:38:56.719: INFO: namespace init-container-6334 deletion completed in 6.394309526s
•SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:38:56.719: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6499
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:39:07.985: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6499" for this suite.
Dec  3 15:39:14.038: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:39:14.430: INFO: namespace resourcequota-6499 deletion completed in 6.425629565s
•SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:39:14.430: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1067
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-2dd19ebd-ef50-4a75-86ba-cd9507c1a745
STEP: Creating a pod to test consume secrets
Dec  3 15:39:14.645: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-7a58334f-fedc-4644-b087-e83e30493c72" in namespace "projected-1067" to be "success or failure"
Dec  3 15:39:14.655: INFO: Pod "pod-projected-secrets-7a58334f-fedc-4644-b087-e83e30493c72": Phase="Pending", Reason="", readiness=false. Elapsed: 10.09689ms
Dec  3 15:39:16.666: INFO: Pod "pod-projected-secrets-7a58334f-fedc-4644-b087-e83e30493c72": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020986346s
STEP: Saw pod success
Dec  3 15:39:16.666: INFO: Pod "pod-projected-secrets-7a58334f-fedc-4644-b087-e83e30493c72" satisfied condition "success or failure"
Dec  3 15:39:16.676: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-projected-secrets-7a58334f-fedc-4644-b087-e83e30493c72 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:39:16.708: INFO: Waiting for pod pod-projected-secrets-7a58334f-fedc-4644-b087-e83e30493c72 to disappear
Dec  3 15:39:16.718: INFO: Pod pod-projected-secrets-7a58334f-fedc-4644-b087-e83e30493c72 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:39:16.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1067" for this suite.
Dec  3 15:39:22.769: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:39:23.122: INFO: namespace projected-1067 deletion completed in 6.385102923s
•SS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:39:23.122: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5113
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:39:23.304: INFO: Creating deployment "test-recreate-deployment"
Dec  3 15:39:23.316: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec  3 15:39:23.336: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec  3 15:39:23.346: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984363, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984363, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984363, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710984363, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:39:25.358: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec  3 15:39:25.379: INFO: Updating deployment test-recreate-deployment
Dec  3 15:39:25.379: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec  3 15:39:25.423: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-5113 /apis/apps/v1/namespaces/deployment-5113/deployments/test-recreate-deployment df844d2a-a3f2-4be6-8412-d4b8ffb8bd03 16201 2 2019-12-03 15:39:23 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003857518 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-12-03 15:39:25 +0000 UTC,LastTransitionTime:2019-12-03 15:39:25 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2019-12-03 15:39:25 +0000 UTC,LastTransitionTime:2019-12-03 15:39:23 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Dec  3 15:39:25.434: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-5113 /apis/apps/v1/namespaces/deployment-5113/replicasets/test-recreate-deployment-5f94c574ff ac8d348b-20c8-4cd0-b609-6ed644af20af 16199 1 2019-12-03 15:39:25 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment df844d2a-a3f2-4be6-8412-d4b8ffb8bd03 0xc0038578d7 0xc0038578d8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003857938 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 15:39:25.434: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec  3 15:39:25.434: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-5113 /apis/apps/v1/namespaces/deployment-5113/replicasets/test-recreate-deployment-68fc85c7bb a8ae9e03-da6b-4a1e-844f-085d74e7fc75 16193 2 2019-12-03 15:39:23 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment df844d2a-a3f2-4be6-8412-d4b8ffb8bd03 0xc0038579a7 0xc0038579a8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003857a08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 15:39:25.445: INFO: Pod "test-recreate-deployment-5f94c574ff-6lbdz" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-6lbdz test-recreate-deployment-5f94c574ff- deployment-5113 /api/v1/namespaces/deployment-5113/pods/test-recreate-deployment-5f94c574ff-6lbdz 19d99186-0404-40ba-bbc3-afa23b59aca4 16202 0 2019-12-03 15:39:25 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff ac8d348b-20c8-4cd0-b609-6ed644af20af 0xc003857e77 0xc003857e78}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-w22hj,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-w22hj,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-w22hj,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:39:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:39:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:39:25 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:39:25 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-12-03 15:39:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:39:25.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5113" for this suite.
Dec  3 15:39:31.497: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:39:31.849: INFO: namespace deployment-5113 deletion completed in 6.384869607s
•SSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:39:31.849: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9868
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-9868
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 15:39:32.032: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 15:39:48.214: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.0.49 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9868 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:39:48.214: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:39:49.637: INFO: Found all expected endpoints: [netserver-0]
Dec  3 15:39:49.647: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 100.64.1.185 8081 | grep -v '^\s*$'] Namespace:pod-network-test-9868 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:39:49.647: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:39:51.114: INFO: Found all expected endpoints: [netserver-1]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:39:51.114: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9868" for this suite.
Dec  3 15:40:03.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:40:03.522: INFO: namespace pod-network-test-9868 deletion completed in 12.388152864s
•SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:40:03.522: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-900
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-341433da-1961-4eff-81c7-ad8c3ebdb6d7 in namespace container-probe-900
Dec  3 15:40:05.738: INFO: Started pod liveness-341433da-1961-4eff-81c7-ad8c3ebdb6d7 in namespace container-probe-900
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 15:40:05.749: INFO: Initial restart count of pod liveness-341433da-1961-4eff-81c7-ad8c3ebdb6d7 is 0
Dec  3 15:40:21.846: INFO: Restart count of pod container-probe-900/liveness-341433da-1961-4eff-81c7-ad8c3ebdb6d7 is now 1 (16.097310297s elapsed)
Dec  3 15:40:41.955: INFO: Restart count of pod container-probe-900/liveness-341433da-1961-4eff-81c7-ad8c3ebdb6d7 is now 2 (36.206509501s elapsed)
Dec  3 15:41:02.067: INFO: Restart count of pod container-probe-900/liveness-341433da-1961-4eff-81c7-ad8c3ebdb6d7 is now 3 (56.318162874s elapsed)
Dec  3 15:41:22.177: INFO: Restart count of pod container-probe-900/liveness-341433da-1961-4eff-81c7-ad8c3ebdb6d7 is now 4 (1m16.427918033s elapsed)
Dec  3 15:42:26.527: INFO: Restart count of pod container-probe-900/liveness-341433da-1961-4eff-81c7-ad8c3ebdb6d7 is now 5 (2m20.778715328s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:42:26.542: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-900" for this suite.
Dec  3 15:42:32.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:42:32.996: INFO: namespace container-probe-900 deletion completed in 6.434824478s
•SSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:42:32.997: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7864
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-0d69da7e-aa95-4c7a-a870-b756176ef1f0
STEP: Creating a pod to test consume configMaps
Dec  3 15:42:33.212: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-3f5948c6-2dd9-4f00-82a2-d5a83368f392" in namespace "projected-7864" to be "success or failure"
Dec  3 15:42:33.222: INFO: Pod "pod-projected-configmaps-3f5948c6-2dd9-4f00-82a2-d5a83368f392": Phase="Pending", Reason="", readiness=false. Elapsed: 10.47591ms
Dec  3 15:42:35.234: INFO: Pod "pod-projected-configmaps-3f5948c6-2dd9-4f00-82a2-d5a83368f392": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021680476s
STEP: Saw pod success
Dec  3 15:42:35.234: INFO: Pod "pod-projected-configmaps-3f5948c6-2dd9-4f00-82a2-d5a83368f392" satisfied condition "success or failure"
Dec  3 15:42:35.244: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-projected-configmaps-3f5948c6-2dd9-4f00-82a2-d5a83368f392 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:42:35.407: INFO: Waiting for pod pod-projected-configmaps-3f5948c6-2dd9-4f00-82a2-d5a83368f392 to disappear
Dec  3 15:42:35.417: INFO: Pod pod-projected-configmaps-3f5948c6-2dd9-4f00-82a2-d5a83368f392 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:42:35.418: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7864" for this suite.
Dec  3 15:42:41.469: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:42:41.826: INFO: namespace projected-7864 deletion completed in 6.388992555s
•SSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:42:41.826: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6096
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Dec  3 15:42:44.068: INFO: Pod pod-hostip-85d2b91c-fb1c-4741-be77-b868ed5bf5eb has hostIP: 10.250.0.2
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:42:44.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6096" for this suite.
Dec  3 15:42:56.121: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:42:56.476: INFO: namespace pods-6096 deletion completed in 12.388534867s
•SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:42:56.476: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6047
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  3 15:43:00.757: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:43:00.768: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:43:02.768: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:43:02.779: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:43:04.768: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:43:04.780: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:43:06.768: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:43:06.779: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:43:08.768: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:43:08.779: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:43:10.768: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:43:10.779: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:43:12.768: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:43:12.779: INFO: Pod pod-with-prestop-exec-hook still exists
Dec  3 15:43:14.768: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec  3 15:43:14.779: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:43:14.802: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6047" for this suite.
Dec  3 15:43:26.854: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:43:27.210: INFO: namespace container-lifecycle-hook-6047 deletion completed in 12.389055276s
•SSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:43:27.210: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-2650
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: Gathering metrics
Dec  3 15:43:27.472: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W1203 15:43:27.472116    5064 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec  3 15:43:27.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-2650" for this suite.
Dec  3 15:43:33.514: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:43:33.867: INFO: namespace gc-2650 deletion completed in 6.385027241s
•S
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:43:33.867: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3712
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  3 15:43:34.067: INFO: Waiting up to 5m0s for pod "pod-e3b91c58-2462-4743-820b-b82bd86632e0" in namespace "emptydir-3712" to be "success or failure"
Dec  3 15:43:34.077: INFO: Pod "pod-e3b91c58-2462-4743-820b-b82bd86632e0": Phase="Pending", Reason="", readiness=false. Elapsed: 10.348227ms
Dec  3 15:43:36.088: INFO: Pod "pod-e3b91c58-2462-4743-820b-b82bd86632e0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021277102s
STEP: Saw pod success
Dec  3 15:43:36.088: INFO: Pod "pod-e3b91c58-2462-4743-820b-b82bd86632e0" satisfied condition "success or failure"
Dec  3 15:43:36.099: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-e3b91c58-2462-4743-820b-b82bd86632e0 container test-container: <nil>
STEP: delete the pod
Dec  3 15:43:36.130: INFO: Waiting for pod pod-e3b91c58-2462-4743-820b-b82bd86632e0 to disappear
Dec  3 15:43:36.140: INFO: Pod pod-e3b91c58-2462-4743-820b-b82bd86632e0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:43:36.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3712" for this suite.
Dec  3 15:43:42.192: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:43:42.541: INFO: namespace emptydir-3712 deletion completed in 6.381857034s
•SSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:43:42.541: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-641
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-e0eaa5f9-0494-4024-98b8-7536cb843188
STEP: Creating a pod to test consume secrets
Dec  3 15:43:42.748: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-60e2158b-ac1b-4056-b454-9e3de4d17562" in namespace "projected-641" to be "success or failure"
Dec  3 15:43:42.758: INFO: Pod "pod-projected-secrets-60e2158b-ac1b-4056-b454-9e3de4d17562": Phase="Pending", Reason="", readiness=false. Elapsed: 9.855771ms
Dec  3 15:43:44.769: INFO: Pod "pod-projected-secrets-60e2158b-ac1b-4056-b454-9e3de4d17562": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020479177s
STEP: Saw pod success
Dec  3 15:43:44.769: INFO: Pod "pod-projected-secrets-60e2158b-ac1b-4056-b454-9e3de4d17562" satisfied condition "success or failure"
Dec  3 15:43:44.779: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-projected-secrets-60e2158b-ac1b-4056-b454-9e3de4d17562 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:43:44.812: INFO: Waiting for pod pod-projected-secrets-60e2158b-ac1b-4056-b454-9e3de4d17562 to disappear
Dec  3 15:43:44.822: INFO: Pod pod-projected-secrets-60e2158b-ac1b-4056-b454-9e3de4d17562 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:43:44.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-641" for this suite.
Dec  3 15:43:50.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:43:51.254: INFO: namespace projected-641 deletion completed in 6.414119465s
•SSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:43:51.255: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1496
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:43:51.482: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"dafaecf9-4c79-46fa-8de4-b204cd138925", Controller:(*bool)(0xc003a4f05a), BlockOwnerDeletion:(*bool)(0xc003a4f05b)}}
Dec  3 15:43:51.494: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"c4aeffdb-d47c-4b0a-b168-bec10b11bc77", Controller:(*bool)(0xc0028e4276), BlockOwnerDeletion:(*bool)(0xc0028e4277)}}
Dec  3 15:43:51.506: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"c9c5a159-db31-4122-b229-adae4682b9da", Controller:(*bool)(0xc007393466), BlockOwnerDeletion:(*bool)(0xc007393467)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:43:56.528: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1496" for this suite.
Dec  3 15:44:02.579: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:44:02.928: INFO: namespace gc-1496 deletion completed in 6.381139353s
•SSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:44:02.928: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-6606
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec  3 15:44:03.174: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6606 /api/v1/namespaces/watch-6606/configmaps/e2e-watch-test-label-changed f5b4f70c-6277-40e2-bf41-aa8be3f321b6 17123 0 2019-12-03 15:44:03 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 15:44:03.175: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6606 /api/v1/namespaces/watch-6606/configmaps/e2e-watch-test-label-changed f5b4f70c-6277-40e2-bf41-aa8be3f321b6 17124 0 2019-12-03 15:44:03 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec  3 15:44:03.175: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6606 /api/v1/namespaces/watch-6606/configmaps/e2e-watch-test-label-changed f5b4f70c-6277-40e2-bf41-aa8be3f321b6 17125 0 2019-12-03 15:44:03 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec  3 15:44:13.252: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6606 /api/v1/namespaces/watch-6606/configmaps/e2e-watch-test-label-changed f5b4f70c-6277-40e2-bf41-aa8be3f321b6 17150 0 2019-12-03 15:44:03 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 15:44:13.252: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6606 /api/v1/namespaces/watch-6606/configmaps/e2e-watch-test-label-changed f5b4f70c-6277-40e2-bf41-aa8be3f321b6 17151 0 2019-12-03 15:44:03 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec  3 15:44:13.253: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-6606 /api/v1/namespaces/watch-6606/configmaps/e2e-watch-test-label-changed f5b4f70c-6277-40e2-bf41-aa8be3f321b6 17152 0 2019-12-03 15:44:03 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:44:13.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-6606" for this suite.
Dec  3 15:44:19.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:44:19.651: INFO: namespace watch-6606 deletion completed in 6.378622346s
•SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:44:19.651: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-6105
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-1a0dc841-de0c-4b39-8279-6460f1d9708c in namespace container-probe-6105
Dec  3 15:44:21.865: INFO: Started pod busybox-1a0dc841-de0c-4b39-8279-6460f1d9708c in namespace container-probe-6105
STEP: checking the pod's current state and verifying that restartCount is present
Dec  3 15:44:21.875: INFO: Initial restart count of pod busybox-1a0dc841-de0c-4b39-8279-6460f1d9708c is 0
Dec  3 15:45:14.171: INFO: Restart count of pod container-probe-6105/busybox-1a0dc841-de0c-4b39-8279-6460f1d9708c is now 1 (52.296373219s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:45:14.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-6105" for this suite.
Dec  3 15:45:20.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:45:20.584: INFO: namespace container-probe-6105 deletion completed in 6.380967686s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:45:20.586: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2750
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-c1f9a500-229c-462c-a1da-4e0b35fce549
STEP: Creating a pod to test consume secrets
Dec  3 15:45:20.798: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-ffb5ad7b-3400-4788-a748-007527e2e388" in namespace "projected-2750" to be "success or failure"
Dec  3 15:45:20.808: INFO: Pod "pod-projected-secrets-ffb5ad7b-3400-4788-a748-007527e2e388": Phase="Pending", Reason="", readiness=false. Elapsed: 9.898242ms
Dec  3 15:45:22.818: INFO: Pod "pod-projected-secrets-ffb5ad7b-3400-4788-a748-007527e2e388": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020505459s
STEP: Saw pod success
Dec  3 15:45:22.818: INFO: Pod "pod-projected-secrets-ffb5ad7b-3400-4788-a748-007527e2e388" satisfied condition "success or failure"
Dec  3 15:45:22.829: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-projected-secrets-ffb5ad7b-3400-4788-a748-007527e2e388 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:45:22.989: INFO: Waiting for pod pod-projected-secrets-ffb5ad7b-3400-4788-a748-007527e2e388 to disappear
Dec  3 15:45:23.000: INFO: Pod pod-projected-secrets-ffb5ad7b-3400-4788-a748-007527e2e388 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:45:23.000: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2750" for this suite.
Dec  3 15:45:29.052: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:45:29.411: INFO: namespace projected-2750 deletion completed in 6.391908737s
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:45:29.412: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1097
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  3 15:45:29.598: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-1097'
Dec  3 15:45:29.953: INFO: stderr: ""
Dec  3 15:45:29.953: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Dec  3 15:45:35.004: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pod e2e-test-httpd-pod --namespace=kubectl-1097 -o json'
Dec  3 15:45:35.232: INFO: stderr: ""
Dec  3 15:45:35.232: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"cni.projectcalico.org/podIP\": \"100.64.1.196/32\",\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-12-03T15:45:29Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-1097\",\n        \"resourceVersion\": \"17393\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-1097/pods/e2e-test-httpd-pod\",\n        \"uid\": \"3876cda2-8ebe-45a1-8b55-45a23e03177a\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-dqcb9\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-dqcb9\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-dqcb9\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-03T15:45:29Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-03T15:45:31Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-03T15:45:31Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-03T15:45:29Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"docker://9ef8572044cd721e896478f2939bbcae788a070cca49f29141939ec7e1ae21ba\",\n                \"image\": \"httpd:2.4.38-alpine\",\n                \"imageID\": \"docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-12-03T15:45:30Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.250.0.2\",\n        \"phase\": \"Running\",\n        \"podIP\": \"100.64.1.196\",\n        \"podIPs\": [\n            {\n                \"ip\": \"100.64.1.196\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-12-03T15:45:29Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec  3 15:45:35.232: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config replace -f - --namespace=kubectl-1097'
Dec  3 15:45:35.650: INFO: stderr: ""
Dec  3 15:45:35.650: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Dec  3 15:45:35.661: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pods e2e-test-httpd-pod --namespace=kubectl-1097'
Dec  3 15:45:37.613: INFO: stderr: ""
Dec  3 15:45:37.613: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:45:37.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1097" for this suite.
Dec  3 15:45:43.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:45:44.025: INFO: namespace kubectl-1097 deletion completed in 6.392836133s
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:45:44.025: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1790
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec  3 15:45:44.331: INFO: Waiting up to 5m0s for pod "pod-80fd72b2-1023-4943-b651-08ca12afd82a" in namespace "emptydir-1790" to be "success or failure"
Dec  3 15:45:44.341: INFO: Pod "pod-80fd72b2-1023-4943-b651-08ca12afd82a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.934017ms
Dec  3 15:45:46.351: INFO: Pod "pod-80fd72b2-1023-4943-b651-08ca12afd82a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020688976s
STEP: Saw pod success
Dec  3 15:45:46.351: INFO: Pod "pod-80fd72b2-1023-4943-b651-08ca12afd82a" satisfied condition "success or failure"
Dec  3 15:45:46.361: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-80fd72b2-1023-4943-b651-08ca12afd82a container test-container: <nil>
STEP: delete the pod
Dec  3 15:45:46.395: INFO: Waiting for pod pod-80fd72b2-1023-4943-b651-08ca12afd82a to disappear
Dec  3 15:45:46.405: INFO: Pod pod-80fd72b2-1023-4943-b651-08ca12afd82a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:45:46.405: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1790" for this suite.
Dec  3 15:45:52.455: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:45:52.807: INFO: namespace emptydir-1790 deletion completed in 6.383189464s
•SSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:45:52.807: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2490
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec  3 15:45:53.002: INFO: Waiting up to 5m0s for pod "pod-4b8d8ad1-d9b2-40da-a265-b9dd3bb34908" in namespace "emptydir-2490" to be "success or failure"
Dec  3 15:45:53.012: INFO: Pod "pod-4b8d8ad1-d9b2-40da-a265-b9dd3bb34908": Phase="Pending", Reason="", readiness=false. Elapsed: 10.085633ms
Dec  3 15:45:55.023: INFO: Pod "pod-4b8d8ad1-d9b2-40da-a265-b9dd3bb34908": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021089821s
STEP: Saw pod success
Dec  3 15:45:55.023: INFO: Pod "pod-4b8d8ad1-d9b2-40da-a265-b9dd3bb34908" satisfied condition "success or failure"
Dec  3 15:45:55.034: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-4b8d8ad1-d9b2-40da-a265-b9dd3bb34908 container test-container: <nil>
STEP: delete the pod
Dec  3 15:45:55.067: INFO: Waiting for pod pod-4b8d8ad1-d9b2-40da-a265-b9dd3bb34908 to disappear
Dec  3 15:45:55.077: INFO: Pod pod-4b8d8ad1-d9b2-40da-a265-b9dd3bb34908 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:45:55.077: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2490" for this suite.
Dec  3 15:46:01.133: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:46:01.480: INFO: namespace emptydir-2490 deletion completed in 6.380687s
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:46:01.481: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-661
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:47:01.687: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-661" for this suite.
Dec  3 15:47:29.739: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:47:30.095: INFO: namespace container-probe-661 deletion completed in 28.388298176s
•SSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:47:30.095: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7233
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7233.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-7233.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7233.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-7233.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7233.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7233.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7233.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-7233.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7233.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-7233.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7233.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 121.18.104.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.104.18.121_udp@PTR;check="$$(dig +tcp +noall +answer +search 121.18.104.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.104.18.121_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-7233.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-7233.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-7233.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-7233.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-7233.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-7233.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-7233.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-7233.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-7233.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-7233.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7233.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 121.18.104.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.104.18.121_udp@PTR;check="$$(dig +tcp +noall +answer +search 121.18.104.100.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/100.104.18.121_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 15:47:34.448: INFO: Unable to read wheezy_udp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:34.489: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:34.502: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:34.514: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:34.943: INFO: Unable to read jessie_udp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:34.956: INFO: Unable to read jessie_tcp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:34.968: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:34.980: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:35.354: INFO: Lookups using dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735 failed for: [wheezy_udp@dns-test-service.dns-7233.svc.cluster.local wheezy_tcp@dns-test-service.dns-7233.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local jessie_udp@dns-test-service.dns-7233.svc.cluster.local jessie_tcp@dns-test-service.dns-7233.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local]

Dec  3 15:47:40.367: INFO: Unable to read wheezy_udp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:40.410: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:40.422: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:40.434: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:40.825: INFO: Unable to read jessie_udp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:40.838: INFO: Unable to read jessie_tcp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:40.850: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:40.861: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:41.251: INFO: Lookups using dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735 failed for: [wheezy_udp@dns-test-service.dns-7233.svc.cluster.local wheezy_tcp@dns-test-service.dns-7233.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local jessie_udp@dns-test-service.dns-7233.svc.cluster.local jessie_tcp@dns-test-service.dns-7233.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local]

Dec  3 15:47:45.368: INFO: Unable to read wheezy_udp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:45.411: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:45.423: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:45.435: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:45.827: INFO: Unable to read jessie_udp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:45.839: INFO: Unable to read jessie_tcp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:45.852: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:45.864: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:46.251: INFO: Lookups using dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735 failed for: [wheezy_udp@dns-test-service.dns-7233.svc.cluster.local wheezy_tcp@dns-test-service.dns-7233.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local jessie_udp@dns-test-service.dns-7233.svc.cluster.local jessie_tcp@dns-test-service.dns-7233.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local]

Dec  3 15:47:50.368: INFO: Unable to read wheezy_udp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:50.411: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:50.423: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:50.435: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:50.828: INFO: Unable to read jessie_udp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:50.840: INFO: Unable to read jessie_tcp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:50.852: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:50.865: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:51.254: INFO: Lookups using dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735 failed for: [wheezy_udp@dns-test-service.dns-7233.svc.cluster.local wheezy_tcp@dns-test-service.dns-7233.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local jessie_udp@dns-test-service.dns-7233.svc.cluster.local jessie_tcp@dns-test-service.dns-7233.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local]

Dec  3 15:47:55.367: INFO: Unable to read wheezy_udp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:55.409: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:55.421: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:55.433: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:55.825: INFO: Unable to read jessie_udp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:55.838: INFO: Unable to read jessie_tcp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:55.850: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:55.862: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:47:56.249: INFO: Lookups using dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735 failed for: [wheezy_udp@dns-test-service.dns-7233.svc.cluster.local wheezy_tcp@dns-test-service.dns-7233.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local jessie_udp@dns-test-service.dns-7233.svc.cluster.local jessie_tcp@dns-test-service.dns-7233.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local]

Dec  3 15:48:00.371: INFO: Unable to read wheezy_udp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:48:00.413: INFO: Unable to read wheezy_tcp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:48:00.425: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:48:00.437: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:48:00.827: INFO: Unable to read jessie_udp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:48:00.839: INFO: Unable to read jessie_tcp@dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:48:00.851: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:48:00.862: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local from pod dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735: the server could not find the requested resource (get pods dns-test-afc888e6-04fa-419c-a38b-6d4518974735)
Dec  3 15:48:01.206: INFO: Lookups using dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735 failed for: [wheezy_udp@dns-test-service.dns-7233.svc.cluster.local wheezy_tcp@dns-test-service.dns-7233.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local jessie_udp@dns-test-service.dns-7233.svc.cluster.local jessie_tcp@dns-test-service.dns-7233.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-7233.svc.cluster.local]

Dec  3 15:48:06.606: INFO: DNS probes using dns-7233/dns-test-afc888e6-04fa-419c-a38b-6d4518974735 succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:48:06.664: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7233" for this suite.
Dec  3 15:48:12.707: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:48:13.063: INFO: namespace dns-7233 deletion completed in 6.388012722s
•SSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:48:13.064: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-5573
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec  3 15:48:13.271: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:48:14.323: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-5573" for this suite.
Dec  3 15:48:20.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:48:20.753: INFO: namespace replication-controller-5573 deletion completed in 6.410071506s
•SSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:48:20.753: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4684
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:48:20.959: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4684" for this suite.
Dec  3 15:48:49.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:48:49.349: INFO: namespace pods-4684 deletion completed in 28.380042942s
•SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:48:49.350: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1282
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-cf599194-eb21-4cde-b20d-49fab79afab5
STEP: Creating configMap with name cm-test-opt-upd-f1bc49b3-a77a-430f-8fc8-de8f97c391e2
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-cf599194-eb21-4cde-b20d-49fab79afab5
STEP: Updating configmap cm-test-opt-upd-f1bc49b3-a77a-430f-8fc8-de8f97c391e2
STEP: Creating configMap with name cm-test-opt-create-2342429b-bf42-4d1f-89b9-20e33c32b496
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:48:54.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1282" for this suite.
Dec  3 15:49:06.139: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:49:06.488: INFO: namespace configmap-1282 deletion completed in 12.382297638s
•SSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:49:06.489: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-3818
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec  3 15:49:10.773: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:49:10.783: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 15:49:12.783: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:49:12.794: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 15:49:14.783: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:49:14.794: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 15:49:16.783: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:49:16.794: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 15:49:18.784: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:49:18.794: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 15:49:20.783: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:49:20.795: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 15:49:22.783: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:49:22.794: INFO: Pod pod-with-prestop-http-hook still exists
Dec  3 15:49:24.784: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec  3 15:49:24.794: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:49:24.812: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-3818" for this suite.
Dec  3 15:49:36.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:49:37.216: INFO: namespace container-lifecycle-hook-3818 deletion completed in 12.384962959s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:49:37.216: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-4962
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-4962, will wait for the garbage collector to delete the pods
Dec  3 15:49:39.496: INFO: Deleting Job.batch foo took: 12.2778ms
Dec  3 15:49:39.596: INFO: Terminating Job.batch foo pods took: 100.393899ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:50:24.807: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-4962" for this suite.
Dec  3 15:50:30.861: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:50:31.263: INFO: namespace job-4962 deletion completed in 6.437693746s
•SSSSSSSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:50:31.263: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-669
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec  3 15:50:35.536: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-669 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:50:35.536: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:50:35.984: INFO: Exec stderr: ""
Dec  3 15:50:35.984: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-669 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:50:35.984: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:50:36.504: INFO: Exec stderr: ""
Dec  3 15:50:36.504: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-669 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:50:36.504: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:50:37.007: INFO: Exec stderr: ""
Dec  3 15:50:37.007: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-669 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:50:37.007: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:50:37.454: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec  3 15:50:37.454: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-669 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:50:37.454: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:50:37.903: INFO: Exec stderr: ""
Dec  3 15:50:37.903: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-669 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:50:37.903: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:50:38.402: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec  3 15:50:38.403: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-669 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:50:38.403: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:50:38.899: INFO: Exec stderr: ""
Dec  3 15:50:38.899: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-669 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:50:38.899: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:50:39.401: INFO: Exec stderr: ""
Dec  3 15:50:39.401: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-669 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:50:39.401: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:50:39.841: INFO: Exec stderr: ""
Dec  3 15:50:39.842: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-669 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 15:50:39.842: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 15:50:40.310: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:50:40.310: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-669" for this suite.
Dec  3 15:51:26.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:51:26.729: INFO: namespace e2e-kubelet-etc-hosts-669 deletion completed in 46.400470148s
•
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:51:26.729: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6068
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec  3 15:51:26.933: INFO: Waiting up to 5m0s for pod "downward-api-60ac569d-a1ae-4b04-b394-15e8a581fb75" in namespace "downward-api-6068" to be "success or failure"
Dec  3 15:51:26.943: INFO: Pod "downward-api-60ac569d-a1ae-4b04-b394-15e8a581fb75": Phase="Pending", Reason="", readiness=false. Elapsed: 10.347707ms
Dec  3 15:51:28.954: INFO: Pod "downward-api-60ac569d-a1ae-4b04-b394-15e8a581fb75": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02135532s
STEP: Saw pod success
Dec  3 15:51:28.954: INFO: Pod "downward-api-60ac569d-a1ae-4b04-b394-15e8a581fb75" satisfied condition "success or failure"
Dec  3 15:51:28.965: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downward-api-60ac569d-a1ae-4b04-b394-15e8a581fb75 container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:51:29.102: INFO: Waiting for pod downward-api-60ac569d-a1ae-4b04-b394-15e8a581fb75 to disappear
Dec  3 15:51:29.112: INFO: Pod downward-api-60ac569d-a1ae-4b04-b394-15e8a581fb75 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:51:29.112: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6068" for this suite.
Dec  3 15:51:35.168: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:51:35.528: INFO: namespace downward-api-6068 deletion completed in 6.394642054s
•SSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:51:35.529: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-2634
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-2634
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec  3 15:51:35.750: INFO: Found 0 stateful pods, waiting for 3
Dec  3 15:51:45.763: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:51:45.763: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:51:45.763: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec  3 15:51:45.827: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec  3 15:51:45.881: INFO: Updating stateful set ss2
Dec  3 15:51:45.901: INFO: Waiting for Pod statefulset-2634/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Dec  3 15:51:55.965: INFO: Found 2 stateful pods, waiting for 3
Dec  3 15:52:05.985: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:52:05.985: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:52:05.985: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Pending - Ready=false
Dec  3 15:52:15.978: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:52:15.978: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 15:52:15.978: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec  3 15:52:16.032: INFO: Updating stateful set ss2
Dec  3 15:52:16.053: INFO: Waiting for Pod statefulset-2634/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  3 15:52:26.108: INFO: Updating stateful set ss2
Dec  3 15:52:26.129: INFO: Waiting for StatefulSet statefulset-2634/ss2 to complete update
Dec  3 15:52:26.129: INFO: Waiting for Pod statefulset-2634/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  3 15:52:36.153: INFO: Deleting all statefulset in ns statefulset-2634
Dec  3 15:52:36.164: INFO: Scaling statefulset ss2 to 0
Dec  3 15:53:06.209: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:53:06.220: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:53:06.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-2634" for this suite.
Dec  3 15:53:12.303: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:53:12.696: INFO: namespace statefulset-2634 deletion completed in 6.423966482s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:53:12.696: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7410
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-b4af8310-43de-4604-9916-fae1b53af4df
STEP: Creating a pod to test consume configMaps
Dec  3 15:53:12.899: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-846f6a25-3eff-4920-bcee-c0f3f103cccd" in namespace "projected-7410" to be "success or failure"
Dec  3 15:53:12.910: INFO: Pod "pod-projected-configmaps-846f6a25-3eff-4920-bcee-c0f3f103cccd": Phase="Pending", Reason="", readiness=false. Elapsed: 10.257446ms
Dec  3 15:53:14.921: INFO: Pod "pod-projected-configmaps-846f6a25-3eff-4920-bcee-c0f3f103cccd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021341261s
STEP: Saw pod success
Dec  3 15:53:14.921: INFO: Pod "pod-projected-configmaps-846f6a25-3eff-4920-bcee-c0f3f103cccd" satisfied condition "success or failure"
Dec  3 15:53:14.932: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-projected-configmaps-846f6a25-3eff-4920-bcee-c0f3f103cccd container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:53:15.092: INFO: Waiting for pod pod-projected-configmaps-846f6a25-3eff-4920-bcee-c0f3f103cccd to disappear
Dec  3 15:53:15.102: INFO: Pod pod-projected-configmaps-846f6a25-3eff-4920-bcee-c0f3f103cccd no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:53:15.102: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7410" for this suite.
Dec  3 15:53:21.154: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:53:21.544: INFO: namespace projected-7410 deletion completed in 6.42279033s
•SSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:53:21.544: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-3240
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:53:21.796: INFO: Create a RollingUpdate DaemonSet
Dec  3 15:53:21.808: INFO: Check that daemon pods launch on every node of the cluster
Dec  3 15:53:21.828: INFO: Number of nodes with available pods: 0
Dec  3 15:53:21.828: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:53:22.858: INFO: Number of nodes with available pods: 0
Dec  3 15:53:22.858: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:53:23.859: INFO: Number of nodes with available pods: 2
Dec  3 15:53:23.859: INFO: Number of running nodes: 2, number of available pods: 2
Dec  3 15:53:23.859: INFO: Update the DaemonSet to trigger a rollout
Dec  3 15:53:23.882: INFO: Updating DaemonSet daemon-set
Dec  3 15:53:33.936: INFO: Roll back the DaemonSet before rollout is complete
Dec  3 15:53:33.957: INFO: Updating DaemonSet daemon-set
Dec  3 15:53:33.957: INFO: Make sure DaemonSet rollback is complete
Dec  3 15:53:33.967: INFO: Wrong image for pod: daemon-set-shks7. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec  3 15:53:33.967: INFO: Pod daemon-set-shks7 is not available
Dec  3 15:53:34.989: INFO: Wrong image for pod: daemon-set-shks7. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec  3 15:53:34.989: INFO: Pod daemon-set-shks7 is not available
Dec  3 15:53:35.989: INFO: Wrong image for pod: daemon-set-shks7. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec  3 15:53:35.989: INFO: Pod daemon-set-shks7 is not available
Dec  3 15:53:36.988: INFO: Pod daemon-set-86d8d is not available
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-3240, will wait for the garbage collector to delete the pods
Dec  3 15:53:37.102: INFO: Deleting DaemonSet.extensions daemon-set took: 12.582151ms
Dec  3 15:53:37.202: INFO: Terminating DaemonSet.extensions daemon-set pods took: 100.263266ms
Dec  3 15:53:39.013: INFO: Number of nodes with available pods: 0
Dec  3 15:53:39.013: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 15:53:39.023: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-3240/daemonsets","resourceVersion":"19113"},"items":null}

Dec  3 15:53:39.033: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-3240/pods","resourceVersion":"19113"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:53:39.074: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-3240" for this suite.
Dec  3 15:53:45.116: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:53:45.466: INFO: namespace daemonsets-3240 deletion completed in 6.382031804s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:53:45.467: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1158
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Dec  3 15:53:45.661: INFO: Waiting up to 5m0s for pod "client-containers-d4209dd5-790d-4058-bde5-2f679925fe39" in namespace "containers-1158" to be "success or failure"
Dec  3 15:53:45.671: INFO: Pod "client-containers-d4209dd5-790d-4058-bde5-2f679925fe39": Phase="Pending", Reason="", readiness=false. Elapsed: 10.20206ms
Dec  3 15:53:47.683: INFO: Pod "client-containers-d4209dd5-790d-4058-bde5-2f679925fe39": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021660584s
STEP: Saw pod success
Dec  3 15:53:47.683: INFO: Pod "client-containers-d4209dd5-790d-4058-bde5-2f679925fe39" satisfied condition "success or failure"
Dec  3 15:53:47.693: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod client-containers-d4209dd5-790d-4058-bde5-2f679925fe39 container test-container: <nil>
STEP: delete the pod
Dec  3 15:53:47.727: INFO: Waiting for pod client-containers-d4209dd5-790d-4058-bde5-2f679925fe39 to disappear
Dec  3 15:53:47.737: INFO: Pod client-containers-d4209dd5-790d-4058-bde5-2f679925fe39 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:53:47.737: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1158" for this suite.
Dec  3 15:53:53.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:53:54.175: INFO: namespace containers-1158 deletion completed in 6.41794191s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:53:54.175: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-50
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Dec  3 15:53:54.914: INFO: created pod pod-service-account-defaultsa
Dec  3 15:53:54.914: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec  3 15:53:54.925: INFO: created pod pod-service-account-mountsa
Dec  3 15:53:54.925: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec  3 15:53:54.936: INFO: created pod pod-service-account-nomountsa
Dec  3 15:53:54.936: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec  3 15:53:54.947: INFO: created pod pod-service-account-defaultsa-mountspec
Dec  3 15:53:54.947: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec  3 15:53:54.959: INFO: created pod pod-service-account-mountsa-mountspec
Dec  3 15:53:54.959: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec  3 15:53:54.970: INFO: created pod pod-service-account-nomountsa-mountspec
Dec  3 15:53:54.970: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec  3 15:53:54.981: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec  3 15:53:54.981: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec  3 15:53:54.992: INFO: created pod pod-service-account-mountsa-nomountspec
Dec  3 15:53:54.992: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec  3 15:53:55.003: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec  3 15:53:55.003: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:53:55.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-50" for this suite.
Dec  3 15:54:07.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:54:07.406: INFO: namespace svcaccounts-50 deletion completed in 12.384696138s
•SSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:54:07.407: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7247
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-9fmm
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 15:54:07.622: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-9fmm" in namespace "subpath-7247" to be "success or failure"
Dec  3 15:54:07.633: INFO: Pod "pod-subpath-test-configmap-9fmm": Phase="Pending", Reason="", readiness=false. Elapsed: 10.487715ms
Dec  3 15:54:09.644: INFO: Pod "pod-subpath-test-configmap-9fmm": Phase="Running", Reason="", readiness=true. Elapsed: 2.021647185s
Dec  3 15:54:11.654: INFO: Pod "pod-subpath-test-configmap-9fmm": Phase="Running", Reason="", readiness=true. Elapsed: 4.032307553s
Dec  3 15:54:13.666: INFO: Pod "pod-subpath-test-configmap-9fmm": Phase="Running", Reason="", readiness=true. Elapsed: 6.043548138s
Dec  3 15:54:15.677: INFO: Pod "pod-subpath-test-configmap-9fmm": Phase="Running", Reason="", readiness=true. Elapsed: 8.054574522s
Dec  3 15:54:17.687: INFO: Pod "pod-subpath-test-configmap-9fmm": Phase="Running", Reason="", readiness=true. Elapsed: 10.065196834s
Dec  3 15:54:19.698: INFO: Pod "pod-subpath-test-configmap-9fmm": Phase="Running", Reason="", readiness=true. Elapsed: 12.076059s
Dec  3 15:54:21.709: INFO: Pod "pod-subpath-test-configmap-9fmm": Phase="Running", Reason="", readiness=true. Elapsed: 14.087109981s
Dec  3 15:54:23.720: INFO: Pod "pod-subpath-test-configmap-9fmm": Phase="Running", Reason="", readiness=true. Elapsed: 16.09832416s
Dec  3 15:54:25.732: INFO: Pod "pod-subpath-test-configmap-9fmm": Phase="Running", Reason="", readiness=true. Elapsed: 18.109469733s
Dec  3 15:54:27.743: INFO: Pod "pod-subpath-test-configmap-9fmm": Phase="Running", Reason="", readiness=true. Elapsed: 20.121128812s
Dec  3 15:54:29.754: INFO: Pod "pod-subpath-test-configmap-9fmm": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.132065298s
STEP: Saw pod success
Dec  3 15:54:29.754: INFO: Pod "pod-subpath-test-configmap-9fmm" satisfied condition "success or failure"
Dec  3 15:54:29.765: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-subpath-test-configmap-9fmm container test-container-subpath-configmap-9fmm: <nil>
STEP: delete the pod
Dec  3 15:54:29.802: INFO: Waiting for pod pod-subpath-test-configmap-9fmm to disappear
Dec  3 15:54:29.812: INFO: Pod pod-subpath-test-configmap-9fmm no longer exists
STEP: Deleting pod pod-subpath-test-configmap-9fmm
Dec  3 15:54:29.812: INFO: Deleting pod "pod-subpath-test-configmap-9fmm" in namespace "subpath-7247"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:54:29.822: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7247" for this suite.
Dec  3 15:54:35.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:54:36.226: INFO: namespace subpath-7247 deletion completed in 6.38477087s
•SSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:54:36.227: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-8144
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:54:36.430: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  3 15:54:38.452: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec  3 15:54:42.535: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-8144 /apis/apps/v1/namespaces/deployment-8144/deployments/test-cleanup-deployment 1e28a616-14e2-42ea-8d76-6cc3e800f347 19422 1 2019-12-03 15:54:38 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[deployment.kubernetes.io/revision:1] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc005215a08 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-03 15:54:38 +0000 UTC,LastTransitionTime:2019-12-03 15:54:38 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-cleanup-deployment-65db99849b" has successfully progressed.,LastUpdateTime:2019-12-03 15:54:40 +0000 UTC,LastTransitionTime:2019-12-03 15:54:38 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 15:54:42.546: INFO: New ReplicaSet "test-cleanup-deployment-65db99849b" of Deployment "test-cleanup-deployment":
&ReplicaSet{ObjectMeta:{test-cleanup-deployment-65db99849b  deployment-8144 /apis/apps/v1/namespaces/deployment-8144/replicasets/test-cleanup-deployment-65db99849b b4442ec5-da3c-447d-a623-02295f6af703 19415 1 2019-12-03 15:54:38 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-cleanup-deployment 1e28a616-14e2-42ea-8d76-6cc3e800f347 0xc000f48567 0xc000f48568}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod-template-hash: 65db99849b,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc000f485c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec  3 15:54:42.557: INFO: Pod "test-cleanup-deployment-65db99849b-tmpw6" is available:
&Pod{ObjectMeta:{test-cleanup-deployment-65db99849b-tmpw6 test-cleanup-deployment-65db99849b- deployment-8144 /api/v1/namespaces/deployment-8144/pods/test-cleanup-deployment-65db99849b-tmpw6 5fcb72d5-cd53-4caa-a845-b375f275d587 19414 0 2019-12-03 15:54:38 +0000 UTC <nil> <nil> map[name:cleanup-pod pod-template-hash:65db99849b] map[cni.projectcalico.org/podIP:100.64.1.231/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-cleanup-deployment-65db99849b b4442ec5-da3c-447d-a623-02295f6af703 0xc000f48d77 0xc000f48d78}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-swplg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-swplg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-swplg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:54:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:54:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:54:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:54:38 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.2,PodIP:100.64.1.231,StartTime:2019-12-03 15:54:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 15:54:39 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://6773c21e3309a82cddeb46b38bec69be27798c3fcec9ffac2292fddd3e92e0e0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.231,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:54:42.557: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-8144" for this suite.
Dec  3 15:54:48.609: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:54:48.972: INFO: namespace deployment-8144 deletion completed in 6.395763741s
•SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:54:48.972: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6436
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:54:49.845: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985289, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985289, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985289, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985289, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:54:51.856: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985289, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985289, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985289, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985289, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:54:54.873: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:54:55.150: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6436" for this suite.
Dec  3 15:55:01.203: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:55:01.591: INFO: namespace webhook-6436 deletion completed in 6.421374678s
STEP: Destroying namespace "webhook-6436-markers" for this suite.
Dec  3 15:55:07.623: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:55:07.975: INFO: namespace webhook-6436-markers deletion completed in 6.383349162s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:55:08.018: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-544
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec  3 15:55:08.204: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 15:55:08.238: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 15:55:08.248: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 before test
Dec  3 15:55:08.369: INFO: calico-typha-deploy-9f6b455c4-6ntkq from kube-system started at 2019-12-03 15:09:21 +0000 UTC (1 container statuses recorded)
Dec  3 15:55:08.369: INFO: 	Container calico-typha ready: true, restart count 0
Dec  3 15:55:08.369: INFO: node-exporter-pwl5b from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 15:55:08.369: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:55:08.369: INFO: kube-proxy-qzrrc from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 15:55:08.369: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 15:55:08.369: INFO: metrics-server-7df74c5758-hnsgs from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:55:08.369: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 15:55:08.369: INFO: calico-node-rc24j from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 15:55:08.369: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:55:08.369: INFO: coredns-59c969ffb8-jwpjr from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:55:08.369: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:55:08.369: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-95f65778d-nb2sc from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:55:08.369: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec  3 15:55:08.369: INFO: calico-kube-controllers-79bcd784b6-pkrdg from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:55:08.369: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  3 15:55:08.369: INFO: addons-kubernetes-dashboard-78954cc66b-gjdxd from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:55:08.369: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  3 15:55:08.370: INFO: calico-typha-horizontal-autoscaler-69df649c59-7l6bk from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:55:08.370: INFO: 	Container autoscaler ready: true, restart count 0
Dec  3 15:55:08.370: INFO: addons-nginx-ingress-controller-7c75bb76db-zkqv8 from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:55:08.370: INFO: 	Container nginx-ingress-controller ready: true, restart count 1
Dec  3 15:55:08.370: INFO: calico-typha-vertical-autoscaler-847d859f8c-vfvq7 from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:55:08.370: INFO: 	Container autoscaler ready: true, restart count 3
Dec  3 15:55:08.370: INFO: coredns-59c969ffb8-p9rws from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:55:08.370: INFO: 	Container coredns ready: true, restart count 0
Dec  3 15:55:08.370: INFO: vpn-shoot-5689b7f9b4-n47mb from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 15:55:08.370: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec  3 15:55:08.370: INFO: blackbox-exporter-7bd7b55dfc-7ktvk from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 15:55:08.370: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec  3 15:55:08.370: INFO: node-problem-detector-xwvwh from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 15:55:08.370: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:55:08.370: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz before test
Dec  3 15:55:08.413: INFO: calico-node-zhw8c from kube-system started at 2019-12-03 14:27:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:55:08.413: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 15:55:08.413: INFO: node-exporter-fmmk4 from kube-system started at 2019-12-03 14:27:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:55:08.413: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 15:55:08.413: INFO: node-problem-detector-4c7x7 from kube-system started at 2019-12-03 14:27:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:55:08.413: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 15:55:08.413: INFO: kube-proxy-n42lb from kube-system started at 2019-12-03 14:27:15 +0000 UTC (1 container statuses recorded)
Dec  3 15:55:08.413: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6
STEP: verifying the node has the label node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz
Dec  3 15:55:08.493: INFO: Pod addons-kubernetes-dashboard-78954cc66b-gjdxd requesting resource cpu=50m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6
Dec  3 15:55:08.493: INFO: Pod addons-nginx-ingress-controller-7c75bb76db-zkqv8 requesting resource cpu=100m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6
Dec  3 15:55:08.493: INFO: Pod addons-nginx-ingress-nginx-ingress-k8s-backend-95f65778d-nb2sc requesting resource cpu=0m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6
Dec  3 15:55:08.493: INFO: Pod blackbox-exporter-7bd7b55dfc-7ktvk requesting resource cpu=5m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6
Dec  3 15:55:08.493: INFO: Pod calico-kube-controllers-79bcd784b6-pkrdg requesting resource cpu=0m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6
Dec  3 15:55:08.493: INFO: Pod calico-node-rc24j requesting resource cpu=100m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6
Dec  3 15:55:08.493: INFO: Pod calico-node-zhw8c requesting resource cpu=100m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz
Dec  3 15:55:08.493: INFO: Pod calico-typha-deploy-9f6b455c4-6ntkq requesting resource cpu=0m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6
Dec  3 15:55:08.493: INFO: Pod calico-typha-horizontal-autoscaler-69df649c59-7l6bk requesting resource cpu=10m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6
Dec  3 15:55:08.493: INFO: Pod calico-typha-vertical-autoscaler-847d859f8c-vfvq7 requesting resource cpu=0m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6
Dec  3 15:55:08.493: INFO: Pod coredns-59c969ffb8-jwpjr requesting resource cpu=50m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6
Dec  3 15:55:08.493: INFO: Pod coredns-59c969ffb8-p9rws requesting resource cpu=50m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6
Dec  3 15:55:08.493: INFO: Pod kube-proxy-n42lb requesting resource cpu=20m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz
Dec  3 15:55:08.493: INFO: Pod kube-proxy-qzrrc requesting resource cpu=20m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6
Dec  3 15:55:08.493: INFO: Pod metrics-server-7df74c5758-hnsgs requesting resource cpu=20m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6
Dec  3 15:55:08.493: INFO: Pod node-exporter-fmmk4 requesting resource cpu=5m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz
Dec  3 15:55:08.493: INFO: Pod node-exporter-pwl5b requesting resource cpu=5m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6
Dec  3 15:55:08.493: INFO: Pod node-problem-detector-4c7x7 requesting resource cpu=20m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz
Dec  3 15:55:08.493: INFO: Pod node-problem-detector-xwvwh requesting resource cpu=20m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6
Dec  3 15:55:08.493: INFO: Pod vpn-shoot-5689b7f9b4-n47mb requesting resource cpu=100m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6
STEP: Starting Pods to consume most of the cluster CPU.
Dec  3 15:55:08.493: INFO: Creating a pod which consumes cpu=973m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6
Dec  3 15:55:08.506: INFO: Creating a pod which consumes cpu=1242m on Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2898218e-4c81-4e94-b681-2c6f3cf5aa5c.15dce78070c78dc4], Reason = [Scheduled], Message = [Successfully assigned sched-pred-544/filler-pod-2898218e-4c81-4e94-b681-2c6f3cf5aa5c to shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2898218e-4c81-4e94-b681-2c6f3cf5aa5c.15dce7809b0cb6dd], Reason = [Pulling], Message = [Pulling image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2898218e-4c81-4e94-b681-2c6f3cf5aa5c.15dce780b3e03e3c], Reason = [Pulled], Message = [Successfully pulled image "k8s.gcr.io/pause:3.1"]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2898218e-4c81-4e94-b681-2c6f3cf5aa5c.15dce780b88ac31b], Reason = [Created], Message = [Created container filler-pod-2898218e-4c81-4e94-b681-2c6f3cf5aa5c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-2898218e-4c81-4e94-b681-2c6f3cf5aa5c.15dce780c1561925], Reason = [Started], Message = [Started container filler-pod-2898218e-4c81-4e94-b681-2c6f3cf5aa5c]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3a1fdc75-7503-4069-aa9c-c761c1fab170.15dce780715eed91], Reason = [Scheduled], Message = [Successfully assigned sched-pred-544/filler-pod-3a1fdc75-7503-4069-aa9c-c761c1fab170 to shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3a1fdc75-7503-4069-aa9c-c761c1fab170.15dce780a4084818], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3a1fdc75-7503-4069-aa9c-c761c1fab170.15dce780a6df8b22], Reason = [Created], Message = [Created container filler-pod-3a1fdc75-7503-4069-aa9c-c761c1fab170]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-3a1fdc75-7503-4069-aa9c-c761c1fab170.15dce780b0163ae2], Reason = [Started], Message = [Started container filler-pod-3a1fdc75-7503-4069-aa9c-c761c1fab170]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15dce780ec49708f], Reason = [FailedScheduling], Message = [0/2 nodes are available: 2 Insufficient cpu.]
STEP: removing the label node off the node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:55:11.661: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-544" for this suite.
Dec  3 15:55:17.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:55:18.053: INFO: namespace sched-pred-544 deletion completed in 6.381171615s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
•SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:55:18.053: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-5882
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-5882
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-5882
STEP: Creating statefulset with conflicting port in namespace statefulset-5882
STEP: Waiting until pod test-pod will start running in namespace statefulset-5882
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-5882
Dec  3 15:55:20.311: INFO: Observed stateful pod in namespace: statefulset-5882, name: ss-0, uid: 3ac14ae6-30b2-4cc7-ac20-2dc60fac25df, status phase: Failed. Waiting for statefulset controller to delete.
Dec  3 15:55:20.337: INFO: Observed stateful pod in namespace: statefulset-5882, name: ss-0, uid: 3ac14ae6-30b2-4cc7-ac20-2dc60fac25df, status phase: Failed. Waiting for statefulset controller to delete.
Dec  3 15:55:20.339: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-5882
STEP: Removing pod with conflicting port in namespace statefulset-5882
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-5882 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  3 15:55:22.376: INFO: Deleting all statefulset in ns statefulset-5882
Dec  3 15:55:22.387: INFO: Scaling statefulset ss to 0
Dec  3 15:55:32.432: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 15:55:32.442: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:55:32.477: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-5882" for this suite.
Dec  3 15:55:38.530: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:55:38.896: INFO: namespace statefulset-5882 deletion completed in 6.399802871s
•SSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:55:38.897: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6940
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:55:43.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6940" for this suite.
Dec  3 15:55:49.165: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:55:49.562: INFO: namespace kubelet-test-6940 deletion completed in 6.429377664s
•SSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:55:49.562: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-7140
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:55:49.746: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec  3 15:55:52.396: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7140 create -f -'
Dec  3 15:55:52.940: INFO: stderr: ""
Dec  3 15:55:52.940: INFO: stdout: "e2e-test-crd-publish-openapi-7394-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec  3 15:55:52.940: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7140 delete e2e-test-crd-publish-openapi-7394-crds test-cr'
Dec  3 15:55:53.066: INFO: stderr: ""
Dec  3 15:55:53.066: INFO: stdout: "e2e-test-crd-publish-openapi-7394-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Dec  3 15:55:53.066: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7140 apply -f -'
Dec  3 15:55:53.278: INFO: stderr: ""
Dec  3 15:55:53.278: INFO: stdout: "e2e-test-crd-publish-openapi-7394-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec  3 15:55:53.278: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-7140 delete e2e-test-crd-publish-openapi-7394-crds test-cr'
Dec  3 15:55:53.403: INFO: stderr: ""
Dec  3 15:55:53.403: INFO: stdout: "e2e-test-crd-publish-openapi-7394-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Dec  3 15:55:53.403: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-7394-crds'
Dec  3 15:55:53.587: INFO: stderr: ""
Dec  3 15:55:53.587: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-7394-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:55:56.681: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-7140" for this suite.
Dec  3 15:56:02.733: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:56:03.095: INFO: namespace crd-publish-openapi-7140 deletion completed in 6.394339695s
•SSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:56:03.095: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3544
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:56:03.279: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Dec  3 15:56:06.373: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3544 create -f -'
Dec  3 15:56:06.910: INFO: stderr: ""
Dec  3 15:56:06.910: INFO: stdout: "e2e-test-crd-publish-openapi-4539-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec  3 15:56:06.910: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3544 delete e2e-test-crd-publish-openapi-4539-crds test-foo'
Dec  3 15:56:07.027: INFO: stderr: ""
Dec  3 15:56:07.027: INFO: stdout: "e2e-test-crd-publish-openapi-4539-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Dec  3 15:56:07.027: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3544 apply -f -'
Dec  3 15:56:07.249: INFO: stderr: ""
Dec  3 15:56:07.249: INFO: stdout: "e2e-test-crd-publish-openapi-4539-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec  3 15:56:07.249: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3544 delete e2e-test-crd-publish-openapi-4539-crds test-foo'
Dec  3 15:56:07.365: INFO: stderr: ""
Dec  3 15:56:07.365: INFO: stdout: "e2e-test-crd-publish-openapi-4539-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Dec  3 15:56:07.365: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3544 create -f -'
Dec  3 15:56:07.601: INFO: rc: 1
Dec  3 15:56:07.601: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3544 apply -f -'
Dec  3 15:56:07.838: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Dec  3 15:56:07.838: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3544 create -f -'
Dec  3 15:56:08.081: INFO: rc: 1
Dec  3 15:56:08.081: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config --namespace=crd-publish-openapi-3544 apply -f -'
Dec  3 15:56:08.320: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Dec  3 15:56:08.320: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-4539-crds'
Dec  3 15:56:08.554: INFO: stderr: ""
Dec  3 15:56:08.554: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4539-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Dec  3 15:56:08.554: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-4539-crds.metadata'
Dec  3 15:56:08.733: INFO: stderr: ""
Dec  3 15:56:08.733: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4539-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Dec  3 15:56:08.734: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-4539-crds.spec'
Dec  3 15:56:08.969: INFO: stderr: ""
Dec  3 15:56:08.969: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4539-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Dec  3 15:56:08.970: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-4539-crds.spec.bars'
Dec  3 15:56:09.208: INFO: stderr: ""
Dec  3 15:56:09.208: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-4539-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Dec  3 15:56:09.208: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config explain e2e-test-crd-publish-openapi-4539-crds.spec.bars2'
Dec  3 15:56:09.450: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:56:12.583: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3544" for this suite.
Dec  3 15:56:18.634: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:56:18.982: INFO: namespace crd-publish-openapi-3544 deletion completed in 6.380055864s
•SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:56:18.982: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9618
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  3 15:56:19.162: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-9618'
Dec  3 15:56:19.279: INFO: stderr: ""
Dec  3 15:56:19.279: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Dec  3 15:56:19.289: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete pods e2e-test-httpd-pod --namespace=kubectl-9618'
Dec  3 15:56:24.767: INFO: stderr: ""
Dec  3 15:56:24.767: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:56:24.767: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9618" for this suite.
Dec  3 15:56:30.818: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:56:31.216: INFO: namespace kubectl-9618 deletion completed in 6.431065106s
•SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:56:31.217: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5176
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  3 15:56:31.401: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-5176'
Dec  3 15:56:31.533: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 15:56:31.533: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: rolling-update to same image controller
Dec  3 15:56:31.554: INFO: scanned /root for discovery docs: <nil>
Dec  3 15:56:31.554: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-5176'
Dec  3 15:56:44.462: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec  3 15:56:44.462: INFO: stdout: "Created e2e-test-httpd-rc-4a0fbf8683345ea347e02bd6d3459fa0\nScaling up e2e-test-httpd-rc-4a0fbf8683345ea347e02bd6d3459fa0 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-4a0fbf8683345ea347e02bd6d3459fa0 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-4a0fbf8683345ea347e02bd6d3459fa0 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Dec  3 15:56:44.462: INFO: stdout: "Created e2e-test-httpd-rc-4a0fbf8683345ea347e02bd6d3459fa0\nScaling up e2e-test-httpd-rc-4a0fbf8683345ea347e02bd6d3459fa0 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-4a0fbf8683345ea347e02bd6d3459fa0 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-4a0fbf8683345ea347e02bd6d3459fa0 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Dec  3 15:56:44.462: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-5176'
Dec  3 15:56:44.669: INFO: stderr: ""
Dec  3 15:56:44.669: INFO: stdout: "e2e-test-httpd-rc-4a0fbf8683345ea347e02bd6d3459fa0-rx2nx e2e-test-httpd-rc-6ns2c "
STEP: Replicas for run=e2e-test-httpd-rc: expected=1 actual=2
Dec  3 15:56:49.669: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-5176'
Dec  3 15:56:49.776: INFO: stderr: ""
Dec  3 15:56:49.776: INFO: stdout: "e2e-test-httpd-rc-4a0fbf8683345ea347e02bd6d3459fa0-rx2nx "
Dec  3 15:56:49.776: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods e2e-test-httpd-rc-4a0fbf8683345ea347e02bd6d3459fa0-rx2nx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-5176'
Dec  3 15:56:49.882: INFO: stderr: ""
Dec  3 15:56:49.882: INFO: stdout: "true"
Dec  3 15:56:49.882: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods e2e-test-httpd-rc-4a0fbf8683345ea347e02bd6d3459fa0-rx2nx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-5176'
Dec  3 15:56:49.985: INFO: stderr: ""
Dec  3 15:56:49.985: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Dec  3 15:56:49.985: INFO: e2e-test-httpd-rc-4a0fbf8683345ea347e02bd6d3459fa0-rx2nx is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Dec  3 15:56:49.985: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete rc e2e-test-httpd-rc --namespace=kubectl-5176'
Dec  3 15:56:50.106: INFO: stderr: ""
Dec  3 15:56:50.106: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:56:50.107: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5176" for this suite.
Dec  3 15:56:56.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:56:56.510: INFO: namespace kubectl-5176 deletion completed in 6.383764492s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:56:56.511: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4686
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-4686/configmap-test-0ff4a17c-b515-4d67-9db8-7a8cfb4a4fb6
STEP: Creating a pod to test consume configMaps
Dec  3 15:56:56.718: INFO: Waiting up to 5m0s for pod "pod-configmaps-db274be4-6b7e-414b-8a6d-de5aeb6badfc" in namespace "configmap-4686" to be "success or failure"
Dec  3 15:56:56.727: INFO: Pod "pod-configmaps-db274be4-6b7e-414b-8a6d-de5aeb6badfc": Phase="Pending", Reason="", readiness=false. Elapsed: 9.766516ms
Dec  3 15:56:58.739: INFO: Pod "pod-configmaps-db274be4-6b7e-414b-8a6d-de5aeb6badfc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021092785s
STEP: Saw pod success
Dec  3 15:56:58.739: INFO: Pod "pod-configmaps-db274be4-6b7e-414b-8a6d-de5aeb6badfc" satisfied condition "success or failure"
Dec  3 15:56:58.749: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-configmaps-db274be4-6b7e-414b-8a6d-de5aeb6badfc container env-test: <nil>
STEP: delete the pod
Dec  3 15:56:58.889: INFO: Waiting for pod pod-configmaps-db274be4-6b7e-414b-8a6d-de5aeb6badfc to disappear
Dec  3 15:56:58.899: INFO: Pod pod-configmaps-db274be4-6b7e-414b-8a6d-de5aeb6badfc no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:56:58.899: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4686" for this suite.
Dec  3 15:57:04.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:57:05.312: INFO: namespace configmap-4686 deletion completed in 6.394505947s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:57:05.313: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-7980
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Dec  3 15:57:05.497: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy --unix-socket=/tmp/kubectl-proxy-unix836592005/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:57:05.576: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-7980" for this suite.
Dec  3 15:57:11.622: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:57:12.007: INFO: namespace kubectl-7980 deletion completed in 6.419585471s
•
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:57:12.007: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-4998
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:57:12.250: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec  3 15:57:12.282: INFO: Number of nodes with available pods: 0
Dec  3 15:57:12.282: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:57:13.311: INFO: Number of nodes with available pods: 0
Dec  3 15:57:13.311: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 15:57:14.312: INFO: Number of nodes with available pods: 2
Dec  3 15:57:14.312: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec  3 15:57:14.388: INFO: Wrong image for pod: daemon-set-65fbh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:57:14.389: INFO: Wrong image for pod: daemon-set-vlglv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:57:15.410: INFO: Wrong image for pod: daemon-set-65fbh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:57:15.411: INFO: Wrong image for pod: daemon-set-vlglv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:57:16.410: INFO: Wrong image for pod: daemon-set-65fbh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:57:16.411: INFO: Wrong image for pod: daemon-set-vlglv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:57:17.410: INFO: Wrong image for pod: daemon-set-65fbh. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:57:17.410: INFO: Pod daemon-set-65fbh is not available
Dec  3 15:57:17.410: INFO: Wrong image for pod: daemon-set-vlglv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:57:18.411: INFO: Pod daemon-set-czxb4 is not available
Dec  3 15:57:18.411: INFO: Wrong image for pod: daemon-set-vlglv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:57:19.411: INFO: Wrong image for pod: daemon-set-vlglv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:57:20.410: INFO: Wrong image for pod: daemon-set-vlglv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:57:20.410: INFO: Pod daemon-set-vlglv is not available
Dec  3 15:57:21.411: INFO: Wrong image for pod: daemon-set-vlglv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:57:21.411: INFO: Pod daemon-set-vlglv is not available
Dec  3 15:57:22.411: INFO: Wrong image for pod: daemon-set-vlglv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:57:22.411: INFO: Pod daemon-set-vlglv is not available
Dec  3 15:57:23.411: INFO: Wrong image for pod: daemon-set-vlglv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:57:23.411: INFO: Pod daemon-set-vlglv is not available
Dec  3 15:57:24.411: INFO: Wrong image for pod: daemon-set-vlglv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec  3 15:57:24.411: INFO: Pod daemon-set-vlglv is not available
Dec  3 15:57:25.411: INFO: Pod daemon-set-99926 is not available
STEP: Check that daemon pods are still running on every node of the cluster.
Dec  3 15:57:25.451: INFO: Number of nodes with available pods: 1
Dec  3 15:57:25.451: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz is running more than one daemon pod
Dec  3 15:57:26.482: INFO: Number of nodes with available pods: 2
Dec  3 15:57:26.482: INFO: Number of running nodes: 2, number of available pods: 2
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-4998, will wait for the garbage collector to delete the pods
Dec  3 15:57:26.610: INFO: Deleting DaemonSet.extensions daemon-set took: 13.330842ms
Dec  3 15:57:27.010: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.396863ms
Dec  3 15:57:34.820: INFO: Number of nodes with available pods: 0
Dec  3 15:57:34.821: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 15:57:34.830: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-4998/daemonsets","resourceVersion":"20323"},"items":null}

Dec  3 15:57:34.840: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-4998/pods","resourceVersion":"20323"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:57:34.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-4998" for this suite.
Dec  3 15:57:40.923: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:57:41.279: INFO: namespace daemonsets-4998 deletion completed in 6.388920886s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:57:41.280: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-8393
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Dec  3 15:57:41.478: INFO: Waiting up to 5m0s for pod "var-expansion-8398c527-3e8e-4136-b5f4-8178da7e562a" in namespace "var-expansion-8393" to be "success or failure"
Dec  3 15:57:41.488: INFO: Pod "var-expansion-8398c527-3e8e-4136-b5f4-8178da7e562a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.053779ms
Dec  3 15:57:43.499: INFO: Pod "var-expansion-8398c527-3e8e-4136-b5f4-8178da7e562a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020665074s
STEP: Saw pod success
Dec  3 15:57:43.499: INFO: Pod "var-expansion-8398c527-3e8e-4136-b5f4-8178da7e562a" satisfied condition "success or failure"
Dec  3 15:57:43.509: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod var-expansion-8398c527-3e8e-4136-b5f4-8178da7e562a container dapi-container: <nil>
STEP: delete the pod
Dec  3 15:57:43.543: INFO: Waiting for pod var-expansion-8398c527-3e8e-4136-b5f4-8178da7e562a to disappear
Dec  3 15:57:43.553: INFO: Pod var-expansion-8398c527-3e8e-4136-b5f4-8178da7e562a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:57:43.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8393" for this suite.
Dec  3 15:57:49.605: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:57:49.989: INFO: namespace var-expansion-8393 deletion completed in 6.416947779s
•SSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:57:49.990: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4907
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-5320324f-ff18-43d6-a248-8aae376dff06
STEP: Creating a pod to test consume secrets
Dec  3 15:57:50.199: INFO: Waiting up to 5m0s for pod "pod-secrets-4d3a5c69-50ac-4a71-b5ee-bd195043ce34" in namespace "secrets-4907" to be "success or failure"
Dec  3 15:57:50.209: INFO: Pod "pod-secrets-4d3a5c69-50ac-4a71-b5ee-bd195043ce34": Phase="Pending", Reason="", readiness=false. Elapsed: 10.246138ms
Dec  3 15:57:52.221: INFO: Pod "pod-secrets-4d3a5c69-50ac-4a71-b5ee-bd195043ce34": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022120398s
STEP: Saw pod success
Dec  3 15:57:52.221: INFO: Pod "pod-secrets-4d3a5c69-50ac-4a71-b5ee-bd195043ce34" satisfied condition "success or failure"
Dec  3 15:57:52.231: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-secrets-4d3a5c69-50ac-4a71-b5ee-bd195043ce34 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 15:57:52.262: INFO: Waiting for pod pod-secrets-4d3a5c69-50ac-4a71-b5ee-bd195043ce34 to disappear
Dec  3 15:57:52.272: INFO: Pod pod-secrets-4d3a5c69-50ac-4a71-b5ee-bd195043ce34 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:57:52.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4907" for this suite.
Dec  3 15:57:58.324: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:57:58.674: INFO: namespace secrets-4907 deletion completed in 6.382536706s
•SSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:57:58.674: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-131
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec  3 15:57:59.455: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985479, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985479, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985479, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985479, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 15:58:01.466: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985479, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985479, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985479, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985479, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 15:58:04.483: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:58:04.493: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:58:05.442: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-131" for this suite.
Dec  3 15:58:11.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:58:11.848: INFO: namespace crd-webhook-131 deletion completed in 6.387253706s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137
•SS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:58:11.891: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5326
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:58:12.075: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config version'
Dec  3 15:58:12.248: INFO: stderr: ""
Dec  3 15:58:12.248: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.3\", GitCommit:\"b3cbbae08ec52a7fc73d334838e18d17e8512749\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:23:11Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.3\", GitCommit:\"b3cbbae08ec52a7fc73d334838e18d17e8512749\", GitTreeState:\"clean\", BuildDate:\"2019-11-13T11:13:49Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:58:12.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5326" for this suite.
Dec  3 15:58:18.293: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:58:18.680: INFO: namespace kubectl-5326 deletion completed in 6.420760533s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:58:18.681: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6496
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-6496
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-6496
I1203 15:58:18.911022    5064 runners.go:184] Created replication controller with name: externalname-service, namespace: services-6496, replica count: 2
Dec  3 15:58:21.961: INFO: Creating new exec pod
I1203 15:58:21.961493    5064 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 15:58:24.994: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-6496 execpodzjt7s -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec  3 15:58:25.531: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec  3 15:58:25.531: INFO: stdout: ""
Dec  3 15:58:25.532: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-6496 execpodzjt7s -- /bin/sh -x -c nc -zv -t -w 2 100.104.110.52 80'
Dec  3 15:58:26.068: INFO: stderr: "+ nc -zv -t -w 2 100.104.110.52 80\nConnection to 100.104.110.52 80 port [tcp/http] succeeded!\n"
Dec  3 15:58:26.068: INFO: stdout: ""
Dec  3 15:58:26.068: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:58:26.087: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6496" for this suite.
Dec  3 15:58:32.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:58:32.492: INFO: namespace services-6496 deletion completed in 6.386841981s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:58:32.493: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3220
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-3220
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-3220
STEP: creating replication controller externalsvc in namespace services-3220
I1203 15:58:32.721602    5064 runners.go:184] Created replication controller with name: externalsvc, namespace: services-3220, replica count: 2
I1203 15:58:35.772222    5064 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Dec  3 15:58:35.809: INFO: Creating new exec pod
Dec  3 15:58:37.842: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-3220 execpodrtpl4 -- /bin/sh -x -c nslookup clusterip-service'
Dec  3 15:58:38.372: INFO: stderr: "+ nslookup clusterip-service\n"
Dec  3 15:58:38.372: INFO: stdout: "Server:\t\t100.104.0.10\nAddress:\t100.104.0.10#53\n\nclusterip-service.services-3220.svc.cluster.local\tcanonical name = externalsvc.services-3220.svc.cluster.local.\nName:\texternalsvc.services-3220.svc.cluster.local\nAddress: 100.111.55.210\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-3220, will wait for the garbage collector to delete the pods
Dec  3 15:58:38.446: INFO: Deleting ReplicationController externalsvc took: 13.364823ms
Dec  3 15:58:38.546: INFO: Terminating ReplicationController externalsvc pods took: 100.282758ms
Dec  3 15:58:44.864: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:58:44.880: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3220" for this suite.
Dec  3 15:58:50.931: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:58:51.325: INFO: namespace services-3220 deletion completed in 6.426102964s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:58:51.325: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6514
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:59:07.600: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6514" for this suite.
Dec  3 15:59:13.651: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:59:14.050: INFO: namespace resourcequota-6514 deletion completed in 6.431119585s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:59:14.051: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5360
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-9a1bb626-3e14-46f7-93ec-5e0663dee68f
STEP: Creating a pod to test consume configMaps
Dec  3 15:59:14.259: INFO: Waiting up to 5m0s for pod "pod-configmaps-884001ca-97b7-4eaf-ace8-84608c9e87ad" in namespace "configmap-5360" to be "success or failure"
Dec  3 15:59:14.269: INFO: Pod "pod-configmaps-884001ca-97b7-4eaf-ace8-84608c9e87ad": Phase="Pending", Reason="", readiness=false. Elapsed: 10.065552ms
Dec  3 15:59:16.280: INFO: Pod "pod-configmaps-884001ca-97b7-4eaf-ace8-84608c9e87ad": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02116776s
STEP: Saw pod success
Dec  3 15:59:16.280: INFO: Pod "pod-configmaps-884001ca-97b7-4eaf-ace8-84608c9e87ad" satisfied condition "success or failure"
Dec  3 15:59:16.290: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-configmaps-884001ca-97b7-4eaf-ace8-84608c9e87ad container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 15:59:16.329: INFO: Waiting for pod pod-configmaps-884001ca-97b7-4eaf-ace8-84608c9e87ad to disappear
Dec  3 15:59:16.340: INFO: Pod pod-configmaps-884001ca-97b7-4eaf-ace8-84608c9e87ad no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:59:16.340: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5360" for this suite.
Dec  3 15:59:22.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:59:22.748: INFO: namespace configmap-5360 deletion completed in 6.389940937s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:59:22.750: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-325
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec  3 15:59:22.945: INFO: Waiting up to 5m0s for pod "pod-0b96c5cb-43b4-4255-a347-bd66a62fa495" in namespace "emptydir-325" to be "success or failure"
Dec  3 15:59:22.955: INFO: Pod "pod-0b96c5cb-43b4-4255-a347-bd66a62fa495": Phase="Pending", Reason="", readiness=false. Elapsed: 10.100255ms
Dec  3 15:59:24.966: INFO: Pod "pod-0b96c5cb-43b4-4255-a347-bd66a62fa495": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021008151s
STEP: Saw pod success
Dec  3 15:59:24.966: INFO: Pod "pod-0b96c5cb-43b4-4255-a347-bd66a62fa495" satisfied condition "success or failure"
Dec  3 15:59:24.977: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-0b96c5cb-43b4-4255-a347-bd66a62fa495 container test-container: <nil>
STEP: delete the pod
Dec  3 15:59:25.011: INFO: Waiting for pod pod-0b96c5cb-43b4-4255-a347-bd66a62fa495 to disappear
Dec  3 15:59:25.021: INFO: Pod pod-0b96c5cb-43b4-4255-a347-bd66a62fa495 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:59:25.021: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-325" for this suite.
Dec  3 15:59:31.072: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:59:31.433: INFO: namespace emptydir-325 deletion completed in 6.392493324s
•SSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:59:31.433: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8274
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec  3 15:59:31.618: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config create -f - --namespace=kubectl-8274'
Dec  3 15:59:31.883: INFO: stderr: ""
Dec  3 15:59:31.883: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec  3 15:59:31.883: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8274'
Dec  3 15:59:32.000: INFO: stderr: ""
Dec  3 15:59:32.000: INFO: stdout: "update-demo-nautilus-g9w49 update-demo-nautilus-p8kpt "
Dec  3 15:59:32.000: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-g9w49 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8274'
Dec  3 15:59:32.109: INFO: stderr: ""
Dec  3 15:59:32.109: INFO: stdout: ""
Dec  3 15:59:32.109: INFO: update-demo-nautilus-g9w49 is created but not running
Dec  3 15:59:37.109: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8274'
Dec  3 15:59:37.222: INFO: stderr: ""
Dec  3 15:59:37.223: INFO: stdout: "update-demo-nautilus-g9w49 update-demo-nautilus-p8kpt "
Dec  3 15:59:37.223: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-g9w49 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8274'
Dec  3 15:59:37.331: INFO: stderr: ""
Dec  3 15:59:37.331: INFO: stdout: "true"
Dec  3 15:59:37.331: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-g9w49 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8274'
Dec  3 15:59:37.443: INFO: stderr: ""
Dec  3 15:59:37.443: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:59:37.443: INFO: validating pod update-demo-nautilus-g9w49
Dec  3 15:59:37.539: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:59:37.539: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:59:37.539: INFO: update-demo-nautilus-g9w49 is verified up and running
Dec  3 15:59:37.539: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-p8kpt -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8274'
Dec  3 15:59:37.646: INFO: stderr: ""
Dec  3 15:59:37.647: INFO: stdout: "true"
Dec  3 15:59:37.647: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods update-demo-nautilus-p8kpt -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8274'
Dec  3 15:59:37.758: INFO: stderr: ""
Dec  3 15:59:37.758: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec  3 15:59:37.758: INFO: validating pod update-demo-nautilus-p8kpt
Dec  3 15:59:37.852: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec  3 15:59:37.852: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec  3 15:59:37.852: INFO: update-demo-nautilus-p8kpt is verified up and running
STEP: using delete to clean up resources
Dec  3 15:59:37.853: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete --grace-period=0 --force -f - --namespace=kubectl-8274'
Dec  3 15:59:37.971: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec  3 15:59:37.971: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec  3 15:59:37.971: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8274'
Dec  3 15:59:38.092: INFO: stderr: "No resources found in kubectl-8274 namespace.\n"
Dec  3 15:59:38.092: INFO: stdout: ""
Dec  3 15:59:38.092: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config get pods -l name=update-demo --namespace=kubectl-8274 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec  3 15:59:38.200: INFO: stderr: ""
Dec  3 15:59:38.200: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:59:38.200: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8274" for this suite.
Dec  3 15:59:50.252: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 15:59:50.639: INFO: namespace kubectl-8274 deletion completed in 12.419908951s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 15:59:50.639: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-1016
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 15:59:50.824: INFO: Creating deployment "webserver-deployment"
Dec  3 15:59:50.835: INFO: Waiting for observed generation 1
Dec  3 15:59:52.856: INFO: Waiting for all required pods to come up
Dec  3 15:59:52.875: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec  3 15:59:56.897: INFO: Waiting for deployment "webserver-deployment" to complete
Dec  3 15:59:56.918: INFO: Updating deployment "webserver-deployment" with a non-existent image
Dec  3 15:59:56.938: INFO: Updating deployment webserver-deployment
Dec  3 15:59:56.939: INFO: Waiting for observed generation 2
Dec  3 15:59:58.960: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec  3 15:59:58.970: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec  3 15:59:58.980: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec  3 15:59:59.011: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec  3 15:59:59.011: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec  3 15:59:59.021: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec  3 15:59:59.042: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Dec  3 15:59:59.042: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Dec  3 15:59:59.063: INFO: Updating deployment webserver-deployment
Dec  3 15:59:59.063: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Dec  3 15:59:59.088: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec  3 15:59:59.099: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec  3 15:59:59.120: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-1016 /apis/apps/v1/namespaces/deployment-1016/deployments/webserver-deployment 7f27b971-8257-4d2d-9099-8684b61d42b4 21155 3 2019-12-03 15:59:50 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003e2f5a8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:3,Replicas:33,UpdatedReplicas:13,AvailableReplicas:8,UnavailableReplicas:25,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-12-03 15:59:59 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2019-12-03 15:59:59 +0000 UTC,LastTransitionTime:2019-12-03 15:59:50 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Dec  3 15:59:59.131: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-1016 /apis/apps/v1/namespaces/deployment-1016/replicasets/webserver-deployment-c7997dcc8 90c95eec-c31f-4e1f-8634-e0b0e30d27b2 21154 3 2019-12-03 15:59:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 7f27b971-8257-4d2d-9099-8684b61d42b4 0xc003e2faa7 0xc003e2faa8}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003e2fb18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:13,FullyLabeledReplicas:13,ObservedGeneration:3,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 15:59:59.131: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Dec  3 15:59:59.131: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-1016 /apis/apps/v1/namespaces/deployment-1016/replicasets/webserver-deployment-595b5b9587 3a343b61-0ced-4bfc-a526-9cec21772bec 21150 3 2019-12-03 15:59:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 7f27b971-8257-4d2d-9099-8684b61d42b4 0xc003e2f9e7 0xc003e2f9e8}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003e2fa48 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:20,FullyLabeledReplicas:20,ObservedGeneration:3,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Dec  3 15:59:59.153: INFO: Pod "webserver-deployment-595b5b9587-24zv4" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-24zv4 webserver-deployment-595b5b9587- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-595b5b9587-24zv4 c2ea67b3-1f93-459f-a5e4-16b7a3a48c10 21040 0 2019-12-03 15:59:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.1.8/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3a343b61-0ced-4bfc-a526-9cec21772bec 0xc00317f137 0xc00317f138}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.2,PodIP:100.64.1.8,StartTime:2019-12-03 15:59:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 15:59:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://934e2bd653cb24452de8581424572168d1b2268c5275030db7b1033eec31364c,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.8,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.153: INFO: Pod "webserver-deployment-595b5b9587-2bg4f" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2bg4f webserver-deployment-595b5b9587- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-595b5b9587-2bg4f 1ded9236-a874-47b1-9aeb-fbecbf4e3097 21144 0 2019-12-03 15:59:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3a343b61-0ced-4bfc-a526-9cec21772bec 0xc00317f2a0 0xc00317f2a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.153: INFO: Pod "webserver-deployment-595b5b9587-4cgkj" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-4cgkj webserver-deployment-595b5b9587- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-595b5b9587-4cgkj 4ceae8dc-d37c-4379-96aa-57bbda010d83 21121 0 2019-12-03 15:59:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3a343b61-0ced-4bfc-a526-9cec21772bec 0xc00317f3a0 0xc00317f3a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.153: INFO: Pod "webserver-deployment-595b5b9587-94wkc" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-94wkc webserver-deployment-595b5b9587- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-595b5b9587-94wkc b90fca0e-c40e-433e-8d9a-4889bae02a94 21043 0 2019-12-03 15:59:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.1.7/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3a343b61-0ced-4bfc-a526-9cec21772bec 0xc00317f4b0 0xc00317f4b1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.2,PodIP:100.64.1.7,StartTime:2019-12-03 15:59:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 15:59:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://a3b1eb83f7e621c8d3a700df955c341956447bdfee01b0d270310331b211bfef,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.7,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.153: INFO: Pod "webserver-deployment-595b5b9587-9bt8x" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9bt8x webserver-deployment-595b5b9587- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-595b5b9587-9bt8x 3869ed09-4e22-438a-95d2-556b3fad52c0 21014 0 2019-12-03 15:59:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.0.61/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3a343b61-0ced-4bfc-a526-9cec21772bec 0xc00317f620 0xc00317f621}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.3,PodIP:100.64.0.61,StartTime:2019-12-03 15:59:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 15:59:52 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://46fe86f20e56bddff24558d1ccd1c0f381cf611f07e1534c07f2cfd90676267b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.61,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.153: INFO: Pod "webserver-deployment-595b5b9587-bf5n9" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-bf5n9 webserver-deployment-595b5b9587- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-595b5b9587-bf5n9 505d357f-7db3-4e56-a25f-bb43b5b267c3 21147 0 2019-12-03 15:59:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3a343b61-0ced-4bfc-a526-9cec21772bec 0xc00317f780 0xc00317f781}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.153: INFO: Pod "webserver-deployment-595b5b9587-cwn5h" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-cwn5h webserver-deployment-595b5b9587- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-595b5b9587-cwn5h 96a7695f-bc3a-4e54-813a-b7d4c810b216 21118 0 2019-12-03 15:59:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3a343b61-0ced-4bfc-a526-9cec21772bec 0xc00317f890 0xc00317f891}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.153: INFO: Pod "webserver-deployment-595b5b9587-cx82c" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-cx82c webserver-deployment-595b5b9587- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-595b5b9587-cx82c a9902225-03f7-4099-9507-0239b0ffd271 21129 0 2019-12-03 15:59:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3a343b61-0ced-4bfc-a526-9cec21772bec 0xc00317f990 0xc00317f991}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.154: INFO: Pod "webserver-deployment-595b5b9587-gflht" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gflht webserver-deployment-595b5b9587- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-595b5b9587-gflht d62cd9b6-617d-4ead-a983-fe0641b42d1c 21141 0 2019-12-03 15:59:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3a343b61-0ced-4bfc-a526-9cec21772bec 0xc00317fa90 0xc00317fa91}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.154: INFO: Pod "webserver-deployment-595b5b9587-gxc76" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gxc76 webserver-deployment-595b5b9587- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-595b5b9587-gxc76 ada941d2-87da-495d-adeb-54c00fadcc75 21037 0 2019-12-03 15:59:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.1.4/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3a343b61-0ced-4bfc-a526-9cec21772bec 0xc00317fba0 0xc00317fba1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.2,PodIP:100.64.1.4,StartTime:2019-12-03 15:59:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 15:59:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://0bb0a5d1ebe2d83466d31e6636d93c319b9cd9845f21d28f20fedcc5a00b0e0e,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.4,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.154: INFO: Pod "webserver-deployment-595b5b9587-hwlvq" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-hwlvq webserver-deployment-595b5b9587- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-595b5b9587-hwlvq 229fa78e-d08e-4f8a-95a5-44eecfff070e 21017 0 2019-12-03 15:59:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.0.60/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3a343b61-0ced-4bfc-a526-9cec21772bec 0xc00317fd10 0xc00317fd11}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:52 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.3,PodIP:100.64.0.60,StartTime:2019-12-03 15:59:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 15:59:51 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://2b6f8bf66066bcb1167f338ff142219abd611774f26cb51bf07a2e94f60e1466,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.0.60,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.154: INFO: Pod "webserver-deployment-595b5b9587-m6wdp" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-m6wdp webserver-deployment-595b5b9587- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-595b5b9587-m6wdp 7ebc5e5b-f9c3-4523-9d97-9c567daef9a4 21049 0 2019-12-03 15:59:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.1.5/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3a343b61-0ced-4bfc-a526-9cec21772bec 0xc00317fe80 0xc00317fe81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:55 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.2,PodIP:100.64.1.5,StartTime:2019-12-03 15:59:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 15:59:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://01c335b9d2f2fc1a5965ef183dde58ce9e4faf6db7af74105f7faba47f8540fb,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.5,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.154: INFO: Pod "webserver-deployment-595b5b9587-mczqx" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mczqx webserver-deployment-595b5b9587- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-595b5b9587-mczqx 28aa8b79-9eb6-4dd3-94ac-9eac1b7248e6 21156 0 2019-12-03 15:59:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3a343b61-0ced-4bfc-a526-9cec21772bec 0xc00317ffe0 0xc00317ffe1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-12-03 15:59:59 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.154: INFO: Pod "webserver-deployment-595b5b9587-mr4nh" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mr4nh webserver-deployment-595b5b9587- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-595b5b9587-mr4nh 83963470-05f1-4a60-922e-50fe56f51d5c 21128 0 2019-12-03 15:59:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3a343b61-0ced-4bfc-a526-9cec21772bec 0xc0049a6120 0xc0049a6121}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.154: INFO: Pod "webserver-deployment-595b5b9587-mscqz" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-mscqz webserver-deployment-595b5b9587- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-595b5b9587-mscqz 651fdece-b54b-4dca-a626-00984666926c 21034 0 2019-12-03 15:59:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.1.254/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3a343b61-0ced-4bfc-a526-9cec21772bec 0xc0049a6230 0xc0049a6231}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.2,PodIP:100.64.1.254,StartTime:2019-12-03 15:59:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 15:59:52 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://56b34ef960292a8a4b8f0c77152070b233f2729b74f66aa90e03aaac16e5e9ba,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.254,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.154: INFO: Pod "webserver-deployment-595b5b9587-nxwtf" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-nxwtf webserver-deployment-595b5b9587- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-595b5b9587-nxwtf 080c0934-cb4e-4741-8c05-82fd21c0abb6 21130 0 2019-12-03 15:59:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3a343b61-0ced-4bfc-a526-9cec21772bec 0xc0049a6390 0xc0049a6391}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.154: INFO: Pod "webserver-deployment-595b5b9587-p8skq" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-p8skq webserver-deployment-595b5b9587- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-595b5b9587-p8skq 60218f0d-773a-4720-bfdf-b7691e70e68d 21031 0 2019-12-03 15:59:50 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[cni.projectcalico.org/podIP:100.64.1.3/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3a343b61-0ced-4bfc-a526-9cec21772bec 0xc0049a64a0 0xc0049a64a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:50 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:50 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.2,PodIP:100.64.1.3,StartTime:2019-12-03 15:59:50 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 15:59:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:httpd:2.4.38-alpine,ImageID:docker-pullable://httpd@sha256:eb8ccf084cf3e80eece1add239effefd171eb39adbc154d33c14260d905d4060,ContainerID:docker://98168c576ec0e8d48be1d7cf8fdd0917997bef3114920d1ff2922d2316a8c655,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.3,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.155: INFO: Pod "webserver-deployment-595b5b9587-pcxl7" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-pcxl7 webserver-deployment-595b5b9587- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-595b5b9587-pcxl7 daafe19b-52f8-4556-a095-9fdeda8a8c98 21146 0 2019-12-03 15:59:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3a343b61-0ced-4bfc-a526-9cec21772bec 0xc0049a6600 0xc0049a6601}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.155: INFO: Pod "webserver-deployment-595b5b9587-t9tvp" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-t9tvp webserver-deployment-595b5b9587- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-595b5b9587-t9tvp 0b45c708-7e55-473f-835b-7ca3f3a136ff 21127 0 2019-12-03 15:59:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3a343b61-0ced-4bfc-a526-9cec21772bec 0xc0049a6700 0xc0049a6701}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.155: INFO: Pod "webserver-deployment-595b5b9587-vpl9b" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-vpl9b webserver-deployment-595b5b9587- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-595b5b9587-vpl9b ed9ec6bc-6927-424a-9a7a-9fbb81a0384e 21139 0 2019-12-03 15:59:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 3a343b61-0ced-4bfc-a526-9cec21772bec 0xc0049a6800 0xc0049a6801}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.155: INFO: Pod "webserver-deployment-c7997dcc8-5sczh" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-5sczh webserver-deployment-c7997dcc8- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-c7997dcc8-5sczh f488901b-b6a5-4415-bb92-617ff91f8a8a 21101 0 2019-12-03 15:59:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:100.64.1.11/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 90c95eec-c31f-4e1f-8634-e0b0e30d27b2 0xc0049a6910 0xc0049a6911}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-12-03 15:59:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.155: INFO: Pod "webserver-deployment-c7997dcc8-62fv7" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-62fv7 webserver-deployment-c7997dcc8- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-c7997dcc8-62fv7 6d204053-dc12-4002-96d2-988a7ee5a56e 21102 0 2019-12-03 15:59:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:100.64.1.12/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 90c95eec-c31f-4e1f-8634-e0b0e30d27b2 0xc0049a6a80 0xc0049a6a81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-12-03 15:59:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.155: INFO: Pod "webserver-deployment-c7997dcc8-bkwc8" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-bkwc8 webserver-deployment-c7997dcc8- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-c7997dcc8-bkwc8 91fd58d4-5989-4284-90d0-6cdf3697829f 21142 0 2019-12-03 15:59:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 90c95eec-c31f-4e1f-8634-e0b0e30d27b2 0xc0049a6be0 0xc0049a6be1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.155: INFO: Pod "webserver-deployment-c7997dcc8-bqgbd" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-bqgbd webserver-deployment-c7997dcc8- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-c7997dcc8-bqgbd 275a1532-9480-4fed-85da-65938bed3264 21103 0 2019-12-03 15:59:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:100.64.1.13/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 90c95eec-c31f-4e1f-8634-e0b0e30d27b2 0xc0049a6d00 0xc0049a6d01}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-12-03 15:59:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.155: INFO: Pod "webserver-deployment-c7997dcc8-clpmj" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-clpmj webserver-deployment-c7997dcc8- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-c7997dcc8-clpmj ab1b1584-5b64-478e-bd02-5decb20d49a5 21098 0 2019-12-03 15:59:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:100.64.0.62/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 90c95eec-c31f-4e1f-8634-e0b0e30d27b2 0xc0049a6e70 0xc0049a6e71}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:56 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:56 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.3,PodIP:,StartTime:2019-12-03 15:59:56 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.155: INFO: Pod "webserver-deployment-c7997dcc8-hnlh4" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-hnlh4 webserver-deployment-c7997dcc8- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-c7997dcc8-hnlh4 a9fe85f8-8d3d-4992-b13b-1db1ad634733 21100 0 2019-12-03 15:59:56 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[cni.projectcalico.org/podIP:100.64.1.10/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 90c95eec-c31f-4e1f-8634-e0b0e30d27b2 0xc0049a6fe0 0xc0049a6fe1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:57 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:57 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:56 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.2,PodIP:,StartTime:2019-12-03 15:59:57 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.156: INFO: Pod "webserver-deployment-c7997dcc8-pqp2r" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-pqp2r webserver-deployment-c7997dcc8- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-c7997dcc8-pqp2r 74fa43ad-afd1-40f4-afa2-2d9078540a7f 21125 0 2019-12-03 15:59:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 90c95eec-c31f-4e1f-8634-e0b0e30d27b2 0xc0049a7160 0xc0049a7161}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.156: INFO: Pod "webserver-deployment-c7997dcc8-r5nwz" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-r5nwz webserver-deployment-c7997dcc8- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-c7997dcc8-r5nwz b6432f60-0598-4ea1-b354-32f941929792 21124 0 2019-12-03 15:59:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 90c95eec-c31f-4e1f-8634-e0b0e30d27b2 0xc0049a7270 0xc0049a7271}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.156: INFO: Pod "webserver-deployment-c7997dcc8-twwkr" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-twwkr webserver-deployment-c7997dcc8- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-c7997dcc8-twwkr d8fbe603-94a9-4287-b53f-5c95f67d3157 21148 0 2019-12-03 15:59:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 90c95eec-c31f-4e1f-8634-e0b0e30d27b2 0xc0049a73a0 0xc0049a73a1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.156: INFO: Pod "webserver-deployment-c7997dcc8-vpdpp" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-vpdpp webserver-deployment-c7997dcc8- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-c7997dcc8-vpdpp 23ecfaa8-7bc5-4147-a68d-2c8cba8a3f50 21151 0 2019-12-03 15:59:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 90c95eec-c31f-4e1f-8634-e0b0e30d27b2 0xc0049a74d0 0xc0049a74d1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.156: INFO: Pod "webserver-deployment-c7997dcc8-vptwz" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-vptwz webserver-deployment-c7997dcc8- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-c7997dcc8-vptwz c42e51d4-edca-4781-9673-3d990b89011e 21116 0 2019-12-03 15:59:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 90c95eec-c31f-4e1f-8634-e0b0e30d27b2 0xc0049a75e0 0xc0049a75e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.156: INFO: Pod "webserver-deployment-c7997dcc8-w55td" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-w55td webserver-deployment-c7997dcc8- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-c7997dcc8-w55td 0a177997-b093-4d81-a647-db57ad307417 21131 0 2019-12-03 15:59:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 90c95eec-c31f-4e1f-8634-e0b0e30d27b2 0xc0049a76f0 0xc0049a76f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec  3 15:59:59.156: INFO: Pod "webserver-deployment-c7997dcc8-x7l6s" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-x7l6s webserver-deployment-c7997dcc8- deployment-1016 /api/v1/namespaces/deployment-1016/pods/webserver-deployment-c7997dcc8-x7l6s cb572b75-1f68-47f7-933b-c2ddfec676bc 21143 0 2019-12-03 15:59:59 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 90c95eec-c31f-4e1f-8634-e0b0e30d27b2 0xc0049a7800 0xc0049a7801}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-bc8nn,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-bc8nn,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-bc8nn,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 15:59:59 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 15:59:59.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-1016" for this suite.
Dec  3 16:00:05.200: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:00:05.555: INFO: namespace deployment-1016 deletion completed in 6.38822147s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:00:05.555: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1084
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 16:00:05.753: INFO: Waiting up to 5m0s for pod "downwardapi-volume-234da6d3-bab6-4166-ba0f-e37e81c5147a" in namespace "downward-api-1084" to be "success or failure"
Dec  3 16:00:05.763: INFO: Pod "downwardapi-volume-234da6d3-bab6-4166-ba0f-e37e81c5147a": Phase="Pending", Reason="", readiness=false. Elapsed: 10.248292ms
Dec  3 16:00:07.774: INFO: Pod "downwardapi-volume-234da6d3-bab6-4166-ba0f-e37e81c5147a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.020986407s
Dec  3 16:00:09.786: INFO: Pod "downwardapi-volume-234da6d3-bab6-4166-ba0f-e37e81c5147a": Phase="Pending", Reason="", readiness=false. Elapsed: 4.033351703s
Dec  3 16:00:11.797: INFO: Pod "downwardapi-volume-234da6d3-bab6-4166-ba0f-e37e81c5147a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.044517837s
STEP: Saw pod success
Dec  3 16:00:11.797: INFO: Pod "downwardapi-volume-234da6d3-bab6-4166-ba0f-e37e81c5147a" satisfied condition "success or failure"
Dec  3 16:00:11.808: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downwardapi-volume-234da6d3-bab6-4166-ba0f-e37e81c5147a container client-container: <nil>
STEP: delete the pod
Dec  3 16:00:11.845: INFO: Waiting for pod downwardapi-volume-234da6d3-bab6-4166-ba0f-e37e81c5147a to disappear
Dec  3 16:00:11.855: INFO: Pod downwardapi-volume-234da6d3-bab6-4166-ba0f-e37e81c5147a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:00:11.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1084" for this suite.
Dec  3 16:00:17.905: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:00:18.285: INFO: namespace downward-api-1084 deletion completed in 6.410959041s
•SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:00:18.286: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3379
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 16:00:18.481: INFO: Waiting up to 5m0s for pod "downwardapi-volume-8fcd6bdb-56b7-4e35-9907-b68570f25493" in namespace "projected-3379" to be "success or failure"
Dec  3 16:00:18.491: INFO: Pod "downwardapi-volume-8fcd6bdb-56b7-4e35-9907-b68570f25493": Phase="Pending", Reason="", readiness=false. Elapsed: 10.129541ms
Dec  3 16:00:20.502: INFO: Pod "downwardapi-volume-8fcd6bdb-56b7-4e35-9907-b68570f25493": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021289573s
STEP: Saw pod success
Dec  3 16:00:20.502: INFO: Pod "downwardapi-volume-8fcd6bdb-56b7-4e35-9907-b68570f25493" satisfied condition "success or failure"
Dec  3 16:00:20.512: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downwardapi-volume-8fcd6bdb-56b7-4e35-9907-b68570f25493 container client-container: <nil>
STEP: delete the pod
Dec  3 16:00:20.557: INFO: Waiting for pod downwardapi-volume-8fcd6bdb-56b7-4e35-9907-b68570f25493 to disappear
Dec  3 16:00:20.567: INFO: Pod downwardapi-volume-8fcd6bdb-56b7-4e35-9907-b68570f25493 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:00:20.567: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3379" for this suite.
Dec  3 16:00:26.617: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:00:26.970: INFO: namespace projected-3379 deletion completed in 6.384775352s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:00:26.971: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-6745
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-6745
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6745 to expose endpoints map[]
Dec  3 16:00:27.178: INFO: successfully validated that service multi-endpoint-test in namespace services-6745 exposes endpoints map[] (9.887548ms elapsed)
STEP: Creating pod pod1 in namespace services-6745
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6745 to expose endpoints map[pod1:[100]]
Dec  3 16:00:29.256: INFO: successfully validated that service multi-endpoint-test in namespace services-6745 exposes endpoints map[pod1:[100]] (2.064280976s elapsed)
STEP: Creating pod pod2 in namespace services-6745
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6745 to expose endpoints map[pod1:[100] pod2:[101]]
Dec  3 16:00:31.363: INFO: successfully validated that service multi-endpoint-test in namespace services-6745 exposes endpoints map[pod1:[100] pod2:[101]] (2.094073297s elapsed)
STEP: Deleting pod pod1 in namespace services-6745
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6745 to expose endpoints map[pod2:[101]]
Dec  3 16:00:31.395: INFO: successfully validated that service multi-endpoint-test in namespace services-6745 exposes endpoints map[pod2:[101]] (19.951026ms elapsed)
STEP: Deleting pod pod2 in namespace services-6745
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-6745 to expose endpoints map[]
Dec  3 16:00:31.416: INFO: successfully validated that service multi-endpoint-test in namespace services-6745 exposes endpoints map[] (9.716293ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:00:31.434: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-6745" for this suite.
Dec  3 16:00:37.486: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:00:37.884: INFO: namespace services-6745 deletion completed in 6.43058803s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:00:37.884: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2739
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-ed2180c5-71fe-4dc0-887e-a9b6ff9d9e19
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:00:42.246: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2739" for this suite.
Dec  3 16:00:54.299: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:00:54.648: INFO: namespace configmap-2739 deletion completed in 12.382449185s
•SSS
------------------------------
[sig-scheduling] NoExecuteTaintManager Single Pod [Serial] 
  removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:00:54.648: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename taint-single-pod
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in taint-single-pod-5666
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/taints.go:164
Dec  3 16:00:54.836: INFO: Waiting up to 1m0s for all nodes to be ready
Dec  3 16:01:54.921: INFO: Waiting for terminating namespaces to be deleted...
[It] removing taint cancels eviction [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:01:54.932: INFO: Starting informer...
STEP: Starting pod...
Dec  3 16:01:54.957: INFO: Pod is running on shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz. Tainting Node
STEP: Trying to apply a taint on the Node
STEP: verifying the node has the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting short time to make sure Pod is queued for deletion
Dec  3 16:01:54.992: INFO: Pod wasn't evicted. Proceeding
Dec  3 16:01:54.992: INFO: Removing taint from Node
STEP: verifying the node doesn't have the taint kubernetes.io/e2e-evict-taint-key=evictTaintVal:NoExecute
STEP: Waiting some time to make sure that toleration time passed.
Dec  3 16:03:10.025: INFO: Pod wasn't evicted. Test successful
[AfterEach] [sig-scheduling] NoExecuteTaintManager Single Pod [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:03:10.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "taint-single-pod-5666" for this suite.
Dec  3 16:03:22.080: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:03:22.444: INFO: namespace taint-single-pod-5666 deletion completed in 12.397496576s
•SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:03:22.444: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-4660
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Dec  3 16:03:22.644: INFO: Waiting up to 5m0s for pod "pod-edbcd7a9-f34e-448e-9c4b-d1471c6d17fc" in namespace "emptydir-4660" to be "success or failure"
Dec  3 16:03:22.654: INFO: Pod "pod-edbcd7a9-f34e-448e-9c4b-d1471c6d17fc": Phase="Pending", Reason="", readiness=false. Elapsed: 10.704191ms
Dec  3 16:03:24.666: INFO: Pod "pod-edbcd7a9-f34e-448e-9c4b-d1471c6d17fc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022341149s
STEP: Saw pod success
Dec  3 16:03:24.666: INFO: Pod "pod-edbcd7a9-f34e-448e-9c4b-d1471c6d17fc" satisfied condition "success or failure"
Dec  3 16:03:24.677: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-edbcd7a9-f34e-448e-9c4b-d1471c6d17fc container test-container: <nil>
STEP: delete the pod
Dec  3 16:03:24.845: INFO: Waiting for pod pod-edbcd7a9-f34e-448e-9c4b-d1471c6d17fc to disappear
Dec  3 16:03:24.855: INFO: Pod pod-edbcd7a9-f34e-448e-9c4b-d1471c6d17fc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:03:24.855: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-4660" for this suite.
Dec  3 16:03:30.907: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:03:31.304: INFO: namespace emptydir-4660 deletion completed in 6.430142546s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:03:31.304: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8578
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-0a4652e9-e1e6-41a4-9e53-3644da24e591
STEP: Creating a pod to test consume secrets
Dec  3 16:03:31.509: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-a0612951-5d31-4588-baba-877ffa565c62" in namespace "projected-8578" to be "success or failure"
Dec  3 16:03:31.522: INFO: Pod "pod-projected-secrets-a0612951-5d31-4588-baba-877ffa565c62": Phase="Pending", Reason="", readiness=false. Elapsed: 13.023152ms
Dec  3 16:03:33.533: INFO: Pod "pod-projected-secrets-a0612951-5d31-4588-baba-877ffa565c62": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.023940937s
STEP: Saw pod success
Dec  3 16:03:33.533: INFO: Pod "pod-projected-secrets-a0612951-5d31-4588-baba-877ffa565c62" satisfied condition "success or failure"
Dec  3 16:03:33.543: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-projected-secrets-a0612951-5d31-4588-baba-877ffa565c62 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:03:33.574: INFO: Waiting for pod pod-projected-secrets-a0612951-5d31-4588-baba-877ffa565c62 to disappear
Dec  3 16:03:33.585: INFO: Pod pod-projected-secrets-a0612951-5d31-4588-baba-877ffa565c62 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:03:33.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8578" for this suite.
Dec  3 16:03:39.635: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:03:40.000: INFO: namespace projected-8578 deletion completed in 6.396781051s
•SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:03:40.001: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-4626
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec  3 16:03:42.243: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:03:42.269: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-4626" for this suite.
Dec  3 16:03:48.319: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:03:48.670: INFO: namespace container-runtime-4626 deletion completed in 6.382110705s
•SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:03:48.670: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8052
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  3 16:03:48.868: INFO: Waiting up to 5m0s for pod "pod-f59b4ba9-1e89-4286-ab34-dd998ebad6d5" in namespace "emptydir-8052" to be "success or failure"
Dec  3 16:03:48.879: INFO: Pod "pod-f59b4ba9-1e89-4286-ab34-dd998ebad6d5": Phase="Pending", Reason="", readiness=false. Elapsed: 10.269898ms
Dec  3 16:03:50.890: INFO: Pod "pod-f59b4ba9-1e89-4286-ab34-dd998ebad6d5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021342954s
STEP: Saw pod success
Dec  3 16:03:50.890: INFO: Pod "pod-f59b4ba9-1e89-4286-ab34-dd998ebad6d5" satisfied condition "success or failure"
Dec  3 16:03:50.900: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-f59b4ba9-1e89-4286-ab34-dd998ebad6d5 container test-container: <nil>
STEP: delete the pod
Dec  3 16:03:50.933: INFO: Waiting for pod pod-f59b4ba9-1e89-4286-ab34-dd998ebad6d5 to disappear
Dec  3 16:03:50.943: INFO: Pod pod-f59b4ba9-1e89-4286-ab34-dd998ebad6d5 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:03:50.943: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8052" for this suite.
Dec  3 16:03:56.994: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:03:57.348: INFO: namespace emptydir-8052 deletion completed in 6.385759165s
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:03:57.348: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9717
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Dec  3 16:03:57.534: INFO: Asynchronously running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:03:57.667: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9717" for this suite.
Dec  3 16:04:03.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:04:04.062: INFO: namespace kubectl-9717 deletion completed in 6.383404347s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:04:04.062: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8244
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 16:04:04.820: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985844, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985844, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985844, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985844, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 16:04:06.831: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985844, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985844, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985844, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710985844, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 16:04:09.848: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Dec  3 16:04:10.013: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:04:10.080: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8244" for this suite.
Dec  3 16:04:16.132: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:04:16.481: INFO: namespace webhook-8244 deletion completed in 6.382094809s
STEP: Destroying namespace "webhook-8244-markers" for this suite.
Dec  3 16:04:22.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:04:22.875: INFO: namespace webhook-8244-markers deletion completed in 6.393171601s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:04:22.919: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-8611
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Dec  3 16:04:25.667: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-8611 pod-service-account-a0738a56-0463-4249-8183-3e3d092ed572 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Dec  3 16:04:26.204: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-8611 pod-service-account-a0738a56-0463-4249-8183-3e3d092ed572 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Dec  3 16:04:26.776: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl exec --namespace=svcaccounts-8611 pod-service-account-a0738a56-0463-4249-8183-3e3d092ed572 -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:04:27.308: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8611" for this suite.
Dec  3 16:04:33.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:04:33.716: INFO: namespace svcaccounts-8611 deletion completed in 6.3895013s
•SSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:04:33.717: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4849
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-4849
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-4849
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-4849
Dec  3 16:04:33.941: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Dec  3 16:04:43.955: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec  3 16:04:43.966: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:04:44.573: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:04:44.573: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:04:44.573: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 16:04:44.584: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  3 16:04:54.598: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 16:04:54.598: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 16:04:54.640: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999524s
Dec  3 16:04:55.652: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.989257862s
Dec  3 16:04:56.662: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.978165693s
Dec  3 16:04:57.674: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.967223559s
Dec  3 16:04:58.685: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.955978029s
Dec  3 16:04:59.697: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.944594639s
Dec  3 16:05:00.708: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.933040725s
Dec  3 16:05:01.719: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.921573763s
Dec  3 16:05:02.730: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.910378769s
Dec  3 16:05:03.741: INFO: Verifying statefulset ss doesn't scale past 1 for another 899.395502ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-4849
Dec  3 16:05:04.753: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:05:05.295: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 16:05:05.295: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 16:05:05.295: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 16:05:05.306: INFO: Found 1 stateful pods, waiting for 3
Dec  3 16:05:15.319: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:05:15.319: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:05:15.319: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec  3 16:05:15.342: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:05:15.873: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:05:15.873: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:05:15.873: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 16:05:15.873: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:05:16.430: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:05:16.430: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:05:16.430: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 16:05:16.430: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:05:16.958: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:05:16.958: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:05:16.958: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 16:05:16.958: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 16:05:16.968: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Dec  3 16:05:26.993: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 16:05:26.993: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 16:05:26.993: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 16:05:27.024: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999062s
Dec  3 16:05:28.036: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.989013979s
Dec  3 16:05:29.048: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.977345692s
Dec  3 16:05:30.060: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.965554687s
Dec  3 16:05:31.071: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.953687243s
Dec  3 16:05:32.083: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.942069108s
Dec  3 16:05:33.096: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.929772675s
Dec  3 16:05:34.108: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.917818979s
Dec  3 16:05:35.119: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.905749726s
Dec  3 16:05:36.131: INFO: Verifying statefulset ss doesn't scale past 3 for another 894.177732ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-4849
Dec  3 16:05:37.142: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:05:37.691: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 16:05:37.691: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 16:05:37.691: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 16:05:37.691: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:05:38.234: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 16:05:38.234: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 16:05:38.234: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 16:05:38.234: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:05:38.688: INFO: rc: 1
Dec  3 16:05:38.689: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  error: Internal error occurred: error executing command in container: container not running (946e289782daa8e3b0033d2d4fa5e2036609a9348473ba8814cd5b92391c9bf3)
 [] <nil> 0xc00458e960 exit status 1 <nil> <nil> true [0xc0058001a8 0xc0058001c0 0xc0058001d8] [0xc0058001a8 0xc0058001c0 0xc0058001d8] [0xc0058001b8 0xc0058001d0] [0x10efe30 0x10efe30] 0xc00734c3c0 <nil>}:
Command stdout:

stderr:
error: Internal error occurred: error executing command in container: container not running (946e289782daa8e3b0033d2d4fa5e2036609a9348473ba8814cd5b92391c9bf3)

error:
exit status 1
Dec  3 16:05:48.689: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:05:48.832: INFO: rc: 1
Dec  3 16:05:48.832: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0009e6510 exit status 1 <nil> <nil> true [0xc000437c90 0xc000437ca8 0xc000437cc0] [0xc000437c90 0xc000437ca8 0xc000437cc0] [0xc000437ca0 0xc000437cb8] [0x10efe30 0x10efe30] 0xc00289ce40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:05:58.832: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:05:58.955: INFO: rc: 1
Dec  3 16:05:58.955: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc005453770 exit status 1 <nil> <nil> true [0xc0050641c0 0xc0050641d8 0xc0050641f0] [0xc0050641c0 0xc0050641d8 0xc0050641f0] [0xc0050641d0 0xc0050641e8] [0x10efe30 0x10efe30] 0xc005af53e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:06:08.959: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:06:09.349: INFO: rc: 1
Dec  3 16:06:09.349: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc00458ef90 exit status 1 <nil> <nil> true [0xc0058001e0 0xc0058001f8 0xc005800210] [0xc0058001e0 0xc0058001f8 0xc005800210] [0xc0058001f0 0xc005800208] [0x10efe30 0x10efe30] 0xc00734c720 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:06:19.350: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:06:19.475: INFO: rc: 1
Dec  3 16:06:19.475: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002fb65a0 exit status 1 <nil> <nil> true [0xc00234c088 0xc00234c3b0 0xc00234c5b8] [0xc00234c088 0xc00234c3b0 0xc00234c5b8] [0xc00234c398 0xc00234c530] [0x10efe30 0x10efe30] 0xc005478360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:06:29.476: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:06:29.618: INFO: rc: 1
Dec  3 16:06:29.618: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc005d20600 exit status 1 <nil> <nil> true [0xc0008900c8 0xc0008906d0 0xc000890e00] [0xc0008900c8 0xc0008906d0 0xc000890e00] [0xc000890470 0xc000890be8] [0x10efe30 0x10efe30] 0xc002e008a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:06:39.618: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:06:39.741: INFO: rc: 1
Dec  3 16:06:39.741: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc005d20c00 exit status 1 <nil> <nil> true [0xc000890ef0 0xc0008911d0 0xc0008914d8] [0xc000890ef0 0xc0008911d0 0xc0008914d8] [0xc0008910d8 0xc000891368] [0x10efe30 0x10efe30] 0xc002e01680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:06:49.741: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:06:49.875: INFO: rc: 1
Dec  3 16:06:49.875: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001930780 exit status 1 <nil> <nil> true [0xc00017b0d8 0xc00017bad0 0xc00017bce8] [0xc00017b0d8 0xc00017bad0 0xc00017bce8] [0xc00017b998 0xc00017bca8] [0x10efe30 0x10efe30] 0xc002dd4900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:06:59.876: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:07:00.005: INFO: rc: 1
Dec  3 16:07:00.005: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc005d21230 exit status 1 <nil> <nil> true [0xc000891710 0xc0008919e8 0xc000891f20] [0xc000891710 0xc0008919e8 0xc000891f20] [0xc0008918f8 0xc000891ed8] [0x10efe30 0x10efe30] 0xc0073161e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:07:10.005: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:07:10.134: INFO: rc: 1
Dec  3 16:07:10.134: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002fb6b70 exit status 1 <nil> <nil> true [0xc00234c620 0xc00234c780 0xc00234c990] [0xc00234c620 0xc00234c780 0xc00234c990] [0xc00234c768 0xc00234c870] [0x10efe30 0x10efe30] 0xc005478a20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:07:20.135: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:07:20.252: INFO: rc: 1
Dec  3 16:07:20.253: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc005b2c600 exit status 1 <nil> <nil> true [0xc0003102d8 0xc000310c48 0xc000310dc8] [0xc0003102d8 0xc000310c48 0xc000310dc8] [0xc000310b38 0xc000310da0] [0x10efe30 0x10efe30] 0xc00502f140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:07:30.253: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:07:30.374: INFO: rc: 1
Dec  3 16:07:30.374: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002fb71d0 exit status 1 <nil> <nil> true [0xc00234cb00 0xc00234cc30 0xc00234cd60] [0xc00234cb00 0xc00234cc30 0xc00234cd60] [0xc00234cc10 0xc00234cd40] [0x10efe30 0x10efe30] 0xc005479080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:07:40.374: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:07:40.494: INFO: rc: 1
Dec  3 16:07:40.495: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002fb77a0 exit status 1 <nil> <nil> true [0xc00234cd80 0xc00234cf30 0xc00234d008] [0xc00234cd80 0xc00234cf30 0xc00234d008] [0xc00234ce90 0xc00234cfe8] [0x10efe30 0x10efe30] 0xc0054793e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:07:50.495: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:07:50.687: INFO: rc: 1
Dec  3 16:07:50.687: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001930d50 exit status 1 <nil> <nil> true [0xc00017bdb0 0xc00017bfd0 0xc001438120] [0xc00017bdb0 0xc00017bfd0 0xc001438120] [0xc00017bfa0 0xc001438060] [0x10efe30 0x10efe30] 0xc002dd5800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:08:00.687: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:08:00.823: INFO: rc: 1
Dec  3 16:08:00.823: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001931350 exit status 1 <nil> <nil> true [0xc001438160 0xc001438228 0xc0014382b0] [0xc001438160 0xc001438228 0xc0014382b0] [0xc0014381e8 0xc001438270] [0x10efe30 0x10efe30] 0xc00308a1e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:08:10.823: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:08:10.949: INFO: rc: 1
Dec  3 16:08:10.949: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc005b2cc60 exit status 1 <nil> <nil> true [0xc000310f90 0xc0003111c8 0xc000311370] [0xc000310f90 0xc0003111c8 0xc000311370] [0xc0003110e8 0xc0003112f8] [0x10efe30 0x10efe30] 0xc00502f4a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:08:20.949: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:08:21.076: INFO: rc: 1
Dec  3 16:08:21.076: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0019307b0 exit status 1 <nil> <nil> true [0xc00017b960 0xc00017bb90 0xc00017bdb0] [0xc00017b960 0xc00017bb90 0xc00017bdb0] [0xc00017bad0 0xc00017bce8] [0x10efe30 0x10efe30] 0xc002dd4900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:08:31.077: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:08:31.198: INFO: rc: 1
Dec  3 16:08:31.198: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc005d205d0 exit status 1 <nil> <nil> true [0xc001438000 0xc001438160 0xc001438228] [0xc001438000 0xc001438160 0xc001438228] [0xc001438120 0xc0014381e8] [0x10efe30 0x10efe30] 0xc002e008a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:08:41.198: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:08:41.318: INFO: rc: 1
Dec  3 16:08:41.318: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc005d20bd0 exit status 1 <nil> <nil> true [0xc001438260 0xc0014382e0 0xc001438398] [0xc001438260 0xc0014382e0 0xc001438398] [0xc0014382b0 0xc001438378] [0x10efe30 0x10efe30] 0xc002e01680 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:08:51.319: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:08:51.441: INFO: rc: 1
Dec  3 16:08:51.441: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc001930db0 exit status 1 <nil> <nil> true [0xc00017beb0 0xc00234c058 0xc00234c398] [0xc00017beb0 0xc00234c058 0xc00234c398] [0xc00017bfd0 0xc00234c0e0] [0x10efe30 0x10efe30] 0xc002dd5800 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:09:01.442: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:09:01.574: INFO: rc: 1
Dec  3 16:09:01.574: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0019313b0 exit status 1 <nil> <nil> true [0xc00234c3b0 0xc00234c5b8 0xc00234c768] [0xc00234c3b0 0xc00234c5b8 0xc00234c768] [0xc00234c530 0xc00234c6d0] [0x10efe30 0x10efe30] 0xc00308a1e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:09:11.575: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:09:11.738: INFO: rc: 1
Dec  3 16:09:11.738: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc005b2c660 exit status 1 <nil> <nil> true [0xc0008900c8 0xc0008906d0 0xc000890e00] [0xc0008900c8 0xc0008906d0 0xc000890e00] [0xc000890470 0xc000890be8] [0x10efe30 0x10efe30] 0xc007316300 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:09:21.738: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:09:21.930: INFO: rc: 1
Dec  3 16:09:21.930: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002fb6630 exit status 1 <nil> <nil> true [0xc0003102d8 0xc000310c48 0xc000310dc8] [0xc0003102d8 0xc000310c48 0xc000310dc8] [0xc000310b38 0xc000310da0] [0x10efe30 0x10efe30] 0xc005478360 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:09:31.930: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:09:32.126: INFO: rc: 1
Dec  3 16:09:32.126: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc005b2ccc0 exit status 1 <nil> <nil> true [0xc000890ef0 0xc0008911d0 0xc0008914d8] [0xc000890ef0 0xc0008911d0 0xc0008914d8] [0xc0008910d8 0xc000891368] [0x10efe30 0x10efe30] 0xc0073167e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:09:42.126: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:09:42.280: INFO: rc: 1
Dec  3 16:09:42.280: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0063ac690 exit status 1 <nil> <nil> true [0xc0035c0020 0xc0035c0038 0xc0035c0050] [0xc0035c0020 0xc0035c0038 0xc0035c0050] [0xc0035c0030 0xc0035c0048] [0x10efe30 0x10efe30] 0xc00299ca80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:09:52.280: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:09:52.520: INFO: rc: 1
Dec  3 16:09:52.520: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0063acc60 exit status 1 <nil> <nil> true [0xc0035c0058 0xc0035c0070 0xc0035c0088] [0xc0035c0058 0xc0035c0070 0xc0035c0088] [0xc0035c0068 0xc0035c0080] [0x10efe30 0x10efe30] 0xc00299da40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:10:02.520: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:10:02.758: INFO: rc: 1
Dec  3 16:10:02.758: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc002fb6ea0 exit status 1 <nil> <nil> true [0xc0003111e0 0xc0003113d8 0xc0003115b8] [0xc0003111e0 0xc0003113d8 0xc0003115b8] [0xc000311370 0xc0003114f0] [0x10efe30 0x10efe30] 0xc005479080 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:10:12.758: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:10:12.958: INFO: rc: 1
Dec  3 16:10:12.958: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0063ad200 exit status 1 <nil> <nil> true [0xc0014383b0 0xc0035c00a0 0xc0035c00b8] [0xc0014383b0 0xc0035c00a0 0xc0035c00b8] [0xc0035c0098 0xc0035c00b0] [0x10efe30 0x10efe30] 0xc00294ed80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:10:22.959: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:10:23.177: INFO: rc: 1
Dec  3 16:10:23.178: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc0063ac600 exit status 1 <nil> <nil> true [0xc0008900d0 0xc000890998 0xc000890ef0] [0xc0008900d0 0xc000890998 0xc000890ef0] [0xc0008906d0 0xc000890e00] [0x10efe30 0x10efe30] 0xc00502f140 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:10:33.178: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:10:33.348: INFO: rc: 1
Dec  3 16:10:33.349: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl [kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-2" not found
 [] <nil> 0xc005b2c5d0 exit status 1 <nil> <nil> true [0xc00017b0d8 0xc00017bad0 0xc00017bce8] [0xc00017b0d8 0xc00017bad0 0xc00017bce8] [0xc00017b998 0xc00017bca8] [0x10efe30 0x10efe30] 0xc002dd4900 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-2" not found

error:
exit status 1
Dec  3 16:10:43.349: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-4849 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:10:43.492: INFO: rc: 1
Dec  3 16:10:43.492: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: 
Dec  3 16:10:43.492: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  3 16:10:43.524: INFO: Deleting all statefulset in ns statefulset-4849
Dec  3 16:10:43.533: INFO: Scaling statefulset ss to 0
Dec  3 16:10:43.562: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 16:10:43.572: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:10:43.603: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4849" for this suite.
Dec  3 16:11:39.652: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:11:39.995: INFO: namespace statefulset-4849 deletion completed in 56.373001833s

• [SLOW TEST:426.278 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:11:39.995: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1763
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Dec  3 16:11:40.246: INFO: Waiting up to 5m0s for pod "var-expansion-60e1d4bc-e931-437f-8654-22a31d01d16a" in namespace "var-expansion-1763" to be "success or failure"
Dec  3 16:11:40.256: INFO: Pod "var-expansion-60e1d4bc-e931-437f-8654-22a31d01d16a": Phase="Pending", Reason="", readiness=false. Elapsed: 9.282553ms
Dec  3 16:11:42.266: INFO: Pod "var-expansion-60e1d4bc-e931-437f-8654-22a31d01d16a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019667195s
STEP: Saw pod success
Dec  3 16:11:42.266: INFO: Pod "var-expansion-60e1d4bc-e931-437f-8654-22a31d01d16a" satisfied condition "success or failure"
Dec  3 16:11:42.276: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod var-expansion-60e1d4bc-e931-437f-8654-22a31d01d16a container dapi-container: <nil>
STEP: delete the pod
Dec  3 16:11:42.433: INFO: Waiting for pod var-expansion-60e1d4bc-e931-437f-8654-22a31d01d16a to disappear
Dec  3 16:11:42.443: INFO: Pod var-expansion-60e1d4bc-e931-437f-8654-22a31d01d16a no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:11:42.443: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1763" for this suite.
Dec  3 16:11:48.491: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:11:48.830: INFO: namespace var-expansion-1763 deletion completed in 6.369152092s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:11:48.831: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-3867
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3234
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-24
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:12:18.722: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-3867" for this suite.
Dec  3 16:12:24.771: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:12:25.116: INFO: namespace namespaces-3867 deletion completed in 6.376436318s
STEP: Destroying namespace "nsdeletetest-3234" for this suite.
Dec  3 16:12:25.296: INFO: Namespace nsdeletetest-3234 was already deleted
STEP: Destroying namespace "nsdeletetest-24" for this suite.
Dec  3 16:12:31.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:12:31.661: INFO: namespace nsdeletetest-24 deletion completed in 6.364615577s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:12:31.674: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4605
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-dab4a567-d420-4c1b-9f68-9700c119f75b
STEP: Creating a pod to test consume configMaps
Dec  3 16:12:31.987: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-b8e0184f-1ecc-4d8b-a2d2-148c00ae6e09" in namespace "projected-4605" to be "success or failure"
Dec  3 16:12:31.997: INFO: Pod "pod-projected-configmaps-b8e0184f-1ecc-4d8b-a2d2-148c00ae6e09": Phase="Pending", Reason="", readiness=false. Elapsed: 9.441371ms
Dec  3 16:12:34.007: INFO: Pod "pod-projected-configmaps-b8e0184f-1ecc-4d8b-a2d2-148c00ae6e09": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019822086s
STEP: Saw pod success
Dec  3 16:12:34.007: INFO: Pod "pod-projected-configmaps-b8e0184f-1ecc-4d8b-a2d2-148c00ae6e09" satisfied condition "success or failure"
Dec  3 16:12:34.017: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-projected-configmaps-b8e0184f-1ecc-4d8b-a2d2-148c00ae6e09 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 16:12:34.049: INFO: Waiting for pod pod-projected-configmaps-b8e0184f-1ecc-4d8b-a2d2-148c00ae6e09 to disappear
Dec  3 16:12:34.058: INFO: Pod pod-projected-configmaps-b8e0184f-1ecc-4d8b-a2d2-148c00ae6e09 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:12:34.058: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4605" for this suite.
Dec  3 16:12:40.106: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:12:40.438: INFO: namespace projected-4605 deletion completed in 6.361830568s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:12:40.439: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2093
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-tr89
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 16:12:40.664: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-tr89" in namespace "subpath-2093" to be "success or failure"
Dec  3 16:12:40.673: INFO: Pod "pod-subpath-test-secret-tr89": Phase="Pending", Reason="", readiness=false. Elapsed: 9.230249ms
Dec  3 16:12:42.684: INFO: Pod "pod-subpath-test-secret-tr89": Phase="Running", Reason="", readiness=true. Elapsed: 2.019757966s
Dec  3 16:12:44.694: INFO: Pod "pod-subpath-test-secret-tr89": Phase="Running", Reason="", readiness=true. Elapsed: 4.030237932s
Dec  3 16:12:46.704: INFO: Pod "pod-subpath-test-secret-tr89": Phase="Running", Reason="", readiness=true. Elapsed: 6.040435233s
Dec  3 16:12:48.930: INFO: Pod "pod-subpath-test-secret-tr89": Phase="Running", Reason="", readiness=true. Elapsed: 8.266220657s
Dec  3 16:12:50.940: INFO: Pod "pod-subpath-test-secret-tr89": Phase="Running", Reason="", readiness=true. Elapsed: 10.276264127s
Dec  3 16:12:52.951: INFO: Pod "pod-subpath-test-secret-tr89": Phase="Running", Reason="", readiness=true. Elapsed: 12.286575244s
Dec  3 16:12:54.961: INFO: Pod "pod-subpath-test-secret-tr89": Phase="Running", Reason="", readiness=true. Elapsed: 14.296796203s
Dec  3 16:12:56.971: INFO: Pod "pod-subpath-test-secret-tr89": Phase="Running", Reason="", readiness=true. Elapsed: 16.307041376s
Dec  3 16:12:58.981: INFO: Pod "pod-subpath-test-secret-tr89": Phase="Running", Reason="", readiness=true. Elapsed: 18.317441998s
Dec  3 16:13:00.992: INFO: Pod "pod-subpath-test-secret-tr89": Phase="Running", Reason="", readiness=true. Elapsed: 20.327564314s
Dec  3 16:13:03.002: INFO: Pod "pod-subpath-test-secret-tr89": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.338022178s
STEP: Saw pod success
Dec  3 16:13:03.002: INFO: Pod "pod-subpath-test-secret-tr89" satisfied condition "success or failure"
Dec  3 16:13:03.012: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-subpath-test-secret-tr89 container test-container-subpath-secret-tr89: <nil>
STEP: delete the pod
Dec  3 16:13:03.043: INFO: Waiting for pod pod-subpath-test-secret-tr89 to disappear
Dec  3 16:13:03.052: INFO: Pod pod-subpath-test-secret-tr89 no longer exists
STEP: Deleting pod pod-subpath-test-secret-tr89
Dec  3 16:13:03.052: INFO: Deleting pod "pod-subpath-test-secret-tr89" in namespace "subpath-2093"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:13:03.062: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2093" for this suite.
Dec  3 16:13:09.112: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:13:09.447: INFO: namespace subpath-2093 deletion completed in 6.366961604s
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:13:09.447: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-3738
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-8d268f59-4b78-411d-8122-6385170eb375
STEP: Creating a pod to test consume configMaps
Dec  3 16:13:09.657: INFO: Waiting up to 5m0s for pod "pod-configmaps-eed565bd-1f5e-49e4-b235-c731ea37667f" in namespace "configmap-3738" to be "success or failure"
Dec  3 16:13:09.667: INFO: Pod "pod-configmaps-eed565bd-1f5e-49e4-b235-c731ea37667f": Phase="Pending", Reason="", readiness=false. Elapsed: 10.344279ms
Dec  3 16:13:11.678: INFO: Pod "pod-configmaps-eed565bd-1f5e-49e4-b235-c731ea37667f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021280749s
STEP: Saw pod success
Dec  3 16:13:11.678: INFO: Pod "pod-configmaps-eed565bd-1f5e-49e4-b235-c731ea37667f" satisfied condition "success or failure"
Dec  3 16:13:11.689: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-configmaps-eed565bd-1f5e-49e4-b235-c731ea37667f container configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 16:13:11.719: INFO: Waiting for pod pod-configmaps-eed565bd-1f5e-49e4-b235-c731ea37667f to disappear
Dec  3 16:13:11.729: INFO: Pod pod-configmaps-eed565bd-1f5e-49e4-b235-c731ea37667f no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:13:11.729: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-3738" for this suite.
Dec  3 16:13:17.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:13:18.116: INFO: namespace configmap-3738 deletion completed in 6.368508595s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:13:18.116: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-6017
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec  3 16:13:18.413: INFO: Number of nodes with available pods: 0
Dec  3 16:13:18.413: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 16:13:19.442: INFO: Number of nodes with available pods: 1
Dec  3 16:13:19.442: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz is running more than one daemon pod
Dec  3 16:13:20.443: INFO: Number of nodes with available pods: 2
Dec  3 16:13:20.443: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec  3 16:13:20.494: INFO: Number of nodes with available pods: 1
Dec  3 16:13:20.494: INFO: Node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 is running more than one daemon pod
Dec  3 16:13:21.523: INFO: Number of nodes with available pods: 2
Dec  3 16:13:21.523: INFO: Number of running nodes: 2, number of available pods: 2
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-6017, will wait for the garbage collector to delete the pods
Dec  3 16:13:21.616: INFO: Deleting DaemonSet.extensions daemon-set took: 14.471493ms
Dec  3 16:13:22.016: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.280603ms
Dec  3 16:13:33.727: INFO: Number of nodes with available pods: 0
Dec  3 16:13:33.727: INFO: Number of running nodes: 0, number of available pods: 0
Dec  3 16:13:33.737: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-6017/daemonsets","resourceVersion":"23756"},"items":null}

Dec  3 16:13:33.747: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-6017/pods","resourceVersion":"23756"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:13:33.787: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-6017" for this suite.
Dec  3 16:13:39.832: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:13:40.163: INFO: namespace daemonsets-6017 deletion completed in 6.362014926s
•SSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:13:40.163: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4168
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Dec  3 16:13:40.452: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec  3 16:13:47.535: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:13:47.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4168" for this suite.
Dec  3 16:13:53.587: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:13:53.941: INFO: namespace pods-4168 deletion completed in 6.385119035s
•SSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:13:53.941: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-4660
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-6c7527b1-55e2-405c-a18f-7c7279b068cf
STEP: Creating a pod to test consume secrets
Dec  3 16:13:54.247: INFO: Waiting up to 5m0s for pod "pod-secrets-67cd8b17-6ca9-430e-8a39-f07fb15fbdb8" in namespace "secrets-4660" to be "success or failure"
Dec  3 16:13:54.256: INFO: Pod "pod-secrets-67cd8b17-6ca9-430e-8a39-f07fb15fbdb8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.527347ms
Dec  3 16:13:56.267: INFO: Pod "pod-secrets-67cd8b17-6ca9-430e-8a39-f07fb15fbdb8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02022008s
STEP: Saw pod success
Dec  3 16:13:56.267: INFO: Pod "pod-secrets-67cd8b17-6ca9-430e-8a39-f07fb15fbdb8" satisfied condition "success or failure"
Dec  3 16:13:56.277: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-secrets-67cd8b17-6ca9-430e-8a39-f07fb15fbdb8 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:13:56.310: INFO: Waiting for pod pod-secrets-67cd8b17-6ca9-430e-8a39-f07fb15fbdb8 to disappear
Dec  3 16:13:56.319: INFO: Pod pod-secrets-67cd8b17-6ca9-430e-8a39-f07fb15fbdb8 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:13:56.319: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-4660" for this suite.
Dec  3 16:14:02.368: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:14:02.720: INFO: namespace secrets-4660 deletion completed in 6.382849186s
•SSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:14:02.720: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7272
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 16:14:03.238: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2220427f-5a5a-4167-86f1-3d7a172e467b" in namespace "downward-api-7272" to be "success or failure"
Dec  3 16:14:03.248: INFO: Pod "downwardapi-volume-2220427f-5a5a-4167-86f1-3d7a172e467b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.681971ms
Dec  3 16:14:05.264: INFO: Pod "downwardapi-volume-2220427f-5a5a-4167-86f1-3d7a172e467b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.026016778s
STEP: Saw pod success
Dec  3 16:14:05.264: INFO: Pod "downwardapi-volume-2220427f-5a5a-4167-86f1-3d7a172e467b" satisfied condition "success or failure"
Dec  3 16:14:05.274: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downwardapi-volume-2220427f-5a5a-4167-86f1-3d7a172e467b container client-container: <nil>
STEP: delete the pod
Dec  3 16:14:05.305: INFO: Waiting for pod downwardapi-volume-2220427f-5a5a-4167-86f1-3d7a172e467b to disappear
Dec  3 16:14:05.315: INFO: Pod downwardapi-volume-2220427f-5a5a-4167-86f1-3d7a172e467b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:14:05.315: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7272" for this suite.
Dec  3 16:14:11.366: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:14:11.707: INFO: namespace downward-api-7272 deletion completed in 6.372934351s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:14:11.708: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-7850
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-7850
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-7850
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-7850
Dec  3 16:14:11.966: INFO: Found 0 stateful pods, waiting for 1
Dec  3 16:14:21.979: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec  3 16:14:21.990: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7850 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:14:22.650: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:14:22.650: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:14:22.650: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 16:14:22.663: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec  3 16:14:32.678: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 16:14:32.678: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 16:14:32.718: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999047s
Dec  3 16:14:33.729: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.989255269s
Dec  3 16:14:34.741: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.978309523s
Dec  3 16:14:35.752: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.966926638s
Dec  3 16:14:36.763: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.956056207s
Dec  3 16:14:37.773: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.945020114s
Dec  3 16:14:38.784: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.934363963s
Dec  3 16:14:39.796: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.923287822s
Dec  3 16:14:40.808: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.910485533s
Dec  3 16:14:41.819: INFO: Verifying statefulset ss doesn't scale past 3 for another 899.46983ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-7850
Dec  3 16:14:42.831: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7850 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:14:43.503: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 16:14:43.503: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 16:14:43.503: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 16:14:43.503: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7850 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:14:44.143: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec  3 16:14:44.143: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 16:14:44.143: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 16:14:44.143: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7850 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:14:44.737: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec  3 16:14:44.737: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 16:14:44.737: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 16:14:44.748: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:14:44.748: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:14:44.748: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec  3 16:14:44.759: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7850 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:14:45.423: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:14:45.423: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:14:45.423: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 16:14:45.423: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7850 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:14:46.136: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:14:46.137: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:14:46.137: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 16:14:46.137: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-7850 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:14:46.820: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:14:46.821: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:14:46.821: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 16:14:46.821: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 16:14:46.830: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 1
Dec  3 16:14:56.854: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 16:14:56.854: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 16:14:56.854: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec  3 16:14:56.885: INFO: POD   NODE                                              PHASE    GRACE  CONDITIONS
Dec  3 16:14:56.885: INFO: ss-0  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:11 +0000 UTC  }]
Dec  3 16:14:56.885: INFO: ss-1  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  }]
Dec  3 16:14:56.885: INFO: ss-2  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  }]
Dec  3 16:14:56.885: INFO: 
Dec  3 16:14:56.885: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 16:14:57.897: INFO: POD   NODE                                              PHASE    GRACE  CONDITIONS
Dec  3 16:14:57.897: INFO: ss-0  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:11 +0000 UTC  }]
Dec  3 16:14:57.897: INFO: ss-1  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  }]
Dec  3 16:14:57.897: INFO: ss-2  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  }]
Dec  3 16:14:57.897: INFO: 
Dec  3 16:14:57.897: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 16:14:58.908: INFO: POD   NODE                                              PHASE    GRACE  CONDITIONS
Dec  3 16:14:58.908: INFO: ss-0  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:11 +0000 UTC  }]
Dec  3 16:14:58.908: INFO: ss-1  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  }]
Dec  3 16:14:58.908: INFO: ss-2  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  }]
Dec  3 16:14:58.908: INFO: 
Dec  3 16:14:58.908: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 16:14:59.919: INFO: POD   NODE                                              PHASE    GRACE  CONDITIONS
Dec  3 16:14:59.919: INFO: ss-0  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:11 +0000 UTC  }]
Dec  3 16:14:59.919: INFO: ss-1  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  }]
Dec  3 16:14:59.919: INFO: ss-2  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  }]
Dec  3 16:14:59.919: INFO: 
Dec  3 16:14:59.919: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 16:15:00.930: INFO: POD   NODE                                              PHASE    GRACE  CONDITIONS
Dec  3 16:15:00.931: INFO: ss-0  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:11 +0000 UTC  }]
Dec  3 16:15:00.931: INFO: ss-1  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  }]
Dec  3 16:15:00.931: INFO: ss-2  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  }]
Dec  3 16:15:00.931: INFO: 
Dec  3 16:15:00.931: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 16:15:01.941: INFO: POD   NODE                                              PHASE    GRACE  CONDITIONS
Dec  3 16:15:01.941: INFO: ss-0  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:11 +0000 UTC  }]
Dec  3 16:15:01.941: INFO: ss-1  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  }]
Dec  3 16:15:01.942: INFO: ss-2  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  }]
Dec  3 16:15:01.942: INFO: 
Dec  3 16:15:01.942: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 16:15:02.952: INFO: POD   NODE                                              PHASE    GRACE  CONDITIONS
Dec  3 16:15:02.952: INFO: ss-0  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:11 +0000 UTC  }]
Dec  3 16:15:02.952: INFO: ss-1  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  }]
Dec  3 16:15:02.952: INFO: ss-2  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  }]
Dec  3 16:15:02.952: INFO: 
Dec  3 16:15:02.952: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 16:15:03.964: INFO: POD   NODE                                              PHASE    GRACE  CONDITIONS
Dec  3 16:15:03.964: INFO: ss-0  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:11 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:45 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:11 +0000 UTC  }]
Dec  3 16:15:03.964: INFO: ss-1  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:46 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  }]
Dec  3 16:15:03.964: INFO: ss-2  shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:47 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-03 16:14:32 +0000 UTC  }]
Dec  3 16:15:03.964: INFO: 
Dec  3 16:15:03.964: INFO: StatefulSet ss has not reached scale 0, at 3
Dec  3 16:15:04.974: INFO: Verifying statefulset ss doesn't scale past 0 for another 1.910485998s
Dec  3 16:15:05.985: INFO: Verifying statefulset ss doesn't scale past 0 for another 900.152549ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-7850
Dec  3 16:15:06.995: INFO: Scaling statefulset ss to 0
Dec  3 16:15:07.025: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  3 16:15:07.035: INFO: Deleting all statefulset in ns statefulset-7850
Dec  3 16:15:07.045: INFO: Scaling statefulset ss to 0
Dec  3 16:15:07.074: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 16:15:07.083: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:15:07.113: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-7850" for this suite.
Dec  3 16:15:13.162: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:15:13.492: INFO: namespace statefulset-7850 deletion completed in 6.360551536s
•SSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:15:13.492: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3513
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec  3 16:15:13.730: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:15:39.394: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3513" for this suite.
Dec  3 16:15:45.444: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:15:45.785: INFO: namespace crd-publish-openapi-3513 deletion completed in 6.372001247s
•SSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:15:45.785: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7939
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-7939
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-7939
STEP: creating replication controller externalsvc in namespace services-7939
I1203 16:15:46.163275    5064 runners.go:184] Created replication controller with name: externalsvc, namespace: services-7939, replica count: 2
I1203 16:15:49.215780    5064 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Dec  3 16:15:49.251: INFO: Creating new exec pod
Dec  3 16:15:51.283: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-7939 execpodp7vzv -- /bin/sh -x -c nslookup nodeport-service'
Dec  3 16:15:52.003: INFO: stderr: "+ nslookup nodeport-service\n"
Dec  3 16:15:52.003: INFO: stdout: "Server:\t\t100.104.0.10\nAddress:\t100.104.0.10#53\n\nnodeport-service.services-7939.svc.cluster.local\tcanonical name = externalsvc.services-7939.svc.cluster.local.\nName:\texternalsvc.services-7939.svc.cluster.local\nAddress: 100.106.67.9\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-7939, will wait for the garbage collector to delete the pods
Dec  3 16:15:52.077: INFO: Deleting ReplicationController externalsvc took: 12.475816ms
Dec  3 16:15:52.477: INFO: Terminating ReplicationController externalsvc pods took: 400.421755ms
Dec  3 16:16:04.895: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:16:04.908: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7939" for this suite.
Dec  3 16:16:10.957: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:16:11.323: INFO: namespace services-7939 deletion completed in 6.396682498s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:16:11.324: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7981
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-ef951b55-1414-45de-b71c-0c452f69f4c1
STEP: Creating secret with name secret-projected-all-test-volume-78e7ba18-ba90-49f4-8289-8cde0feed1ac
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec  3 16:16:11.579: INFO: Waiting up to 5m0s for pod "projected-volume-a3ceb42c-0e25-441f-9fbc-9902e4819499" in namespace "projected-7981" to be "success or failure"
Dec  3 16:16:11.592: INFO: Pod "projected-volume-a3ceb42c-0e25-441f-9fbc-9902e4819499": Phase="Pending", Reason="", readiness=false. Elapsed: 12.235145ms
Dec  3 16:16:13.602: INFO: Pod "projected-volume-a3ceb42c-0e25-441f-9fbc-9902e4819499": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022546046s
STEP: Saw pod success
Dec  3 16:16:13.602: INFO: Pod "projected-volume-a3ceb42c-0e25-441f-9fbc-9902e4819499" satisfied condition "success or failure"
Dec  3 16:16:13.612: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod projected-volume-a3ceb42c-0e25-441f-9fbc-9902e4819499 container projected-all-volume-test: <nil>
STEP: delete the pod
Dec  3 16:16:13.770: INFO: Waiting for pod projected-volume-a3ceb42c-0e25-441f-9fbc-9902e4819499 to disappear
Dec  3 16:16:13.779: INFO: Pod projected-volume-a3ceb42c-0e25-441f-9fbc-9902e4819499 no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:16:13.779: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7981" for this suite.
Dec  3 16:16:19.831: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:16:20.176: INFO: namespace projected-7981 deletion completed in 6.377749293s
•SS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:16:20.176: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-2155
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Dec  3 16:16:20.448: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-2155" to be "success or failure"
Dec  3 16:16:20.458: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 10.114631ms
Dec  3 16:16:22.468: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.02043206s
STEP: Saw pod success
Dec  3 16:16:22.523: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec  3 16:16:22.533: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec  3 16:16:22.565: INFO: Waiting for pod pod-host-path-test to disappear
Dec  3 16:16:22.575: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:16:22.575: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-2155" for this suite.
Dec  3 16:16:28.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:16:28.985: INFO: namespace hostpath-2155 deletion completed in 6.391599172s
•
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:16:28.985: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-1197
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-1197
I1203 16:16:29.242177    5064 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-1197, replica count: 1
I1203 16:16:30.292700    5064 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 16:16:30.408: INFO: Created: latency-svc-jzg5k
Dec  3 16:16:30.411: INFO: Got endpoints: latency-svc-jzg5k [18.509994ms]
Dec  3 16:16:30.426: INFO: Created: latency-svc-cj2n7
Dec  3 16:16:30.433: INFO: Created: latency-svc-cxsvw
Dec  3 16:16:30.433: INFO: Got endpoints: latency-svc-cj2n7 [22.197644ms]
Dec  3 16:16:30.435: INFO: Got endpoints: latency-svc-cxsvw [23.006954ms]
Dec  3 16:16:30.435: INFO: Created: latency-svc-hc6rn
Dec  3 16:16:30.438: INFO: Got endpoints: latency-svc-hc6rn [26.49354ms]
Dec  3 16:16:30.439: INFO: Created: latency-svc-s7znp
Dec  3 16:16:30.443: INFO: Got endpoints: latency-svc-s7znp [31.200282ms]
Dec  3 16:16:30.444: INFO: Created: latency-svc-tmzgj
Dec  3 16:16:30.447: INFO: Got endpoints: latency-svc-tmzgj [35.161428ms]
Dec  3 16:16:30.448: INFO: Created: latency-svc-6lpv6
Dec  3 16:16:30.452: INFO: Got endpoints: latency-svc-6lpv6 [39.72403ms]
Dec  3 16:16:30.452: INFO: Created: latency-svc-kjlgf
Dec  3 16:16:30.457: INFO: Got endpoints: latency-svc-kjlgf [44.527797ms]
Dec  3 16:16:30.457: INFO: Created: latency-svc-9ssbp
Dec  3 16:16:30.461: INFO: Got endpoints: latency-svc-9ssbp [48.771497ms]
Dec  3 16:16:30.461: INFO: Created: latency-svc-wtl72
Dec  3 16:16:30.465: INFO: Created: latency-svc-ggk98
Dec  3 16:16:30.469: INFO: Got endpoints: latency-svc-ggk98 [56.368224ms]
Dec  3 16:16:30.469: INFO: Created: latency-svc-52bwv
Dec  3 16:16:30.473: INFO: Got endpoints: latency-svc-52bwv [60.823356ms]
Dec  3 16:16:30.473: INFO: Created: latency-svc-ttznn
Dec  3 16:16:30.479: INFO: Created: latency-svc-57p5v
Dec  3 16:16:30.482: INFO: Created: latency-svc-xq7fp
Dec  3 16:16:30.485: INFO: Created: latency-svc-p6lpr
Dec  3 16:16:30.490: INFO: Got endpoints: latency-svc-wtl72 [77.964163ms]
Dec  3 16:16:30.490: INFO: Got endpoints: latency-svc-ttznn [77.822728ms]
Dec  3 16:16:30.491: INFO: Got endpoints: latency-svc-57p5v [77.849763ms]
Dec  3 16:16:30.491: INFO: Created: latency-svc-hh5rr
Dec  3 16:16:30.491: INFO: Got endpoints: latency-svc-p6lpr [78.013305ms]
Dec  3 16:16:30.491: INFO: Got endpoints: latency-svc-xq7fp [78.098098ms]
Dec  3 16:16:30.494: INFO: Got endpoints: latency-svc-hh5rr [60.881531ms]
Dec  3 16:16:30.495: INFO: Created: latency-svc-4b5hx
Dec  3 16:16:30.499: INFO: Got endpoints: latency-svc-4b5hx [63.907709ms]
Dec  3 16:16:30.499: INFO: Created: latency-svc-tmpx5
Dec  3 16:16:30.501: INFO: Got endpoints: latency-svc-tmpx5 [62.036846ms]
Dec  3 16:16:30.504: INFO: Created: latency-svc-tl6p5
Dec  3 16:16:30.510: INFO: Created: latency-svc-mxc4j
Dec  3 16:16:30.514: INFO: Created: latency-svc-dzskv
Dec  3 16:16:30.519: INFO: Created: latency-svc-pdtz8
Dec  3 16:16:30.532: INFO: Created: latency-svc-x27fp
Dec  3 16:16:30.536: INFO: Created: latency-svc-khn86
Dec  3 16:16:30.540: INFO: Created: latency-svc-p8x82
Dec  3 16:16:30.544: INFO: Created: latency-svc-ltvs5
Dec  3 16:16:30.548: INFO: Created: latency-svc-b6kks
Dec  3 16:16:30.552: INFO: Created: latency-svc-ngk2r
Dec  3 16:16:30.556: INFO: Created: latency-svc-nrd4n
Dec  3 16:16:30.560: INFO: Created: latency-svc-nwx85
Dec  3 16:16:30.564: INFO: Created: latency-svc-jzd7m
Dec  3 16:16:30.567: INFO: Created: latency-svc-89crj
Dec  3 16:16:30.572: INFO: Created: latency-svc-rwtmz
Dec  3 16:16:30.589: INFO: Got endpoints: latency-svc-mxc4j [141.825177ms]
Dec  3 16:16:30.589: INFO: Got endpoints: latency-svc-tl6p5 [146.400843ms]
Dec  3 16:16:30.590: INFO: Got endpoints: latency-svc-pdtz8 [132.828655ms]
Dec  3 16:16:30.590: INFO: Got endpoints: latency-svc-dzskv [137.879691ms]
Dec  3 16:16:30.590: INFO: Got endpoints: latency-svc-x27fp [128.664979ms]
Dec  3 16:16:30.593: INFO: Got endpoints: latency-svc-p8x82 [119.66924ms]
Dec  3 16:16:30.593: INFO: Got endpoints: latency-svc-ltvs5 [102.474851ms]
Dec  3 16:16:30.593: INFO: Got endpoints: latency-svc-b6kks [102.625961ms]
Dec  3 16:16:30.593: INFO: Got endpoints: latency-svc-ngk2r [102.729133ms]
Dec  3 16:16:30.593: INFO: Got endpoints: latency-svc-khn86 [124.221032ms]
Dec  3 16:16:30.595: INFO: Got endpoints: latency-svc-89crj [96.650809ms]
Dec  3 16:16:30.596: INFO: Got endpoints: latency-svc-nrd4n [104.827833ms]
Dec  3 16:16:30.596: INFO: Got endpoints: latency-svc-nwx85 [105.177529ms]
Dec  3 16:16:30.596: INFO: Got endpoints: latency-svc-jzd7m [101.896461ms]
Dec  3 16:16:30.603: INFO: Created: latency-svc-z45tm
Dec  3 16:16:30.607: INFO: Created: latency-svc-njlt9
Dec  3 16:16:30.612: INFO: Got endpoints: latency-svc-rwtmz [110.999201ms]
Dec  3 16:16:30.612: INFO: Created: latency-svc-f7bdm
Dec  3 16:16:30.615: INFO: Created: latency-svc-sqf6k
Dec  3 16:16:30.620: INFO: Created: latency-svc-mxzts
Dec  3 16:16:30.624: INFO: Created: latency-svc-8jdw8
Dec  3 16:16:30.628: INFO: Created: latency-svc-brcs9
Dec  3 16:16:30.632: INFO: Created: latency-svc-vxlhw
Dec  3 16:16:30.640: INFO: Created: latency-svc-f2mpn
Dec  3 16:16:30.644: INFO: Created: latency-svc-6hjxb
Dec  3 16:16:30.648: INFO: Created: latency-svc-g9hb4
Dec  3 16:16:30.652: INFO: Created: latency-svc-sbj9c
Dec  3 16:16:30.656: INFO: Created: latency-svc-qxqsv
Dec  3 16:16:30.661: INFO: Created: latency-svc-n4lgr
Dec  3 16:16:30.665: INFO: Created: latency-svc-cs7zc
Dec  3 16:16:30.688: INFO: Got endpoints: latency-svc-z45tm [99.536958ms]
Dec  3 16:16:30.703: INFO: Created: latency-svc-mgfjb
Dec  3 16:16:30.711: INFO: Got endpoints: latency-svc-njlt9 [121.226056ms]
Dec  3 16:16:30.731: INFO: Created: latency-svc-wbjb6
Dec  3 16:16:30.761: INFO: Got endpoints: latency-svc-f7bdm [171.536374ms]
Dec  3 16:16:30.776: INFO: Created: latency-svc-qwxlm
Dec  3 16:16:30.811: INFO: Got endpoints: latency-svc-sqf6k [221.447532ms]
Dec  3 16:16:30.826: INFO: Created: latency-svc-zd8ls
Dec  3 16:16:30.861: INFO: Got endpoints: latency-svc-mxzts [271.22261ms]
Dec  3 16:16:30.876: INFO: Created: latency-svc-jcftd
Dec  3 16:16:30.911: INFO: Got endpoints: latency-svc-8jdw8 [318.053835ms]
Dec  3 16:16:30.925: INFO: Created: latency-svc-8gfqq
Dec  3 16:16:30.961: INFO: Got endpoints: latency-svc-brcs9 [367.673305ms]
Dec  3 16:16:30.975: INFO: Created: latency-svc-4dggc
Dec  3 16:16:31.011: INFO: Got endpoints: latency-svc-vxlhw [417.445858ms]
Dec  3 16:16:31.025: INFO: Created: latency-svc-9hp5c
Dec  3 16:16:31.061: INFO: Got endpoints: latency-svc-f2mpn [467.692661ms]
Dec  3 16:16:31.075: INFO: Created: latency-svc-jfklz
Dec  3 16:16:31.111: INFO: Got endpoints: latency-svc-6hjxb [517.700407ms]
Dec  3 16:16:31.126: INFO: Created: latency-svc-vl4jk
Dec  3 16:16:31.161: INFO: Got endpoints: latency-svc-g9hb4 [565.383001ms]
Dec  3 16:16:31.175: INFO: Created: latency-svc-27rwk
Dec  3 16:16:31.211: INFO: Got endpoints: latency-svc-sbj9c [615.481808ms]
Dec  3 16:16:31.226: INFO: Created: latency-svc-n6zsc
Dec  3 16:16:31.261: INFO: Got endpoints: latency-svc-qxqsv [664.816822ms]
Dec  3 16:16:31.276: INFO: Created: latency-svc-gbhf2
Dec  3 16:16:31.311: INFO: Got endpoints: latency-svc-n4lgr [714.831796ms]
Dec  3 16:16:31.325: INFO: Created: latency-svc-ghwb2
Dec  3 16:16:31.361: INFO: Got endpoints: latency-svc-cs7zc [749.672642ms]
Dec  3 16:16:31.376: INFO: Created: latency-svc-7g92h
Dec  3 16:16:31.411: INFO: Got endpoints: latency-svc-mgfjb [722.476658ms]
Dec  3 16:16:31.425: INFO: Created: latency-svc-tdgdf
Dec  3 16:16:31.461: INFO: Got endpoints: latency-svc-wbjb6 [750.105349ms]
Dec  3 16:16:31.475: INFO: Created: latency-svc-rktmv
Dec  3 16:16:31.511: INFO: Got endpoints: latency-svc-qwxlm [749.316685ms]
Dec  3 16:16:31.525: INFO: Created: latency-svc-ml7z6
Dec  3 16:16:31.561: INFO: Got endpoints: latency-svc-zd8ls [749.674392ms]
Dec  3 16:16:31.575: INFO: Created: latency-svc-kg824
Dec  3 16:16:31.611: INFO: Got endpoints: latency-svc-jcftd [749.811642ms]
Dec  3 16:16:31.626: INFO: Created: latency-svc-knng5
Dec  3 16:16:31.661: INFO: Got endpoints: latency-svc-8gfqq [749.627566ms]
Dec  3 16:16:31.675: INFO: Created: latency-svc-lrj62
Dec  3 16:16:31.711: INFO: Got endpoints: latency-svc-4dggc [750.311559ms]
Dec  3 16:16:31.725: INFO: Created: latency-svc-l8xn2
Dec  3 16:16:31.761: INFO: Got endpoints: latency-svc-9hp5c [749.896367ms]
Dec  3 16:16:31.779: INFO: Created: latency-svc-wfdzm
Dec  3 16:16:31.811: INFO: Got endpoints: latency-svc-jfklz [750.211836ms]
Dec  3 16:16:31.826: INFO: Created: latency-svc-rwpn4
Dec  3 16:16:31.861: INFO: Got endpoints: latency-svc-vl4jk [749.861939ms]
Dec  3 16:16:31.879: INFO: Created: latency-svc-tqdsn
Dec  3 16:16:31.911: INFO: Got endpoints: latency-svc-27rwk [750.079601ms]
Dec  3 16:16:31.926: INFO: Created: latency-svc-hq4h9
Dec  3 16:16:31.961: INFO: Got endpoints: latency-svc-n6zsc [749.90967ms]
Dec  3 16:16:31.976: INFO: Created: latency-svc-kwk2g
Dec  3 16:16:32.011: INFO: Got endpoints: latency-svc-gbhf2 [749.588356ms]
Dec  3 16:16:32.027: INFO: Created: latency-svc-qpdnh
Dec  3 16:16:32.061: INFO: Got endpoints: latency-svc-ghwb2 [749.924469ms]
Dec  3 16:16:32.076: INFO: Created: latency-svc-w5285
Dec  3 16:16:32.111: INFO: Got endpoints: latency-svc-7g92h [749.210923ms]
Dec  3 16:16:32.130: INFO: Created: latency-svc-n97w7
Dec  3 16:16:32.161: INFO: Got endpoints: latency-svc-tdgdf [749.697932ms]
Dec  3 16:16:32.176: INFO: Created: latency-svc-774p6
Dec  3 16:16:32.211: INFO: Got endpoints: latency-svc-rktmv [750.206448ms]
Dec  3 16:16:32.230: INFO: Created: latency-svc-ghf8d
Dec  3 16:16:32.261: INFO: Got endpoints: latency-svc-ml7z6 [750.396512ms]
Dec  3 16:16:32.279: INFO: Created: latency-svc-ncqzm
Dec  3 16:16:32.311: INFO: Got endpoints: latency-svc-kg824 [750.562295ms]
Dec  3 16:16:32.326: INFO: Created: latency-svc-bt2zp
Dec  3 16:16:32.362: INFO: Got endpoints: latency-svc-knng5 [751.269611ms]
Dec  3 16:16:32.377: INFO: Created: latency-svc-xvwql
Dec  3 16:16:32.411: INFO: Got endpoints: latency-svc-lrj62 [750.437583ms]
Dec  3 16:16:32.426: INFO: Created: latency-svc-9nbp4
Dec  3 16:16:32.461: INFO: Got endpoints: latency-svc-l8xn2 [749.942694ms]
Dec  3 16:16:32.476: INFO: Created: latency-svc-mlxfg
Dec  3 16:16:32.511: INFO: Got endpoints: latency-svc-wfdzm [750.253312ms]
Dec  3 16:16:32.526: INFO: Created: latency-svc-wxs7j
Dec  3 16:16:32.589: INFO: Got endpoints: latency-svc-rwpn4 [777.672555ms]
Dec  3 16:16:32.604: INFO: Created: latency-svc-cr8wz
Dec  3 16:16:32.611: INFO: Got endpoints: latency-svc-tqdsn [750.009857ms]
Dec  3 16:16:32.626: INFO: Created: latency-svc-wkkxg
Dec  3 16:16:32.661: INFO: Got endpoints: latency-svc-hq4h9 [750.349707ms]
Dec  3 16:16:32.676: INFO: Created: latency-svc-vtghb
Dec  3 16:16:32.711: INFO: Got endpoints: latency-svc-kwk2g [749.915624ms]
Dec  3 16:16:32.726: INFO: Created: latency-svc-f8q2n
Dec  3 16:16:32.761: INFO: Got endpoints: latency-svc-qpdnh [749.986847ms]
Dec  3 16:16:32.776: INFO: Created: latency-svc-c45x5
Dec  3 16:16:32.811: INFO: Got endpoints: latency-svc-w5285 [750.193934ms]
Dec  3 16:16:32.826: INFO: Created: latency-svc-749bx
Dec  3 16:16:32.861: INFO: Got endpoints: latency-svc-n97w7 [750.256302ms]
Dec  3 16:16:32.876: INFO: Created: latency-svc-9kx2g
Dec  3 16:16:32.910: INFO: Got endpoints: latency-svc-774p6 [749.595577ms]
Dec  3 16:16:32.927: INFO: Created: latency-svc-rj28n
Dec  3 16:16:32.961: INFO: Got endpoints: latency-svc-ghf8d [749.577682ms]
Dec  3 16:16:32.976: INFO: Created: latency-svc-9jm7p
Dec  3 16:16:33.011: INFO: Got endpoints: latency-svc-ncqzm [749.842002ms]
Dec  3 16:16:33.026: INFO: Created: latency-svc-8bdv5
Dec  3 16:16:33.061: INFO: Got endpoints: latency-svc-bt2zp [749.258623ms]
Dec  3 16:16:33.076: INFO: Created: latency-svc-49t9q
Dec  3 16:16:33.111: INFO: Got endpoints: latency-svc-xvwql [748.816219ms]
Dec  3 16:16:33.127: INFO: Created: latency-svc-kh956
Dec  3 16:16:33.161: INFO: Got endpoints: latency-svc-9nbp4 [749.64498ms]
Dec  3 16:16:33.176: INFO: Created: latency-svc-pm9xp
Dec  3 16:16:33.211: INFO: Got endpoints: latency-svc-mlxfg [749.882011ms]
Dec  3 16:16:33.226: INFO: Created: latency-svc-qcvhc
Dec  3 16:16:33.261: INFO: Got endpoints: latency-svc-wxs7j [750.246341ms]
Dec  3 16:16:33.276: INFO: Created: latency-svc-djb5x
Dec  3 16:16:33.311: INFO: Got endpoints: latency-svc-cr8wz [721.969375ms]
Dec  3 16:16:33.326: INFO: Created: latency-svc-9g7bv
Dec  3 16:16:33.361: INFO: Got endpoints: latency-svc-wkkxg [750.151869ms]
Dec  3 16:16:33.377: INFO: Created: latency-svc-xhqvv
Dec  3 16:16:33.411: INFO: Got endpoints: latency-svc-vtghb [749.683324ms]
Dec  3 16:16:33.426: INFO: Created: latency-svc-nv529
Dec  3 16:16:33.461: INFO: Got endpoints: latency-svc-f8q2n [749.889428ms]
Dec  3 16:16:33.476: INFO: Created: latency-svc-ztv9m
Dec  3 16:16:33.511: INFO: Got endpoints: latency-svc-c45x5 [750.240169ms]
Dec  3 16:16:33.529: INFO: Created: latency-svc-hrvlq
Dec  3 16:16:33.564: INFO: Got endpoints: latency-svc-749bx [752.667734ms]
Dec  3 16:16:33.579: INFO: Created: latency-svc-4kw56
Dec  3 16:16:33.611: INFO: Got endpoints: latency-svc-9kx2g [749.947562ms]
Dec  3 16:16:33.626: INFO: Created: latency-svc-bhbvs
Dec  3 16:16:33.661: INFO: Got endpoints: latency-svc-rj28n [750.214788ms]
Dec  3 16:16:33.675: INFO: Created: latency-svc-zw8kh
Dec  3 16:16:33.711: INFO: Got endpoints: latency-svc-9jm7p [749.878668ms]
Dec  3 16:16:33.726: INFO: Created: latency-svc-gxkdd
Dec  3 16:16:33.761: INFO: Got endpoints: latency-svc-8bdv5 [749.932536ms]
Dec  3 16:16:33.777: INFO: Created: latency-svc-qrhm9
Dec  3 16:16:33.811: INFO: Got endpoints: latency-svc-49t9q [750.133112ms]
Dec  3 16:16:33.827: INFO: Created: latency-svc-kdfgm
Dec  3 16:16:33.861: INFO: Got endpoints: latency-svc-kh956 [749.742888ms]
Dec  3 16:16:33.876: INFO: Created: latency-svc-6fcqc
Dec  3 16:16:33.911: INFO: Got endpoints: latency-svc-pm9xp [749.236887ms]
Dec  3 16:16:33.925: INFO: Created: latency-svc-m4vxf
Dec  3 16:16:33.961: INFO: Got endpoints: latency-svc-qcvhc [749.515886ms]
Dec  3 16:16:33.975: INFO: Created: latency-svc-w9b24
Dec  3 16:16:34.011: INFO: Got endpoints: latency-svc-djb5x [750.113145ms]
Dec  3 16:16:34.026: INFO: Created: latency-svc-xkx5q
Dec  3 16:16:34.061: INFO: Got endpoints: latency-svc-9g7bv [749.868474ms]
Dec  3 16:16:34.078: INFO: Created: latency-svc-wh9m2
Dec  3 16:16:34.111: INFO: Got endpoints: latency-svc-xhqvv [749.830372ms]
Dec  3 16:16:34.126: INFO: Created: latency-svc-cv696
Dec  3 16:16:34.161: INFO: Got endpoints: latency-svc-nv529 [749.570743ms]
Dec  3 16:16:34.180: INFO: Created: latency-svc-75frs
Dec  3 16:16:34.211: INFO: Got endpoints: latency-svc-ztv9m [749.485578ms]
Dec  3 16:16:34.227: INFO: Created: latency-svc-r49dj
Dec  3 16:16:34.261: INFO: Got endpoints: latency-svc-hrvlq [749.267802ms]
Dec  3 16:16:34.275: INFO: Created: latency-svc-l4w4h
Dec  3 16:16:34.311: INFO: Got endpoints: latency-svc-4kw56 [746.873378ms]
Dec  3 16:16:34.325: INFO: Created: latency-svc-96xtm
Dec  3 16:16:34.361: INFO: Got endpoints: latency-svc-bhbvs [750.21112ms]
Dec  3 16:16:34.376: INFO: Created: latency-svc-gb2jg
Dec  3 16:16:34.411: INFO: Got endpoints: latency-svc-zw8kh [750.102481ms]
Dec  3 16:16:34.426: INFO: Created: latency-svc-r28bf
Dec  3 16:16:34.461: INFO: Got endpoints: latency-svc-gxkdd [749.902716ms]
Dec  3 16:16:34.475: INFO: Created: latency-svc-59vbx
Dec  3 16:16:34.511: INFO: Got endpoints: latency-svc-qrhm9 [749.843921ms]
Dec  3 16:16:34.525: INFO: Created: latency-svc-lhfcm
Dec  3 16:16:34.561: INFO: Got endpoints: latency-svc-kdfgm [750.212437ms]
Dec  3 16:16:34.576: INFO: Created: latency-svc-vpwgp
Dec  3 16:16:34.611: INFO: Got endpoints: latency-svc-6fcqc [749.525814ms]
Dec  3 16:16:34.625: INFO: Created: latency-svc-27r5z
Dec  3 16:16:34.661: INFO: Got endpoints: latency-svc-m4vxf [750.427322ms]
Dec  3 16:16:34.676: INFO: Created: latency-svc-fmd76
Dec  3 16:16:34.711: INFO: Got endpoints: latency-svc-w9b24 [750.068254ms]
Dec  3 16:16:34.725: INFO: Created: latency-svc-29mmc
Dec  3 16:16:34.761: INFO: Got endpoints: latency-svc-xkx5q [749.294965ms]
Dec  3 16:16:34.776: INFO: Created: latency-svc-zqx5g
Dec  3 16:16:34.811: INFO: Got endpoints: latency-svc-wh9m2 [749.904253ms]
Dec  3 16:16:34.826: INFO: Created: latency-svc-gsjpr
Dec  3 16:16:34.861: INFO: Got endpoints: latency-svc-cv696 [749.566061ms]
Dec  3 16:16:34.875: INFO: Created: latency-svc-vgk6j
Dec  3 16:16:34.912: INFO: Got endpoints: latency-svc-75frs [751.519279ms]
Dec  3 16:16:34.927: INFO: Created: latency-svc-sm5s4
Dec  3 16:16:34.961: INFO: Got endpoints: latency-svc-r49dj [750.019454ms]
Dec  3 16:16:34.976: INFO: Created: latency-svc-4m6gh
Dec  3 16:16:35.011: INFO: Got endpoints: latency-svc-l4w4h [750.194332ms]
Dec  3 16:16:35.027: INFO: Created: latency-svc-nsfjk
Dec  3 16:16:35.061: INFO: Got endpoints: latency-svc-96xtm [749.822969ms]
Dec  3 16:16:35.077: INFO: Created: latency-svc-bzjnh
Dec  3 16:16:35.111: INFO: Got endpoints: latency-svc-gb2jg [749.851915ms]
Dec  3 16:16:35.129: INFO: Created: latency-svc-cg7f4
Dec  3 16:16:35.161: INFO: Got endpoints: latency-svc-r28bf [749.976825ms]
Dec  3 16:16:35.177: INFO: Created: latency-svc-64hcd
Dec  3 16:16:35.211: INFO: Got endpoints: latency-svc-59vbx [750.317184ms]
Dec  3 16:16:35.229: INFO: Created: latency-svc-42vww
Dec  3 16:16:35.261: INFO: Got endpoints: latency-svc-lhfcm [749.728042ms]
Dec  3 16:16:35.275: INFO: Created: latency-svc-8jt5t
Dec  3 16:16:35.311: INFO: Got endpoints: latency-svc-vpwgp [749.270772ms]
Dec  3 16:16:35.326: INFO: Created: latency-svc-znsrx
Dec  3 16:16:35.361: INFO: Got endpoints: latency-svc-27r5z [750.292762ms]
Dec  3 16:16:35.376: INFO: Created: latency-svc-cgz7j
Dec  3 16:16:35.412: INFO: Got endpoints: latency-svc-fmd76 [750.524211ms]
Dec  3 16:16:35.428: INFO: Created: latency-svc-5x8ht
Dec  3 16:16:35.461: INFO: Got endpoints: latency-svc-29mmc [750.334252ms]
Dec  3 16:16:35.476: INFO: Created: latency-svc-56bsz
Dec  3 16:16:35.511: INFO: Got endpoints: latency-svc-zqx5g [749.981953ms]
Dec  3 16:16:35.526: INFO: Created: latency-svc-85p8g
Dec  3 16:16:35.561: INFO: Got endpoints: latency-svc-gsjpr [750.314292ms]
Dec  3 16:16:35.576: INFO: Created: latency-svc-vg6tn
Dec  3 16:16:35.611: INFO: Got endpoints: latency-svc-vgk6j [750.035144ms]
Dec  3 16:16:35.626: INFO: Created: latency-svc-l5fmb
Dec  3 16:16:35.661: INFO: Got endpoints: latency-svc-sm5s4 [748.950344ms]
Dec  3 16:16:35.676: INFO: Created: latency-svc-4hz67
Dec  3 16:16:35.711: INFO: Got endpoints: latency-svc-4m6gh [750.153558ms]
Dec  3 16:16:35.727: INFO: Created: latency-svc-6vjjt
Dec  3 16:16:35.761: INFO: Got endpoints: latency-svc-nsfjk [750.01078ms]
Dec  3 16:16:35.776: INFO: Created: latency-svc-wnqdh
Dec  3 16:16:35.811: INFO: Got endpoints: latency-svc-bzjnh [749.982967ms]
Dec  3 16:16:35.826: INFO: Created: latency-svc-97gcc
Dec  3 16:16:35.861: INFO: Got endpoints: latency-svc-cg7f4 [749.535504ms]
Dec  3 16:16:35.876: INFO: Created: latency-svc-hzvtj
Dec  3 16:16:35.911: INFO: Got endpoints: latency-svc-64hcd [750.294221ms]
Dec  3 16:16:35.927: INFO: Created: latency-svc-4558c
Dec  3 16:16:35.961: INFO: Got endpoints: latency-svc-42vww [749.892017ms]
Dec  3 16:16:35.976: INFO: Created: latency-svc-45df5
Dec  3 16:16:36.011: INFO: Got endpoints: latency-svc-8jt5t [750.219655ms]
Dec  3 16:16:36.026: INFO: Created: latency-svc-kkn4b
Dec  3 16:16:36.065: INFO: Got endpoints: latency-svc-znsrx [754.33544ms]
Dec  3 16:16:36.080: INFO: Created: latency-svc-wsplw
Dec  3 16:16:36.161: INFO: Got endpoints: latency-svc-5x8ht [749.700634ms]
Dec  3 16:16:36.176: INFO: Created: latency-svc-bvj9m
Dec  3 16:16:36.188: INFO: Got endpoints: latency-svc-cgz7j [827.415687ms]
Dec  3 16:16:36.204: INFO: Created: latency-svc-j2clt
Dec  3 16:16:36.210: INFO: Got endpoints: latency-svc-56bsz [749.058491ms]
Dec  3 16:16:36.226: INFO: Created: latency-svc-x27mc
Dec  3 16:16:36.260: INFO: Got endpoints: latency-svc-85p8g [749.483049ms]
Dec  3 16:16:36.279: INFO: Created: latency-svc-5fg26
Dec  3 16:16:36.311: INFO: Got endpoints: latency-svc-vg6tn [749.353647ms]
Dec  3 16:16:36.325: INFO: Created: latency-svc-qws45
Dec  3 16:16:36.361: INFO: Got endpoints: latency-svc-l5fmb [750.115451ms]
Dec  3 16:16:36.379: INFO: Created: latency-svc-xxsdz
Dec  3 16:16:36.411: INFO: Got endpoints: latency-svc-4hz67 [749.426873ms]
Dec  3 16:16:36.426: INFO: Created: latency-svc-8xh89
Dec  3 16:16:36.461: INFO: Got endpoints: latency-svc-6vjjt [749.965452ms]
Dec  3 16:16:36.476: INFO: Created: latency-svc-266tb
Dec  3 16:16:36.511: INFO: Got endpoints: latency-svc-wnqdh [749.67405ms]
Dec  3 16:16:36.525: INFO: Created: latency-svc-np6xl
Dec  3 16:16:36.561: INFO: Got endpoints: latency-svc-97gcc [749.891593ms]
Dec  3 16:16:36.576: INFO: Created: latency-svc-kkqjk
Dec  3 16:16:36.611: INFO: Got endpoints: latency-svc-hzvtj [750.517125ms]
Dec  3 16:16:36.626: INFO: Created: latency-svc-vg68z
Dec  3 16:16:36.661: INFO: Got endpoints: latency-svc-4558c [749.380774ms]
Dec  3 16:16:36.675: INFO: Created: latency-svc-s84nm
Dec  3 16:16:36.711: INFO: Got endpoints: latency-svc-45df5 [749.706458ms]
Dec  3 16:16:36.726: INFO: Created: latency-svc-mslc7
Dec  3 16:16:36.761: INFO: Got endpoints: latency-svc-kkn4b [749.880715ms]
Dec  3 16:16:36.776: INFO: Created: latency-svc-swlfj
Dec  3 16:16:36.812: INFO: Got endpoints: latency-svc-wsplw [746.449768ms]
Dec  3 16:16:36.827: INFO: Created: latency-svc-npnh9
Dec  3 16:16:36.889: INFO: Got endpoints: latency-svc-bvj9m [727.210515ms]
Dec  3 16:16:36.907: INFO: Created: latency-svc-7hlbl
Dec  3 16:16:36.961: INFO: Got endpoints: latency-svc-x27mc [750.596962ms]
Dec  3 16:16:36.976: INFO: Created: latency-svc-jzd9p
Dec  3 16:16:36.999: INFO: Got endpoints: latency-svc-j2clt [810.662435ms]
Dec  3 16:16:37.014: INFO: Created: latency-svc-2qz9h
Dec  3 16:16:37.088: INFO: Got endpoints: latency-svc-5fg26 [827.918972ms]
Dec  3 16:16:37.089: INFO: Got endpoints: latency-svc-qws45 [778.352593ms]
Dec  3 16:16:37.103: INFO: Created: latency-svc-dxxrs
Dec  3 16:16:37.111: INFO: Got endpoints: latency-svc-xxsdz [750.244633ms]
Dec  3 16:16:37.112: INFO: Created: latency-svc-gt5r4
Dec  3 16:16:37.126: INFO: Created: latency-svc-jpxwm
Dec  3 16:16:37.189: INFO: Got endpoints: latency-svc-8xh89 [777.893078ms]
Dec  3 16:16:37.204: INFO: Created: latency-svc-658jc
Dec  3 16:16:37.211: INFO: Got endpoints: latency-svc-266tb [749.644355ms]
Dec  3 16:16:37.226: INFO: Created: latency-svc-flgwx
Dec  3 16:16:37.261: INFO: Got endpoints: latency-svc-np6xl [750.290961ms]
Dec  3 16:16:37.276: INFO: Created: latency-svc-c9j9x
Dec  3 16:16:37.311: INFO: Got endpoints: latency-svc-kkqjk [749.462399ms]
Dec  3 16:16:37.325: INFO: Created: latency-svc-qvpg6
Dec  3 16:16:37.361: INFO: Got endpoints: latency-svc-vg68z [749.622374ms]
Dec  3 16:16:37.387: INFO: Created: latency-svc-r8fv6
Dec  3 16:16:37.411: INFO: Got endpoints: latency-svc-s84nm [750.211218ms]
Dec  3 16:16:37.429: INFO: Created: latency-svc-qwx8k
Dec  3 16:16:37.461: INFO: Got endpoints: latency-svc-mslc7 [749.952964ms]
Dec  3 16:16:37.475: INFO: Created: latency-svc-plk6l
Dec  3 16:16:37.511: INFO: Got endpoints: latency-svc-swlfj [749.722915ms]
Dec  3 16:16:37.532: INFO: Created: latency-svc-w7g74
Dec  3 16:16:37.561: INFO: Got endpoints: latency-svc-npnh9 [749.734325ms]
Dec  3 16:16:37.581: INFO: Created: latency-svc-krwfp
Dec  3 16:16:37.611: INFO: Got endpoints: latency-svc-7hlbl [722.245383ms]
Dec  3 16:16:37.626: INFO: Created: latency-svc-jfxld
Dec  3 16:16:37.661: INFO: Got endpoints: latency-svc-jzd9p [699.965519ms]
Dec  3 16:16:37.676: INFO: Created: latency-svc-fdprv
Dec  3 16:16:37.711: INFO: Got endpoints: latency-svc-2qz9h [712.049636ms]
Dec  3 16:16:37.726: INFO: Created: latency-svc-k6thr
Dec  3 16:16:37.761: INFO: Got endpoints: latency-svc-dxxrs [672.520916ms]
Dec  3 16:16:37.776: INFO: Created: latency-svc-m9b2h
Dec  3 16:16:37.811: INFO: Got endpoints: latency-svc-gt5r4 [721.874945ms]
Dec  3 16:16:37.826: INFO: Created: latency-svc-xjmjv
Dec  3 16:16:37.861: INFO: Got endpoints: latency-svc-jpxwm [749.163798ms]
Dec  3 16:16:37.875: INFO: Created: latency-svc-lthl2
Dec  3 16:16:37.911: INFO: Got endpoints: latency-svc-658jc [721.65622ms]
Dec  3 16:16:37.925: INFO: Created: latency-svc-jbrd8
Dec  3 16:16:37.961: INFO: Got endpoints: latency-svc-flgwx [750.439227ms]
Dec  3 16:16:37.977: INFO: Created: latency-svc-bfz6w
Dec  3 16:16:38.011: INFO: Got endpoints: latency-svc-c9j9x [749.783363ms]
Dec  3 16:16:38.027: INFO: Created: latency-svc-hnbzs
Dec  3 16:16:38.061: INFO: Got endpoints: latency-svc-qvpg6 [750.456768ms]
Dec  3 16:16:38.077: INFO: Created: latency-svc-6fjb7
Dec  3 16:16:38.111: INFO: Got endpoints: latency-svc-r8fv6 [749.912698ms]
Dec  3 16:16:38.126: INFO: Created: latency-svc-46w6h
Dec  3 16:16:38.162: INFO: Got endpoints: latency-svc-qwx8k [750.348083ms]
Dec  3 16:16:38.177: INFO: Created: latency-svc-rssbp
Dec  3 16:16:38.211: INFO: Got endpoints: latency-svc-plk6l [749.985454ms]
Dec  3 16:16:38.226: INFO: Created: latency-svc-jbsgf
Dec  3 16:16:38.261: INFO: Got endpoints: latency-svc-w7g74 [750.110232ms]
Dec  3 16:16:38.312: INFO: Got endpoints: latency-svc-krwfp [750.067742ms]
Dec  3 16:16:38.361: INFO: Got endpoints: latency-svc-jfxld [750.03777ms]
Dec  3 16:16:38.411: INFO: Got endpoints: latency-svc-fdprv [749.550764ms]
Dec  3 16:16:38.461: INFO: Got endpoints: latency-svc-k6thr [749.643911ms]
Dec  3 16:16:38.511: INFO: Got endpoints: latency-svc-m9b2h [749.925036ms]
Dec  3 16:16:38.562: INFO: Got endpoints: latency-svc-xjmjv [750.420602ms]
Dec  3 16:16:38.611: INFO: Got endpoints: latency-svc-lthl2 [750.348388ms]
Dec  3 16:16:38.661: INFO: Got endpoints: latency-svc-jbrd8 [750.467824ms]
Dec  3 16:16:38.711: INFO: Got endpoints: latency-svc-bfz6w [749.862159ms]
Dec  3 16:16:38.761: INFO: Got endpoints: latency-svc-hnbzs [750.122819ms]
Dec  3 16:16:38.811: INFO: Got endpoints: latency-svc-6fjb7 [749.991429ms]
Dec  3 16:16:38.861: INFO: Got endpoints: latency-svc-46w6h [749.576332ms]
Dec  3 16:16:38.911: INFO: Got endpoints: latency-svc-rssbp [749.58358ms]
Dec  3 16:16:38.961: INFO: Got endpoints: latency-svc-jbsgf [750.031423ms]
Dec  3 16:16:38.961: INFO: Latencies: [22.197644ms 23.006954ms 26.49354ms 31.200282ms 35.161428ms 39.72403ms 44.527797ms 48.771497ms 56.368224ms 60.823356ms 60.881531ms 62.036846ms 63.907709ms 77.822728ms 77.849763ms 77.964163ms 78.013305ms 78.098098ms 96.650809ms 99.536958ms 101.896461ms 102.474851ms 102.625961ms 102.729133ms 104.827833ms 105.177529ms 110.999201ms 119.66924ms 121.226056ms 124.221032ms 128.664979ms 132.828655ms 137.879691ms 141.825177ms 146.400843ms 171.536374ms 221.447532ms 271.22261ms 318.053835ms 367.673305ms 417.445858ms 467.692661ms 517.700407ms 565.383001ms 615.481808ms 664.816822ms 672.520916ms 699.965519ms 712.049636ms 714.831796ms 721.65622ms 721.874945ms 721.969375ms 722.245383ms 722.476658ms 727.210515ms 746.449768ms 746.873378ms 748.816219ms 748.950344ms 749.058491ms 749.163798ms 749.210923ms 749.236887ms 749.258623ms 749.267802ms 749.270772ms 749.294965ms 749.316685ms 749.353647ms 749.380774ms 749.426873ms 749.462399ms 749.483049ms 749.485578ms 749.515886ms 749.525814ms 749.535504ms 749.550764ms 749.566061ms 749.570743ms 749.576332ms 749.577682ms 749.58358ms 749.588356ms 749.595577ms 749.622374ms 749.627566ms 749.643911ms 749.644355ms 749.64498ms 749.672642ms 749.67405ms 749.674392ms 749.683324ms 749.697932ms 749.700634ms 749.706458ms 749.722915ms 749.728042ms 749.734325ms 749.742888ms 749.783363ms 749.811642ms 749.822969ms 749.830372ms 749.842002ms 749.843921ms 749.851915ms 749.861939ms 749.862159ms 749.868474ms 749.878668ms 749.880715ms 749.882011ms 749.889428ms 749.891593ms 749.892017ms 749.896367ms 749.902716ms 749.904253ms 749.90967ms 749.912698ms 749.915624ms 749.924469ms 749.925036ms 749.932536ms 749.942694ms 749.947562ms 749.952964ms 749.965452ms 749.976825ms 749.981953ms 749.982967ms 749.985454ms 749.986847ms 749.991429ms 750.009857ms 750.01078ms 750.019454ms 750.031423ms 750.035144ms 750.03777ms 750.067742ms 750.068254ms 750.079601ms 750.102481ms 750.105349ms 750.110232ms 750.113145ms 750.115451ms 750.122819ms 750.133112ms 750.151869ms 750.153558ms 750.193934ms 750.194332ms 750.206448ms 750.21112ms 750.211218ms 750.211836ms 750.212437ms 750.214788ms 750.219655ms 750.240169ms 750.244633ms 750.246341ms 750.253312ms 750.256302ms 750.290961ms 750.292762ms 750.294221ms 750.311559ms 750.314292ms 750.317184ms 750.334252ms 750.348083ms 750.348388ms 750.349707ms 750.396512ms 750.420602ms 750.427322ms 750.437583ms 750.439227ms 750.456768ms 750.467824ms 750.517125ms 750.524211ms 750.562295ms 750.596962ms 751.269611ms 751.519279ms 752.667734ms 754.33544ms 777.672555ms 777.893078ms 778.352593ms 810.662435ms 827.415687ms 827.918972ms]
Dec  3 16:16:38.962: INFO: 50 %ile: 749.734325ms
Dec  3 16:16:38.962: INFO: 90 %ile: 750.420602ms
Dec  3 16:16:38.962: INFO: 99 %ile: 827.415687ms
Dec  3 16:16:38.962: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:16:38.962: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-1197" for this suite.
Dec  3 16:16:57.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:16:57.341: INFO: namespace svc-latency-1197 deletion completed in 18.369094503s
•SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:16:57.341: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8927
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 16:16:58.279: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986618, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986618, loc:(*time.Location)(0x84bfb00)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-86d95b659d\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986618, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986618, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
Dec  3 16:17:00.290: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986618, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986618, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986618, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986618, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 16:17:03.306: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:17:03.317: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:17:04.349: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8927" for this suite.
Dec  3 16:17:10.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:17:10.729: INFO: namespace webhook-8927 deletion completed in 6.362001738s
STEP: Destroying namespace "webhook-8927-markers" for this suite.
Dec  3 16:17:16.760: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:17:17.095: INFO: namespace webhook-8927-markers deletion completed in 6.366255457s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:17:17.136: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-6888
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:17:17.359: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-6888" for this suite.
Dec  3 16:17:23.399: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:17:23.746: INFO: namespace custom-resource-definition-6888 deletion completed in 6.376654968s
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:17:23.747: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9963
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-978d2e2b-2e98-4cc6-b90a-646d4b2b4a2f
STEP: Creating a pod to test consume secrets
Dec  3 16:17:23.960: INFO: Waiting up to 5m0s for pod "pod-secrets-0e7dc47e-e958-49b7-8f39-2c72a5afc8f9" in namespace "secrets-9963" to be "success or failure"
Dec  3 16:17:23.969: INFO: Pod "pod-secrets-0e7dc47e-e958-49b7-8f39-2c72a5afc8f9": Phase="Pending", Reason="", readiness=false. Elapsed: 9.560259ms
Dec  3 16:17:25.979: INFO: Pod "pod-secrets-0e7dc47e-e958-49b7-8f39-2c72a5afc8f9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.0195407s
STEP: Saw pod success
Dec  3 16:17:25.979: INFO: Pod "pod-secrets-0e7dc47e-e958-49b7-8f39-2c72a5afc8f9" satisfied condition "success or failure"
Dec  3 16:17:25.989: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-secrets-0e7dc47e-e958-49b7-8f39-2c72a5afc8f9 container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:17:26.035: INFO: Waiting for pod pod-secrets-0e7dc47e-e958-49b7-8f39-2c72a5afc8f9 to disappear
Dec  3 16:17:26.045: INFO: Pod pod-secrets-0e7dc47e-e958-49b7-8f39-2c72a5afc8f9 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:17:26.045: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9963" for this suite.
Dec  3 16:17:32.096: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:17:32.452: INFO: namespace secrets-9963 deletion completed in 6.388465623s
•SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:17:32.453: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2209
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 16:17:33.284: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986653, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986653, loc:(*time.Location)(0x84bfb00)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-86d95b659d\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986653, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986653, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 16:17:36.312: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:17:36.323: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4875-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:17:37.285: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2209" for this suite.
Dec  3 16:17:43.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:17:43.705: INFO: namespace webhook-2209 deletion completed in 6.400991602s
STEP: Destroying namespace "webhook-2209-markers" for this suite.
Dec  3 16:17:49.736: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:17:50.070: INFO: namespace webhook-2209-markers deletion completed in 6.365156716s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:17:50.112: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1312
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  3 16:17:50.434: INFO: Waiting up to 5m0s for pod "pod-54053097-379b-4cd3-b5c3-0f7eb2da845c" in namespace "emptydir-1312" to be "success or failure"
Dec  3 16:17:50.444: INFO: Pod "pod-54053097-379b-4cd3-b5c3-0f7eb2da845c": Phase="Pending", Reason="", readiness=false. Elapsed: 9.5083ms
Dec  3 16:17:52.454: INFO: Pod "pod-54053097-379b-4cd3-b5c3-0f7eb2da845c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019719001s
STEP: Saw pod success
Dec  3 16:17:52.454: INFO: Pod "pod-54053097-379b-4cd3-b5c3-0f7eb2da845c" satisfied condition "success or failure"
Dec  3 16:17:52.464: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-54053097-379b-4cd3-b5c3-0f7eb2da845c container test-container: <nil>
STEP: delete the pod
Dec  3 16:17:52.496: INFO: Waiting for pod pod-54053097-379b-4cd3-b5c3-0f7eb2da845c to disappear
Dec  3 16:17:52.505: INFO: Pod pod-54053097-379b-4cd3-b5c3-0f7eb2da845c no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:17:52.506: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1312" for this suite.
Dec  3 16:17:58.555: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:17:58.885: INFO: namespace emptydir-1312 deletion completed in 6.361323204s
•SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:17:58.886: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4695
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec  3 16:17:59.132: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 16:17:59.162: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 16:17:59.172: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 before test
Dec  3 16:17:59.198: INFO: coredns-59c969ffb8-p9rws from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 16:17:59.198: INFO: 	Container coredns ready: true, restart count 0
Dec  3 16:17:59.198: INFO: blackbox-exporter-7bd7b55dfc-7ktvk from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 16:17:59.198: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec  3 16:17:59.198: INFO: kube-proxy-qzrrc from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 16:17:59.199: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 16:17:59.199: INFO: metrics-server-7df74c5758-hnsgs from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 16:17:59.199: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 16:17:59.199: INFO: addons-nginx-ingress-controller-7c75bb76db-zkqv8 from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 16:17:59.199: INFO: 	Container nginx-ingress-controller ready: true, restart count 1
Dec  3 16:17:59.199: INFO: addons-kubernetes-dashboard-78954cc66b-gjdxd from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 16:17:59.199: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  3 16:17:59.199: INFO: calico-typha-horizontal-autoscaler-69df649c59-7l6bk from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 16:17:59.199: INFO: 	Container autoscaler ready: true, restart count 0
Dec  3 16:17:59.199: INFO: calico-typha-vertical-autoscaler-847d859f8c-vfvq7 from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 16:17:59.199: INFO: 	Container autoscaler ready: true, restart count 3
Dec  3 16:17:59.199: INFO: vpn-shoot-5689b7f9b4-n47mb from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 16:17:59.199: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec  3 16:17:59.199: INFO: node-problem-detector-xwvwh from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 16:17:59.199: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 16:17:59.199: INFO: calico-typha-deploy-9f6b455c4-6ntkq from kube-system started at 2019-12-03 15:09:21 +0000 UTC (1 container statuses recorded)
Dec  3 16:17:59.199: INFO: 	Container calico-typha ready: true, restart count 0
Dec  3 16:17:59.199: INFO: node-exporter-pwl5b from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 16:17:59.199: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 16:17:59.199: INFO: coredns-59c969ffb8-jwpjr from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 16:17:59.199: INFO: 	Container coredns ready: true, restart count 0
Dec  3 16:17:59.199: INFO: calico-node-rc24j from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 16:17:59.199: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 16:17:59.199: INFO: calico-kube-controllers-79bcd784b6-pkrdg from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 16:17:59.199: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  3 16:17:59.199: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-95f65778d-nb2sc from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 16:17:59.199: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec  3 16:17:59.199: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz before test
Dec  3 16:17:59.243: INFO: node-problem-detector-4c7x7 from kube-system started at 2019-12-03 14:27:15 +0000 UTC (1 container statuses recorded)
Dec  3 16:17:59.243: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 16:17:59.243: INFO: node-exporter-fmmk4 from kube-system started at 2019-12-03 14:27:15 +0000 UTC (1 container statuses recorded)
Dec  3 16:17:59.243: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 16:17:59.243: INFO: kube-proxy-n42lb from kube-system started at 2019-12-03 14:27:15 +0000 UTC (1 container statuses recorded)
Dec  3 16:17:59.243: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 16:17:59.243: INFO: calico-node-zhw8c from kube-system started at 2019-12-03 14:27:15 +0000 UTC (1 container statuses recorded)
Dec  3 16:17:59.243: INFO: 	Container calico-node ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-3a85b14b-2cc0-4a15-a312-dab915feb6fa 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-3a85b14b-2cc0-4a15-a312-dab915feb6fa off the node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz
STEP: verifying the node doesn't have the label kubernetes.io/e2e-3a85b14b-2cc0-4a15-a312-dab915feb6fa
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:18:07.453: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4695" for this suite.
Dec  3 16:19:39.493: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:19:39.832: INFO: namespace sched-pred-4695 deletion completed in 1m32.369409911s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78
•SSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:19:39.832: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-7188
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7188.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-7188.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7188.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-7188.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7188.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-7188.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-7188.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-7188.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-7188.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-7188.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec  3 16:19:42.182: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:42.225: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:42.237: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:42.249: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:42.386: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:42.398: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:42.410: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:42.421: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:42.559: INFO: Lookups using dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7188.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7188.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local jessie_udp@dns-test-service-2.dns-7188.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7188.svc.cluster.local]

Dec  3 16:19:47.571: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:47.614: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:47.625: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:47.636: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:47.774: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:47.786: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:47.797: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:47.809: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:47.906: INFO: Lookups using dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7188.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7188.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local jessie_udp@dns-test-service-2.dns-7188.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7188.svc.cluster.local]

Dec  3 16:19:52.571: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:52.583: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:52.595: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:52.606: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:52.744: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:52.758: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:52.769: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:52.781: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:52.876: INFO: Lookups using dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7188.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7188.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local jessie_udp@dns-test-service-2.dns-7188.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7188.svc.cluster.local]

Dec  3 16:19:57.571: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:57.583: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:57.594: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:57.606: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:57.744: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:57.755: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:57.766: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:57.778: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:19:57.914: INFO: Lookups using dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7188.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7188.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local jessie_udp@dns-test-service-2.dns-7188.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7188.svc.cluster.local]

Dec  3 16:20:02.572: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:20:02.614: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:20:02.625: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:20:02.637: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:20:02.775: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:20:02.786: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:20:02.798: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:20:02.810: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:20:02.948: INFO: Lookups using dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7188.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7188.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local jessie_udp@dns-test-service-2.dns-7188.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7188.svc.cluster.local]

Dec  3 16:20:07.571: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:20:07.614: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:20:07.625: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:20:07.636: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:20:07.774: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:20:07.786: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:20:07.797: INFO: Unable to read jessie_udp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:20:07.810: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-7188.svc.cluster.local from pod dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56: the server could not find the requested resource (get pods dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56)
Dec  3 16:20:07.904: INFO: Lookups using dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local wheezy_udp@dns-test-service-2.dns-7188.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-7188.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-7188.svc.cluster.local jessie_udp@dns-test-service-2.dns-7188.svc.cluster.local jessie_tcp@dns-test-service-2.dns-7188.svc.cluster.local]

Dec  3 16:20:13.370: INFO: DNS probes using dns-7188/dns-test-2f9c3df6-7516-4c57-a816-9e731a158f56 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:20:13.399: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-7188" for this suite.
Dec  3 16:20:19.441: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:20:19.815: INFO: namespace dns-7188 deletion completed in 6.406758524s
•SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:20:19.816: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-7821
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:20:20.048: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-7821" for this suite.
Dec  3 16:20:26.091: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:20:26.435: INFO: namespace tables-7821 deletion completed in 6.3759154s
•SSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:20:26.435: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-5372
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:20:26.659: INFO: (0) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 13.871015ms)
Dec  3 16:20:26.701: INFO: (1) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 41.823706ms)
Dec  3 16:20:26.713: INFO: (2) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.359407ms)
Dec  3 16:20:26.724: INFO: (3) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.413792ms)
Dec  3 16:20:26.736: INFO: (4) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.618307ms)
Dec  3 16:20:26.747: INFO: (5) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.229646ms)
Dec  3 16:20:26.758: INFO: (6) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 10.835862ms)
Dec  3 16:20:26.770: INFO: (7) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.45805ms)
Dec  3 16:20:26.781: INFO: (8) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.340582ms)
Dec  3 16:20:26.794: INFO: (9) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.391668ms)
Dec  3 16:20:26.805: INFO: (10) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.481793ms)
Dec  3 16:20:26.817: INFO: (11) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.604116ms)
Dec  3 16:20:26.830: INFO: (12) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.692657ms)
Dec  3 16:20:26.841: INFO: (13) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.64555ms)
Dec  3 16:20:26.853: INFO: (14) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.026845ms)
Dec  3 16:20:26.865: INFO: (15) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.166369ms)
Dec  3 16:20:26.877: INFO: (16) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 12.035554ms)
Dec  3 16:20:26.888: INFO: (17) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.263252ms)
Dec  3 16:20:26.901: INFO: (18) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 13.226125ms)
Dec  3 16:20:26.913: INFO: (19) /api/v1/nodes/shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6/proxy/logs/: <pre>
<a href="btmp">btmp</a>
<a href="containers/">containers/</a>
<a href="faillog">faillog</a>... (200; 11.323514ms)
[AfterEach] version v1
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:20:26.913: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-5372" for this suite.
Dec  3 16:20:32.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:20:33.294: INFO: namespace proxy-5372 deletion completed in 6.371110629s
•SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:20:33.295: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-1610
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:20:33.546: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-19b80819-35db-464b-90c1-4e02a46a0742" in namespace "security-context-test-1610" to be "success or failure"
Dec  3 16:20:33.556: INFO: Pod "busybox-privileged-false-19b80819-35db-464b-90c1-4e02a46a0742": Phase="Pending", Reason="", readiness=false. Elapsed: 10.442821ms
Dec  3 16:20:35.568: INFO: Pod "busybox-privileged-false-19b80819-35db-464b-90c1-4e02a46a0742": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.022601736s
Dec  3 16:20:35.569: INFO: Pod "busybox-privileged-false-19b80819-35db-464b-90c1-4e02a46a0742" satisfied condition "success or failure"
Dec  3 16:20:35.718: INFO: Got logs for pod "busybox-privileged-false-19b80819-35db-464b-90c1-4e02a46a0742": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:20:35.718: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-1610" for this suite.
Dec  3 16:20:41.768: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:20:42.107: INFO: namespace security-context-test-1610 deletion completed in 6.370546138s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:20:42.108: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8132
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-0ab61534-8a76-480e-88fd-efcfd3fe11b9
STEP: Creating a pod to test consume secrets
Dec  3 16:20:42.353: INFO: Waiting up to 5m0s for pod "pod-secrets-782e6610-bc15-4066-a313-00c7a0a4ca36" in namespace "secrets-8132" to be "success or failure"
Dec  3 16:20:42.362: INFO: Pod "pod-secrets-782e6610-bc15-4066-a313-00c7a0a4ca36": Phase="Pending", Reason="", readiness=false. Elapsed: 9.359275ms
Dec  3 16:20:44.373: INFO: Pod "pod-secrets-782e6610-bc15-4066-a313-00c7a0a4ca36": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019684294s
STEP: Saw pod success
Dec  3 16:20:44.373: INFO: Pod "pod-secrets-782e6610-bc15-4066-a313-00c7a0a4ca36" satisfied condition "success or failure"
Dec  3 16:20:44.383: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-secrets-782e6610-bc15-4066-a313-00c7a0a4ca36 container secret-env-test: <nil>
STEP: delete the pod
Dec  3 16:20:44.414: INFO: Waiting for pod pod-secrets-782e6610-bc15-4066-a313-00c7a0a4ca36 to disappear
Dec  3 16:20:44.423: INFO: Pod pod-secrets-782e6610-bc15-4066-a313-00c7a0a4ca36 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:20:44.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8132" for this suite.
Dec  3 16:20:50.472: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:20:50.815: INFO: namespace secrets-8132 deletion completed in 6.374050619s
•SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:20:50.815: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5201
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:20:51.034: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec  3 16:20:51.055: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec  3 16:20:53.075: INFO: Creating deployment "test-rolling-update-deployment"
Dec  3 16:20:53.086: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec  3 16:20:53.106: INFO: deployment "test-rolling-update-deployment" doesn't have the required revision set
Dec  3 16:20:55.127: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec  3 16:20:55.137: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec  3 16:20:55.167: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-5201 /apis/apps/v1/namespaces/deployment-5201/deployments/test-rolling-update-deployment cdb78cca-e404-494f-ab22-f5720f83367e 26658 1 2019-12-03 16:20:53 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006609e18 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-03 16:20:53 +0000 UTC,LastTransitionTime:2019-12-03 16:20:53 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2019-12-03 16:20:54 +0000 UTC,LastTransitionTime:2019-12-03 16:20:53 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec  3 16:20:55.177: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-5201 /apis/apps/v1/namespaces/deployment-5201/replicasets/test-rolling-update-deployment-55d946486 65ac5090-0a0b-4aca-a47e-afcd1a777b3a 26651 1 2019-12-03 16:20:53 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment cdb78cca-e404-494f-ab22-f5720f83367e 0xc0031f3180 0xc0031f3181}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0031f31e8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec  3 16:20:55.177: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec  3 16:20:55.177: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-5201 /apis/apps/v1/namespaces/deployment-5201/replicasets/test-rolling-update-controller e93afc66-cfb1-4d4f-b8c1-d7320be549f9 26657 2 2019-12-03 16:20:51 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment cdb78cca-e404-494f-ab22-f5720f83367e 0xc0031f30b7 0xc0031f30b8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0031f3118 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec  3 16:20:55.188: INFO: Pod "test-rolling-update-deployment-55d946486-vzj6r" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-vzj6r test-rolling-update-deployment-55d946486- deployment-5201 /api/v1/namespaces/deployment-5201/pods/test-rolling-update-deployment-55d946486-vzj6r 3d8dd368-19b6-4003-b1a6-f9712e28654c 26650 0 2019-12-03 16:20:53 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[cni.projectcalico.org/podIP:100.64.1.69/32 kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 65ac5090-0a0b-4aca-a47e-afcd1a777b3a 0xc0031f3650 0xc0031f3651}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-lp9nw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-lp9nw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-lp9nw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:20:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:20:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:20:54 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-03 16:20:53 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.250.0.2,PodIP:100.64.1.69,StartTime:2019-12-03 16:20:53 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-03 16:20:54 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:redis:5.0.5-alpine,ImageID:docker-pullable://redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:docker://b41b3c521d77933fba2b751871aa898c3c614384601c61919a089bae0fb197f9,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:100.64.1.69,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:20:55.188: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5201" for this suite.
Dec  3 16:21:03.236: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:21:03.573: INFO: namespace deployment-5201 deletion completed in 8.366802341s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:21:03.573: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-5906
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec  3 16:21:03.964: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5906 /api/v1/namespaces/watch-5906/configmaps/e2e-watch-test-watch-closed e6281001-8627-4c69-bf02-5f8de1820983 26699 0 2019-12-03 16:21:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec  3 16:21:03.964: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5906 /api/v1/namespaces/watch-5906/configmaps/e2e-watch-test-watch-closed e6281001-8627-4c69-bf02-5f8de1820983 26700 0 2019-12-03 16:21:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec  3 16:21:04.004: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5906 /api/v1/namespaces/watch-5906/configmaps/e2e-watch-test-watch-closed e6281001-8627-4c69-bf02-5f8de1820983 26701 0 2019-12-03 16:21:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec  3 16:21:04.004: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-5906 /api/v1/namespaces/watch-5906/configmaps/e2e-watch-test-watch-closed e6281001-8627-4c69-bf02-5f8de1820983 26702 0 2019-12-03 16:21:03 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:21:04.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-5906" for this suite.
Dec  3 16:21:10.045: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:21:10.397: INFO: namespace watch-5906 deletion completed in 6.382421456s
•SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:21:10.397: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-506
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 16:21:11.452: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986871, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986871, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986871, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986871, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 16:21:13.463: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986871, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986871, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986871, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710986871, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 16:21:16.477: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:21:16.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-506" for this suite.
Dec  3 16:21:22.865: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:21:23.215: INFO: namespace webhook-506 deletion completed in 6.379847002s
STEP: Destroying namespace "webhook-506-markers" for this suite.
Dec  3 16:21:29.246: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:21:29.588: INFO: namespace webhook-506-markers deletion completed in 6.372543649s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:21:29.629: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-454
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-669e2390-3e0a-475d-8dbb-2919174ab132
STEP: Creating a pod to test consume configMaps
Dec  3 16:21:29.860: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-dcfde0ad-3e5a-4118-a0a1-ec6f8802cab3" in namespace "projected-454" to be "success or failure"
Dec  3 16:21:29.871: INFO: Pod "pod-projected-configmaps-dcfde0ad-3e5a-4118-a0a1-ec6f8802cab3": Phase="Pending", Reason="", readiness=false. Elapsed: 10.872612ms
Dec  3 16:21:31.881: INFO: Pod "pod-projected-configmaps-dcfde0ad-3e5a-4118-a0a1-ec6f8802cab3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.021068507s
STEP: Saw pod success
Dec  3 16:21:31.882: INFO: Pod "pod-projected-configmaps-dcfde0ad-3e5a-4118-a0a1-ec6f8802cab3" satisfied condition "success or failure"
Dec  3 16:21:31.891: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-projected-configmaps-dcfde0ad-3e5a-4118-a0a1-ec6f8802cab3 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec  3 16:21:31.920: INFO: Waiting for pod pod-projected-configmaps-dcfde0ad-3e5a-4118-a0a1-ec6f8802cab3 to disappear
Dec  3 16:21:31.930: INFO: Pod pod-projected-configmaps-dcfde0ad-3e5a-4118-a0a1-ec6f8802cab3 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:21:31.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-454" for this suite.
Dec  3 16:21:37.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:21:38.320: INFO: namespace projected-454 deletion completed in 6.37204941s
•SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:21:38.320: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6517
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec  3 16:21:38.549: INFO: Waiting up to 5m0s for pod "pod-a0100c52-3a52-4977-889b-6c1dc7f8b9ac" in namespace "emptydir-6517" to be "success or failure"
Dec  3 16:21:38.559: INFO: Pod "pod-a0100c52-3a52-4977-889b-6c1dc7f8b9ac": Phase="Pending", Reason="", readiness=false. Elapsed: 9.804169ms
Dec  3 16:21:40.569: INFO: Pod "pod-a0100c52-3a52-4977-889b-6c1dc7f8b9ac": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020197761s
STEP: Saw pod success
Dec  3 16:21:40.569: INFO: Pod "pod-a0100c52-3a52-4977-889b-6c1dc7f8b9ac" satisfied condition "success or failure"
Dec  3 16:21:40.579: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-a0100c52-3a52-4977-889b-6c1dc7f8b9ac container test-container: <nil>
STEP: delete the pod
Dec  3 16:21:40.612: INFO: Waiting for pod pod-a0100c52-3a52-4977-889b-6c1dc7f8b9ac to disappear
Dec  3 16:21:40.621: INFO: Pod pod-a0100c52-3a52-4977-889b-6c1dc7f8b9ac no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:21:40.622: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6517" for this suite.
Dec  3 16:21:46.670: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:21:47.032: INFO: namespace emptydir-6517 deletion completed in 6.392088965s
•SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:21:47.033: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8384
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec  3 16:21:47.230: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:22:06.242: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8384" for this suite.
Dec  3 16:22:12.292: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:22:12.626: INFO: namespace crd-publish-openapi-8384 deletion completed in 6.365641879s
•SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:22:12.627: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-783
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec  3 16:22:12.831: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec  3 16:22:12.862: INFO: Waiting for terminating namespaces to be deleted...
Dec  3 16:22:12.872: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-9bzf6 before test
Dec  3 16:22:12.987: INFO: kube-proxy-qzrrc from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 16:22:12.988: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 16:22:12.988: INFO: metrics-server-7df74c5758-hnsgs from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 16:22:12.988: INFO: 	Container metrics-server ready: true, restart count 0
Dec  3 16:22:12.988: INFO: calico-typha-horizontal-autoscaler-69df649c59-7l6bk from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 16:22:12.988: INFO: 	Container autoscaler ready: true, restart count 0
Dec  3 16:22:12.988: INFO: addons-nginx-ingress-controller-7c75bb76db-zkqv8 from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 16:22:12.988: INFO: 	Container nginx-ingress-controller ready: true, restart count 1
Dec  3 16:22:12.988: INFO: addons-kubernetes-dashboard-78954cc66b-gjdxd from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 16:22:12.988: INFO: 	Container kubernetes-dashboard ready: true, restart count 0
Dec  3 16:22:12.988: INFO: node-problem-detector-xwvwh from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 16:22:12.988: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 16:22:12.988: INFO: calico-typha-vertical-autoscaler-847d859f8c-vfvq7 from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 16:22:12.988: INFO: 	Container autoscaler ready: true, restart count 3
Dec  3 16:22:12.988: INFO: vpn-shoot-5689b7f9b4-n47mb from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 16:22:12.988: INFO: 	Container vpn-shoot ready: true, restart count 0
Dec  3 16:22:12.988: INFO: node-exporter-pwl5b from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 16:22:12.988: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 16:22:12.988: INFO: calico-typha-deploy-9f6b455c4-6ntkq from kube-system started at 2019-12-03 15:09:21 +0000 UTC (1 container statuses recorded)
Dec  3 16:22:12.988: INFO: 	Container calico-typha ready: true, restart count 0
Dec  3 16:22:12.988: INFO: calico-node-rc24j from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 16:22:12.988: INFO: 	Container calico-node ready: true, restart count 0
Dec  3 16:22:12.988: INFO: coredns-59c969ffb8-jwpjr from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 16:22:12.988: INFO: 	Container coredns ready: true, restart count 0
Dec  3 16:22:12.988: INFO: addons-nginx-ingress-nginx-ingress-k8s-backend-95f65778d-nb2sc from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 16:22:12.988: INFO: 	Container nginx-ingress-nginx-ingress-k8s-backend ready: true, restart count 0
Dec  3 16:22:12.988: INFO: calico-kube-controllers-79bcd784b6-pkrdg from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 16:22:12.988: INFO: 	Container calico-kube-controllers ready: true, restart count 0
Dec  3 16:22:12.988: INFO: blackbox-exporter-7bd7b55dfc-7ktvk from kube-system started at 2019-12-03 14:27:13 +0000 UTC (1 container statuses recorded)
Dec  3 16:22:12.988: INFO: 	Container blackbox-exporter ready: true, restart count 0
Dec  3 16:22:12.988: INFO: coredns-59c969ffb8-p9rws from kube-system started at 2019-12-03 14:27:34 +0000 UTC (1 container statuses recorded)
Dec  3 16:22:12.988: INFO: 	Container coredns ready: true, restart count 0
Dec  3 16:22:12.988: INFO: 
Logging pods the kubelet thinks is on node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz before test
Dec  3 16:22:13.031: INFO: node-problem-detector-4c7x7 from kube-system started at 2019-12-03 14:27:15 +0000 UTC (1 container statuses recorded)
Dec  3 16:22:13.031: INFO: 	Container node-problem-detector ready: true, restart count 0
Dec  3 16:22:13.031: INFO: node-exporter-fmmk4 from kube-system started at 2019-12-03 14:27:15 +0000 UTC (1 container statuses recorded)
Dec  3 16:22:13.031: INFO: 	Container node-exporter ready: true, restart count 0
Dec  3 16:22:13.031: INFO: kube-proxy-n42lb from kube-system started at 2019-12-03 14:27:15 +0000 UTC (1 container statuses recorded)
Dec  3 16:22:13.031: INFO: 	Container kube-proxy ready: true, restart count 0
Dec  3 16:22:13.031: INFO: calico-node-zhw8c from kube-system started at 2019-12-03 14:27:15 +0000 UTC (1 container statuses recorded)
Dec  3 16:22:13.031: INFO: 	Container calico-node ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-1ec7fa97-c14e-4759-98ea-6a492985fb49 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-1ec7fa97-c14e-4759-98ea-6a492985fb49 off the node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz
STEP: verifying the node doesn't have the label kubernetes.io/e2e-1ec7fa97-c14e-4759-98ea-6a492985fb49
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:27:17.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-783" for this suite.
Dec  3 16:27:37.255: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:27:37.592: INFO: namespace sched-pred-783 deletion completed in 20.368002176s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:324.965 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:27:37.592: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4192
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:27:53.995: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4192" for this suite.
Dec  3 16:28:00.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:28:00.403: INFO: namespace resourcequota-4192 deletion completed in 6.386273217s
•SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:28:00.403: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3842
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 16:28:01.824: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987281, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987281, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987281, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987281, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec  3 16:28:03.834: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987281, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987281, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987281, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987281, loc:(*time.Location)(0x84bfb00)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 16:28:06.851: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:28:07.083: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3842" for this suite.
Dec  3 16:28:19.137: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:28:19.465: INFO: namespace webhook-3842 deletion completed in 12.361905233s
STEP: Destroying namespace "webhook-3842-markers" for this suite.
Dec  3 16:28:25.495: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:28:25.825: INFO: namespace webhook-3842-markers deletion completed in 6.360278293s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:28:25.866: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2352
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec  3 16:28:26.219: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:28:27.561: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2352" for this suite.
Dec  3 16:28:33.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:28:33.946: INFO: namespace custom-resource-definition-2352 deletion completed in 6.366051051s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:28:33.946: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-366
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Dec  3 16:28:34.130: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Dec  3 16:28:49.549: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 16:28:53.142: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:29:08.678: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-366" for this suite.
Dec  3 16:29:14.728: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:29:15.070: INFO: namespace crd-publish-openapi-366 deletion completed in 6.373263419s
•SS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:29:15.070: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-5726
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Dec  3 16:29:15.545: INFO: Waiting up to 5m0s for pod "client-containers-63baae62-2fe6-4c67-a829-6d77339a3cf8" in namespace "containers-5726" to be "success or failure"
Dec  3 16:29:15.555: INFO: Pod "client-containers-63baae62-2fe6-4c67-a829-6d77339a3cf8": Phase="Pending", Reason="", readiness=false. Elapsed: 9.563033ms
Dec  3 16:29:17.565: INFO: Pod "client-containers-63baae62-2fe6-4c67-a829-6d77339a3cf8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019663811s
STEP: Saw pod success
Dec  3 16:29:17.565: INFO: Pod "client-containers-63baae62-2fe6-4c67-a829-6d77339a3cf8" satisfied condition "success or failure"
Dec  3 16:29:17.575: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod client-containers-63baae62-2fe6-4c67-a829-6d77339a3cf8 container test-container: <nil>
STEP: delete the pod
Dec  3 16:29:17.733: INFO: Waiting for pod client-containers-63baae62-2fe6-4c67-a829-6d77339a3cf8 to disappear
Dec  3 16:29:17.742: INFO: Pod client-containers-63baae62-2fe6-4c67-a829-6d77339a3cf8 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:29:17.742: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-5726" for this suite.
Dec  3 16:29:23.790: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:29:24.129: INFO: namespace containers-5726 deletion completed in 6.36929155s
•SSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:29:24.130: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-2126
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-w5sx
STEP: Creating a pod to test atomic-volume-subpath
Dec  3 16:29:24.365: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-w5sx" in namespace "subpath-2126" to be "success or failure"
Dec  3 16:29:24.374: INFO: Pod "pod-subpath-test-configmap-w5sx": Phase="Pending", Reason="", readiness=false. Elapsed: 9.251762ms
Dec  3 16:29:26.385: INFO: Pod "pod-subpath-test-configmap-w5sx": Phase="Running", Reason="", readiness=true. Elapsed: 2.019601135s
Dec  3 16:29:28.395: INFO: Pod "pod-subpath-test-configmap-w5sx": Phase="Running", Reason="", readiness=true. Elapsed: 4.03002377s
Dec  3 16:29:30.409: INFO: Pod "pod-subpath-test-configmap-w5sx": Phase="Running", Reason="", readiness=true. Elapsed: 6.043328205s
Dec  3 16:29:32.419: INFO: Pod "pod-subpath-test-configmap-w5sx": Phase="Running", Reason="", readiness=true. Elapsed: 8.053868804s
Dec  3 16:29:34.430: INFO: Pod "pod-subpath-test-configmap-w5sx": Phase="Running", Reason="", readiness=true. Elapsed: 10.064354602s
Dec  3 16:29:36.440: INFO: Pod "pod-subpath-test-configmap-w5sx": Phase="Running", Reason="", readiness=true. Elapsed: 12.074687332s
Dec  3 16:29:38.451: INFO: Pod "pod-subpath-test-configmap-w5sx": Phase="Running", Reason="", readiness=true. Elapsed: 14.08529691s
Dec  3 16:29:40.461: INFO: Pod "pod-subpath-test-configmap-w5sx": Phase="Running", Reason="", readiness=true. Elapsed: 16.095887433s
Dec  3 16:29:42.471: INFO: Pod "pod-subpath-test-configmap-w5sx": Phase="Running", Reason="", readiness=true. Elapsed: 18.106251582s
Dec  3 16:29:44.482: INFO: Pod "pod-subpath-test-configmap-w5sx": Phase="Running", Reason="", readiness=true. Elapsed: 20.116516412s
Dec  3 16:29:46.492: INFO: Pod "pod-subpath-test-configmap-w5sx": Phase="Succeeded", Reason="", readiness=false. Elapsed: 22.126949225s
STEP: Saw pod success
Dec  3 16:29:46.492: INFO: Pod "pod-subpath-test-configmap-w5sx" satisfied condition "success or failure"
Dec  3 16:29:46.502: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-subpath-test-configmap-w5sx container test-container-subpath-configmap-w5sx: <nil>
STEP: delete the pod
Dec  3 16:29:46.535: INFO: Waiting for pod pod-subpath-test-configmap-w5sx to disappear
Dec  3 16:29:46.544: INFO: Pod pod-subpath-test-configmap-w5sx no longer exists
STEP: Deleting pod pod-subpath-test-configmap-w5sx
Dec  3 16:29:46.544: INFO: Deleting pod "pod-subpath-test-configmap-w5sx" in namespace "subpath-2126"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:29:46.555: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-2126" for this suite.
Dec  3 16:29:52.604: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:29:52.966: INFO: namespace subpath-2126 deletion completed in 6.392573312s
•SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:29:52.967: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-700
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 16:29:53.243: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e8a1f8cf-d4c2-4006-a219-1b732fd31487" in namespace "downward-api-700" to be "success or failure"
Dec  3 16:29:53.252: INFO: Pod "downwardapi-volume-e8a1f8cf-d4c2-4006-a219-1b732fd31487": Phase="Pending", Reason="", readiness=false. Elapsed: 9.446625ms
Dec  3 16:29:55.263: INFO: Pod "downwardapi-volume-e8a1f8cf-d4c2-4006-a219-1b732fd31487": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.020312349s
STEP: Saw pod success
Dec  3 16:29:55.263: INFO: Pod "downwardapi-volume-e8a1f8cf-d4c2-4006-a219-1b732fd31487" satisfied condition "success or failure"
Dec  3 16:29:55.273: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downwardapi-volume-e8a1f8cf-d4c2-4006-a219-1b732fd31487 container client-container: <nil>
STEP: delete the pod
Dec  3 16:29:55.303: INFO: Waiting for pod downwardapi-volume-e8a1f8cf-d4c2-4006-a219-1b732fd31487 to disappear
Dec  3 16:29:55.314: INFO: Pod downwardapi-volume-e8a1f8cf-d4c2-4006-a219-1b732fd31487 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:29:55.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-700" for this suite.
Dec  3 16:30:01.363: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:30:01.708: INFO: namespace downward-api-700 deletion completed in 6.375432287s
•SSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:30:01.708: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8309
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-3b6b703a-020a-4a32-b054-3d2e51b530f2
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-3b6b703a-020a-4a32-b054-3d2e51b530f2
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:30:06.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8309" for this suite.
Dec  3 16:30:18.259: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:30:18.603: INFO: namespace projected-8309 deletion completed in 12.375350342s
•SSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:30:18.603: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-9062
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-9062
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec  3 16:30:18.950: INFO: Found 0 stateful pods, waiting for 3
Dec  3 16:30:28.963: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:30:28.963: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:30:28.963: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec  3 16:30:28.993: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-9062 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:30:29.890: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:30:29.890: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:30:29.890: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec  3 16:30:39.963: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec  3 16:30:39.994: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-9062 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:30:40.586: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 16:30:40.586: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 16:30:40.586: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec  3 16:30:50.649: INFO: Waiting for StatefulSet statefulset-9062/ss2 to complete update
Dec  3 16:30:50.649: INFO: Waiting for Pod statefulset-9062/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  3 16:30:50.649: INFO: Waiting for Pod statefulset-9062/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  3 16:30:50.649: INFO: Waiting for Pod statefulset-9062/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec  3 16:31:00.670: INFO: Waiting for StatefulSet statefulset-9062/ss2 to complete update
Dec  3 16:31:00.670: INFO: Waiting for Pod statefulset-9062/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Rolling back to a previous revision
Dec  3 16:31:10.671: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-9062 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec  3 16:31:11.262: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec  3 16:31:11.262: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec  3 16:31:11.262: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec  3 16:31:21.335: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec  3 16:31:21.366: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=statefulset-9062 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec  3 16:31:21.988: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec  3 16:31:21.988: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec  3 16:31:21.988: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec  3 16:31:42.051: INFO: Deleting all statefulset in ns statefulset-9062
Dec  3 16:31:42.061: INFO: Scaling statefulset ss2 to 0
Dec  3 16:32:12.106: INFO: Waiting for statefulset status.replicas updated to 0
Dec  3 16:32:12.116: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:32:12.148: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-9062" for this suite.
Dec  3 16:32:18.198: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:32:18.535: INFO: namespace statefulset-9062 deletion completed in 6.368417043s
•SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:32:18.535: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-9634
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec  3 16:32:18.754: INFO: Waiting up to 5m0s for pod "pod-33c1a0f5-b4ce-4578-a250-c10f1bebb47d" in namespace "emptydir-9634" to be "success or failure"
Dec  3 16:32:18.763: INFO: Pod "pod-33c1a0f5-b4ce-4578-a250-c10f1bebb47d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.387383ms
Dec  3 16:32:20.774: INFO: Pod "pod-33c1a0f5-b4ce-4578-a250-c10f1bebb47d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019929058s
STEP: Saw pod success
Dec  3 16:32:20.774: INFO: Pod "pod-33c1a0f5-b4ce-4578-a250-c10f1bebb47d" satisfied condition "success or failure"
Dec  3 16:32:20.784: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-33c1a0f5-b4ce-4578-a250-c10f1bebb47d container test-container: <nil>
STEP: delete the pod
Dec  3 16:32:20.941: INFO: Waiting for pod pod-33c1a0f5-b4ce-4578-a250-c10f1bebb47d to disappear
Dec  3 16:32:20.951: INFO: Pod pod-33c1a0f5-b4ce-4578-a250-c10f1bebb47d no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:32:20.951: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-9634" for this suite.
Dec  3 16:32:27.001: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:32:27.342: INFO: namespace emptydir-9634 deletion completed in 6.370836754s
•SS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:32:27.342: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7019
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec  3 16:32:30.124: INFO: Successfully updated pod "annotationupdateaa3b92b8-a7bb-48ac-96b5-ca9d0fd15b89"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:32:32.158: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7019" for this suite.
Dec  3 16:32:44.208: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:32:44.542: INFO: namespace projected-7019 deletion completed in 12.365398677s
•SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:32:44.543: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5534
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Dec  3 16:32:44.738: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config cluster-info'
Dec  3 16:32:44.856: INFO: stderr: ""
Dec  3 16:32:44.856: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com\x1b[0m\n\x1b[0;32mCoreDNS\x1b[0m is running at \x1b[0;33mhttps://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\x1b[0;32mkubernetes-dashboard\x1b[0m is running at \x1b[0;33mhttps://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com/api/v1/namespaces/kube-system/services/https:kubernetes-dashboard:/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:32:44.856: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5534" for this suite.
Dec  3 16:32:50.897: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:32:51.273: INFO: namespace kubectl-5534 deletion completed in 6.406213373s
•SSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:32:51.273: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3949
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-3949
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3949 to expose endpoints map[]
Dec  3 16:32:51.558: INFO: successfully validated that service endpoint-test2 in namespace services-3949 exposes endpoints map[] (9.522911ms elapsed)
STEP: Creating pod pod1 in namespace services-3949
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3949 to expose endpoints map[pod1:[80]]
Dec  3 16:32:53.633: INFO: successfully validated that service endpoint-test2 in namespace services-3949 exposes endpoints map[pod1:[80]] (2.061978296s elapsed)
STEP: Creating pod pod2 in namespace services-3949
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3949 to expose endpoints map[pod1:[80] pod2:[80]]
Dec  3 16:32:55.737: INFO: successfully validated that service endpoint-test2 in namespace services-3949 exposes endpoints map[pod1:[80] pod2:[80]] (2.093404247s elapsed)
STEP: Deleting pod pod1 in namespace services-3949
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3949 to expose endpoints map[pod2:[80]]
Dec  3 16:32:55.767: INFO: successfully validated that service endpoint-test2 in namespace services-3949 exposes endpoints map[pod2:[80]] (18.702016ms elapsed)
STEP: Deleting pod pod2 in namespace services-3949
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-3949 to expose endpoints map[]
Dec  3 16:32:55.789: INFO: successfully validated that service endpoint-test2 in namespace services-3949 exposes endpoints map[] (9.441283ms elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:32:55.806: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3949" for this suite.
Dec  3 16:33:01.856: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:33:02.201: INFO: namespace services-3949 deletion completed in 6.376899563s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:33:02.202: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3446
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec  3 16:33:03.241: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:0, UpdatedReplicas:0, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987583, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987583, loc:(*time.Location)(0x84bfb00)}}, Reason:"NewReplicaSetCreated", Message:"Created new replica set \"sample-webhook-deployment-86d95b659d\""}, v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987583, loc:(*time.Location)(0x84bfb00)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63710987583, loc:(*time.Location)(0x84bfb00)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec  3 16:33:06.269: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:33:18.888: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3446" for this suite.
Dec  3 16:33:24.940: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:33:25.273: INFO: namespace webhook-3446 deletion completed in 6.363494481s
STEP: Destroying namespace "webhook-3446-markers" for this suite.
Dec  3 16:33:31.304: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:33:31.636: INFO: namespace webhook-3446-markers deletion completed in 6.363149076s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:33:31.678: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3048
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-3048
STEP: creating replication controller nodeport-test in namespace services-3048
I1203 16:33:31.958633    5064 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-3048, replica count: 2
Dec  3 16:33:35.009: INFO: Creating new exec pod
I1203 16:33:35.009059    5064 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec  3 16:33:38.062: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-3048 execpod7dps4 -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Dec  3 16:33:38.652: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec  3 16:33:38.652: INFO: stdout: ""
Dec  3 16:33:38.653: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-3048 execpod7dps4 -- /bin/sh -x -c nc -zv -t -w 2 100.108.73.189 80'
Dec  3 16:33:39.275: INFO: stderr: "+ nc -zv -t -w 2 100.108.73.189 80\nConnection to 100.108.73.189 80 port [tcp/http] succeeded!\n"
Dec  3 16:33:39.275: INFO: stdout: ""
Dec  3 16:33:39.275: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-3048 execpod7dps4 -- /bin/sh -x -c nc -zv -t -w 2 10.250.0.3 30814'
Dec  3 16:33:39.843: INFO: stderr: "+ nc -zv -t -w 2 10.250.0.3 30814\nConnection to 10.250.0.3 30814 port [tcp/30814] succeeded!\n"
Dec  3 16:33:39.844: INFO: stdout: ""
Dec  3 16:33:39.844: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config exec --namespace=services-3048 execpod7dps4 -- /bin/sh -x -c nc -zv -t -w 2 10.250.0.2 30814'
Dec  3 16:33:40.396: INFO: stderr: "+ nc -zv -t -w 2 10.250.0.2 30814\nConnection to 10.250.0.2 30814 port [tcp/30814] succeeded!\n"
Dec  3 16:33:40.397: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:33:40.397: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3048" for this suite.
Dec  3 16:33:48.446: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:33:48.784: INFO: namespace services-3048 deletion completed in 8.369105122s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:33:48.784: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-4010
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Dec  3 16:33:49.046: INFO: Waiting up to 5m0s for pod "var-expansion-0fcc7360-ecec-4d42-8c39-561639ddd8e5" in namespace "var-expansion-4010" to be "success or failure"
Dec  3 16:33:49.055: INFO: Pod "var-expansion-0fcc7360-ecec-4d42-8c39-561639ddd8e5": Phase="Pending", Reason="", readiness=false. Elapsed: 9.244568ms
Dec  3 16:33:51.066: INFO: Pod "var-expansion-0fcc7360-ecec-4d42-8c39-561639ddd8e5": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01945178s
STEP: Saw pod success
Dec  3 16:33:51.066: INFO: Pod "var-expansion-0fcc7360-ecec-4d42-8c39-561639ddd8e5" satisfied condition "success or failure"
Dec  3 16:33:51.077: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod var-expansion-0fcc7360-ecec-4d42-8c39-561639ddd8e5 container dapi-container: <nil>
STEP: delete the pod
Dec  3 16:33:51.109: INFO: Waiting for pod var-expansion-0fcc7360-ecec-4d42-8c39-561639ddd8e5 to disappear
Dec  3 16:33:51.118: INFO: Pod var-expansion-0fcc7360-ecec-4d42-8c39-561639ddd8e5 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:33:51.118: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4010" for this suite.
Dec  3 16:33:57.171: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:33:57.542: INFO: namespace var-expansion-4010 deletion completed in 6.402715002s
•SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:33:57.542: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1205
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec  3 16:33:57.733: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-1205'
Dec  3 16:33:57.849: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec  3 16:33:57.850: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Dec  3 16:33:59.870: INFO: Running '/go/src/k8s.io/kubernetes/platforms/linux/amd64/kubectl --server=https://api.tmh9b-w9f.it.internal.staging.k8s.ondemand.com --kubeconfig=/tmp/tm/kubeconfig/shoot.config delete deployment e2e-test-httpd-deployment --namespace=kubectl-1205'
Dec  3 16:34:00.012: INFO: stderr: ""
Dec  3 16:34:00.012: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:34:00.012: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1205" for this suite.
Dec  3 16:34:28.061: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:34:28.393: INFO: namespace kubectl-1205 deletion completed in 28.362117232s
•SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:34:28.393: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-2663
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:34:45.726: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-2663" for this suite.
Dec  3 16:34:51.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:34:52.110: INFO: namespace resourcequota-2663 deletion completed in 6.364879001s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:34:52.110: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-1682
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:34:52.357: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-1682" for this suite.
Dec  3 16:34:58.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:34:58.728: INFO: namespace kubelet-test-1682 deletion completed in 6.360952736s
•SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:34:58.728: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-959
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-b63c38cb-27d2-4a7c-9d1c-4e7347fb24e5
STEP: Creating a pod to test consume secrets
Dec  3 16:34:59.148: INFO: Waiting up to 5m0s for pod "pod-secrets-7a85c420-b31d-40b1-91dc-bb1406611a1d" in namespace "secrets-959" to be "success or failure"
Dec  3 16:34:59.158: INFO: Pod "pod-secrets-7a85c420-b31d-40b1-91dc-bb1406611a1d": Phase="Pending", Reason="", readiness=false. Elapsed: 9.248014ms
Dec  3 16:35:01.168: INFO: Pod "pod-secrets-7a85c420-b31d-40b1-91dc-bb1406611a1d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019786774s
STEP: Saw pod success
Dec  3 16:35:01.168: INFO: Pod "pod-secrets-7a85c420-b31d-40b1-91dc-bb1406611a1d" satisfied condition "success or failure"
Dec  3 16:35:01.178: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod pod-secrets-7a85c420-b31d-40b1-91dc-bb1406611a1d container secret-volume-test: <nil>
STEP: delete the pod
Dec  3 16:35:01.210: INFO: Waiting for pod pod-secrets-7a85c420-b31d-40b1-91dc-bb1406611a1d to disappear
Dec  3 16:35:01.220: INFO: Pod pod-secrets-7a85c420-b31d-40b1-91dc-bb1406611a1d no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:35:01.220: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-959" for this suite.
Dec  3 16:35:07.269: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:35:07.600: INFO: namespace secrets-959 deletion completed in 6.36193378s
•SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:35:07.601: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-810
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 16:35:07.848: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7c9b5ce6-242a-40fb-af91-a8e7a7d0c8ae" in namespace "projected-810" to be "success or failure"
Dec  3 16:35:07.857: INFO: Pod "downwardapi-volume-7c9b5ce6-242a-40fb-af91-a8e7a7d0c8ae": Phase="Pending", Reason="", readiness=false. Elapsed: 9.30624ms
Dec  3 16:35:09.868: INFO: Pod "downwardapi-volume-7c9b5ce6-242a-40fb-af91-a8e7a7d0c8ae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.01980165s
STEP: Saw pod success
Dec  3 16:35:09.868: INFO: Pod "downwardapi-volume-7c9b5ce6-242a-40fb-af91-a8e7a7d0c8ae" satisfied condition "success or failure"
Dec  3 16:35:09.878: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downwardapi-volume-7c9b5ce6-242a-40fb-af91-a8e7a7d0c8ae container client-container: <nil>
STEP: delete the pod
Dec  3 16:35:09.910: INFO: Waiting for pod downwardapi-volume-7c9b5ce6-242a-40fb-af91-a8e7a7d0c8ae to disappear
Dec  3 16:35:09.919: INFO: Pod downwardapi-volume-7c9b5ce6-242a-40fb-af91-a8e7a7d0c8ae no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:35:09.919: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-810" for this suite.
Dec  3 16:35:15.967: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:35:16.333: INFO: namespace projected-810 deletion completed in 6.39640831s
•SSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:35:16.334: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4402
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec  3 16:35:16.548: INFO: Waiting up to 5m0s for pod "downwardapi-volume-234bebb4-5446-406a-95e0-fde560e8d60b" in namespace "downward-api-4402" to be "success or failure"
Dec  3 16:35:16.557: INFO: Pod "downwardapi-volume-234bebb4-5446-406a-95e0-fde560e8d60b": Phase="Pending", Reason="", readiness=false. Elapsed: 9.571247ms
Dec  3 16:35:18.568: INFO: Pod "downwardapi-volume-234bebb4-5446-406a-95e0-fde560e8d60b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019936869s
STEP: Saw pod success
Dec  3 16:35:18.568: INFO: Pod "downwardapi-volume-234bebb4-5446-406a-95e0-fde560e8d60b" satisfied condition "success or failure"
Dec  3 16:35:18.578: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod downwardapi-volume-234bebb4-5446-406a-95e0-fde560e8d60b container client-container: <nil>
STEP: delete the pod
Dec  3 16:35:18.607: INFO: Waiting for pod downwardapi-volume-234bebb4-5446-406a-95e0-fde560e8d60b to disappear
Dec  3 16:35:18.616: INFO: Pod downwardapi-volume-234bebb4-5446-406a-95e0-fde560e8d60b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:35:18.616: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4402" for this suite.
Dec  3 16:35:24.664: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:35:25.032: INFO: namespace downward-api-4402 deletion completed in 6.398500405s
•SSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:35:25.033: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7896
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:35:25.240: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7896" for this suite.
Dec  3 16:35:31.280: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:35:31.611: INFO: namespace services-7896 deletion completed in 6.360642029s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95
•
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:35:31.611: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-2104
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Dec  3 16:35:31.846: INFO: Waiting up to 5m0s for pod "client-containers-780c4241-581a-4dc0-b5a8-202449be6061" in namespace "containers-2104" to be "success or failure"
Dec  3 16:35:31.855: INFO: Pod "client-containers-780c4241-581a-4dc0-b5a8-202449be6061": Phase="Pending", Reason="", readiness=false. Elapsed: 9.343465ms
Dec  3 16:35:33.866: INFO: Pod "client-containers-780c4241-581a-4dc0-b5a8-202449be6061": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.019839952s
STEP: Saw pod success
Dec  3 16:35:33.866: INFO: Pod "client-containers-780c4241-581a-4dc0-b5a8-202449be6061" satisfied condition "success or failure"
Dec  3 16:35:33.875: INFO: Trying to get logs from node shoot--it--tmh9b-w9f-worker-1-z1-f7dc5f884-qk2nz pod client-containers-780c4241-581a-4dc0-b5a8-202449be6061 container test-container: <nil>
STEP: delete the pod
Dec  3 16:35:33.914: INFO: Waiting for pod client-containers-780c4241-581a-4dc0-b5a8-202449be6061 to disappear
Dec  3 16:35:33.924: INFO: Pod client-containers-780c4241-581a-4dc0-b5a8-202449be6061 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:35:33.924: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-2104" for this suite.
Dec  3 16:35:39.974: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:35:40.305: INFO: namespace containers-2104 deletion completed in 6.362367624s
•SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec  3 16:35:40.305: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-1347
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-1347
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec  3 16:35:40.533: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec  3 16:35:56.716: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.104:8080/dial?request=hostName&protocol=http&host=100.64.1.103&port=8080&tries=1'] Namespace:pod-network-test-1347 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 16:35:56.716: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 16:35:57.231: INFO: Waiting for endpoints: map[]
Dec  3 16:35:57.241: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://100.64.1.104:8080/dial?request=hostName&protocol=http&host=100.64.0.78&port=8080&tries=1'] Namespace:pod-network-test-1347 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec  3 16:35:57.241: INFO: >>> kubeConfig: /tmp/tm/kubeconfig/shoot.config
Dec  3 16:35:57.750: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.3-beta.0.56+b3cbbae08ec52a/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec  3 16:35:57.750: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-1347" for this suite.
Dec  3 16:36:09.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec  3 16:36:10.144: INFO: namespace pod-network-test-1347 deletion completed in 12.375718401s
•SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSDec  3 16:36:10.145: INFO: Running AfterSuite actions on all nodes
Dec  3 16:36:10.145: INFO: Running AfterSuite actions on node 1
Dec  3 16:36:10.145: INFO: Skipping dumping logs from cluster

Ran 276 of 4732 Specs in 7170.303 seconds
SUCCESS! -- 276 Passed | 0 Failed | 0 Flaked | 0 Pending | 4456 Skipped
PASS

Ginkgo ran 1 suite in 1h59m32.29130685s
Test Suite Passed
