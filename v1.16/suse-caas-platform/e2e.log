I1220 09:06:41.478500      26 test_context.go:414] Using a temporary kubeconfig file from in-cluster config : /tmp/kubeconfig-816092167
I1220 09:06:41.478673      26 e2e.go:92] Starting e2e run "358dda68-3951-4246-aaaa-1f6659ce6c8a" on Ginkgo node 1
Running Suite: Kubernetes e2e suite
===================================
Random Seed: 1576832799 - Will randomize all specs
Will run 274 of 4897 specs

Dec 20 09:06:41.561: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 09:06:41.564: INFO: Waiting up to 30m0s for all (but 0) nodes to be schedulable
Dec 20 09:06:41.582: INFO: Waiting up to 10m0s for all pods (need at least 0) in namespace 'kube-system' to be running and ready
Dec 20 09:06:41.635: INFO: The status of Pod caasp-remove-etcd-member-7495052c08-from-92a47d4ddb-4nbbw is Succeeded, skipping waiting
Dec 20 09:06:41.635: INFO: 33 / 34 pods in namespace 'kube-system' are running and ready (0 seconds elapsed)
Dec 20 09:06:41.635: INFO: expected 10 pod replicas in namespace 'kube-system', 10 are Running and Ready.
Dec 20 09:06:41.635: INFO: Waiting up to 5m0s for all daemonsets in namespace 'kube-system' to start
Dec 20 09:06:41.649: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'cilium' (0 seconds elapsed)
Dec 20 09:06:41.649: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'kube-proxy' (0 seconds elapsed)
Dec 20 09:06:41.649: INFO: 5 / 5 pods ready in namespace 'kube-system' in daemonset 'kured' (0 seconds elapsed)
Dec 20 09:06:41.649: INFO: e2e test version: v1.16.2
Dec 20 09:06:41.650: INFO: kube-apiserver version: v1.16.2
Dec 20 09:06:41.650: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 09:06:41.656: INFO: Cluster IP family: ipv4
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:06:41.656: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename configmap
Dec 20 09:06:41.686: INFO: Found PodSecurityPolicies; assuming PodSecurityPolicy is enabled.
Dec 20 09:06:41.696: INFO: Found ClusterRoles; assuming RBAC is enabled.
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-6555
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-9973b1dd-6467-4365-9778-4c069858a854
STEP: Creating a pod to test consume configMaps
Dec 20 09:06:41.817: INFO: Waiting up to 5m0s for pod "pod-configmaps-fd1f96c7-882f-48b7-ac1a-57b905c8436c" in namespace "configmap-6555" to be "success or failure"
Dec 20 09:06:41.819: INFO: Pod "pod-configmaps-fd1f96c7-882f-48b7-ac1a-57b905c8436c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.362734ms
Dec 20 09:06:43.823: INFO: Pod "pod-configmaps-fd1f96c7-882f-48b7-ac1a-57b905c8436c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006325164s
Dec 20 09:06:45.828: INFO: Pod "pod-configmaps-fd1f96c7-882f-48b7-ac1a-57b905c8436c": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011033955s
Dec 20 09:06:47.832: INFO: Pod "pod-configmaps-fd1f96c7-882f-48b7-ac1a-57b905c8436c": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015385757s
Dec 20 09:06:49.837: INFO: Pod "pod-configmaps-fd1f96c7-882f-48b7-ac1a-57b905c8436c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.020497603s
STEP: Saw pod success
Dec 20 09:06:49.837: INFO: Pod "pod-configmaps-fd1f96c7-882f-48b7-ac1a-57b905c8436c" satisfied condition "success or failure"
Dec 20 09:06:49.841: INFO: Trying to get logs from node caasp-worker-th-before-0 pod pod-configmaps-fd1f96c7-882f-48b7-ac1a-57b905c8436c container configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 09:06:49.873: INFO: Waiting for pod pod-configmaps-fd1f96c7-882f-48b7-ac1a-57b905c8436c to disappear
Dec 20 09:06:49.875: INFO: Pod pod-configmaps-fd1f96c7-882f-48b7-ac1a-57b905c8436c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:06:49.875: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-6555" for this suite.
Dec 20 09:06:55.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:06:55.983: INFO: namespace configmap-6555 deletion completed in 6.104512924s

• [SLOW TEST:14.327 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:06:55.983: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7274
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 20 09:06:56.121: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c027ffa2-eb54-4674-9154-45ae112f3d06" in namespace "projected-7274" to be "success or failure"
Dec 20 09:06:56.124: INFO: Pod "downwardapi-volume-c027ffa2-eb54-4674-9154-45ae112f3d06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.698451ms
Dec 20 09:06:58.128: INFO: Pod "downwardapi-volume-c027ffa2-eb54-4674-9154-45ae112f3d06": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006852152s
Dec 20 09:07:00.132: INFO: Pod "downwardapi-volume-c027ffa2-eb54-4674-9154-45ae112f3d06": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011444323s
Dec 20 09:07:02.137: INFO: Pod "downwardapi-volume-c027ffa2-eb54-4674-9154-45ae112f3d06": Phase="Pending", Reason="", readiness=false. Elapsed: 6.015587754s
Dec 20 09:07:04.140: INFO: Pod "downwardapi-volume-c027ffa2-eb54-4674-9154-45ae112f3d06": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.019366102s
STEP: Saw pod success
Dec 20 09:07:04.140: INFO: Pod "downwardapi-volume-c027ffa2-eb54-4674-9154-45ae112f3d06" satisfied condition "success or failure"
Dec 20 09:07:04.144: INFO: Trying to get logs from node caasp-worker-th-before-4 pod downwardapi-volume-c027ffa2-eb54-4674-9154-45ae112f3d06 container client-container: <nil>
STEP: delete the pod
Dec 20 09:07:04.169: INFO: Waiting for pod downwardapi-volume-c027ffa2-eb54-4674-9154-45ae112f3d06 to disappear
Dec 20 09:07:04.172: INFO: Pod downwardapi-volume-c027ffa2-eb54-4674-9154-45ae112f3d06 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:07:04.172: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7274" for this suite.
Dec 20 09:07:10.185: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:07:10.282: INFO: namespace projected-7274 deletion completed in 6.106835943s

• [SLOW TEST:14.299 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:07:10.282: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6450
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-ad89d1c3-9c22-4ff5-98b0-b5beb23e3fb2
STEP: Creating a pod to test consume configMaps
Dec 20 09:07:10.447: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-90177b0b-6ebc-4d9c-a9cf-579a4e04379a" in namespace "projected-6450" to be "success or failure"
Dec 20 09:07:10.449: INFO: Pod "pod-projected-configmaps-90177b0b-6ebc-4d9c-a9cf-579a4e04379a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.35924ms
Dec 20 09:07:12.453: INFO: Pod "pod-projected-configmaps-90177b0b-6ebc-4d9c-a9cf-579a4e04379a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006102887s
Dec 20 09:07:14.457: INFO: Pod "pod-projected-configmaps-90177b0b-6ebc-4d9c-a9cf-579a4e04379a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009939967s
STEP: Saw pod success
Dec 20 09:07:14.457: INFO: Pod "pod-projected-configmaps-90177b0b-6ebc-4d9c-a9cf-579a4e04379a" satisfied condition "success or failure"
Dec 20 09:07:14.460: INFO: Trying to get logs from node caasp-worker-th-before-0 pod pod-projected-configmaps-90177b0b-6ebc-4d9c-a9cf-579a4e04379a container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 09:07:14.477: INFO: Waiting for pod pod-projected-configmaps-90177b0b-6ebc-4d9c-a9cf-579a4e04379a to disappear
Dec 20 09:07:14.479: INFO: Pod pod-projected-configmaps-90177b0b-6ebc-4d9c-a9cf-579a4e04379a no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:07:14.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6450" for this suite.
Dec 20 09:07:20.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:07:20.586: INFO: namespace projected-6450 deletion completed in 6.103067026s

• [SLOW TEST:10.304 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:07:20.586: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-4156
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support rollover [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 09:07:20.730: INFO: Pod name rollover-pod: Found 0 pods out of 1
Dec 20 09:07:25.735: INFO: Pod name rollover-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 20 09:07:33.741: INFO: Waiting for pods owned by replica set "test-rollover-controller" to become ready
Dec 20 09:07:35.746: INFO: Creating deployment "test-rollover-deployment"
Dec 20 09:07:35.753: INFO: Make sure deployment "test-rollover-deployment" performs scaling operations
Dec 20 09:07:37.758: INFO: Check revision of new replica set for deployment "test-rollover-deployment"
Dec 20 09:07:37.763: INFO: Ensure that both replica sets have 1 created replica
Dec 20 09:07:37.768: INFO: Rollover old replica sets for deployment "test-rollover-deployment" with new image update
Dec 20 09:07:37.774: INFO: Updating deployment test-rollover-deployment
Dec 20 09:07:37.774: INFO: Wait deployment "test-rollover-deployment" to be observed by the deployment controller
Dec 20 09:07:39.780: INFO: Wait for revision update of deployment "test-rollover-deployment" to 2
Dec 20 09:07:39.787: INFO: Make sure deployment "test-rollover-deployment" is complete
Dec 20 09:07:39.793: INFO: all replica sets need to contain the pod-template-hash label
Dec 20 09:07:39.793: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429658, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 09:07:41.801: INFO: all replica sets need to contain the pod-template-hash label
Dec 20 09:07:41.801: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429658, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 09:07:43.801: INFO: all replica sets need to contain the pod-template-hash label
Dec 20 09:07:43.801: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429658, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 09:07:45.800: INFO: all replica sets need to contain the pod-template-hash label
Dec 20 09:07:45.801: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429658, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 09:07:47.800: INFO: all replica sets need to contain the pod-template-hash label
Dec 20 09:07:47.800: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429667, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 09:07:49.803: INFO: all replica sets need to contain the pod-template-hash label
Dec 20 09:07:49.803: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429667, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 09:07:51.801: INFO: all replica sets need to contain the pod-template-hash label
Dec 20 09:07:51.801: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429667, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 09:07:53.801: INFO: all replica sets need to contain the pod-template-hash label
Dec 20 09:07:53.801: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429667, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 09:07:55.803: INFO: all replica sets need to contain the pod-template-hash label
Dec 20 09:07:55.803: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:2, Replicas:2, UpdatedReplicas:1, ReadyReplicas:2, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429667, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429656, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rollover-deployment-7d7dc6548c\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 09:07:57.800: INFO: 
Dec 20 09:07:57.800: INFO: Ensure that both old replica sets have no replicas
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 20 09:07:57.809: INFO: Deployment "test-rollover-deployment":
&Deployment{ObjectMeta:{test-rollover-deployment  deployment-4156 /apis/apps/v1/namespaces/deployment-4156/deployments/test-rollover-deployment d14e4b02-72ce-49d2-be30-09d9e805e0cb 102820 2 2019-12-20 09:07:35 +0000 UTC <nil> <nil> map[name:rollover-pod] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003bf5228 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:0,MaxSurge:1,},},MinReadySeconds:10,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-20 09:07:36 +0000 UTC,LastTransitionTime:2019-12-20 09:07:36 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rollover-deployment-7d7dc6548c" has successfully progressed.,LastUpdateTime:2019-12-20 09:07:57 +0000 UTC,LastTransitionTime:2019-12-20 09:07:36 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 20 09:07:57.812: INFO: New ReplicaSet "test-rollover-deployment-7d7dc6548c" of Deployment "test-rollover-deployment":
&ReplicaSet{ObjectMeta:{test-rollover-deployment-7d7dc6548c  deployment-4156 /apis/apps/v1/namespaces/deployment-4156/replicasets/test-rollover-deployment-7d7dc6548c f237daf9-c6be-47a0-a711-57a2b0514645 102809 2 2019-12-20 09:07:37 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-rollover-deployment d14e4b02-72ce-49d2-be30-09d9e805e0cb 0xc003bf56e7 0xc003bf56e8}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: 7d7dc6548c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003bf5748 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:2,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 20 09:07:57.812: INFO: All old ReplicaSets of Deployment "test-rollover-deployment":
Dec 20 09:07:57.812: INFO: &ReplicaSet{ObjectMeta:{test-rollover-controller  deployment-4156 /apis/apps/v1/namespaces/deployment-4156/replicasets/test-rollover-controller 71514004-36ce-4fbb-9917-80ba68fe7f8f 102818 2 2019-12-20 09:07:20 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2] [{apps/v1 Deployment test-rollover-deployment d14e4b02-72ce-49d2-be30-09d9e805e0cb 0xc003bf5617 0xc003bf5618}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003bf5678 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 20 09:07:57.812: INFO: &ReplicaSet{ObjectMeta:{test-rollover-deployment-f6c94f66c  deployment-4156 /apis/apps/v1/namespaces/deployment-4156/replicasets/test-rollover-deployment-f6c94f66c cb1c64ae-3b37-4b9d-9420-2c4d5f3909d6 102730 2 2019-12-20 09:07:35 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-rollover-deployment d14e4b02-72ce-49d2-be30-09d9e805e0cb 0xc003bf57b0 0xc003bf57b1}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: rollover-pod,pod-template-hash: f6c94f66c,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:f6c94f66c] map[] [] []  []} {[] [] [{redis-slave gcr.io/google_samples/gb-redisslave:nonexistent [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003bf5828 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:10,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 20 09:07:57.815: INFO: Pod "test-rollover-deployment-7d7dc6548c-l2gkz" is available:
&Pod{ObjectMeta:{test-rollover-deployment-7d7dc6548c-l2gkz test-rollover-deployment-7d7dc6548c- deployment-4156 /api/v1/namespaces/deployment-4156/pods/test-rollover-deployment-7d7dc6548c-l2gkz be4a484b-f221-4ee4-8531-6b2284771578 102776 0 2019-12-20 09:07:37 +0000 UTC <nil> <nil> map[name:rollover-pod pod-template-hash:7d7dc6548c] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rollover-deployment-7d7dc6548c f237daf9-c6be-47a0-a711-57a2b0514645 0xc003bf5d87 0xc003bf5d88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hk2gg,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hk2gg,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hk2gg,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:07:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:07:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:07:46 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:07:37 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.84.149.232,PodIP:10.244.5.81,StartTime:2019-12-20 09:07:38 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-20 09:07:46 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:cri-o://ae90a758c738ea4cf00a854931c19eefea1f756b3b4260ef5e47fc4444174ab6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.5.81,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:07:57.815: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-4156" for this suite.
Dec 20 09:08:03.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:08:03.927: INFO: namespace deployment-4156 deletion completed in 6.108505263s

• [SLOW TEST:43.341 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support rollover [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:08:03.927: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6765
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 09:08:04.062: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:08:14.147: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6765" for this suite.
Dec 20 09:08:52.164: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:08:52.262: INFO: namespace pods-6765 deletion completed in 38.110258859s

• [SLOW TEST:48.334 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support remote command execution over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Secrets 
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:08:52.262: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7848
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secret-namespace-6533
STEP: Creating secret with name secret-test-2b8eac30-ddee-46f1-bcdf-a5ace06313fe
STEP: Creating a pod to test consume secrets
Dec 20 09:08:52.537: INFO: Waiting up to 5m0s for pod "pod-secrets-cd7c51d8-c8d8-4873-a81d-a25cc661c022" in namespace "secrets-7848" to be "success or failure"
Dec 20 09:08:52.539: INFO: Pod "pod-secrets-cd7c51d8-c8d8-4873-a81d-a25cc661c022": Phase="Pending", Reason="", readiness=false. Elapsed: 2.163955ms
Dec 20 09:08:54.543: INFO: Pod "pod-secrets-cd7c51d8-c8d8-4873-a81d-a25cc661c022": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005817506s
Dec 20 09:08:56.546: INFO: Pod "pod-secrets-cd7c51d8-c8d8-4873-a81d-a25cc661c022": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009275763s
Dec 20 09:08:58.550: INFO: Pod "pod-secrets-cd7c51d8-c8d8-4873-a81d-a25cc661c022": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013115791s
Dec 20 09:09:00.554: INFO: Pod "pod-secrets-cd7c51d8-c8d8-4873-a81d-a25cc661c022": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.016602723s
STEP: Saw pod success
Dec 20 09:09:00.554: INFO: Pod "pod-secrets-cd7c51d8-c8d8-4873-a81d-a25cc661c022" satisfied condition "success or failure"
Dec 20 09:09:00.556: INFO: Trying to get logs from node caasp-worker-th-before-3 pod pod-secrets-cd7c51d8-c8d8-4873-a81d-a25cc661c022 container secret-volume-test: <nil>
STEP: delete the pod
Dec 20 09:09:00.582: INFO: Waiting for pod pod-secrets-cd7c51d8-c8d8-4873-a81d-a25cc661c022 to disappear
Dec 20 09:09:00.584: INFO: Pod pod-secrets-cd7c51d8-c8d8-4873-a81d-a25cc661c022 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:09:00.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7848" for this suite.
Dec 20 09:09:06.599: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:09:06.694: INFO: namespace secrets-7848 deletion completed in 6.106484206s
STEP: Destroying namespace "secret-namespace-6533" for this suite.
Dec 20 09:09:12.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:09:12.807: INFO: namespace secret-namespace-6533 deletion completed in 6.113430142s

• [SLOW TEST:20.546 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:09:12.808: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7894
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 20 09:09:12.946: INFO: Waiting up to 5m0s for pod "pod-7a14359d-e358-4351-9dd3-f871f310c048" in namespace "emptydir-7894" to be "success or failure"
Dec 20 09:09:12.949: INFO: Pod "pod-7a14359d-e358-4351-9dd3-f871f310c048": Phase="Pending", Reason="", readiness=false. Elapsed: 2.415765ms
Dec 20 09:09:14.953: INFO: Pod "pod-7a14359d-e358-4351-9dd3-f871f310c048": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006655363s
Dec 20 09:09:16.958: INFO: Pod "pod-7a14359d-e358-4351-9dd3-f871f310c048": Phase="Pending", Reason="", readiness=false. Elapsed: 4.011457654s
Dec 20 09:09:18.961: INFO: Pod "pod-7a14359d-e358-4351-9dd3-f871f310c048": Phase="Succeeded", Reason="", readiness=false. Elapsed: 6.015142821s
STEP: Saw pod success
Dec 20 09:09:18.961: INFO: Pod "pod-7a14359d-e358-4351-9dd3-f871f310c048" satisfied condition "success or failure"
Dec 20 09:09:18.964: INFO: Trying to get logs from node caasp-worker-th-before-4 pod pod-7a14359d-e358-4351-9dd3-f871f310c048 container test-container: <nil>
STEP: delete the pod
Dec 20 09:09:18.997: INFO: Waiting for pod pod-7a14359d-e358-4351-9dd3-f871f310c048 to disappear
Dec 20 09:09:18.999: INFO: Pod pod-7a14359d-e358-4351-9dd3-f871f310c048 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:09:18.999: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7894" for this suite.
Dec 20 09:09:25.013: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:09:25.109: INFO: namespace emptydir-7894 deletion completed in 6.106688238s

• [SLOW TEST:12.302 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-network] Service endpoints latency 
  should not be very high  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:09:25.110: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename svc-latency
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svc-latency-7516
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be very high  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating replication controller svc-latency-rc in namespace svc-latency-7516
I1220 09:09:25.249888      26 runners.go:184] Created replication controller with name: svc-latency-rc, namespace: svc-latency-7516, replica count: 1
I1220 09:09:26.300384      26 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1220 09:09:27.300644      26 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1220 09:09:28.300963      26 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1220 09:09:29.301316      26 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1220 09:09:30.301606      26 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1220 09:09:31.301988      26 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1220 09:09:32.302259      26 runners.go:184] svc-latency-rc Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 20 09:09:32.414: INFO: Created: latency-svc-59zwp
Dec 20 09:09:32.419: INFO: Got endpoints: latency-svc-59zwp [16.915226ms]
Dec 20 09:09:32.430: INFO: Created: latency-svc-k5z6d
Dec 20 09:09:32.433: INFO: Got endpoints: latency-svc-k5z6d [13.737785ms]
Dec 20 09:09:32.437: INFO: Created: latency-svc-tfngg
Dec 20 09:09:32.444: INFO: Got endpoints: latency-svc-tfngg [25.083924ms]
Dec 20 09:09:32.449: INFO: Created: latency-svc-nnp8x
Dec 20 09:09:32.451: INFO: Got endpoints: latency-svc-nnp8x [32.184842ms]
Dec 20 09:09:32.455: INFO: Created: latency-svc-hdrzn
Dec 20 09:09:32.458: INFO: Got endpoints: latency-svc-hdrzn [38.855006ms]
Dec 20 09:09:32.463: INFO: Created: latency-svc-4v5pq
Dec 20 09:09:32.466: INFO: Got endpoints: latency-svc-4v5pq [46.628222ms]
Dec 20 09:09:32.471: INFO: Created: latency-svc-qs5t8
Dec 20 09:09:32.475: INFO: Got endpoints: latency-svc-qs5t8 [55.339962ms]
Dec 20 09:09:32.480: INFO: Created: latency-svc-pljxc
Dec 20 09:09:32.483: INFO: Got endpoints: latency-svc-pljxc [63.559464ms]
Dec 20 09:09:32.487: INFO: Created: latency-svc-f5cq5
Dec 20 09:09:32.490: INFO: Got endpoints: latency-svc-f5cq5 [71.023532ms]
Dec 20 09:09:32.499: INFO: Created: latency-svc-zcs99
Dec 20 09:09:32.502: INFO: Got endpoints: latency-svc-zcs99 [82.573145ms]
Dec 20 09:09:32.507: INFO: Created: latency-svc-fqhlv
Dec 20 09:09:32.509: INFO: Got endpoints: latency-svc-fqhlv [90.290107ms]
Dec 20 09:09:32.514: INFO: Created: latency-svc-dgmcn
Dec 20 09:09:32.516: INFO: Got endpoints: latency-svc-dgmcn [97.264649ms]
Dec 20 09:09:32.529: INFO: Created: latency-svc-mfjtj
Dec 20 09:09:32.532: INFO: Got endpoints: latency-svc-mfjtj [112.904568ms]
Dec 20 09:09:32.537: INFO: Created: latency-svc-q55lw
Dec 20 09:09:32.540: INFO: Got endpoints: latency-svc-q55lw [120.460324ms]
Dec 20 09:09:32.544: INFO: Created: latency-svc-gjp7z
Dec 20 09:09:32.547: INFO: Got endpoints: latency-svc-gjp7z [127.485275ms]
Dec 20 09:09:32.552: INFO: Created: latency-svc-rrwmf
Dec 20 09:09:32.555: INFO: Got endpoints: latency-svc-rrwmf [135.559833ms]
Dec 20 09:09:32.563: INFO: Created: latency-svc-qclnz
Dec 20 09:09:32.567: INFO: Got endpoints: latency-svc-qclnz [134.186082ms]
Dec 20 09:09:32.572: INFO: Created: latency-svc-gfq6m
Dec 20 09:09:32.575: INFO: Got endpoints: latency-svc-gfq6m [130.564802ms]
Dec 20 09:09:32.579: INFO: Created: latency-svc-qq2lm
Dec 20 09:09:32.581: INFO: Got endpoints: latency-svc-qq2lm [129.917985ms]
Dec 20 09:09:32.586: INFO: Created: latency-svc-5bxkl
Dec 20 09:09:32.589: INFO: Got endpoints: latency-svc-5bxkl [130.981438ms]
Dec 20 09:09:32.594: INFO: Created: latency-svc-692jx
Dec 20 09:09:32.598: INFO: Got endpoints: latency-svc-692jx [132.282506ms]
Dec 20 09:09:32.603: INFO: Created: latency-svc-mv7fz
Dec 20 09:09:32.606: INFO: Got endpoints: latency-svc-mv7fz [131.698404ms]
Dec 20 09:09:32.610: INFO: Created: latency-svc-xtnfp
Dec 20 09:09:32.613: INFO: Got endpoints: latency-svc-xtnfp [129.629565ms]
Dec 20 09:09:32.617: INFO: Created: latency-svc-g4ljp
Dec 20 09:09:32.619: INFO: Got endpoints: latency-svc-g4ljp [128.857109ms]
Dec 20 09:09:32.623: INFO: Created: latency-svc-c7hcq
Dec 20 09:09:32.626: INFO: Got endpoints: latency-svc-c7hcq [124.119556ms]
Dec 20 09:09:32.630: INFO: Created: latency-svc-4vwhq
Dec 20 09:09:32.633: INFO: Got endpoints: latency-svc-4vwhq [123.223487ms]
Dec 20 09:09:32.638: INFO: Created: latency-svc-588c6
Dec 20 09:09:32.641: INFO: Got endpoints: latency-svc-588c6 [124.064582ms]
Dec 20 09:09:32.644: INFO: Created: latency-svc-zjs4b
Dec 20 09:09:32.647: INFO: Got endpoints: latency-svc-zjs4b [114.75767ms]
Dec 20 09:09:32.651: INFO: Created: latency-svc-f6v6r
Dec 20 09:09:32.654: INFO: Got endpoints: latency-svc-f6v6r [114.229898ms]
Dec 20 09:09:32.658: INFO: Created: latency-svc-mbk57
Dec 20 09:09:32.663: INFO: Got endpoints: latency-svc-mbk57 [116.283452ms]
Dec 20 09:09:32.666: INFO: Created: latency-svc-5k84p
Dec 20 09:09:32.680: INFO: Got endpoints: latency-svc-5k84p [125.530681ms]
Dec 20 09:09:32.691: INFO: Created: latency-svc-pm7wp
Dec 20 09:09:32.695: INFO: Got endpoints: latency-svc-pm7wp [127.643178ms]
Dec 20 09:09:32.699: INFO: Created: latency-svc-hcxjv
Dec 20 09:09:32.702: INFO: Got endpoints: latency-svc-hcxjv [127.052388ms]
Dec 20 09:09:32.706: INFO: Created: latency-svc-rrgv9
Dec 20 09:09:32.709: INFO: Got endpoints: latency-svc-rrgv9 [127.52117ms]
Dec 20 09:09:32.713: INFO: Created: latency-svc-zc4fg
Dec 20 09:09:32.715: INFO: Got endpoints: latency-svc-zc4fg [125.919331ms]
Dec 20 09:09:32.720: INFO: Created: latency-svc-dpn9j
Dec 20 09:09:32.725: INFO: Got endpoints: latency-svc-dpn9j [126.532491ms]
Dec 20 09:09:32.727: INFO: Created: latency-svc-7jb2d
Dec 20 09:09:32.734: INFO: Created: latency-svc-c7pbr
Dec 20 09:09:32.749: INFO: Created: latency-svc-9mrcg
Dec 20 09:09:32.756: INFO: Created: latency-svc-hw569
Dec 20 09:09:32.763: INFO: Created: latency-svc-trshz
Dec 20 09:09:32.768: INFO: Got endpoints: latency-svc-7jb2d [161.207362ms]
Dec 20 09:09:32.769: INFO: Created: latency-svc-zzwwc
Dec 20 09:09:32.775: INFO: Created: latency-svc-bdkx8
Dec 20 09:09:32.781: INFO: Created: latency-svc-75sl5
Dec 20 09:09:32.788: INFO: Created: latency-svc-92pvq
Dec 20 09:09:32.795: INFO: Created: latency-svc-9f2wb
Dec 20 09:09:32.803: INFO: Created: latency-svc-dcs47
Dec 20 09:09:32.809: INFO: Created: latency-svc-gvfsp
Dec 20 09:09:32.819: INFO: Got endpoints: latency-svc-c7pbr [206.359015ms]
Dec 20 09:09:32.820: INFO: Created: latency-svc-qqnjm
Dec 20 09:09:32.827: INFO: Created: latency-svc-c58xl
Dec 20 09:09:32.834: INFO: Created: latency-svc-thqgq
Dec 20 09:09:32.840: INFO: Created: latency-svc-vxc48
Dec 20 09:09:32.848: INFO: Created: latency-svc-pv2t2
Dec 20 09:09:32.869: INFO: Got endpoints: latency-svc-9mrcg [249.991589ms]
Dec 20 09:09:32.879: INFO: Created: latency-svc-x4rps
Dec 20 09:09:32.918: INFO: Got endpoints: latency-svc-hw569 [292.433921ms]
Dec 20 09:09:32.927: INFO: Created: latency-svc-hq99k
Dec 20 09:09:32.971: INFO: Got endpoints: latency-svc-trshz [338.278423ms]
Dec 20 09:09:32.981: INFO: Created: latency-svc-qdccg
Dec 20 09:09:33.018: INFO: Got endpoints: latency-svc-zzwwc [376.998575ms]
Dec 20 09:09:33.028: INFO: Created: latency-svc-764xk
Dec 20 09:09:33.069: INFO: Got endpoints: latency-svc-bdkx8 [421.862804ms]
Dec 20 09:09:33.079: INFO: Created: latency-svc-hv59q
Dec 20 09:09:33.119: INFO: Got endpoints: latency-svc-75sl5 [464.747203ms]
Dec 20 09:09:33.129: INFO: Created: latency-svc-5xlv2
Dec 20 09:09:33.169: INFO: Got endpoints: latency-svc-92pvq [505.476484ms]
Dec 20 09:09:33.179: INFO: Created: latency-svc-4pvx8
Dec 20 09:09:33.219: INFO: Got endpoints: latency-svc-9f2wb [538.927909ms]
Dec 20 09:09:33.230: INFO: Created: latency-svc-nnwzr
Dec 20 09:09:33.268: INFO: Got endpoints: latency-svc-dcs47 [573.718984ms]
Dec 20 09:09:33.280: INFO: Created: latency-svc-kctkg
Dec 20 09:09:33.319: INFO: Got endpoints: latency-svc-gvfsp [616.753141ms]
Dec 20 09:09:33.329: INFO: Created: latency-svc-2rz9q
Dec 20 09:09:33.368: INFO: Got endpoints: latency-svc-qqnjm [659.262455ms]
Dec 20 09:09:33.378: INFO: Created: latency-svc-kftqt
Dec 20 09:09:33.419: INFO: Got endpoints: latency-svc-c58xl [703.696346ms]
Dec 20 09:09:33.429: INFO: Created: latency-svc-fbk8l
Dec 20 09:09:33.469: INFO: Got endpoints: latency-svc-thqgq [744.53744ms]
Dec 20 09:09:33.482: INFO: Created: latency-svc-vs6bt
Dec 20 09:09:33.519: INFO: Got endpoints: latency-svc-vxc48 [750.985995ms]
Dec 20 09:09:33.530: INFO: Created: latency-svc-xjmtz
Dec 20 09:09:33.569: INFO: Got endpoints: latency-svc-pv2t2 [749.657733ms]
Dec 20 09:09:33.579: INFO: Created: latency-svc-q69tb
Dec 20 09:09:33.619: INFO: Got endpoints: latency-svc-x4rps [749.629181ms]
Dec 20 09:09:33.630: INFO: Created: latency-svc-7qvmm
Dec 20 09:09:33.671: INFO: Got endpoints: latency-svc-hq99k [752.587766ms]
Dec 20 09:09:33.681: INFO: Created: latency-svc-9l5sd
Dec 20 09:09:33.719: INFO: Got endpoints: latency-svc-qdccg [747.906606ms]
Dec 20 09:09:33.730: INFO: Created: latency-svc-qqxmr
Dec 20 09:09:33.768: INFO: Got endpoints: latency-svc-764xk [750.686659ms]
Dec 20 09:09:33.780: INFO: Created: latency-svc-8ccxv
Dec 20 09:09:33.818: INFO: Got endpoints: latency-svc-hv59q [748.877656ms]
Dec 20 09:09:33.826: INFO: Created: latency-svc-hv6jp
Dec 20 09:09:33.869: INFO: Got endpoints: latency-svc-5xlv2 [749.849134ms]
Dec 20 09:09:33.879: INFO: Created: latency-svc-tfnr9
Dec 20 09:09:33.919: INFO: Got endpoints: latency-svc-4pvx8 [749.903155ms]
Dec 20 09:09:33.929: INFO: Created: latency-svc-mqbw6
Dec 20 09:09:33.969: INFO: Got endpoints: latency-svc-nnwzr [749.852683ms]
Dec 20 09:09:33.980: INFO: Created: latency-svc-klc52
Dec 20 09:09:34.018: INFO: Got endpoints: latency-svc-kctkg [749.579907ms]
Dec 20 09:09:34.029: INFO: Created: latency-svc-fszt7
Dec 20 09:09:34.068: INFO: Got endpoints: latency-svc-2rz9q [749.710114ms]
Dec 20 09:09:34.078: INFO: Created: latency-svc-7cbfq
Dec 20 09:09:34.119: INFO: Got endpoints: latency-svc-kftqt [750.507502ms]
Dec 20 09:09:34.129: INFO: Created: latency-svc-sr4np
Dec 20 09:09:34.169: INFO: Got endpoints: latency-svc-fbk8l [749.896773ms]
Dec 20 09:09:34.198: INFO: Created: latency-svc-8xf2t
Dec 20 09:09:34.219: INFO: Got endpoints: latency-svc-vs6bt [749.794886ms]
Dec 20 09:09:34.230: INFO: Created: latency-svc-vbxdh
Dec 20 09:09:34.268: INFO: Got endpoints: latency-svc-xjmtz [749.721629ms]
Dec 20 09:09:34.280: INFO: Created: latency-svc-zqnhd
Dec 20 09:09:34.319: INFO: Got endpoints: latency-svc-q69tb [750.148335ms]
Dec 20 09:09:34.329: INFO: Created: latency-svc-d7ft8
Dec 20 09:09:34.369: INFO: Got endpoints: latency-svc-7qvmm [750.389563ms]
Dec 20 09:09:34.383: INFO: Created: latency-svc-c4k7b
Dec 20 09:09:34.418: INFO: Got endpoints: latency-svc-9l5sd [746.93021ms]
Dec 20 09:09:34.428: INFO: Created: latency-svc-vp2hm
Dec 20 09:09:34.469: INFO: Got endpoints: latency-svc-qqxmr [750.213542ms]
Dec 20 09:09:34.481: INFO: Created: latency-svc-9p2kn
Dec 20 09:09:34.518: INFO: Got endpoints: latency-svc-8ccxv [750.010739ms]
Dec 20 09:09:34.529: INFO: Created: latency-svc-m6dww
Dec 20 09:09:34.569: INFO: Got endpoints: latency-svc-hv6jp [751.06927ms]
Dec 20 09:09:34.579: INFO: Created: latency-svc-jh74k
Dec 20 09:09:34.618: INFO: Got endpoints: latency-svc-tfnr9 [749.492631ms]
Dec 20 09:09:34.627: INFO: Created: latency-svc-hnp4d
Dec 20 09:09:34.668: INFO: Got endpoints: latency-svc-mqbw6 [749.324766ms]
Dec 20 09:09:34.678: INFO: Created: latency-svc-hggvg
Dec 20 09:09:34.719: INFO: Got endpoints: latency-svc-klc52 [749.947851ms]
Dec 20 09:09:34.730: INFO: Created: latency-svc-zfjqm
Dec 20 09:09:34.768: INFO: Got endpoints: latency-svc-fszt7 [750.267712ms]
Dec 20 09:09:34.779: INFO: Created: latency-svc-4g92d
Dec 20 09:09:34.818: INFO: Got endpoints: latency-svc-7cbfq [749.981844ms]
Dec 20 09:09:34.828: INFO: Created: latency-svc-2twpx
Dec 20 09:09:34.868: INFO: Got endpoints: latency-svc-sr4np [749.499823ms]
Dec 20 09:09:34.878: INFO: Created: latency-svc-hp52d
Dec 20 09:09:34.919: INFO: Got endpoints: latency-svc-8xf2t [750.424256ms]
Dec 20 09:09:34.928: INFO: Created: latency-svc-k47qs
Dec 20 09:09:34.969: INFO: Got endpoints: latency-svc-vbxdh [749.579015ms]
Dec 20 09:09:34.978: INFO: Created: latency-svc-hdw8v
Dec 20 09:09:35.019: INFO: Got endpoints: latency-svc-zqnhd [750.234973ms]
Dec 20 09:09:35.030: INFO: Created: latency-svc-htv68
Dec 20 09:09:35.068: INFO: Got endpoints: latency-svc-d7ft8 [748.897067ms]
Dec 20 09:09:35.077: INFO: Created: latency-svc-8q2gt
Dec 20 09:09:35.119: INFO: Got endpoints: latency-svc-c4k7b [750.05542ms]
Dec 20 09:09:35.129: INFO: Created: latency-svc-6fqmz
Dec 20 09:09:35.168: INFO: Got endpoints: latency-svc-vp2hm [750.369254ms]
Dec 20 09:09:35.178: INFO: Created: latency-svc-snf4p
Dec 20 09:09:35.219: INFO: Got endpoints: latency-svc-9p2kn [750.003375ms]
Dec 20 09:09:35.230: INFO: Created: latency-svc-6pjgn
Dec 20 09:09:35.268: INFO: Got endpoints: latency-svc-m6dww [749.834636ms]
Dec 20 09:09:35.280: INFO: Created: latency-svc-7z9gs
Dec 20 09:09:35.318: INFO: Got endpoints: latency-svc-jh74k [749.718066ms]
Dec 20 09:09:35.331: INFO: Created: latency-svc-gkqvh
Dec 20 09:09:35.368: INFO: Got endpoints: latency-svc-hnp4d [750.198144ms]
Dec 20 09:09:35.379: INFO: Created: latency-svc-s5vnk
Dec 20 09:09:35.419: INFO: Got endpoints: latency-svc-hggvg [750.663366ms]
Dec 20 09:09:35.429: INFO: Created: latency-svc-5rc8f
Dec 20 09:09:35.470: INFO: Got endpoints: latency-svc-zfjqm [750.674745ms]
Dec 20 09:09:35.482: INFO: Created: latency-svc-lbbvq
Dec 20 09:09:35.518: INFO: Got endpoints: latency-svc-4g92d [749.723685ms]
Dec 20 09:09:35.531: INFO: Created: latency-svc-g6cvb
Dec 20 09:09:35.568: INFO: Got endpoints: latency-svc-2twpx [749.989663ms]
Dec 20 09:09:35.578: INFO: Created: latency-svc-kk5vk
Dec 20 09:09:35.618: INFO: Got endpoints: latency-svc-hp52d [750.010572ms]
Dec 20 09:09:35.628: INFO: Created: latency-svc-rc56t
Dec 20 09:09:35.669: INFO: Got endpoints: latency-svc-k47qs [749.512187ms]
Dec 20 09:09:35.679: INFO: Created: latency-svc-hfcx6
Dec 20 09:09:35.719: INFO: Got endpoints: latency-svc-hdw8v [750.37995ms]
Dec 20 09:09:35.730: INFO: Created: latency-svc-7v9m5
Dec 20 09:09:35.768: INFO: Got endpoints: latency-svc-htv68 [749.242674ms]
Dec 20 09:09:35.778: INFO: Created: latency-svc-2mvd2
Dec 20 09:09:35.818: INFO: Got endpoints: latency-svc-8q2gt [750.330628ms]
Dec 20 09:09:35.828: INFO: Created: latency-svc-kscrf
Dec 20 09:09:35.869: INFO: Got endpoints: latency-svc-6fqmz [749.244074ms]
Dec 20 09:09:35.895: INFO: Created: latency-svc-6wmvf
Dec 20 09:09:35.919: INFO: Got endpoints: latency-svc-snf4p [750.574904ms]
Dec 20 09:09:35.929: INFO: Created: latency-svc-sxdc6
Dec 20 09:09:35.971: INFO: Got endpoints: latency-svc-6pjgn [751.75053ms]
Dec 20 09:09:35.981: INFO: Created: latency-svc-7ckw2
Dec 20 09:09:36.019: INFO: Got endpoints: latency-svc-7z9gs [750.738496ms]
Dec 20 09:09:36.030: INFO: Created: latency-svc-whmp7
Dec 20 09:09:36.068: INFO: Got endpoints: latency-svc-gkqvh [749.741319ms]
Dec 20 09:09:36.078: INFO: Created: latency-svc-x5nbw
Dec 20 09:09:36.118: INFO: Got endpoints: latency-svc-s5vnk [750.039786ms]
Dec 20 09:09:36.130: INFO: Created: latency-svc-mv7zv
Dec 20 09:09:36.168: INFO: Got endpoints: latency-svc-5rc8f [749.571997ms]
Dec 20 09:09:36.178: INFO: Created: latency-svc-zd4vj
Dec 20 09:09:36.219: INFO: Got endpoints: latency-svc-lbbvq [749.352238ms]
Dec 20 09:09:36.231: INFO: Created: latency-svc-cht4r
Dec 20 09:09:36.268: INFO: Got endpoints: latency-svc-g6cvb [749.745132ms]
Dec 20 09:09:36.281: INFO: Created: latency-svc-ttchw
Dec 20 09:09:36.319: INFO: Got endpoints: latency-svc-kk5vk [750.417341ms]
Dec 20 09:09:36.329: INFO: Created: latency-svc-dbzw2
Dec 20 09:09:36.369: INFO: Got endpoints: latency-svc-rc56t [750.137981ms]
Dec 20 09:09:36.380: INFO: Created: latency-svc-2xfsg
Dec 20 09:09:36.419: INFO: Got endpoints: latency-svc-hfcx6 [750.521687ms]
Dec 20 09:09:36.437: INFO: Created: latency-svc-d7zdg
Dec 20 09:09:36.469: INFO: Got endpoints: latency-svc-7v9m5 [749.698435ms]
Dec 20 09:09:36.480: INFO: Created: latency-svc-d8wqq
Dec 20 09:09:36.518: INFO: Got endpoints: latency-svc-2mvd2 [750.321328ms]
Dec 20 09:09:36.529: INFO: Created: latency-svc-gw8rf
Dec 20 09:09:36.569: INFO: Got endpoints: latency-svc-kscrf [750.560133ms]
Dec 20 09:09:36.578: INFO: Created: latency-svc-57nr7
Dec 20 09:09:36.618: INFO: Got endpoints: latency-svc-6wmvf [749.407845ms]
Dec 20 09:09:36.628: INFO: Created: latency-svc-g9sb4
Dec 20 09:09:36.668: INFO: Got endpoints: latency-svc-sxdc6 [749.374581ms]
Dec 20 09:09:36.678: INFO: Created: latency-svc-fgp7j
Dec 20 09:09:36.719: INFO: Got endpoints: latency-svc-7ckw2 [747.645979ms]
Dec 20 09:09:36.732: INFO: Created: latency-svc-dwf7w
Dec 20 09:09:36.768: INFO: Got endpoints: latency-svc-whmp7 [749.338233ms]
Dec 20 09:09:36.778: INFO: Created: latency-svc-zjz7m
Dec 20 09:09:36.819: INFO: Got endpoints: latency-svc-x5nbw [750.501797ms]
Dec 20 09:09:36.829: INFO: Created: latency-svc-85nc2
Dec 20 09:09:36.869: INFO: Got endpoints: latency-svc-mv7zv [749.996035ms]
Dec 20 09:09:36.878: INFO: Created: latency-svc-brjzm
Dec 20 09:09:36.918: INFO: Got endpoints: latency-svc-zd4vj [749.93064ms]
Dec 20 09:09:36.928: INFO: Created: latency-svc-wq2hq
Dec 20 09:09:36.969: INFO: Got endpoints: latency-svc-cht4r [749.266069ms]
Dec 20 09:09:36.979: INFO: Created: latency-svc-md8fd
Dec 20 09:09:37.018: INFO: Got endpoints: latency-svc-ttchw [749.912074ms]
Dec 20 09:09:37.029: INFO: Created: latency-svc-lxvmt
Dec 20 09:09:37.068: INFO: Got endpoints: latency-svc-dbzw2 [749.304871ms]
Dec 20 09:09:37.077: INFO: Created: latency-svc-ktw2f
Dec 20 09:09:37.118: INFO: Got endpoints: latency-svc-2xfsg [749.758209ms]
Dec 20 09:09:37.128: INFO: Created: latency-svc-fhggs
Dec 20 09:09:37.168: INFO: Got endpoints: latency-svc-d7zdg [749.244987ms]
Dec 20 09:09:37.179: INFO: Created: latency-svc-xrpjj
Dec 20 09:09:37.220: INFO: Got endpoints: latency-svc-d8wqq [750.702192ms]
Dec 20 09:09:37.232: INFO: Created: latency-svc-jt7zh
Dec 20 09:09:37.268: INFO: Got endpoints: latency-svc-gw8rf [750.017072ms]
Dec 20 09:09:37.279: INFO: Created: latency-svc-d2495
Dec 20 09:09:37.318: INFO: Got endpoints: latency-svc-57nr7 [749.669723ms]
Dec 20 09:09:37.332: INFO: Created: latency-svc-788fs
Dec 20 09:09:37.368: INFO: Got endpoints: latency-svc-g9sb4 [750.272199ms]
Dec 20 09:09:37.378: INFO: Created: latency-svc-rlkcp
Dec 20 09:09:37.419: INFO: Got endpoints: latency-svc-fgp7j [750.483326ms]
Dec 20 09:09:37.430: INFO: Created: latency-svc-cdhjn
Dec 20 09:09:37.469: INFO: Got endpoints: latency-svc-dwf7w [750.224237ms]
Dec 20 09:09:37.480: INFO: Created: latency-svc-r5jgq
Dec 20 09:09:37.518: INFO: Got endpoints: latency-svc-zjz7m [749.931184ms]
Dec 20 09:09:37.530: INFO: Created: latency-svc-xv8qd
Dec 20 09:09:37.568: INFO: Got endpoints: latency-svc-85nc2 [749.125382ms]
Dec 20 09:09:37.578: INFO: Created: latency-svc-k8vjv
Dec 20 09:09:37.619: INFO: Got endpoints: latency-svc-brjzm [750.025458ms]
Dec 20 09:09:37.629: INFO: Created: latency-svc-m5wl2
Dec 20 09:09:37.669: INFO: Got endpoints: latency-svc-wq2hq [750.271969ms]
Dec 20 09:09:37.678: INFO: Created: latency-svc-9cmz4
Dec 20 09:09:37.720: INFO: Got endpoints: latency-svc-md8fd [750.783972ms]
Dec 20 09:09:37.731: INFO: Created: latency-svc-8n9hv
Dec 20 09:09:37.768: INFO: Got endpoints: latency-svc-lxvmt [750.064853ms]
Dec 20 09:09:37.778: INFO: Created: latency-svc-kjdzm
Dec 20 09:09:37.818: INFO: Got endpoints: latency-svc-ktw2f [749.819764ms]
Dec 20 09:09:37.828: INFO: Created: latency-svc-x4cwc
Dec 20 09:09:37.868: INFO: Got endpoints: latency-svc-fhggs [749.864901ms]
Dec 20 09:09:37.878: INFO: Created: latency-svc-92c7l
Dec 20 09:09:37.919: INFO: Got endpoints: latency-svc-xrpjj [750.23275ms]
Dec 20 09:09:37.929: INFO: Created: latency-svc-m9nlh
Dec 20 09:09:37.969: INFO: Got endpoints: latency-svc-jt7zh [749.737461ms]
Dec 20 09:09:37.980: INFO: Created: latency-svc-gdxgt
Dec 20 09:09:38.019: INFO: Got endpoints: latency-svc-d2495 [750.070623ms]
Dec 20 09:09:38.029: INFO: Created: latency-svc-b6b87
Dec 20 09:09:38.068: INFO: Got endpoints: latency-svc-788fs [749.809506ms]
Dec 20 09:09:38.078: INFO: Created: latency-svc-jb9xg
Dec 20 09:09:38.119: INFO: Got endpoints: latency-svc-rlkcp [750.12026ms]
Dec 20 09:09:38.128: INFO: Created: latency-svc-w42dk
Dec 20 09:09:38.168: INFO: Got endpoints: latency-svc-cdhjn [749.309926ms]
Dec 20 09:09:38.178: INFO: Created: latency-svc-qkx58
Dec 20 09:09:38.219: INFO: Got endpoints: latency-svc-r5jgq [749.737389ms]
Dec 20 09:09:38.232: INFO: Created: latency-svc-bzxl9
Dec 20 09:09:38.268: INFO: Got endpoints: latency-svc-xv8qd [749.534519ms]
Dec 20 09:09:38.278: INFO: Created: latency-svc-kmk2q
Dec 20 09:09:38.318: INFO: Got endpoints: latency-svc-k8vjv [750.072266ms]
Dec 20 09:09:38.327: INFO: Created: latency-svc-pcmct
Dec 20 09:09:38.369: INFO: Got endpoints: latency-svc-m5wl2 [750.080543ms]
Dec 20 09:09:38.378: INFO: Created: latency-svc-xfntr
Dec 20 09:09:38.418: INFO: Got endpoints: latency-svc-9cmz4 [749.78164ms]
Dec 20 09:09:38.428: INFO: Created: latency-svc-27mgh
Dec 20 09:09:38.469: INFO: Got endpoints: latency-svc-8n9hv [749.598773ms]
Dec 20 09:09:38.480: INFO: Created: latency-svc-kzv7d
Dec 20 09:09:38.519: INFO: Got endpoints: latency-svc-kjdzm [750.495679ms]
Dec 20 09:09:38.529: INFO: Created: latency-svc-fcdtx
Dec 20 09:09:38.568: INFO: Got endpoints: latency-svc-x4cwc [750.220494ms]
Dec 20 09:09:38.577: INFO: Created: latency-svc-7xt2d
Dec 20 09:09:38.618: INFO: Got endpoints: latency-svc-92c7l [749.81192ms]
Dec 20 09:09:38.628: INFO: Created: latency-svc-kcctl
Dec 20 09:09:38.669: INFO: Got endpoints: latency-svc-m9nlh [749.961477ms]
Dec 20 09:09:38.677: INFO: Created: latency-svc-pcpbc
Dec 20 09:09:38.719: INFO: Got endpoints: latency-svc-gdxgt [749.948295ms]
Dec 20 09:09:38.730: INFO: Created: latency-svc-wr8tg
Dec 20 09:09:38.768: INFO: Got endpoints: latency-svc-b6b87 [749.711367ms]
Dec 20 09:09:38.778: INFO: Created: latency-svc-2drcs
Dec 20 09:09:38.819: INFO: Got endpoints: latency-svc-jb9xg [750.9686ms]
Dec 20 09:09:38.829: INFO: Created: latency-svc-xnw72
Dec 20 09:09:38.868: INFO: Got endpoints: latency-svc-w42dk [749.691077ms]
Dec 20 09:09:38.878: INFO: Created: latency-svc-vcq5n
Dec 20 09:09:38.918: INFO: Got endpoints: latency-svc-qkx58 [750.184894ms]
Dec 20 09:09:38.928: INFO: Created: latency-svc-8rrqn
Dec 20 09:09:38.976: INFO: Got endpoints: latency-svc-bzxl9 [756.568458ms]
Dec 20 09:09:38.986: INFO: Created: latency-svc-lt7rh
Dec 20 09:09:39.019: INFO: Got endpoints: latency-svc-kmk2q [750.471764ms]
Dec 20 09:09:39.029: INFO: Created: latency-svc-prr4q
Dec 20 09:09:39.068: INFO: Got endpoints: latency-svc-pcmct [750.065221ms]
Dec 20 09:09:39.077: INFO: Created: latency-svc-xbqt2
Dec 20 09:09:39.118: INFO: Got endpoints: latency-svc-xfntr [749.533198ms]
Dec 20 09:09:39.128: INFO: Created: latency-svc-bdwbz
Dec 20 09:09:39.168: INFO: Got endpoints: latency-svc-27mgh [750.004871ms]
Dec 20 09:09:39.178: INFO: Created: latency-svc-727ph
Dec 20 09:09:39.219: INFO: Got endpoints: latency-svc-kzv7d [749.539917ms]
Dec 20 09:09:39.230: INFO: Created: latency-svc-lq2bv
Dec 20 09:09:39.268: INFO: Got endpoints: latency-svc-fcdtx [749.783128ms]
Dec 20 09:09:39.278: INFO: Created: latency-svc-qq5fg
Dec 20 09:09:39.318: INFO: Got endpoints: latency-svc-7xt2d [749.35466ms]
Dec 20 09:09:39.329: INFO: Created: latency-svc-k9tbf
Dec 20 09:09:39.368: INFO: Got endpoints: latency-svc-kcctl [749.791903ms]
Dec 20 09:09:39.378: INFO: Created: latency-svc-r8ngk
Dec 20 09:09:39.418: INFO: Got endpoints: latency-svc-pcpbc [749.590589ms]
Dec 20 09:09:39.428: INFO: Created: latency-svc-szscz
Dec 20 09:09:39.469: INFO: Got endpoints: latency-svc-wr8tg [749.408316ms]
Dec 20 09:09:39.480: INFO: Created: latency-svc-7jvgf
Dec 20 09:09:39.518: INFO: Got endpoints: latency-svc-2drcs [750.108188ms]
Dec 20 09:09:39.537: INFO: Created: latency-svc-zsfwm
Dec 20 09:09:39.568: INFO: Got endpoints: latency-svc-xnw72 [748.329705ms]
Dec 20 09:09:39.585: INFO: Created: latency-svc-dnrb5
Dec 20 09:09:39.619: INFO: Got endpoints: latency-svc-vcq5n [750.313984ms]
Dec 20 09:09:39.632: INFO: Created: latency-svc-lmjff
Dec 20 09:09:39.669: INFO: Got endpoints: latency-svc-8rrqn [749.946992ms]
Dec 20 09:09:39.678: INFO: Created: latency-svc-lbvmx
Dec 20 09:09:39.720: INFO: Got endpoints: latency-svc-lt7rh [744.165021ms]
Dec 20 09:09:39.732: INFO: Created: latency-svc-kzn8n
Dec 20 09:09:39.769: INFO: Got endpoints: latency-svc-prr4q [750.280181ms]
Dec 20 09:09:39.780: INFO: Created: latency-svc-92hxl
Dec 20 09:09:39.819: INFO: Got endpoints: latency-svc-xbqt2 [750.426463ms]
Dec 20 09:09:39.828: INFO: Created: latency-svc-8rd98
Dec 20 09:09:39.868: INFO: Got endpoints: latency-svc-bdwbz [749.676054ms]
Dec 20 09:09:39.878: INFO: Created: latency-svc-gdv47
Dec 20 09:09:39.919: INFO: Got endpoints: latency-svc-727ph [750.486729ms]
Dec 20 09:09:39.929: INFO: Created: latency-svc-mrxdx
Dec 20 09:09:39.970: INFO: Got endpoints: latency-svc-lq2bv [750.981237ms]
Dec 20 09:09:39.999: INFO: Created: latency-svc-q8cqz
Dec 20 09:09:40.019: INFO: Got endpoints: latency-svc-qq5fg [750.555256ms]
Dec 20 09:09:40.030: INFO: Created: latency-svc-kt88w
Dec 20 09:09:40.067: INFO: Got endpoints: latency-svc-k9tbf [749.596724ms]
Dec 20 09:09:40.076: INFO: Created: latency-svc-62d2s
Dec 20 09:09:40.119: INFO: Got endpoints: latency-svc-r8ngk [750.794509ms]
Dec 20 09:09:40.129: INFO: Created: latency-svc-whhhb
Dec 20 09:09:40.169: INFO: Got endpoints: latency-svc-szscz [750.152924ms]
Dec 20 09:09:40.178: INFO: Created: latency-svc-vjhj5
Dec 20 09:09:40.219: INFO: Got endpoints: latency-svc-7jvgf [750.134718ms]
Dec 20 09:09:40.229: INFO: Created: latency-svc-8449m
Dec 20 09:09:40.268: INFO: Got endpoints: latency-svc-zsfwm [749.705585ms]
Dec 20 09:09:40.319: INFO: Got endpoints: latency-svc-dnrb5 [750.97638ms]
Dec 20 09:09:40.368: INFO: Got endpoints: latency-svc-lmjff [749.751579ms]
Dec 20 09:09:40.419: INFO: Got endpoints: latency-svc-lbvmx [750.094036ms]
Dec 20 09:09:40.470: INFO: Got endpoints: latency-svc-kzn8n [749.718933ms]
Dec 20 09:09:40.518: INFO: Got endpoints: latency-svc-92hxl [749.315489ms]
Dec 20 09:09:40.568: INFO: Got endpoints: latency-svc-8rd98 [749.363919ms]
Dec 20 09:09:40.618: INFO: Got endpoints: latency-svc-gdv47 [750.218003ms]
Dec 20 09:09:40.668: INFO: Got endpoints: latency-svc-mrxdx [748.605882ms]
Dec 20 09:09:40.719: INFO: Got endpoints: latency-svc-q8cqz [749.32277ms]
Dec 20 09:09:40.769: INFO: Got endpoints: latency-svc-kt88w [749.583681ms]
Dec 20 09:09:40.818: INFO: Got endpoints: latency-svc-62d2s [750.454438ms]
Dec 20 09:09:40.875: INFO: Got endpoints: latency-svc-whhhb [756.493582ms]
Dec 20 09:09:40.918: INFO: Got endpoints: latency-svc-vjhj5 [749.794555ms]
Dec 20 09:09:40.969: INFO: Got endpoints: latency-svc-8449m [749.831717ms]
Dec 20 09:09:40.969: INFO: Latencies: [13.737785ms 25.083924ms 32.184842ms 38.855006ms 46.628222ms 55.339962ms 63.559464ms 71.023532ms 82.573145ms 90.290107ms 97.264649ms 112.904568ms 114.229898ms 114.75767ms 116.283452ms 120.460324ms 123.223487ms 124.064582ms 124.119556ms 125.530681ms 125.919331ms 126.532491ms 127.052388ms 127.485275ms 127.52117ms 127.643178ms 128.857109ms 129.629565ms 129.917985ms 130.564802ms 130.981438ms 131.698404ms 132.282506ms 134.186082ms 135.559833ms 161.207362ms 206.359015ms 249.991589ms 292.433921ms 338.278423ms 376.998575ms 421.862804ms 464.747203ms 505.476484ms 538.927909ms 573.718984ms 616.753141ms 659.262455ms 703.696346ms 744.165021ms 744.53744ms 746.93021ms 747.645979ms 747.906606ms 748.329705ms 748.605882ms 748.877656ms 748.897067ms 749.125382ms 749.242674ms 749.244074ms 749.244987ms 749.266069ms 749.304871ms 749.309926ms 749.315489ms 749.32277ms 749.324766ms 749.338233ms 749.352238ms 749.35466ms 749.363919ms 749.374581ms 749.407845ms 749.408316ms 749.492631ms 749.499823ms 749.512187ms 749.533198ms 749.534519ms 749.539917ms 749.571997ms 749.579015ms 749.579907ms 749.583681ms 749.590589ms 749.596724ms 749.598773ms 749.629181ms 749.657733ms 749.669723ms 749.676054ms 749.691077ms 749.698435ms 749.705585ms 749.710114ms 749.711367ms 749.718066ms 749.718933ms 749.721629ms 749.723685ms 749.737389ms 749.737461ms 749.741319ms 749.745132ms 749.751579ms 749.758209ms 749.78164ms 749.783128ms 749.791903ms 749.794555ms 749.794886ms 749.809506ms 749.81192ms 749.819764ms 749.831717ms 749.834636ms 749.849134ms 749.852683ms 749.864901ms 749.896773ms 749.903155ms 749.912074ms 749.93064ms 749.931184ms 749.946992ms 749.947851ms 749.948295ms 749.961477ms 749.981844ms 749.989663ms 749.996035ms 750.003375ms 750.004871ms 750.010572ms 750.010739ms 750.017072ms 750.025458ms 750.039786ms 750.05542ms 750.064853ms 750.065221ms 750.070623ms 750.072266ms 750.080543ms 750.094036ms 750.108188ms 750.12026ms 750.134718ms 750.137981ms 750.148335ms 750.152924ms 750.184894ms 750.198144ms 750.213542ms 750.218003ms 750.220494ms 750.224237ms 750.23275ms 750.234973ms 750.267712ms 750.271969ms 750.272199ms 750.280181ms 750.313984ms 750.321328ms 750.330628ms 750.369254ms 750.37995ms 750.389563ms 750.417341ms 750.424256ms 750.426463ms 750.454438ms 750.471764ms 750.483326ms 750.486729ms 750.495679ms 750.501797ms 750.507502ms 750.521687ms 750.555256ms 750.560133ms 750.574904ms 750.663366ms 750.674745ms 750.686659ms 750.702192ms 750.738496ms 750.783972ms 750.794509ms 750.9686ms 750.97638ms 750.981237ms 750.985995ms 751.06927ms 751.75053ms 752.587766ms 756.493582ms 756.568458ms]
Dec 20 09:09:40.969: INFO: 50 %ile: 749.723685ms
Dec 20 09:09:40.969: INFO: 90 %ile: 750.521687ms
Dec 20 09:09:40.969: INFO: 99 %ile: 756.493582ms
Dec 20 09:09:40.969: INFO: Total sample count: 200
[AfterEach] [sig-network] Service endpoints latency
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:09:40.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svc-latency-7516" for this suite.
Dec 20 09:09:52.985: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:09:53.069: INFO: namespace svc-latency-7516 deletion completed in 12.094467102s

• [SLOW TEST:27.959 seconds]
[sig-network] Service endpoints latency
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should not be very high  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:09:53.069: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1506
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Pod that fits quota
STEP: Ensuring ResourceQuota status captures the pod usage
STEP: Not allowing a pod to be created that exceeds remaining quota
STEP: Not allowing a pod to be created that exceeds remaining quota(validation on extended resources)
STEP: Ensuring a pod cannot update its resource requirements
STEP: Ensuring attempts to update pod resource requirements did not change quota usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:10:06.253: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1506" for this suite.
Dec 20 09:10:12.268: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:10:12.365: INFO: namespace resourcequota-1506 deletion completed in 6.107711531s

• [SLOW TEST:19.296 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a pod. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Guestbook application 
  should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:10:12.365: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5447
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create and stop a working application  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating all guestbook components
Dec 20 09:10:12.496: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-slave
  labels:
    app: redis
    role: slave
    tier: backend
spec:
  ports:
  - port: 6379
  selector:
    app: redis
    role: slave
    tier: backend

Dec 20 09:10:12.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 create -f - --namespace=kubectl-5447'
Dec 20 09:10:12.777: INFO: stderr: ""
Dec 20 09:10:12.777: INFO: stdout: "service/redis-slave created\n"
Dec 20 09:10:12.777: INFO: apiVersion: v1
kind: Service
metadata:
  name: redis-master
  labels:
    app: redis
    role: master
    tier: backend
spec:
  ports:
  - port: 6379
    targetPort: 6379
  selector:
    app: redis
    role: master
    tier: backend

Dec 20 09:10:12.777: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 create -f - --namespace=kubectl-5447'
Dec 20 09:10:12.988: INFO: stderr: ""
Dec 20 09:10:12.988: INFO: stdout: "service/redis-master created\n"
Dec 20 09:10:12.988: INFO: apiVersion: v1
kind: Service
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # if your cluster supports it, uncomment the following to automatically create
  # an external load-balanced IP for the frontend service.
  # type: LoadBalancer
  ports:
  - port: 80
  selector:
    app: guestbook
    tier: frontend

Dec 20 09:10:12.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 create -f - --namespace=kubectl-5447'
Dec 20 09:10:13.145: INFO: stderr: ""
Dec 20 09:10:13.145: INFO: stdout: "service/frontend created\n"
Dec 20 09:10:13.146: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: frontend
spec:
  replicas: 3
  selector:
    matchLabels:
      app: guestbook
      tier: frontend
  template:
    metadata:
      labels:
        app: guestbook
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google-samples/gb-frontend:v6
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access environment variables to find service host
          # info, comment out the 'value: dns' line above, and uncomment the
          # line below:
          # value: env
        ports:
        - containerPort: 80

Dec 20 09:10:13.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 create -f - --namespace=kubectl-5447'
Dec 20 09:10:13.385: INFO: stderr: ""
Dec 20 09:10:13.385: INFO: stdout: "deployment.apps/frontend created\n"
Dec 20 09:10:13.385: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
      role: master
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: master
        tier: backend
    spec:
      containers:
      - name: master
        image: docker.io/library/redis:5.0.5-alpine
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        ports:
        - containerPort: 6379

Dec 20 09:10:13.385: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 create -f - --namespace=kubectl-5447'
Dec 20 09:10:13.541: INFO: stderr: ""
Dec 20 09:10:13.542: INFO: stdout: "deployment.apps/redis-master created\n"
Dec 20 09:10:13.542: INFO: apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-slave
spec:
  replicas: 2
  selector:
    matchLabels:
      app: redis
      role: slave
      tier: backend
  template:
    metadata:
      labels:
        app: redis
        role: slave
        tier: backend
    spec:
      containers:
      - name: slave
        image: docker.io/library/redis:5.0.5-alpine
        # We are only implementing the dns option of:
        # https://github.com/kubernetes/examples/blob/97c7ed0eb6555a4b667d2877f965d392e00abc45/guestbook/redis-slave/run.sh
        command: [ "redis-server", "--slaveof", "redis-master", "6379" ]
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
        env:
        - name: GET_HOSTS_FROM
          value: dns
          # If your cluster config does not include a dns service, then to
          # instead access an environment variable to find the master
          # service's host, comment out the 'value: dns' line above, and
          # uncomment the line below:
          # value: env
        ports:
        - containerPort: 6379

Dec 20 09:10:13.542: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 create -f - --namespace=kubectl-5447'
Dec 20 09:10:13.768: INFO: stderr: ""
Dec 20 09:10:13.768: INFO: stdout: "deployment.apps/redis-slave created\n"
STEP: validating guestbook app
Dec 20 09:10:13.768: INFO: Waiting for all frontend pods to be Running.
Dec 20 09:10:38.820: INFO: Waiting for frontend to serve content.
Dec 20 09:10:38.837: INFO: Trying to add a new entry to the guestbook.
Dec 20 09:10:38.850: INFO: Verifying that added entry can be retrieved.
STEP: using delete to clean up resources
Dec 20 09:10:38.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 delete --grace-period=0 --force -f - --namespace=kubectl-5447'
Dec 20 09:10:38.970: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 20 09:10:38.970: INFO: stdout: "service \"redis-slave\" force deleted\n"
STEP: using delete to clean up resources
Dec 20 09:10:38.970: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 delete --grace-period=0 --force -f - --namespace=kubectl-5447'
Dec 20 09:10:39.070: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 20 09:10:39.070: INFO: stdout: "service \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 20 09:10:39.071: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 delete --grace-period=0 --force -f - --namespace=kubectl-5447'
Dec 20 09:10:39.177: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 20 09:10:39.177: INFO: stdout: "service \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 20 09:10:39.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 delete --grace-period=0 --force -f - --namespace=kubectl-5447'
Dec 20 09:10:39.283: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 20 09:10:39.283: INFO: stdout: "deployment.apps \"frontend\" force deleted\n"
STEP: using delete to clean up resources
Dec 20 09:10:39.283: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 delete --grace-period=0 --force -f - --namespace=kubectl-5447'
Dec 20 09:10:39.382: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 20 09:10:39.382: INFO: stdout: "deployment.apps \"redis-master\" force deleted\n"
STEP: using delete to clean up resources
Dec 20 09:10:39.382: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 delete --grace-period=0 --force -f - --namespace=kubectl-5447'
Dec 20 09:10:39.469: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 20 09:10:39.469: INFO: stdout: "deployment.apps \"redis-slave\" force deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:10:39.469: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5447" for this suite.
Dec 20 09:10:45.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:10:45.582: INFO: namespace kubectl-5447 deletion completed in 6.106889936s

• [SLOW TEST:33.216 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Guestbook application
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:333
    should create and stop a working application  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[k8s.io] Pods 
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:10:45.582: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2676
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating pod
Dec 20 09:10:49.739: INFO: Pod pod-hostip-5049a18e-2461-4aab-9954-3db107c5e3cb has hostIP: 10.84.149.223
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:10:49.739: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2676" for this suite.
Dec 20 09:11:17.753: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:11:17.839: INFO: namespace pods-2676 deletion completed in 28.096056105s

• [SLOW TEST:32.257 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should get a host IP [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:11:17.839: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-4393
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-4393
[It] should have a working scale subresource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating statefulset ss in namespace statefulset-4393
Dec 20 09:11:17.983: INFO: Found 0 stateful pods, waiting for 1
Dec 20 09:11:27.988: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Pending - Ready=false
Dec 20 09:11:37.987: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: getting scale subresource
STEP: updating a scale subresource
STEP: verifying the statefulset Spec.Replicas was modified
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 20 09:11:38.005: INFO: Deleting all statefulset in ns statefulset-4393
Dec 20 09:11:38.007: INFO: Scaling statefulset ss to 0
Dec 20 09:11:48.026: INFO: Waiting for statefulset status.replicas updated to 0
Dec 20 09:11:48.030: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:11:48.042: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-4393" for this suite.
Dec 20 09:11:54.056: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:11:54.155: INFO: namespace statefulset-4393 deletion completed in 6.109845054s

• [SLOW TEST:36.316 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should have a working scale subresource [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:11:54.156: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7221
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-2c8802d8-3d51-434e-a580-161cb33c26a4
STEP: Creating a pod to test consume secrets
Dec 20 09:11:54.303: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-455717d3-7a0a-4dba-8878-7b8e4802ff5e" in namespace "projected-7221" to be "success or failure"
Dec 20 09:11:54.306: INFO: Pod "pod-projected-secrets-455717d3-7a0a-4dba-8878-7b8e4802ff5e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.468899ms
Dec 20 09:11:56.309: INFO: Pod "pod-projected-secrets-455717d3-7a0a-4dba-8878-7b8e4802ff5e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006134023s
Dec 20 09:11:58.314: INFO: Pod "pod-projected-secrets-455717d3-7a0a-4dba-8878-7b8e4802ff5e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010503337s
STEP: Saw pod success
Dec 20 09:11:58.314: INFO: Pod "pod-projected-secrets-455717d3-7a0a-4dba-8878-7b8e4802ff5e" satisfied condition "success or failure"
Dec 20 09:11:58.317: INFO: Trying to get logs from node caasp-worker-th-before-0 pod pod-projected-secrets-455717d3-7a0a-4dba-8878-7b8e4802ff5e container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 20 09:11:58.349: INFO: Waiting for pod pod-projected-secrets-455717d3-7a0a-4dba-8878-7b8e4802ff5e to disappear
Dec 20 09:11:58.351: INFO: Pod pod-projected-secrets-455717d3-7a0a-4dba-8878-7b8e4802ff5e no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:11:58.351: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7221" for this suite.
Dec 20 09:12:04.365: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:12:04.455: INFO: namespace projected-7221 deletion completed in 6.10064309s

• [SLOW TEST:10.299 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:12:04.455: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-960
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 20 09:12:04.595: INFO: Waiting up to 5m0s for pod "downward-api-6afd502f-2eb5-4738-a423-86c0cdb41037" in namespace "downward-api-960" to be "success or failure"
Dec 20 09:12:04.599: INFO: Pod "downward-api-6afd502f-2eb5-4738-a423-86c0cdb41037": Phase="Pending", Reason="", readiness=false. Elapsed: 3.546591ms
Dec 20 09:12:06.603: INFO: Pod "downward-api-6afd502f-2eb5-4738-a423-86c0cdb41037": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007473965s
Dec 20 09:12:08.608: INFO: Pod "downward-api-6afd502f-2eb5-4738-a423-86c0cdb41037": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012355747s
STEP: Saw pod success
Dec 20 09:12:08.608: INFO: Pod "downward-api-6afd502f-2eb5-4738-a423-86c0cdb41037" satisfied condition "success or failure"
Dec 20 09:12:08.611: INFO: Trying to get logs from node caasp-worker-th-before-0 pod downward-api-6afd502f-2eb5-4738-a423-86c0cdb41037 container dapi-container: <nil>
STEP: delete the pod
Dec 20 09:12:08.626: INFO: Waiting for pod downward-api-6afd502f-2eb5-4738-a423-86c0cdb41037 to disappear
Dec 20 09:12:08.628: INFO: Pod downward-api-6afd502f-2eb5-4738-a423-86c0cdb41037 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:12:08.628: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-960" for this suite.
Dec 20 09:12:14.643: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:12:14.735: INFO: namespace downward-api-960 deletion completed in 6.102003125s

• [SLOW TEST:10.281 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-cli] Kubectl client Kubectl run --rm job 
  should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:12:14.736: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-3603
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create a job from an image, then delete the job  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: executing a command with run --rm and attach with stdin
Dec 20 09:12:14.866: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 --namespace=kubectl-3603 run e2e-test-rm-busybox-job --image=docker.io/library/busybox:1.29 --rm=true --generator=job/v1 --restart=OnFailure --attach=true --stdin -- sh -c cat && echo 'stdin closed''
Dec 20 09:12:22.954: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\nIf you don't see a command prompt, try pressing enter.\n"
Dec 20 09:12:22.954: INFO: stdout: "abcd1234stdin closed\njob.batch \"e2e-test-rm-busybox-job\" deleted\n"
STEP: verifying the job e2e-test-rm-busybox-job was deleted
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:12:24.960: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-3603" for this suite.
Dec 20 09:12:38.984: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:12:39.077: INFO: namespace kubectl-3603 deletion completed in 14.106096466s

• [SLOW TEST:24.342 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run --rm job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1751
    should create a job from an image, then delete the job  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] Deployment 
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:12:39.077: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-61
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 09:12:39.212: INFO: Creating replica set "test-rolling-update-controller" (going to be adopted)
Dec 20 09:12:39.221: INFO: Pod name sample-pod: Found 0 pods out of 1
Dec 20 09:12:44.226: INFO: Pod name sample-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 20 09:12:44.226: INFO: Creating deployment "test-rolling-update-deployment"
Dec 20 09:12:44.231: INFO: Ensuring deployment "test-rolling-update-deployment" gets the next revision from the one the adopted replica set "test-rolling-update-controller" has
Dec 20 09:12:44.237: INFO: new replicaset for deployment "test-rolling-update-deployment" is yet to be created
Dec 20 09:12:46.244: INFO: Ensuring status for deployment "test-rolling-update-deployment" is the expected
Dec 20 09:12:46.246: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429965, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429965, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429965, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429965, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 09:12:48.251: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429965, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429965, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429965, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429965, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 09:12:50.250: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429965, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429965, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429965, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429965, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 09:12:52.250: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:2, UpdatedReplicas:1, ReadyReplicas:1, AvailableReplicas:1, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429965, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429965, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasAvailable", Message:"Deployment has minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429965, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712429965, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-rolling-update-deployment-55d946486\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 09:12:54.250: INFO: Ensuring deployment "test-rolling-update-deployment" has one old replica set (the one it adopted)
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 20 09:12:54.260: INFO: Deployment "test-rolling-update-deployment":
&Deployment{ObjectMeta:{test-rolling-update-deployment  deployment-61 /apis/apps/v1/namespaces/deployment-61/deployments/test-rolling-update-deployment bbb7ea55-a891-4fee-83ae-4b7d764394ea 105684 1 2019-12-20 09:12:44 +0000 UTC <nil> <nil> map[name:sample-pod] map[deployment.kubernetes.io/revision:3546343826724305833] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003a14188 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:1,Replicas:1,UpdatedReplicas:1,AvailableReplicas:1,UnavailableReplicas:0,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-20 09:12:45 +0000 UTC,LastTransitionTime:2019-12-20 09:12:45 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:NewReplicaSetAvailable,Message:ReplicaSet "test-rolling-update-deployment-55d946486" has successfully progressed.,LastUpdateTime:2019-12-20 09:12:54 +0000 UTC,LastTransitionTime:2019-12-20 09:12:45 +0000 UTC,},},ReadyReplicas:1,CollisionCount:nil,},}

Dec 20 09:12:54.263: INFO: New ReplicaSet "test-rolling-update-deployment-55d946486" of Deployment "test-rolling-update-deployment":
&ReplicaSet{ObjectMeta:{test-rolling-update-deployment-55d946486  deployment-61 /apis/apps/v1/namespaces/deployment-61/replicasets/test-rolling-update-deployment-55d946486 6021a7cc-99d0-4e97-95ab-6bc420e1826e 105673 1 2019-12-20 09:12:44 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305833] [{apps/v1 Deployment test-rolling-update-deployment bbb7ea55-a891-4fee-83ae-4b7d764394ea 0xc003a14670 0xc003a14671}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod-template-hash: 55d946486,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc003a146d8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 20 09:12:54.263: INFO: All old ReplicaSets of Deployment "test-rolling-update-deployment":
Dec 20 09:12:54.263: INFO: &ReplicaSet{ObjectMeta:{test-rolling-update-controller  deployment-61 /apis/apps/v1/namespaces/deployment-61/replicasets/test-rolling-update-controller d0fb4e34-fe2b-4d8b-b2b6-753947a279ff 105683 2 2019-12-20 09:12:39 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:2 deployment.kubernetes.io/revision:3546343826724305832] [{apps/v1 Deployment test-rolling-update-deployment bbb7ea55-a891-4fee-83ae-4b7d764394ea 0xc003a145a7 0xc003a145a8}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc003a14608 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 20 09:12:54.266: INFO: Pod "test-rolling-update-deployment-55d946486-z94v7" is available:
&Pod{ObjectMeta:{test-rolling-update-deployment-55d946486-z94v7 test-rolling-update-deployment-55d946486- deployment-61 /api/v1/namespaces/deployment-61/pods/test-rolling-update-deployment-55d946486-z94v7 7bd30f2f-39dc-48af-b172-2a80f3bf0354 105672 0 2019-12-20 09:12:44 +0000 UTC <nil> <nil> map[name:sample-pod pod-template-hash:55d946486] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-rolling-update-deployment-55d946486 6021a7cc-99d0-4e97-95ab-6bc420e1826e 0xc003a14b40 0xc003a14b41}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sj9v5,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sj9v5,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:redis,Image:docker.io/library/redis:5.0.5-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sj9v5,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:12:45 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:12:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:12:53 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:12:44 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.84.149.226,PodIP:10.244.6.226,StartTime:2019-12-20 09:12:45 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:redis,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-20 09:12:53 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/redis:5.0.5-alpine,ImageID:docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858,ContainerID:cri-o://286803519ebd56a70528f4af465dbc6a56b4b1ed63c08c58241e97e4d3ba40be,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.6.226,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:12:54.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-61" for this suite.
Dec 20 09:13:00.282: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:13:00.378: INFO: namespace deployment-61 deletion completed in 6.108128407s

• [SLOW TEST:21.301 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RollingUpdateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:13:00.379: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9105
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 09:13:00.528: INFO: Creating daemon "daemon-set" with a node selector
STEP: Initially, daemon pods should not be running on any nodes.
Dec 20 09:13:00.534: INFO: Number of nodes with available pods: 0
Dec 20 09:13:00.534: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Change node label to blue, check that daemon pod is launched.
Dec 20 09:13:00.546: INFO: Number of nodes with available pods: 0
Dec 20 09:13:00.546: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 09:13:01.550: INFO: Number of nodes with available pods: 0
Dec 20 09:13:01.550: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 09:13:02.551: INFO: Number of nodes with available pods: 0
Dec 20 09:13:02.551: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 09:13:03.550: INFO: Number of nodes with available pods: 1
Dec 20 09:13:03.550: INFO: Number of running nodes: 1, number of available pods: 1
STEP: Update the node label to green, and wait for daemons to be unscheduled
Dec 20 09:13:03.562: INFO: Number of nodes with available pods: 1
Dec 20 09:13:03.562: INFO: Number of running nodes: 0, number of available pods: 1
Dec 20 09:13:04.566: INFO: Number of nodes with available pods: 0
Dec 20 09:13:04.566: INFO: Number of running nodes: 0, number of available pods: 0
STEP: Update DaemonSet node selector to green, and change its update strategy to RollingUpdate
Dec 20 09:13:04.597: INFO: Number of nodes with available pods: 0
Dec 20 09:13:04.597: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 09:13:05.601: INFO: Number of nodes with available pods: 0
Dec 20 09:13:05.601: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 09:13:06.603: INFO: Number of nodes with available pods: 0
Dec 20 09:13:06.603: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 09:13:07.602: INFO: Number of nodes with available pods: 0
Dec 20 09:13:07.602: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 09:13:08.601: INFO: Number of nodes with available pods: 0
Dec 20 09:13:08.601: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 09:13:09.601: INFO: Number of nodes with available pods: 0
Dec 20 09:13:09.601: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 09:13:10.602: INFO: Number of nodes with available pods: 0
Dec 20 09:13:10.602: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 09:13:11.601: INFO: Number of nodes with available pods: 0
Dec 20 09:13:11.601: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 09:13:12.601: INFO: Number of nodes with available pods: 0
Dec 20 09:13:12.601: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 09:13:13.601: INFO: Number of nodes with available pods: 1
Dec 20 09:13:13.601: INFO: Number of running nodes: 1, number of available pods: 1
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9105, will wait for the garbage collector to delete the pods
Dec 20 09:13:13.667: INFO: Deleting DaemonSet.extensions daemon-set took: 6.874425ms
Dec 20 09:13:14.067: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.298382ms
Dec 20 09:13:21.070: INFO: Number of nodes with available pods: 0
Dec 20 09:13:21.070: INFO: Number of running nodes: 0, number of available pods: 0
Dec 20 09:13:21.076: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9105/daemonsets","resourceVersion":"105861"},"items":null}

Dec 20 09:13:21.079: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9105/pods","resourceVersion":"105861"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:13:21.097: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9105" for this suite.
Dec 20 09:13:27.111: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:13:27.201: INFO: namespace daemonsets-9105 deletion completed in 6.10075165s

• [SLOW TEST:26.822 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop complex daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:13:27.202: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-596
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-a97082ae-d9ff-47f0-ba67-12c0418ff763 in namespace container-probe-596
Dec 20 09:13:35.355: INFO: Started pod busybox-a97082ae-d9ff-47f0-ba67-12c0418ff763 in namespace container-probe-596
STEP: checking the pod's current state and verifying that restartCount is present
Dec 20 09:13:35.358: INFO: Initial restart count of pod busybox-a97082ae-d9ff-47f0-ba67-12c0418ff763 is 0
Dec 20 09:14:25.461: INFO: Restart count of pod container-probe-596/busybox-a97082ae-d9ff-47f0-ba67-12c0418ff763 is now 1 (50.103447413s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:14:25.471: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-596" for this suite.
Dec 20 09:14:31.485: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:14:31.571: INFO: namespace container-probe-596 deletion completed in 6.095672647s

• [SLOW TEST:64.370 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-cli] Kubectl client Kubectl run pod 
  should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:14:31.571: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-6108
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1668
[It] should create a pod from an image when restart is Never  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 20 09:14:31.701: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 run e2e-test-httpd-pod --restart=Never --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-6108'
Dec 20 09:14:31.815: INFO: stderr: ""
Dec 20 09:14:31.815: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod was created
[AfterEach] Kubectl run pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1673
Dec 20 09:14:31.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 delete pods e2e-test-httpd-pod --namespace=kubectl-6108'
Dec 20 09:14:41.011: INFO: stderr: ""
Dec 20 09:14:41.011: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:14:41.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-6108" for this suite.
Dec 20 09:14:47.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:14:47.114: INFO: namespace kubectl-6108 deletion completed in 6.099217759s

• [SLOW TEST:15.543 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1664
    should create a pod from an image when restart is Never  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:14:47.114: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-9077
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 20 09:14:47.267: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:47.267: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:47.269: INFO: Number of nodes with available pods: 0
Dec 20 09:14:47.269: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 09:14:48.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:48.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:48.277: INFO: Number of nodes with available pods: 0
Dec 20 09:14:48.277: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 09:14:49.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:49.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:49.277: INFO: Number of nodes with available pods: 1
Dec 20 09:14:49.277: INFO: Node caasp-worker-th-before-3 is running more than one daemon pod
Dec 20 09:14:50.275: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:50.275: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:50.278: INFO: Number of nodes with available pods: 2
Dec 20 09:14:50.278: INFO: Node caasp-worker-th-before-4 is running more than one daemon pod
Dec 20 09:14:51.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:51.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:51.277: INFO: Number of nodes with available pods: 2
Dec 20 09:14:51.277: INFO: Node caasp-worker-th-before-4 is running more than one daemon pod
Dec 20 09:14:52.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:52.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:52.277: INFO: Number of nodes with available pods: 2
Dec 20 09:14:52.277: INFO: Node caasp-worker-th-before-4 is running more than one daemon pod
Dec 20 09:14:53.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:53.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:53.278: INFO: Number of nodes with available pods: 2
Dec 20 09:14:53.278: INFO: Node caasp-worker-th-before-4 is running more than one daemon pod
Dec 20 09:14:54.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:54.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:54.278: INFO: Number of nodes with available pods: 2
Dec 20 09:14:54.278: INFO: Node caasp-worker-th-before-4 is running more than one daemon pod
Dec 20 09:14:55.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:55.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:55.277: INFO: Number of nodes with available pods: 2
Dec 20 09:14:55.277: INFO: Node caasp-worker-th-before-4 is running more than one daemon pod
Dec 20 09:14:56.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:56.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:56.278: INFO: Number of nodes with available pods: 2
Dec 20 09:14:56.278: INFO: Node caasp-worker-th-before-4 is running more than one daemon pod
Dec 20 09:14:57.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:57.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:57.277: INFO: Number of nodes with available pods: 2
Dec 20 09:14:57.277: INFO: Node caasp-worker-th-before-4 is running more than one daemon pod
Dec 20 09:14:58.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:58.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:58.277: INFO: Number of nodes with available pods: 2
Dec 20 09:14:58.277: INFO: Node caasp-worker-th-before-4 is running more than one daemon pod
Dec 20 09:14:59.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:59.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:59.277: INFO: Number of nodes with available pods: 3
Dec 20 09:14:59.277: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Set a daemon pod's phase to 'Failed', check that the daemon pod is revived.
Dec 20 09:14:59.290: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:59.290: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:14:59.293: INFO: Number of nodes with available pods: 2
Dec 20 09:14:59.293: INFO: Node caasp-worker-th-before-4 is running more than one daemon pod
Dec 20 09:15:00.298: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:15:00.298: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:15:00.301: INFO: Number of nodes with available pods: 2
Dec 20 09:15:00.301: INFO: Node caasp-worker-th-before-4 is running more than one daemon pod
Dec 20 09:15:01.298: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:15:01.298: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:15:01.302: INFO: Number of nodes with available pods: 2
Dec 20 09:15:01.302: INFO: Node caasp-worker-th-before-4 is running more than one daemon pod
Dec 20 09:15:02.298: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:15:02.298: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:15:02.301: INFO: Number of nodes with available pods: 2
Dec 20 09:15:02.301: INFO: Node caasp-worker-th-before-4 is running more than one daemon pod
Dec 20 09:15:03.300: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:15:03.300: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:15:03.305: INFO: Number of nodes with available pods: 3
Dec 20 09:15:03.305: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Wait for the failed daemon pod to be completely deleted.
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-9077, will wait for the garbage collector to delete the pods
Dec 20 09:15:03.371: INFO: Deleting DaemonSet.extensions daemon-set took: 7.570669ms
Dec 20 09:15:05.571: INFO: Terminating DaemonSet.extensions daemon-set pods took: 2.200324726s
Dec 20 09:15:15.674: INFO: Number of nodes with available pods: 0
Dec 20 09:15:15.674: INFO: Number of running nodes: 0, number of available pods: 0
Dec 20 09:15:15.677: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-9077/daemonsets","resourceVersion":"106395"},"items":null}

Dec 20 09:15:15.679: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-9077/pods","resourceVersion":"106395"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:15:15.690: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-9077" for this suite.
Dec 20 09:15:21.702: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:15:21.794: INFO: namespace daemonsets-9077 deletion completed in 6.100697237s

• [SLOW TEST:34.680 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should retry creating failed daemon pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl version 
  should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:15:21.794: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1760
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check is all data is printed  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 09:15:21.923: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 version'
Dec 20 09:15:22.018: INFO: stderr: ""
Dec 20 09:15:22.018: INFO: stdout: "Client Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.2\", GitCommit:\"c97fe5036ef3df2967d086711e6c0c405941e14b\", GitTreeState:\"clean\", BuildDate:\"2019-10-15T19:18:23Z\", GoVersion:\"go1.12.10\", Compiler:\"gc\", Platform:\"linux/amd64\"}\nServer Version: version.Info{Major:\"1\", Minor:\"16\", GitVersion:\"v1.16.2\", GitCommit:\"c97fe5036ef3df2967d086711e6c0c405941e14b\", GitTreeState:\"clean\", BuildDate:\"2019-11-30T12:00:00Z\", GoVersion:\"go1.12.12\", Compiler:\"gc\", Platform:\"linux/amd64\"}\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:15:22.018: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1760" for this suite.
Dec 20 09:15:28.033: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:15:28.121: INFO: namespace kubectl-1760 deletion completed in 6.098177608s

• [SLOW TEST:6.327 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl version
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1380
    should check is all data is printed  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:15:28.122: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-2910
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on node default medium
Dec 20 09:15:28.259: INFO: Waiting up to 5m0s for pod "pod-826fe7dd-0092-43f9-a388-d2103bb7edc2" in namespace "emptydir-2910" to be "success or failure"
Dec 20 09:15:28.261: INFO: Pod "pod-826fe7dd-0092-43f9-a388-d2103bb7edc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.115046ms
Dec 20 09:15:30.264: INFO: Pod "pod-826fe7dd-0092-43f9-a388-d2103bb7edc2": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00549594s
Dec 20 09:15:32.268: INFO: Pod "pod-826fe7dd-0092-43f9-a388-d2103bb7edc2": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009040325s
STEP: Saw pod success
Dec 20 09:15:32.268: INFO: Pod "pod-826fe7dd-0092-43f9-a388-d2103bb7edc2" satisfied condition "success or failure"
Dec 20 09:15:32.271: INFO: Trying to get logs from node caasp-worker-th-before-0 pod pod-826fe7dd-0092-43f9-a388-d2103bb7edc2 container test-container: <nil>
STEP: delete the pod
Dec 20 09:15:32.297: INFO: Waiting for pod pod-826fe7dd-0092-43f9-a388-d2103bb7edc2 to disappear
Dec 20 09:15:32.299: INFO: Pod pod-826fe7dd-0092-43f9-a388-d2103bb7edc2 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:15:32.299: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-2910" for this suite.
Dec 20 09:15:38.312: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:15:38.406: INFO: namespace emptydir-2910 deletion completed in 6.103950622s

• [SLOW TEST:10.284 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:15:38.407: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-2901
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-a0a84896-dfc1-4bec-b5fe-1f6b500fd715
STEP: Creating a pod to test consume secrets
Dec 20 09:15:38.547: INFO: Waiting up to 5m0s for pod "pod-secrets-b53b7b3b-3940-415e-8b06-c391991ebdd3" in namespace "secrets-2901" to be "success or failure"
Dec 20 09:15:38.549: INFO: Pod "pod-secrets-b53b7b3b-3940-415e-8b06-c391991ebdd3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.019316ms
Dec 20 09:15:40.553: INFO: Pod "pod-secrets-b53b7b3b-3940-415e-8b06-c391991ebdd3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006025087s
Dec 20 09:15:42.557: INFO: Pod "pod-secrets-b53b7b3b-3940-415e-8b06-c391991ebdd3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010305551s
STEP: Saw pod success
Dec 20 09:15:42.557: INFO: Pod "pod-secrets-b53b7b3b-3940-415e-8b06-c391991ebdd3" satisfied condition "success or failure"
Dec 20 09:15:42.561: INFO: Trying to get logs from node caasp-worker-th-before-4 pod pod-secrets-b53b7b3b-3940-415e-8b06-c391991ebdd3 container secret-volume-test: <nil>
STEP: delete the pod
Dec 20 09:15:42.588: INFO: Waiting for pod pod-secrets-b53b7b3b-3940-415e-8b06-c391991ebdd3 to disappear
Dec 20 09:15:42.591: INFO: Pod pod-secrets-b53b7b3b-3940-415e-8b06-c391991ebdd3 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:15:42.591: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-2901" for this suite.
Dec 20 09:15:48.608: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:15:48.697: INFO: namespace secrets-2901 deletion completed in 6.100486401s

• [SLOW TEST:10.290 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:15:48.697: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-150
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 20 09:15:50.153: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 20 09:15:52.162: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712430151, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712430151, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712430151, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712430151, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 09:15:54.166: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712430151, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712430151, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712430151, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712430151, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 09:15:56.166: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712430151, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712430151, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712430151, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712430151, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 09:15:58.167: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712430151, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712430151, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712430151, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712430151, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 20 09:16:01.176: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a webhook that server cannot talk to, with fail closed policy, via the AdmissionRegistration API
STEP: create a namespace for the webhook
STEP: create a configmap should be unconditionally rejected by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:16:01.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-150" for this suite.
Dec 20 09:16:07.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:16:07.402: INFO: namespace webhook-150 deletion completed in 6.105578039s
STEP: Destroying namespace "webhook-150-markers" for this suite.
Dec 20 09:16:13.413: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:16:13.510: INFO: namespace webhook-150-markers deletion completed in 6.107834529s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.827 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should unconditionally reject operations on fail closed webhook [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:16:13.525: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1390
STEP: Waiting for a default service account to be provisioned in namespace
[It] should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting a background goroutine to produce watch events
STEP: creating watches starting from each resource version of the events produced and verifying they all receive resource versions in the same order
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:16:18.281: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1390" for this suite.
Dec 20 09:16:24.434: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:16:24.529: INFO: namespace watch-1390 deletion completed in 6.197414683s

• [SLOW TEST:11.004 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should receive events on concurrent watches in same order [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Garbage collector 
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:16:24.530: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4547
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 09:16:24.678: INFO: pod1.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod3", UID:"4e39fe0a-83ea-4e55-80c8-476ae51d08e5", Controller:(*bool)(0xc0038a7c0a), BlockOwnerDeletion:(*bool)(0xc0038a7c0b)}}
Dec 20 09:16:24.684: INFO: pod2.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod1", UID:"94de41f9-5f0d-4b99-bcf3-d3cf0b94206c", Controller:(*bool)(0xc0037ce662), BlockOwnerDeletion:(*bool)(0xc0037ce663)}}
Dec 20 09:16:24.690: INFO: pod3.ObjectMeta.OwnerReferences=[]v1.OwnerReference{v1.OwnerReference{APIVersion:"v1", Kind:"Pod", Name:"pod2", UID:"47d3f100-383f-41b8-9e9b-940f59f01f5a", Controller:(*bool)(0xc00331c4ca), BlockOwnerDeletion:(*bool)(0xc00331c4cb)}}
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:16:29.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4547" for this suite.
Dec 20 09:16:35.713: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:16:35.813: INFO: namespace gc-4547 deletion completed in 6.112035681s

• [SLOW TEST:11.284 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be blocked by dependency circle [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-cli] Kubectl client Kubectl replace 
  should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:16:35.813: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2673
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl replace
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1704
[It] should update a single-container pod's image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 20 09:16:35.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 run e2e-test-httpd-pod --generator=run-pod/v1 --image=docker.io/library/httpd:2.4.38-alpine --labels=run=e2e-test-httpd-pod --namespace=kubectl-2673'
Dec 20 09:16:36.064: INFO: stderr: ""
Dec 20 09:16:36.064: INFO: stdout: "pod/e2e-test-httpd-pod created\n"
STEP: verifying the pod e2e-test-httpd-pod is running
STEP: verifying the pod e2e-test-httpd-pod was created
Dec 20 09:16:41.114: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pod e2e-test-httpd-pod --namespace=kubectl-2673 -o json'
Dec 20 09:16:41.207: INFO: stderr: ""
Dec 20 09:16:41.207: INFO: stdout: "{\n    \"apiVersion\": \"v1\",\n    \"kind\": \"Pod\",\n    \"metadata\": {\n        \"annotations\": {\n            \"kubernetes.io/psp\": \"e2e-test-privileged-psp\"\n        },\n        \"creationTimestamp\": \"2019-12-20T09:16:37Z\",\n        \"labels\": {\n            \"run\": \"e2e-test-httpd-pod\"\n        },\n        \"name\": \"e2e-test-httpd-pod\",\n        \"namespace\": \"kubectl-2673\",\n        \"resourceVersion\": \"107038\",\n        \"selfLink\": \"/api/v1/namespaces/kubectl-2673/pods/e2e-test-httpd-pod\",\n        \"uid\": \"234832f3-4eea-4f31-a8e8-ce2bf1777e34\"\n    },\n    \"spec\": {\n        \"containers\": [\n            {\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imagePullPolicy\": \"IfNotPresent\",\n                \"name\": \"e2e-test-httpd-pod\",\n                \"resources\": {},\n                \"terminationMessagePath\": \"/dev/termination-log\",\n                \"terminationMessagePolicy\": \"File\",\n                \"volumeMounts\": [\n                    {\n                        \"mountPath\": \"/var/run/secrets/kubernetes.io/serviceaccount\",\n                        \"name\": \"default-token-962ft\",\n                        \"readOnly\": true\n                    }\n                ]\n            }\n        ],\n        \"dnsPolicy\": \"ClusterFirst\",\n        \"enableServiceLinks\": true,\n        \"nodeName\": \"caasp-worker-th-before-3\",\n        \"priority\": 0,\n        \"restartPolicy\": \"Always\",\n        \"schedulerName\": \"default-scheduler\",\n        \"securityContext\": {},\n        \"serviceAccount\": \"default\",\n        \"serviceAccountName\": \"default\",\n        \"terminationGracePeriodSeconds\": 30,\n        \"tolerations\": [\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/not-ready\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            },\n            {\n                \"effect\": \"NoExecute\",\n                \"key\": \"node.kubernetes.io/unreachable\",\n                \"operator\": \"Exists\",\n                \"tolerationSeconds\": 300\n            }\n        ],\n        \"volumes\": [\n            {\n                \"name\": \"default-token-962ft\",\n                \"secret\": {\n                    \"defaultMode\": 420,\n                    \"secretName\": \"default-token-962ft\"\n                }\n            }\n        ]\n    },\n    \"status\": {\n        \"conditions\": [\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-20T09:16:36Z\",\n                \"status\": \"True\",\n                \"type\": \"Initialized\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-20T09:16:39Z\",\n                \"status\": \"True\",\n                \"type\": \"Ready\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-20T09:16:39Z\",\n                \"status\": \"True\",\n                \"type\": \"ContainersReady\"\n            },\n            {\n                \"lastProbeTime\": null,\n                \"lastTransitionTime\": \"2019-12-20T09:16:36Z\",\n                \"status\": \"True\",\n                \"type\": \"PodScheduled\"\n            }\n        ],\n        \"containerStatuses\": [\n            {\n                \"containerID\": \"cri-o://0efb11b5c645adccd4f8d7abf20447b9f8837ca40258e9734da1efe5bd25ce84\",\n                \"image\": \"docker.io/library/httpd:2.4.38-alpine\",\n                \"imageID\": \"docker.io/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4\",\n                \"lastState\": {},\n                \"name\": \"e2e-test-httpd-pod\",\n                \"ready\": true,\n                \"restartCount\": 0,\n                \"started\": true,\n                \"state\": {\n                    \"running\": {\n                        \"startedAt\": \"2019-12-20T09:16:38Z\"\n                    }\n                }\n            }\n        ],\n        \"hostIP\": \"10.84.149.226\",\n        \"phase\": \"Running\",\n        \"podIP\": \"10.244.6.56\",\n        \"podIPs\": [\n            {\n                \"ip\": \"10.244.6.56\"\n            }\n        ],\n        \"qosClass\": \"BestEffort\",\n        \"startTime\": \"2019-12-20T09:16:36Z\"\n    }\n}\n"
STEP: replace the image in the pod
Dec 20 09:16:41.208: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 replace -f - --namespace=kubectl-2673'
Dec 20 09:16:41.374: INFO: stderr: ""
Dec 20 09:16:41.374: INFO: stdout: "pod/e2e-test-httpd-pod replaced\n"
STEP: verifying the pod e2e-test-httpd-pod has the right image docker.io/library/busybox:1.29
[AfterEach] Kubectl replace
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1709
Dec 20 09:16:41.377: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 delete pods e2e-test-httpd-pod --namespace=kubectl-2673'
Dec 20 09:16:45.630: INFO: stderr: ""
Dec 20 09:16:45.630: INFO: stdout: "pod \"e2e-test-httpd-pod\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:16:45.630: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2673" for this suite.
Dec 20 09:16:51.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:16:51.745: INFO: namespace kubectl-2673 deletion completed in 6.109062714s

• [SLOW TEST:15.931 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl replace
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1700
    should update a single-container pod's image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:16:51.745: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-540
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 20 09:16:51.882: INFO: Waiting up to 5m0s for pod "pod-5764bf5e-5092-476f-b8dc-2ca7f990cfed" in namespace "emptydir-540" to be "success or failure"
Dec 20 09:16:51.884: INFO: Pod "pod-5764bf5e-5092-476f-b8dc-2ca7f990cfed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.472536ms
Dec 20 09:16:53.888: INFO: Pod "pod-5764bf5e-5092-476f-b8dc-2ca7f990cfed": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005869828s
Dec 20 09:16:55.892: INFO: Pod "pod-5764bf5e-5092-476f-b8dc-2ca7f990cfed": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010482956s
STEP: Saw pod success
Dec 20 09:16:55.892: INFO: Pod "pod-5764bf5e-5092-476f-b8dc-2ca7f990cfed" satisfied condition "success or failure"
Dec 20 09:16:55.895: INFO: Trying to get logs from node caasp-worker-th-before-4 pod pod-5764bf5e-5092-476f-b8dc-2ca7f990cfed container test-container: <nil>
STEP: delete the pod
Dec 20 09:16:55.912: INFO: Waiting for pod pod-5764bf5e-5092-476f-b8dc-2ca7f990cfed to disappear
Dec 20 09:16:55.915: INFO: Pod pod-5764bf5e-5092-476f-b8dc-2ca7f990cfed no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:16:55.915: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-540" for this suite.
Dec 20 09:17:01.928: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:17:02.017: INFO: namespace emptydir-540 deletion completed in 6.098737671s

• [SLOW TEST:10.273 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl cluster-info 
  should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:17:02.018: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1591
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if Kubernetes master services is included in cluster-info  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating cluster-info
Dec 20 09:17:02.150: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 cluster-info'
Dec 20 09:17:02.247: INFO: stderr: ""
Dec 20 09:17:02.247: INFO: stdout: "\x1b[0;32mKubernetes master\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443\x1b[0m\n\x1b[0;32mKubeDNS\x1b[0m is running at \x1b[0;33mhttps://10.96.0.1:443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\x1b[0m\n\nTo further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:17:02.248: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1591" for this suite.
Dec 20 09:17:08.263: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:17:08.354: INFO: namespace kubectl-1591 deletion completed in 6.101801162s

• [SLOW TEST:6.336 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl cluster-info
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:974
    should check if Kubernetes master services is included in cluster-info  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected configMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:17:08.354: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-5546
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-f10809a7-6dcf-4ede-bd99-25333cffbdab
STEP: Creating a pod to test consume configMaps
Dec 20 09:17:08.496: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-ebe21adb-4eb6-4a96-bc7b-b2f2180ab506" in namespace "projected-5546" to be "success or failure"
Dec 20 09:17:08.498: INFO: Pod "pod-projected-configmaps-ebe21adb-4eb6-4a96-bc7b-b2f2180ab506": Phase="Pending", Reason="", readiness=false. Elapsed: 2.471956ms
Dec 20 09:17:10.502: INFO: Pod "pod-projected-configmaps-ebe21adb-4eb6-4a96-bc7b-b2f2180ab506": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006629805s
Dec 20 09:17:12.506: INFO: Pod "pod-projected-configmaps-ebe21adb-4eb6-4a96-bc7b-b2f2180ab506": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010549033s
STEP: Saw pod success
Dec 20 09:17:12.506: INFO: Pod "pod-projected-configmaps-ebe21adb-4eb6-4a96-bc7b-b2f2180ab506" satisfied condition "success or failure"
Dec 20 09:17:12.509: INFO: Trying to get logs from node caasp-worker-th-before-4 pod pod-projected-configmaps-ebe21adb-4eb6-4a96-bc7b-b2f2180ab506 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 09:17:12.526: INFO: Waiting for pod pod-projected-configmaps-ebe21adb-4eb6-4a96-bc7b-b2f2180ab506 to disappear
Dec 20 09:17:12.529: INFO: Pod pod-projected-configmaps-ebe21adb-4eb6-4a96-bc7b-b2f2180ab506 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:17:12.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-5546" for this suite.
Dec 20 09:17:18.546: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:17:18.640: INFO: namespace projected-5546 deletion completed in 6.107157872s

• [SLOW TEST:10.287 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:17:18.641: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-835
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-835
STEP: changing the ExternalName service to type=NodePort
STEP: creating replication controller externalname-service in namespace services-835
I1220 09:17:18.799104      26 runners.go:184] Created replication controller with name: externalname-service, namespace: services-835, replica count: 2
I1220 09:17:21.849616      26 runners.go:184] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1220 09:17:24.849848      26 runners.go:184] externalname-service Pods: 2 out of 2 created, 1 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 20 09:17:27.850: INFO: Creating new exec pod
I1220 09:17:27.850107      26 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 20 09:17:32.869: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=services-835 execpodljlrm -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec 20 09:17:33.037: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 20 09:17:33.037: INFO: stdout: ""
Dec 20 09:17:33.038: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=services-835 execpodljlrm -- /bin/sh -x -c nc -zv -t -w 2 10.97.210.28 80'
Dec 20 09:17:33.202: INFO: stderr: "+ nc -zv -t -w 2 10.97.210.28 80\nConnection to 10.97.210.28 80 port [tcp/http] succeeded!\n"
Dec 20 09:17:33.202: INFO: stdout: ""
Dec 20 09:17:33.202: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=services-835 execpodljlrm -- /bin/sh -x -c nc -zv -t -w 2 10.84.149.223 30466'
Dec 20 09:17:33.373: INFO: stderr: "+ nc -zv -t -w 2 10.84.149.223 30466\nConnection to 10.84.149.223 30466 port [tcp/30466] succeeded!\n"
Dec 20 09:17:33.373: INFO: stdout: ""
Dec 20 09:17:33.373: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=services-835 execpodljlrm -- /bin/sh -x -c nc -zv -t -w 2 10.84.149.226 30466'
Dec 20 09:17:33.532: INFO: stderr: "+ nc -zv -t -w 2 10.84.149.226 30466\nConnection to 10.84.149.226 30466 port [tcp/30466] succeeded!\n"
Dec 20 09:17:33.532: INFO: stdout: ""
Dec 20 09:17:33.532: INFO: Cleaning up the ExternalName to NodePort test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:17:33.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-835" for this suite.
Dec 20 09:17:39.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:17:39.665: INFO: namespace services-835 deletion completed in 6.107403979s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:21.024 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to NodePort [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:17:39.665: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8764
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should create and stop a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec 20 09:17:39.799: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 create -f - --namespace=kubectl-8764'
Dec 20 09:17:39.958: INFO: stderr: ""
Dec 20 09:17:39.958: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 20 09:17:39.958: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8764'
Dec 20 09:17:40.052: INFO: stderr: ""
Dec 20 09:17:40.052: INFO: stdout: "update-demo-nautilus-l2xhp update-demo-nautilus-vr8kc "
Dec 20 09:17:40.052: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-l2xhp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8764'
Dec 20 09:17:40.142: INFO: stderr: ""
Dec 20 09:17:40.142: INFO: stdout: ""
Dec 20 09:17:40.142: INFO: update-demo-nautilus-l2xhp is created but not running
Dec 20 09:17:45.143: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8764'
Dec 20 09:17:45.242: INFO: stderr: ""
Dec 20 09:17:45.242: INFO: stdout: "update-demo-nautilus-l2xhp update-demo-nautilus-vr8kc "
Dec 20 09:17:45.242: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-l2xhp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8764'
Dec 20 09:17:45.326: INFO: stderr: ""
Dec 20 09:17:45.326: INFO: stdout: ""
Dec 20 09:17:45.326: INFO: update-demo-nautilus-l2xhp is created but not running
Dec 20 09:17:50.326: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-8764'
Dec 20 09:17:50.455: INFO: stderr: ""
Dec 20 09:17:50.455: INFO: stdout: "update-demo-nautilus-l2xhp update-demo-nautilus-vr8kc "
Dec 20 09:17:50.455: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-l2xhp -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8764'
Dec 20 09:17:50.569: INFO: stderr: ""
Dec 20 09:17:50.569: INFO: stdout: "true"
Dec 20 09:17:50.569: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-l2xhp -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8764'
Dec 20 09:17:50.684: INFO: stderr: ""
Dec 20 09:17:50.684: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 20 09:17:50.684: INFO: validating pod update-demo-nautilus-l2xhp
Dec 20 09:17:50.690: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 20 09:17:50.690: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 20 09:17:50.690: INFO: update-demo-nautilus-l2xhp is verified up and running
Dec 20 09:17:50.690: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-vr8kc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-8764'
Dec 20 09:17:50.782: INFO: stderr: ""
Dec 20 09:17:50.782: INFO: stdout: "true"
Dec 20 09:17:50.782: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-vr8kc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-8764'
Dec 20 09:17:50.874: INFO: stderr: ""
Dec 20 09:17:50.874: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 20 09:17:50.874: INFO: validating pod update-demo-nautilus-vr8kc
Dec 20 09:17:50.880: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 20 09:17:50.880: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 20 09:17:50.880: INFO: update-demo-nautilus-vr8kc is verified up and running
STEP: using delete to clean up resources
Dec 20 09:17:50.880: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 delete --grace-period=0 --force -f - --namespace=kubectl-8764'
Dec 20 09:17:50.969: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 20 09:17:50.969: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 20 09:17:50.969: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-8764'
Dec 20 09:17:51.060: INFO: stderr: "No resources found in kubectl-8764 namespace.\n"
Dec 20 09:17:51.060: INFO: stdout: ""
Dec 20 09:17:51.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods -l name=update-demo --namespace=kubectl-8764 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 20 09:17:51.160: INFO: stderr: ""
Dec 20 09:17:51.160: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:17:51.160: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8764" for this suite.
Dec 20 09:18:03.175: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:18:03.271: INFO: namespace kubectl-8764 deletion completed in 12.106356771s

• [SLOW TEST:23.606 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should create and stop a replication controller  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-cli] Kubectl client Kubectl rolling-update 
  should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:18:03.271: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4021
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl rolling-update
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1499
[It] should support rolling-update to same image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 20 09:18:03.401: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-4021'
Dec 20 09:18:03.503: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 20 09:18:03.503: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
Dec 20 09:18:03.506: INFO: Waiting for rc e2e-test-httpd-rc to stabilize, generation 1 observed generation 1 spec.replicas 1 status.replicas 0
STEP: rolling-update to same image controller
Dec 20 09:18:03.509: INFO: scanned /root for discovery docs: <nil>
Dec 20 09:18:03.509: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 rolling-update e2e-test-httpd-rc --update-period=1s --image=docker.io/library/httpd:2.4.38-alpine --image-pull-policy=IfNotPresent --namespace=kubectl-4021'
Dec 20 09:18:19.285: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 20 09:18:19.285: INFO: stdout: "Created e2e-test-httpd-rc-7ca4e4391077699cdd4780d826dee7a1\nScaling up e2e-test-httpd-rc-7ca4e4391077699cdd4780d826dee7a1 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-7ca4e4391077699cdd4780d826dee7a1 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-7ca4e4391077699cdd4780d826dee7a1 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
Dec 20 09:18:19.285: INFO: stdout: "Created e2e-test-httpd-rc-7ca4e4391077699cdd4780d826dee7a1\nScaling up e2e-test-httpd-rc-7ca4e4391077699cdd4780d826dee7a1 from 0 to 1, scaling down e2e-test-httpd-rc from 1 to 0 (keep 1 pods available, don't exceed 2 pods)\nScaling e2e-test-httpd-rc-7ca4e4391077699cdd4780d826dee7a1 up to 1\nScaling e2e-test-httpd-rc down to 0\nUpdate succeeded. Deleting old controller: e2e-test-httpd-rc\nRenaming e2e-test-httpd-rc-7ca4e4391077699cdd4780d826dee7a1 to e2e-test-httpd-rc\nreplicationcontroller/e2e-test-httpd-rc rolling updated\n"
STEP: waiting for all containers in run=e2e-test-httpd-rc pods to come up.
Dec 20 09:18:19.285: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l run=e2e-test-httpd-rc --namespace=kubectl-4021'
Dec 20 09:18:19.383: INFO: stderr: ""
Dec 20 09:18:19.383: INFO: stdout: "e2e-test-httpd-rc-7ca4e4391077699cdd4780d826dee7a1-9xwnc "
Dec 20 09:18:19.383: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods e2e-test-httpd-rc-7ca4e4391077699cdd4780d826dee7a1-9xwnc -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "e2e-test-httpd-rc") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4021'
Dec 20 09:18:19.470: INFO: stderr: ""
Dec 20 09:18:19.470: INFO: stdout: "true"
Dec 20 09:18:19.470: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods e2e-test-httpd-rc-7ca4e4391077699cdd4780d826dee7a1-9xwnc -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "e2e-test-httpd-rc"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4021'
Dec 20 09:18:19.557: INFO: stderr: ""
Dec 20 09:18:19.557: INFO: stdout: "docker.io/library/httpd:2.4.38-alpine"
Dec 20 09:18:19.557: INFO: e2e-test-httpd-rc-7ca4e4391077699cdd4780d826dee7a1-9xwnc is verified up and running
[AfterEach] Kubectl rolling-update
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1505
Dec 20 09:18:19.557: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 delete rc e2e-test-httpd-rc --namespace=kubectl-4021'
Dec 20 09:18:19.654: INFO: stderr: ""
Dec 20 09:18:19.654: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:18:19.654: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4021" for this suite.
Dec 20 09:18:25.667: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:18:25.748: INFO: namespace kubectl-4021 deletion completed in 6.09100687s

• [SLOW TEST:22.477 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl rolling-update
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1494
    should support rolling-update to same image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:18:25.749: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9886
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 20 09:18:30.421: INFO: Successfully updated pod "annotationupdate69ab3546-ade0-4033-8a1c-dd6292695b13"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:18:32.435: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9886" for this suite.
Dec 20 09:18:44.452: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:18:44.548: INFO: namespace projected-9886 deletion completed in 12.108692474s

• [SLOW TEST:18.799 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:18:44.548: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-6961
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating replication controller my-hostname-basic-d1b56d07-cc07-4746-80d0-ccde420a7d43
Dec 20 09:18:44.690: INFO: Pod name my-hostname-basic-d1b56d07-cc07-4746-80d0-ccde420a7d43: Found 0 pods out of 1
Dec 20 09:18:49.695: INFO: Pod name my-hostname-basic-d1b56d07-cc07-4746-80d0-ccde420a7d43: Found 1 pods out of 1
Dec 20 09:18:49.695: INFO: Ensuring all pods for ReplicationController "my-hostname-basic-d1b56d07-cc07-4746-80d0-ccde420a7d43" are running
Dec 20 09:18:55.702: INFO: Pod "my-hostname-basic-d1b56d07-cc07-4746-80d0-ccde420a7d43-j8fzc" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-20 09:18:45 +0000 UTC Reason: Message:} {Type:Ready Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-20 09:18:45 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-d1b56d07-cc07-4746-80d0-ccde420a7d43]} {Type:ContainersReady Status:False LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-20 09:18:45 +0000 UTC Reason:ContainersNotReady Message:containers with unready status: [my-hostname-basic-d1b56d07-cc07-4746-80d0-ccde420a7d43]} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-20 09:18:44 +0000 UTC Reason: Message:}])
Dec 20 09:18:55.702: INFO: Trying to dial the pod
Dec 20 09:19:00.715: INFO: Controller my-hostname-basic-d1b56d07-cc07-4746-80d0-ccde420a7d43: Got expected result from replica 1 [my-hostname-basic-d1b56d07-cc07-4746-80d0-ccde420a7d43-j8fzc]: "my-hostname-basic-d1b56d07-cc07-4746-80d0-ccde420a7d43-j8fzc", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:19:00.715: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-6961" for this suite.
Dec 20 09:19:06.735: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:19:06.824: INFO: namespace replication-controller-6961 deletion completed in 6.103563404s

• [SLOW TEST:22.276 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:19:06.825: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3188
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-20f334a8-85f1-42eb-bf72-7ee683750ba3
STEP: Creating a pod to test consume secrets
Dec 20 09:19:06.965: INFO: Waiting up to 5m0s for pod "pod-secrets-60e488ac-a9b4-4bb2-b1df-0df9a21ee002" in namespace "secrets-3188" to be "success or failure"
Dec 20 09:19:06.968: INFO: Pod "pod-secrets-60e488ac-a9b4-4bb2-b1df-0df9a21ee002": Phase="Pending", Reason="", readiness=false. Elapsed: 3.133169ms
Dec 20 09:19:08.973: INFO: Pod "pod-secrets-60e488ac-a9b4-4bb2-b1df-0df9a21ee002": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007328517s
Dec 20 09:19:10.977: INFO: Pod "pod-secrets-60e488ac-a9b4-4bb2-b1df-0df9a21ee002": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011376293s
STEP: Saw pod success
Dec 20 09:19:10.977: INFO: Pod "pod-secrets-60e488ac-a9b4-4bb2-b1df-0df9a21ee002" satisfied condition "success or failure"
Dec 20 09:19:10.980: INFO: Trying to get logs from node caasp-worker-th-before-3 pod pod-secrets-60e488ac-a9b4-4bb2-b1df-0df9a21ee002 container secret-volume-test: <nil>
STEP: delete the pod
Dec 20 09:19:11.006: INFO: Waiting for pod pod-secrets-60e488ac-a9b4-4bb2-b1df-0df9a21ee002 to disappear
Dec 20 09:19:11.008: INFO: Pod pod-secrets-60e488ac-a9b4-4bb2-b1df-0df9a21ee002 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:19:11.008: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3188" for this suite.
Dec 20 09:19:17.022: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:19:17.114: INFO: namespace secrets-3188 deletion completed in 6.102410757s

• [SLOW TEST:10.290 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:19:17.114: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-2830
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 20 09:19:18.564: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 20 09:19:20.576: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712430359, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712430359, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712430359, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712430359, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 20 09:19:23.590: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 09:19:23.593: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Registering the custom resource webhook via the AdmissionRegistration API
STEP: Creating a custom resource that should be denied by the webhook
STEP: Creating a custom resource whose deletion would be denied by the webhook
STEP: Updating the custom resource with disallowed data should be denied
STEP: Deleting the custom resource should be denied
STEP: Remove the offending key and value from the custom resource data
STEP: Deleting the updated custom resource should be successful
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:19:24.226: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-2830" for this suite.
Dec 20 09:19:30.244: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:19:30.332: INFO: namespace webhook-2830 deletion completed in 6.100359214s
STEP: Destroying namespace "webhook-2830-markers" for this suite.
Dec 20 09:19:36.343: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:19:36.435: INFO: namespace webhook-2830-markers deletion completed in 6.102114449s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.332 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny custom resource creation, update and deletion [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:19:36.447: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4614
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc1
STEP: create the rc2
STEP: set half of pods created by rc simpletest-rc-to-be-deleted to have rc simpletest-rc-to-stay as owner as well
STEP: delete the rc simpletest-rc-to-be-deleted
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 20 09:19:46.639: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W1220 09:19:46.639349      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 20 09:19:46.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4614" for this suite.
Dec 20 09:19:52.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:19:52.743: INFO: namespace gc-4614 deletion completed in 6.099730212s

• [SLOW TEST:16.296 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:19:52.743: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-2467
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 20 09:19:52.872: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:19:56.832: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-2467" for this suite.
Dec 20 09:20:02.849: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:20:02.940: INFO: namespace init-container-2467 deletion completed in 6.102983964s

• [SLOW TEST:10.197 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:20:02.940: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-8693
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 09:20:03.075: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: client-side validation (kubectl create and apply) allows request with known and required properties
Dec 20 09:20:08.091: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 --namespace=crd-publish-openapi-8693 create -f -'
Dec 20 09:20:08.365: INFO: stderr: ""
Dec 20 09:20:08.365: INFO: stdout: "e2e-test-crd-publish-openapi-9443-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 20 09:20:08.365: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 --namespace=crd-publish-openapi-8693 delete e2e-test-crd-publish-openapi-9443-crds test-foo'
Dec 20 09:20:08.496: INFO: stderr: ""
Dec 20 09:20:08.496: INFO: stdout: "e2e-test-crd-publish-openapi-9443-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
Dec 20 09:20:08.496: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 --namespace=crd-publish-openapi-8693 apply -f -'
Dec 20 09:20:08.737: INFO: stderr: ""
Dec 20 09:20:08.737: INFO: stdout: "e2e-test-crd-publish-openapi-9443-crd.crd-publish-openapi-test-foo.example.com/test-foo created\n"
Dec 20 09:20:08.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 --namespace=crd-publish-openapi-8693 delete e2e-test-crd-publish-openapi-9443-crds test-foo'
Dec 20 09:20:08.834: INFO: stderr: ""
Dec 20 09:20:08.834: INFO: stdout: "e2e-test-crd-publish-openapi-9443-crd.crd-publish-openapi-test-foo.example.com \"test-foo\" deleted\n"
STEP: client-side validation (kubectl create and apply) rejects request with unknown properties when disallowed by the schema
Dec 20 09:20:08.834: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 --namespace=crd-publish-openapi-8693 create -f -'
Dec 20 09:20:08.987: INFO: rc: 1
Dec 20 09:20:08.988: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 --namespace=crd-publish-openapi-8693 apply -f -'
Dec 20 09:20:09.223: INFO: rc: 1
STEP: client-side validation (kubectl create and apply) rejects request without required properties
Dec 20 09:20:09.223: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 --namespace=crd-publish-openapi-8693 create -f -'
Dec 20 09:20:09.367: INFO: rc: 1
Dec 20 09:20:09.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 --namespace=crd-publish-openapi-8693 apply -f -'
Dec 20 09:20:09.636: INFO: rc: 1
STEP: kubectl explain works to explain CR properties
Dec 20 09:20:09.636: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 explain e2e-test-crd-publish-openapi-9443-crds'
Dec 20 09:20:09.875: INFO: stderr: ""
Dec 20 09:20:09.875: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9443-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nDESCRIPTION:\n     Foo CRD for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<Object>\n     Specification of Foo\n\n   status\t<Object>\n     Status of Foo\n\n"
STEP: kubectl explain works to explain CR properties recursively
Dec 20 09:20:09.876: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 explain e2e-test-crd-publish-openapi-9443-crds.metadata'
Dec 20 09:20:10.024: INFO: stderr: ""
Dec 20 09:20:10.024: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9443-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: metadata <Object>\n\nDESCRIPTION:\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n     ObjectMeta is metadata that all persisted resources must have, which\n     includes all objects users must create.\n\nFIELDS:\n   annotations\t<map[string]string>\n     Annotations is an unstructured key value map stored with a resource that\n     may be set by external tools to store and retrieve arbitrary metadata. They\n     are not queryable and should be preserved when modifying objects. More\n     info: http://kubernetes.io/docs/user-guide/annotations\n\n   clusterName\t<string>\n     The name of the cluster which the object belongs to. This is used to\n     distinguish resources with same name and namespace in different clusters.\n     This field is not set anywhere right now and apiserver is going to ignore\n     it if set in create or update request.\n\n   creationTimestamp\t<string>\n     CreationTimestamp is a timestamp representing the server time when this\n     object was created. It is not guaranteed to be set in happens-before order\n     across separate operations. Clients may not set this value. It is\n     represented in RFC3339 form and is in UTC. Populated by the system.\n     Read-only. Null for lists. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   deletionGracePeriodSeconds\t<integer>\n     Number of seconds allowed for this object to gracefully terminate before it\n     will be removed from the system. Only set when deletionTimestamp is also\n     set. May only be shortened. Read-only.\n\n   deletionTimestamp\t<string>\n     DeletionTimestamp is RFC 3339 date and time at which this resource will be\n     deleted. This field is set by the server when a graceful deletion is\n     requested by the user, and is not directly settable by a client. The\n     resource is expected to be deleted (no longer visible from resource lists,\n     and not reachable by name) after the time in this field, once the\n     finalizers list is empty. As long as the finalizers list contains items,\n     deletion is blocked. Once the deletionTimestamp is set, this value may not\n     be unset or be set further into the future, although it may be shortened or\n     the resource may be deleted prior to this time. For example, a user may\n     request that a pod is deleted in 30 seconds. The Kubelet will react by\n     sending a graceful termination signal to the containers in the pod. After\n     that 30 seconds, the Kubelet will send a hard termination signal (SIGKILL)\n     to the container and after cleanup, remove the pod from the API. In the\n     presence of network partitions, this object may still exist after this\n     timestamp, until an administrator or automated process can determine the\n     resource is fully terminated. If not set, graceful deletion of the object\n     has not been requested. Populated by the system when a graceful deletion is\n     requested. Read-only. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   finalizers\t<[]string>\n     Must be empty before the object is deleted from the registry. Each entry is\n     an identifier for the responsible component that will remove the entry from\n     the list. If the deletionTimestamp of the object is non-nil, entries in\n     this list can only be removed.\n\n   generateName\t<string>\n     GenerateName is an optional prefix, used by the server, to generate a\n     unique name ONLY IF the Name field has not been provided. If this field is\n     used, the name returned to the client will be different than the name\n     passed. This value will also be combined with a unique suffix. The provided\n     value has the same validation rules as the Name field, and may be truncated\n     by the length of the suffix required to make the value unique on the\n     server. If this field is specified and the generated name exists, the\n     server will NOT return a 409 - instead, it will either return 201 Created\n     or 500 with Reason ServerTimeout indicating a unique name could not be\n     found in the time allotted, and the client should retry (optionally after\n     the time indicated in the Retry-After header). Applied only if Name is not\n     specified. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#idempotency\n\n   generation\t<integer>\n     A sequence number representing a specific generation of the desired state.\n     Populated by the system. Read-only.\n\n   labels\t<map[string]string>\n     Map of string keys and values that can be used to organize and categorize\n     (scope and select) objects. May match selectors of replication controllers\n     and services. More info: http://kubernetes.io/docs/user-guide/labels\n\n   managedFields\t<[]Object>\n     ManagedFields maps workflow-id and version to the set of fields that are\n     managed by that workflow. This is mostly for internal housekeeping, and\n     users typically shouldn't need to set or understand this field. A workflow\n     can be the user's name, a controller's name, or the name of a specific\n     apply path like \"ci-cd\". The set of fields is always in the version that\n     the workflow used when modifying the object.\n\n   name\t<string>\n     Name must be unique within a namespace. Is required when creating\n     resources, although some resources may allow a client to request the\n     generation of an appropriate name automatically. Name is primarily intended\n     for creation idempotence and configuration definition. Cannot be updated.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#names\n\n   namespace\t<string>\n     Namespace defines the space within each name must be unique. An empty\n     namespace is equivalent to the \"default\" namespace, but \"default\" is the\n     canonical representation. Not all objects are required to be scoped to a\n     namespace - the value of this field for those objects will be empty. Must\n     be a DNS_LABEL. Cannot be updated. More info:\n     http://kubernetes.io/docs/user-guide/namespaces\n\n   ownerReferences\t<[]Object>\n     List of objects depended by this object. If ALL objects in the list have\n     been deleted, this object will be garbage collected. If this object is\n     managed by a controller, then an entry in this list will point to this\n     controller, with the controller field set to true. There cannot be more\n     than one managing controller.\n\n   resourceVersion\t<string>\n     An opaque value that represents the internal version of this object that\n     can be used by clients to determine when objects have changed. May be used\n     for optimistic concurrency, change detection, and the watch operation on a\n     resource or set of resources. Clients must treat these values as opaque and\n     passed unmodified back to the server. They may only be valid for a\n     particular resource or set of resources. Populated by the system.\n     Read-only. Value must be treated as opaque by clients and . More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#concurrency-control-and-consistency\n\n   selfLink\t<string>\n     SelfLink is a URL representing this object. Populated by the system.\n     Read-only. DEPRECATED Kubernetes will stop propagating this field in 1.20\n     release and the field is planned to be removed in 1.21 release.\n\n   uid\t<string>\n     UID is the unique in time and space value for this object. It is typically\n     generated by the server on successful creation of a resource and is not\n     allowed to change on PUT operations. Populated by the system. Read-only.\n     More info: http://kubernetes.io/docs/user-guide/identifiers#uids\n\n"
Dec 20 09:20:10.025: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 explain e2e-test-crd-publish-openapi-9443-crds.spec'
Dec 20 09:20:10.179: INFO: stderr: ""
Dec 20 09:20:10.180: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9443-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: spec <Object>\n\nDESCRIPTION:\n     Specification of Foo\n\nFIELDS:\n   bars\t<[]Object>\n     List of Bars and their specs.\n\n"
Dec 20 09:20:10.180: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 explain e2e-test-crd-publish-openapi-9443-crds.spec.bars'
Dec 20 09:20:10.324: INFO: stderr: ""
Dec 20 09:20:10.324: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-9443-crd\nVERSION:  crd-publish-openapi-test-foo.example.com/v1\n\nRESOURCE: bars <[]Object>\n\nDESCRIPTION:\n     List of Bars and their specs.\n\nFIELDS:\n   age\t<string>\n     Age of Bar.\n\n   bazs\t<[]string>\n     List of Bazs.\n\n   name\t<string> -required-\n     Name of Bar.\n\n"
STEP: kubectl explain works to return error when explain is called on property that doesn't exist
Dec 20 09:20:10.324: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 explain e2e-test-crd-publish-openapi-9443-crds.spec.bars2'
Dec 20 09:20:10.480: INFO: rc: 1
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:20:15.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-8693" for this suite.
Dec 20 09:20:21.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:20:21.336: INFO: namespace crd-publish-openapi-8693 deletion completed in 6.10311435s

• [SLOW TEST:18.396 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD with validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:20:21.337: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-8967
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-33c68cef-9e17-4be6-a9ca-73aa1c474300
STEP: Creating a pod to test consume secrets
Dec 20 09:20:21.483: INFO: Waiting up to 5m0s for pod "pod-secrets-540dc163-28c1-4042-8dc7-dcb40c99e531" in namespace "secrets-8967" to be "success or failure"
Dec 20 09:20:21.486: INFO: Pod "pod-secrets-540dc163-28c1-4042-8dc7-dcb40c99e531": Phase="Pending", Reason="", readiness=false. Elapsed: 2.328281ms
Dec 20 09:20:23.490: INFO: Pod "pod-secrets-540dc163-28c1-4042-8dc7-dcb40c99e531": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006422067s
Dec 20 09:20:25.494: INFO: Pod "pod-secrets-540dc163-28c1-4042-8dc7-dcb40c99e531": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010424267s
STEP: Saw pod success
Dec 20 09:20:25.494: INFO: Pod "pod-secrets-540dc163-28c1-4042-8dc7-dcb40c99e531" satisfied condition "success or failure"
Dec 20 09:20:25.496: INFO: Trying to get logs from node caasp-worker-th-before-0 pod pod-secrets-540dc163-28c1-4042-8dc7-dcb40c99e531 container secret-volume-test: <nil>
STEP: delete the pod
Dec 20 09:20:25.525: INFO: Waiting for pod pod-secrets-540dc163-28c1-4042-8dc7-dcb40c99e531 to disappear
Dec 20 09:20:25.527: INFO: Pod pod-secrets-540dc163-28c1-4042-8dc7-dcb40c99e531 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:20:25.527: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-8967" for this suite.
Dec 20 09:20:31.540: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:20:31.634: INFO: namespace secrets-8967 deletion completed in 6.103662187s

• [SLOW TEST:10.298 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-apps] Deployment 
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:20:31.634: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-5238
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 09:20:31.767: INFO: Creating deployment "webserver-deployment"
Dec 20 09:20:31.771: INFO: Waiting for observed generation 1
Dec 20 09:20:33.778: INFO: Waiting for all required pods to come up
Dec 20 09:20:33.782: INFO: Pod name httpd: Found 10 pods out of 10
STEP: ensuring each pod is running
Dec 20 09:20:39.790: INFO: Waiting for deployment "webserver-deployment" to complete
Dec 20 09:20:39.796: INFO: Updating deployment "webserver-deployment" with a non-existent image
Dec 20 09:20:39.803: INFO: Updating deployment webserver-deployment
Dec 20 09:20:39.803: INFO: Waiting for observed generation 2
Dec 20 09:20:41.809: INFO: Waiting for the first rollout's replicaset to have .status.availableReplicas = 8
Dec 20 09:20:41.811: INFO: Waiting for the first rollout's replicaset to have .spec.replicas = 8
Dec 20 09:20:41.813: INFO: Waiting for the first rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 20 09:20:41.820: INFO: Verifying that the second rollout's replicaset has .status.availableReplicas = 0
Dec 20 09:20:41.820: INFO: Waiting for the second rollout's replicaset to have .spec.replicas = 5
Dec 20 09:20:41.822: INFO: Waiting for the second rollout's replicaset of deployment "webserver-deployment" to have desired number of replicas
Dec 20 09:20:41.826: INFO: Verifying that deployment "webserver-deployment" has minimum required number of available replicas
Dec 20 09:20:41.826: INFO: Scaling up the deployment "webserver-deployment" from 10 to 30
Dec 20 09:20:41.831: INFO: Updating deployment webserver-deployment
Dec 20 09:20:41.831: INFO: Waiting for the replicasets of deployment "webserver-deployment" to have desired number of replicas
Dec 20 09:20:41.836: INFO: Verifying that first rollout's replicaset has .spec.replicas = 20
Dec 20 09:20:41.838: INFO: Verifying that second rollout's replicaset has .spec.replicas = 13
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 20 09:20:41.843: INFO: Deployment "webserver-deployment":
&Deployment{ObjectMeta:{webserver-deployment  deployment-5238 /apis/apps/v1/namespaces/deployment-5238/deployments/webserver-deployment 40312372-df58-4e1a-b6fc-74967d4d2e21 108964 3 2019-12-20 09:20:31 +0000 UTC <nil> <nil> map[name:httpd] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*30,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006afdbf8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:2,MaxSurge:3,},},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:13,UpdatedReplicas:5,AvailableReplicas:8,UnavailableReplicas:5,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:True,Reason:MinimumReplicasAvailable,Message:Deployment has minimum availability.,LastUpdateTime:2019-12-20 09:20:39 +0000 UTC,LastTransitionTime:2019-12-20 09:20:39 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "webserver-deployment-c7997dcc8" is progressing.,LastUpdateTime:2019-12-20 09:20:40 +0000 UTC,LastTransitionTime:2019-12-20 09:20:32 +0000 UTC,},},ReadyReplicas:8,CollisionCount:nil,},}

Dec 20 09:20:41.847: INFO: New ReplicaSet "webserver-deployment-c7997dcc8" of Deployment "webserver-deployment":
&ReplicaSet{ObjectMeta:{webserver-deployment-c7997dcc8  deployment-5238 /apis/apps/v1/namespaces/deployment-5238/replicasets/webserver-deployment-c7997dcc8 2ff91eaa-c001-47d7-a323-c5fce1e6f33c 108967 3 2019-12-20 09:20:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment webserver-deployment 40312372-df58-4e1a-b6fc-74967d4d2e21 0xc0060b2137 0xc0060b2138}] []  []},Spec:ReplicaSetSpec{Replicas:*13,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: c7997dcc8,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[] [] []  []} {[] [] [{httpd webserver:404 [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0060b21c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:5,FullyLabeledReplicas:5,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 20 09:20:41.847: INFO: All old ReplicaSets of Deployment "webserver-deployment":
Dec 20 09:20:41.848: INFO: &ReplicaSet{ObjectMeta:{webserver-deployment-595b5b9587  deployment-5238 /apis/apps/v1/namespaces/deployment-5238/replicasets/webserver-deployment-595b5b9587 b80fb94e-a42f-4f63-8cf9-c23d2641aa45 108965 3 2019-12-20 09:20:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[deployment.kubernetes.io/desired-replicas:30 deployment.kubernetes.io/max-replicas:33 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment webserver-deployment 40312372-df58-4e1a-b6fc-74967d4d2e21 0xc0060b2047 0xc0060b2048}] []  []},Spec:ReplicaSetSpec{Replicas:*20,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: httpd,pod-template-hash: 595b5b9587,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0060b20c8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:8,FullyLabeledReplicas:8,ObservedGeneration:2,ReadyReplicas:8,AvailableReplicas:8,Conditions:[]ReplicaSetCondition{},},}
Dec 20 09:20:41.853: INFO: Pod "webserver-deployment-595b5b9587-2gkf8" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-2gkf8 webserver-deployment-595b5b9587- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-595b5b9587-2gkf8 14802af4-6e2b-4b92-9f28-bbd43d83cb00 108852 0 2019-12-20 09:20:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 b80fb94e-a42f-4f63-8cf9-c23d2641aa45 0xc0060b26b7 0xc0060b26b8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.84.149.232,PodIP:10.244.5.195,StartTime:2019-12-20 09:20:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-20 09:20:36 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:cri-o://4da928d70f786702b10ac27c76e22a7db8f44baa0415e18b59256dedfd0f8fac,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.5.195,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.854: INFO: Pod "webserver-deployment-595b5b9587-4mbbv" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-4mbbv webserver-deployment-595b5b9587- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-595b5b9587-4mbbv bd8ccf3b-9178-4cda-8d5a-4fbe01312cfe 108886 0 2019-12-20 09:20:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 b80fb94e-a42f-4f63-8cf9-c23d2641aa45 0xc0060b2827 0xc0060b2828}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.84.149.226,PodIP:10.244.6.186,StartTime:2019-12-20 09:20:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-20 09:20:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:cri-o://b1cb170140b524089ece4f01feca114d39a24f8a7b7e56073cae2381c10da815,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.6.186,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.854: INFO: Pod "webserver-deployment-595b5b9587-7v75t" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-7v75t webserver-deployment-595b5b9587- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-595b5b9587-7v75t 43391669-0149-4c57-b7c1-3fef13287cf4 108841 0 2019-12-20 09:20:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 b80fb94e-a42f-4f63-8cf9-c23d2641aa45 0xc0060b2997 0xc0060b2998}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.84.149.232,PodIP:10.244.5.138,StartTime:2019-12-20 09:20:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-20 09:20:36 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:cri-o://9b9ac92879210bfdbd415e3fb68d529e1a63839a99891f8141b25830242461d1,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.5.138,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.854: INFO: Pod "webserver-deployment-595b5b9587-9h9q8" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-9h9q8 webserver-deployment-595b5b9587- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-595b5b9587-9h9q8 4308953a-7ade-4fcc-aa84-1d804b5993fd 108986 0 2019-12-20 09:20:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 b80fb94e-a42f-4f63-8cf9-c23d2641aa45 0xc0060b2b87 0xc0060b2b88}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.854: INFO: Pod "webserver-deployment-595b5b9587-dt9fg" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-dt9fg webserver-deployment-595b5b9587- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-595b5b9587-dt9fg 38a07818-c055-4ea3-94e2-39759759034e 108844 0 2019-12-20 09:20:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 b80fb94e-a42f-4f63-8cf9-c23d2641aa45 0xc0060b2c80 0xc0060b2c81}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.84.149.232,PodIP:10.244.5.116,StartTime:2019-12-20 09:20:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-20 09:20:36 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:cri-o://ba41ed689d6ef508ae2658d2fb5b6177ed707403f7211037102c11b52cc707cc,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.5.116,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.854: INFO: Pod "webserver-deployment-595b5b9587-gg7dz" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gg7dz webserver-deployment-595b5b9587- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-595b5b9587-gg7dz 6f90cd63-da55-4d0c-b07b-0af907af71ee 108842 0 2019-12-20 09:20:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 b80fb94e-a42f-4f63-8cf9-c23d2641aa45 0xc0060b2e47 0xc0060b2e48}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.84.149.223,PodIP:10.244.7.252,StartTime:2019-12-20 09:20:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-20 09:20:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:cri-o://f17d113b9338d5b7254e31ccbc8e619df3e375cd7f41f9c9c1e5c876da9d6442,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.7.252,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.855: INFO: Pod "webserver-deployment-595b5b9587-gjxvm" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-gjxvm webserver-deployment-595b5b9587- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-595b5b9587-gjxvm 429f7359-abe2-47f0-942d-f3831141d167 108985 0 2019-12-20 09:20:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 b80fb94e-a42f-4f63-8cf9-c23d2641aa45 0xc0060b2ff7 0xc0060b2ff8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.855: INFO: Pod "webserver-deployment-595b5b9587-hv65t" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-hv65t webserver-deployment-595b5b9587- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-595b5b9587-hv65t 91fd33d5-497e-4cd7-a76e-467793151514 108877 0 2019-12-20 09:20:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 b80fb94e-a42f-4f63-8cf9-c23d2641aa45 0xc0060b3120 0xc0060b3121}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:39 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.84.149.226,PodIP:10.244.6.230,StartTime:2019-12-20 09:20:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-20 09:20:38 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:cri-o://ee1838e89116bfb3dbb568446776301ced008df56afa3049afa8d8c8081c79f6,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.6.230,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.855: INFO: Pod "webserver-deployment-595b5b9587-jvdwp" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-jvdwp webserver-deployment-595b5b9587- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-595b5b9587-jvdwp 79b7c820-0190-474c-886c-dab8d195ab3e 108982 0 2019-12-20 09:20:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 b80fb94e-a42f-4f63-8cf9-c23d2641aa45 0xc0060b32e7 0xc0060b32e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.855: INFO: Pod "webserver-deployment-595b5b9587-ncrq6" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-ncrq6 webserver-deployment-595b5b9587- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-595b5b9587-ncrq6 c6957f2e-4a68-485b-a7d9-8b1713334271 108972 0 2019-12-20 09:20:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 b80fb94e-a42f-4f63-8cf9-c23d2641aa45 0xc0060b3400 0xc0060b3401}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:41 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.855: INFO: Pod "webserver-deployment-595b5b9587-nkgqq" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-nkgqq webserver-deployment-595b5b9587- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-595b5b9587-nkgqq 64e1291a-6c7f-4034-9139-a31d71b00042 108847 0 2019-12-20 09:20:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 b80fb94e-a42f-4f63-8cf9-c23d2641aa45 0xc0060b3550 0xc0060b3551}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.84.149.223,PodIP:10.244.7.236,StartTime:2019-12-20 09:20:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-20 09:20:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:cri-o://82dda313de1edb5eae0b3702cb5975139fe82322341ae16183f7e1373d9db02f,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.7.236,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.855: INFO: Pod "webserver-deployment-595b5b9587-nm2k5" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-nm2k5 webserver-deployment-595b5b9587- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-595b5b9587-nm2k5 d6d5f706-1061-4e0c-b9de-d049ae4a2d1c 108980 0 2019-12-20 09:20:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 b80fb94e-a42f-4f63-8cf9-c23d2641aa45 0xc0060b36e7 0xc0060b36e8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:41 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.856: INFO: Pod "webserver-deployment-595b5b9587-nq7bx" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-nq7bx webserver-deployment-595b5b9587- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-595b5b9587-nq7bx 83f243df-f6ad-4d48-8d05-99761193a80b 108983 0 2019-12-20 09:20:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 b80fb94e-a42f-4f63-8cf9-c23d2641aa45 0xc0060b37f0 0xc0060b37f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:41 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.856: INFO: Pod "webserver-deployment-595b5b9587-xg7s2" is available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-xg7s2 webserver-deployment-595b5b9587- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-595b5b9587-xg7s2 f488d9fd-db8c-4ee7-a936-57274c73eca3 108853 0 2019-12-20 09:20:31 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 b80fb94e-a42f-4f63-8cf9-c23d2641aa45 0xc0060b38f0 0xc0060b38f1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:32 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:37 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:31 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.84.149.223,PodIP:10.244.7.127,StartTime:2019-12-20 09:20:32 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-20 09:20:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:cri-o://517a00f453c77fbe842f11bdf6b23749d818a539190fd7ebbecfb7eca98f827a,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.7.127,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.856: INFO: Pod "webserver-deployment-595b5b9587-znsqn" is not available:
&Pod{ObjectMeta:{webserver-deployment-595b5b9587-znsqn webserver-deployment-595b5b9587- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-595b5b9587-znsqn 1f25891c-74e9-4c4f-ab59-81960780e33a 108984 0 2019-12-20 09:20:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:595b5b9587] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-595b5b9587 b80fb94e-a42f-4f63-8cf9-c23d2641aa45 0xc0060b3a57 0xc0060b3a58}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.856: INFO: Pod "webserver-deployment-c7997dcc8-8rk6l" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-8rk6l webserver-deployment-c7997dcc8- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-c7997dcc8-8rk6l 2ab3770d-92d6-4cde-a690-c2f71eb48193 108923 0 2019-12-20 09:20:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 2ff91eaa-c001-47d7-a323-c5fce1e6f33c 0xc0060b3b50 0xc0060b3b51}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.84.149.226,PodIP:,StartTime:2019-12-20 09:20:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.857: INFO: Pod "webserver-deployment-c7997dcc8-gcstj" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-gcstj webserver-deployment-c7997dcc8- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-c7997dcc8-gcstj ab52cf23-58c1-4825-b6a5-194877143dd7 108926 0 2019-12-20 09:20:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 2ff91eaa-c001-47d7-a323-c5fce1e6f33c 0xc0060b3cb7 0xc0060b3cb8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.84.149.232,PodIP:,StartTime:2019-12-20 09:20:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.857: INFO: Pod "webserver-deployment-c7997dcc8-h2n4d" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-h2n4d webserver-deployment-c7997dcc8- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-c7997dcc8-h2n4d 5e5c1386-aaf9-4bb1-9983-76b0eaaea9a4 108942 0 2019-12-20 09:20:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 2ff91eaa-c001-47d7-a323-c5fce1e6f33c 0xc0060b3e67 0xc0060b3e68}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.84.149.232,PodIP:,StartTime:2019-12-20 09:20:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.857: INFO: Pod "webserver-deployment-c7997dcc8-j62nj" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-j62nj webserver-deployment-c7997dcc8- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-c7997dcc8-j62nj d88f0f2f-180e-448f-af81-4fd1234b4a09 108940 0 2019-12-20 09:20:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 2ff91eaa-c001-47d7-a323-c5fce1e6f33c 0xc0060b3ff7 0xc0060b3ff8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.84.149.223,PodIP:,StartTime:2019-12-20 09:20:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.857: INFO: Pod "webserver-deployment-c7997dcc8-llrts" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-llrts webserver-deployment-c7997dcc8- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-c7997dcc8-llrts 95f44eef-8ca3-4b59-a85f-b2d676bc7a46 108919 0 2019-12-20 09:20:39 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 2ff91eaa-c001-47d7-a323-c5fce1e6f33c 0xc0060d61a7 0xc0060d61a8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:40 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:40 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:39 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.84.149.223,PodIP:,StartTime:2019-12-20 09:20:40 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:webserver:404,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.857: INFO: Pod "webserver-deployment-c7997dcc8-rs8l5" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-rs8l5 webserver-deployment-c7997dcc8- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-c7997dcc8-rs8l5 97ea1ded-a1dd-44c3-a92c-f5a9e47210fc 108979 0 2019-12-20 09:20:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 2ff91eaa-c001-47d7-a323-c5fce1e6f33c 0xc0060d6347 0xc0060d6348}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.858: INFO: Pod "webserver-deployment-c7997dcc8-sw5wp" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-sw5wp webserver-deployment-c7997dcc8- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-c7997dcc8-sw5wp 46183b59-84d1-4dc9-ae0e-dc4630080d1d 108977 0 2019-12-20 09:20:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 2ff91eaa-c001-47d7-a323-c5fce1e6f33c 0xc0060d6490 0xc0060d6491}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-3,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:20:41 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
Dec 20 09:20:41.858: INFO: Pod "webserver-deployment-c7997dcc8-w4jpw" is not available:
&Pod{ObjectMeta:{webserver-deployment-c7997dcc8-w4jpw webserver-deployment-c7997dcc8- deployment-5238 /api/v1/namespaces/deployment-5238/pods/webserver-deployment-c7997dcc8-w4jpw 6360907f-c9d2-4a62-b2fd-d64f7aef202a 108981 0 2019-12-20 09:20:41 +0000 UTC <nil> <nil> map[name:httpd pod-template-hash:c7997dcc8] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet webserver-deployment-c7997dcc8 2ff91eaa-c001-47d7-a323-c5fce1e6f33c 0xc0060d65e0 0xc0060d65e1}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-sfskd,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-sfskd,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:webserver:404,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-sfskd,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{},Message:,Reason:,HostIP:,PodIP:,StartTime:<nil>,ContainerStatuses:[]ContainerStatus{},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:20:41.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-5238" for this suite.
Dec 20 09:20:47.874: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:20:47.960: INFO: namespace deployment-5238 deletion completed in 6.096942699s

• [SLOW TEST:16.326 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should support proportional scaling [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:20:47.961: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-273
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-79aea764-ae48-49f7-94da-5dddf8a43153
STEP: Creating a pod to test consume secrets
Dec 20 09:20:48.105: INFO: Waiting up to 5m0s for pod "pod-secrets-bf2f87f4-ad2c-4e46-be83-1ab87dc33153" in namespace "secrets-273" to be "success or failure"
Dec 20 09:20:48.107: INFO: Pod "pod-secrets-bf2f87f4-ad2c-4e46-be83-1ab87dc33153": Phase="Pending", Reason="", readiness=false. Elapsed: 2.422944ms
Dec 20 09:20:50.111: INFO: Pod "pod-secrets-bf2f87f4-ad2c-4e46-be83-1ab87dc33153": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006245476s
Dec 20 09:20:52.115: INFO: Pod "pod-secrets-bf2f87f4-ad2c-4e46-be83-1ab87dc33153": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01037667s
STEP: Saw pod success
Dec 20 09:20:52.115: INFO: Pod "pod-secrets-bf2f87f4-ad2c-4e46-be83-1ab87dc33153" satisfied condition "success or failure"
Dec 20 09:20:52.118: INFO: Trying to get logs from node caasp-worker-th-before-0 pod pod-secrets-bf2f87f4-ad2c-4e46-be83-1ab87dc33153 container secret-volume-test: <nil>
STEP: delete the pod
Dec 20 09:20:52.133: INFO: Waiting for pod pod-secrets-bf2f87f4-ad2c-4e46-be83-1ab87dc33153 to disappear
Dec 20 09:20:52.136: INFO: Pod pod-secrets-bf2f87f4-ad2c-4e46-be83-1ab87dc33153 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:20:52.136: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-273" for this suite.
Dec 20 09:20:58.151: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:20:58.254: INFO: namespace secrets-273 deletion completed in 6.11493959s

• [SLOW TEST:10.294 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:20:58.254: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-7498
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-52871438-a84d-46bd-b709-cd0eb052af7a
STEP: Creating a pod to test consume secrets
Dec 20 09:20:58.400: INFO: Waiting up to 5m0s for pod "pod-secrets-88776add-e069-4eb2-b7ee-7e08433e8b9c" in namespace "secrets-7498" to be "success or failure"
Dec 20 09:20:58.402: INFO: Pod "pod-secrets-88776add-e069-4eb2-b7ee-7e08433e8b9c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.544579ms
Dec 20 09:21:00.407: INFO: Pod "pod-secrets-88776add-e069-4eb2-b7ee-7e08433e8b9c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007859952s
Dec 20 09:21:02.411: INFO: Pod "pod-secrets-88776add-e069-4eb2-b7ee-7e08433e8b9c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011328336s
STEP: Saw pod success
Dec 20 09:21:02.411: INFO: Pod "pod-secrets-88776add-e069-4eb2-b7ee-7e08433e8b9c" satisfied condition "success or failure"
Dec 20 09:21:02.413: INFO: Trying to get logs from node caasp-worker-th-before-3 pod pod-secrets-88776add-e069-4eb2-b7ee-7e08433e8b9c container secret-volume-test: <nil>
STEP: delete the pod
Dec 20 09:21:02.442: INFO: Waiting for pod pod-secrets-88776add-e069-4eb2-b7ee-7e08433e8b9c to disappear
Dec 20 09:21:02.444: INFO: Pod pod-secrets-88776add-e069-4eb2-b7ee-7e08433e8b9c no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:21:02.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-7498" for this suite.
Dec 20 09:21:08.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:21:08.552: INFO: namespace secrets-7498 deletion completed in 6.103751645s

• [SLOW TEST:10.298 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:21:08.552: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-8327
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 09:21:34.705: INFO: Container started at 2019-12-20 09:21:15 +0000 UTC, pod became ready at 2019-12-20 09:21:33 +0000 UTC
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:21:34.705: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-8327" for this suite.
Dec 20 09:21:46.721: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:21:46.822: INFO: namespace container-probe-8327 deletion completed in 12.112574783s

• [SLOW TEST:38.269 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Pods Set QOS Class 
  should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:21:46.822: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-2141
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:179
[It] should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying QOS class is set on the pod
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:21:46.968: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-2141" for this suite.
Dec 20 09:21:58.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:21:59.077: INFO: namespace pods-2141 deletion completed in 12.105703593s

• [SLOW TEST:12.255 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Pods Set QOS Class
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:21:59.078: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9905
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 20 09:21:59.227: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2636e73c-561c-4e16-90b1-48344693aa95" in namespace "projected-9905" to be "success or failure"
Dec 20 09:21:59.230: INFO: Pod "downwardapi-volume-2636e73c-561c-4e16-90b1-48344693aa95": Phase="Pending", Reason="", readiness=false. Elapsed: 2.571022ms
Dec 20 09:22:01.235: INFO: Pod "downwardapi-volume-2636e73c-561c-4e16-90b1-48344693aa95": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007664809s
Dec 20 09:22:03.238: INFO: Pod "downwardapi-volume-2636e73c-561c-4e16-90b1-48344693aa95": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011302788s
STEP: Saw pod success
Dec 20 09:22:03.238: INFO: Pod "downwardapi-volume-2636e73c-561c-4e16-90b1-48344693aa95" satisfied condition "success or failure"
Dec 20 09:22:03.241: INFO: Trying to get logs from node caasp-worker-th-before-0 pod downwardapi-volume-2636e73c-561c-4e16-90b1-48344693aa95 container client-container: <nil>
STEP: delete the pod
Dec 20 09:22:03.256: INFO: Waiting for pod downwardapi-volume-2636e73c-561c-4e16-90b1-48344693aa95 to disappear
Dec 20 09:22:03.258: INFO: Pod downwardapi-volume-2636e73c-561c-4e16-90b1-48344693aa95 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:22:03.258: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9905" for this suite.
Dec 20 09:22:09.271: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:22:09.358: INFO: namespace projected-9905 deletion completed in 6.096659157s

• [SLOW TEST:10.281 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:22:09.358: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6214
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in different groups (two CRDs) show up in OpenAPI documentation
Dec 20 09:22:09.492: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 09:22:14.515: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:22:34.252: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6214" for this suite.
Dec 20 09:22:40.270: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:22:40.354: INFO: namespace crd-publish-openapi-6214 deletion completed in 6.098189948s

• [SLOW TEST:30.996 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of different groups [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:22:40.355: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-871
STEP: Waiting for a default service account to be provisioned in namespace
[It] creating/deleting custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 09:22:40.482: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:22:41.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-871" for this suite.
Dec 20 09:22:47.516: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:22:47.601: INFO: namespace custom-resource-definition-871 deletion completed in 6.096544091s

• [SLOW TEST:7.246 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    creating/deleting custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:22:47.601: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-9186
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name secret-emptykey-test-c2798b98-c293-4cf4-810b-11895ccf3198
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:22:47.735: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-9186" for this suite.
Dec 20 09:22:53.749: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:22:53.840: INFO: namespace secrets-9186 deletion completed in 6.100628151s

• [SLOW TEST:6.238 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should fail to create secret due to empty secret key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-node] ConfigMap 
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:22:53.840: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-7499
STEP: Waiting for a default service account to be provisioned in namespace
[It] should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap that has name configmap-test-emptyKey-51ef587c-9c15-4393-974a-fc3be3248970
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:22:53.976: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-7499" for this suite.
Dec 20 09:22:59.992: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:23:00.088: INFO: namespace configmap-7499 deletion completed in 6.107313426s

• [SLOW TEST:6.248 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should fail to create ConfigMap with empty key [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:23:00.089: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-4637
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating 50 configmaps
STEP: Creating RC which spawns configmap-volume pods
Dec 20 09:23:00.446: INFO: Pod name wrapped-volume-race-fd918a13-bcf8-4572-905a-014485f60d07: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-fd918a13-bcf8-4572-905a-014485f60d07 in namespace emptydir-wrapper-4637, will wait for the garbage collector to delete the pods
Dec 20 09:23:20.571: INFO: Deleting ReplicationController wrapped-volume-race-fd918a13-bcf8-4572-905a-014485f60d07 took: 7.76396ms
Dec 20 09:23:20.971: INFO: Terminating ReplicationController wrapped-volume-race-fd918a13-bcf8-4572-905a-014485f60d07 pods took: 400.230774ms
STEP: Creating RC which spawns configmap-volume pods
Dec 20 09:24:01.488: INFO: Pod name wrapped-volume-race-07f62f30-c3e4-450d-998a-81e636e7dd59: Found 0 pods out of 5
Dec 20 09:24:06.494: INFO: Pod name wrapped-volume-race-07f62f30-c3e4-450d-998a-81e636e7dd59: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-07f62f30-c3e4-450d-998a-81e636e7dd59 in namespace emptydir-wrapper-4637, will wait for the garbage collector to delete the pods
Dec 20 09:24:22.572: INFO: Deleting ReplicationController wrapped-volume-race-07f62f30-c3e4-450d-998a-81e636e7dd59 took: 6.739431ms
Dec 20 09:24:22.972: INFO: Terminating ReplicationController wrapped-volume-race-07f62f30-c3e4-450d-998a-81e636e7dd59 pods took: 400.233464ms
STEP: Creating RC which spawns configmap-volume pods
Dec 20 09:24:57.186: INFO: Pod name wrapped-volume-race-bbf36567-87da-4086-8006-0ee288dd4cab: Found 0 pods out of 5
Dec 20 09:25:02.192: INFO: Pod name wrapped-volume-race-bbf36567-87da-4086-8006-0ee288dd4cab: Found 5 pods out of 5
STEP: Ensuring each pod is running
STEP: deleting ReplicationController wrapped-volume-race-bbf36567-87da-4086-8006-0ee288dd4cab in namespace emptydir-wrapper-4637, will wait for the garbage collector to delete the pods
Dec 20 09:25:18.274: INFO: Deleting ReplicationController wrapped-volume-race-bbf36567-87da-4086-8006-0ee288dd4cab took: 7.910044ms
Dec 20 09:25:18.674: INFO: Terminating ReplicationController wrapped-volume-race-bbf36567-87da-4086-8006-0ee288dd4cab pods took: 400.29571ms
STEP: Cleaning up the configMaps
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:25:54.231: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-4637" for this suite.
Dec 20 09:26:02.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:26:02.340: INFO: namespace emptydir-wrapper-4637 deletion completed in 8.105104626s

• [SLOW TEST:182.252 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not cause race condition when used for configmaps [Serial] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[k8s.io] Probing container 
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:26:02.340: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-2602
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-e9bb9d04-7be0-417b-a9af-808ab0273b26 in namespace container-probe-2602
Dec 20 09:26:06.490: INFO: Started pod liveness-e9bb9d04-7be0-417b-a9af-808ab0273b26 in namespace container-probe-2602
STEP: checking the pod's current state and verifying that restartCount is present
Dec 20 09:26:06.493: INFO: Initial restart count of pod liveness-e9bb9d04-7be0-417b-a9af-808ab0273b26 is 0
Dec 20 09:26:18.517: INFO: Restart count of pod container-probe-2602/liveness-e9bb9d04-7be0-417b-a9af-808ab0273b26 is now 1 (12.024725623s elapsed)
Dec 20 09:26:38.554: INFO: Restart count of pod container-probe-2602/liveness-e9bb9d04-7be0-417b-a9af-808ab0273b26 is now 2 (32.06095038s elapsed)
Dec 20 09:26:58.588: INFO: Restart count of pod container-probe-2602/liveness-e9bb9d04-7be0-417b-a9af-808ab0273b26 is now 3 (52.095343055s elapsed)
Dec 20 09:27:18.630: INFO: Restart count of pod container-probe-2602/liveness-e9bb9d04-7be0-417b-a9af-808ab0273b26 is now 4 (1m12.137414711s elapsed)
Dec 20 09:28:18.754: INFO: Restart count of pod container-probe-2602/liveness-e9bb9d04-7be0-417b-a9af-808ab0273b26 is now 5 (2m12.261106063s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:28:18.763: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-2602" for this suite.
Dec 20 09:28:24.777: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:28:24.859: INFO: namespace container-probe-2602 deletion completed in 6.09249883s

• [SLOW TEST:142.519 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should have monotonically increasing restart count [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:28:24.860: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-1473
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test env composition
Dec 20 09:28:24.997: INFO: Waiting up to 5m0s for pod "var-expansion-eb9bb136-bc07-43d5-9149-c347861cde88" in namespace "var-expansion-1473" to be "success or failure"
Dec 20 09:28:24.999: INFO: Pod "var-expansion-eb9bb136-bc07-43d5-9149-c347861cde88": Phase="Pending", Reason="", readiness=false. Elapsed: 2.121515ms
Dec 20 09:28:27.002: INFO: Pod "var-expansion-eb9bb136-bc07-43d5-9149-c347861cde88": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00564938s
Dec 20 09:28:29.006: INFO: Pod "var-expansion-eb9bb136-bc07-43d5-9149-c347861cde88": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009696279s
STEP: Saw pod success
Dec 20 09:28:29.007: INFO: Pod "var-expansion-eb9bb136-bc07-43d5-9149-c347861cde88" satisfied condition "success or failure"
Dec 20 09:28:29.010: INFO: Trying to get logs from node caasp-worker-th-before-4 pod var-expansion-eb9bb136-bc07-43d5-9149-c347861cde88 container dapi-container: <nil>
STEP: delete the pod
Dec 20 09:28:29.042: INFO: Waiting for pod var-expansion-eb9bb136-bc07-43d5-9149-c347861cde88 to disappear
Dec 20 09:28:29.044: INFO: Pod var-expansion-eb9bb136-bc07-43d5-9149-c347861cde88 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:28:29.044: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-1473" for this suite.
Dec 20 09:28:35.057: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:28:35.156: INFO: namespace var-expansion-1473 deletion completed in 6.109232995s

• [SLOW TEST:10.297 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow composing env vars into new env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Security Context when creating containers with AllowPrivilegeEscalation 
  should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:28:35.157: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-885
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 09:28:35.293: INFO: Waiting up to 5m0s for pod "alpine-nnp-false-a3a2dbfd-84f8-40c9-a3c6-ae94071f1459" in namespace "security-context-test-885" to be "success or failure"
Dec 20 09:28:35.295: INFO: Pod "alpine-nnp-false-a3a2dbfd-84f8-40c9-a3c6-ae94071f1459": Phase="Pending", Reason="", readiness=false. Elapsed: 2.261006ms
Dec 20 09:28:37.298: INFO: Pod "alpine-nnp-false-a3a2dbfd-84f8-40c9-a3c6-ae94071f1459": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00554274s
Dec 20 09:28:39.302: INFO: Pod "alpine-nnp-false-a3a2dbfd-84f8-40c9-a3c6-ae94071f1459": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009143415s
Dec 20 09:28:41.306: INFO: Pod "alpine-nnp-false-a3a2dbfd-84f8-40c9-a3c6-ae94071f1459": Phase="Pending", Reason="", readiness=false. Elapsed: 6.012837603s
Dec 20 09:28:43.309: INFO: Pod "alpine-nnp-false-a3a2dbfd-84f8-40c9-a3c6-ae94071f1459": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.015962913s
Dec 20 09:28:43.309: INFO: Pod "alpine-nnp-false-a3a2dbfd-84f8-40c9-a3c6-ae94071f1459" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:28:43.338: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-885" for this suite.
Dec 20 09:28:49.355: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:28:49.450: INFO: namespace security-context-test-885 deletion completed in 6.107242068s

• [SLOW TEST:14.294 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when creating containers with AllowPrivilegeEscalation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:277
    should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:28:49.450: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9790
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:28:56.595: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9790" for this suite.
Dec 20 09:29:02.610: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:29:02.699: INFO: namespace resourcequota-9790 deletion completed in 6.099071601s

• [SLOW TEST:13.248 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:29:02.699: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7386
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 20 09:29:02.839: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e66a11de-c7ff-4e67-b088-b6498613f7fe" in namespace "downward-api-7386" to be "success or failure"
Dec 20 09:29:02.841: INFO: Pod "downwardapi-volume-e66a11de-c7ff-4e67-b088-b6498613f7fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.369167ms
Dec 20 09:29:04.846: INFO: Pod "downwardapi-volume-e66a11de-c7ff-4e67-b088-b6498613f7fe": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007042487s
Dec 20 09:29:06.851: INFO: Pod "downwardapi-volume-e66a11de-c7ff-4e67-b088-b6498613f7fe": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.012134129s
STEP: Saw pod success
Dec 20 09:29:06.851: INFO: Pod "downwardapi-volume-e66a11de-c7ff-4e67-b088-b6498613f7fe" satisfied condition "success or failure"
Dec 20 09:29:06.854: INFO: Trying to get logs from node caasp-worker-th-before-4 pod downwardapi-volume-e66a11de-c7ff-4e67-b088-b6498613f7fe container client-container: <nil>
STEP: delete the pod
Dec 20 09:29:06.868: INFO: Waiting for pod downwardapi-volume-e66a11de-c7ff-4e67-b088-b6498613f7fe to disappear
Dec 20 09:29:06.870: INFO: Pod downwardapi-volume-e66a11de-c7ff-4e67-b088-b6498613f7fe no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:29:06.870: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7386" for this suite.
Dec 20 09:29:12.885: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:29:12.976: INFO: namespace downward-api-7386 deletion completed in 6.101965673s

• [SLOW TEST:10.278 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:29:12.976: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4866
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 20 09:29:13.113: INFO: Waiting up to 5m0s for pod "downwardapi-volume-1bc5b330-c65d-4770-b1a0-57f50384f680" in namespace "projected-4866" to be "success or failure"
Dec 20 09:29:13.115: INFO: Pod "downwardapi-volume-1bc5b330-c65d-4770-b1a0-57f50384f680": Phase="Pending", Reason="", readiness=false. Elapsed: 2.131267ms
Dec 20 09:29:15.119: INFO: Pod "downwardapi-volume-1bc5b330-c65d-4770-b1a0-57f50384f680": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005842547s
Dec 20 09:29:17.123: INFO: Pod "downwardapi-volume-1bc5b330-c65d-4770-b1a0-57f50384f680": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009708603s
STEP: Saw pod success
Dec 20 09:29:17.123: INFO: Pod "downwardapi-volume-1bc5b330-c65d-4770-b1a0-57f50384f680" satisfied condition "success or failure"
Dec 20 09:29:17.125: INFO: Trying to get logs from node caasp-worker-th-before-0 pod downwardapi-volume-1bc5b330-c65d-4770-b1a0-57f50384f680 container client-container: <nil>
STEP: delete the pod
Dec 20 09:29:17.140: INFO: Waiting for pod downwardapi-volume-1bc5b330-c65d-4770-b1a0-57f50384f680 to disappear
Dec 20 09:29:17.142: INFO: Pod downwardapi-volume-1bc5b330-c65d-4770-b1a0-57f50384f680 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:29:17.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4866" for this suite.
Dec 20 09:29:23.156: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:29:23.245: INFO: namespace projected-4866 deletion completed in 6.099413279s

• [SLOW TEST:10.268 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:29:23.245: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-749
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group but different versions (one multiversion CRD) show up in OpenAPI documentation
Dec 20 09:29:23.378: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: CRs in the same group but different versions (two CRDs) show up in OpenAPI documentation
Dec 20 09:29:43.169: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 09:29:48.194: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:30:08.758: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-749" for this suite.
Dec 20 09:30:14.775: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:30:14.867: INFO: namespace crd-publish-openapi-749 deletion completed in 6.10417382s

• [SLOW TEST:51.622 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group but different versions [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:30:14.867: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-7875
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: Orphaning one of the Job's Pods
Dec 20 09:30:19.520: INFO: Successfully updated pod "adopt-release-ksqqk"
STEP: Checking that the Job readopts the Pod
Dec 20 09:30:19.520: INFO: Waiting up to 15m0s for pod "adopt-release-ksqqk" in namespace "job-7875" to be "adopted"
Dec 20 09:30:19.522: INFO: Pod "adopt-release-ksqqk": Phase="Running", Reason="", readiness=true. Elapsed: 2.109198ms
Dec 20 09:30:21.526: INFO: Pod "adopt-release-ksqqk": Phase="Running", Reason="", readiness=true. Elapsed: 2.006125643s
Dec 20 09:30:21.526: INFO: Pod "adopt-release-ksqqk" satisfied condition "adopted"
STEP: Removing the labels from the Job's Pod
Dec 20 09:30:22.034: INFO: Successfully updated pod "adopt-release-ksqqk"
STEP: Checking that the Job releases the Pod
Dec 20 09:30:22.034: INFO: Waiting up to 15m0s for pod "adopt-release-ksqqk" in namespace "job-7875" to be "released"
Dec 20 09:30:22.037: INFO: Pod "adopt-release-ksqqk": Phase="Running", Reason="", readiness=true. Elapsed: 2.574205ms
Dec 20 09:30:24.040: INFO: Pod "adopt-release-ksqqk": Phase="Running", Reason="", readiness=true. Elapsed: 2.005823722s
Dec 20 09:30:24.040: INFO: Pod "adopt-release-ksqqk" satisfied condition "released"
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:30:24.040: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7875" for this suite.
Dec 20 09:31:08.054: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:31:08.150: INFO: namespace job-7875 deletion completed in 44.105870385s

• [SLOW TEST:53.283 seconds]
[sig-apps] Job
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching orphans and release non-matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:31:08.150: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-7411
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-c0496769-108b-4c8c-bac5-1b8057f095d8
STEP: Creating a pod to test consume configMaps
Dec 20 09:31:08.290: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-883b167e-beb1-45e8-af56-eed23defa72c" in namespace "projected-7411" to be "success or failure"
Dec 20 09:31:08.292: INFO: Pod "pod-projected-configmaps-883b167e-beb1-45e8-af56-eed23defa72c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.409762ms
Dec 20 09:31:10.296: INFO: Pod "pod-projected-configmaps-883b167e-beb1-45e8-af56-eed23defa72c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006907134s
Dec 20 09:31:12.300: INFO: Pod "pod-projected-configmaps-883b167e-beb1-45e8-af56-eed23defa72c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010699988s
STEP: Saw pod success
Dec 20 09:31:12.300: INFO: Pod "pod-projected-configmaps-883b167e-beb1-45e8-af56-eed23defa72c" satisfied condition "success or failure"
Dec 20 09:31:12.303: INFO: Trying to get logs from node caasp-worker-th-before-0 pod pod-projected-configmaps-883b167e-beb1-45e8-af56-eed23defa72c container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 09:31:12.327: INFO: Waiting for pod pod-projected-configmaps-883b167e-beb1-45e8-af56-eed23defa72c to disappear
Dec 20 09:31:12.329: INFO: Pod pod-projected-configmaps-883b167e-beb1-45e8-af56-eed23defa72c no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:31:12.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-7411" for this suite.
Dec 20 09:31:18.342: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:31:18.429: INFO: namespace projected-7411 deletion completed in 6.097204769s

• [SLOW TEST:10.279 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:31:18.430: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1189
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-e75fa5e8-cb90-4243-84cb-e488ebd52911
STEP: Creating a pod to test consume configMaps
Dec 20 09:31:18.570: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-36a3d9c1-3a52-4882-8569-3bdd690699dd" in namespace "projected-1189" to be "success or failure"
Dec 20 09:31:18.573: INFO: Pod "pod-projected-configmaps-36a3d9c1-3a52-4882-8569-3bdd690699dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.58505ms
Dec 20 09:31:20.576: INFO: Pod "pod-projected-configmaps-36a3d9c1-3a52-4882-8569-3bdd690699dd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006150502s
Dec 20 09:31:22.580: INFO: Pod "pod-projected-configmaps-36a3d9c1-3a52-4882-8569-3bdd690699dd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01013452s
STEP: Saw pod success
Dec 20 09:31:22.580: INFO: Pod "pod-projected-configmaps-36a3d9c1-3a52-4882-8569-3bdd690699dd" satisfied condition "success or failure"
Dec 20 09:31:22.583: INFO: Trying to get logs from node caasp-worker-th-before-3 pod pod-projected-configmaps-36a3d9c1-3a52-4882-8569-3bdd690699dd container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 09:31:22.611: INFO: Waiting for pod pod-projected-configmaps-36a3d9c1-3a52-4882-8569-3bdd690699dd to disappear
Dec 20 09:31:22.613: INFO: Pod pod-projected-configmaps-36a3d9c1-3a52-4882-8569-3bdd690699dd no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:31:22.613: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1189" for this suite.
Dec 20 09:31:28.625: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:31:28.715: INFO: namespace projected-1189 deletion completed in 6.099191729s

• [SLOW TEST:10.286 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:31:28.715: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-8638
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-5f79d97d-9f8b-4971-896b-7caebf7e7294
STEP: Creating a pod to test consume configMaps
Dec 20 09:31:28.865: INFO: Waiting up to 5m0s for pod "pod-configmaps-11b0fac8-a450-42ca-8d6a-2a60792183c6" in namespace "configmap-8638" to be "success or failure"
Dec 20 09:31:28.868: INFO: Pod "pod-configmaps-11b0fac8-a450-42ca-8d6a-2a60792183c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.470454ms
Dec 20 09:31:30.872: INFO: Pod "pod-configmaps-11b0fac8-a450-42ca-8d6a-2a60792183c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006852181s
Dec 20 09:31:32.876: INFO: Pod "pod-configmaps-11b0fac8-a450-42ca-8d6a-2a60792183c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010893681s
STEP: Saw pod success
Dec 20 09:31:32.876: INFO: Pod "pod-configmaps-11b0fac8-a450-42ca-8d6a-2a60792183c6" satisfied condition "success or failure"
Dec 20 09:31:32.879: INFO: Trying to get logs from node caasp-worker-th-before-3 pod pod-configmaps-11b0fac8-a450-42ca-8d6a-2a60792183c6 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 09:31:32.893: INFO: Waiting for pod pod-configmaps-11b0fac8-a450-42ca-8d6a-2a60792183c6 to disappear
Dec 20 09:31:32.895: INFO: Pod pod-configmaps-11b0fac8-a450-42ca-8d6a-2a60792183c6 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:31:32.895: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-8638" for this suite.
Dec 20 09:31:38.908: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:31:39.003: INFO: namespace configmap-8638 deletion completed in 6.104451624s

• [SLOW TEST:10.288 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:31:39.003: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2673
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support --unix-socket=/path  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Starting the proxy
Dec 20 09:31:39.137: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-816092167 proxy --unix-socket=/tmp/kubectl-proxy-unix585536674/test'
STEP: retrieving proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:31:39.202: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2673" for this suite.
Dec 20 09:31:45.216: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:31:45.306: INFO: namespace kubectl-2673 deletion completed in 6.100473312s

• [SLOW TEST:6.303 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support --unix-socket=/path  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Proxy server 
  should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:31:45.306: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9213
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should support proxy with --port 0  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting the proxy server
Dec 20 09:31:45.436: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-816092167 proxy -p 0 --disable-filter'
STEP: curling proxy /api/ output
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:31:45.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9213" for this suite.
Dec 20 09:31:51.567: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:31:51.661: INFO: namespace kubectl-9213 deletion completed in 6.105399373s

• [SLOW TEST:6.355 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Proxy server
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1782
    should support proxy with --port 0  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:31:51.662: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7046
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 20 09:31:56.322: INFO: Successfully updated pod "labelsupdate97b814ca-38f7-40f5-a48a-33a9ddf89787"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:31:58.335: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7046" for this suite.
Dec 20 09:32:10.353: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:32:10.439: INFO: namespace downward-api-7046 deletion completed in 12.099588243s

• [SLOW TEST:18.777 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:32:10.439: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4921
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-760c1ebc-9805-4a94-a21a-0249278ba152
STEP: Creating a pod to test consume configMaps
Dec 20 09:32:10.579: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-fc4b8897-8501-40c7-8f16-7cf6925f2021" in namespace "projected-4921" to be "success or failure"
Dec 20 09:32:10.581: INFO: Pod "pod-projected-configmaps-fc4b8897-8501-40c7-8f16-7cf6925f2021": Phase="Pending", Reason="", readiness=false. Elapsed: 2.298468ms
Dec 20 09:32:12.584: INFO: Pod "pod-projected-configmaps-fc4b8897-8501-40c7-8f16-7cf6925f2021": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005409241s
Dec 20 09:32:14.588: INFO: Pod "pod-projected-configmaps-fc4b8897-8501-40c7-8f16-7cf6925f2021": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.00947791s
STEP: Saw pod success
Dec 20 09:32:14.588: INFO: Pod "pod-projected-configmaps-fc4b8897-8501-40c7-8f16-7cf6925f2021" satisfied condition "success or failure"
Dec 20 09:32:14.591: INFO: Trying to get logs from node caasp-worker-th-before-4 pod pod-projected-configmaps-fc4b8897-8501-40c7-8f16-7cf6925f2021 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 09:32:14.622: INFO: Waiting for pod pod-projected-configmaps-fc4b8897-8501-40c7-8f16-7cf6925f2021 to disappear
Dec 20 09:32:14.624: INFO: Pod pod-projected-configmaps-fc4b8897-8501-40c7-8f16-7cf6925f2021 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:32:14.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4921" for this suite.
Dec 20 09:32:20.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:32:20.728: INFO: namespace projected-4921 deletion completed in 6.09979378s

• [SLOW TEST:10.289 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings as non-root [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:32:20.728: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-1210
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not best effort scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a best-effort pod
STEP: Ensuring resource quota with best effort scope captures the pod usage
STEP: Ensuring resource quota with not best effort ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a not best-effort pod
STEP: Ensuring resource quota with not best effort scope captures the pod usage
STEP: Ensuring resource quota with best effort scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:32:36.930: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-1210" for this suite.
Dec 20 09:32:42.945: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:32:43.038: INFO: namespace resourcequota-1210 deletion completed in 6.102940694s

• [SLOW TEST:22.310 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with best effort scope. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:32:43.038: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-1932
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 20 09:32:51.211: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 20 09:32:51.213: INFO: Pod pod-with-poststart-http-hook still exists
Dec 20 09:32:53.213: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 20 09:32:53.217: INFO: Pod pod-with-poststart-http-hook still exists
Dec 20 09:32:55.214: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 20 09:32:55.218: INFO: Pod pod-with-poststart-http-hook still exists
Dec 20 09:32:57.213: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 20 09:32:57.219: INFO: Pod pod-with-poststart-http-hook still exists
Dec 20 09:32:59.214: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 20 09:32:59.218: INFO: Pod pod-with-poststart-http-hook still exists
Dec 20 09:33:01.214: INFO: Waiting for pod pod-with-poststart-http-hook to disappear
Dec 20 09:33:01.217: INFO: Pod pod-with-poststart-http-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:33:01.217: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-1932" for this suite.
Dec 20 09:33:13.234: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:33:13.320: INFO: namespace container-lifecycle-hook-1932 deletion completed in 12.097534845s

• [SLOW TEST:30.282 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[k8s.io] Probing container 
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:33:13.320: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-96
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:34:13.465: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-96" for this suite.
Dec 20 09:34:41.484: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:34:41.582: INFO: namespace container-probe-96 deletion completed in 28.111626966s

• [SLOW TEST:88.262 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:34:41.583: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1750
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 20 09:34:41.729: INFO: Waiting up to 5m0s for pod "downward-api-dc97551e-aaf8-4026-8bc4-9cba1492b51f" in namespace "downward-api-1750" to be "success or failure"
Dec 20 09:34:41.732: INFO: Pod "downward-api-dc97551e-aaf8-4026-8bc4-9cba1492b51f": Phase="Pending", Reason="", readiness=false. Elapsed: 3.005646ms
Dec 20 09:34:43.736: INFO: Pod "downward-api-dc97551e-aaf8-4026-8bc4-9cba1492b51f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00680654s
Dec 20 09:34:45.740: INFO: Pod "downward-api-dc97551e-aaf8-4026-8bc4-9cba1492b51f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010977269s
STEP: Saw pod success
Dec 20 09:34:45.740: INFO: Pod "downward-api-dc97551e-aaf8-4026-8bc4-9cba1492b51f" satisfied condition "success or failure"
Dec 20 09:34:45.743: INFO: Trying to get logs from node caasp-worker-th-before-3 pod downward-api-dc97551e-aaf8-4026-8bc4-9cba1492b51f container dapi-container: <nil>
STEP: delete the pod
Dec 20 09:34:45.773: INFO: Waiting for pod downward-api-dc97551e-aaf8-4026-8bc4-9cba1492b51f to disappear
Dec 20 09:34:45.775: INFO: Pod downward-api-dc97551e-aaf8-4026-8bc4-9cba1492b51f no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:34:45.775: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1750" for this suite.
Dec 20 09:34:51.789: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:34:51.871: INFO: namespace downward-api-1750 deletion completed in 6.092274652s

• [SLOW TEST:10.288 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:34:51.871: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9088
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Discovering how many secrets are in namespace by default
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Secret
STEP: Ensuring resource quota status captures secret creation
STEP: Deleting a secret
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:35:09.043: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9088" for this suite.
Dec 20 09:35:15.059: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:35:15.147: INFO: namespace resourcequota-9088 deletion completed in 6.099788758s

• [SLOW TEST:23.276 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a secret. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:35:15.147: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1967
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 20 09:35:15.283: INFO: Waiting up to 5m0s for pod "pod-dfd7f0ea-cf83-4611-9c8f-a9207633ad48" in namespace "emptydir-1967" to be "success or failure"
Dec 20 09:35:15.286: INFO: Pod "pod-dfd7f0ea-cf83-4611-9c8f-a9207633ad48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.38405ms
Dec 20 09:35:17.289: INFO: Pod "pod-dfd7f0ea-cf83-4611-9c8f-a9207633ad48": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005953892s
Dec 20 09:35:19.293: INFO: Pod "pod-dfd7f0ea-cf83-4611-9c8f-a9207633ad48": Phase="Pending", Reason="", readiness=false. Elapsed: 4.009775354s
Dec 20 09:35:21.296: INFO: Pod "pod-dfd7f0ea-cf83-4611-9c8f-a9207633ad48": Phase="Pending", Reason="", readiness=false. Elapsed: 6.013215963s
Dec 20 09:35:23.300: INFO: Pod "pod-dfd7f0ea-cf83-4611-9c8f-a9207633ad48": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.016902309s
STEP: Saw pod success
Dec 20 09:35:23.300: INFO: Pod "pod-dfd7f0ea-cf83-4611-9c8f-a9207633ad48" satisfied condition "success or failure"
Dec 20 09:35:23.308: INFO: Trying to get logs from node caasp-worker-th-before-3 pod pod-dfd7f0ea-cf83-4611-9c8f-a9207633ad48 container test-container: <nil>
STEP: delete the pod
Dec 20 09:35:23.324: INFO: Waiting for pod pod-dfd7f0ea-cf83-4611-9c8f-a9207633ad48 to disappear
Dec 20 09:35:23.326: INFO: Pod pod-dfd7f0ea-cf83-4611-9c8f-a9207633ad48 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:35:23.326: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1967" for this suite.
Dec 20 09:35:29.339: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:35:29.430: INFO: namespace emptydir-1967 deletion completed in 6.101009372s

• [SLOW TEST:14.283 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:35:29.431: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-9766
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption is created
STEP: When a replication controller with a matching selector is created
STEP: Then the orphan pod is adopted
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:35:34.587: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-9766" for this suite.
Dec 20 09:36:02.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:36:02.692: INFO: namespace replication-controller-9766 deletion completed in 28.10096733s

• [SLOW TEST:33.261 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run deployment 
  should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:36:02.692: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5516
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1540
[It] should create a deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 20 09:36:02.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --generator=deployment/apps.v1 --namespace=kubectl-5516'
Dec 20 09:36:02.960: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 20 09:36:02.960: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the deployment e2e-test-httpd-deployment was created
STEP: verifying the pod controlled by deployment e2e-test-httpd-deployment was created
[AfterEach] Kubectl run deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1545
Dec 20 09:36:04.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 delete deployment e2e-test-httpd-deployment --namespace=kubectl-5516'
Dec 20 09:36:05.071: INFO: stderr: ""
Dec 20 09:36:05.071: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:36:05.071: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5516" for this suite.
Dec 20 09:36:33.084: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:36:33.178: INFO: namespace kubectl-5516 deletion completed in 28.104077702s

• [SLOW TEST:30.486 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1536
    should create a deployment from an image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-auth] ServiceAccounts 
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:36:33.178: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-7475
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
Dec 20 09:36:33.829: INFO: created pod pod-service-account-defaultsa
Dec 20 09:36:33.829: INFO: pod pod-service-account-defaultsa service account token volume mount: true
Dec 20 09:36:33.833: INFO: created pod pod-service-account-mountsa
Dec 20 09:36:33.833: INFO: pod pod-service-account-mountsa service account token volume mount: true
Dec 20 09:36:33.836: INFO: created pod pod-service-account-nomountsa
Dec 20 09:36:33.836: INFO: pod pod-service-account-nomountsa service account token volume mount: false
Dec 20 09:36:33.839: INFO: created pod pod-service-account-defaultsa-mountspec
Dec 20 09:36:33.839: INFO: pod pod-service-account-defaultsa-mountspec service account token volume mount: true
Dec 20 09:36:33.844: INFO: created pod pod-service-account-mountsa-mountspec
Dec 20 09:36:33.844: INFO: pod pod-service-account-mountsa-mountspec service account token volume mount: true
Dec 20 09:36:33.850: INFO: created pod pod-service-account-nomountsa-mountspec
Dec 20 09:36:33.850: INFO: pod pod-service-account-nomountsa-mountspec service account token volume mount: true
Dec 20 09:36:33.853: INFO: created pod pod-service-account-defaultsa-nomountspec
Dec 20 09:36:33.853: INFO: pod pod-service-account-defaultsa-nomountspec service account token volume mount: false
Dec 20 09:36:33.856: INFO: created pod pod-service-account-mountsa-nomountspec
Dec 20 09:36:33.857: INFO: pod pod-service-account-mountsa-nomountspec service account token volume mount: false
Dec 20 09:36:33.860: INFO: created pod pod-service-account-nomountsa-nomountspec
Dec 20 09:36:33.860: INFO: pod pod-service-account-nomountsa-nomountspec service account token volume mount: false
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:36:33.860: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-7475" for this suite.
Dec 20 09:36:45.873: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:36:45.969: INFO: namespace svcaccounts-7475 deletion completed in 12.106397516s

• [SLOW TEST:12.791 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should allow opting out of API token automount  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:36:45.970: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-3656
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3656.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service.dns-3656.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3656.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service.dns-3656.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3656.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3656.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3656.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_udp@_http._tcp.test-service-2.dns-3656.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3656.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/wheezy_tcp@_http._tcp.test-service-2.dns-3656.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3656.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 71.143.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.143.71_udp@PTR;check="$$(dig +tcp +noall +answer +search 71.143.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.143.71_tcp@PTR;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-test-service.dns-3656.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service.dns-3656.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service.dns-3656.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service.dns-3656.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.dns-test-service.dns-3656.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.dns-test-service.dns-3656.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local;check="$$(dig +notcp +noall +answer +search _http._tcp.test-service-2.dns-3656.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_udp@_http._tcp.test-service-2.dns-3656.svc.cluster.local;check="$$(dig +tcp +noall +answer +search _http._tcp.test-service-2.dns-3656.svc.cluster.local SRV)" && test -n "$$check" && echo OK > /results/jessie_tcp@_http._tcp.test-service-2.dns-3656.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-3656.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;check="$$(dig +notcp +noall +answer +search 71.143.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.143.71_udp@PTR;check="$$(dig +tcp +noall +answer +search 71.143.100.10.in-addr.arpa. PTR)" && test -n "$$check" && echo OK > /results/10.100.143.71_tcp@PTR;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 20 09:37:04.142: INFO: Unable to read wheezy_udp@dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:04.145: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:04.148: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:04.152: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:04.175: INFO: Unable to read jessie_udp@dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:04.178: INFO: Unable to read jessie_tcp@dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:04.182: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:04.185: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:04.203: INFO: Lookups using dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec failed for: [wheezy_udp@dns-test-service.dns-3656.svc.cluster.local wheezy_tcp@dns-test-service.dns-3656.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local jessie_udp@dns-test-service.dns-3656.svc.cluster.local jessie_tcp@dns-test-service.dns-3656.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local]

Dec 20 09:37:09.208: INFO: Unable to read wheezy_udp@dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:09.212: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:09.216: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:09.220: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:09.245: INFO: Unable to read jessie_udp@dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:09.248: INFO: Unable to read jessie_tcp@dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:09.251: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:09.254: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:09.273: INFO: Lookups using dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec failed for: [wheezy_udp@dns-test-service.dns-3656.svc.cluster.local wheezy_tcp@dns-test-service.dns-3656.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local jessie_udp@dns-test-service.dns-3656.svc.cluster.local jessie_tcp@dns-test-service.dns-3656.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local]

Dec 20 09:37:14.209: INFO: Unable to read wheezy_udp@dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:14.213: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:14.217: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:14.222: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:14.247: INFO: Unable to read jessie_udp@dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:14.250: INFO: Unable to read jessie_tcp@dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:14.253: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:14.257: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:14.275: INFO: Lookups using dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec failed for: [wheezy_udp@dns-test-service.dns-3656.svc.cluster.local wheezy_tcp@dns-test-service.dns-3656.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local jessie_udp@dns-test-service.dns-3656.svc.cluster.local jessie_tcp@dns-test-service.dns-3656.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local]

Dec 20 09:37:19.208: INFO: Unable to read wheezy_udp@dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:19.212: INFO: Unable to read wheezy_tcp@dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:19.215: INFO: Unable to read wheezy_udp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:19.220: INFO: Unable to read wheezy_tcp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:19.245: INFO: Unable to read jessie_udp@dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:19.248: INFO: Unable to read jessie_tcp@dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:19.251: INFO: Unable to read jessie_udp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:19.254: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:19.273: INFO: Lookups using dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec failed for: [wheezy_udp@dns-test-service.dns-3656.svc.cluster.local wheezy_tcp@dns-test-service.dns-3656.svc.cluster.local wheezy_udp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local wheezy_tcp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local jessie_udp@dns-test-service.dns-3656.svc.cluster.local jessie_tcp@dns-test-service.dns-3656.svc.cluster.local jessie_udp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local jessie_tcp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local]

Dec 20 09:37:24.254: INFO: Unable to read jessie_tcp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local from pod dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec: the server could not find the requested resource (get pods dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec)
Dec 20 09:37:24.272: INFO: Lookups using dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec failed for: [jessie_tcp@_http._tcp.dns-test-service.dns-3656.svc.cluster.local]

Dec 20 09:37:29.280: INFO: DNS probes using dns-3656/dns-test-1b365c7d-f727-4b6f-b0ea-596e313f0bec succeeded

STEP: deleting the pod
STEP: deleting the test service
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:37:29.314: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-3656" for this suite.
Dec 20 09:37:35.328: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:37:35.422: INFO: namespace dns-3656 deletion completed in 6.104172616s

• [SLOW TEST:49.452 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for services  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[k8s.io] [sig-node] Events 
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:37:35.422: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename events
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in events-9487
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: retrieving the pod
Dec 20 09:37:39.572: INFO: &Pod{ObjectMeta:{send-events-8cf9669d-e8ab-4f3b-9571-f34dc31e91de  events-9487 /api/v1/namespaces/events-9487/pods/send-events-8cf9669d-e8ab-4f3b-9571-f34dc31e91de 4865251c-dae3-41f5-921d-abc4f7f1ea6a 114535 0 2019-12-20 09:37:35 +0000 UTC <nil> <nil> map[name:foo time:552395118] map[kubernetes.io/psp:e2e-test-privileged-psp] [] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-fh2fw,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-fh2fw,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:p,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,Command:[],Args:[serve-hostname],WorkingDir:,Ports:[]ContainerPort{ContainerPort{Name:,HostPort:0,ContainerPort:80,Protocol:TCP,HostIP:,},},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-fh2fw,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*30,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-4,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:37:36 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:37:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:37:38 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 09:37:35 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.84.149.232,PodIP:10.244.5.168,StartTime:2019-12-20 09:37:36 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:p,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-20 09:37:37 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:gcr.io/kubernetes-e2e-test-images/agnhost:2.6,ImageID:gcr.io/kubernetes-e2e-test-images/agnhost@sha256:4057a5580c7b59c4fe10d8ab2732c9dec35eea80fd41f7bafc7bd5acc7edf727,ContainerID:cri-o://baf54ec080f57f17fc356825683109ae08927e67b1fd4250932eb31fc908a8e0,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.5.168,},},EphemeralContainerStatuses:[]ContainerStatus{},},}

STEP: checking for scheduler event about the pod
Dec 20 09:37:41.576: INFO: Saw scheduler event for our pod.
STEP: checking for kubelet event about the pod
Dec 20 09:37:43.581: INFO: Saw kubelet event for our pod.
STEP: deleting the pod
[AfterEach] [k8s.io] [sig-node] Events
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:37:43.586: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "events-9487" for this suite.
Dec 20 09:38:27.603: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:38:27.692: INFO: namespace events-9487 deletion completed in 44.101451307s

• [SLOW TEST:52.270 seconds]
[k8s.io] [sig-node] Events
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be sent by kubelets and the scheduler about pods scheduling and running  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] ConfigMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:38:27.692: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-1646
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-97358c08-76ab-4860-ab33-14cd588d12c6
STEP: Creating configMap with name cm-test-opt-upd-4db7f86d-4761-4545-bf01-54461d761602
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-97358c08-76ab-4860-ab33-14cd588d12c6
STEP: Updating configmap cm-test-opt-upd-4db7f86d-4761-4545-bf01-54461d761602
STEP: Creating configMap with name cm-test-opt-create-a1e0908e-c807-4ac0-9968-65ef1db4d29a
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:39:56.264: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-1646" for this suite.
Dec 20 09:40:08.278: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:40:08.369: INFO: namespace configmap-1646 deletion completed in 12.101536123s

• [SLOW TEST:100.677 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl describe 
  should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:40:08.370: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-8830
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if kubectl describe prints relevant information for rc and pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 09:40:08.502: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 create -f - --namespace=kubectl-8830'
Dec 20 09:40:08.750: INFO: stderr: ""
Dec 20 09:40:08.750: INFO: stdout: "replicationcontroller/redis-master created\n"
Dec 20 09:40:08.750: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 create -f - --namespace=kubectl-8830'
Dec 20 09:40:08.932: INFO: stderr: ""
Dec 20 09:40:08.932: INFO: stdout: "service/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 20 09:40:09.938: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 09:40:09.938: INFO: Found 0 / 1
Dec 20 09:40:10.937: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 09:40:10.937: INFO: Found 1 / 1
Dec 20 09:40:10.937: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 20 09:40:10.941: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 09:40:10.941: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 20 09:40:10.941: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 describe pod redis-master-5dfcd --namespace=kubectl-8830'
Dec 20 09:40:11.059: INFO: stderr: ""
Dec 20 09:40:11.059: INFO: stdout: "Name:         redis-master-5dfcd\nNamespace:    kubectl-8830\nPriority:     0\nNode:         caasp-worker-th-before-3/10.84.149.226\nStart Time:   Fri, 20 Dec 2019 09:40:09 +0000\nLabels:       app=redis\n              role=master\nAnnotations:  kubernetes.io/psp: e2e-test-privileged-psp\nStatus:       Running\nIP:           10.244.6.110\nIPs:\n  IP:           10.244.6.110\nControlled By:  ReplicationController/redis-master\nContainers:\n  redis-master:\n    Container ID:   cri-o://96c441237a67817fb8069dda54eb341799236ce6aa3e529dec909126a0318101\n    Image:          docker.io/library/redis:5.0.5-alpine\n    Image ID:       docker.io/library/redis@sha256:50899ea1ceed33fa03232f3ac57578a424faa1742c1ac9c7a7bdb95cdf19b858\n    Port:           6379/TCP\n    Host Port:      0/TCP\n    State:          Running\n      Started:      Fri, 20 Dec 2019 09:40:11 +0000\n    Ready:          True\n    Restart Count:  0\n    Environment:    <none>\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from default-token-t97b6 (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             True \n  ContainersReady   True \n  PodScheduled      True \nVolumes:\n  default-token-t97b6:\n    Type:        Secret (a volume populated by a Secret)\n    SecretName:  default-token-t97b6\n    Optional:    false\nQoS Class:       BestEffort\nNode-Selectors:  <none>\nTolerations:     node.kubernetes.io/not-ready:NoExecute for 300s\n                 node.kubernetes.io/unreachable:NoExecute for 300s\nEvents:\n  Type    Reason     Age        From                               Message\n  ----    ------     ----       ----                               -------\n  Normal  Scheduled  <unknown>  default-scheduler                  Successfully assigned kubectl-8830/redis-master-5dfcd to caasp-worker-th-before-3\n  Normal  Pulled     0s         kubelet, caasp-worker-th-before-3  Container image \"docker.io/library/redis:5.0.5-alpine\" already present on machine\n  Normal  Created    0s         kubelet, caasp-worker-th-before-3  Created container redis-master\n  Normal  Started    0s         kubelet, caasp-worker-th-before-3  Started container redis-master\n"
Dec 20 09:40:11.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 describe rc redis-master --namespace=kubectl-8830'
Dec 20 09:40:11.185: INFO: stderr: ""
Dec 20 09:40:11.185: INFO: stdout: "Name:         redis-master\nNamespace:    kubectl-8830\nSelector:     app=redis,role=master\nLabels:       app=redis\n              role=master\nAnnotations:  <none>\nReplicas:     1 current / 1 desired\nPods Status:  1 Running / 0 Waiting / 0 Succeeded / 0 Failed\nPod Template:\n  Labels:  app=redis\n           role=master\n  Containers:\n   redis-master:\n    Image:        docker.io/library/redis:5.0.5-alpine\n    Port:         6379/TCP\n    Host Port:    0/TCP\n    Environment:  <none>\n    Mounts:       <none>\n  Volumes:        <none>\nEvents:\n  Type    Reason            Age   From                    Message\n  ----    ------            ----  ----                    -------\n  Normal  SuccessfulCreate  2s    replication-controller  Created pod: redis-master-5dfcd\n"
Dec 20 09:40:11.185: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 describe service redis-master --namespace=kubectl-8830'
Dec 20 09:40:11.295: INFO: stderr: ""
Dec 20 09:40:11.295: INFO: stdout: "Name:              redis-master\nNamespace:         kubectl-8830\nLabels:            app=redis\n                   role=master\nAnnotations:       <none>\nSelector:          app=redis,role=master\nType:              ClusterIP\nIP:                10.102.17.160\nPort:              <unset>  6379/TCP\nTargetPort:        redis-server/TCP\nEndpoints:         10.244.6.110:6379\nSession Affinity:  None\nEvents:            <none>\n"
Dec 20 09:40:11.302: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 describe node caasp-master-th-before-0'
Dec 20 09:40:11.429: INFO: stderr: ""
Dec 20 09:40:11.429: INFO: stdout: "Name:               caasp-master-th-before-0\nRoles:              master\nLabels:             beta.kubernetes.io/arch=amd64\n                    beta.kubernetes.io/os=linux\n                    kubernetes.io/arch=amd64\n                    kubernetes.io/hostname=caasp-master-th-before-0\n                    kubernetes.io/os=linux\n                    node-role.kubernetes.io/master=\nAnnotations:        caasp.suse.com/has-disruptive-updates: no\n                    caasp.suse.com/has-security-updates: no\n                    caasp.suse.com/has-updates: no\n                    io.cilium.network.ipv4-cilium-host: 10.244.0.1\n                    io.cilium.network.ipv4-health-ip: 10.244.0.86\n                    io.cilium.network.ipv4-pod-cidr: 10.244.0.0/24\n                    kubeadm.alpha.kubernetes.io/cri-socket: /var/run/crio/crio.sock\n                    node.alpha.kubernetes.io/ttl: 0\n                    volumes.kubernetes.io/controller-managed-attach-detach: true\nCreationTimestamp:  Thu, 19 Dec 2019 22:42:08 +0000\nTaints:             node-role.kubernetes.io/master:NoSchedule\nUnschedulable:      false\nConditions:\n  Type                 Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message\n  ----                 ------  -----------------                 ------------------                ------                       -------\n  NetworkUnavailable   False   Thu, 19 Dec 2019 23:38:27 +0000   Thu, 19 Dec 2019 23:38:27 +0000   CiliumIsUp                   Cilium is running on this node\n  MemoryPressure       False   Fri, 20 Dec 2019 09:39:13 +0000   Thu, 19 Dec 2019 22:42:02 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available\n  DiskPressure         False   Fri, 20 Dec 2019 09:39:13 +0000   Thu, 19 Dec 2019 22:42:02 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure\n  PIDPressure          False   Fri, 20 Dec 2019 09:39:13 +0000   Thu, 19 Dec 2019 22:42:02 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available\n  Ready                True    Fri, 20 Dec 2019 09:39:13 +0000   Thu, 19 Dec 2019 22:43:18 +0000   KubeletReady                 kubelet is posting ready status. AppArmor enabled\nAddresses:\n  InternalIP:  10.84.149.220\n  Hostname:    caasp-master-th-before-0\nCapacity:\n cpu:                24\n ephemeral-storage:  553927964Ki\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             98945740Ki\n pods:               110\nAllocatable:\n cpu:                24\n ephemeral-storage:  510500010778\n hugepages-1Gi:      0\n hugepages-2Mi:      0\n memory:             98843340Ki\n pods:               110\nSystem Info:\n Machine ID:                 0dce28065bac49aeb53661ec0a960b7c\n System UUID:                30313436-3631-5355-4534-32305942574c\n Boot ID:                    b48a539c-548e-473d-b0b1-ec33b62af7d4\n Kernel Version:             4.12.14-197.29-default\n OS Image:                   SUSE Linux Enterprise Server 15 SP1\n Operating System:           linux\n Architecture:               amd64\n Container Runtime Version:  cri-o://1.16.0\n Kubelet Version:            v1.16.2\n Kube-Proxy Version:         v1.16.2\nPodCIDR:                     10.244.0.0/24\nPodCIDRs:                    10.244.0.0/24\nNon-terminated Pods:         (14 in total)\n  Namespace                  Name                                                CPU Requests  CPU Limits  Memory Requests  Memory Limits  AGE\n  ---------                  ----                                                ------------  ----------  ---------------  -------------  ---\n  kube-system                cilium-operator-97cfc4756-6rfsp                     0 (0%)        0 (0%)      0 (0%)           0 (0%)         10h\n  kube-system                cilium-s26lj                                        0 (0%)        0 (0%)      0 (0%)           0 (0%)         10h\n  kube-system                coredns-88dfb894c-7d2fx                             100m (0%)     0 (0%)      70Mi (0%)        170Mi (0%)     10h\n  kube-system                coredns-88dfb894c-fhggx                             100m (0%)     0 (0%)      70Mi (0%)        170Mi (0%)     10h\n  kube-system                etcd-caasp-master-th-before-0                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         10h\n  kube-system                kube-apiserver-caasp-master-th-before-0             250m (1%)     0 (0%)      0 (0%)           0 (0%)         10h\n  kube-system                kube-controller-manager-caasp-master-th-before-0    200m (0%)     0 (0%)      0 (0%)           0 (0%)         10h\n  kube-system                kube-proxy-x856n                                    0 (0%)        0 (0%)      0 (0%)           0 (0%)         10h\n  kube-system                kube-scheduler-caasp-master-th-before-0             100m (0%)     0 (0%)      0 (0%)           0 (0%)         10h\n  kube-system                kured-r7zj9                                         0 (0%)        0 (0%)      0 (0%)           0 (0%)         10h\n  kube-system                oidc-gangway-5f7496c7df-24mcg                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         10h\n  kube-system                oidc-gangway-5f7496c7df-jnmkk                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         10h\n  kube-system                oidc-gangway-5f7496c7df-k4mgp                       0 (0%)        0 (0%)      0 (0%)           0 (0%)         10h\n  sonobuoy                   sonobuoy-e2e-job-c8d94badbd054e00                   0 (0%)        0 (0%)      0 (0%)           0 (0%)         33m\nAllocated resources:\n  (Total limits may be over 100 percent, i.e., overcommitted.)\n  Resource           Requests    Limits\n  --------           --------    ------\n  cpu                750m (3%)   0 (0%)\n  memory             140Mi (0%)  340Mi (0%)\n  ephemeral-storage  0 (0%)      0 (0%)\nEvents:\n  Type     Reason         Age                  From                               Message\n  ----     ------         ----                 ----                               -------\n  Warning  ImageGCFailed  2m6s (x120 over 9h)  kubelet, caasp-master-th-before-0  failed to get imageFs info: non-existent label \"crio-images\"\n"
Dec 20 09:40:11.429: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 describe namespace kubectl-8830'
Dec 20 09:40:11.536: INFO: stderr: ""
Dec 20 09:40:11.536: INFO: stdout: "Name:         kubectl-8830\nLabels:       e2e-framework=kubectl\n              e2e-run=358dda68-3951-4246-aaaa-1f6659ce6c8a\nAnnotations:  <none>\nStatus:       Active\n\nNo resource quota.\n\nNo resource limits.\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:40:11.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-8830" for this suite.
Dec 20 09:40:39.550: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:40:39.640: INFO: namespace kubectl-8830 deletion completed in 28.100704513s

• [SLOW TEST:31.271 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl describe
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1000
    should check if kubectl describe prints relevant information for rc and pods  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:40:39.641: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-6122
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 20 09:40:39.779: INFO: Waiting up to 5m0s for pod "downwardapi-volume-f27536e1-b3c7-46d1-ad1f-eaf868fac97a" in namespace "downward-api-6122" to be "success or failure"
Dec 20 09:40:39.782: INFO: Pod "downwardapi-volume-f27536e1-b3c7-46d1-ad1f-eaf868fac97a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.497766ms
Dec 20 09:40:41.786: INFO: Pod "downwardapi-volume-f27536e1-b3c7-46d1-ad1f-eaf868fac97a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006644586s
Dec 20 09:40:43.790: INFO: Pod "downwardapi-volume-f27536e1-b3c7-46d1-ad1f-eaf868fac97a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01055324s
STEP: Saw pod success
Dec 20 09:40:43.790: INFO: Pod "downwardapi-volume-f27536e1-b3c7-46d1-ad1f-eaf868fac97a" satisfied condition "success or failure"
Dec 20 09:40:43.793: INFO: Trying to get logs from node caasp-worker-th-before-0 pod downwardapi-volume-f27536e1-b3c7-46d1-ad1f-eaf868fac97a container client-container: <nil>
STEP: delete the pod
Dec 20 09:40:43.822: INFO: Waiting for pod downwardapi-volume-f27536e1-b3c7-46d1-ad1f-eaf868fac97a to disappear
Dec 20 09:40:43.825: INFO: Pod downwardapi-volume-f27536e1-b3c7-46d1-ad1f-eaf868fac97a no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:40:43.825: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-6122" for this suite.
Dec 20 09:40:49.838: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:40:49.930: INFO: namespace downward-api-6122 deletion completed in 6.101548823s

• [SLOW TEST:10.289 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:40:49.930: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-3642
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 20 09:40:52.078: INFO: Expected: &{OK} to match Container's Termination Message: OK --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:40:52.089: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-3642" for this suite.
Dec 20 09:40:58.105: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:40:58.197: INFO: namespace container-runtime-3642 deletion completed in 6.104126392s

• [SLOW TEST:8.266 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:40:58.197: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-9210
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 20 09:40:58.328: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 20 09:40:58.340: INFO: Waiting for terminating namespaces to be deleted...
Dec 20 09:40:58.343: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-th-before-0 before test
Dec 20 09:40:58.351: INFO: cilium-srq5l from kube-system started at 2019-12-19 23:00:47 +0000 UTC (1 container statuses recorded)
Dec 20 09:40:58.351: INFO: 	Container cilium-agent ready: true, restart count 1
Dec 20 09:40:58.351: INFO: kube-proxy-m8mx6 from kube-system started at 2019-12-19 23:00:47 +0000 UTC (1 container statuses recorded)
Dec 20 09:40:58.351: INFO: 	Container kube-proxy ready: true, restart count 1
Dec 20 09:40:58.351: INFO: sonobuoy from sonobuoy started at 2019-12-20 09:06:03 +0000 UTC (1 container statuses recorded)
Dec 20 09:40:58.351: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 20 09:40:58.351: INFO: kured-cvqgx from kube-system started at 2019-12-19 23:02:27 +0000 UTC (1 container statuses recorded)
Dec 20 09:40:58.351: INFO: 	Container kured ready: true, restart count 1
Dec 20 09:40:58.351: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-th-before-3 before test
Dec 20 09:40:58.374: INFO: tiller-deploy-6b954db788-gjd4h from kube-system started at 2019-12-19 23:05:50 +0000 UTC (1 container statuses recorded)
Dec 20 09:40:58.374: INFO: 	Container tiller ready: true, restart count 7
Dec 20 09:40:58.374: INFO: kube-proxy-frbl9 from kube-system started at 2019-12-19 23:00:46 +0000 UTC (1 container statuses recorded)
Dec 20 09:40:58.374: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 20 09:40:58.374: INFO: cilium-sm7nn from kube-system started at 2019-12-19 23:00:46 +0000 UTC (1 container statuses recorded)
Dec 20 09:40:58.374: INFO: 	Container cilium-agent ready: true, restart count 4
Dec 20 09:40:58.374: INFO: kured-ddrtt from kube-system started at 2019-12-19 23:01:46 +0000 UTC (1 container statuses recorded)
Dec 20 09:40:58.374: INFO: 	Container kured ready: true, restart count 0
Dec 20 09:40:58.374: INFO: oidc-dex-799996b768-8xqtt from kube-system started at 2019-12-19 23:24:29 +0000 UTC (1 container statuses recorded)
Dec 20 09:40:58.374: INFO: 	Container oidc-dex ready: true, restart count 0
Dec 20 09:40:58.374: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-th-before-4 before test
Dec 20 09:40:58.380: INFO: kured-zktcs from kube-system started at 2019-12-19 23:01:56 +0000 UTC (1 container statuses recorded)
Dec 20 09:40:58.380: INFO: 	Container kured ready: true, restart count 0
Dec 20 09:40:58.380: INFO: cilium-nllss from kube-system started at 2019-12-19 23:00:46 +0000 UTC (1 container statuses recorded)
Dec 20 09:40:58.380: INFO: 	Container cilium-agent ready: true, restart count 4
Dec 20 09:40:58.380: INFO: kube-proxy-qcm45 from kube-system started at 2019-12-19 23:00:46 +0000 UTC (1 container statuses recorded)
Dec 20 09:40:58.380: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 20 09:40:58.380: INFO: oidc-dex-799996b768-4r6tn from kube-system started at 2019-12-19 23:24:29 +0000 UTC (1 container statuses recorded)
Dec 20 09:40:58.380: INFO: 	Container oidc-dex ready: true, restart count 0
[It] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-57d3ab34-f8fd-43f9-bad4-cd94ca7ba49c 95
STEP: Trying to create a pod(pod4) with hostport 54322 and hostIP 0.0.0.0(empty string here) and expect scheduled
STEP: Trying to create another pod(pod5) with hostport 54322 but hostIP 127.0.0.1 on the node which pod4 resides and expect not scheduled
STEP: removing the label kubernetes.io/e2e-57d3ab34-f8fd-43f9-bad4-cd94ca7ba49c off the node caasp-worker-th-before-3
STEP: verifying the node doesn't have the label kubernetes.io/e2e-57d3ab34-f8fd-43f9-bad4-cd94ca7ba49c
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:46:10.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-9210" for this suite.
Dec 20 09:46:28.458: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:46:28.559: INFO: namespace sched-pred-9210 deletion completed in 18.110466995s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:330.362 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Job 
  should delete a job [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:46:28.559: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-7627
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete a job [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring active pods == parallelism
STEP: delete a job
STEP: deleting Job.batch foo in namespace job-7627, will wait for the garbage collector to delete the pods
Dec 20 09:46:32.759: INFO: Deleting Job.batch foo took: 6.847257ms
Dec 20 09:46:33.160: INFO: Terminating Job.batch foo pods took: 400.280822ms
STEP: Ensuring job was deleted
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:47:15.663: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-7627" for this suite.
Dec 20 09:47:21.678: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:47:21.773: INFO: namespace job-7627 deletion completed in 6.105815005s

• [SLOW TEST:53.213 seconds]
[sig-apps] Job
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should delete a job [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:47:21.773: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-5577
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-f86r
STEP: Creating a pod to test atomic-volume-subpath
Dec 20 09:47:21.919: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-f86r" in namespace "subpath-5577" to be "success or failure"
Dec 20 09:47:21.922: INFO: Pod "pod-subpath-test-configmap-f86r": Phase="Pending", Reason="", readiness=false. Elapsed: 2.626951ms
Dec 20 09:47:23.926: INFO: Pod "pod-subpath-test-configmap-f86r": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006479625s
Dec 20 09:47:25.930: INFO: Pod "pod-subpath-test-configmap-f86r": Phase="Running", Reason="", readiness=true. Elapsed: 4.010858912s
Dec 20 09:47:27.934: INFO: Pod "pod-subpath-test-configmap-f86r": Phase="Running", Reason="", readiness=true. Elapsed: 6.014781401s
Dec 20 09:47:29.937: INFO: Pod "pod-subpath-test-configmap-f86r": Phase="Running", Reason="", readiness=true. Elapsed: 8.018394578s
Dec 20 09:47:31.941: INFO: Pod "pod-subpath-test-configmap-f86r": Phase="Running", Reason="", readiness=true. Elapsed: 10.022113169s
Dec 20 09:47:33.945: INFO: Pod "pod-subpath-test-configmap-f86r": Phase="Running", Reason="", readiness=true. Elapsed: 12.026003938s
Dec 20 09:47:35.950: INFO: Pod "pod-subpath-test-configmap-f86r": Phase="Running", Reason="", readiness=true. Elapsed: 14.031083882s
Dec 20 09:47:37.955: INFO: Pod "pod-subpath-test-configmap-f86r": Phase="Running", Reason="", readiness=true. Elapsed: 16.035531421s
Dec 20 09:47:39.958: INFO: Pod "pod-subpath-test-configmap-f86r": Phase="Running", Reason="", readiness=true. Elapsed: 18.039069892s
Dec 20 09:47:41.962: INFO: Pod "pod-subpath-test-configmap-f86r": Phase="Running", Reason="", readiness=true. Elapsed: 20.042963501s
Dec 20 09:47:43.966: INFO: Pod "pod-subpath-test-configmap-f86r": Phase="Running", Reason="", readiness=true. Elapsed: 22.04733361s
Dec 20 09:47:45.973: INFO: Pod "pod-subpath-test-configmap-f86r": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.053523621s
STEP: Saw pod success
Dec 20 09:47:45.973: INFO: Pod "pod-subpath-test-configmap-f86r" satisfied condition "success or failure"
Dec 20 09:47:45.976: INFO: Trying to get logs from node caasp-worker-th-before-3 pod pod-subpath-test-configmap-f86r container test-container-subpath-configmap-f86r: <nil>
STEP: delete the pod
Dec 20 09:47:46.007: INFO: Waiting for pod pod-subpath-test-configmap-f86r to disappear
Dec 20 09:47:46.009: INFO: Pod pod-subpath-test-configmap-f86r no longer exists
STEP: Deleting pod pod-subpath-test-configmap-f86r
Dec 20 09:47:46.009: INFO: Deleting pod "pod-subpath-test-configmap-f86r" in namespace "subpath-5577"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:47:46.011: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-5577" for this suite.
Dec 20 09:47:52.025: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:47:52.129: INFO: namespace subpath-5577 deletion completed in 6.113867972s

• [SLOW TEST:30.356 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:47:52.129: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-830
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should be possible to delete [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:47:52.278: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-830" for this suite.
Dec 20 09:47:58.291: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:47:58.392: INFO: namespace kubelet-test-830 deletion completed in 6.110662682s

• [SLOW TEST:6.263 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should be possible to delete [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:47:58.393: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-586
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicationController
STEP: Ensuring resource quota status captures replication controller creation
STEP: Deleting a ReplicationController
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:48:09.558: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-586" for this suite.
Dec 20 09:48:15.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:48:15.664: INFO: namespace resourcequota-586 deletion completed in 6.101664495s

• [SLOW TEST:17.272 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replication controller. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:48:15.665: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9817
STEP: Waiting for a default service account to be provisioned in namespace
[It] binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-881b76a1-85aa-4c71-92e3-ac2050010136
STEP: Creating the pod
STEP: Waiting for pod with text data
STEP: Waiting for pod with binary data
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:48:19.829: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9817" for this suite.
Dec 20 09:48:37.843: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:48:37.938: INFO: namespace configmap-9817 deletion completed in 18.105603916s

• [SLOW TEST:22.273 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  binary data should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:48:37.938: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-4177
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service endpoint-test2 in namespace services-4177
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4177 to expose endpoints map[]
Dec 20 09:48:38.083: INFO: Get endpoints failed (2.269043ms elapsed, ignoring for 5s): endpoints "endpoint-test2" not found
Dec 20 09:48:39.087: INFO: successfully validated that service endpoint-test2 in namespace services-4177 exposes endpoints map[] (1.00597094s elapsed)
STEP: Creating pod pod1 in namespace services-4177
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4177 to expose endpoints map[pod1:[80]]
Dec 20 09:48:42.125: INFO: successfully validated that service endpoint-test2 in namespace services-4177 exposes endpoints map[pod1:[80]] (3.026305358s elapsed)
STEP: Creating pod pod2 in namespace services-4177
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4177 to expose endpoints map[pod1:[80] pod2:[80]]
Dec 20 09:48:45.164: INFO: successfully validated that service endpoint-test2 in namespace services-4177 exposes endpoints map[pod1:[80] pod2:[80]] (3.03443307s elapsed)
STEP: Deleting pod pod1 in namespace services-4177
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4177 to expose endpoints map[pod2:[80]]
Dec 20 09:48:46.181: INFO: successfully validated that service endpoint-test2 in namespace services-4177 exposes endpoints map[pod2:[80]] (1.012229979s elapsed)
STEP: Deleting pod pod2 in namespace services-4177
STEP: waiting up to 3m0s for service endpoint-test2 in namespace services-4177 to expose endpoints map[]
Dec 20 09:48:47.192: INFO: successfully validated that service endpoint-test2 in namespace services-4177 exposes endpoints map[] (1.005463258s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:48:47.209: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-4177" for this suite.
Dec 20 09:48:59.223: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:48:59.327: INFO: namespace services-4177 deletion completed in 12.114290937s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:21.389 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve a basic endpoint from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:48:59.327: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8443
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 20 09:48:59.473: INFO: Waiting up to 5m0s for pod "pod-c7eddea6-3b63-4602-9def-dafc8c190d1f" in namespace "emptydir-8443" to be "success or failure"
Dec 20 09:48:59.476: INFO: Pod "pod-c7eddea6-3b63-4602-9def-dafc8c190d1f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.794932ms
Dec 20 09:49:01.480: INFO: Pod "pod-c7eddea6-3b63-4602-9def-dafc8c190d1f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006526459s
Dec 20 09:49:03.484: INFO: Pod "pod-c7eddea6-3b63-4602-9def-dafc8c190d1f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010622577s
STEP: Saw pod success
Dec 20 09:49:03.484: INFO: Pod "pod-c7eddea6-3b63-4602-9def-dafc8c190d1f" satisfied condition "success or failure"
Dec 20 09:49:03.487: INFO: Trying to get logs from node caasp-worker-th-before-3 pod pod-c7eddea6-3b63-4602-9def-dafc8c190d1f container test-container: <nil>
STEP: delete the pod
Dec 20 09:49:03.503: INFO: Waiting for pod pod-c7eddea6-3b63-4602-9def-dafc8c190d1f to disappear
Dec 20 09:49:03.505: INFO: Pod pod-c7eddea6-3b63-4602-9def-dafc8c190d1f no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:49:03.505: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8443" for this suite.
Dec 20 09:49:09.519: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:49:09.612: INFO: namespace emptydir-8443 deletion completed in 6.103681269s

• [SLOW TEST:10.285 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:49:09.613: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-4301
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 20 09:49:09.748: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 20 09:49:09.762: INFO: Waiting for terminating namespaces to be deleted...
Dec 20 09:49:09.765: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-th-before-0 before test
Dec 20 09:49:09.782: INFO: kube-proxy-m8mx6 from kube-system started at 2019-12-19 23:00:47 +0000 UTC (1 container statuses recorded)
Dec 20 09:49:09.782: INFO: 	Container kube-proxy ready: true, restart count 1
Dec 20 09:49:09.782: INFO: sonobuoy from sonobuoy started at 2019-12-20 09:06:03 +0000 UTC (1 container statuses recorded)
Dec 20 09:49:09.782: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 20 09:49:09.782: INFO: kured-cvqgx from kube-system started at 2019-12-19 23:02:27 +0000 UTC (1 container statuses recorded)
Dec 20 09:49:09.782: INFO: 	Container kured ready: true, restart count 1
Dec 20 09:49:09.782: INFO: cilium-srq5l from kube-system started at 2019-12-19 23:00:47 +0000 UTC (1 container statuses recorded)
Dec 20 09:49:09.782: INFO: 	Container cilium-agent ready: true, restart count 1
Dec 20 09:49:09.782: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-th-before-3 before test
Dec 20 09:49:09.788: INFO: cilium-sm7nn from kube-system started at 2019-12-19 23:00:46 +0000 UTC (1 container statuses recorded)
Dec 20 09:49:09.788: INFO: 	Container cilium-agent ready: true, restart count 4
Dec 20 09:49:09.788: INFO: oidc-dex-799996b768-8xqtt from kube-system started at 2019-12-19 23:24:29 +0000 UTC (1 container statuses recorded)
Dec 20 09:49:09.788: INFO: 	Container oidc-dex ready: true, restart count 0
Dec 20 09:49:09.788: INFO: kured-ddrtt from kube-system started at 2019-12-19 23:01:46 +0000 UTC (1 container statuses recorded)
Dec 20 09:49:09.788: INFO: 	Container kured ready: true, restart count 0
Dec 20 09:49:09.788: INFO: tiller-deploy-6b954db788-gjd4h from kube-system started at 2019-12-19 23:05:50 +0000 UTC (1 container statuses recorded)
Dec 20 09:49:09.788: INFO: 	Container tiller ready: true, restart count 7
Dec 20 09:49:09.788: INFO: kube-proxy-frbl9 from kube-system started at 2019-12-19 23:00:46 +0000 UTC (1 container statuses recorded)
Dec 20 09:49:09.788: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 20 09:49:09.788: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-th-before-4 before test
Dec 20 09:49:09.807: INFO: cilium-nllss from kube-system started at 2019-12-19 23:00:46 +0000 UTC (1 container statuses recorded)
Dec 20 09:49:09.807: INFO: 	Container cilium-agent ready: true, restart count 4
Dec 20 09:49:09.807: INFO: kube-proxy-qcm45 from kube-system started at 2019-12-19 23:00:46 +0000 UTC (1 container statuses recorded)
Dec 20 09:49:09.807: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 20 09:49:09.807: INFO: oidc-dex-799996b768-4r6tn from kube-system started at 2019-12-19 23:24:29 +0000 UTC (1 container statuses recorded)
Dec 20 09:49:09.807: INFO: 	Container oidc-dex ready: true, restart count 0
Dec 20 09:49:09.807: INFO: kured-zktcs from kube-system started at 2019-12-19 23:01:56 +0000 UTC (1 container statuses recorded)
Dec 20 09:49:09.807: INFO: 	Container kured ready: true, restart count 0
[It] validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-34a6747d-76c5-4589-8603-be3a569530cb 42
STEP: Trying to relaunch the pod, now with labels.
STEP: removing the label kubernetes.io/e2e-34a6747d-76c5-4589-8603-be3a569530cb off the node caasp-worker-th-before-4
STEP: verifying the node doesn't have the label kubernetes.io/e2e-34a6747d-76c5-4589-8603-be3a569530cb
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:49:17.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-4301" for this suite.
Dec 20 09:49:25.882: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:49:25.962: INFO: namespace sched-pred-4301 deletion completed in 8.091130815s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:16.350 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:49:25.963: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-8524
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 20 09:49:26.721: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 20 09:49:28.731: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432167, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432167, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432167, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432167, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 20 09:49:31.749: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate configmap [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating configmap webhook via the AdmissionRegistration API
STEP: create a configmap that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:49:31.783: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-8524" for this suite.
Dec 20 09:49:37.797: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:49:37.890: INFO: namespace webhook-8524 deletion completed in 6.102355568s
STEP: Destroying namespace "webhook-8524-markers" for this suite.
Dec 20 09:49:43.900: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:49:43.994: INFO: namespace webhook-8524-markers deletion completed in 6.103517924s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.043 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate configmap [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:49:44.006: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3562
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 20 09:49:45.270: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 20 09:49:47.289: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432186, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432186, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432186, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432186, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 20 09:49:50.305: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the mutating pod webhook via the AdmissionRegistration API
STEP: create a pod that should be updated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:49:50.347: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3562" for this suite.
Dec 20 09:50:02.361: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:50:02.457: INFO: namespace webhook-3562 deletion completed in 12.106169296s
STEP: Destroying namespace "webhook-3562-markers" for this suite.
Dec 20 09:50:08.468: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:50:08.563: INFO: namespace webhook-3562-markers deletion completed in 6.106371743s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:24.570 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate pod and apply defaults after mutation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Projected combined 
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:50:08.576: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3185
STEP: Waiting for a default service account to be provisioned in namespace
[It] should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-projected-all-test-volume-4ad300be-501f-4592-9905-7151e4bb79ed
STEP: Creating secret with name secret-projected-all-test-volume-54d5adcc-889a-4e95-aa8c-32f108fce47d
STEP: Creating a pod to test Check all projections for projected volume plugin
Dec 20 09:50:08.724: INFO: Waiting up to 5m0s for pod "projected-volume-06750af4-c5d6-43db-83ea-383b2447ca5c" in namespace "projected-3185" to be "success or failure"
Dec 20 09:50:08.727: INFO: Pod "projected-volume-06750af4-c5d6-43db-83ea-383b2447ca5c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.612499ms
Dec 20 09:50:10.730: INFO: Pod "projected-volume-06750af4-c5d6-43db-83ea-383b2447ca5c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006514628s
Dec 20 09:50:12.736: INFO: Pod "projected-volume-06750af4-c5d6-43db-83ea-383b2447ca5c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011810494s
STEP: Saw pod success
Dec 20 09:50:12.736: INFO: Pod "projected-volume-06750af4-c5d6-43db-83ea-383b2447ca5c" satisfied condition "success or failure"
Dec 20 09:50:12.739: INFO: Trying to get logs from node caasp-worker-th-before-0 pod projected-volume-06750af4-c5d6-43db-83ea-383b2447ca5c container projected-all-volume-test: <nil>
STEP: delete the pod
Dec 20 09:50:12.755: INFO: Waiting for pod projected-volume-06750af4-c5d6-43db-83ea-383b2447ca5c to disappear
Dec 20 09:50:12.757: INFO: Pod projected-volume-06750af4-c5d6-43db-83ea-383b2447ca5c no longer exists
[AfterEach] [sig-storage] Projected combined
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:50:12.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3185" for this suite.
Dec 20 09:50:18.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:50:18.862: INFO: namespace projected-3185 deletion completed in 6.100881024s

• [SLOW TEST:10.286 seconds]
[sig-storage] Projected combined
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_combined.go:32
  should project all components that make up the projection API [Projection][NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:50:18.862: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-2677
STEP: Waiting for a default service account to be provisioned in namespace
[It] should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a ReplicationController is created
STEP: When the matched label of one of its pods change
Dec 20 09:50:19.002: INFO: Pod name pod-release: Found 0 pods out of 1
Dec 20 09:50:24.007: INFO: Pod name pod-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:50:25.020: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-2677" for this suite.
Dec 20 09:50:31.036: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:50:31.130: INFO: namespace replication-controller-2677 deletion completed in 6.106177091s

• [SLOW TEST:12.268 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:50:31.131: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-53
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-53.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@dns-test-service-2.dns-53.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-53.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@dns-test-service-2.dns-53.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-53.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local;check="$$(dig +notcp +noall +answer +search dns-test-service-2.dns-53.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@dns-test-service-2.dns-53.svc.cluster.local;check="$$(dig +tcp +noall +answer +search dns-test-service-2.dns-53.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@dns-test-service-2.dns-53.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-53.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 20 09:50:49.286: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:49.289: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:49.293: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:49.296: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:49.305: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:49.308: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:49.312: INFO: Unable to read jessie_udp@dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:49.315: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:49.320: INFO: Lookups using dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local wheezy_udp@dns-test-service-2.dns-53.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-53.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local jessie_udp@dns-test-service-2.dns-53.svc.cluster.local jessie_tcp@dns-test-service-2.dns-53.svc.cluster.local]

Dec 20 09:50:54.326: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:54.330: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:54.334: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:54.337: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:54.348: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:54.351: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:54.354: INFO: Unable to read jessie_udp@dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:54.357: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:54.363: INFO: Lookups using dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local wheezy_udp@dns-test-service-2.dns-53.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-53.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local jessie_udp@dns-test-service-2.dns-53.svc.cluster.local jessie_tcp@dns-test-service-2.dns-53.svc.cluster.local]

Dec 20 09:50:59.327: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:59.331: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:59.335: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:59.338: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:59.351: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:59.355: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:59.359: INFO: Unable to read jessie_udp@dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:59.362: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:50:59.369: INFO: Lookups using dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local wheezy_udp@dns-test-service-2.dns-53.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-53.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local jessie_udp@dns-test-service-2.dns-53.svc.cluster.local jessie_tcp@dns-test-service-2.dns-53.svc.cluster.local]

Dec 20 09:51:04.326: INFO: Unable to read wheezy_udp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:51:04.330: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:51:04.334: INFO: Unable to read wheezy_udp@dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:51:04.337: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:51:04.350: INFO: Unable to read jessie_udp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:51:04.354: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:51:04.357: INFO: Unable to read jessie_udp@dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:51:04.361: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:51:04.368: INFO: Lookups using dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615 failed for: [wheezy_udp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local wheezy_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local wheezy_udp@dns-test-service-2.dns-53.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-53.svc.cluster.local jessie_udp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local jessie_udp@dns-test-service-2.dns-53.svc.cluster.local jessie_tcp@dns-test-service-2.dns-53.svc.cluster.local]

Dec 20 09:51:09.329: INFO: Unable to read wheezy_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:51:09.336: INFO: Unable to read wheezy_tcp@dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:51:09.349: INFO: Unable to read jessie_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:51:09.352: INFO: Unable to read jessie_udp@dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:51:09.355: INFO: Unable to read jessie_tcp@dns-test-service-2.dns-53.svc.cluster.local from pod dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615: the server could not find the requested resource (get pods dns-test-18510749-17a7-4a38-b040-2b0f09ca1615)
Dec 20 09:51:09.361: INFO: Lookups using dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615 failed for: [wheezy_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local wheezy_tcp@dns-test-service-2.dns-53.svc.cluster.local jessie_tcp@dns-querier-2.dns-test-service-2.dns-53.svc.cluster.local jessie_udp@dns-test-service-2.dns-53.svc.cluster.local jessie_tcp@dns-test-service-2.dns-53.svc.cluster.local]

Dec 20 09:51:14.367: INFO: DNS probes using dns-53/dns-test-18510749-17a7-4a38-b040-2b0f09ca1615 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:51:14.385: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-53" for this suite.
Dec 20 09:51:20.398: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:51:20.489: INFO: namespace dns-53 deletion completed in 6.100779606s

• [SLOW TEST:49.359 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Subdomain [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:51:20.490: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-1445
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 09:51:20.633: INFO: (0) /api/v1/nodes/caasp-worker-th-before-0/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 6.700114ms)
Dec 20 09:51:20.637: INFO: (1) /api/v1/nodes/caasp-worker-th-before-0/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 4.116799ms)
Dec 20 09:51:20.641: INFO: (2) /api/v1/nodes/caasp-worker-th-before-0/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.603299ms)
Dec 20 09:51:20.644: INFO: (3) /api/v1/nodes/caasp-worker-th-before-0/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.37524ms)
Dec 20 09:51:20.648: INFO: (4) /api/v1/nodes/caasp-worker-th-before-0/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.302504ms)
Dec 20 09:51:20.651: INFO: (5) /api/v1/nodes/caasp-worker-th-before-0/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.085859ms)
Dec 20 09:51:20.654: INFO: (6) /api/v1/nodes/caasp-worker-th-before-0/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.209909ms)
Dec 20 09:51:20.657: INFO: (7) /api/v1/nodes/caasp-worker-th-before-0/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.017846ms)
Dec 20 09:51:20.660: INFO: (8) /api/v1/nodes/caasp-worker-th-before-0/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.267613ms)
Dec 20 09:51:20.663: INFO: (9) /api/v1/nodes/caasp-worker-th-before-0/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.087774ms)
Dec 20 09:51:20.666: INFO: (10) /api/v1/nodes/caasp-worker-th-before-0/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 2.909887ms)
Dec 20 09:51:20.670: INFO: (11) /api/v1/nodes/caasp-worker-th-before-0/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.241454ms)
Dec 20 09:51:20.672: INFO: (12) /api/v1/nodes/caasp-worker-th-before-0/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 2.794874ms)
Dec 20 09:51:20.675: INFO: (13) /api/v1/nodes/caasp-worker-th-before-0/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 2.792676ms)
Dec 20 09:51:20.678: INFO: (14) /api/v1/nodes/caasp-worker-th-before-0/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 2.875461ms)
Dec 20 09:51:20.681: INFO: (15) /api/v1/nodes/caasp-worker-th-before-0/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 2.829402ms)
Dec 20 09:51:20.684: INFO: (16) /api/v1/nodes/caasp-worker-th-before-0/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 2.803247ms)
Dec 20 09:51:20.687: INFO: (17) /api/v1/nodes/caasp-worker-th-before-0/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 2.809129ms)
Dec 20 09:51:20.690: INFO: (18) /api/v1/nodes/caasp-worker-th-before-0/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 2.962081ms)
Dec 20 09:51:20.692: INFO: (19) /api/v1/nodes/caasp-worker-th-before-0/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 2.669794ms)
[AfterEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:51:20.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-1445" for this suite.
Dec 20 09:51:26.704: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:51:26.807: INFO: namespace proxy-1445 deletion completed in 6.11164545s

• [SLOW TEST:6.317 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node using proxy subresource  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-network] Services 
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:51:26.807: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3108
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service multi-endpoint-test in namespace services-3108
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3108 to expose endpoints map[]
Dec 20 09:51:26.955: INFO: Get endpoints failed (2.365598ms elapsed, ignoring for 5s): endpoints "multi-endpoint-test" not found
Dec 20 09:51:27.959: INFO: successfully validated that service multi-endpoint-test in namespace services-3108 exposes endpoints map[] (1.006201281s elapsed)
STEP: Creating pod pod1 in namespace services-3108
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3108 to expose endpoints map[pod1:[100]]
Dec 20 09:51:30.996: INFO: successfully validated that service multi-endpoint-test in namespace services-3108 exposes endpoints map[pod1:[100]] (3.030268219s elapsed)
STEP: Creating pod pod2 in namespace services-3108
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3108 to expose endpoints map[pod1:[100] pod2:[101]]
Dec 20 09:51:34.040: INFO: successfully validated that service multi-endpoint-test in namespace services-3108 exposes endpoints map[pod1:[100] pod2:[101]] (3.038237945s elapsed)
STEP: Deleting pod pod1 in namespace services-3108
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3108 to expose endpoints map[pod2:[101]]
Dec 20 09:51:35.056: INFO: successfully validated that service multi-endpoint-test in namespace services-3108 exposes endpoints map[pod2:[101]] (1.01126829s elapsed)
STEP: Deleting pod pod2 in namespace services-3108
STEP: waiting up to 3m0s for service multi-endpoint-test in namespace services-3108 to expose endpoints map[]
Dec 20 09:51:36.067: INFO: successfully validated that service multi-endpoint-test in namespace services-3108 exposes endpoints map[] (1.005482952s elapsed)
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:51:36.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3108" for this suite.
Dec 20 09:51:42.102: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:51:42.190: INFO: namespace services-3108 deletion completed in 6.101888422s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:15.383 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should serve multiport endpoints from pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:51:42.190: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-1787
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override command
Dec 20 09:51:42.334: INFO: Waiting up to 5m0s for pod "client-containers-265211ff-e7aa-4051-9e16-2ac873199ebc" in namespace "containers-1787" to be "success or failure"
Dec 20 09:51:42.336: INFO: Pod "client-containers-265211ff-e7aa-4051-9e16-2ac873199ebc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.148206ms
Dec 20 09:51:44.339: INFO: Pod "client-containers-265211ff-e7aa-4051-9e16-2ac873199ebc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00564108s
Dec 20 09:51:46.345: INFO: Pod "client-containers-265211ff-e7aa-4051-9e16-2ac873199ebc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011850966s
STEP: Saw pod success
Dec 20 09:51:46.345: INFO: Pod "client-containers-265211ff-e7aa-4051-9e16-2ac873199ebc" satisfied condition "success or failure"
Dec 20 09:51:46.348: INFO: Trying to get logs from node caasp-worker-th-before-4 pod client-containers-265211ff-e7aa-4051-9e16-2ac873199ebc container test-container: <nil>
STEP: delete the pod
Dec 20 09:51:46.374: INFO: Waiting for pod client-containers-265211ff-e7aa-4051-9e16-2ac873199ebc to disappear
Dec 20 09:51:46.376: INFO: Pod client-containers-265211ff-e7aa-4051-9e16-2ac873199ebc no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:51:46.376: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-1787" for this suite.
Dec 20 09:51:52.391: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:51:52.487: INFO: namespace containers-1787 deletion completed in 6.107132628s

• [SLOW TEST:10.297 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command (docker entrypoint) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:51:52.487: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-936
STEP: Waiting for a default service account to be provisioned in namespace
[It] listing custom resource definition objects works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 09:51:52.621: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:51:58.857: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-936" for this suite.
Dec 20 09:52:04.876: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:52:04.965: INFO: namespace custom-resource-definition-936 deletion completed in 6.101659292s

• [SLOW TEST:12.478 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    listing custom resource definition objects works  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:52:04.965: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-9176
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-76279ed2-0c2e-4e68-8ab2-e2e68190a99d
STEP: Creating a pod to test consume configMaps
Dec 20 09:52:05.113: INFO: Waiting up to 5m0s for pod "pod-configmaps-f3721fef-6f8f-4dbd-9fd9-61ac49a46bae" in namespace "configmap-9176" to be "success or failure"
Dec 20 09:52:05.115: INFO: Pod "pod-configmaps-f3721fef-6f8f-4dbd-9fd9-61ac49a46bae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.283897ms
Dec 20 09:52:07.119: INFO: Pod "pod-configmaps-f3721fef-6f8f-4dbd-9fd9-61ac49a46bae": Phase="Pending", Reason="", readiness=false. Elapsed: 2.0066677s
Dec 20 09:52:09.124: INFO: Pod "pod-configmaps-f3721fef-6f8f-4dbd-9fd9-61ac49a46bae": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011171512s
STEP: Saw pod success
Dec 20 09:52:09.124: INFO: Pod "pod-configmaps-f3721fef-6f8f-4dbd-9fd9-61ac49a46bae" satisfied condition "success or failure"
Dec 20 09:52:09.127: INFO: Trying to get logs from node caasp-worker-th-before-4 pod pod-configmaps-f3721fef-6f8f-4dbd-9fd9-61ac49a46bae container configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 09:52:09.143: INFO: Waiting for pod pod-configmaps-f3721fef-6f8f-4dbd-9fd9-61ac49a46bae to disappear
Dec 20 09:52:09.145: INFO: Pod pod-configmaps-f3721fef-6f8f-4dbd-9fd9-61ac49a46bae no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:52:09.145: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-9176" for this suite.
Dec 20 09:52:15.158: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:52:15.256: INFO: namespace configmap-9176 deletion completed in 6.107660107s

• [SLOW TEST:10.291 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-node] Downward API 
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:52:15.256: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-8336
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 20 09:52:15.395: INFO: Waiting up to 5m0s for pod "downward-api-70854fec-3127-493d-896d-45c322430b0d" in namespace "downward-api-8336" to be "success or failure"
Dec 20 09:52:15.398: INFO: Pod "downward-api-70854fec-3127-493d-896d-45c322430b0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.624375ms
Dec 20 09:52:17.402: INFO: Pod "downward-api-70854fec-3127-493d-896d-45c322430b0d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00609303s
Dec 20 09:52:19.406: INFO: Pod "downward-api-70854fec-3127-493d-896d-45c322430b0d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010265489s
STEP: Saw pod success
Dec 20 09:52:19.406: INFO: Pod "downward-api-70854fec-3127-493d-896d-45c322430b0d" satisfied condition "success or failure"
Dec 20 09:52:19.409: INFO: Trying to get logs from node caasp-worker-th-before-4 pod downward-api-70854fec-3127-493d-896d-45c322430b0d container dapi-container: <nil>
STEP: delete the pod
Dec 20 09:52:19.425: INFO: Waiting for pod downward-api-70854fec-3127-493d-896d-45c322430b0d to disappear
Dec 20 09:52:19.427: INFO: Pod downward-api-70854fec-3127-493d-896d-45c322430b0d no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:52:19.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-8336" for this suite.
Dec 20 09:52:25.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:52:25.532: INFO: namespace downward-api-8336 deletion completed in 6.10137355s

• [SLOW TEST:10.276 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Services 
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:52:25.532: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-2558
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service nodeport-service with the type=NodePort in namespace services-2558
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-2558
STEP: creating replication controller externalsvc in namespace services-2558
I1220 09:52:25.689096      26 runners.go:184] Created replication controller with name: externalsvc, namespace: services-2558, replica count: 2
I1220 09:52:28.739581      26 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the NodePort service to type=ExternalName
Dec 20 09:52:28.761: INFO: Creating new exec pod
Dec 20 09:52:32.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=services-2558 execpod7x975 -- /bin/sh -x -c nslookup nodeport-service'
Dec 20 09:52:32.990: INFO: stderr: "+ nslookup nodeport-service\n"
Dec 20 09:52:32.990: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nnodeport-service.services-2558.svc.cluster.local\tcanonical name = externalsvc.services-2558.svc.cluster.local.\nName:\texternalsvc.services-2558.svc.cluster.local\nAddress: 10.102.211.106\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-2558, will wait for the garbage collector to delete the pods
Dec 20 09:52:33.052: INFO: Deleting ReplicationController externalsvc took: 7.948461ms
Dec 20 09:52:33.452: INFO: Terminating ReplicationController externalsvc pods took: 400.285334ms
Dec 20 09:52:37.871: INFO: Cleaning up the NodePort to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:52:37.881: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-2558" for this suite.
Dec 20 09:52:43.894: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:52:43.988: INFO: namespace services-2558 deletion completed in 6.103466576s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:18.456 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from NodePort to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:52:43.989: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-1661
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test headless service
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1661.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-2.dns-test-service-2.dns-1661.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/wheezy_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1661.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-2.dns-test-service-2.dns-1661.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-2.dns-test-service-2.dns-1661.svc.cluster.local;test -n "$$(getent hosts dns-querier-2)" && echo OK > /results/jessie_hosts@dns-querier-2;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-1661.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 20 09:53:06.173: INFO: DNS probes using dns-1661/dns-test-d1e0e8b5-6570-4269-925a-72a903cd48f1 succeeded

STEP: deleting the pod
STEP: deleting the test headless service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:53:06.191: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-1661" for this suite.
Dec 20 09:53:12.204: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:53:12.300: INFO: namespace dns-1661 deletion completed in 6.105037454s

• [SLOW TEST:28.311 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for pods for Hostname [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:53:12.300: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3824
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-3f47a4bd-bd92-4a02-a181-6f56939b8e0f
STEP: Creating a pod to test consume secrets
Dec 20 09:53:12.442: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-b52bdf0b-15e6-4adf-bf5d-fcde1aece463" in namespace "projected-3824" to be "success or failure"
Dec 20 09:53:12.444: INFO: Pod "pod-projected-secrets-b52bdf0b-15e6-4adf-bf5d-fcde1aece463": Phase="Pending", Reason="", readiness=false. Elapsed: 2.459315ms
Dec 20 09:53:14.448: INFO: Pod "pod-projected-secrets-b52bdf0b-15e6-4adf-bf5d-fcde1aece463": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006760001s
Dec 20 09:53:16.452: INFO: Pod "pod-projected-secrets-b52bdf0b-15e6-4adf-bf5d-fcde1aece463": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010416014s
STEP: Saw pod success
Dec 20 09:53:16.452: INFO: Pod "pod-projected-secrets-b52bdf0b-15e6-4adf-bf5d-fcde1aece463" satisfied condition "success or failure"
Dec 20 09:53:16.454: INFO: Trying to get logs from node caasp-worker-th-before-4 pod pod-projected-secrets-b52bdf0b-15e6-4adf-bf5d-fcde1aece463 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 20 09:53:16.469: INFO: Waiting for pod pod-projected-secrets-b52bdf0b-15e6-4adf-bf5d-fcde1aece463 to disappear
Dec 20 09:53:16.472: INFO: Pod pod-projected-secrets-b52bdf0b-15e6-4adf-bf5d-fcde1aece463 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:53:16.472: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3824" for this suite.
Dec 20 09:53:22.487: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:53:22.581: INFO: namespace projected-3824 deletion completed in 6.104789442s

• [SLOW TEST:10.281 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:53:22.581: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-250
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 20 09:53:22.715: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 20 09:53:22.732: INFO: Waiting for terminating namespaces to be deleted...
Dec 20 09:53:22.735: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-th-before-0 before test
Dec 20 09:53:22.757: INFO: cilium-srq5l from kube-system started at 2019-12-19 23:00:47 +0000 UTC (1 container statuses recorded)
Dec 20 09:53:22.757: INFO: 	Container cilium-agent ready: true, restart count 1
Dec 20 09:53:22.757: INFO: kube-proxy-m8mx6 from kube-system started at 2019-12-19 23:00:47 +0000 UTC (1 container statuses recorded)
Dec 20 09:53:22.757: INFO: 	Container kube-proxy ready: true, restart count 1
Dec 20 09:53:22.757: INFO: sonobuoy from sonobuoy started at 2019-12-20 09:06:03 +0000 UTC (1 container statuses recorded)
Dec 20 09:53:22.757: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 20 09:53:22.757: INFO: kured-cvqgx from kube-system started at 2019-12-19 23:02:27 +0000 UTC (1 container statuses recorded)
Dec 20 09:53:22.757: INFO: 	Container kured ready: true, restart count 1
Dec 20 09:53:22.757: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-th-before-3 before test
Dec 20 09:53:22.774: INFO: kured-ddrtt from kube-system started at 2019-12-19 23:01:46 +0000 UTC (1 container statuses recorded)
Dec 20 09:53:22.774: INFO: 	Container kured ready: true, restart count 0
Dec 20 09:53:22.774: INFO: oidc-dex-799996b768-8xqtt from kube-system started at 2019-12-19 23:24:29 +0000 UTC (1 container statuses recorded)
Dec 20 09:53:22.774: INFO: 	Container oidc-dex ready: true, restart count 0
Dec 20 09:53:22.774: INFO: tiller-deploy-6b954db788-gjd4h from kube-system started at 2019-12-19 23:05:50 +0000 UTC (1 container statuses recorded)
Dec 20 09:53:22.774: INFO: 	Container tiller ready: true, restart count 7
Dec 20 09:53:22.774: INFO: kube-proxy-frbl9 from kube-system started at 2019-12-19 23:00:46 +0000 UTC (1 container statuses recorded)
Dec 20 09:53:22.774: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 20 09:53:22.774: INFO: cilium-sm7nn from kube-system started at 2019-12-19 23:00:46 +0000 UTC (1 container statuses recorded)
Dec 20 09:53:22.774: INFO: 	Container cilium-agent ready: true, restart count 4
Dec 20 09:53:22.774: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-th-before-4 before test
Dec 20 09:53:22.780: INFO: oidc-dex-799996b768-4r6tn from kube-system started at 2019-12-19 23:24:29 +0000 UTC (1 container statuses recorded)
Dec 20 09:53:22.780: INFO: 	Container oidc-dex ready: true, restart count 0
Dec 20 09:53:22.780: INFO: kured-zktcs from kube-system started at 2019-12-19 23:01:56 +0000 UTC (1 container statuses recorded)
Dec 20 09:53:22.780: INFO: 	Container kured ready: true, restart count 0
Dec 20 09:53:22.780: INFO: cilium-nllss from kube-system started at 2019-12-19 23:00:46 +0000 UTC (1 container statuses recorded)
Dec 20 09:53:22.780: INFO: 	Container cilium-agent ready: true, restart count 4
Dec 20 09:53:22.780: INFO: kube-proxy-qcm45 from kube-system started at 2019-12-19 23:00:46 +0000 UTC (1 container statuses recorded)
Dec 20 09:53:22.780: INFO: 	Container kube-proxy ready: true, restart count 0
[It] validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to launch a pod without a label to get a node which can launch it.
STEP: Explicitly delete pod here to free the resource it takes.
STEP: Trying to apply a random label on the found node.
STEP: verifying the node has the label kubernetes.io/e2e-6f5e3f76-9b64-4f7e-b6a6-ec26e2a04d1c 90
STEP: Trying to create a pod(pod1) with hostport 54321 and hostIP 127.0.0.1 and expect scheduled
STEP: Trying to create another pod(pod2) with hostport 54321 but hostIP 127.0.0.2 on the node which pod1 resides and expect scheduled
STEP: Trying to create a third pod(pod3) with hostport 54321, hostIP 127.0.0.2 but use UDP protocol on the node which pod2 resides
STEP: removing the label kubernetes.io/e2e-6f5e3f76-9b64-4f7e-b6a6-ec26e2a04d1c off the node caasp-worker-th-before-3
STEP: verifying the node doesn't have the label kubernetes.io/e2e-6f5e3f76-9b64-4f7e-b6a6-ec26e2a04d1c
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:53:54.858: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-250" for this suite.
Dec 20 09:54:04.872: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:54:04.958: INFO: namespace sched-pred-250 deletion completed in 10.097243561s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:42.377 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that there is no conflict between pods with same hostPort but different hostIP and protocol [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:54:04.959: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5450
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-5450
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 20 09:54:05.093: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 20 09:54:29.160: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.6.219:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5450 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 09:54:29.160: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 09:54:29.239: INFO: Found all expected endpoints: [netserver-0]
Dec 20 09:54:29.242: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.5.164:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5450 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 09:54:29.242: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 09:54:29.317: INFO: Found all expected endpoints: [netserver-1]
Dec 20 09:54:29.320: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s --max-time 15 --connect-timeout 1 http://10.244.7.92:8080/hostName | grep -v '^\s*$'] Namespace:pod-network-test-5450 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 09:54:29.320: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 09:54:29.387: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:54:29.387: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5450" for this suite.
Dec 20 09:54:41.401: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:54:41.502: INFO: namespace pod-network-test-5450 deletion completed in 12.111604106s

• [SLOW TEST:36.544 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl patch 
  should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:54:41.503: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1629
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should add annotations for pods in rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec 20 09:54:41.634: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 create -f - --namespace=kubectl-1629'
Dec 20 09:54:41.879: INFO: stderr: ""
Dec 20 09:54:41.879: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 20 09:54:42.883: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 09:54:42.883: INFO: Found 0 / 1
Dec 20 09:54:43.883: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 09:54:43.883: INFO: Found 0 / 1
Dec 20 09:54:44.883: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 09:54:44.883: INFO: Found 1 / 1
Dec 20 09:54:44.883: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
STEP: patching all pods
Dec 20 09:54:44.887: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 09:54:44.887: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 20 09:54:44.887: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 patch pod redis-master-vxn6p --namespace=kubectl-1629 -p {"metadata":{"annotations":{"x":"y"}}}'
Dec 20 09:54:44.980: INFO: stderr: ""
Dec 20 09:54:44.980: INFO: stdout: "pod/redis-master-vxn6p patched\n"
STEP: checking annotations
Dec 20 09:54:44.983: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 09:54:44.983: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:54:44.983: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1629" for this suite.
Dec 20 09:54:56.999: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:54:57.087: INFO: namespace kubectl-1629 deletion completed in 12.09958275s

• [SLOW TEST:15.585 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl patch
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1346
    should add annotations for pods in rc  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:54:57.088: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3340
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 20 09:54:57.621: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 20 09:54:59.633: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432498, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432498, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432498, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432498, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 20 09:55:02.647: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 09:55:02.651: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-6184-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource while v1 is storage version
STEP: Patching Custom Resource Definition to set v2 as storage
STEP: Patching the custom resource while v2 is storage version
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:55:03.889: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3340" for this suite.
Dec 20 09:55:09.904: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:55:10.000: INFO: namespace webhook-3340 deletion completed in 6.106805649s
STEP: Destroying namespace "webhook-3340-markers" for this suite.
Dec 20 09:55:16.010: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:55:16.102: INFO: namespace webhook-3340-markers deletion completed in 6.101972049s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.026 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with different stored version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:55:16.115: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-1209
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 09:55:16.267: INFO: Create a RollingUpdate DaemonSet
Dec 20 09:55:16.270: INFO: Check that daemon pods launch on every node of the cluster
Dec 20 09:55:16.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:55:16.274: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:55:16.276: INFO: Number of nodes with available pods: 0
Dec 20 09:55:16.276: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 09:55:17.280: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:55:17.281: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:55:17.284: INFO: Number of nodes with available pods: 0
Dec 20 09:55:17.284: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 09:55:18.280: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:55:18.281: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:55:18.284: INFO: Number of nodes with available pods: 0
Dec 20 09:55:18.284: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 09:55:19.280: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:55:19.280: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:55:19.283: INFO: Number of nodes with available pods: 3
Dec 20 09:55:19.283: INFO: Number of running nodes: 3, number of available pods: 3
Dec 20 09:55:19.283: INFO: Update the DaemonSet to trigger a rollout
Dec 20 09:55:19.289: INFO: Updating DaemonSet daemon-set
Dec 20 09:55:31.303: INFO: Roll back the DaemonSet before rollout is complete
Dec 20 09:55:31.309: INFO: Updating DaemonSet daemon-set
Dec 20 09:55:31.309: INFO: Make sure DaemonSet rollback is complete
Dec 20 09:55:31.312: INFO: Wrong image for pod: daemon-set-wvvp7. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 20 09:55:31.312: INFO: Pod daemon-set-wvvp7 is not available
Dec 20 09:55:31.315: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:55:31.315: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:55:32.319: INFO: Wrong image for pod: daemon-set-wvvp7. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 20 09:55:32.319: INFO: Pod daemon-set-wvvp7 is not available
Dec 20 09:55:32.322: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:55:32.322: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:55:33.319: INFO: Wrong image for pod: daemon-set-wvvp7. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 20 09:55:33.319: INFO: Pod daemon-set-wvvp7 is not available
Dec 20 09:55:33.324: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:55:33.324: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:55:34.319: INFO: Wrong image for pod: daemon-set-wvvp7. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 20 09:55:34.319: INFO: Pod daemon-set-wvvp7 is not available
Dec 20 09:55:34.322: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:55:34.323: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:55:35.319: INFO: Wrong image for pod: daemon-set-wvvp7. Expected: docker.io/library/httpd:2.4.38-alpine, got: foo:non-existent.
Dec 20 09:55:35.319: INFO: Pod daemon-set-wvvp7 is not available
Dec 20 09:55:35.323: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:55:35.323: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:55:36.319: INFO: Pod daemon-set-tv7bj is not available
Dec 20 09:55:36.323: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 09:55:36.323: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-1209, will wait for the garbage collector to delete the pods
Dec 20 09:55:36.388: INFO: Deleting DaemonSet.extensions daemon-set took: 6.596485ms
Dec 20 09:55:36.788: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.25452ms
Dec 20 09:55:45.392: INFO: Number of nodes with available pods: 0
Dec 20 09:55:45.392: INFO: Number of running nodes: 0, number of available pods: 0
Dec 20 09:55:45.395: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-1209/daemonsets","resourceVersion":"119592"},"items":null}

Dec 20 09:55:45.397: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-1209/pods","resourceVersion":"119592"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:55:45.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-1209" for this suite.
Dec 20 09:55:51.423: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:55:51.517: INFO: namespace daemonsets-1209 deletion completed in 6.104409332s

• [SLOW TEST:35.402 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should rollback without unnecessary restarts [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:55:51.517: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5745
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-5745/configmap-test-56a2379a-b695-4fdd-96ec-94f7881b1550
STEP: Creating a pod to test consume configMaps
Dec 20 09:55:51.661: INFO: Waiting up to 5m0s for pod "pod-configmaps-4be0a4b6-fd92-4fab-ab94-8382bb783ff7" in namespace "configmap-5745" to be "success or failure"
Dec 20 09:55:51.664: INFO: Pod "pod-configmaps-4be0a4b6-fd92-4fab-ab94-8382bb783ff7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.529211ms
Dec 20 09:55:53.668: INFO: Pod "pod-configmaps-4be0a4b6-fd92-4fab-ab94-8382bb783ff7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006694554s
Dec 20 09:55:55.672: INFO: Pod "pod-configmaps-4be0a4b6-fd92-4fab-ab94-8382bb783ff7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011001069s
STEP: Saw pod success
Dec 20 09:55:55.672: INFO: Pod "pod-configmaps-4be0a4b6-fd92-4fab-ab94-8382bb783ff7" satisfied condition "success or failure"
Dec 20 09:55:55.676: INFO: Trying to get logs from node caasp-worker-th-before-3 pod pod-configmaps-4be0a4b6-fd92-4fab-ab94-8382bb783ff7 container env-test: <nil>
STEP: delete the pod
Dec 20 09:55:55.701: INFO: Waiting for pod pod-configmaps-4be0a4b6-fd92-4fab-ab94-8382bb783ff7 to disappear
Dec 20 09:55:55.703: INFO: Pod pod-configmaps-4be0a4b6-fd92-4fab-ab94-8382bb783ff7 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:55:55.703: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5745" for this suite.
Dec 20 09:56:01.718: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:56:01.812: INFO: namespace configmap-5745 deletion completed in 6.105010681s

• [SLOW TEST:10.295 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl logs 
  should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:56:01.813: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-1594
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl logs
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1274
STEP: creating an pod
Dec 20 09:56:01.944: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 run logs-generator --generator=run-pod/v1 --image=gcr.io/kubernetes-e2e-test-images/agnhost:2.6 --namespace=kubectl-1594 -- logs-generator --log-lines-total 100 --run-duration 20s'
Dec 20 09:56:02.066: INFO: stderr: ""
Dec 20 09:56:02.066: INFO: stdout: "pod/logs-generator created\n"
[It] should be able to retrieve and filter logs  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Waiting for log generator to start.
Dec 20 09:56:02.066: INFO: Waiting up to 5m0s for 1 pods to be running and ready, or succeeded: [logs-generator]
Dec 20 09:56:02.066: INFO: Waiting up to 5m0s for pod "logs-generator" in namespace "kubectl-1594" to be "running and ready, or succeeded"
Dec 20 09:56:02.068: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.578166ms
Dec 20 09:56:04.072: INFO: Pod "logs-generator": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006218168s
Dec 20 09:56:06.076: INFO: Pod "logs-generator": Phase="Running", Reason="", readiness=true. Elapsed: 4.010319759s
Dec 20 09:56:06.076: INFO: Pod "logs-generator" satisfied condition "running and ready, or succeeded"
Dec 20 09:56:06.076: INFO: Wanted all 1 pods to be running and ready, or succeeded. Result: true. Pods: [logs-generator]
STEP: checking for a matching strings
Dec 20 09:56:06.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 logs logs-generator logs-generator --namespace=kubectl-1594'
Dec 20 09:56:06.228: INFO: stderr: ""
Dec 20 09:56:06.228: INFO: stdout: "I1220 09:56:04.487318       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/mbdz 396\nI1220 09:56:04.687533       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/tvq 350\nI1220 09:56:04.887511       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/67kd 490\nI1220 09:56:05.087508       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/z2cn 223\nI1220 09:56:05.287558       1 logs_generator.go:76] 4 POST /api/v1/namespaces/default/pods/6ct2 401\nI1220 09:56:05.487556       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/tlh 379\nI1220 09:56:05.687651       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/vn9 256\nI1220 09:56:05.887489       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/wh7 595\nI1220 09:56:06.087542       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/lhw 313\nI1220 09:56:06.287528       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/rwt6 422\nI1220 09:56:06.487512       1 logs_generator.go:76] 10 POST /api/v1/namespaces/ns/pods/g4ks 282\nI1220 09:56:06.687535       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/kz4c 576\n"
STEP: limiting log lines
Dec 20 09:56:06.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 logs logs-generator logs-generator --namespace=kubectl-1594 --tail=1'
Dec 20 09:56:06.340: INFO: stderr: ""
Dec 20 09:56:06.340: INFO: stdout: "I1220 09:56:06.887470       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/xvpc 230\n"
STEP: limiting log bytes
Dec 20 09:56:06.340: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 logs logs-generator logs-generator --namespace=kubectl-1594 --limit-bytes=1'
Dec 20 09:56:06.462: INFO: stderr: ""
Dec 20 09:56:06.462: INFO: stdout: "I"
STEP: exposing timestamps
Dec 20 09:56:06.462: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 logs logs-generator logs-generator --namespace=kubectl-1594 --tail=1 --timestamps'
Dec 20 09:56:06.563: INFO: stderr: ""
Dec 20 09:56:06.563: INFO: stdout: "2019-12-20T09:56:07.087560057Z I1220 09:56:07.087509       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/8pt 347\n"
STEP: restricting to a time range
Dec 20 09:56:09.063: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 logs logs-generator logs-generator --namespace=kubectl-1594 --since=1s'
Dec 20 09:56:09.165: INFO: stderr: ""
Dec 20 09:56:09.165: INFO: stdout: "I1220 09:56:08.887522       1 logs_generator.go:76] 22 POST /api/v1/namespaces/ns/pods/v96 361\nI1220 09:56:09.087516       1 logs_generator.go:76] 23 GET /api/v1/namespaces/ns/pods/c6jx 238\nI1220 09:56:09.287516       1 logs_generator.go:76] 24 GET /api/v1/namespaces/default/pods/ghs 407\nI1220 09:56:09.487521       1 logs_generator.go:76] 25 GET /api/v1/namespaces/ns/pods/rltf 452\nI1220 09:56:09.687552       1 logs_generator.go:76] 26 POST /api/v1/namespaces/kube-system/pods/sq5 442\n"
Dec 20 09:56:09.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 logs logs-generator logs-generator --namespace=kubectl-1594 --since=24h'
Dec 20 09:56:09.276: INFO: stderr: ""
Dec 20 09:56:09.276: INFO: stdout: "I1220 09:56:04.487318       1 logs_generator.go:76] 0 GET /api/v1/namespaces/ns/pods/mbdz 396\nI1220 09:56:04.687533       1 logs_generator.go:76] 1 POST /api/v1/namespaces/ns/pods/tvq 350\nI1220 09:56:04.887511       1 logs_generator.go:76] 2 PUT /api/v1/namespaces/default/pods/67kd 490\nI1220 09:56:05.087508       1 logs_generator.go:76] 3 POST /api/v1/namespaces/ns/pods/z2cn 223\nI1220 09:56:05.287558       1 logs_generator.go:76] 4 POST /api/v1/namespaces/default/pods/6ct2 401\nI1220 09:56:05.487556       1 logs_generator.go:76] 5 POST /api/v1/namespaces/kube-system/pods/tlh 379\nI1220 09:56:05.687651       1 logs_generator.go:76] 6 PUT /api/v1/namespaces/default/pods/vn9 256\nI1220 09:56:05.887489       1 logs_generator.go:76] 7 GET /api/v1/namespaces/default/pods/wh7 595\nI1220 09:56:06.087542       1 logs_generator.go:76] 8 POST /api/v1/namespaces/default/pods/lhw 313\nI1220 09:56:06.287528       1 logs_generator.go:76] 9 POST /api/v1/namespaces/default/pods/rwt6 422\nI1220 09:56:06.487512       1 logs_generator.go:76] 10 POST /api/v1/namespaces/ns/pods/g4ks 282\nI1220 09:56:06.687535       1 logs_generator.go:76] 11 GET /api/v1/namespaces/kube-system/pods/kz4c 576\nI1220 09:56:06.887470       1 logs_generator.go:76] 12 POST /api/v1/namespaces/default/pods/xvpc 230\nI1220 09:56:07.087509       1 logs_generator.go:76] 13 POST /api/v1/namespaces/kube-system/pods/8pt 347\nI1220 09:56:07.287490       1 logs_generator.go:76] 14 PUT /api/v1/namespaces/kube-system/pods/fkx 571\nI1220 09:56:07.487512       1 logs_generator.go:76] 15 PUT /api/v1/namespaces/default/pods/xz7 232\nI1220 09:56:07.687507       1 logs_generator.go:76] 16 POST /api/v1/namespaces/ns/pods/njt5 440\nI1220 09:56:07.887514       1 logs_generator.go:76] 17 POST /api/v1/namespaces/kube-system/pods/58jb 257\nI1220 09:56:08.087536       1 logs_generator.go:76] 18 PUT /api/v1/namespaces/kube-system/pods/wwkx 534\nI1220 09:56:08.287569       1 logs_generator.go:76] 19 PUT /api/v1/namespaces/kube-system/pods/shs 453\nI1220 09:56:08.487478       1 logs_generator.go:76] 20 GET /api/v1/namespaces/kube-system/pods/5wzv 352\nI1220 09:56:08.687527       1 logs_generator.go:76] 21 PUT /api/v1/namespaces/default/pods/7r7 443\nI1220 09:56:08.887522       1 logs_generator.go:76] 22 POST /api/v1/namespaces/ns/pods/v96 361\nI1220 09:56:09.087516       1 logs_generator.go:76] 23 GET /api/v1/namespaces/ns/pods/c6jx 238\nI1220 09:56:09.287516       1 logs_generator.go:76] 24 GET /api/v1/namespaces/default/pods/ghs 407\nI1220 09:56:09.487521       1 logs_generator.go:76] 25 GET /api/v1/namespaces/ns/pods/rltf 452\nI1220 09:56:09.687552       1 logs_generator.go:76] 26 POST /api/v1/namespaces/kube-system/pods/sq5 442\n"
[AfterEach] Kubectl logs
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1280
Dec 20 09:56:09.276: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 delete pod logs-generator --namespace=kubectl-1594'
Dec 20 09:56:15.358: INFO: stderr: ""
Dec 20 09:56:15.358: INFO: stdout: "pod \"logs-generator\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:56:15.358: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-1594" for this suite.
Dec 20 09:56:21.372: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:56:21.452: INFO: namespace kubectl-1594 deletion completed in 6.090167617s

• [SLOW TEST:19.639 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl logs
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1270
    should be able to retrieve and filter logs  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:56:21.452: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9170
STEP: Waiting for a default service account to be provisioned in namespace
[It] should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota with terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a ResourceQuota with not terminating scope
STEP: Ensuring ResourceQuota status is calculated
STEP: Creating a long running pod
STEP: Ensuring resource quota with not terminating scope captures the pod usage
STEP: Ensuring resource quota with terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
STEP: Creating a terminating pod
STEP: Ensuring resource quota with terminating scope captures the pod usage
STEP: Ensuring resource quota with not terminating scope ignored the pod usage
STEP: Deleting the pod
STEP: Ensuring resource quota status released the pod usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:56:37.665: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9170" for this suite.
Dec 20 09:56:43.681: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:56:43.781: INFO: namespace resourcequota-9170 deletion completed in 6.111301505s

• [SLOW TEST:22.328 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should verify ResourceQuota with terminating scopes. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:56:43.781: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-2381
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: closing the watch once it receives two notifications
Dec 20 09:56:43.923: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2381 /api/v1/namespaces/watch-2381/configmaps/e2e-watch-test-watch-closed 87c6a618-1ee1-4ff4-92ff-8ef64c2fbc5c 119934 0 2019-12-20 09:56:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 20 09:56:43.923: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2381 /api/v1/namespaces/watch-2381/configmaps/e2e-watch-test-watch-closed 87c6a618-1ee1-4ff4-92ff-8ef64c2fbc5c 119935 0 2019-12-20 09:56:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time, while the watch is closed
STEP: creating a new watch on configmaps from the last resource version observed by the first watch
STEP: deleting the configmap
STEP: Expecting to observe notifications for all changes to the configmap since the first watch closed
Dec 20 09:56:43.935: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2381 /api/v1/namespaces/watch-2381/configmaps/e2e-watch-test-watch-closed 87c6a618-1ee1-4ff4-92ff-8ef64c2fbc5c 119936 0 2019-12-20 09:56:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 20 09:56:43.935: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-watch-closed  watch-2381 /api/v1/namespaces/watch-2381/configmaps/e2e-watch-test-watch-closed 87c6a618-1ee1-4ff4-92ff-8ef64c2fbc5c 119937 0 2019-12-20 09:56:43 +0000 UTC <nil> <nil> map[watch-this-configmap:watch-closed-and-restarted] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:56:43.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-2381" for this suite.
Dec 20 09:56:49.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:56:50.047: INFO: namespace watch-2381 deletion completed in 6.10791455s

• [SLOW TEST:6.266 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to restart watching from the last resource version observed by the previous watch [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:56:50.047: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-357
STEP: Waiting for a default service account to be provisioned in namespace
[It] removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec 20 09:56:50.180: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: mark a version not serverd
STEP: check the unserved version gets removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:57:18.607: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-357" for this suite.
Dec 20 09:57:24.624: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:57:24.716: INFO: namespace crd-publish-openapi-357 deletion completed in 6.104515832s

• [SLOW TEST:34.669 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  removes definition from spec when one version gets changed to not be served [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:57:24.716: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-4787
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 20 09:57:25.571: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 20 09:57:27.581: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432646, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432646, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432646, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432646, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 20 09:57:30.596: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a mutating webhook configuration
STEP: Updating a mutating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that should not be mutated
STEP: Patching a mutating webhook configuration's rules to include the create operation
STEP: Creating a configMap that should be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:57:30.656: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-4787" for this suite.
Dec 20 09:57:36.669: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:57:36.774: INFO: namespace webhook-4787 deletion completed in 6.114273087s
STEP: Destroying namespace "webhook-4787-markers" for this suite.
Dec 20 09:57:42.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:57:42.874: INFO: namespace webhook-4787-markers deletion completed in 6.099864169s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.169 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a mutating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:57:42.885: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7262
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 20 09:57:43.023: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9eea21a8-3ff6-4d66-b9b9-c30c41ed2d49" in namespace "downward-api-7262" to be "success or failure"
Dec 20 09:57:43.025: INFO: Pod "downwardapi-volume-9eea21a8-3ff6-4d66-b9b9-c30c41ed2d49": Phase="Pending", Reason="", readiness=false. Elapsed: 2.671255ms
Dec 20 09:57:45.029: INFO: Pod "downwardapi-volume-9eea21a8-3ff6-4d66-b9b9-c30c41ed2d49": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006185821s
Dec 20 09:57:47.033: INFO: Pod "downwardapi-volume-9eea21a8-3ff6-4d66-b9b9-c30c41ed2d49": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010058685s
STEP: Saw pod success
Dec 20 09:57:47.033: INFO: Pod "downwardapi-volume-9eea21a8-3ff6-4d66-b9b9-c30c41ed2d49" satisfied condition "success or failure"
Dec 20 09:57:47.036: INFO: Trying to get logs from node caasp-worker-th-before-4 pod downwardapi-volume-9eea21a8-3ff6-4d66-b9b9-c30c41ed2d49 container client-container: <nil>
STEP: delete the pod
Dec 20 09:57:47.065: INFO: Waiting for pod downwardapi-volume-9eea21a8-3ff6-4d66-b9b9-c30c41ed2d49 to disappear
Dec 20 09:57:47.068: INFO: Pod downwardapi-volume-9eea21a8-3ff6-4d66-b9b9-c30c41ed2d49 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:57:47.068: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7262" for this suite.
Dec 20 09:57:53.081: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:57:53.174: INFO: namespace downward-api-7262 deletion completed in 6.103318247s

• [SLOW TEST:10.289 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl expose 
  should create services for rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:57:53.175: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5142
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should create services for rc  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating Redis RC
Dec 20 09:57:53.307: INFO: namespace kubectl-5142
Dec 20 09:57:53.307: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 create -f - --namespace=kubectl-5142'
Dec 20 09:57:53.540: INFO: stderr: ""
Dec 20 09:57:53.540: INFO: stdout: "replicationcontroller/redis-master created\n"
STEP: Waiting for Redis master to start.
Dec 20 09:57:54.545: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 09:57:54.545: INFO: Found 0 / 1
Dec 20 09:57:55.544: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 09:57:55.544: INFO: Found 0 / 1
Dec 20 09:57:56.545: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 09:57:56.545: INFO: Found 1 / 1
Dec 20 09:57:56.545: INFO: WaitFor completed with timeout 5m0s.  Pods found = 1 out of 1
Dec 20 09:57:56.548: INFO: Selector matched 1 pods for map[app:redis]
Dec 20 09:57:56.548: INFO: ForEach: Found 1 pods from the filter.  Now looping through them.
Dec 20 09:57:56.548: INFO: wait on redis-master startup in kubectl-5142 
Dec 20 09:57:56.548: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 logs redis-master-k7kjq redis-master --namespace=kubectl-5142'
Dec 20 09:57:56.663: INFO: stderr: ""
Dec 20 09:57:56.663: INFO: stdout: "1:C 20 Dec 2019 09:57:56.088 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n1:C 20 Dec 2019 09:57:56.088 # Redis version=5.0.5, bits=64, commit=00000000, modified=0, pid=1, just started\n1:C 20 Dec 2019 09:57:56.088 # Warning: no config file specified, using the default config. In order to specify a config file use redis-server /path/to/redis.conf\n1:M 20 Dec 2019 09:57:56.090 * Running mode=standalone, port=6379.\n1:M 20 Dec 2019 09:57:56.090 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.\n1:M 20 Dec 2019 09:57:56.090 # Server initialized\n1:M 20 Dec 2019 09:57:56.090 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n1:M 20 Dec 2019 09:57:56.090 * Ready to accept connections\n"
STEP: exposing RC
Dec 20 09:57:56.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 expose rc redis-master --name=rm2 --port=1234 --target-port=6379 --namespace=kubectl-5142'
Dec 20 09:57:56.779: INFO: stderr: ""
Dec 20 09:57:56.779: INFO: stdout: "service/rm2 exposed\n"
Dec 20 09:57:56.782: INFO: Service rm2 in namespace kubectl-5142 found.
STEP: exposing service
Dec 20 09:57:58.789: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 expose service rm2 --name=rm3 --port=2345 --target-port=6379 --namespace=kubectl-5142'
Dec 20 09:57:58.892: INFO: stderr: ""
Dec 20 09:57:58.892: INFO: stdout: "service/rm3 exposed\n"
Dec 20 09:57:58.894: INFO: Service rm3 in namespace kubectl-5142 found.
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:58:00.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5142" for this suite.
Dec 20 09:58:28.917: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:58:29.013: INFO: namespace kubectl-5142 deletion completed in 28.107462556s

• [SLOW TEST:35.838 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl expose
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1105
    should create services for rc  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] Watchers 
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:58:29.013: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-7957
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with a certain label
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: changing the label value of the configmap
STEP: Expecting to observe a delete notification for the watched object
Dec 20 09:58:29.159: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7957 /api/v1/namespaces/watch-7957/configmaps/e2e-watch-test-label-changed 5fb2b97f-abe9-442a-9468-f1dfb8e67322 120422 0 2019-12-20 09:58:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 20 09:58:29.159: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7957 /api/v1/namespaces/watch-7957/configmaps/e2e-watch-test-label-changed 5fb2b97f-abe9-442a-9468-f1dfb8e67322 120423 0 2019-12-20 09:58:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 20 09:58:29.159: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7957 /api/v1/namespaces/watch-7957/configmaps/e2e-watch-test-label-changed 5fb2b97f-abe9-442a-9468-f1dfb8e67322 120424 0 2019-12-20 09:58:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying the configmap a second time
STEP: Expecting not to observe a notification because the object no longer meets the selector's requirements
STEP: changing the label value of the configmap back
STEP: modifying the configmap a third time
STEP: deleting the configmap
STEP: Expecting to observe an add notification for the watched object when the label value was restored
Dec 20 09:58:39.180: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7957 /api/v1/namespaces/watch-7957/configmaps/e2e-watch-test-label-changed 5fb2b97f-abe9-442a-9468-f1dfb8e67322 120452 0 2019-12-20 09:58:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 20 09:58:39.180: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7957 /api/v1/namespaces/watch-7957/configmaps/e2e-watch-test-label-changed 5fb2b97f-abe9-442a-9468-f1dfb8e67322 120453 0 2019-12-20 09:58:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
Dec 20 09:58:39.180: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-label-changed  watch-7957 /api/v1/namespaces/watch-7957/configmaps/e2e-watch-test-label-changed 5fb2b97f-abe9-442a-9468-f1dfb8e67322 120454 0 2019-12-20 09:58:29 +0000 UTC <nil> <nil> map[watch-this-configmap:label-changed-and-restored] map[] [] []  []},Data:map[string]string{mutation: 3,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:58:39.180: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-7957" for this suite.
Dec 20 09:58:45.194: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:58:45.294: INFO: namespace watch-7957 deletion completed in 6.109990401s

• [SLOW TEST:16.281 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe an object deletion if it stops meeting the requirements of the selector [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Proxy version v1 
  should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:58:45.294: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-9484
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy through a service and a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: starting an echo server on multiple ports
STEP: creating replication controller proxy-service-f6649 in namespace proxy-9484
I1220 09:58:45.460129      26 runners.go:184] Created replication controller with name: proxy-service-f6649, namespace: proxy-9484, replica count: 1
I1220 09:58:46.510574      26 runners.go:184] proxy-service-f6649 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1220 09:58:47.510806      26 runners.go:184] proxy-service-f6649 Pods: 1 out of 1 created, 0 running, 1 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
I1220 09:58:48.511041      26 runners.go:184] proxy-service-f6649 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1220 09:58:49.511304      26 runners.go:184] proxy-service-f6649 Pods: 1 out of 1 created, 0 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 1 runningButNotReady 
I1220 09:58:50.511539      26 runners.go:184] proxy-service-f6649 Pods: 1 out of 1 created, 1 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 20 09:58:50.516: INFO: setup took 5.092145787s, starting test cases
STEP: running 16 cases, 20 attempts per case, 320 total attempts
Dec 20 09:58:50.522: INFO: (0) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/rewriteme">test</a> (200; 5.953035ms)
Dec 20 09:58:50.522: INFO: (0) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/rewriteme">test<... (200; 5.917856ms)
Dec 20 09:58:50.523: INFO: (0) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname2/proxy/: bar (200; 6.278395ms)
Dec 20 09:58:50.523: INFO: (0) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:162/proxy/: bar (200; 6.784497ms)
Dec 20 09:58:50.523: INFO: (0) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname1/proxy/: foo (200; 6.964401ms)
Dec 20 09:58:50.523: INFO: (0) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:160/proxy/: foo (200; 7.07486ms)
Dec 20 09:58:50.523: INFO: (0) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/rewriteme">... (200; 7.123485ms)
Dec 20 09:58:50.524: INFO: (0) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:162/proxy/: bar (200; 7.772118ms)
Dec 20 09:58:50.524: INFO: (0) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname2/proxy/: bar (200; 7.809894ms)
Dec 20 09:58:50.524: INFO: (0) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:160/proxy/: foo (200; 7.759171ms)
Dec 20 09:58:50.524: INFO: (0) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname1/proxy/: foo (200; 7.86996ms)
Dec 20 09:58:50.530: INFO: (0) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:460/proxy/: tls baz (200; 14.111149ms)
Dec 20 09:58:50.530: INFO: (0) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/tlsrewritem... (200; 14.115317ms)
Dec 20 09:58:50.530: INFO: (0) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:462/proxy/: tls qux (200; 14.270159ms)
Dec 20 09:58:50.531: INFO: (0) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname1/proxy/: tls baz (200; 14.832917ms)
Dec 20 09:58:50.532: INFO: (0) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname2/proxy/: tls qux (200; 15.261796ms)
Dec 20 09:58:50.536: INFO: (1) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:460/proxy/: tls baz (200; 3.888594ms)
Dec 20 09:58:50.536: INFO: (1) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:160/proxy/: foo (200; 3.887277ms)
Dec 20 09:58:50.536: INFO: (1) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/tlsrewritem... (200; 3.911624ms)
Dec 20 09:58:50.536: INFO: (1) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/rewriteme">test<... (200; 4.070413ms)
Dec 20 09:58:50.536: INFO: (1) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/rewriteme">test</a> (200; 4.164011ms)
Dec 20 09:58:50.536: INFO: (1) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:162/proxy/: bar (200; 4.084988ms)
Dec 20 09:58:50.536: INFO: (1) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:160/proxy/: foo (200; 4.121875ms)
Dec 20 09:58:50.536: INFO: (1) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/rewriteme">... (200; 4.13857ms)
Dec 20 09:58:50.536: INFO: (1) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:162/proxy/: bar (200; 4.748096ms)
Dec 20 09:58:50.536: INFO: (1) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname1/proxy/: tls baz (200; 4.816288ms)
Dec 20 09:58:50.536: INFO: (1) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:462/proxy/: tls qux (200; 4.732436ms)
Dec 20 09:58:50.537: INFO: (1) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname2/proxy/: bar (200; 5.176041ms)
Dec 20 09:58:50.538: INFO: (1) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname1/proxy/: foo (200; 5.978157ms)
Dec 20 09:58:50.538: INFO: (1) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname1/proxy/: foo (200; 6.089525ms)
Dec 20 09:58:50.538: INFO: (1) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname2/proxy/: bar (200; 6.074234ms)
Dec 20 09:58:50.538: INFO: (1) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname2/proxy/: tls qux (200; 6.092678ms)
Dec 20 09:58:50.541: INFO: (2) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:462/proxy/: tls qux (200; 2.89276ms)
Dec 20 09:58:50.542: INFO: (2) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/rewriteme">test<... (200; 3.611066ms)
Dec 20 09:58:50.542: INFO: (2) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/rewriteme">... (200; 3.683354ms)
Dec 20 09:58:50.542: INFO: (2) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:160/proxy/: foo (200; 3.78896ms)
Dec 20 09:58:50.542: INFO: (2) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/tlsrewritem... (200; 3.708258ms)
Dec 20 09:58:50.542: INFO: (2) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:460/proxy/: tls baz (200; 3.856444ms)
Dec 20 09:58:50.542: INFO: (2) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:160/proxy/: foo (200; 4.176097ms)
Dec 20 09:58:50.542: INFO: (2) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:162/proxy/: bar (200; 4.259774ms)
Dec 20 09:58:50.542: INFO: (2) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/rewriteme">test</a> (200; 4.291093ms)
Dec 20 09:58:50.542: INFO: (2) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:162/proxy/: bar (200; 4.336358ms)
Dec 20 09:58:50.543: INFO: (2) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname2/proxy/: tls qux (200; 4.830345ms)
Dec 20 09:58:50.544: INFO: (2) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname1/proxy/: tls baz (200; 5.801993ms)
Dec 20 09:58:50.544: INFO: (2) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname2/proxy/: bar (200; 5.948014ms)
Dec 20 09:58:50.544: INFO: (2) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname1/proxy/: foo (200; 5.933645ms)
Dec 20 09:58:50.544: INFO: (2) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname2/proxy/: bar (200; 5.907878ms)
Dec 20 09:58:50.544: INFO: (2) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname1/proxy/: foo (200; 5.936995ms)
Dec 20 09:58:50.547: INFO: (3) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/rewriteme">test<... (200; 2.570203ms)
Dec 20 09:58:50.547: INFO: (3) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:160/proxy/: foo (200; 3.18934ms)
Dec 20 09:58:50.548: INFO: (3) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:162/proxy/: bar (200; 3.511473ms)
Dec 20 09:58:50.548: INFO: (3) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:160/proxy/: foo (200; 3.571396ms)
Dec 20 09:58:50.548: INFO: (3) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:162/proxy/: bar (200; 3.534548ms)
Dec 20 09:58:50.548: INFO: (3) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:462/proxy/: tls qux (200; 3.6206ms)
Dec 20 09:58:50.548: INFO: (3) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/tlsrewritem... (200; 3.57149ms)
Dec 20 09:58:50.548: INFO: (3) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/rewriteme">test</a> (200; 3.640202ms)
Dec 20 09:58:50.548: INFO: (3) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:460/proxy/: tls baz (200; 3.741459ms)
Dec 20 09:58:50.548: INFO: (3) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/rewriteme">... (200; 3.772181ms)
Dec 20 09:58:50.549: INFO: (3) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname1/proxy/: foo (200; 4.34278ms)
Dec 20 09:58:50.550: INFO: (3) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname2/proxy/: bar (200; 5.377057ms)
Dec 20 09:58:50.550: INFO: (3) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname2/proxy/: tls qux (200; 5.500464ms)
Dec 20 09:58:50.550: INFO: (3) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname1/proxy/: tls baz (200; 5.453801ms)
Dec 20 09:58:50.550: INFO: (3) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname1/proxy/: foo (200; 5.604507ms)
Dec 20 09:58:50.550: INFO: (3) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname2/proxy/: bar (200; 5.542826ms)
Dec 20 09:58:50.552: INFO: (4) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/rewriteme">test<... (200; 2.589285ms)
Dec 20 09:58:50.553: INFO: (4) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/rewriteme">test</a> (200; 3.282289ms)
Dec 20 09:58:50.553: INFO: (4) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/rewriteme">... (200; 3.334004ms)
Dec 20 09:58:50.553: INFO: (4) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:160/proxy/: foo (200; 3.640589ms)
Dec 20 09:58:50.554: INFO: (4) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/tlsrewritem... (200; 3.681562ms)
Dec 20 09:58:50.554: INFO: (4) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:460/proxy/: tls baz (200; 3.675168ms)
Dec 20 09:58:50.554: INFO: (4) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:162/proxy/: bar (200; 3.737409ms)
Dec 20 09:58:50.554: INFO: (4) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:462/proxy/: tls qux (200; 3.72258ms)
Dec 20 09:58:50.554: INFO: (4) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:160/proxy/: foo (200; 3.723292ms)
Dec 20 09:58:50.554: INFO: (4) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:162/proxy/: bar (200; 3.826157ms)
Dec 20 09:58:50.554: INFO: (4) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname1/proxy/: foo (200; 4.423277ms)
Dec 20 09:58:50.555: INFO: (4) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname1/proxy/: foo (200; 5.668341ms)
Dec 20 09:58:50.555: INFO: (4) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname1/proxy/: tls baz (200; 5.592772ms)
Dec 20 09:58:50.556: INFO: (4) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname2/proxy/: tls qux (200; 5.687953ms)
Dec 20 09:58:50.556: INFO: (4) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname2/proxy/: bar (200; 5.693129ms)
Dec 20 09:58:50.556: INFO: (4) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname2/proxy/: bar (200; 5.803104ms)
Dec 20 09:58:50.559: INFO: (5) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:162/proxy/: bar (200; 3.647984ms)
Dec 20 09:58:50.559: INFO: (5) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:160/proxy/: foo (200; 3.737682ms)
Dec 20 09:58:50.560: INFO: (5) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:162/proxy/: bar (200; 3.806673ms)
Dec 20 09:58:50.560: INFO: (5) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/rewriteme">... (200; 3.754924ms)
Dec 20 09:58:50.560: INFO: (5) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/rewriteme">test</a> (200; 4.052306ms)
Dec 20 09:58:50.560: INFO: (5) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:160/proxy/: foo (200; 4.043732ms)
Dec 20 09:58:50.560: INFO: (5) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:460/proxy/: tls baz (200; 4.069069ms)
Dec 20 09:58:50.560: INFO: (5) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/tlsrewritem... (200; 4.058694ms)
Dec 20 09:58:50.560: INFO: (5) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:462/proxy/: tls qux (200; 4.397755ms)
Dec 20 09:58:50.560: INFO: (5) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/rewriteme">test<... (200; 4.356777ms)
Dec 20 09:58:50.560: INFO: (5) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname1/proxy/: foo (200; 4.572987ms)
Dec 20 09:58:50.561: INFO: (5) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname2/proxy/: bar (200; 5.016302ms)
Dec 20 09:58:50.562: INFO: (5) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname2/proxy/: bar (200; 6.31559ms)
Dec 20 09:58:50.562: INFO: (5) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname1/proxy/: foo (200; 6.196517ms)
Dec 20 09:58:50.562: INFO: (5) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname2/proxy/: tls qux (200; 6.467598ms)
Dec 20 09:58:50.562: INFO: (5) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname1/proxy/: tls baz (200; 6.392014ms)
Dec 20 09:58:50.565: INFO: (6) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:460/proxy/: tls baz (200; 2.555691ms)
Dec 20 09:58:50.566: INFO: (6) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/rewriteme">test<... (200; 3.662667ms)
Dec 20 09:58:50.566: INFO: (6) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:160/proxy/: foo (200; 3.654028ms)
Dec 20 09:58:50.566: INFO: (6) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/tlsrewritem... (200; 3.659094ms)
Dec 20 09:58:50.566: INFO: (6) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:462/proxy/: tls qux (200; 3.672439ms)
Dec 20 09:58:50.566: INFO: (6) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/rewriteme">... (200; 3.692866ms)
Dec 20 09:58:50.566: INFO: (6) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:160/proxy/: foo (200; 3.674213ms)
Dec 20 09:58:50.566: INFO: (6) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/rewriteme">test</a> (200; 3.69636ms)
Dec 20 09:58:50.566: INFO: (6) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:162/proxy/: bar (200; 4.01449ms)
Dec 20 09:58:50.566: INFO: (6) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:162/proxy/: bar (200; 4.070262ms)
Dec 20 09:58:50.567: INFO: (6) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname2/proxy/: bar (200; 4.80508ms)
Dec 20 09:58:50.568: INFO: (6) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname2/proxy/: bar (200; 5.351377ms)
Dec 20 09:58:50.568: INFO: (6) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname1/proxy/: foo (200; 5.56692ms)
Dec 20 09:58:50.568: INFO: (6) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname1/proxy/: tls baz (200; 5.516439ms)
Dec 20 09:58:50.568: INFO: (6) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname2/proxy/: tls qux (200; 5.550441ms)
Dec 20 09:58:50.568: INFO: (6) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname1/proxy/: foo (200; 5.716542ms)
Dec 20 09:58:50.571: INFO: (7) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/tlsrewritem... (200; 2.538382ms)
Dec 20 09:58:50.571: INFO: (7) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:162/proxy/: bar (200; 3.258426ms)
Dec 20 09:58:50.571: INFO: (7) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/rewriteme">... (200; 3.232586ms)
Dec 20 09:58:50.572: INFO: (7) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/rewriteme">test</a> (200; 3.368317ms)
Dec 20 09:58:50.572: INFO: (7) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:160/proxy/: foo (200; 3.332749ms)
Dec 20 09:58:50.572: INFO: (7) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/rewriteme">test<... (200; 3.381534ms)
Dec 20 09:58:50.572: INFO: (7) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:460/proxy/: tls baz (200; 3.401645ms)
Dec 20 09:58:50.572: INFO: (7) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:160/proxy/: foo (200; 3.663928ms)
Dec 20 09:58:50.572: INFO: (7) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:162/proxy/: bar (200; 4.011719ms)
Dec 20 09:58:50.572: INFO: (7) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:462/proxy/: tls qux (200; 3.974781ms)
Dec 20 09:58:50.573: INFO: (7) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname2/proxy/: bar (200; 4.626453ms)
Dec 20 09:58:50.573: INFO: (7) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname1/proxy/: foo (200; 4.674464ms)
Dec 20 09:58:50.573: INFO: (7) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname2/proxy/: tls qux (200; 5.137105ms)
Dec 20 09:58:50.574: INFO: (7) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname1/proxy/: foo (200; 5.802452ms)
Dec 20 09:58:50.574: INFO: (7) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname2/proxy/: bar (200; 5.824593ms)
Dec 20 09:58:50.574: INFO: (7) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname1/proxy/: tls baz (200; 5.838735ms)
Dec 20 09:58:50.577: INFO: (8) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/tlsrewritem... (200; 2.530432ms)
Dec 20 09:58:50.577: INFO: (8) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/rewriteme">... (200; 3.284894ms)
Dec 20 09:58:50.577: INFO: (8) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:160/proxy/: foo (200; 3.195113ms)
Dec 20 09:58:50.577: INFO: (8) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:160/proxy/: foo (200; 3.18983ms)
Dec 20 09:58:50.577: INFO: (8) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:462/proxy/: tls qux (200; 3.300968ms)
Dec 20 09:58:50.577: INFO: (8) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/rewriteme">test</a> (200; 3.265514ms)
Dec 20 09:58:50.577: INFO: (8) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:162/proxy/: bar (200; 3.282862ms)
Dec 20 09:58:50.578: INFO: (8) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:162/proxy/: bar (200; 3.689258ms)
Dec 20 09:58:50.578: INFO: (8) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:460/proxy/: tls baz (200; 3.681653ms)
Dec 20 09:58:50.578: INFO: (8) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/rewriteme">test<... (200; 3.683441ms)
Dec 20 09:58:50.578: INFO: (8) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname1/proxy/: tls baz (200; 4.18926ms)
Dec 20 09:58:50.579: INFO: (8) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname2/proxy/: tls qux (200; 4.84775ms)
Dec 20 09:58:50.579: INFO: (8) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname1/proxy/: foo (200; 4.966467ms)
Dec 20 09:58:50.579: INFO: (8) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname1/proxy/: foo (200; 4.906686ms)
Dec 20 09:58:50.579: INFO: (8) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname2/proxy/: bar (200; 4.923013ms)
Dec 20 09:58:50.579: INFO: (8) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname2/proxy/: bar (200; 4.981077ms)
Dec 20 09:58:50.582: INFO: (9) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/tlsrewritem... (200; 2.456531ms)
Dec 20 09:58:50.582: INFO: (9) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:162/proxy/: bar (200; 2.65339ms)
Dec 20 09:58:50.582: INFO: (9) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:160/proxy/: foo (200; 2.846661ms)
Dec 20 09:58:50.582: INFO: (9) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/rewriteme">test</a> (200; 2.846735ms)
Dec 20 09:58:50.582: INFO: (9) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/rewriteme">test<... (200; 2.855539ms)
Dec 20 09:58:50.583: INFO: (9) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:162/proxy/: bar (200; 3.621774ms)
Dec 20 09:58:50.583: INFO: (9) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/rewriteme">... (200; 3.794614ms)
Dec 20 09:58:50.583: INFO: (9) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:160/proxy/: foo (200; 3.891307ms)
Dec 20 09:58:50.583: INFO: (9) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:462/proxy/: tls qux (200; 3.924381ms)
Dec 20 09:58:50.583: INFO: (9) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:460/proxy/: tls baz (200; 3.979301ms)
Dec 20 09:58:50.583: INFO: (9) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname1/proxy/: foo (200; 3.954456ms)
Dec 20 09:58:50.584: INFO: (9) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname2/proxy/: bar (200; 4.577958ms)
Dec 20 09:58:50.584: INFO: (9) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname2/proxy/: bar (200; 4.728415ms)
Dec 20 09:58:50.584: INFO: (9) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname1/proxy/: foo (200; 4.752952ms)
Dec 20 09:58:50.584: INFO: (9) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname1/proxy/: tls baz (200; 4.788806ms)
Dec 20 09:58:50.584: INFO: (9) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname2/proxy/: tls qux (200; 4.817181ms)
Dec 20 09:58:50.587: INFO: (10) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:162/proxy/: bar (200; 2.837285ms)
Dec 20 09:58:50.587: INFO: (10) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:460/proxy/: tls baz (200; 2.969553ms)
Dec 20 09:58:50.587: INFO: (10) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/rewriteme">test<... (200; 3.030572ms)
Dec 20 09:58:50.587: INFO: (10) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:462/proxy/: tls qux (200; 2.996693ms)
Dec 20 09:58:50.587: INFO: (10) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/tlsrewritem... (200; 2.962484ms)
Dec 20 09:58:50.587: INFO: (10) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:160/proxy/: foo (200; 3.233988ms)
Dec 20 09:58:50.587: INFO: (10) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/rewriteme">test</a> (200; 3.389635ms)
Dec 20 09:58:50.588: INFO: (10) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:160/proxy/: foo (200; 3.598898ms)
Dec 20 09:58:50.588: INFO: (10) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:162/proxy/: bar (200; 3.617067ms)
Dec 20 09:58:50.588: INFO: (10) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/rewriteme">... (200; 3.636283ms)
Dec 20 09:58:50.588: INFO: (10) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname2/proxy/: tls qux (200; 4.042354ms)
Dec 20 09:58:50.589: INFO: (10) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname1/proxy/: foo (200; 4.476033ms)
Dec 20 09:58:50.589: INFO: (10) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname1/proxy/: foo (200; 4.436685ms)
Dec 20 09:58:50.589: INFO: (10) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname2/proxy/: bar (200; 4.532843ms)
Dec 20 09:58:50.589: INFO: (10) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname2/proxy/: bar (200; 4.812047ms)
Dec 20 09:58:50.589: INFO: (10) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname1/proxy/: tls baz (200; 5.097509ms)
Dec 20 09:58:50.593: INFO: (11) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:160/proxy/: foo (200; 3.368337ms)
Dec 20 09:58:50.593: INFO: (11) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:460/proxy/: tls baz (200; 3.661316ms)
Dec 20 09:58:50.593: INFO: (11) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/rewriteme">test</a> (200; 3.66708ms)
Dec 20 09:58:50.593: INFO: (11) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:162/proxy/: bar (200; 3.822334ms)
Dec 20 09:58:50.594: INFO: (11) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/rewriteme">test<... (200; 4.343123ms)
Dec 20 09:58:50.594: INFO: (11) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/tlsrewritem... (200; 4.650312ms)
Dec 20 09:58:50.594: INFO: (11) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:160/proxy/: foo (200; 4.77472ms)
Dec 20 09:58:50.594: INFO: (11) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:162/proxy/: bar (200; 4.779299ms)
Dec 20 09:58:50.594: INFO: (11) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:462/proxy/: tls qux (200; 4.744334ms)
Dec 20 09:58:50.595: INFO: (11) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname1/proxy/: foo (200; 5.317201ms)
Dec 20 09:58:50.595: INFO: (11) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/rewriteme">... (200; 5.380248ms)
Dec 20 09:58:50.595: INFO: (11) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname2/proxy/: bar (200; 5.483897ms)
Dec 20 09:58:50.595: INFO: (11) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname2/proxy/: tls qux (200; 5.963143ms)
Dec 20 09:58:50.595: INFO: (11) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname1/proxy/: foo (200; 5.856153ms)
Dec 20 09:58:50.595: INFO: (11) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname2/proxy/: bar (200; 6.129117ms)
Dec 20 09:58:50.596: INFO: (11) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname1/proxy/: tls baz (200; 6.24173ms)
Dec 20 09:58:50.598: INFO: (12) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/rewriteme">test<... (200; 2.675373ms)
Dec 20 09:58:50.599: INFO: (12) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:160/proxy/: foo (200; 3.097799ms)
Dec 20 09:58:50.599: INFO: (12) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:160/proxy/: foo (200; 3.124542ms)
Dec 20 09:58:50.600: INFO: (12) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:162/proxy/: bar (200; 3.847455ms)
Dec 20 09:58:50.600: INFO: (12) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/rewriteme">... (200; 4.27594ms)
Dec 20 09:58:50.600: INFO: (12) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:460/proxy/: tls baz (200; 4.370942ms)
Dec 20 09:58:50.600: INFO: (12) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/rewriteme">test</a> (200; 4.379928ms)
Dec 20 09:58:50.600: INFO: (12) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/tlsrewritem... (200; 4.329249ms)
Dec 20 09:58:50.600: INFO: (12) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:162/proxy/: bar (200; 4.282507ms)
Dec 20 09:58:50.600: INFO: (12) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname1/proxy/: foo (200; 4.27233ms)
Dec 20 09:58:50.600: INFO: (12) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:462/proxy/: tls qux (200; 4.459672ms)
Dec 20 09:58:50.601: INFO: (12) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname2/proxy/: bar (200; 5.17277ms)
Dec 20 09:58:50.601: INFO: (12) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname2/proxy/: bar (200; 5.260843ms)
Dec 20 09:58:50.601: INFO: (12) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname1/proxy/: foo (200; 5.174074ms)
Dec 20 09:58:50.601: INFO: (12) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname1/proxy/: tls baz (200; 5.149697ms)
Dec 20 09:58:50.601: INFO: (12) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname2/proxy/: tls qux (200; 5.457957ms)
Dec 20 09:58:50.604: INFO: (13) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/rewriteme">test</a> (200; 2.995431ms)
Dec 20 09:58:50.605: INFO: (13) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:160/proxy/: foo (200; 3.56225ms)
Dec 20 09:58:50.605: INFO: (13) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:162/proxy/: bar (200; 3.669885ms)
Dec 20 09:58:50.605: INFO: (13) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:162/proxy/: bar (200; 3.733711ms)
Dec 20 09:58:50.605: INFO: (13) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/rewriteme">test<... (200; 3.72365ms)
Dec 20 09:58:50.605: INFO: (13) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:462/proxy/: tls qux (200; 3.715285ms)
Dec 20 09:58:50.605: INFO: (13) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/rewriteme">... (200; 3.756586ms)
Dec 20 09:58:50.605: INFO: (13) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/tlsrewritem... (200; 3.802702ms)
Dec 20 09:58:50.605: INFO: (13) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:160/proxy/: foo (200; 3.836176ms)
Dec 20 09:58:50.606: INFO: (13) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:460/proxy/: tls baz (200; 3.996862ms)
Dec 20 09:58:50.606: INFO: (13) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname1/proxy/: foo (200; 4.196211ms)
Dec 20 09:58:50.607: INFO: (13) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname1/proxy/: foo (200; 5.058465ms)
Dec 20 09:58:50.607: INFO: (13) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname2/proxy/: bar (200; 5.023515ms)
Dec 20 09:58:50.607: INFO: (13) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname2/proxy/: tls qux (200; 5.099867ms)
Dec 20 09:58:50.607: INFO: (13) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname2/proxy/: bar (200; 5.257678ms)
Dec 20 09:58:50.607: INFO: (13) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname1/proxy/: tls baz (200; 5.152928ms)
Dec 20 09:58:50.609: INFO: (14) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/tlsrewritem... (200; 2.438588ms)
Dec 20 09:58:50.610: INFO: (14) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:162/proxy/: bar (200; 3.165447ms)
Dec 20 09:58:50.610: INFO: (14) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/rewriteme">test</a> (200; 3.130993ms)
Dec 20 09:58:50.610: INFO: (14) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:160/proxy/: foo (200; 3.188441ms)
Dec 20 09:58:50.610: INFO: (14) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:460/proxy/: tls baz (200; 3.221445ms)
Dec 20 09:58:50.610: INFO: (14) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:462/proxy/: tls qux (200; 3.247728ms)
Dec 20 09:58:50.610: INFO: (14) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:162/proxy/: bar (200; 3.294426ms)
Dec 20 09:58:50.610: INFO: (14) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:160/proxy/: foo (200; 3.377772ms)
Dec 20 09:58:50.610: INFO: (14) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/rewriteme">... (200; 3.429131ms)
Dec 20 09:58:50.610: INFO: (14) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/rewriteme">test<... (200; 3.516542ms)
Dec 20 09:58:50.611: INFO: (14) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname2/proxy/: tls qux (200; 4.432066ms)
Dec 20 09:58:50.612: INFO: (14) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname1/proxy/: foo (200; 5.163028ms)
Dec 20 09:58:50.612: INFO: (14) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname1/proxy/: tls baz (200; 5.190075ms)
Dec 20 09:58:50.612: INFO: (14) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname2/proxy/: bar (200; 5.184703ms)
Dec 20 09:58:50.612: INFO: (14) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname2/proxy/: bar (200; 5.309469ms)
Dec 20 09:58:50.612: INFO: (14) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname1/proxy/: foo (200; 5.347751ms)
Dec 20 09:58:50.616: INFO: (15) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/rewriteme">test<... (200; 3.259325ms)
Dec 20 09:58:50.616: INFO: (15) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/tlsrewritem... (200; 3.295937ms)
Dec 20 09:58:50.616: INFO: (15) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:160/proxy/: foo (200; 3.296024ms)
Dec 20 09:58:50.616: INFO: (15) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:162/proxy/: bar (200; 3.358615ms)
Dec 20 09:58:50.616: INFO: (15) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:462/proxy/: tls qux (200; 3.388235ms)
Dec 20 09:58:50.616: INFO: (15) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:162/proxy/: bar (200; 3.438447ms)
Dec 20 09:58:50.617: INFO: (15) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/rewriteme">test</a> (200; 4.108365ms)
Dec 20 09:58:50.617: INFO: (15) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:460/proxy/: tls baz (200; 4.130256ms)
Dec 20 09:58:50.617: INFO: (15) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:160/proxy/: foo (200; 4.126631ms)
Dec 20 09:58:50.617: INFO: (15) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/rewriteme">... (200; 4.159729ms)
Dec 20 09:58:50.617: INFO: (15) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname1/proxy/: tls baz (200; 4.360391ms)
Dec 20 09:58:50.617: INFO: (15) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname2/proxy/: bar (200; 4.321001ms)
Dec 20 09:58:50.617: INFO: (15) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname1/proxy/: foo (200; 5.099231ms)
Dec 20 09:58:50.618: INFO: (15) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname1/proxy/: foo (200; 5.25776ms)
Dec 20 09:58:50.618: INFO: (15) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname2/proxy/: bar (200; 5.40637ms)
Dec 20 09:58:50.618: INFO: (15) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname2/proxy/: tls qux (200; 5.335561ms)
Dec 20 09:58:50.620: INFO: (16) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/tlsrewritem... (200; 2.566151ms)
Dec 20 09:58:50.621: INFO: (16) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:162/proxy/: bar (200; 3.337879ms)
Dec 20 09:58:50.621: INFO: (16) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/rewriteme">test<... (200; 3.465651ms)
Dec 20 09:58:50.621: INFO: (16) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/rewriteme">... (200; 3.373939ms)
Dec 20 09:58:50.621: INFO: (16) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:160/proxy/: foo (200; 3.497981ms)
Dec 20 09:58:50.621: INFO: (16) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:160/proxy/: foo (200; 3.472964ms)
Dec 20 09:58:50.621: INFO: (16) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:162/proxy/: bar (200; 3.46837ms)
Dec 20 09:58:50.621: INFO: (16) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:460/proxy/: tls baz (200; 3.528305ms)
Dec 20 09:58:50.621: INFO: (16) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:462/proxy/: tls qux (200; 3.492569ms)
Dec 20 09:58:50.621: INFO: (16) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/rewriteme">test</a> (200; 3.603583ms)
Dec 20 09:58:50.622: INFO: (16) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname2/proxy/: tls qux (200; 4.144411ms)
Dec 20 09:58:50.622: INFO: (16) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname1/proxy/: foo (200; 4.559919ms)
Dec 20 09:58:50.623: INFO: (16) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname1/proxy/: foo (200; 5.317197ms)
Dec 20 09:58:50.623: INFO: (16) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname2/proxy/: bar (200; 5.301091ms)
Dec 20 09:58:50.623: INFO: (16) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname1/proxy/: tls baz (200; 5.433716ms)
Dec 20 09:58:50.623: INFO: (16) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname2/proxy/: bar (200; 5.434918ms)
Dec 20 09:58:50.626: INFO: (17) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/rewriteme">test</a> (200; 2.539618ms)
Dec 20 09:58:50.627: INFO: (17) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:160/proxy/: foo (200; 3.152167ms)
Dec 20 09:58:50.627: INFO: (17) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:160/proxy/: foo (200; 3.430559ms)
Dec 20 09:58:50.627: INFO: (17) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:162/proxy/: bar (200; 3.493686ms)
Dec 20 09:58:50.627: INFO: (17) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/rewriteme">test<... (200; 3.673842ms)
Dec 20 09:58:50.627: INFO: (17) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:162/proxy/: bar (200; 3.599666ms)
Dec 20 09:58:50.627: INFO: (17) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/tlsrewritem... (200; 3.825553ms)
Dec 20 09:58:50.627: INFO: (17) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/rewriteme">... (200; 3.816487ms)
Dec 20 09:58:50.627: INFO: (17) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:462/proxy/: tls qux (200; 3.836879ms)
Dec 20 09:58:50.627: INFO: (17) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:460/proxy/: tls baz (200; 3.885853ms)
Dec 20 09:58:50.628: INFO: (17) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname2/proxy/: tls qux (200; 4.942848ms)
Dec 20 09:58:50.629: INFO: (17) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname1/proxy/: foo (200; 5.600974ms)
Dec 20 09:58:50.629: INFO: (17) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname1/proxy/: tls baz (200; 5.680207ms)
Dec 20 09:58:50.629: INFO: (17) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname2/proxy/: bar (200; 5.603644ms)
Dec 20 09:58:50.629: INFO: (17) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname2/proxy/: bar (200; 5.635462ms)
Dec 20 09:58:50.629: INFO: (17) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname1/proxy/: foo (200; 5.65635ms)
Dec 20 09:58:50.632: INFO: (18) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/rewriteme">test</a> (200; 2.473935ms)
Dec 20 09:58:50.632: INFO: (18) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/rewriteme">test<... (200; 2.869386ms)
Dec 20 09:58:50.632: INFO: (18) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/rewriteme">... (200; 2.911037ms)
Dec 20 09:58:50.632: INFO: (18) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:162/proxy/: bar (200; 2.960389ms)
Dec 20 09:58:50.632: INFO: (18) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:160/proxy/: foo (200; 3.070338ms)
Dec 20 09:58:50.632: INFO: (18) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:160/proxy/: foo (200; 3.148283ms)
Dec 20 09:58:50.632: INFO: (18) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:460/proxy/: tls baz (200; 3.126214ms)
Dec 20 09:58:50.633: INFO: (18) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:162/proxy/: bar (200; 3.367212ms)
Dec 20 09:58:50.633: INFO: (18) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:462/proxy/: tls qux (200; 3.526554ms)
Dec 20 09:58:50.633: INFO: (18) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/tlsrewritem... (200; 3.54355ms)
Dec 20 09:58:50.633: INFO: (18) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname1/proxy/: tls baz (200; 4.039263ms)
Dec 20 09:58:50.634: INFO: (18) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname1/proxy/: foo (200; 4.637795ms)
Dec 20 09:58:50.634: INFO: (18) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname2/proxy/: bar (200; 5.190387ms)
Dec 20 09:58:50.635: INFO: (18) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname2/proxy/: bar (200; 5.294472ms)
Dec 20 09:58:50.635: INFO: (18) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname2/proxy/: tls qux (200; 5.387045ms)
Dec 20 09:58:50.635: INFO: (18) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname1/proxy/: foo (200; 5.45995ms)
Dec 20 09:58:50.637: INFO: (19) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:162/proxy/: bar (200; 2.415217ms)
Dec 20 09:58:50.638: INFO: (19) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b/proxy/rewriteme">test</a> (200; 2.923352ms)
Dec 20 09:58:50.638: INFO: (19) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:460/proxy/: tls baz (200; 3.087451ms)
Dec 20 09:58:50.638: INFO: (19) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:160/proxy/: foo (200; 3.148314ms)
Dec 20 09:58:50.639: INFO: (19) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:162/proxy/: bar (200; 3.732869ms)
Dec 20 09:58:50.639: INFO: (19) /api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/http:proxy-service-f6649-c298b:1080/proxy/rewriteme">... (200; 3.738668ms)
Dec 20 09:58:50.639: INFO: (19) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:462/proxy/: tls qux (200; 3.893297ms)
Dec 20 09:58:50.639: INFO: (19) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:160/proxy/: foo (200; 3.779022ms)
Dec 20 09:58:50.639: INFO: (19) /api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/https:proxy-service-f6649-c298b:443/proxy/tlsrewritem... (200; 3.836173ms)
Dec 20 09:58:50.639: INFO: (19) /api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/: <a href="/api/v1/namespaces/proxy-9484/pods/proxy-service-f6649-c298b:1080/proxy/rewriteme">test<... (200; 3.900535ms)
Dec 20 09:58:50.639: INFO: (19) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname2/proxy/: tls qux (200; 4.362534ms)
Dec 20 09:58:50.640: INFO: (19) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname2/proxy/: bar (200; 5.14973ms)
Dec 20 09:58:50.640: INFO: (19) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname2/proxy/: bar (200; 5.079305ms)
Dec 20 09:58:50.640: INFO: (19) /api/v1/namespaces/proxy-9484/services/proxy-service-f6649:portname1/proxy/: foo (200; 5.114706ms)
Dec 20 09:58:50.641: INFO: (19) /api/v1/namespaces/proxy-9484/services/https:proxy-service-f6649:tlsportname1/proxy/: tls baz (200; 5.702703ms)
Dec 20 09:58:50.641: INFO: (19) /api/v1/namespaces/proxy-9484/services/http:proxy-service-f6649:portname1/proxy/: foo (200; 5.747026ms)
STEP: deleting ReplicationController proxy-service-f6649 in namespace proxy-9484, will wait for the garbage collector to delete the pods
Dec 20 09:58:50.701: INFO: Deleting ReplicationController proxy-service-f6649 took: 7.687344ms
Dec 20 09:58:51.101: INFO: Terminating ReplicationController proxy-service-f6649 pods took: 400.23702ms
[AfterEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:58:55.601: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-9484" for this suite.
Dec 20 09:59:01.618: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:59:01.706: INFO: namespace proxy-9484 deletion completed in 6.100609595s

• [SLOW TEST:16.412 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy through a service and a pod  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:59:01.707: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-7617
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 20 09:59:04.373: INFO: Successfully updated pod "pod-update-activedeadlineseconds-08ddf9a5-7d22-4fc3-a43b-6f9cd323a0e9"
Dec 20 09:59:04.373: INFO: Waiting up to 5m0s for pod "pod-update-activedeadlineseconds-08ddf9a5-7d22-4fc3-a43b-6f9cd323a0e9" in namespace "pods-7617" to be "terminated due to deadline exceeded"
Dec 20 09:59:04.376: INFO: Pod "pod-update-activedeadlineseconds-08ddf9a5-7d22-4fc3-a43b-6f9cd323a0e9": Phase="Running", Reason="", readiness=true. Elapsed: 2.550173ms
Dec 20 09:59:06.380: INFO: Pod "pod-update-activedeadlineseconds-08ddf9a5-7d22-4fc3-a43b-6f9cd323a0e9": Phase="Running", Reason="", readiness=true. Elapsed: 2.006168353s
Dec 20 09:59:08.383: INFO: Pod "pod-update-activedeadlineseconds-08ddf9a5-7d22-4fc3-a43b-6f9cd323a0e9": Phase="Failed", Reason="DeadlineExceeded", readiness=false. Elapsed: 4.00974752s
Dec 20 09:59:08.383: INFO: Pod "pod-update-activedeadlineseconds-08ddf9a5-7d22-4fc3-a43b-6f9cd323a0e9" satisfied condition "terminated due to deadline exceeded"
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:59:08.383: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-7617" for this suite.
Dec 20 09:59:14.397: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:59:14.490: INFO: namespace pods-7617 deletion completed in 6.102197739s

• [SLOW TEST:12.783 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicationController 
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:59:14.490: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename replication-controller
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replication-controller-8455
STEP: Waiting for a default service account to be provisioned in namespace
[It] should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 09:59:14.625: INFO: Creating quota "condition-test" that allows only two pods to run in the current namespace
STEP: Creating rc "condition-test" that asks for more than the allowed pod quota
STEP: Checking rc "condition-test" has the desired failure condition set
STEP: Scaling down rc "condition-test" to satisfy pod quota
Dec 20 09:59:16.652: INFO: Updating replication controller "condition-test"
STEP: Checking rc "condition-test" has no failure condition set
[AfterEach] [sig-apps] ReplicationController
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:59:17.658: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replication-controller-8455" for this suite.
Dec 20 09:59:23.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:59:23.769: INFO: namespace replication-controller-8455 deletion completed in 6.106672353s

• [SLOW TEST:9.279 seconds]
[sig-apps] ReplicationController
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should surface a failure condition on a common issue like exceeded quota [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:59:23.769: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-708
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for all rs to be garbage collected
STEP: expected 0 rs, got 1 rs
STEP: expected 0 pods, got 2 pods
STEP: Gathering metrics
Dec 20 09:59:24.939: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

W1220 09:59:24.939919      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:59:24.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-708" for this suite.
Dec 20 09:59:30.955: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 09:59:31.051: INFO: namespace gc-708 deletion completed in 6.107721786s

• [SLOW TEST:7.282 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete RS created by deployment when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 09:59:31.052: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-6831
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute poststart exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: check poststart hook
STEP: delete the pod with lifecycle hook
Dec 20 09:59:39.236: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 20 09:59:39.239: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 20 09:59:41.239: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 20 09:59:41.243: INFO: Pod pod-with-poststart-exec-hook still exists
Dec 20 09:59:43.239: INFO: Waiting for pod pod-with-poststart-exec-hook to disappear
Dec 20 09:59:43.244: INFO: Pod pod-with-poststart-exec-hook no longer exists
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 09:59:43.244: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-6831" for this suite.
Dec 20 10:00:11.260: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:00:11.350: INFO: namespace container-lifecycle-hook-6831 deletion completed in 28.100768258s

• [SLOW TEST:40.298 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute poststart exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:00:11.350: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8924
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-16a2d924-c2fc-4e6d-8693-1bf1fae6dc51
STEP: Creating a pod to test consume secrets
Dec 20 10:00:11.494: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-9f83bcb1-6b15-4d70-b392-e56732739e66" in namespace "projected-8924" to be "success or failure"
Dec 20 10:00:11.496: INFO: Pod "pod-projected-secrets-9f83bcb1-6b15-4d70-b392-e56732739e66": Phase="Pending", Reason="", readiness=false. Elapsed: 2.281442ms
Dec 20 10:00:13.500: INFO: Pod "pod-projected-secrets-9f83bcb1-6b15-4d70-b392-e56732739e66": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006157675s
Dec 20 10:00:15.504: INFO: Pod "pod-projected-secrets-9f83bcb1-6b15-4d70-b392-e56732739e66": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010143137s
STEP: Saw pod success
Dec 20 10:00:15.504: INFO: Pod "pod-projected-secrets-9f83bcb1-6b15-4d70-b392-e56732739e66" satisfied condition "success or failure"
Dec 20 10:00:15.507: INFO: Trying to get logs from node caasp-worker-th-before-3 pod pod-projected-secrets-9f83bcb1-6b15-4d70-b392-e56732739e66 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 20 10:00:15.534: INFO: Waiting for pod pod-projected-secrets-9f83bcb1-6b15-4d70-b392-e56732739e66 to disappear
Dec 20 10:00:15.536: INFO: Pod pod-projected-secrets-9f83bcb1-6b15-4d70-b392-e56732739e66 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:00:15.536: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8924" for this suite.
Dec 20 10:00:21.549: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:00:21.642: INFO: namespace projected-8924 deletion completed in 6.102533185s

• [SLOW TEST:10.292 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command that always fails in a pod 
  should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:00:21.643: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-6804
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[BeforeEach] when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:81
[It] should have an terminated reason [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:00:25.786: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-6804" for this suite.
Dec 20 10:00:31.802: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:00:31.895: INFO: namespace kubelet-test-6804 deletion completed in 6.104957295s

• [SLOW TEST:10.252 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command that always fails in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:78
    should have an terminated reason [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:00:31.895: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8520
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 20 10:00:36.570: INFO: Successfully updated pod "labelsupdateb4246792-ed4f-4518-892b-50dce1a5914b"
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:00:38.585: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8520" for this suite.
Dec 20 10:01:06.601: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:01:06.695: INFO: namespace projected-8520 deletion completed in 28.10580064s

• [SLOW TEST:34.800 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should update labels on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:01:06.695: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-399
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 20 10:01:07.502: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 20 10:01:09.513: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432868, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432868, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432868, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432868, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 20 10:01:12.528: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the admissionregistration.k8s.io API group in the /apis discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/admissionregistration.k8s.io discovery document
STEP: finding the admissionregistration.k8s.io/v1 API group/version in the /apis/admissionregistration.k8s.io discovery document
STEP: fetching the /apis/admissionregistration.k8s.io/v1 discovery document
STEP: finding mutatingwebhookconfigurations and validatingwebhookconfigurations resources in the /apis/admissionregistration.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:01:12.534: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-399" for this suite.
Dec 20 10:01:18.547: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:01:18.635: INFO: namespace webhook-399 deletion completed in 6.097791721s
STEP: Destroying namespace "webhook-399-markers" for this suite.
Dec 20 10:01:24.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:01:24.741: INFO: namespace webhook-399-markers deletion completed in 6.105484141s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.059 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include webhook resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:01:24.754: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-3638
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 10:01:24.886: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 20 10:01:29.707: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 --namespace=crd-publish-openapi-3638 create -f -'
Dec 20 10:01:30.061: INFO: stderr: ""
Dec 20 10:01:30.061: INFO: stdout: "e2e-test-crd-publish-openapi-5940-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 20 10:01:30.061: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 --namespace=crd-publish-openapi-3638 delete e2e-test-crd-publish-openapi-5940-crds test-cr'
Dec 20 10:01:30.228: INFO: stderr: ""
Dec 20 10:01:30.228: INFO: stdout: "e2e-test-crd-publish-openapi-5940-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
Dec 20 10:01:30.228: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 --namespace=crd-publish-openapi-3638 apply -f -'
Dec 20 10:01:30.467: INFO: stderr: ""
Dec 20 10:01:30.467: INFO: stdout: "e2e-test-crd-publish-openapi-5940-crd.crd-publish-openapi-test-empty.example.com/test-cr created\n"
Dec 20 10:01:30.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 --namespace=crd-publish-openapi-3638 delete e2e-test-crd-publish-openapi-5940-crds test-cr'
Dec 20 10:01:30.559: INFO: stderr: ""
Dec 20 10:01:30.559: INFO: stdout: "e2e-test-crd-publish-openapi-5940-crd.crd-publish-openapi-test-empty.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR without validation schema
Dec 20 10:01:30.559: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 explain e2e-test-crd-publish-openapi-5940-crds'
Dec 20 10:01:30.727: INFO: stderr: ""
Dec 20 10:01:30.727: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-5940-crd\nVERSION:  crd-publish-openapi-test-empty.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:01:35.639: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-3638" for this suite.
Dec 20 10:01:41.656: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:01:41.757: INFO: namespace crd-publish-openapi-3638 deletion completed in 6.113157453s

• [SLOW TEST:17.003 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD without validation schema [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:01:41.757: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9072
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 20 10:01:42.538: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 20 10:01:44.547: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432903, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432903, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432903, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432903, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 20 10:01:47.562: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a validating webhook configuration
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Updating a validating webhook configuration's rules to not include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Patching a validating webhook configuration's rules to include the create operation
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:01:47.623: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9072" for this suite.
Dec 20 10:01:53.638: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:01:53.747: INFO: namespace webhook-9072 deletion completed in 6.120078389s
STEP: Destroying namespace "webhook-9072-markers" for this suite.
Dec 20 10:01:59.758: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:01:59.851: INFO: namespace webhook-9072-markers deletion completed in 6.104236568s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.107 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  patching/updating a validating webhook should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:01:59.865: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-7327
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 20 10:02:00.810: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 20 10:02:02.820: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432921, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432921, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432921, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712432921, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 20 10:02:05.834: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that should be mutated
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that should not be mutated
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:02:05.966: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-7327" for this suite.
Dec 20 10:02:11.982: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:02:12.074: INFO: namespace webhook-7327 deletion completed in 6.103121103s
STEP: Destroying namespace "webhook-7327-markers" for this suite.
Dec 20 10:02:18.085: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:02:18.173: INFO: namespace webhook-7327-markers deletion completed in 6.098560386s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.319 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing mutating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:02:18.184: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-9329
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ReplicaSet
STEP: Ensuring resource quota status captures replicaset creation
STEP: Deleting a ReplicaSet
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:02:29.354: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-9329" for this suite.
Dec 20 10:02:35.370: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:02:35.454: INFO: namespace resourcequota-9329 deletion completed in 6.096276129s

• [SLOW TEST:17.271 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a replica set. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:02:35.455: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4321
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-map-eec90430-c3e3-4767-9068-6786f75a61aa
STEP: Creating a pod to test consume configMaps
Dec 20 10:02:35.599: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-26bc21c2-7bf0-4070-a93d-aa1f3da78a59" in namespace "projected-4321" to be "success or failure"
Dec 20 10:02:35.602: INFO: Pod "pod-projected-configmaps-26bc21c2-7bf0-4070-a93d-aa1f3da78a59": Phase="Pending", Reason="", readiness=false. Elapsed: 2.82355ms
Dec 20 10:02:37.606: INFO: Pod "pod-projected-configmaps-26bc21c2-7bf0-4070-a93d-aa1f3da78a59": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006704387s
Dec 20 10:02:39.610: INFO: Pod "pod-projected-configmaps-26bc21c2-7bf0-4070-a93d-aa1f3da78a59": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010753758s
STEP: Saw pod success
Dec 20 10:02:39.610: INFO: Pod "pod-projected-configmaps-26bc21c2-7bf0-4070-a93d-aa1f3da78a59" satisfied condition "success or failure"
Dec 20 10:02:39.614: INFO: Trying to get logs from node caasp-worker-th-before-3 pod pod-projected-configmaps-26bc21c2-7bf0-4070-a93d-aa1f3da78a59 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 10:02:39.638: INFO: Waiting for pod pod-projected-configmaps-26bc21c2-7bf0-4070-a93d-aa1f3da78a59 to disappear
Dec 20 10:02:39.641: INFO: Pod pod-projected-configmaps-26bc21c2-7bf0-4070-a93d-aa1f3da78a59 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:02:39.641: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4321" for this suite.
Dec 20 10:02:45.654: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:02:45.752: INFO: namespace projected-4321 deletion completed in 6.107462526s

• [SLOW TEST:10.297 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run default 
  should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:02:45.752: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5125
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run default
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1403
[It] should create an rc or deployment from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 20 10:02:45.884: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 run e2e-test-httpd-deployment --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-5125'
Dec 20 10:02:45.988: INFO: stderr: "kubectl run --generator=deployment/apps.v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 20 10:02:45.988: INFO: stdout: "deployment.apps/e2e-test-httpd-deployment created\n"
STEP: verifying the pod controlled by e2e-test-httpd-deployment gets created
[AfterEach] Kubectl run default
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1409
Dec 20 10:02:47.994: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 delete deployment e2e-test-httpd-deployment --namespace=kubectl-5125'
Dec 20 10:02:48.085: INFO: stderr: ""
Dec 20 10:02:48.085: INFO: stdout: "deployment.apps \"e2e-test-httpd-deployment\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:02:48.085: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5125" for this suite.
Dec 20 10:03:00.103: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:03:00.195: INFO: namespace kubectl-5125 deletion completed in 12.106324728s

• [SLOW TEST:14.443 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run default
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1397
    should create an rc or deployment from an image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:03:00.195: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-5297
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-5297
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 20 10:03:00.329: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 20 10:03:26.399: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.7.225 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5297 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 10:03:26.399: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 10:03:27.472: INFO: Found all expected endpoints: [netserver-0]
Dec 20 10:03:27.476: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.6.185 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5297 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 10:03:27.476: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 10:03:28.553: INFO: Found all expected endpoints: [netserver-1]
Dec 20 10:03:28.557: INFO: ExecWithOptions {Command:[/bin/sh -c echo hostName | nc -w 1 -u 10.244.5.115 8081 | grep -v '^\s*$'] Namespace:pod-network-test-5297 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 10:03:28.557: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 10:03:29.624: INFO: Found all expected endpoints: [netserver-2]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:03:29.624: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-5297" for this suite.
Dec 20 10:03:41.639: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:03:41.735: INFO: namespace pod-network-test-5297 deletion completed in 12.106642596s

• [SLOW TEST:41.540 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:03:41.735: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9699
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 20 10:03:42.447: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 20 10:03:44.457: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712433023, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712433023, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712433023, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712433023, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 20 10:03:47.474: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Listing all of the created validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
STEP: Deleting the collection of validation webhooks
STEP: Creating a configMap that does not comply to the validation webhook rules
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:03:47.614: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9699" for this suite.
Dec 20 10:03:53.628: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:03:53.717: INFO: namespace webhook-9699 deletion completed in 6.099170666s
STEP: Destroying namespace "webhook-9699-markers" for this suite.
Dec 20 10:03:59.729: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:03:59.823: INFO: namespace webhook-9699-markers deletion completed in 6.106016854s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.099 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  listing validating webhooks should work [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:03:59.835: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-618
STEP: Waiting for a default service account to be provisioned in namespace
[It] should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Given a Pod with a 'name' label pod-adoption-release is created
STEP: When a replicaset with a matching selector is created
STEP: Then the orphan pod is adopted
STEP: When the matched label of one of its pods change
Dec 20 10:04:05.005: INFO: Pod name pod-adoption-release: Found 1 pods out of 1
STEP: Then the pod is released
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:04:06.019: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-618" for this suite.
Dec 20 10:04:18.035: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:04:18.131: INFO: namespace replicaset-618 deletion completed in 12.107153547s

• [SLOW TEST:18.296 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should adopt matching pods on creation and release no longer matching pods [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:04:18.132: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4069
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod liveness-a0b56124-7439-4901-9ecb-27d20eb92b87 in namespace container-probe-4069
Dec 20 10:04:22.278: INFO: Started pod liveness-a0b56124-7439-4901-9ecb-27d20eb92b87 in namespace container-probe-4069
STEP: checking the pod's current state and verifying that restartCount is present
Dec 20 10:04:22.281: INFO: Initial restart count of pod liveness-a0b56124-7439-4901-9ecb-27d20eb92b87 is 0
Dec 20 10:04:40.321: INFO: Restart count of pod container-probe-4069/liveness-a0b56124-7439-4901-9ecb-27d20eb92b87 is now 1 (18.039781044s elapsed)
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:04:40.329: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4069" for this suite.
Dec 20 10:04:46.341: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:04:46.440: INFO: namespace container-probe-4069 deletion completed in 6.107838328s

• [SLOW TEST:28.308 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:04:46.441: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6077
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6077
[It] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Initializing watcher for selector baz=blah,foo=bar
STEP: Creating stateful set ss in namespace statefulset-6077
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-6077
Dec 20 10:04:46.586: INFO: Found 0 stateful pods, waiting for 1
Dec 20 10:04:56.591: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will halt with unhealthy stateful pod
Dec 20 10:04:56.595: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-6077 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 20 10:04:56.756: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 20 10:04:56.756: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 20 10:04:56.756: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 20 10:04:56.760: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 20 10:05:06.766: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 20 10:05:06.766: INFO: Waiting for statefulset status.replicas updated to 0
Dec 20 10:05:06.780: INFO: Verifying statefulset ss doesn't scale past 1 for another 9.999999699s
Dec 20 10:05:07.785: INFO: Verifying statefulset ss doesn't scale past 1 for another 8.996951019s
Dec 20 10:05:08.789: INFO: Verifying statefulset ss doesn't scale past 1 for another 7.992056291s
Dec 20 10:05:09.793: INFO: Verifying statefulset ss doesn't scale past 1 for another 6.988006934s
Dec 20 10:05:10.797: INFO: Verifying statefulset ss doesn't scale past 1 for another 5.983814411s
Dec 20 10:05:11.801: INFO: Verifying statefulset ss doesn't scale past 1 for another 4.97947771s
Dec 20 10:05:12.806: INFO: Verifying statefulset ss doesn't scale past 1 for another 3.975565604s
Dec 20 10:05:13.811: INFO: Verifying statefulset ss doesn't scale past 1 for another 2.970388608s
Dec 20 10:05:14.815: INFO: Verifying statefulset ss doesn't scale past 1 for another 1.965671861s
Dec 20 10:05:15.820: INFO: Verifying statefulset ss doesn't scale past 1 for another 961.471865ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-6077
Dec 20 10:05:16.825: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-6077 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 10:05:16.996: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 20 10:05:16.997: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 20 10:05:16.997: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 20 10:05:17.000: INFO: Found 1 stateful pods, waiting for 3
Dec 20 10:05:27.006: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 10:05:27.006: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 10:05:27.006: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Verifying that stateful set ss was scaled up in order
STEP: Scale down will halt with unhealthy stateful pod
Dec 20 10:05:27.012: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-6077 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 20 10:05:27.177: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 20 10:05:27.177: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 20 10:05:27.177: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 20 10:05:27.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-6077 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 20 10:05:27.366: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 20 10:05:27.366: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 20 10:05:27.367: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 20 10:05:27.367: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-6077 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 20 10:05:27.529: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 20 10:05:27.529: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 20 10:05:27.529: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 20 10:05:27.529: INFO: Waiting for statefulset status.replicas updated to 0
Dec 20 10:05:27.533: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec 20 10:05:37.541: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 20 10:05:37.541: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 20 10:05:37.541: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 20 10:05:37.550: INFO: Verifying statefulset ss doesn't scale past 3 for another 9.999999725s
Dec 20 10:05:38.554: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.99689997s
Dec 20 10:05:39.558: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.992616205s
Dec 20 10:05:40.563: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.988789108s
Dec 20 10:05:41.567: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.983890591s
Dec 20 10:05:42.576: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.979666372s
Dec 20 10:05:43.580: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.970847168s
Dec 20 10:05:44.585: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.966680687s
Dec 20 10:05:45.589: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.962178757s
Dec 20 10:05:46.594: INFO: Verifying statefulset ss doesn't scale past 3 for another 957.802121ms
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-6077
Dec 20 10:05:47.600: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-6077 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 10:05:47.759: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 20 10:05:47.759: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 20 10:05:47.759: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 20 10:05:47.759: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-6077 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 10:05:47.922: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 20 10:05:47.922: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 20 10:05:47.922: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 20 10:05:47.922: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-6077 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 10:05:48.097: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 20 10:05:48.098: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 20 10:05:48.098: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 20 10:05:48.098: INFO: Scaling statefulset ss to 0
STEP: Verifying that stateful set ss was scaled down in reverse order
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 20 10:06:18.117: INFO: Deleting all statefulset in ns statefulset-6077
Dec 20 10:06:18.121: INFO: Scaling statefulset ss to 0
Dec 20 10:06:18.130: INFO: Waiting for statefulset status.replicas updated to 0
Dec 20 10:06:18.133: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:06:18.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6077" for this suite.
Dec 20 10:06:24.157: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:06:24.253: INFO: namespace statefulset-6077 deletion completed in 6.106143938s

• [SLOW TEST:97.813 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a read only busybox container 
  should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:06:24.253: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-3594
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:06:28.423: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-3594" for this suite.
Dec 20 10:07:12.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:07:12.531: INFO: namespace kubelet-test-3594 deletion completed in 44.104676679s

• [SLOW TEST:48.278 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a read only busybox container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:187
    should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:07:12.532: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-4427
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should scale a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a replication controller
Dec 20 10:07:12.663: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 create -f - --namespace=kubectl-4427'
Dec 20 10:07:12.902: INFO: stderr: ""
Dec 20 10:07:12.902: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 20 10:07:12.902: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4427'
Dec 20 10:07:12.982: INFO: stderr: ""
Dec 20 10:07:12.982: INFO: stdout: "update-demo-nautilus-fpwpx update-demo-nautilus-g5w9n "
Dec 20 10:07:12.982: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-fpwpx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4427'
Dec 20 10:07:13.055: INFO: stderr: ""
Dec 20 10:07:13.055: INFO: stdout: ""
Dec 20 10:07:13.055: INFO: update-demo-nautilus-fpwpx is created but not running
Dec 20 10:07:18.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4427'
Dec 20 10:07:18.157: INFO: stderr: ""
Dec 20 10:07:18.157: INFO: stdout: "update-demo-nautilus-fpwpx update-demo-nautilus-g5w9n "
Dec 20 10:07:18.157: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-fpwpx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4427'
Dec 20 10:07:18.245: INFO: stderr: ""
Dec 20 10:07:18.245: INFO: stdout: ""
Dec 20 10:07:18.245: INFO: update-demo-nautilus-fpwpx is created but not running
Dec 20 10:07:23.245: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4427'
Dec 20 10:07:23.354: INFO: stderr: ""
Dec 20 10:07:23.354: INFO: stdout: "update-demo-nautilus-fpwpx update-demo-nautilus-g5w9n "
Dec 20 10:07:23.354: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-fpwpx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4427'
Dec 20 10:07:23.438: INFO: stderr: ""
Dec 20 10:07:23.438: INFO: stdout: "true"
Dec 20 10:07:23.438: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-fpwpx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4427'
Dec 20 10:07:23.530: INFO: stderr: ""
Dec 20 10:07:23.530: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 20 10:07:23.530: INFO: validating pod update-demo-nautilus-fpwpx
Dec 20 10:07:23.535: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 20 10:07:23.535: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 20 10:07:23.535: INFO: update-demo-nautilus-fpwpx is verified up and running
Dec 20 10:07:23.535: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-g5w9n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4427'
Dec 20 10:07:23.627: INFO: stderr: ""
Dec 20 10:07:23.627: INFO: stdout: "true"
Dec 20 10:07:23.627: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-g5w9n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4427'
Dec 20 10:07:23.715: INFO: stderr: ""
Dec 20 10:07:23.715: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 20 10:07:23.715: INFO: validating pod update-demo-nautilus-g5w9n
Dec 20 10:07:23.720: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 20 10:07:23.720: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 20 10:07:23.720: INFO: update-demo-nautilus-g5w9n is verified up and running
STEP: scaling down the replication controller
Dec 20 10:07:23.724: INFO: scanned /root for discovery docs: <nil>
Dec 20 10:07:23.724: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 scale rc update-demo-nautilus --replicas=1 --timeout=5m --namespace=kubectl-4427'
Dec 20 10:07:24.829: INFO: stderr: ""
Dec 20 10:07:24.829: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 20 10:07:24.829: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4427'
Dec 20 10:07:24.927: INFO: stderr: ""
Dec 20 10:07:24.927: INFO: stdout: "update-demo-nautilus-fpwpx update-demo-nautilus-g5w9n "
STEP: Replicas for name=update-demo: expected=1 actual=2
Dec 20 10:07:29.927: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4427'
Dec 20 10:07:30.018: INFO: stderr: ""
Dec 20 10:07:30.018: INFO: stdout: "update-demo-nautilus-g5w9n "
Dec 20 10:07:30.019: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-g5w9n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4427'
Dec 20 10:07:30.115: INFO: stderr: ""
Dec 20 10:07:30.115: INFO: stdout: "true"
Dec 20 10:07:30.115: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-g5w9n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4427'
Dec 20 10:07:30.198: INFO: stderr: ""
Dec 20 10:07:30.198: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 20 10:07:30.198: INFO: validating pod update-demo-nautilus-g5w9n
Dec 20 10:07:30.203: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 20 10:07:30.203: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 20 10:07:30.203: INFO: update-demo-nautilus-g5w9n is verified up and running
STEP: scaling up the replication controller
Dec 20 10:07:30.205: INFO: scanned /root for discovery docs: <nil>
Dec 20 10:07:30.205: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 scale rc update-demo-nautilus --replicas=2 --timeout=5m --namespace=kubectl-4427'
Dec 20 10:07:31.312: INFO: stderr: ""
Dec 20 10:07:31.312: INFO: stdout: "replicationcontroller/update-demo-nautilus scaled\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 20 10:07:31.312: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4427'
Dec 20 10:07:31.429: INFO: stderr: ""
Dec 20 10:07:31.429: INFO: stdout: "update-demo-nautilus-bpk94 update-demo-nautilus-g5w9n "
Dec 20 10:07:31.430: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-bpk94 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4427'
Dec 20 10:07:31.513: INFO: stderr: ""
Dec 20 10:07:31.513: INFO: stdout: ""
Dec 20 10:07:31.513: INFO: update-demo-nautilus-bpk94 is created but not running
Dec 20 10:07:36.514: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-4427'
Dec 20 10:07:36.615: INFO: stderr: ""
Dec 20 10:07:36.615: INFO: stdout: "update-demo-nautilus-bpk94 update-demo-nautilus-g5w9n "
Dec 20 10:07:36.615: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-bpk94 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4427'
Dec 20 10:07:36.700: INFO: stderr: ""
Dec 20 10:07:36.700: INFO: stdout: "true"
Dec 20 10:07:36.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-bpk94 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4427'
Dec 20 10:07:36.813: INFO: stderr: ""
Dec 20 10:07:36.813: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 20 10:07:36.813: INFO: validating pod update-demo-nautilus-bpk94
Dec 20 10:07:36.819: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 20 10:07:36.819: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 20 10:07:36.819: INFO: update-demo-nautilus-bpk94 is verified up and running
Dec 20 10:07:36.819: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-g5w9n -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-4427'
Dec 20 10:07:36.931: INFO: stderr: ""
Dec 20 10:07:36.931: INFO: stdout: "true"
Dec 20 10:07:36.932: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-g5w9n -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-4427'
Dec 20 10:07:37.029: INFO: stderr: ""
Dec 20 10:07:37.029: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 20 10:07:37.029: INFO: validating pod update-demo-nautilus-g5w9n
Dec 20 10:07:37.034: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 20 10:07:37.034: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 20 10:07:37.034: INFO: update-demo-nautilus-g5w9n is verified up and running
STEP: using delete to clean up resources
Dec 20 10:07:37.034: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 delete --grace-period=0 --force -f - --namespace=kubectl-4427'
Dec 20 10:07:37.132: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 20 10:07:37.132: INFO: stdout: "replicationcontroller \"update-demo-nautilus\" force deleted\n"
Dec 20 10:07:37.132: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4427'
Dec 20 10:07:37.222: INFO: stderr: "No resources found in kubectl-4427 namespace.\n"
Dec 20 10:07:37.222: INFO: stdout: ""
Dec 20 10:07:37.222: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods -l name=update-demo --namespace=kubectl-4427 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 20 10:07:37.317: INFO: stderr: ""
Dec 20 10:07:37.317: INFO: stdout: "update-demo-nautilus-bpk94\nupdate-demo-nautilus-g5w9n\n"
Dec 20 10:07:37.818: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get rc,svc -l name=update-demo --no-headers --namespace=kubectl-4427'
Dec 20 10:07:37.935: INFO: stderr: "No resources found in kubectl-4427 namespace.\n"
Dec 20 10:07:37.935: INFO: stdout: ""
Dec 20 10:07:37.935: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods -l name=update-demo --namespace=kubectl-4427 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 20 10:07:38.033: INFO: stderr: ""
Dec 20 10:07:38.033: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:07:38.033: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-4427" for this suite.
Dec 20 10:08:06.048: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:08:06.143: INFO: namespace kubectl-4427 deletion completed in 28.106262398s

• [SLOW TEST:53.612 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should scale a replication controller  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:08:06.144: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-4084
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: CRs in the same group and version but different kinds (two CRDs) show up in OpenAPI documentation
Dec 20 10:08:06.279: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 10:08:11.452: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:08:31.677: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-4084" for this suite.
Dec 20 10:08:37.693: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:08:37.789: INFO: namespace crd-publish-openapi-4084 deletion completed in 6.107315504s

• [SLOW TEST:31.644 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for multiple CRDs of same group and version but different kinds [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Security Context When creating a container with runAsUser 
  should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:08:37.789: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-2063
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 10:08:37.927: INFO: Waiting up to 5m0s for pod "busybox-user-65534-8e9ee978-1b7e-4ab5-bc9a-825d259eac55" in namespace "security-context-test-2063" to be "success or failure"
Dec 20 10:08:37.930: INFO: Pod "busybox-user-65534-8e9ee978-1b7e-4ab5-bc9a-825d259eac55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.740679ms
Dec 20 10:08:39.934: INFO: Pod "busybox-user-65534-8e9ee978-1b7e-4ab5-bc9a-825d259eac55": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006373249s
Dec 20 10:08:41.937: INFO: Pod "busybox-user-65534-8e9ee978-1b7e-4ab5-bc9a-825d259eac55": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009752769s
Dec 20 10:08:41.937: INFO: Pod "busybox-user-65534-8e9ee978-1b7e-4ab5-bc9a-825d259eac55" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:08:41.937: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2063" for this suite.
Dec 20 10:08:47.952: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:08:48.055: INFO: namespace security-context-test-2063 deletion completed in 6.113369852s

• [SLOW TEST:10.266 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a container with runAsUser
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:44
    should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-network] Proxy version v1 
  should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:08:48.055: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename proxy
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in proxy-8033
STEP: Waiting for a default service account to be provisioned in namespace
[It] should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 10:08:48.210: INFO: (0) /api/v1/nodes/caasp-worker-th-before-0:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 19.6441ms)
Dec 20 10:08:48.213: INFO: (1) /api/v1/nodes/caasp-worker-th-before-0:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.878375ms)
Dec 20 10:08:48.218: INFO: (2) /api/v1/nodes/caasp-worker-th-before-0:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 4.220831ms)
Dec 20 10:08:48.222: INFO: (3) /api/v1/nodes/caasp-worker-th-before-0:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 4.129506ms)
Dec 20 10:08:48.226: INFO: (4) /api/v1/nodes/caasp-worker-th-before-0:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 4.169599ms)
Dec 20 10:08:48.230: INFO: (5) /api/v1/nodes/caasp-worker-th-before-0:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.801892ms)
Dec 20 10:08:48.234: INFO: (6) /api/v1/nodes/caasp-worker-th-before-0:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 4.135238ms)
Dec 20 10:08:48.238: INFO: (7) /api/v1/nodes/caasp-worker-th-before-0:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.729449ms)
Dec 20 10:08:48.241: INFO: (8) /api/v1/nodes/caasp-worker-th-before-0:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.610725ms)
Dec 20 10:08:48.245: INFO: (9) /api/v1/nodes/caasp-worker-th-before-0:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.719043ms)
Dec 20 10:08:48.249: INFO: (10) /api/v1/nodes/caasp-worker-th-before-0:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.352374ms)
Dec 20 10:08:48.252: INFO: (11) /api/v1/nodes/caasp-worker-th-before-0:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.542195ms)
Dec 20 10:08:48.256: INFO: (12) /api/v1/nodes/caasp-worker-th-before-0:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.513315ms)
Dec 20 10:08:48.259: INFO: (13) /api/v1/nodes/caasp-worker-th-before-0:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.637695ms)
Dec 20 10:08:48.263: INFO: (14) /api/v1/nodes/caasp-worker-th-before-0:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.174002ms)
Dec 20 10:08:48.266: INFO: (15) /api/v1/nodes/caasp-worker-th-before-0:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.496702ms)
Dec 20 10:08:48.269: INFO: (16) /api/v1/nodes/caasp-worker-th-before-0:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.332816ms)
Dec 20 10:08:48.273: INFO: (17) /api/v1/nodes/caasp-worker-th-before-0:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.400333ms)
Dec 20 10:08:48.276: INFO: (18) /api/v1/nodes/caasp-worker-th-before-0:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.542989ms)
Dec 20 10:08:48.280: INFO: (19) /api/v1/nodes/caasp-worker-th-before-0:10250/proxy/logs/: <pre>
<a href="NetworkManager">NetworkManager</a>
<a href="YaST2/">YaST2/</a>
<a href="acpid">acp... (200; 3.46218ms)
[AfterEach] version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:08:48.280: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "proxy-8033" for this suite.
Dec 20 10:08:54.294: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:08:54.394: INFO: namespace proxy-8033 deletion completed in 6.110516352s

• [SLOW TEST:6.340 seconds]
[sig-network] Proxy
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  version v1
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/proxy.go:57
    should proxy logs on node with explicit kubelet port using proxy subresource  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:08:54.395: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-3681
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 20 10:08:55.558: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 20 10:08:57.567: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712433336, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712433336, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712433336, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712433336, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 20 10:09:00.582: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod that should be denied by the webhook
STEP: create a pod that causes the webhook to hang
STEP: create a configmap that should be denied by the webhook
STEP: create a configmap that should be admitted by the webhook
STEP: update (PUT) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: update (PATCH) the admitted configmap to a non-compliant one should be rejected by the webhook
STEP: create a namespace that bypass the webhook
STEP: create a configmap that violates the webhook policy but is in a whitelisted namespace
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:09:10.675: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-3681" for this suite.
Dec 20 10:09:16.689: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:09:16.787: INFO: namespace webhook-3681 deletion completed in 6.108643533s
STEP: Destroying namespace "webhook-3681-markers" for this suite.
Dec 20 10:09:22.798: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:09:22.892: INFO: namespace webhook-3681-markers deletion completed in 6.104855588s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.510 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny pod and configmap creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:09:22.905: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-1055
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 10:09:23.036: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 20 10:09:28.181: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 --namespace=crd-publish-openapi-1055 create -f -'
Dec 20 10:09:28.538: INFO: stderr: ""
Dec 20 10:09:28.538: INFO: stdout: "e2e-test-crd-publish-openapi-90-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 20 10:09:28.538: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 --namespace=crd-publish-openapi-1055 delete e2e-test-crd-publish-openapi-90-crds test-cr'
Dec 20 10:09:28.688: INFO: stderr: ""
Dec 20 10:09:28.689: INFO: stdout: "e2e-test-crd-publish-openapi-90-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
Dec 20 10:09:28.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 --namespace=crd-publish-openapi-1055 apply -f -'
Dec 20 10:09:28.871: INFO: stderr: ""
Dec 20 10:09:28.871: INFO: stdout: "e2e-test-crd-publish-openapi-90-crd.crd-publish-openapi-test-unknown-at-root.example.com/test-cr created\n"
Dec 20 10:09:28.871: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 --namespace=crd-publish-openapi-1055 delete e2e-test-crd-publish-openapi-90-crds test-cr'
Dec 20 10:09:28.965: INFO: stderr: ""
Dec 20 10:09:28.965: INFO: stdout: "e2e-test-crd-publish-openapi-90-crd.crd-publish-openapi-test-unknown-at-root.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec 20 10:09:28.965: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 explain e2e-test-crd-publish-openapi-90-crds'
Dec 20 10:09:29.128: INFO: stderr: ""
Dec 20 10:09:29.128: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-90-crd\nVERSION:  crd-publish-openapi-test-unknown-at-root.example.com/v1\n\nDESCRIPTION:\n     <empty>\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:09:34.366: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-1055" for this suite.
Dec 20 10:09:40.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:09:40.467: INFO: namespace crd-publish-openapi-1055 deletion completed in 6.095452889s

• [SLOW TEST:17.562 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields at the schema root [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:09:40.468: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-186
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up watch
STEP: submitting the pod to kubernetes
Dec 20 10:09:40.607: INFO: observed the pod list
STEP: verifying the pod is in kubernetes
STEP: verifying pod creation was observed
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
STEP: verifying pod deletion was observed
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:09:55.554: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-186" for this suite.
Dec 20 10:10:01.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:10:01.662: INFO: namespace pods-186 deletion completed in 6.104514443s

• [SLOW TEST:21.194 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be submitted and removed [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:10:01.662: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-2230
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test externalName service
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2230.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2230.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2230.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2230.svc.cluster.local; sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 20 10:10:05.821: INFO: DNS probes using dns-test-2f91b2c5-fb1c-49b3-82d1-7517a405c3c5 succeeded

STEP: deleting the pod
STEP: changing the externalName to bar.example.com
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2230.svc.cluster.local CNAME > /results/wheezy_udp@dns-test-service-3.dns-2230.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2230.svc.cluster.local CNAME > /results/jessie_udp@dns-test-service-3.dns-2230.svc.cluster.local; sleep 1; done

STEP: creating a second pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 20 10:10:09.856: INFO: File wheezy_udp@dns-test-service-3.dns-2230.svc.cluster.local from pod  dns-2230/dns-test-55f49740-e166-4a7c-891a-7583900be050 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 20 10:10:09.859: INFO: File jessie_udp@dns-test-service-3.dns-2230.svc.cluster.local from pod  dns-2230/dns-test-55f49740-e166-4a7c-891a-7583900be050 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 20 10:10:09.859: INFO: Lookups using dns-2230/dns-test-55f49740-e166-4a7c-891a-7583900be050 failed for: [wheezy_udp@dns-test-service-3.dns-2230.svc.cluster.local jessie_udp@dns-test-service-3.dns-2230.svc.cluster.local]

Dec 20 10:10:14.865: INFO: File wheezy_udp@dns-test-service-3.dns-2230.svc.cluster.local from pod  dns-2230/dns-test-55f49740-e166-4a7c-891a-7583900be050 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 20 10:10:14.869: INFO: File jessie_udp@dns-test-service-3.dns-2230.svc.cluster.local from pod  dns-2230/dns-test-55f49740-e166-4a7c-891a-7583900be050 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 20 10:10:14.869: INFO: Lookups using dns-2230/dns-test-55f49740-e166-4a7c-891a-7583900be050 failed for: [wheezy_udp@dns-test-service-3.dns-2230.svc.cluster.local jessie_udp@dns-test-service-3.dns-2230.svc.cluster.local]

Dec 20 10:10:19.865: INFO: File wheezy_udp@dns-test-service-3.dns-2230.svc.cluster.local from pod  dns-2230/dns-test-55f49740-e166-4a7c-891a-7583900be050 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 20 10:10:19.869: INFO: File jessie_udp@dns-test-service-3.dns-2230.svc.cluster.local from pod  dns-2230/dns-test-55f49740-e166-4a7c-891a-7583900be050 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 20 10:10:19.869: INFO: Lookups using dns-2230/dns-test-55f49740-e166-4a7c-891a-7583900be050 failed for: [wheezy_udp@dns-test-service-3.dns-2230.svc.cluster.local jessie_udp@dns-test-service-3.dns-2230.svc.cluster.local]

Dec 20 10:10:24.864: INFO: File wheezy_udp@dns-test-service-3.dns-2230.svc.cluster.local from pod  dns-2230/dns-test-55f49740-e166-4a7c-891a-7583900be050 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 20 10:10:24.867: INFO: File jessie_udp@dns-test-service-3.dns-2230.svc.cluster.local from pod  dns-2230/dns-test-55f49740-e166-4a7c-891a-7583900be050 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 20 10:10:24.867: INFO: Lookups using dns-2230/dns-test-55f49740-e166-4a7c-891a-7583900be050 failed for: [wheezy_udp@dns-test-service-3.dns-2230.svc.cluster.local jessie_udp@dns-test-service-3.dns-2230.svc.cluster.local]

Dec 20 10:10:29.864: INFO: File wheezy_udp@dns-test-service-3.dns-2230.svc.cluster.local from pod  dns-2230/dns-test-55f49740-e166-4a7c-891a-7583900be050 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 20 10:10:29.868: INFO: File jessie_udp@dns-test-service-3.dns-2230.svc.cluster.local from pod  dns-2230/dns-test-55f49740-e166-4a7c-891a-7583900be050 contains 'foo.example.com.
' instead of 'bar.example.com.'
Dec 20 10:10:29.868: INFO: Lookups using dns-2230/dns-test-55f49740-e166-4a7c-891a-7583900be050 failed for: [wheezy_udp@dns-test-service-3.dns-2230.svc.cluster.local jessie_udp@dns-test-service-3.dns-2230.svc.cluster.local]

Dec 20 10:10:34.868: INFO: DNS probes using dns-test-55f49740-e166-4a7c-891a-7583900be050 succeeded

STEP: deleting the pod
STEP: changing the service to type=ClusterIP
STEP: Running these commands on wheezy: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2230.svc.cluster.local A > /results/wheezy_udp@dns-test-service-3.dns-2230.svc.cluster.local; sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 30`; do dig +short dns-test-service-3.dns-2230.svc.cluster.local A > /results/jessie_udp@dns-test-service-3.dns-2230.svc.cluster.local; sleep 1; done

STEP: creating a third pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 20 10:10:38.919: INFO: DNS probes using dns-test-e54ce468-898c-4662-a844-fdce3dc95e77 succeeded

STEP: deleting the pod
STEP: deleting the test externalName service
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:10:38.940: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-2230" for this suite.
Dec 20 10:10:44.954: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:10:45.047: INFO: namespace dns-2230 deletion completed in 6.103020668s

• [SLOW TEST:43.385 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for ExternalName services [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:10:45.047: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3197
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 10:10:45.224: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: creating the pod
STEP: submitting the pod to kubernetes
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:10:47.272: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3197" for this suite.
Dec 20 10:11:31.286: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:11:31.378: INFO: namespace pods-3197 deletion completed in 44.101756713s

• [SLOW TEST:46.331 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should support retrieving logs from the container over websockets [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl label 
  should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:11:31.378: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9133
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl label
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1192
STEP: creating the pod
Dec 20 10:11:31.511: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 create -f - --namespace=kubectl-9133'
Dec 20 10:11:31.760: INFO: stderr: ""
Dec 20 10:11:31.760: INFO: stdout: "pod/pause created\n"
Dec 20 10:11:31.760: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [pause]
Dec 20 10:11:31.760: INFO: Waiting up to 5m0s for pod "pause" in namespace "kubectl-9133" to be "running and ready"
Dec 20 10:11:31.762: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.23466ms
Dec 20 10:11:33.767: INFO: Pod "pause": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006497787s
Dec 20 10:11:35.770: INFO: Pod "pause": Phase="Running", Reason="", readiness=true. Elapsed: 4.010240873s
Dec 20 10:11:35.770: INFO: Pod "pause" satisfied condition "running and ready"
Dec 20 10:11:35.770: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [pause]
[It] should update the label on a resource  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: adding the label testing-label with value testing-label-value to a pod
Dec 20 10:11:35.771: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 label pods pause testing-label=testing-label-value --namespace=kubectl-9133'
Dec 20 10:11:35.870: INFO: stderr: ""
Dec 20 10:11:35.870: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod has the label testing-label with the value testing-label-value
Dec 20 10:11:35.870: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pod pause -L testing-label --namespace=kubectl-9133'
Dec 20 10:11:35.959: INFO: stderr: ""
Dec 20 10:11:35.959: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          5s    testing-label-value\n"
STEP: removing the label testing-label of a pod
Dec 20 10:11:35.959: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 label pods pause testing-label- --namespace=kubectl-9133'
Dec 20 10:11:36.055: INFO: stderr: ""
Dec 20 10:11:36.055: INFO: stdout: "pod/pause labeled\n"
STEP: verifying the pod doesn't have the label testing-label
Dec 20 10:11:36.055: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pod pause -L testing-label --namespace=kubectl-9133'
Dec 20 10:11:36.156: INFO: stderr: ""
Dec 20 10:11:36.156: INFO: stdout: "NAME    READY   STATUS    RESTARTS   AGE   TESTING-LABEL\npause   1/1     Running   0          4s    \n"
[AfterEach] Kubectl label
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1199
STEP: using delete to clean up resources
Dec 20 10:11:36.156: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 delete --grace-period=0 --force -f - --namespace=kubectl-9133'
Dec 20 10:11:36.249: INFO: stderr: "warning: Immediate deletion does not wait for confirmation that the running resource has been terminated. The resource may continue to run on the cluster indefinitely.\n"
Dec 20 10:11:36.249: INFO: stdout: "pod \"pause\" force deleted\n"
Dec 20 10:11:36.249: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get rc,svc -l name=pause --no-headers --namespace=kubectl-9133'
Dec 20 10:11:36.337: INFO: stderr: "No resources found in kubectl-9133 namespace.\n"
Dec 20 10:11:36.337: INFO: stdout: ""
Dec 20 10:11:36.337: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods -l name=pause --namespace=kubectl-9133 -o go-template={{ range .items }}{{ if not .metadata.deletionTimestamp }}{{ .metadata.name }}{{ "\n" }}{{ end }}{{ end }}'
Dec 20 10:11:36.422: INFO: stderr: ""
Dec 20 10:11:36.422: INFO: stdout: ""
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:11:36.422: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9133" for this suite.
Dec 20 10:11:42.437: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:11:42.531: INFO: namespace kubectl-9133 deletion completed in 6.10487146s

• [SLOW TEST:11.153 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl label
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1189
    should update the label on a resource  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:11:42.531: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8290
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on node default medium
Dec 20 10:11:42.670: INFO: Waiting up to 5m0s for pod "pod-db5a794b-2af4-40c3-a34f-3a24ff3abf17" in namespace "emptydir-8290" to be "success or failure"
Dec 20 10:11:42.672: INFO: Pod "pod-db5a794b-2af4-40c3-a34f-3a24ff3abf17": Phase="Pending", Reason="", readiness=false. Elapsed: 2.134358ms
Dec 20 10:11:44.675: INFO: Pod "pod-db5a794b-2af4-40c3-a34f-3a24ff3abf17": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005472751s
Dec 20 10:11:46.679: INFO: Pod "pod-db5a794b-2af4-40c3-a34f-3a24ff3abf17": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009268032s
STEP: Saw pod success
Dec 20 10:11:46.679: INFO: Pod "pod-db5a794b-2af4-40c3-a34f-3a24ff3abf17" satisfied condition "success or failure"
Dec 20 10:11:46.682: INFO: Trying to get logs from node caasp-worker-th-before-3 pod pod-db5a794b-2af4-40c3-a34f-3a24ff3abf17 container test-container: <nil>
STEP: delete the pod
Dec 20 10:11:46.709: INFO: Waiting for pod pod-db5a794b-2af4-40c3-a34f-3a24ff3abf17 to disappear
Dec 20 10:11:46.711: INFO: Pod pod-db5a794b-2af4-40c3-a34f-3a24ff3abf17 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:11:46.711: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8290" for this suite.
Dec 20 10:11:52.727: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:11:52.815: INFO: namespace emptydir-8290 deletion completed in 6.10094139s

• [SLOW TEST:10.284 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:11:52.816: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4108
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-20841b2f-ec6d-4b2e-aef1-81ee69cd249a
STEP: Creating a pod to test consume configMaps
Dec 20 10:11:52.957: INFO: Waiting up to 5m0s for pod "pod-configmaps-c974ffec-39b9-4903-866a-8f946887d57c" in namespace "configmap-4108" to be "success or failure"
Dec 20 10:11:52.960: INFO: Pod "pod-configmaps-c974ffec-39b9-4903-866a-8f946887d57c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.361303ms
Dec 20 10:11:54.963: INFO: Pod "pod-configmaps-c974ffec-39b9-4903-866a-8f946887d57c": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00592439s
Dec 20 10:11:56.968: INFO: Pod "pod-configmaps-c974ffec-39b9-4903-866a-8f946887d57c": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010165836s
STEP: Saw pod success
Dec 20 10:11:56.968: INFO: Pod "pod-configmaps-c974ffec-39b9-4903-866a-8f946887d57c" satisfied condition "success or failure"
Dec 20 10:11:56.972: INFO: Trying to get logs from node caasp-worker-th-before-4 pod pod-configmaps-c974ffec-39b9-4903-866a-8f946887d57c container configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 10:11:57.002: INFO: Waiting for pod pod-configmaps-c974ffec-39b9-4903-866a-8f946887d57c to disappear
Dec 20 10:11:57.004: INFO: Pod pod-configmaps-c974ffec-39b9-4903-866a-8f946887d57c no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:11:57.004: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4108" for this suite.
Dec 20 10:12:03.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:12:03.113: INFO: namespace configmap-4108 deletion completed in 6.105599336s

• [SLOW TEST:10.297 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:12:03.113: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-7456
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-9799
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a service in the namespace
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3227
STEP: Verifying there is no service in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:12:09.529: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-7456" for this suite.
Dec 20 10:12:15.544: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:12:15.638: INFO: namespace namespaces-7456 deletion completed in 6.104828576s
STEP: Destroying namespace "nsdeletetest-9799" for this suite.
Dec 20 10:12:15.641: INFO: Namespace nsdeletetest-9799 was already deleted
STEP: Destroying namespace "nsdeletetest-3227" for this suite.
Dec 20 10:12:21.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:12:21.741: INFO: namespace nsdeletetest-3227 deletion completed in 6.09994904s

• [SLOW TEST:18.628 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all services are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:12:21.741: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-4175
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a Service
STEP: Ensuring resource quota status captures service creation
STEP: Deleting a Service
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:12:32.944: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-4175" for this suite.
Dec 20 10:12:38.959: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:12:39.047: INFO: namespace resourcequota-4175 deletion completed in 6.098769744s

• [SLOW TEST:17.306 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a service. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Deployment 
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:12:39.048: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-2633
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 10:12:39.179: INFO: Creating deployment "test-recreate-deployment"
Dec 20 10:12:39.183: INFO: Waiting deployment "test-recreate-deployment" to be updated to revision 1
Dec 20 10:12:39.188: INFO: deployment "test-recreate-deployment" doesn't have the required revision set
Dec 20 10:12:41.196: INFO: Waiting deployment "test-recreate-deployment" to complete
Dec 20 10:12:41.199: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712433560, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712433560, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712433560, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712433560, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"test-recreate-deployment-68fc85c7bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 10:12:43.202: INFO: Triggering a new rollout for deployment "test-recreate-deployment"
Dec 20 10:12:43.209: INFO: Updating deployment test-recreate-deployment
Dec 20 10:12:43.209: INFO: Watching deployment "test-recreate-deployment" to verify that new pods will not run with olds pods
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 20 10:12:43.260: INFO: Deployment "test-recreate-deployment":
&Deployment{ObjectMeta:{test-recreate-deployment  deployment-2633 /apis/apps/v1/namespaces/deployment-2633/deployments/test-recreate-deployment 150231a2-dc24-45d1-8707-1917bab9eadb 125135 2 2019-12-20 10:12:39 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[deployment.kubernetes.io/revision:2] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc004d8dd78 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:Recreate,RollingUpdate:nil,},MinReadySeconds:0,RevisionHistoryLimit:*10,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:2,Replicas:1,UpdatedReplicas:1,AvailableReplicas:0,UnavailableReplicas:1,Conditions:[]DeploymentCondition{DeploymentCondition{Type:Available,Status:False,Reason:MinimumReplicasUnavailable,Message:Deployment does not have minimum availability.,LastUpdateTime:2019-12-20 10:12:44 +0000 UTC,LastTransitionTime:2019-12-20 10:12:44 +0000 UTC,},DeploymentCondition{Type:Progressing,Status:True,Reason:ReplicaSetUpdated,Message:ReplicaSet "test-recreate-deployment-5f94c574ff" is progressing.,LastUpdateTime:2019-12-20 10:12:44 +0000 UTC,LastTransitionTime:2019-12-20 10:12:40 +0000 UTC,},},ReadyReplicas:0,CollisionCount:nil,},}

Dec 20 10:12:43.263: INFO: New ReplicaSet "test-recreate-deployment-5f94c574ff" of Deployment "test-recreate-deployment":
&ReplicaSet{ObjectMeta:{test-recreate-deployment-5f94c574ff  deployment-2633 /apis/apps/v1/namespaces/deployment-2633/replicasets/test-recreate-deployment-5f94c574ff 02cc5045-0511-448b-8330-0a6c14aa0064 125133 1 2019-12-20 10:12:43 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:2] [{apps/v1 Deployment test-recreate-deployment 150231a2-dc24-45d1-8707-1917bab9eadb 0xc0023a2157 0xc0023a2158}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 5f94c574ff,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0023a21b8 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 20 10:12:43.263: INFO: All old ReplicaSets of Deployment "test-recreate-deployment":
Dec 20 10:12:43.263: INFO: &ReplicaSet{ObjectMeta:{test-recreate-deployment-68fc85c7bb  deployment-2633 /apis/apps/v1/namespaces/deployment-2633/replicasets/test-recreate-deployment-68fc85c7bb 61ca1ab5-eb0f-4839-94dd-4702f90439d5 125124 2 2019-12-20 10:12:39 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[deployment.kubernetes.io/desired-replicas:1 deployment.kubernetes.io/max-replicas:1 deployment.kubernetes.io/revision:1] [{apps/v1 Deployment test-recreate-deployment 150231a2-dc24-45d1-8707-1917bab9eadb 0xc0023a2227 0xc0023a2228}] []  []},Spec:ReplicaSetSpec{Replicas:*0,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: sample-pod-3,pod-template-hash: 68fc85c7bb,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:68fc85c7bb] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc0023a2288 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:0,FullyLabeledReplicas:0,ObservedGeneration:2,ReadyReplicas:0,AvailableReplicas:0,Conditions:[]ReplicaSetCondition{},},}
Dec 20 10:12:43.266: INFO: Pod "test-recreate-deployment-5f94c574ff-kxxg2" is not available:
&Pod{ObjectMeta:{test-recreate-deployment-5f94c574ff-kxxg2 test-recreate-deployment-5f94c574ff- deployment-2633 /api/v1/namespaces/deployment-2633/pods/test-recreate-deployment-5f94c574ff-kxxg2 5ef2775d-c4e9-4e13-9464-9c49e35e9127 125136 0 2019-12-20 10:12:43 +0000 UTC <nil> <nil> map[name:sample-pod-3 pod-template-hash:5f94c574ff] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-recreate-deployment-5f94c574ff 02cc5045-0511-448b-8330-0a6c14aa0064 0xc0023a26f7 0xc0023a26f8}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-8xczz,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-8xczz,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-8xczz,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:&SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,},Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Pending,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 10:12:44 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 10:12:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:ContainersReady,Status:False,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 10:12:44 +0000 UTC,Reason:ContainersNotReady,Message:containers with unready status: [httpd],},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 10:12:43 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.84.149.223,PodIP:,StartTime:2019-12-20 10:12:44 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:&ContainerStateWaiting{Reason:ContainerCreating,Message:,},Running:nil,Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:false,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:,ContainerID:,Started:*false,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:12:43.266: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-2633" for this suite.
Dec 20 10:12:49.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:12:49.373: INFO: namespace deployment-2633 deletion completed in 6.103960723s

• [SLOW TEST:10.326 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  RecreateDeployment should delete old pods and create new ones [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox Pod with hostAliases 
  should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:12:49.373: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-5965
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:12:53.545: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-5965" for this suite.
Dec 20 10:13:43.559: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:13:43.655: INFO: namespace kubelet-test-5965 deletion completed in 50.105815379s

• [SLOW TEST:54.281 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox Pod with hostAliases
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:136
    should write entries to /etc/hosts [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] ReplicaSet 
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:13:43.655: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename replicaset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in replicaset-3543
STEP: Waiting for a default service account to be provisioned in namespace
[It] should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 10:13:43.786: INFO: Creating ReplicaSet my-hostname-basic-88583dfb-0198-48f4-a8f0-61a2a9b6bb2e
Dec 20 10:13:43.794: INFO: Pod name my-hostname-basic-88583dfb-0198-48f4-a8f0-61a2a9b6bb2e: Found 0 pods out of 1
Dec 20 10:13:48.799: INFO: Pod name my-hostname-basic-88583dfb-0198-48f4-a8f0-61a2a9b6bb2e: Found 1 pods out of 1
Dec 20 10:13:48.799: INFO: Ensuring a pod for ReplicaSet "my-hostname-basic-88583dfb-0198-48f4-a8f0-61a2a9b6bb2e" is running
Dec 20 10:13:48.802: INFO: Pod "my-hostname-basic-88583dfb-0198-48f4-a8f0-61a2a9b6bb2e-ts5bq" is running (conditions: [{Type:Initialized Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-20 10:13:44 +0000 UTC Reason: Message:} {Type:Ready Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-20 10:13:46 +0000 UTC Reason: Message:} {Type:ContainersReady Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-20 10:13:46 +0000 UTC Reason: Message:} {Type:PodScheduled Status:True LastProbeTime:0001-01-01 00:00:00 +0000 UTC LastTransitionTime:2019-12-20 10:13:43 +0000 UTC Reason: Message:}])
Dec 20 10:13:48.802: INFO: Trying to dial the pod
Dec 20 10:13:53.813: INFO: Controller my-hostname-basic-88583dfb-0198-48f4-a8f0-61a2a9b6bb2e: Got expected result from replica 1 [my-hostname-basic-88583dfb-0198-48f4-a8f0-61a2a9b6bb2e-ts5bq]: "my-hostname-basic-88583dfb-0198-48f4-a8f0-61a2a9b6bb2e-ts5bq", 1 of 1 required successes so far
[AfterEach] [sig-apps] ReplicaSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:13:53.813: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "replicaset-3543" for this suite.
Dec 20 10:13:59.829: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:13:59.926: INFO: namespace replicaset-3543 deletion completed in 6.109474222s

• [SLOW TEST:16.271 seconds]
[sig-apps] ReplicaSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should serve a basic image on each replica with a public image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:13:59.927: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-7074
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod test-webserver-d7e591ac-f80b-42dd-8f22-800676443016 in namespace container-probe-7074
Dec 20 10:14:04.071: INFO: Started pod test-webserver-d7e591ac-f80b-42dd-8f22-800676443016 in namespace container-probe-7074
STEP: checking the pod's current state and verifying that restartCount is present
Dec 20 10:14:04.074: INFO: Initial restart count of pod test-webserver-d7e591ac-f80b-42dd-8f22-800676443016 is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:18:04.578: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-7074" for this suite.
Dec 20 10:18:10.593: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:18:10.683: INFO: namespace container-probe-7074 deletion completed in 6.100691732s

• [SLOW TEST:250.756 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-node] Downward API 
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:18:10.683: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9172
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 20 10:18:10.819: INFO: Waiting up to 5m0s for pod "downward-api-827efe5f-7500-4bb1-ac78-40b8df93bb6e" in namespace "downward-api-9172" to be "success or failure"
Dec 20 10:18:10.822: INFO: Pod "downward-api-827efe5f-7500-4bb1-ac78-40b8df93bb6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.552103ms
Dec 20 10:18:12.825: INFO: Pod "downward-api-827efe5f-7500-4bb1-ac78-40b8df93bb6e": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005996179s
Dec 20 10:18:14.829: INFO: Pod "downward-api-827efe5f-7500-4bb1-ac78-40b8df93bb6e": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009638877s
STEP: Saw pod success
Dec 20 10:18:14.829: INFO: Pod "downward-api-827efe5f-7500-4bb1-ac78-40b8df93bb6e" satisfied condition "success or failure"
Dec 20 10:18:14.832: INFO: Trying to get logs from node caasp-worker-th-before-3 pod downward-api-827efe5f-7500-4bb1-ac78-40b8df93bb6e container dapi-container: <nil>
STEP: delete the pod
Dec 20 10:18:14.864: INFO: Waiting for pod downward-api-827efe5f-7500-4bb1-ac78-40b8df93bb6e to disappear
Dec 20 10:18:14.866: INFO: Pod downward-api-827efe5f-7500-4bb1-ac78-40b8df93bb6e no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:18:14.866: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9172" for this suite.
Dec 20 10:18:20.880: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:18:20.964: INFO: namespace downward-api-9172 deletion completed in 6.093780348s

• [SLOW TEST:10.281 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide pod UID as env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:18:20.964: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-1607
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating service nodeport-test with type=NodePort in namespace services-1607
STEP: creating replication controller nodeport-test in namespace services-1607
I1220 10:18:21.122666      26 runners.go:184] Created replication controller with name: nodeport-test, namespace: services-1607, replica count: 2
I1220 10:18:24.173129      26 runners.go:184] nodeport-test Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 20 10:18:24.173: INFO: Creating new exec pod
Dec 20 10:18:29.190: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=services-1607 execpodmbmgb -- /bin/sh -x -c nc -zv -t -w 2 nodeport-test 80'
Dec 20 10:18:29.378: INFO: stderr: "+ nc -zv -t -w 2 nodeport-test 80\nConnection to nodeport-test 80 port [tcp/http] succeeded!\n"
Dec 20 10:18:29.379: INFO: stdout: ""
Dec 20 10:18:29.379: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=services-1607 execpodmbmgb -- /bin/sh -x -c nc -zv -t -w 2 10.111.121.247 80'
Dec 20 10:18:29.539: INFO: stderr: "+ nc -zv -t -w 2 10.111.121.247 80\nConnection to 10.111.121.247 80 port [tcp/http] succeeded!\n"
Dec 20 10:18:29.539: INFO: stdout: ""
Dec 20 10:18:29.539: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=services-1607 execpodmbmgb -- /bin/sh -x -c nc -zv -t -w 2 10.84.149.223 31800'
Dec 20 10:18:29.712: INFO: stderr: "+ nc -zv -t -w 2 10.84.149.223 31800\nConnection to 10.84.149.223 31800 port [tcp/31800] succeeded!\n"
Dec 20 10:18:29.712: INFO: stdout: ""
Dec 20 10:18:29.712: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=services-1607 execpodmbmgb -- /bin/sh -x -c nc -zv -t -w 2 10.84.149.226 31800'
Dec 20 10:18:29.872: INFO: stderr: "+ nc -zv -t -w 2 10.84.149.226 31800\nConnection to 10.84.149.226 31800 port [tcp/31800] succeeded!\n"
Dec 20 10:18:29.872: INFO: stdout: ""
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:18:29.872: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-1607" for this suite.
Dec 20 10:18:35.888: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:18:35.982: INFO: namespace services-1607 deletion completed in 6.105284637s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:15.018 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to create a functioning NodePort service [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-auth] ServiceAccounts 
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:18:35.982: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename svcaccounts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in svcaccounts-8959
STEP: Waiting for a default service account to be provisioned in namespace
[It] should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: getting the auto-created API token
STEP: reading a file in the container
Dec 20 10:18:40.638: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8959 pod-service-account-e75efc87-89b7-4e94-92ba-10cdf62abccd -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/token'
STEP: reading a file in the container
Dec 20 10:18:40.809: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8959 pod-service-account-e75efc87-89b7-4e94-92ba-10cdf62abccd -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/ca.crt'
STEP: reading a file in the container
Dec 20 10:18:40.980: INFO: Running '/usr/local/bin/kubectl exec --namespace=svcaccounts-8959 pod-service-account-e75efc87-89b7-4e94-92ba-10cdf62abccd -c=test -- cat /var/run/secrets/kubernetes.io/serviceaccount/namespace'
[AfterEach] [sig-auth] ServiceAccounts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:18:41.143: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "svcaccounts-8959" for this suite.
Dec 20 10:18:47.159: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:18:47.261: INFO: namespace svcaccounts-8959 deletion completed in 6.113116551s

• [SLOW TEST:11.279 seconds]
[sig-auth] ServiceAccounts
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/auth/framework.go:23
  should mount an API token into pods  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] DNS 
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:18:47.261: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-5835
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5835.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do check="$$(dig +notcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_udp@kubernetes.default.svc.cluster.local;check="$$(dig +tcp +noall +answer +search kubernetes.default.svc.cluster.local A)" && test -n "$$check" && echo OK > /results/jessie_tcp@kubernetes.default.svc.cluster.local;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-5835.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe DNS
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 20 10:18:51.436: INFO: DNS probes using dns-5835/dns-test-7a2d7561-f267-46f5-93e9-681e1554486f succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:18:51.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-5835" for this suite.
Dec 20 10:18:57.457: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:18:57.550: INFO: namespace dns-5835 deletion completed in 6.102941761s

• [SLOW TEST:10.289 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide DNS for the cluster  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:18:57.551: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7182
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 20 10:18:57.687: INFO: Waiting up to 5m0s for pod "downwardapi-volume-6ed6382c-b044-4de0-af8f-4ddaba1b0381" in namespace "downward-api-7182" to be "success or failure"
Dec 20 10:18:57.689: INFO: Pod "downwardapi-volume-6ed6382c-b044-4de0-af8f-4ddaba1b0381": Phase="Pending", Reason="", readiness=false. Elapsed: 2.222787ms
Dec 20 10:18:59.693: INFO: Pod "downwardapi-volume-6ed6382c-b044-4de0-af8f-4ddaba1b0381": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006126268s
Dec 20 10:19:01.698: INFO: Pod "downwardapi-volume-6ed6382c-b044-4de0-af8f-4ddaba1b0381": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010362241s
STEP: Saw pod success
Dec 20 10:19:01.698: INFO: Pod "downwardapi-volume-6ed6382c-b044-4de0-af8f-4ddaba1b0381" satisfied condition "success or failure"
Dec 20 10:19:01.701: INFO: Trying to get logs from node caasp-worker-th-before-3 pod downwardapi-volume-6ed6382c-b044-4de0-af8f-4ddaba1b0381 container client-container: <nil>
STEP: delete the pod
Dec 20 10:19:01.716: INFO: Waiting for pod downwardapi-volume-6ed6382c-b044-4de0-af8f-4ddaba1b0381 to disappear
Dec 20 10:19:01.720: INFO: Pod downwardapi-volume-6ed6382c-b044-4de0-af8f-4ddaba1b0381 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:19:01.721: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7182" for this suite.
Dec 20 10:19:07.737: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:19:07.822: INFO: namespace downward-api-7182 deletion completed in 6.097089298s

• [SLOW TEST:10.272 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:19:07.823: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-7210
STEP: Waiting for a default service account to be provisioned in namespace
[It] pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating Pod
STEP: Waiting for the pod running
STEP: Geting the pod
STEP: Reading file content from the nginx-container
Dec 20 10:19:11.987: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec pod-sharedvolume-3dd5d8e2-647a-4fa1-acf1-7b0151fac5e7 -c busybox-main-container --namespace=emptydir-7210 -- cat /usr/share/volumeshare/shareddata.txt'
Dec 20 10:19:12.154: INFO: stderr: ""
Dec 20 10:19:12.154: INFO: stdout: "Hello from the busy-box sub-container\n"
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:19:12.154: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-7210" for this suite.
Dec 20 10:19:18.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:19:18.263: INFO: namespace emptydir-7210 deletion completed in 6.104750106s

• [SLOW TEST:10.440 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  pod should support shared volumes between containers [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-storage] Projected configMap 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:19:18.263: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-3847
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name cm-test-opt-del-49d8cc49-ce5e-4442-a31f-856f004afbd9
STEP: Creating configMap with name cm-test-opt-upd-f6def2aa-a404-4bf9-9d49-3c2d288d4ddc
STEP: Creating the pod
STEP: Deleting configmap cm-test-opt-del-49d8cc49-ce5e-4442-a31f-856f004afbd9
STEP: Updating configmap cm-test-opt-upd-f6def2aa-a404-4bf9-9d49-3c2d288d4ddc
STEP: Creating configMap with name cm-test-opt-create-7cb3aeed-2e0c-4720-95e0-0692aa259f5e
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:20:34.748: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-3847" for this suite.
Dec 20 10:20:46.761: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:20:46.855: INFO: namespace projected-3847 deletion completed in 12.103636762s

• [SLOW TEST:88.592 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:20:46.856: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-5699
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 20 10:20:47.000: INFO: Waiting up to 5m0s for pod "downwardapi-volume-c2e273d1-d59c-4ff0-8ade-dd22753acef9" in namespace "downward-api-5699" to be "success or failure"
Dec 20 10:20:47.002: INFO: Pod "downwardapi-volume-c2e273d1-d59c-4ff0-8ade-dd22753acef9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.228575ms
Dec 20 10:20:49.007: INFO: Pod "downwardapi-volume-c2e273d1-d59c-4ff0-8ade-dd22753acef9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006389531s
Dec 20 10:20:51.010: INFO: Pod "downwardapi-volume-c2e273d1-d59c-4ff0-8ade-dd22753acef9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010085226s
STEP: Saw pod success
Dec 20 10:20:51.010: INFO: Pod "downwardapi-volume-c2e273d1-d59c-4ff0-8ade-dd22753acef9" satisfied condition "success or failure"
Dec 20 10:20:51.013: INFO: Trying to get logs from node caasp-worker-th-before-3 pod downwardapi-volume-c2e273d1-d59c-4ff0-8ade-dd22753acef9 container client-container: <nil>
STEP: delete the pod
Dec 20 10:20:51.027: INFO: Waiting for pod downwardapi-volume-c2e273d1-d59c-4ff0-8ade-dd22753acef9 to disappear
Dec 20 10:20:51.029: INFO: Pod downwardapi-volume-c2e273d1-d59c-4ff0-8ade-dd22753acef9 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:20:51.029: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-5699" for this suite.
Dec 20 10:20:57.042: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:20:57.137: INFO: namespace downward-api-5699 deletion completed in 6.105187624s

• [SLOW TEST:10.282 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide podname only [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch 
  watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:20:57.138: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename crd-watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-watch-1822
STEP: Waiting for a default service account to be provisioned in namespace
[It] watch on custom resource definition objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 10:20:57.268: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Creating first CR 
Dec 20 10:20:57.839: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-20T10:20:57Z generation:1 name:name1 resourceVersion:127135 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:e3742360-76d0-44eb-9408-f43d0d0103f1] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Creating second CR
Dec 20 10:21:07.845: INFO: Got : ADDED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-20T10:21:07Z generation:1 name:name2 resourceVersion:127162 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:b8dcb508-7c48-4436-af7f-44c4310e41d4] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying first CR
Dec 20 10:21:17.850: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-20T10:20:57Z generation:2 name:name1 resourceVersion:127194 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:e3742360-76d0-44eb-9408-f43d0d0103f1] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Modifying second CR
Dec 20 10:21:27.857: INFO: Got : MODIFIED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-20T10:21:07Z generation:2 name:name2 resourceVersion:127224 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:b8dcb508-7c48-4436-af7f-44c4310e41d4] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting first CR
Dec 20 10:21:37.865: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-20T10:20:57Z generation:2 name:name1 resourceVersion:127245 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name1 uid:e3742360-76d0-44eb-9408-f43d0d0103f1] num:map[num1:9223372036854775807 num2:1000000]]}
STEP: Deleting second CR
Dec 20 10:21:47.882: INFO: Got : DELETED &{map[apiVersion:mygroup.example.com/v1beta1 content:map[key:value] dummy:test kind:WishIHadChosenNoxu metadata:map[creationTimestamp:2019-12-20T10:21:07Z generation:2 name:name2 resourceVersion:127271 selfLink:/apis/mygroup.example.com/v1beta1/noxus/name2 uid:b8dcb508-7c48-4436-af7f-44c4310e41d4] num:map[num1:9223372036854775807 num2:1000000]]}
[AfterEach] [sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:21:58.393: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-watch-1822" for this suite.
Dec 20 10:22:04.410: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:22:04.508: INFO: namespace crd-watch-1822 deletion completed in 6.110446559s

• [SLOW TEST:67.370 seconds]
[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  CustomResourceDefinition Watch
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_watch.go:42
    watch on custom resource definition objects [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:22:04.508: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-8220
STEP: Waiting for a default service account to be provisioned in namespace
[It] volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir volume type on tmpfs
Dec 20 10:22:04.648: INFO: Waiting up to 5m0s for pod "pod-d2f8aa01-1480-4965-876d-9a7a004216e3" in namespace "emptydir-8220" to be "success or failure"
Dec 20 10:22:04.650: INFO: Pod "pod-d2f8aa01-1480-4965-876d-9a7a004216e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.016121ms
Dec 20 10:22:06.654: INFO: Pod "pod-d2f8aa01-1480-4965-876d-9a7a004216e3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005563283s
Dec 20 10:22:08.658: INFO: Pod "pod-d2f8aa01-1480-4965-876d-9a7a004216e3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010242457s
STEP: Saw pod success
Dec 20 10:22:08.658: INFO: Pod "pod-d2f8aa01-1480-4965-876d-9a7a004216e3" satisfied condition "success or failure"
Dec 20 10:22:08.661: INFO: Trying to get logs from node caasp-worker-th-before-0 pod pod-d2f8aa01-1480-4965-876d-9a7a004216e3 container test-container: <nil>
STEP: delete the pod
Dec 20 10:22:08.690: INFO: Waiting for pod pod-d2f8aa01-1480-4965-876d-9a7a004216e3 to disappear
Dec 20 10:22:08.692: INFO: Pod pod-d2f8aa01-1480-4965-876d-9a7a004216e3 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:22:08.692: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-8220" for this suite.
Dec 20 10:22:14.706: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:22:14.802: INFO: namespace emptydir-8220 deletion completed in 6.10645369s

• [SLOW TEST:10.294 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] Namespaces [Serial] 
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:22:14.802: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename namespaces
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in namespaces-8756
STEP: Waiting for a default service account to be provisioned in namespace
[It] should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a test namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-3320
STEP: Waiting for a default service account to be provisioned in namespace
STEP: Creating a pod in the namespace
STEP: Waiting for the pod to have running status
STEP: Deleting the namespace
STEP: Waiting for the namespace to be removed.
STEP: Recreating the namespace
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in nsdeletetest-5250
STEP: Verifying there are no pods in the namespace
[AfterEach] [sig-api-machinery] Namespaces [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:22:30.223: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "namespaces-8756" for this suite.
Dec 20 10:22:36.238: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:22:36.332: INFO: namespace namespaces-8756 deletion completed in 6.105497187s
STEP: Destroying namespace "nsdeletetest-3320" for this suite.
Dec 20 10:22:36.335: INFO: Namespace nsdeletetest-3320 was already deleted
STEP: Destroying namespace "nsdeletetest-5250" for this suite.
Dec 20 10:22:42.347: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:22:42.443: INFO: namespace nsdeletetest-5250 deletion completed in 6.108408624s

• [SLOW TEST:27.641 seconds]
[sig-api-machinery] Namespaces [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should ensure that all pods are removed when a namespace is deleted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] 
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:22:42.443: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-2975
STEP: Waiting for a default service account to be provisioned in namespace
[It] should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: fetching the /apis discovery document
STEP: finding the apiextensions.k8s.io API group in the /apis discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis discovery document
STEP: fetching the /apis/apiextensions.k8s.io discovery document
STEP: finding the apiextensions.k8s.io/v1 API group/version in the /apis/apiextensions.k8s.io discovery document
STEP: fetching the /apis/apiextensions.k8s.io/v1 discovery document
STEP: finding customresourcedefinitions resources in the /apis/apiextensions.k8s.io/v1 discovery document
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:22:42.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-2975" for this suite.
Dec 20 10:22:48.595: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:22:48.691: INFO: namespace custom-resource-definition-2975 deletion completed in 6.106468593s

• [SLOW TEST:6.248 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should include custom resource definition resources in discovery documents [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:22:48.691: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6229
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating secret secrets-6229/secret-test-8b31e0d6-b916-409e-88aa-658b036aa111
STEP: Creating a pod to test consume secrets
Dec 20 10:22:48.835: INFO: Waiting up to 5m0s for pod "pod-configmaps-b2eb9930-76b1-4f3a-be34-fc3af5a6a91f" in namespace "secrets-6229" to be "success or failure"
Dec 20 10:22:48.837: INFO: Pod "pod-configmaps-b2eb9930-76b1-4f3a-be34-fc3af5a6a91f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.515848ms
Dec 20 10:22:50.841: INFO: Pod "pod-configmaps-b2eb9930-76b1-4f3a-be34-fc3af5a6a91f": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006417702s
Dec 20 10:22:52.846: INFO: Pod "pod-configmaps-b2eb9930-76b1-4f3a-be34-fc3af5a6a91f": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010782334s
STEP: Saw pod success
Dec 20 10:22:52.846: INFO: Pod "pod-configmaps-b2eb9930-76b1-4f3a-be34-fc3af5a6a91f" satisfied condition "success or failure"
Dec 20 10:22:52.849: INFO: Trying to get logs from node caasp-worker-th-before-4 pod pod-configmaps-b2eb9930-76b1-4f3a-be34-fc3af5a6a91f container env-test: <nil>
STEP: delete the pod
Dec 20 10:22:52.879: INFO: Waiting for pod pod-configmaps-b2eb9930-76b1-4f3a-be34-fc3af5a6a91f to disappear
Dec 20 10:22:52.882: INFO: Pod pod-configmaps-b2eb9930-76b1-4f3a-be34-fc3af5a6a91f no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:22:52.882: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6229" for this suite.
Dec 20 10:22:58.896: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:22:58.996: INFO: namespace secrets-6229 deletion completed in 6.110488949s

• [SLOW TEST:10.305 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable via the environment [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:22:58.997: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1867
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-8f00f764-9810-4d44-9f61-0f43729288d6
STEP: Creating a pod to test consume secrets
Dec 20 10:22:59.138: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-f4b086c7-1d37-4bb5-ad4e-b4a48dc32fd9" in namespace "projected-1867" to be "success or failure"
Dec 20 10:22:59.140: INFO: Pod "pod-projected-secrets-f4b086c7-1d37-4bb5-ad4e-b4a48dc32fd9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.199504ms
Dec 20 10:23:01.145: INFO: Pod "pod-projected-secrets-f4b086c7-1d37-4bb5-ad4e-b4a48dc32fd9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00670366s
Dec 20 10:23:03.149: INFO: Pod "pod-projected-secrets-f4b086c7-1d37-4bb5-ad4e-b4a48dc32fd9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011076644s
STEP: Saw pod success
Dec 20 10:23:03.149: INFO: Pod "pod-projected-secrets-f4b086c7-1d37-4bb5-ad4e-b4a48dc32fd9" satisfied condition "success or failure"
Dec 20 10:23:03.152: INFO: Trying to get logs from node caasp-worker-th-before-0 pod pod-projected-secrets-f4b086c7-1d37-4bb5-ad4e-b4a48dc32fd9 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 20 10:23:03.169: INFO: Waiting for pod pod-projected-secrets-f4b086c7-1d37-4bb5-ad4e-b4a48dc32fd9 to disappear
Dec 20 10:23:03.171: INFO: Pod pod-projected-secrets-f4b086c7-1d37-4bb5-ad4e-b4a48dc32fd9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:23:03.171: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1867" for this suite.
Dec 20 10:23:09.184: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:23:09.280: INFO: namespace projected-1867 deletion completed in 6.106035959s

• [SLOW TEST:10.284 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:23:09.280: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-5796
STEP: Waiting for a default service account to be provisioned in namespace
[It] should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Counting existing ResourceQuota
STEP: Creating a ResourceQuota
STEP: Ensuring resource quota status is calculated
STEP: Creating a ConfigMap
STEP: Ensuring resource quota status captures configMap creation
STEP: Deleting a ConfigMap
STEP: Ensuring resource quota status released usage
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:23:25.445: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-5796" for this suite.
Dec 20 10:23:31.460: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:23:31.557: INFO: namespace resourcequota-5796 deletion completed in 6.107200759s

• [SLOW TEST:22.276 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should create a ResourceQuota and capture the life of a configMap. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:23:31.557: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-8134
STEP: Waiting for a default service account to be provisioned in namespace
[It] should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a watch on configmaps with label A
STEP: creating a watch on configmaps with label B
STEP: creating a watch on configmaps with label A or B
STEP: creating a configmap with label A and ensuring the correct watchers observe the notification
Dec 20 10:23:31.693: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8134 /api/v1/namespaces/watch-8134/configmaps/e2e-watch-test-configmap-a 569089c6-a98c-4153-bd74-953cbfa9984a 127762 0 2019-12-20 10:23:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 20 10:23:31.694: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8134 /api/v1/namespaces/watch-8134/configmaps/e2e-watch-test-configmap-a 569089c6-a98c-4153-bd74-953cbfa9984a 127762 0 2019-12-20 10:23:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: modifying configmap A and ensuring the correct watchers observe the notification
Dec 20 10:23:41.703: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8134 /api/v1/namespaces/watch-8134/configmaps/e2e-watch-test-configmap-a 569089c6-a98c-4153-bd74-953cbfa9984a 127787 0 2019-12-20 10:23:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
Dec 20 10:23:41.703: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8134 /api/v1/namespaces/watch-8134/configmaps/e2e-watch-test-configmap-a 569089c6-a98c-4153-bd74-953cbfa9984a 127787 0 2019-12-20 10:23:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 1,},BinaryData:map[string][]byte{},}
STEP: modifying configmap A again and ensuring the correct watchers observe the notification
Dec 20 10:23:51.712: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8134 /api/v1/namespaces/watch-8134/configmaps/e2e-watch-test-configmap-a 569089c6-a98c-4153-bd74-953cbfa9984a 127815 0 2019-12-20 10:23:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 20 10:23:51.712: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8134 /api/v1/namespaces/watch-8134/configmaps/e2e-watch-test-configmap-a 569089c6-a98c-4153-bd74-953cbfa9984a 127815 0 2019-12-20 10:23:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: deleting configmap A and ensuring the correct watchers observe the notification
Dec 20 10:24:01.721: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8134 /api/v1/namespaces/watch-8134/configmaps/e2e-watch-test-configmap-a 569089c6-a98c-4153-bd74-953cbfa9984a 127848 0 2019-12-20 10:23:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 20 10:24:01.721: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-a  watch-8134 /api/v1/namespaces/watch-8134/configmaps/e2e-watch-test-configmap-a 569089c6-a98c-4153-bd74-953cbfa9984a 127848 0 2019-12-20 10:23:31 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-A] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
STEP: creating a configmap with label B and ensuring the correct watchers observe the notification
Dec 20 10:24:11.731: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8134 /api/v1/namespaces/watch-8134/configmaps/e2e-watch-test-configmap-b 8f1a5e10-2a47-44d5-aff2-e6c8743c19c9 127872 0 2019-12-20 10:24:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 20 10:24:11.731: INFO: Got : ADDED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8134 /api/v1/namespaces/watch-8134/configmaps/e2e-watch-test-configmap-b 8f1a5e10-2a47-44d5-aff2-e6c8743c19c9 127872 0 2019-12-20 10:24:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
STEP: deleting configmap B and ensuring the correct watchers observe the notification
Dec 20 10:24:21.740: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8134 /api/v1/namespaces/watch-8134/configmaps/e2e-watch-test-configmap-b 8f1a5e10-2a47-44d5-aff2-e6c8743c19c9 127896 0 2019-12-20 10:24:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
Dec 20 10:24:21.740: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-configmap-b  watch-8134 /api/v1/namespaces/watch-8134/configmaps/e2e-watch-test-configmap-b 8f1a5e10-2a47-44d5-aff2-e6c8743c19c9 127896 0 2019-12-20 10:24:11 +0000 UTC <nil> <nil> map[watch-this-configmap:multiple-watchers-B] map[] [] []  []},Data:map[string]string{},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:24:31.740: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-8134" for this suite.
Dec 20 10:24:37.756: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:24:37.844: INFO: namespace watch-8134 deletion completed in 6.09851077s

• [SLOW TEST:66.287 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should observe add, update, and delete watch notifications on configmaps [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:24:37.844: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-2412
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with secret that has name projected-secret-test-map-284553af-118f-4712-939c-d6886d22e35d
STEP: Creating a pod to test consume secrets
Dec 20 10:24:37.988: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-e98620b6-db7c-4884-91c6-4a318c8466e8" in namespace "projected-2412" to be "success or failure"
Dec 20 10:24:37.991: INFO: Pod "pod-projected-secrets-e98620b6-db7c-4884-91c6-4a318c8466e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.298931ms
Dec 20 10:24:39.995: INFO: Pod "pod-projected-secrets-e98620b6-db7c-4884-91c6-4a318c8466e8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006577207s
Dec 20 10:24:41.999: INFO: Pod "pod-projected-secrets-e98620b6-db7c-4884-91c6-4a318c8466e8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011242167s
STEP: Saw pod success
Dec 20 10:24:42.000: INFO: Pod "pod-projected-secrets-e98620b6-db7c-4884-91c6-4a318c8466e8" satisfied condition "success or failure"
Dec 20 10:24:42.003: INFO: Trying to get logs from node caasp-worker-th-before-0 pod pod-projected-secrets-e98620b6-db7c-4884-91c6-4a318c8466e8 container projected-secret-volume-test: <nil>
STEP: delete the pod
Dec 20 10:24:42.032: INFO: Waiting for pod pod-projected-secrets-e98620b6-db7c-4884-91c6-4a318c8466e8 to disappear
Dec 20 10:24:42.035: INFO: Pod pod-projected-secrets-e98620b6-db7c-4884-91c6-4a318c8466e8 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:24:42.035: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-2412" for this suite.
Dec 20 10:24:48.049: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:24:48.141: INFO: namespace projected-2412 deletion completed in 6.102368972s

• [SLOW TEST:10.296 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:24:48.141: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-3965
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 20 10:24:48.279: INFO: Waiting up to 5m0s for pod "downwardapi-volume-502a84e4-9a69-4944-bdca-3b09a40bb884" in namespace "downward-api-3965" to be "success or failure"
Dec 20 10:24:48.282: INFO: Pod "downwardapi-volume-502a84e4-9a69-4944-bdca-3b09a40bb884": Phase="Pending", Reason="", readiness=false. Elapsed: 2.696089ms
Dec 20 10:24:50.287: INFO: Pod "downwardapi-volume-502a84e4-9a69-4944-bdca-3b09a40bb884": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007429629s
Dec 20 10:24:52.291: INFO: Pod "downwardapi-volume-502a84e4-9a69-4944-bdca-3b09a40bb884": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011699062s
STEP: Saw pod success
Dec 20 10:24:52.291: INFO: Pod "downwardapi-volume-502a84e4-9a69-4944-bdca-3b09a40bb884" satisfied condition "success or failure"
Dec 20 10:24:52.294: INFO: Trying to get logs from node caasp-worker-th-before-4 pod downwardapi-volume-502a84e4-9a69-4944-bdca-3b09a40bb884 container client-container: <nil>
STEP: delete the pod
Dec 20 10:24:52.320: INFO: Waiting for pod downwardapi-volume-502a84e4-9a69-4944-bdca-3b09a40bb884 to disappear
Dec 20 10:24:52.322: INFO: Pod downwardapi-volume-502a84e4-9a69-4944-bdca-3b09a40bb884 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:24:52.322: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-3965" for this suite.
Dec 20 10:24:58.336: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:24:58.426: INFO: namespace downward-api-3965 deletion completed in 6.100388477s

• [SLOW TEST:10.285 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Servers with support for Table transformation 
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:24:58.427: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename tables
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in tables-5171
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/table_conversion.go:47
[It] should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-api-machinery] Servers with support for Table transformation
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:24:58.559: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "tables-5171" for this suite.
Dec 20 10:25:04.575: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:25:04.671: INFO: namespace tables-5171 deletion completed in 6.107583826s

• [SLOW TEST:6.245 seconds]
[sig-api-machinery] Servers with support for Table transformation
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should return a 406 for a backend which does not implement metadata [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run rc 
  should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:25:04.671: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-2307
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run rc
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1439
[It] should create an rc from an image  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 20 10:25:04.803: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 run e2e-test-httpd-rc --image=docker.io/library/httpd:2.4.38-alpine --generator=run/v1 --namespace=kubectl-2307'
Dec 20 10:25:04.947: INFO: stderr: "kubectl run --generator=run/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 20 10:25:04.947: INFO: stdout: "replicationcontroller/e2e-test-httpd-rc created\n"
STEP: verifying the rc e2e-test-httpd-rc was created
STEP: verifying the pod controlled by rc e2e-test-httpd-rc was created
STEP: confirm that you can get logs from an rc
Dec 20 10:25:04.952: INFO: Waiting up to 5m0s for 1 pods to be running and ready: [e2e-test-httpd-rc-ng9zq]
Dec 20 10:25:04.952: INFO: Waiting up to 5m0s for pod "e2e-test-httpd-rc-ng9zq" in namespace "kubectl-2307" to be "running and ready"
Dec 20 10:25:04.954: INFO: Pod "e2e-test-httpd-rc-ng9zq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.27679ms
Dec 20 10:25:06.958: INFO: Pod "e2e-test-httpd-rc-ng9zq": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005928096s
Dec 20 10:25:08.962: INFO: Pod "e2e-test-httpd-rc-ng9zq": Phase="Running", Reason="", readiness=true. Elapsed: 4.009953201s
Dec 20 10:25:08.962: INFO: Pod "e2e-test-httpd-rc-ng9zq" satisfied condition "running and ready"
Dec 20 10:25:08.962: INFO: Wanted all 1 pods to be running and ready. Result: true. Pods: [e2e-test-httpd-rc-ng9zq]
Dec 20 10:25:08.962: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 logs rc/e2e-test-httpd-rc --namespace=kubectl-2307'
Dec 20 10:25:09.124: INFO: stderr: ""
Dec 20 10:25:09.124: INFO: stdout: "AH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.244.5.194. Set the 'ServerName' directive globally to suppress this message\nAH00558: httpd: Could not reliably determine the server's fully qualified domain name, using 10.244.5.194. Set the 'ServerName' directive globally to suppress this message\n[Fri Dec 20 10:25:07.469545 2019] [mpm_event:notice] [pid 1:tid 140652887010152] AH00489: Apache/2.4.38 (Unix) configured -- resuming normal operations\n[Fri Dec 20 10:25:07.469590 2019] [core:notice] [pid 1:tid 140652887010152] AH00094: Command line: 'httpd -D FOREGROUND'\n"
[AfterEach] Kubectl run rc
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1444
Dec 20 10:25:09.124: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 delete rc e2e-test-httpd-rc --namespace=kubectl-2307'
Dec 20 10:25:09.215: INFO: stderr: ""
Dec 20 10:25:09.215: INFO: stdout: "replicationcontroller \"e2e-test-httpd-rc\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:25:09.215: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-2307" for this suite.
Dec 20 10:25:15.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:25:15.319: INFO: namespace kubectl-2307 deletion completed in 6.098064306s

• [SLOW TEST:10.647 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run rc
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1435
    should create an rc from an image  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:25:15.319: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5134
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 20 10:25:15.459: INFO: Waiting up to 5m0s for pod "pod-82f0ae51-0ec4-4bee-a4c4-6d6e33c8cd94" in namespace "emptydir-5134" to be "success or failure"
Dec 20 10:25:15.462: INFO: Pod "pod-82f0ae51-0ec4-4bee-a4c4-6d6e33c8cd94": Phase="Pending", Reason="", readiness=false. Elapsed: 2.359809ms
Dec 20 10:25:17.466: INFO: Pod "pod-82f0ae51-0ec4-4bee-a4c4-6d6e33c8cd94": Phase="Succeeded", Reason="", readiness=false. Elapsed: 2.006417401s
STEP: Saw pod success
Dec 20 10:25:17.466: INFO: Pod "pod-82f0ae51-0ec4-4bee-a4c4-6d6e33c8cd94" satisfied condition "success or failure"
Dec 20 10:25:17.470: INFO: Trying to get logs from node caasp-worker-th-before-4 pod pod-82f0ae51-0ec4-4bee-a4c4-6d6e33c8cd94 container test-container: <nil>
STEP: delete the pod
Dec 20 10:25:17.484: INFO: Waiting for pod pod-82f0ae51-0ec4-4bee-a4c4-6d6e33c8cd94 to disappear
Dec 20 10:25:17.487: INFO: Pod pod-82f0ae51-0ec4-4bee-a4c4-6d6e33c8cd94 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:25:17.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5134" for this suite.
Dec 20 10:25:23.499: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:25:23.594: INFO: namespace emptydir-5134 deletion completed in 6.103552553s

• [SLOW TEST:8.275 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:25:23.594: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9013
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 20 10:25:23.742: INFO: Waiting up to 5m0s for pod "downwardapi-volume-458003b0-c128-4347-9531-2bfb265e9aef" in namespace "projected-9013" to be "success or failure"
Dec 20 10:25:23.744: INFO: Pod "downwardapi-volume-458003b0-c128-4347-9531-2bfb265e9aef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.541398ms
Dec 20 10:25:25.748: INFO: Pod "downwardapi-volume-458003b0-c128-4347-9531-2bfb265e9aef": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005743368s
Dec 20 10:25:27.751: INFO: Pod "downwardapi-volume-458003b0-c128-4347-9531-2bfb265e9aef": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009357498s
STEP: Saw pod success
Dec 20 10:25:27.751: INFO: Pod "downwardapi-volume-458003b0-c128-4347-9531-2bfb265e9aef" satisfied condition "success or failure"
Dec 20 10:25:27.754: INFO: Trying to get logs from node caasp-worker-th-before-4 pod downwardapi-volume-458003b0-c128-4347-9531-2bfb265e9aef container client-container: <nil>
STEP: delete the pod
Dec 20 10:25:27.768: INFO: Waiting for pod downwardapi-volume-458003b0-c128-4347-9531-2bfb265e9aef to disappear
Dec 20 10:25:27.770: INFO: Pod downwardapi-volume-458003b0-c128-4347-9531-2bfb265e9aef no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:25:27.770: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9013" for this suite.
Dec 20 10:25:33.784: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:25:33.869: INFO: namespace projected-9013 deletion completed in 6.095303446s

• [SLOW TEST:10.275 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:25:33.869: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-8463
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 20 10:25:33.999: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 20 10:25:34.010: INFO: Waiting for terminating namespaces to be deleted...
Dec 20 10:25:34.013: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-th-before-0 before test
Dec 20 10:25:34.018: INFO: cilium-srq5l from kube-system started at 2019-12-19 23:00:47 +0000 UTC (1 container statuses recorded)
Dec 20 10:25:34.018: INFO: 	Container cilium-agent ready: true, restart count 1
Dec 20 10:25:34.018: INFO: kube-proxy-m8mx6 from kube-system started at 2019-12-19 23:00:47 +0000 UTC (1 container statuses recorded)
Dec 20 10:25:34.018: INFO: 	Container kube-proxy ready: true, restart count 1
Dec 20 10:25:34.018: INFO: sonobuoy from sonobuoy started at 2019-12-20 09:06:03 +0000 UTC (1 container statuses recorded)
Dec 20 10:25:34.018: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 20 10:25:34.018: INFO: kured-cvqgx from kube-system started at 2019-12-19 23:02:27 +0000 UTC (1 container statuses recorded)
Dec 20 10:25:34.018: INFO: 	Container kured ready: true, restart count 1
Dec 20 10:25:34.018: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-th-before-3 before test
Dec 20 10:25:34.034: INFO: tiller-deploy-6b954db788-gjd4h from kube-system started at 2019-12-19 23:05:50 +0000 UTC (1 container statuses recorded)
Dec 20 10:25:34.034: INFO: 	Container tiller ready: true, restart count 7
Dec 20 10:25:34.034: INFO: kube-proxy-frbl9 from kube-system started at 2019-12-19 23:00:46 +0000 UTC (1 container statuses recorded)
Dec 20 10:25:34.034: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 20 10:25:34.034: INFO: cilium-sm7nn from kube-system started at 2019-12-19 23:00:46 +0000 UTC (1 container statuses recorded)
Dec 20 10:25:34.034: INFO: 	Container cilium-agent ready: true, restart count 4
Dec 20 10:25:34.034: INFO: kured-ddrtt from kube-system started at 2019-12-19 23:01:46 +0000 UTC (1 container statuses recorded)
Dec 20 10:25:34.034: INFO: 	Container kured ready: true, restart count 0
Dec 20 10:25:34.034: INFO: oidc-dex-799996b768-8xqtt from kube-system started at 2019-12-19 23:24:29 +0000 UTC (1 container statuses recorded)
Dec 20 10:25:34.034: INFO: 	Container oidc-dex ready: true, restart count 0
Dec 20 10:25:34.034: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-th-before-4 before test
Dec 20 10:25:34.039: INFO: kured-zktcs from kube-system started at 2019-12-19 23:01:56 +0000 UTC (1 container statuses recorded)
Dec 20 10:25:34.039: INFO: 	Container kured ready: true, restart count 0
Dec 20 10:25:34.039: INFO: cilium-nllss from kube-system started at 2019-12-19 23:00:46 +0000 UTC (1 container statuses recorded)
Dec 20 10:25:34.039: INFO: 	Container cilium-agent ready: true, restart count 4
Dec 20 10:25:34.039: INFO: kube-proxy-qcm45 from kube-system started at 2019-12-19 23:00:46 +0000 UTC (1 container statuses recorded)
Dec 20 10:25:34.039: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 20 10:25:34.039: INFO: oidc-dex-799996b768-4r6tn from kube-system started at 2019-12-19 23:24:29 +0000 UTC (1 container statuses recorded)
Dec 20 10:25:34.039: INFO: 	Container oidc-dex ready: true, restart count 0
[It] validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: verifying the node has the label node caasp-worker-th-before-0
STEP: verifying the node has the label node caasp-worker-th-before-3
STEP: verifying the node has the label node caasp-worker-th-before-4
Dec 20 10:25:34.073: INFO: Pod cilium-nllss requesting resource cpu=0m on Node caasp-worker-th-before-4
Dec 20 10:25:34.073: INFO: Pod cilium-sm7nn requesting resource cpu=0m on Node caasp-worker-th-before-3
Dec 20 10:25:34.073: INFO: Pod cilium-srq5l requesting resource cpu=0m on Node caasp-worker-th-before-0
Dec 20 10:25:34.073: INFO: Pod kube-proxy-frbl9 requesting resource cpu=0m on Node caasp-worker-th-before-3
Dec 20 10:25:34.073: INFO: Pod kube-proxy-m8mx6 requesting resource cpu=0m on Node caasp-worker-th-before-0
Dec 20 10:25:34.073: INFO: Pod kube-proxy-qcm45 requesting resource cpu=0m on Node caasp-worker-th-before-4
Dec 20 10:25:34.073: INFO: Pod kured-cvqgx requesting resource cpu=0m on Node caasp-worker-th-before-0
Dec 20 10:25:34.073: INFO: Pod kured-ddrtt requesting resource cpu=0m on Node caasp-worker-th-before-3
Dec 20 10:25:34.073: INFO: Pod kured-zktcs requesting resource cpu=0m on Node caasp-worker-th-before-4
Dec 20 10:25:34.073: INFO: Pod oidc-dex-799996b768-4r6tn requesting resource cpu=0m on Node caasp-worker-th-before-4
Dec 20 10:25:34.073: INFO: Pod oidc-dex-799996b768-8xqtt requesting resource cpu=0m on Node caasp-worker-th-before-3
Dec 20 10:25:34.073: INFO: Pod tiller-deploy-6b954db788-gjd4h requesting resource cpu=0m on Node caasp-worker-th-before-3
Dec 20 10:25:34.073: INFO: Pod sonobuoy requesting resource cpu=0m on Node caasp-worker-th-before-0
STEP: Starting Pods to consume most of the cluster CPU.
Dec 20 10:25:34.073: INFO: Creating a pod which consumes cpu=16800m on Node caasp-worker-th-before-0
Dec 20 10:25:34.079: INFO: Creating a pod which consumes cpu=16800m on Node caasp-worker-th-before-3
Dec 20 10:25:34.082: INFO: Creating a pod which consumes cpu=16800m on Node caasp-worker-th-before-4
STEP: Creating another pod that requires unavailable amount of CPU.
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-03fa64d9-04af-4365-865d-875735e7751b.15e20d624155d835], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8463/filler-pod-03fa64d9-04af-4365-865d-875735e7751b to caasp-worker-th-before-4]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-03fa64d9-04af-4365-865d-875735e7751b.15e20d628e79d6f2], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-03fa64d9-04af-4365-865d-875735e7751b.15e20d6292cf1805], Reason = [Created], Message = [Created container filler-pod-03fa64d9-04af-4365-865d-875735e7751b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-03fa64d9-04af-4365-865d-875735e7751b.15e20d6293f756e8], Reason = [Started], Message = [Started container filler-pod-03fa64d9-04af-4365-865d-875735e7751b]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6461c138-df17-461f-88f9-2c83f8038aa3.15e20d62412c5b34], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8463/filler-pod-6461c138-df17-461f-88f9-2c83f8038aa3 to caasp-worker-th-before-3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6461c138-df17-461f-88f9-2c83f8038aa3.15e20d62ae9dd744], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6461c138-df17-461f-88f9-2c83f8038aa3.15e20d62b3588859], Reason = [Created], Message = [Created container filler-pod-6461c138-df17-461f-88f9-2c83f8038aa3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-6461c138-df17-461f-88f9-2c83f8038aa3.15e20d62b48b097e], Reason = [Started], Message = [Started container filler-pod-6461c138-df17-461f-88f9-2c83f8038aa3]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ced16f82-0478-426a-85cc-8a50c50d6ec9.15e20d6241006c7b], Reason = [Scheduled], Message = [Successfully assigned sched-pred-8463/filler-pod-ced16f82-0478-426a-85cc-8a50c50d6ec9 to caasp-worker-th-before-0]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ced16f82-0478-426a-85cc-8a50c50d6ec9.15e20d62a747b625], Reason = [Pulled], Message = [Container image "k8s.gcr.io/pause:3.1" already present on machine]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ced16f82-0478-426a-85cc-8a50c50d6ec9.15e20d62aba5420a], Reason = [Created], Message = [Created container filler-pod-ced16f82-0478-426a-85cc-8a50c50d6ec9]
STEP: Considering event: 
Type = [Normal], Name = [filler-pod-ced16f82-0478-426a-85cc-8a50c50d6ec9.15e20d62ace774f4], Reason = [Started], Message = [Started container filler-pod-ced16f82-0478-426a-85cc-8a50c50d6ec9]
STEP: Considering event: 
Type = [Warning], Name = [additional-pod.15e20d63310ef351], Reason = [FailedScheduling], Message = [0/5 nodes are available: 2 node(s) had taints that the pod didn't tolerate, 3 Insufficient cpu.]
STEP: removing the label node off the node caasp-worker-th-before-0
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node caasp-worker-th-before-3
STEP: verifying the node doesn't have the label node
STEP: removing the label node off the node caasp-worker-th-before-4
STEP: verifying the node doesn't have the label node
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:25:39.140: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-8463" for this suite.
Dec 20 10:25:45.153: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:25:45.252: INFO: namespace sched-pred-8463 deletion completed in 6.109057438s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:11.383 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates resource limits of pods that are allowed to run  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[k8s.io] [sig-node] PreStop 
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:25:45.252: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename prestop
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in prestop-4048
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pre_stop.go:173
[It] should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating server pod server in namespace prestop-4048
STEP: Waiting for pods to come up.
STEP: Creating tester pod tester in namespace prestop-4048
STEP: Deleting pre-stop pod
Dec 20 10:25:58.422: INFO: Saw: {
	"Hostname": "server",
	"Sent": null,
	"Received": {
		"prestop": 1
	},
	"Errors": null,
	"Log": [
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up.",
		"default/nettest has 0 endpoints ([]), which is less than 8 as expected. Waiting for all endpoints to come up."
	],
	"StillContactingPeers": true
}
STEP: Deleting the server pod
[AfterEach] [k8s.io] [sig-node] PreStop
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:25:58.427: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "prestop-4048" for this suite.
Dec 20 10:26:42.440: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:26:42.531: INFO: namespace prestop-4048 deletion completed in 44.099298968s

• [SLOW TEST:57.278 seconds]
[k8s.io] [sig-node] PreStop
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should call prestop when killing a pod  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:26:42.531: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-2442
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-8732f22b-3fb7-4197-a108-8484034b2b57
STEP: Creating a pod to test consume configMaps
Dec 20 10:26:42.672: INFO: Waiting up to 5m0s for pod "pod-configmaps-ce7f9c5b-1874-4469-9fff-a75b01e23fdf" in namespace "configmap-2442" to be "success or failure"
Dec 20 10:26:42.674: INFO: Pod "pod-configmaps-ce7f9c5b-1874-4469-9fff-a75b01e23fdf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.309803ms
Dec 20 10:26:44.677: INFO: Pod "pod-configmaps-ce7f9c5b-1874-4469-9fff-a75b01e23fdf": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005474112s
Dec 20 10:26:46.681: INFO: Pod "pod-configmaps-ce7f9c5b-1874-4469-9fff-a75b01e23fdf": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008683366s
STEP: Saw pod success
Dec 20 10:26:46.681: INFO: Pod "pod-configmaps-ce7f9c5b-1874-4469-9fff-a75b01e23fdf" satisfied condition "success or failure"
Dec 20 10:26:46.683: INFO: Trying to get logs from node caasp-worker-th-before-3 pod pod-configmaps-ce7f9c5b-1874-4469-9fff-a75b01e23fdf container configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 10:26:46.697: INFO: Waiting for pod pod-configmaps-ce7f9c5b-1874-4469-9fff-a75b01e23fdf to disappear
Dec 20 10:26:46.699: INFO: Pod pod-configmaps-ce7f9c5b-1874-4469-9fff-a75b01e23fdf no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:26:46.699: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-2442" for this suite.
Dec 20 10:26:52.712: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:26:52.806: INFO: namespace configmap-2442 deletion completed in 6.103897954s

• [SLOW TEST:10.275 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:26:52.806: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-1398
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the pods
STEP: Gathering metrics
Dec 20 10:27:32.963: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W1220 10:27:32.963849      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 20 10:27:32.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-1398" for this suite.
Dec 20 10:27:38.978: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:27:39.064: INFO: namespace gc-1398 deletion completed in 6.097262663s

• [SLOW TEST:46.258 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan pods created by rc if delete options say so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-storage] Secrets 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:27:39.064: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6797
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-5be7e888-9a83-47e8-9fad-a305fc7197db
STEP: Creating secret with name s-test-opt-upd-c2408cda-4d31-4942-a5df-c8691ee39a14
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-5be7e888-9a83-47e8-9fad-a305fc7197db
STEP: Updating secret s-test-opt-upd-c2408cda-4d31-4942-a5df-c8691ee39a14
STEP: Creating secret with name s-test-opt-create-c2a64d09-435b-4b09-b3e9-53d9a5eafd01
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:29:11.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6797" for this suite.
Dec 20 10:29:39.645: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:29:39.742: INFO: namespace secrets-6797 deletion completed in 28.107245458s

• [SLOW TEST:120.678 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SS
------------------------------
[sig-api-machinery] Garbage collector 
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:29:39.742: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9
STEP: Waiting for a default service account to be provisioned in namespace
[It] should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the deployment
STEP: Wait for the Deployment to create new ReplicaSet
STEP: delete the deployment
STEP: wait for 30 seconds to see if the garbage collector mistakenly deletes the rs
STEP: Gathering metrics
Dec 20 10:30:10.409: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W1220 10:30:10.409891      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 20 10:30:10.409: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9" for this suite.
Dec 20 10:30:16.422: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:30:16.512: INFO: namespace gc-9 deletion completed in 6.099501415s

• [SLOW TEST:36.770 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[k8s.io] Security Context When creating a pod with readOnlyRootFilesystem 
  should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:30:16.512: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-2601
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 10:30:16.649: INFO: Waiting up to 5m0s for pod "busybox-readonly-false-4290446e-0767-4f64-a847-8c32a19dc1c3" in namespace "security-context-test-2601" to be "success or failure"
Dec 20 10:30:16.651: INFO: Pod "busybox-readonly-false-4290446e-0767-4f64-a847-8c32a19dc1c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.372912ms
Dec 20 10:30:18.655: INFO: Pod "busybox-readonly-false-4290446e-0767-4f64-a847-8c32a19dc1c3": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006220773s
Dec 20 10:30:20.659: INFO: Pod "busybox-readonly-false-4290446e-0767-4f64-a847-8c32a19dc1c3": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010302889s
Dec 20 10:30:20.659: INFO: Pod "busybox-readonly-false-4290446e-0767-4f64-a847-8c32a19dc1c3" satisfied condition "success or failure"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:30:20.659: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-2601" for this suite.
Dec 20 10:30:26.673: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:30:26.769: INFO: namespace security-context-test-2601 deletion completed in 6.105893365s

• [SLOW TEST:10.256 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with readOnlyRootFilesystem
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:165
    should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:30:26.769: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8324
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name projected-configmap-test-volume-dc0fbad0-6cbd-4b9e-8d31-20e36302e995
STEP: Creating a pod to test consume configMaps
Dec 20 10:30:26.911: INFO: Waiting up to 5m0s for pod "pod-projected-configmaps-4cafc04c-1e3d-4402-a078-0c58ee11f014" in namespace "projected-8324" to be "success or failure"
Dec 20 10:30:26.913: INFO: Pod "pod-projected-configmaps-4cafc04c-1e3d-4402-a078-0c58ee11f014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.389943ms
Dec 20 10:30:28.917: INFO: Pod "pod-projected-configmaps-4cafc04c-1e3d-4402-a078-0c58ee11f014": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005773769s
Dec 20 10:30:30.920: INFO: Pod "pod-projected-configmaps-4cafc04c-1e3d-4402-a078-0c58ee11f014": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009426868s
STEP: Saw pod success
Dec 20 10:30:30.920: INFO: Pod "pod-projected-configmaps-4cafc04c-1e3d-4402-a078-0c58ee11f014" satisfied condition "success or failure"
Dec 20 10:30:30.923: INFO: Trying to get logs from node caasp-worker-th-before-3 pod pod-projected-configmaps-4cafc04c-1e3d-4402-a078-0c58ee11f014 container projected-configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 10:30:30.936: INFO: Waiting for pod pod-projected-configmaps-4cafc04c-1e3d-4402-a078-0c58ee11f014 to disappear
Dec 20 10:30:30.938: INFO: Pod pod-projected-configmaps-4cafc04c-1e3d-4402-a078-0c58ee11f014 no longer exists
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:30:30.938: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8324" for this suite.
Dec 20 10:30:36.950: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:30:37.040: INFO: namespace projected-8324 deletion completed in 6.09843129s

• [SLOW TEST:10.271 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  should be consumable from pods in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-apps] Job 
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:30:37.040: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename job
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in job-1693
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a job
STEP: Ensuring job reaches completions
[AfterEach] [sig-apps] Job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:30:45.186: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "job-1693" for this suite.
Dec 20 10:30:51.201: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:30:51.306: INFO: namespace job-1693 deletion completed in 6.115931382s

• [SLOW TEST:14.266 seconds]
[sig-apps] Job
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:30:51.307: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8796
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override all
Dec 20 10:30:51.446: INFO: Waiting up to 5m0s for pod "client-containers-68bb9ff1-190b-49ad-ab31-992e80ec5406" in namespace "containers-8796" to be "success or failure"
Dec 20 10:30:51.448: INFO: Pod "client-containers-68bb9ff1-190b-49ad-ab31-992e80ec5406": Phase="Pending", Reason="", readiness=false. Elapsed: 2.637026ms
Dec 20 10:30:53.452: INFO: Pod "client-containers-68bb9ff1-190b-49ad-ab31-992e80ec5406": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006648832s
Dec 20 10:30:55.456: INFO: Pod "client-containers-68bb9ff1-190b-49ad-ab31-992e80ec5406": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.01028906s
STEP: Saw pod success
Dec 20 10:30:55.456: INFO: Pod "client-containers-68bb9ff1-190b-49ad-ab31-992e80ec5406" satisfied condition "success or failure"
Dec 20 10:30:55.459: INFO: Trying to get logs from node caasp-worker-th-before-0 pod client-containers-68bb9ff1-190b-49ad-ab31-992e80ec5406 container test-container: <nil>
STEP: delete the pod
Dec 20 10:30:55.485: INFO: Waiting for pod client-containers-68bb9ff1-190b-49ad-ab31-992e80ec5406 to disappear
Dec 20 10:30:55.487: INFO: Pod client-containers-68bb9ff1-190b-49ad-ab31-992e80ec5406 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:30:55.487: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8796" for this suite.
Dec 20 10:31:01.502: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:31:01.588: INFO: namespace containers-8796 deletion completed in 6.096700212s

• [SLOW TEST:10.281 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default command and arguments [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[sig-node] Downward API 
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:31:01.588: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-9283
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward api env vars
Dec 20 10:31:01.731: INFO: Waiting up to 5m0s for pod "downward-api-11a5b060-9a0c-4f6b-88dc-38d7fc842745" in namespace "downward-api-9283" to be "success or failure"
Dec 20 10:31:01.733: INFO: Pod "downward-api-11a5b060-9a0c-4f6b-88dc-38d7fc842745": Phase="Pending", Reason="", readiness=false. Elapsed: 2.235662ms
Dec 20 10:31:03.737: INFO: Pod "downward-api-11a5b060-9a0c-4f6b-88dc-38d7fc842745": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006146969s
Dec 20 10:31:05.741: INFO: Pod "downward-api-11a5b060-9a0c-4f6b-88dc-38d7fc842745": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010085325s
STEP: Saw pod success
Dec 20 10:31:05.741: INFO: Pod "downward-api-11a5b060-9a0c-4f6b-88dc-38d7fc842745" satisfied condition "success or failure"
Dec 20 10:31:05.744: INFO: Trying to get logs from node caasp-worker-th-before-0 pod downward-api-11a5b060-9a0c-4f6b-88dc-38d7fc842745 container dapi-container: <nil>
STEP: delete the pod
Dec 20 10:31:05.759: INFO: Waiting for pod downward-api-11a5b060-9a0c-4f6b-88dc-38d7fc842745 to disappear
Dec 20 10:31:05.762: INFO: Pod downward-api-11a5b060-9a0c-4f6b-88dc-38d7fc842745 no longer exists
[AfterEach] [sig-node] Downward API
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:31:05.762: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-9283" for this suite.
Dec 20 10:31:11.778: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:31:11.867: INFO: namespace downward-api-9283 deletion completed in 6.101019953s

• [SLOW TEST:10.279 seconds]
[sig-node] Downward API
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downward_api.go:32
  should provide host IP as an env var [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:31:11.867: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-9500
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-9500
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 20 10:31:11.998: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 20 10:31:38.067: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.7.163:8080/dial?request=hostName&protocol=http&host=10.244.7.151&port=8080&tries=1'] Namespace:pod-network-test-9500 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 10:31:38.067: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 10:31:38.144: INFO: Waiting for endpoints: map[]
Dec 20 10:31:38.147: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.7.163:8080/dial?request=hostName&protocol=http&host=10.244.5.186&port=8080&tries=1'] Namespace:pod-network-test-9500 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 10:31:38.147: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 10:31:38.215: INFO: Waiting for endpoints: map[]
Dec 20 10:31:38.219: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.7.163:8080/dial?request=hostName&protocol=http&host=10.244.6.77&port=8080&tries=1'] Namespace:pod-network-test-9500 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 10:31:38.219: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 10:31:38.292: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:31:38.292: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-9500" for this suite.
Dec 20 10:31:50.308: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:31:50.404: INFO: namespace pod-network-test-9500 deletion completed in 12.107997456s

• [SLOW TEST:38.537 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:31:50.404: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7506
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 20 10:31:53.558: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:31:53.569: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7506" for this suite.
Dec 20 10:31:59.582: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:31:59.678: INFO: namespace container-runtime-7506 deletion completed in 6.105177291s

• [SLOW TEST:9.273 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:31:59.678: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-8928
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 10:31:59.826: INFO: Creating simple daemon set daemon-set
STEP: Check that daemon pods launch on every node of the cluster.
Dec 20 10:31:59.833: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:31:59.833: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:31:59.835: INFO: Number of nodes with available pods: 0
Dec 20 10:31:59.835: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 10:32:00.841: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:00.841: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:00.846: INFO: Number of nodes with available pods: 0
Dec 20 10:32:00.846: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 10:32:01.840: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:01.840: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:01.845: INFO: Number of nodes with available pods: 0
Dec 20 10:32:01.845: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 10:32:02.841: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:02.841: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:02.847: INFO: Number of nodes with available pods: 3
Dec 20 10:32:02.847: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Update daemon pods image.
STEP: Check that daemon pods images are updated.
Dec 20 10:32:02.871: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:02.871: INFO: Wrong image for pod: daemon-set-ml9bx. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:02.871: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:02.875: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:02.875: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:03.879: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:03.879: INFO: Wrong image for pod: daemon-set-ml9bx. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:03.879: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:03.884: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:03.884: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:04.879: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:04.879: INFO: Wrong image for pod: daemon-set-ml9bx. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:04.879: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:04.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:04.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:05.879: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:05.879: INFO: Wrong image for pod: daemon-set-ml9bx. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:05.879: INFO: Pod daemon-set-ml9bx is not available
Dec 20 10:32:05.879: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:05.884: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:05.884: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:06.880: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:06.880: INFO: Wrong image for pod: daemon-set-ml9bx. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:06.880: INFO: Pod daemon-set-ml9bx is not available
Dec 20 10:32:06.880: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:06.885: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:06.885: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:07.879: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:07.879: INFO: Wrong image for pod: daemon-set-ml9bx. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:07.879: INFO: Pod daemon-set-ml9bx is not available
Dec 20 10:32:07.879: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:07.882: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:07.882: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:08.880: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:08.880: INFO: Wrong image for pod: daemon-set-ml9bx. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:08.880: INFO: Pod daemon-set-ml9bx is not available
Dec 20 10:32:08.880: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:08.885: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:08.885: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:09.879: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:09.879: INFO: Wrong image for pod: daemon-set-ml9bx. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:09.879: INFO: Pod daemon-set-ml9bx is not available
Dec 20 10:32:09.879: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:09.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:09.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:10.878: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:10.878: INFO: Wrong image for pod: daemon-set-ml9bx. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:10.878: INFO: Pod daemon-set-ml9bx is not available
Dec 20 10:32:10.878: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:10.882: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:10.882: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:11.884: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:11.884: INFO: Pod daemon-set-kpn2b is not available
Dec 20 10:32:11.884: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:11.888: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:11.889: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:12.879: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:12.879: INFO: Pod daemon-set-kpn2b is not available
Dec 20 10:32:12.879: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:12.884: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:12.884: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:13.879: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:13.879: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:13.884: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:13.884: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:14.878: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:14.878: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:14.878: INFO: Pod daemon-set-rghlv is not available
Dec 20 10:32:14.882: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:14.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:15.879: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:15.879: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:15.879: INFO: Pod daemon-set-rghlv is not available
Dec 20 10:32:15.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:15.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:16.879: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:16.879: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:16.879: INFO: Pod daemon-set-rghlv is not available
Dec 20 10:32:16.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:16.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:17.879: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:17.879: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:17.879: INFO: Pod daemon-set-rghlv is not available
Dec 20 10:32:17.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:17.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:18.879: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:18.879: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:18.879: INFO: Pod daemon-set-rghlv is not available
Dec 20 10:32:18.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:18.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:19.880: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:19.880: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:19.880: INFO: Pod daemon-set-rghlv is not available
Dec 20 10:32:19.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:19.884: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:20.879: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:20.879: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:20.879: INFO: Pod daemon-set-rghlv is not available
Dec 20 10:32:20.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:20.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:21.879: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:21.879: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:21.879: INFO: Pod daemon-set-rghlv is not available
Dec 20 10:32:21.884: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:21.884: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:22.879: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:22.879: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:22.879: INFO: Pod daemon-set-rghlv is not available
Dec 20 10:32:22.884: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:22.884: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:23.880: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:23.880: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:23.880: INFO: Pod daemon-set-rghlv is not available
Dec 20 10:32:23.884: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:23.884: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:24.878: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:24.878: INFO: Wrong image for pod: daemon-set-rghlv. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:24.878: INFO: Pod daemon-set-rghlv is not available
Dec 20 10:32:24.882: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:24.882: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:25.879: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:25.879: INFO: Pod daemon-set-l5drh is not available
Dec 20 10:32:25.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:25.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:26.879: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:26.879: INFO: Pod daemon-set-l5drh is not available
Dec 20 10:32:26.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:26.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:27.880: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:27.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:27.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:28.879: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:28.879: INFO: Pod daemon-set-7xph5 is not available
Dec 20 10:32:28.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:28.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:29.879: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:29.879: INFO: Pod daemon-set-7xph5 is not available
Dec 20 10:32:29.882: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:29.882: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:30.879: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:30.879: INFO: Pod daemon-set-7xph5 is not available
Dec 20 10:32:30.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:30.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:31.880: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:31.880: INFO: Pod daemon-set-7xph5 is not available
Dec 20 10:32:31.884: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:31.884: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:32.879: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:32.879: INFO: Pod daemon-set-7xph5 is not available
Dec 20 10:32:32.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:32.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:33.880: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:33.880: INFO: Pod daemon-set-7xph5 is not available
Dec 20 10:32:33.885: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:33.886: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:34.879: INFO: Wrong image for pod: daemon-set-7xph5. Expected: docker.io/library/redis:5.0.5-alpine, got: docker.io/library/httpd:2.4.38-alpine.
Dec 20 10:32:34.879: INFO: Pod daemon-set-7xph5 is not available
Dec 20 10:32:34.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:34.883: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:35.878: INFO: Pod daemon-set-r27jf is not available
Dec 20 10:32:35.882: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:35.882: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
STEP: Check that daemon pods are still running on every node of the cluster.
Dec 20 10:32:35.886: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:35.886: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:35.889: INFO: Number of nodes with available pods: 2
Dec 20 10:32:35.889: INFO: Node caasp-worker-th-before-3 is running more than one daemon pod
Dec 20 10:32:36.894: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:36.894: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:36.897: INFO: Number of nodes with available pods: 2
Dec 20 10:32:36.897: INFO: Node caasp-worker-th-before-3 is running more than one daemon pod
Dec 20 10:32:37.894: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:37.894: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:37.898: INFO: Number of nodes with available pods: 2
Dec 20 10:32:37.898: INFO: Node caasp-worker-th-before-3 is running more than one daemon pod
Dec 20 10:32:38.895: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:38.895: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:32:38.898: INFO: Number of nodes with available pods: 3
Dec 20 10:32:38.898: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-8928, will wait for the garbage collector to delete the pods
Dec 20 10:32:38.975: INFO: Deleting DaemonSet.extensions daemon-set took: 8.882867ms
Dec 20 10:32:39.375: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.347366ms
Dec 20 10:32:45.579: INFO: Number of nodes with available pods: 0
Dec 20 10:32:45.579: INFO: Number of running nodes: 0, number of available pods: 0
Dec 20 10:32:45.581: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-8928/daemonsets","resourceVersion":"130745"},"items":null}

Dec 20 10:32:45.584: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-8928/pods","resourceVersion":"130745"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:32:45.598: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-8928" for this suite.
Dec 20 10:32:51.613: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:32:51.701: INFO: namespace daemonsets-8928 deletion completed in 6.098690438s

• [SLOW TEST:52.023 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should update pod when spec was updated and update strategy is RollingUpdate [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:32:51.702: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1191
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 20 10:32:52.458: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 20 10:32:54.469: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712434773, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712434773, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712434773, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712434773, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 20 10:32:57.484: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 10:32:57.487: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-3366-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:32:58.602: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1191" for this suite.
Dec 20 10:33:04.616: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:33:04.704: INFO: namespace webhook-1191 deletion completed in 6.098788668s
STEP: Destroying namespace "webhook-1191-markers" for this suite.
Dec 20 10:33:10.715: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:33:10.805: INFO: namespace webhook-1191-markers deletion completed in 6.101088056s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.116 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource with pruning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:33:10.818: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-4099
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 20 10:33:10.963: INFO: Waiting up to 5m0s for pod "downwardapi-volume-35674a20-6ee7-4ae7-b5d9-21df10f5e49b" in namespace "downward-api-4099" to be "success or failure"
Dec 20 10:33:10.965: INFO: Pod "downwardapi-volume-35674a20-6ee7-4ae7-b5d9-21df10f5e49b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.37249ms
Dec 20 10:33:12.971: INFO: Pod "downwardapi-volume-35674a20-6ee7-4ae7-b5d9-21df10f5e49b": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007641447s
Dec 20 10:33:14.974: INFO: Pod "downwardapi-volume-35674a20-6ee7-4ae7-b5d9-21df10f5e49b": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011443252s
STEP: Saw pod success
Dec 20 10:33:14.974: INFO: Pod "downwardapi-volume-35674a20-6ee7-4ae7-b5d9-21df10f5e49b" satisfied condition "success or failure"
Dec 20 10:33:14.977: INFO: Trying to get logs from node caasp-worker-th-before-0 pod downwardapi-volume-35674a20-6ee7-4ae7-b5d9-21df10f5e49b container client-container: <nil>
STEP: delete the pod
Dec 20 10:33:15.001: INFO: Waiting for pod downwardapi-volume-35674a20-6ee7-4ae7-b5d9-21df10f5e49b to disappear
Dec 20 10:33:15.003: INFO: Pod downwardapi-volume-35674a20-6ee7-4ae7-b5d9-21df10f5e49b no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:33:15.003: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-4099" for this suite.
Dec 20 10:33:21.017: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:33:21.114: INFO: namespace downward-api-4099 deletion completed in 6.107701109s

• [SLOW TEST:10.297 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] [sig-node] Pods Extended [k8s.io] Delete Grace Period 
  should be submitted and removed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:33:21.114: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-4862
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/node/pods.go:47
[It] should be submitted and removed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: setting up selector
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
Dec 20 10:33:25.268: INFO: Asynchronously running '/usr/local/bin/kubectl kubectl --kubeconfig=/tmp/kubeconfig-816092167 proxy -p 0'
STEP: deleting the pod gracefully
STEP: verifying the kubelet observed the termination notice
Dec 20 10:33:35.364: INFO: no pod exists with the name we were looking for, assuming the termination request was observed and completed
[AfterEach] [k8s.io] [sig-node] Pods Extended
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:33:35.367: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-4862" for this suite.
Dec 20 10:33:41.382: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:33:41.475: INFO: namespace pods-4862 deletion completed in 6.103759366s

• [SLOW TEST:20.360 seconds]
[k8s.io] [sig-node] Pods Extended
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  [k8s.io] Delete Grace Period
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should be submitted and removed [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:33:41.475: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-8515
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with downward pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-downwardapi-zjjn
STEP: Creating a pod to test atomic-volume-subpath
Dec 20 10:33:41.621: INFO: Waiting up to 5m0s for pod "pod-subpath-test-downwardapi-zjjn" in namespace "subpath-8515" to be "success or failure"
Dec 20 10:33:41.623: INFO: Pod "pod-subpath-test-downwardapi-zjjn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.161538ms
Dec 20 10:33:43.627: INFO: Pod "pod-subpath-test-downwardapi-zjjn": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006032619s
Dec 20 10:33:45.631: INFO: Pod "pod-subpath-test-downwardapi-zjjn": Phase="Running", Reason="", readiness=true. Elapsed: 4.010618482s
Dec 20 10:33:47.635: INFO: Pod "pod-subpath-test-downwardapi-zjjn": Phase="Running", Reason="", readiness=true. Elapsed: 6.014540489s
Dec 20 10:33:49.639: INFO: Pod "pod-subpath-test-downwardapi-zjjn": Phase="Running", Reason="", readiness=true. Elapsed: 8.018199288s
Dec 20 10:33:51.644: INFO: Pod "pod-subpath-test-downwardapi-zjjn": Phase="Running", Reason="", readiness=true. Elapsed: 10.023004672s
Dec 20 10:33:53.648: INFO: Pod "pod-subpath-test-downwardapi-zjjn": Phase="Running", Reason="", readiness=true. Elapsed: 12.027354922s
Dec 20 10:33:55.652: INFO: Pod "pod-subpath-test-downwardapi-zjjn": Phase="Running", Reason="", readiness=true. Elapsed: 14.031150345s
Dec 20 10:33:57.656: INFO: Pod "pod-subpath-test-downwardapi-zjjn": Phase="Running", Reason="", readiness=true. Elapsed: 16.035717423s
Dec 20 10:33:59.661: INFO: Pod "pod-subpath-test-downwardapi-zjjn": Phase="Running", Reason="", readiness=true. Elapsed: 18.039942759s
Dec 20 10:34:01.666: INFO: Pod "pod-subpath-test-downwardapi-zjjn": Phase="Running", Reason="", readiness=true. Elapsed: 20.045554142s
Dec 20 10:34:03.670: INFO: Pod "pod-subpath-test-downwardapi-zjjn": Phase="Running", Reason="", readiness=true. Elapsed: 22.049197242s
Dec 20 10:34:05.674: INFO: Pod "pod-subpath-test-downwardapi-zjjn": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.053014061s
STEP: Saw pod success
Dec 20 10:34:05.674: INFO: Pod "pod-subpath-test-downwardapi-zjjn" satisfied condition "success or failure"
Dec 20 10:34:05.677: INFO: Trying to get logs from node caasp-worker-th-before-4 pod pod-subpath-test-downwardapi-zjjn container test-container-subpath-downwardapi-zjjn: <nil>
STEP: delete the pod
Dec 20 10:34:05.692: INFO: Waiting for pod pod-subpath-test-downwardapi-zjjn to disappear
Dec 20 10:34:05.694: INFO: Pod pod-subpath-test-downwardapi-zjjn no longer exists
STEP: Deleting pod pod-subpath-test-downwardapi-zjjn
Dec 20 10:34:05.694: INFO: Deleting pod "pod-subpath-test-downwardapi-zjjn" in namespace "subpath-8515"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:34:05.696: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-8515" for this suite.
Dec 20 10:34:11.714: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:34:11.807: INFO: namespace subpath-8515 deletion completed in 6.108264843s

• [SLOW TEST:30.332 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with downward pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Pods 
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:34:11.808: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-6890
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 10:34:15.975: INFO: Waiting up to 5m0s for pod "client-envvars-3272113d-77a8-48b5-8cdd-bf4e62c4cae8" in namespace "pods-6890" to be "success or failure"
Dec 20 10:34:15.977: INFO: Pod "client-envvars-3272113d-77a8-48b5-8cdd-bf4e62c4cae8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.376589ms
Dec 20 10:34:17.981: INFO: Pod "client-envvars-3272113d-77a8-48b5-8cdd-bf4e62c4cae8": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006197427s
Dec 20 10:34:19.985: INFO: Pod "client-envvars-3272113d-77a8-48b5-8cdd-bf4e62c4cae8": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009979074s
STEP: Saw pod success
Dec 20 10:34:19.985: INFO: Pod "client-envvars-3272113d-77a8-48b5-8cdd-bf4e62c4cae8" satisfied condition "success or failure"
Dec 20 10:34:19.988: INFO: Trying to get logs from node caasp-worker-th-before-3 pod client-envvars-3272113d-77a8-48b5-8cdd-bf4e62c4cae8 container env3cont: <nil>
STEP: delete the pod
Dec 20 10:34:20.014: INFO: Waiting for pod client-envvars-3272113d-77a8-48b5-8cdd-bf4e62c4cae8 to disappear
Dec 20 10:34:20.016: INFO: Pod client-envvars-3272113d-77a8-48b5-8cdd-bf4e62c4cae8 no longer exists
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:34:20.016: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-6890" for this suite.
Dec 20 10:34:48.030: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:34:48.125: INFO: namespace pods-6890 deletion completed in 28.104857936s

• [SLOW TEST:36.317 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should contain environment variables for services [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:34:48.125: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-1522
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 20 10:34:49.069: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 20 10:34:51.079: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712434890, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712434890, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712434890, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712434890, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 20 10:34:54.095: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should deny crd creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the crd webhook via the AdmissionRegistration API
STEP: Creating a custom resource definition that should be denied by the webhook
Dec 20 10:34:54.118: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:34:54.132: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-1522" for this suite.
Dec 20 10:35:00.149: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:35:00.235: INFO: namespace webhook-1522 deletion completed in 6.096443158s
STEP: Destroying namespace "webhook-1522-markers" for this suite.
Dec 20 10:35:06.245: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:35:06.332: INFO: namespace webhook-1522-markers deletion completed in 6.097112736s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.220 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should deny crd creation [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:35:06.346: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1026
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on node default medium
Dec 20 10:35:06.486: INFO: Waiting up to 5m0s for pod "pod-39d76f3c-39d4-4f91-a531-0067443f9f9a" in namespace "emptydir-1026" to be "success or failure"
Dec 20 10:35:06.489: INFO: Pod "pod-39d76f3c-39d4-4f91-a531-0067443f9f9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.294589ms
Dec 20 10:35:08.493: INFO: Pod "pod-39d76f3c-39d4-4f91-a531-0067443f9f9a": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006022453s
Dec 20 10:35:10.496: INFO: Pod "pod-39d76f3c-39d4-4f91-a531-0067443f9f9a": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009792423s
STEP: Saw pod success
Dec 20 10:35:10.496: INFO: Pod "pod-39d76f3c-39d4-4f91-a531-0067443f9f9a" satisfied condition "success or failure"
Dec 20 10:35:10.499: INFO: Trying to get logs from node caasp-worker-th-before-4 pod pod-39d76f3c-39d4-4f91-a531-0067443f9f9a container test-container: <nil>
STEP: delete the pod
Dec 20 10:35:10.516: INFO: Waiting for pod pod-39d76f3c-39d4-4f91-a531-0067443f9f9a to disappear
Dec 20 10:35:10.519: INFO: Pod pod-39d76f3c-39d4-4f91-a531-0067443f9f9a no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:35:10.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1026" for this suite.
Dec 20 10:35:16.533: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:35:16.626: INFO: namespace emptydir-1026 deletion completed in 6.10389971s

• [SLOW TEST:10.280 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Services 
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:35:16.626: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-5645
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service clusterip-service with the type=ClusterIP in namespace services-5645
STEP: Creating active service to test reachability when its FQDN is referred as externalName for another service
STEP: creating service externalsvc in namespace services-5645
STEP: creating replication controller externalsvc in namespace services-5645
I1220 10:35:16.779171      26 runners.go:184] Created replication controller with name: externalsvc, namespace: services-5645, replica count: 2
I1220 10:35:19.829655      26 runners.go:184] externalsvc Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
STEP: changing the ClusterIP service to type=ExternalName
Dec 20 10:35:19.847: INFO: Creating new exec pod
Dec 20 10:35:23.858: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=services-5645 execpodg7mgd -- /bin/sh -x -c nslookup clusterip-service'
Dec 20 10:35:24.072: INFO: stderr: "+ nslookup clusterip-service\n"
Dec 20 10:35:24.072: INFO: stdout: "Server:\t\t10.96.0.10\nAddress:\t10.96.0.10#53\n\nclusterip-service.services-5645.svc.cluster.local\tcanonical name = externalsvc.services-5645.svc.cluster.local.\nName:\texternalsvc.services-5645.svc.cluster.local\nAddress: 10.100.106.239\n\n"
STEP: deleting ReplicationController externalsvc in namespace services-5645, will wait for the garbage collector to delete the pods
Dec 20 10:35:24.134: INFO: Deleting ReplicationController externalsvc took: 8.506368ms
Dec 20 10:35:24.535: INFO: Terminating ReplicationController externalsvc pods took: 400.281595ms
Dec 20 10:35:35.352: INFO: Cleaning up the ClusterIP to ExternalName test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:35:35.361: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-5645" for this suite.
Dec 20 10:35:41.374: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:35:41.464: INFO: namespace services-5645 deletion completed in 6.098727366s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:24.838 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ClusterIP to ExternalName [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:35:41.464: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-3833
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 20 10:35:41.607: INFO: Waiting up to 5m0s for pod "pod-c1282a6a-c087-44c8-a7c6-90098531c1cc" in namespace "emptydir-3833" to be "success or failure"
Dec 20 10:35:41.610: INFO: Pod "pod-c1282a6a-c087-44c8-a7c6-90098531c1cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.779928ms
Dec 20 10:35:43.614: INFO: Pod "pod-c1282a6a-c087-44c8-a7c6-90098531c1cc": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006526909s
Dec 20 10:35:45.618: INFO: Pod "pod-c1282a6a-c087-44c8-a7c6-90098531c1cc": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010985047s
STEP: Saw pod success
Dec 20 10:35:45.619: INFO: Pod "pod-c1282a6a-c087-44c8-a7c6-90098531c1cc" satisfied condition "success or failure"
Dec 20 10:35:45.621: INFO: Trying to get logs from node caasp-worker-th-before-4 pod pod-c1282a6a-c087-44c8-a7c6-90098531c1cc container test-container: <nil>
STEP: delete the pod
Dec 20 10:35:45.636: INFO: Waiting for pod pod-c1282a6a-c087-44c8-a7c6-90098531c1cc to disappear
Dec 20 10:35:45.638: INFO: Pod pod-c1282a6a-c087-44c8-a7c6-90098531c1cc no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:35:45.638: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-3833" for this suite.
Dec 20 10:35:51.650: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:35:51.746: INFO: namespace emptydir-3833 deletion completed in 6.104516771s

• [SLOW TEST:10.281 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] KubeletManagedEtcHosts 
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:35:51.746: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename e2e-kubelet-etc-hosts
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in e2e-kubelet-etc-hosts-745
STEP: Waiting for a default service account to be provisioned in namespace
[It] should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting up the test
STEP: Creating hostNetwork=false pod
STEP: Creating hostNetwork=true pod
STEP: Running the test
STEP: Verifying /etc/hosts of container is kubelet-managed for pod with hostNetwork=false
Dec 20 10:35:57.906: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-745 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 10:35:57.906: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 10:35:57.972: INFO: Exec stderr: ""
Dec 20 10:35:57.972: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-745 PodName:test-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 10:35:57.972: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 10:35:58.034: INFO: Exec stderr: ""
Dec 20 10:35:58.034: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-745 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 10:35:58.034: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 10:35:58.099: INFO: Exec stderr: ""
Dec 20 10:35:58.099: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-745 PodName:test-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 10:35:58.099: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 10:35:58.164: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts of container is not kubelet-managed since container specifies /etc/hosts mount
Dec 20 10:35:58.164: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-745 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 10:35:58.164: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 10:35:58.231: INFO: Exec stderr: ""
Dec 20 10:35:58.231: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-745 PodName:test-pod ContainerName:busybox-3 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 10:35:58.231: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 10:35:58.296: INFO: Exec stderr: ""
STEP: Verifying /etc/hosts content of container is not kubelet-managed for pod with hostNetwork=true
Dec 20 10:35:58.296: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-745 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 10:35:58.296: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 10:35:58.356: INFO: Exec stderr: ""
Dec 20 10:35:58.356: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-745 PodName:test-host-network-pod ContainerName:busybox-1 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 10:35:58.356: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 10:35:58.424: INFO: Exec stderr: ""
Dec 20 10:35:58.424: INFO: ExecWithOptions {Command:[cat /etc/hosts] Namespace:e2e-kubelet-etc-hosts-745 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 10:35:58.424: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 10:35:58.488: INFO: Exec stderr: ""
Dec 20 10:35:58.488: INFO: ExecWithOptions {Command:[cat /etc/hosts-original] Namespace:e2e-kubelet-etc-hosts-745 PodName:test-host-network-pod ContainerName:busybox-2 Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 10:35:58.488: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 10:35:58.552: INFO: Exec stderr: ""
[AfterEach] [k8s.io] KubeletManagedEtcHosts
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:35:58.552: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "e2e-kubelet-etc-hosts-745" for this suite.
Dec 20 10:36:42.569: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:36:42.670: INFO: namespace e2e-kubelet-etc-hosts-745 deletion completed in 44.11394785s

• [SLOW TEST:50.924 seconds]
[k8s.io] KubeletManagedEtcHosts
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should test kubelet managed /etc/hosts file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:36:42.670: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4020
STEP: Waiting for a default service account to be provisioned in namespace
[It] optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name s-test-opt-del-5ca4fc8b-8f86-4f0c-815d-08dc5a56e6ee
STEP: Creating secret with name s-test-opt-upd-50c4a8d0-1037-4d9c-9c63-4bf649c1c970
STEP: Creating the pod
STEP: Deleting secret s-test-opt-del-5ca4fc8b-8f86-4f0c-815d-08dc5a56e6ee
STEP: Updating secret s-test-opt-upd-50c4a8d0-1037-4d9c-9c63-4bf649c1c970
STEP: Creating secret with name s-test-opt-create-7e8f973a-6e8d-4ab8-90a6-3d3766643c49
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:36:48.901: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4020" for this suite.
Dec 20 10:37:00.915: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:37:01.010: INFO: namespace projected-4020 deletion completed in 12.105070895s

• [SLOW TEST:18.339 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  optional updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] Aggregator 
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:37:01.010: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename aggregator
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in aggregator-1516
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:77
Dec 20 10:37:01.141: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
[It] Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the sample API server.
Dec 20 10:37:01.585: INFO: deployment "sample-apiserver-deployment" doesn't have the required revision set
Dec 20 10:37:03.621: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 10:37:05.626: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 10:37:07.626: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 10:37:09.625: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 10:37:11.625: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 10:37:13.626: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 10:37:15.626: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 10:37:17.625: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 10:37:19.625: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 10:37:21.625: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435022, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-apiserver-deployment-8447597c78\" is progressing."}}, CollisionCount:(*int32)(nil)}
Dec 20 10:37:24.662: INFO: Waited 1.029512227s for the sample-apiserver to be ready to handle requests.
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/aggregator.go:68
[AfterEach] [sig-api-machinery] Aggregator
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:37:25.142: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "aggregator-1516" for this suite.
Dec 20 10:37:31.296: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:37:31.395: INFO: namespace aggregator-1516 deletion completed in 6.20111701s

• [SLOW TEST:30.385 seconds]
[sig-api-machinery] Aggregator
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Should be able to support the 1.10 Sample API Server using the current Aggregator [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:37:31.395: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-7662
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Succeeded
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 20 10:37:34.550: INFO: Expected: &{} to match Container's Termination Message:  --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:37:34.560: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-7662" for this suite.
Dec 20 10:37:40.573: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:37:40.657: INFO: namespace container-runtime-7662 deletion completed in 6.09357527s

• [SLOW TEST:9.262 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:37:40.658: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-4728
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 20 10:37:40.785: INFO: PodSpec: initContainers in spec.initContainers
Dec 20 10:38:30.024: INFO: init container has failed twice: &v1.Pod{TypeMeta:v1.TypeMeta{Kind:"", APIVersion:""}, ObjectMeta:v1.ObjectMeta{Name:"pod-init-769d3a8a-79d6-48d8-9338-0a83aa001e4f", GenerateName:"", Namespace:"init-container-4728", SelfLink:"/api/v1/namespaces/init-container-4728/pods/pod-init-769d3a8a-79d6-48d8-9338-0a83aa001e4f", UID:"6416bab4-b672-4df5-95e2-ed9d880fe6ac", ResourceVersion:"132527", Generation:0, CreationTimestamp:v1.Time{Time:time.Time{wall:0x0, ext:63712435060, loc:(*time.Location)(0x84c02a0)}}, DeletionTimestamp:(*v1.Time)(nil), DeletionGracePeriodSeconds:(*int64)(nil), Labels:map[string]string{"name":"foo", "time":"785616037"}, Annotations:map[string]string{"kubernetes.io/psp":"e2e-test-privileged-psp"}, OwnerReferences:[]v1.OwnerReference(nil), Finalizers:[]string(nil), ClusterName:"", ManagedFields:[]v1.ManagedFieldsEntry(nil)}, Spec:v1.PodSpec{Volumes:[]v1.Volume{v1.Volume{Name:"default-token-c4xl2", VolumeSource:v1.VolumeSource{HostPath:(*v1.HostPathVolumeSource)(nil), EmptyDir:(*v1.EmptyDirVolumeSource)(nil), GCEPersistentDisk:(*v1.GCEPersistentDiskVolumeSource)(nil), AWSElasticBlockStore:(*v1.AWSElasticBlockStoreVolumeSource)(nil), GitRepo:(*v1.GitRepoVolumeSource)(nil), Secret:(*v1.SecretVolumeSource)(0xc006787480), NFS:(*v1.NFSVolumeSource)(nil), ISCSI:(*v1.ISCSIVolumeSource)(nil), Glusterfs:(*v1.GlusterfsVolumeSource)(nil), PersistentVolumeClaim:(*v1.PersistentVolumeClaimVolumeSource)(nil), RBD:(*v1.RBDVolumeSource)(nil), FlexVolume:(*v1.FlexVolumeSource)(nil), Cinder:(*v1.CinderVolumeSource)(nil), CephFS:(*v1.CephFSVolumeSource)(nil), Flocker:(*v1.FlockerVolumeSource)(nil), DownwardAPI:(*v1.DownwardAPIVolumeSource)(nil), FC:(*v1.FCVolumeSource)(nil), AzureFile:(*v1.AzureFileVolumeSource)(nil), ConfigMap:(*v1.ConfigMapVolumeSource)(nil), VsphereVolume:(*v1.VsphereVirtualDiskVolumeSource)(nil), Quobyte:(*v1.QuobyteVolumeSource)(nil), AzureDisk:(*v1.AzureDiskVolumeSource)(nil), PhotonPersistentDisk:(*v1.PhotonPersistentDiskVolumeSource)(nil), Projected:(*v1.ProjectedVolumeSource)(nil), PortworxVolume:(*v1.PortworxVolumeSource)(nil), ScaleIO:(*v1.ScaleIOVolumeSource)(nil), StorageOS:(*v1.StorageOSVolumeSource)(nil), CSI:(*v1.CSIVolumeSource)(nil)}}}, InitContainers:[]v1.Container{v1.Container{Name:"init1", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/false"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-c4xl2", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}, v1.Container{Name:"init2", Image:"docker.io/library/busybox:1.29", Command:[]string{"/bin/true"}, Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList(nil), Requests:v1.ResourceList(nil)}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-c4xl2", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, Containers:[]v1.Container{v1.Container{Name:"run1", Image:"k8s.gcr.io/pause:3.1", Command:[]string(nil), Args:[]string(nil), WorkingDir:"", Ports:[]v1.ContainerPort(nil), EnvFrom:[]v1.EnvFromSource(nil), Env:[]v1.EnvVar(nil), Resources:v1.ResourceRequirements{Limits:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}, Requests:v1.ResourceList{"cpu":resource.Quantity{i:resource.int64Amount{value:100, scale:-3}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"100m", Format:"DecimalSI"}, "memory":resource.Quantity{i:resource.int64Amount{value:52428800, scale:0}, d:resource.infDecAmount{Dec:(*inf.Dec)(nil)}, s:"52428800", Format:"DecimalSI"}}}, VolumeMounts:[]v1.VolumeMount{v1.VolumeMount{Name:"default-token-c4xl2", ReadOnly:true, MountPath:"/var/run/secrets/kubernetes.io/serviceaccount", SubPath:"", MountPropagation:(*v1.MountPropagationMode)(nil), SubPathExpr:""}}, VolumeDevices:[]v1.VolumeDevice(nil), LivenessProbe:(*v1.Probe)(nil), ReadinessProbe:(*v1.Probe)(nil), StartupProbe:(*v1.Probe)(nil), Lifecycle:(*v1.Lifecycle)(nil), TerminationMessagePath:"/dev/termination-log", TerminationMessagePolicy:"File", ImagePullPolicy:"IfNotPresent", SecurityContext:(*v1.SecurityContext)(nil), Stdin:false, StdinOnce:false, TTY:false}}, EphemeralContainers:[]v1.EphemeralContainer(nil), RestartPolicy:"Always", TerminationGracePeriodSeconds:(*int64)(0xc00498d7e8), ActiveDeadlineSeconds:(*int64)(nil), DNSPolicy:"ClusterFirst", NodeSelector:map[string]string(nil), ServiceAccountName:"default", DeprecatedServiceAccount:"default", AutomountServiceAccountToken:(*bool)(nil), NodeName:"caasp-worker-th-before-3", HostNetwork:false, HostPID:false, HostIPC:false, ShareProcessNamespace:(*bool)(nil), SecurityContext:(*v1.PodSecurityContext)(0xc004688a20), ImagePullSecrets:[]v1.LocalObjectReference(nil), Hostname:"", Subdomain:"", Affinity:(*v1.Affinity)(nil), SchedulerName:"default-scheduler", Tolerations:[]v1.Toleration{v1.Toleration{Key:"node.kubernetes.io/not-ready", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00498d860)}, v1.Toleration{Key:"node.kubernetes.io/unreachable", Operator:"Exists", Value:"", Effect:"NoExecute", TolerationSeconds:(*int64)(0xc00498d880)}}, HostAliases:[]v1.HostAlias(nil), PriorityClassName:"", Priority:(*int32)(0xc00498d888), DNSConfig:(*v1.PodDNSConfig)(nil), ReadinessGates:[]v1.PodReadinessGate(nil), RuntimeClassName:(*string)(nil), EnableServiceLinks:(*bool)(0xc00498d88c), PreemptionPolicy:(*v1.PreemptionPolicy)(nil), Overhead:v1.ResourceList(nil), TopologySpreadConstraints:[]v1.TopologySpreadConstraint(nil)}, Status:v1.PodStatus{Phase:"Pending", Conditions:[]v1.PodCondition{v1.PodCondition{Type:"Initialized", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435061, loc:(*time.Location)(0x84c02a0)}}, Reason:"ContainersNotInitialized", Message:"containers with incomplete status: [init1 init2]"}, v1.PodCondition{Type:"Ready", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435061, loc:(*time.Location)(0x84c02a0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"ContainersReady", Status:"False", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435061, loc:(*time.Location)(0x84c02a0)}}, Reason:"ContainersNotReady", Message:"containers with unready status: [run1]"}, v1.PodCondition{Type:"PodScheduled", Status:"True", LastProbeTime:v1.Time{Time:time.Time{wall:0x0, ext:0, loc:(*time.Location)(nil)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435060, loc:(*time.Location)(0x84c02a0)}}, Reason:"", Message:""}}, Message:"", Reason:"", NominatedNodeName:"", HostIP:"10.84.149.226", PodIP:"10.244.6.230", PodIPs:[]v1.PodIP{v1.PodIP{IP:"10.244.6.230"}}, StartTime:(*v1.Time)(0xc00248c7a0), InitContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"init1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc003216460)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(0xc0032164d0)}, Ready:false, RestartCount:3, Image:"docker.io/library/busybox:1.29", ImageID:"docker.io/library/busybox@sha256:8ccbac733d19c0dd4d70b4f0c1e12245b5fa3ad24758a11035ee505c629c0796", ContainerID:"cri-o://77e426d1bc9cf2d4b3f988ff3e41a4cb2124306cda2395b014078ec0b2599db4", Started:(*bool)(nil)}, v1.ContainerStatus{Name:"init2", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00248c820), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"docker.io/library/busybox:1.29", ImageID:"", ContainerID:"", Started:(*bool)(nil)}}, ContainerStatuses:[]v1.ContainerStatus{v1.ContainerStatus{Name:"run1", State:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(0xc00248c7c0), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, LastTerminationState:v1.ContainerState{Waiting:(*v1.ContainerStateWaiting)(nil), Running:(*v1.ContainerStateRunning)(nil), Terminated:(*v1.ContainerStateTerminated)(nil)}, Ready:false, RestartCount:0, Image:"k8s.gcr.io/pause:3.1", ImageID:"", ContainerID:"", Started:(*bool)(0xc00498d90f)}}, QOSClass:"Burstable", EphemeralContainerStatuses:[]v1.ContainerStatus(nil)}}
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:38:30.025: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-4728" for this suite.
Dec 20 10:38:52.039: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:38:52.127: INFO: namespace init-container-4728 deletion completed in 22.0978735s

• [SLOW TEST:71.469 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers if init containers fail on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Security Context When creating a pod with privileged 
  should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:38:52.128: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename security-context-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in security-context-test-8651
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:40
[It] should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 10:38:52.265: INFO: Waiting up to 5m0s for pod "busybox-privileged-false-3ae09ba1-c9bd-42e2-a8e4-6b80b08b311d" in namespace "security-context-test-8651" to be "success or failure"
Dec 20 10:38:52.268: INFO: Pod "busybox-privileged-false-3ae09ba1-c9bd-42e2-a8e4-6b80b08b311d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.439325ms
Dec 20 10:38:54.271: INFO: Pod "busybox-privileged-false-3ae09ba1-c9bd-42e2-a8e4-6b80b08b311d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006001728s
Dec 20 10:38:56.276: INFO: Pod "busybox-privileged-false-3ae09ba1-c9bd-42e2-a8e4-6b80b08b311d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010716395s
Dec 20 10:38:56.276: INFO: Pod "busybox-privileged-false-3ae09ba1-c9bd-42e2-a8e4-6b80b08b311d" satisfied condition "success or failure"
Dec 20 10:38:56.294: INFO: Got logs for pod "busybox-privileged-false-3ae09ba1-c9bd-42e2-a8e4-6b80b08b311d": "ip: RTNETLINK answers: Operation not permitted\n"
[AfterEach] [k8s.io] Security Context
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:38:56.294: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "security-context-test-8651" for this suite.
Dec 20 10:39:02.310: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:39:02.411: INFO: namespace security-context-test-8651 deletion completed in 6.113061999s

• [SLOW TEST:10.284 seconds]
[k8s.io] Security Context
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  When creating a pod with privileged
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/security_context.go:226
    should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl api-versions 
  should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:39:02.412: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-9931
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[It] should check if v1 is in available api versions  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: validating api versions
Dec 20 10:39:02.545: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 api-versions'
Dec 20 10:39:02.631: INFO: stderr: ""
Dec 20 10:39:02.631: INFO: stdout: "admissionregistration.k8s.io/v1\nadmissionregistration.k8s.io/v1beta1\napiextensions.k8s.io/v1\napiextensions.k8s.io/v1beta1\napiregistration.k8s.io/v1\napiregistration.k8s.io/v1beta1\napps/v1\nauthentication.k8s.io/v1\nauthentication.k8s.io/v1beta1\nauthorization.k8s.io/v1\nauthorization.k8s.io/v1beta1\nautoscaling/v1\nautoscaling/v2beta1\nautoscaling/v2beta2\nbatch/v1\nbatch/v1beta1\ncertificates.k8s.io/v1beta1\ncilium.io/v2\ncoordination.k8s.io/v1\ncoordination.k8s.io/v1beta1\ndex.coreos.com/v1\nevents.k8s.io/v1beta1\nextensions/v1beta1\nnetworking.k8s.io/v1\nnetworking.k8s.io/v1beta1\nnode.k8s.io/v1beta1\npolicy/v1beta1\nrbac.authorization.k8s.io/v1\nrbac.authorization.k8s.io/v1beta1\nscheduling.k8s.io/v1\nscheduling.k8s.io/v1beta1\nstorage.k8s.io/v1\nstorage.k8s.io/v1beta1\nv1\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:39:02.631: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-9931" for this suite.
Dec 20 10:39:08.647: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:39:08.751: INFO: namespace kubectl-9931 deletion completed in 6.114264878s

• [SLOW TEST:6.339 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl api-versions
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:738
    should check if v1 is in available api versions  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-scheduling] SchedulerPredicates [Serial] 
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:39:08.751: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename sched-pred
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in sched-pred-5779
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:87
Dec 20 10:39:08.884: INFO: Waiting up to 1m0s for all (but 0) nodes to be ready
Dec 20 10:39:08.897: INFO: Waiting for terminating namespaces to be deleted...
Dec 20 10:39:08.899: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-th-before-0 before test
Dec 20 10:39:08.916: INFO: kured-cvqgx from kube-system started at 2019-12-19 23:02:27 +0000 UTC (1 container statuses recorded)
Dec 20 10:39:08.916: INFO: 	Container kured ready: true, restart count 1
Dec 20 10:39:08.916: INFO: cilium-srq5l from kube-system started at 2019-12-19 23:00:47 +0000 UTC (1 container statuses recorded)
Dec 20 10:39:08.916: INFO: 	Container cilium-agent ready: true, restart count 1
Dec 20 10:39:08.916: INFO: kube-proxy-m8mx6 from kube-system started at 2019-12-19 23:00:47 +0000 UTC (1 container statuses recorded)
Dec 20 10:39:08.916: INFO: 	Container kube-proxy ready: true, restart count 1
Dec 20 10:39:08.916: INFO: sonobuoy from sonobuoy started at 2019-12-20 09:06:03 +0000 UTC (1 container statuses recorded)
Dec 20 10:39:08.916: INFO: 	Container kube-sonobuoy ready: true, restart count 0
Dec 20 10:39:08.916: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-th-before-3 before test
Dec 20 10:39:08.934: INFO: cilium-sm7nn from kube-system started at 2019-12-19 23:00:46 +0000 UTC (1 container statuses recorded)
Dec 20 10:39:08.934: INFO: 	Container cilium-agent ready: true, restart count 4
Dec 20 10:39:08.934: INFO: oidc-dex-799996b768-8xqtt from kube-system started at 2019-12-19 23:24:29 +0000 UTC (1 container statuses recorded)
Dec 20 10:39:08.934: INFO: 	Container oidc-dex ready: true, restart count 0
Dec 20 10:39:08.934: INFO: kured-ddrtt from kube-system started at 2019-12-19 23:01:46 +0000 UTC (1 container statuses recorded)
Dec 20 10:39:08.934: INFO: 	Container kured ready: true, restart count 0
Dec 20 10:39:08.934: INFO: tiller-deploy-6b954db788-gjd4h from kube-system started at 2019-12-19 23:05:50 +0000 UTC (1 container statuses recorded)
Dec 20 10:39:08.934: INFO: 	Container tiller ready: true, restart count 7
Dec 20 10:39:08.934: INFO: kube-proxy-frbl9 from kube-system started at 2019-12-19 23:00:46 +0000 UTC (1 container statuses recorded)
Dec 20 10:39:08.934: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 20 10:39:08.934: INFO: 
Logging pods the kubelet thinks is on node caasp-worker-th-before-4 before test
Dec 20 10:39:08.940: INFO: cilium-nllss from kube-system started at 2019-12-19 23:00:46 +0000 UTC (1 container statuses recorded)
Dec 20 10:39:08.940: INFO: 	Container cilium-agent ready: true, restart count 4
Dec 20 10:39:08.940: INFO: kube-proxy-qcm45 from kube-system started at 2019-12-19 23:00:46 +0000 UTC (1 container statuses recorded)
Dec 20 10:39:08.940: INFO: 	Container kube-proxy ready: true, restart count 0
Dec 20 10:39:08.940: INFO: oidc-dex-799996b768-4r6tn from kube-system started at 2019-12-19 23:24:29 +0000 UTC (1 container statuses recorded)
Dec 20 10:39:08.940: INFO: 	Container oidc-dex ready: true, restart count 0
Dec 20 10:39:08.940: INFO: kured-zktcs from kube-system started at 2019-12-19 23:01:56 +0000 UTC (1 container statuses recorded)
Dec 20 10:39:08.940: INFO: 	Container kured ready: true, restart count 0
[It] validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Trying to schedule Pod with nonempty NodeSelector.
STEP: Considering event: 
Type = [Warning], Name = [restricted-pod.15e20e1ffcddc929], Reason = [FailedScheduling], Message = [0/5 nodes are available: 5 node(s) didn't match node selector.]
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:39:09.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "sched-pred-5779" for this suite.
Dec 20 10:39:15.981: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:39:16.067: INFO: namespace sched-pred-5779 deletion completed in 6.10037827s
[AfterEach] [sig-scheduling] SchedulerPredicates [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/predicates.go:78

• [SLOW TEST:7.316 seconds]
[sig-scheduling] SchedulerPredicates [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/scheduling/framework.go:23
  validates that NodeSelector is respected if not matching  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:39:16.068: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-1091
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec 20 10:39:17.117: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Dec 20 10:39:19.127: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435158, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435158, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435158, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435158, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 20 10:39:22.142: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 10:39:22.146: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Creating a v1 custom resource
STEP: Create a v2 custom resource
STEP: List CRs in v1
STEP: List CRs in v2
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:39:23.360: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-1091" for this suite.
Dec 20 10:39:29.375: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:39:29.472: INFO: namespace crd-webhook-1091 deletion completed in 6.10805322s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:13.419 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert a non homogeneous list of CRs [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Secrets 
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:39:29.487: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-6768
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-map-d15dd8a8-dead-4b7f-8e9a-52a4a3de9c72
STEP: Creating a pod to test consume secrets
Dec 20 10:39:29.632: INFO: Waiting up to 5m0s for pod "pod-secrets-6aac797e-4a1c-4cd8-b137-b2cf9d506a08" in namespace "secrets-6768" to be "success or failure"
Dec 20 10:39:29.634: INFO: Pod "pod-secrets-6aac797e-4a1c-4cd8-b137-b2cf9d506a08": Phase="Pending", Reason="", readiness=false. Elapsed: 2.472799ms
Dec 20 10:39:31.638: INFO: Pod "pod-secrets-6aac797e-4a1c-4cd8-b137-b2cf9d506a08": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006169079s
Dec 20 10:39:33.642: INFO: Pod "pod-secrets-6aac797e-4a1c-4cd8-b137-b2cf9d506a08": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010343921s
STEP: Saw pod success
Dec 20 10:39:33.642: INFO: Pod "pod-secrets-6aac797e-4a1c-4cd8-b137-b2cf9d506a08" satisfied condition "success or failure"
Dec 20 10:39:33.645: INFO: Trying to get logs from node caasp-worker-th-before-0 pod pod-secrets-6aac797e-4a1c-4cd8-b137-b2cf9d506a08 container secret-volume-test: <nil>
STEP: delete the pod
Dec 20 10:39:33.659: INFO: Waiting for pod pod-secrets-6aac797e-4a1c-4cd8-b137-b2cf9d506a08 to disappear
Dec 20 10:39:33.662: INFO: Pod pod-secrets-6aac797e-4a1c-4cd8-b137-b2cf9d506a08 no longer exists
[AfterEach] [sig-storage] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:39:33.662: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-6768" for this suite.
Dec 20 10:39:39.675: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:39:39.765: INFO: namespace secrets-6768 deletion completed in 6.100281726s

• [SLOW TEST:10.278 seconds]
[sig-storage] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets_volume.go:35
  should be consumable from pods in volume with mappings [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-storage] Projected downwardAPI 
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:39:39.766: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-9874
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 20 10:39:39.902: INFO: Waiting up to 5m0s for pod "downwardapi-volume-e8588afc-d03e-42ad-880c-fb1453827f61" in namespace "projected-9874" to be "success or failure"
Dec 20 10:39:39.904: INFO: Pod "downwardapi-volume-e8588afc-d03e-42ad-880c-fb1453827f61": Phase="Pending", Reason="", readiness=false. Elapsed: 2.470847ms
Dec 20 10:39:41.907: INFO: Pod "downwardapi-volume-e8588afc-d03e-42ad-880c-fb1453827f61": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005594013s
Dec 20 10:39:43.911: INFO: Pod "downwardapi-volume-e8588afc-d03e-42ad-880c-fb1453827f61": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008929728s
STEP: Saw pod success
Dec 20 10:39:43.911: INFO: Pod "downwardapi-volume-e8588afc-d03e-42ad-880c-fb1453827f61" satisfied condition "success or failure"
Dec 20 10:39:43.913: INFO: Trying to get logs from node caasp-worker-th-before-4 pod downwardapi-volume-e8588afc-d03e-42ad-880c-fb1453827f61 container client-container: <nil>
STEP: delete the pod
Dec 20 10:39:43.926: INFO: Waiting for pod downwardapi-volume-e8588afc-d03e-42ad-880c-fb1453827f61 to disappear
Dec 20 10:39:43.928: INFO: Pod downwardapi-volume-e8588afc-d03e-42ad-880c-fb1453827f61 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:39:43.928: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-9874" for this suite.
Dec 20 10:39:49.941: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:39:50.032: INFO: namespace projected-9874 deletion completed in 6.099685722s

• [SLOW TEST:10.266 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:39:50.032: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-7178
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test override arguments
Dec 20 10:39:50.167: INFO: Waiting up to 5m0s for pod "client-containers-326c0589-551a-4df0-b34e-5289c7a08522" in namespace "containers-7178" to be "success or failure"
Dec 20 10:39:50.170: INFO: Pod "client-containers-326c0589-551a-4df0-b34e-5289c7a08522": Phase="Pending", Reason="", readiness=false. Elapsed: 2.173643ms
Dec 20 10:39:52.172: INFO: Pod "client-containers-326c0589-551a-4df0-b34e-5289c7a08522": Phase="Running", Reason="", readiness=true. Elapsed: 2.004976468s
Dec 20 10:39:54.176: INFO: Pod "client-containers-326c0589-551a-4df0-b34e-5289c7a08522": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008870381s
STEP: Saw pod success
Dec 20 10:39:54.176: INFO: Pod "client-containers-326c0589-551a-4df0-b34e-5289c7a08522" satisfied condition "success or failure"
Dec 20 10:39:54.179: INFO: Trying to get logs from node caasp-worker-th-before-3 pod client-containers-326c0589-551a-4df0-b34e-5289c7a08522 container test-container: <nil>
STEP: delete the pod
Dec 20 10:39:54.194: INFO: Waiting for pod client-containers-326c0589-551a-4df0-b34e-5289c7a08522 to disappear
Dec 20 10:39:54.196: INFO: Pod client-containers-326c0589-551a-4df0-b34e-5289c7a08522 no longer exists
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:39:54.196: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-7178" for this suite.
Dec 20 10:40:00.212: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:40:00.306: INFO: namespace containers-7178 deletion completed in 6.105981974s

• [SLOW TEST:10.274 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be able to override the image's default arguments (docker cmd) [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:40:00.306: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-181
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 20 10:40:00.445: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9df51156-683a-4cef-8080-9b37457121b7" in namespace "downward-api-181" to be "success or failure"
Dec 20 10:40:00.448: INFO: Pod "downwardapi-volume-9df51156-683a-4cef-8080-9b37457121b7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.44508ms
Dec 20 10:40:02.452: INFO: Pod "downwardapi-volume-9df51156-683a-4cef-8080-9b37457121b7": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006948654s
Dec 20 10:40:04.457: INFO: Pod "downwardapi-volume-9df51156-683a-4cef-8080-9b37457121b7": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011378946s
STEP: Saw pod success
Dec 20 10:40:04.457: INFO: Pod "downwardapi-volume-9df51156-683a-4cef-8080-9b37457121b7" satisfied condition "success or failure"
Dec 20 10:40:04.460: INFO: Trying to get logs from node caasp-worker-th-before-3 pod downwardapi-volume-9df51156-683a-4cef-8080-9b37457121b7 container client-container: <nil>
STEP: delete the pod
Dec 20 10:40:04.476: INFO: Waiting for pod downwardapi-volume-9df51156-683a-4cef-8080-9b37457121b7 to disappear
Dec 20 10:40:04.479: INFO: Pod downwardapi-volume-9df51156-683a-4cef-8080-9b37457121b7 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:40:04.479: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-181" for this suite.
Dec 20 10:40:10.494: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:40:10.583: INFO: namespace downward-api-181 deletion completed in 6.100050429s

• [SLOW TEST:10.276 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-storage] Downward API volume 
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:40:10.583: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-1292
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating the pod
Dec 20 10:40:15.252: INFO: Successfully updated pod "annotationupdate6cbe1421-d9b6-4ab8-83ab-3597faffc139"
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:40:17.265: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-1292" for this suite.
Dec 20 10:40:29.279: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:40:29.378: INFO: namespace downward-api-1292 deletion completed in 12.109009372s

• [SLOW TEST:18.795 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should update annotations on modification [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:40:29.378: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-6867
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on node default medium
Dec 20 10:40:29.517: INFO: Waiting up to 5m0s for pod "pod-4bad044b-3dfb-4b72-a9b5-1de925b6f1c9" in namespace "emptydir-6867" to be "success or failure"
Dec 20 10:40:29.520: INFO: Pod "pod-4bad044b-3dfb-4b72-a9b5-1de925b6f1c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.84283ms
Dec 20 10:40:31.524: INFO: Pod "pod-4bad044b-3dfb-4b72-a9b5-1de925b6f1c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006878343s
Dec 20 10:40:33.528: INFO: Pod "pod-4bad044b-3dfb-4b72-a9b5-1de925b6f1c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011256899s
STEP: Saw pod success
Dec 20 10:40:33.528: INFO: Pod "pod-4bad044b-3dfb-4b72-a9b5-1de925b6f1c9" satisfied condition "success or failure"
Dec 20 10:40:33.531: INFO: Trying to get logs from node caasp-worker-th-before-0 pod pod-4bad044b-3dfb-4b72-a9b5-1de925b6f1c9 container test-container: <nil>
STEP: delete the pod
Dec 20 10:40:33.547: INFO: Waiting for pod pod-4bad044b-3dfb-4b72-a9b5-1de925b6f1c9 to disappear
Dec 20 10:40:33.549: INFO: Pod pod-4bad044b-3dfb-4b72-a9b5-1de925b6f1c9 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:40:33.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-6867" for this suite.
Dec 20 10:40:39.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:40:39.656: INFO: namespace emptydir-6867 deletion completed in 6.103589636s

• [SLOW TEST:10.278 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test on terminated container 
  should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:40:39.657: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-9500
STEP: Waiting for a default service account to be provisioned in namespace
[It] should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the container
STEP: wait for the container to reach Failed
STEP: get the container status
STEP: the container should be terminated
STEP: the termination message should be set
Dec 20 10:40:42.837: INFO: Expected: &{DONE} to match Container's Termination Message: DONE --
STEP: delete the container
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:40:42.849: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-9500" for this suite.
Dec 20 10:40:48.863: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:40:48.951: INFO: namespace container-runtime-9500 deletion completed in 6.098617709s

• [SLOW TEST:9.295 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    on terminated container
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:132
      should report termination message [LinuxOnly] from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:40:48.952: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-8712
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 20 10:40:49.086: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:40:53.303: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-8712" for this suite.
Dec 20 10:40:59.318: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:40:59.406: INFO: namespace init-container-8712 deletion completed in 6.099269227s

• [SLOW TEST:10.455 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-node] ConfigMap 
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:40:59.407: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4923
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap configmap-4923/configmap-test-4456de7d-27cb-40f9-b115-29b40c1a0128
STEP: Creating a pod to test consume configMaps
Dec 20 10:40:59.546: INFO: Waiting up to 5m0s for pod "pod-configmaps-2dfc323b-e396-4486-82d5-9e00c0578911" in namespace "configmap-4923" to be "success or failure"
Dec 20 10:40:59.549: INFO: Pod "pod-configmaps-2dfc323b-e396-4486-82d5-9e00c0578911": Phase="Pending", Reason="", readiness=false. Elapsed: 2.438713ms
Dec 20 10:41:01.552: INFO: Pod "pod-configmaps-2dfc323b-e396-4486-82d5-9e00c0578911": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006161847s
Dec 20 10:41:03.556: INFO: Pod "pod-configmaps-2dfc323b-e396-4486-82d5-9e00c0578911": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009975963s
STEP: Saw pod success
Dec 20 10:41:03.556: INFO: Pod "pod-configmaps-2dfc323b-e396-4486-82d5-9e00c0578911" satisfied condition "success or failure"
Dec 20 10:41:03.559: INFO: Trying to get logs from node caasp-worker-th-before-0 pod pod-configmaps-2dfc323b-e396-4486-82d5-9e00c0578911 container env-test: <nil>
STEP: delete the pod
Dec 20 10:41:03.576: INFO: Waiting for pod pod-configmaps-2dfc323b-e396-4486-82d5-9e00c0578911 to disappear
Dec 20 10:41:03.580: INFO: Pod pod-configmaps-2dfc323b-e396-4486-82d5-9e00c0578911 no longer exists
[AfterEach] [sig-node] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:41:03.580: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4923" for this suite.
Dec 20 10:41:09.597: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:41:09.689: INFO: namespace configmap-4923 deletion completed in 6.105027939s

• [SLOW TEST:10.282 seconds]
[sig-node] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap.go:32
  should be consumable via environment variable [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] HostPath 
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:41:09.689: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename hostpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in hostpath-2282
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] HostPath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:37
[It] should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test hostPath mode
Dec 20 10:41:09.832: INFO: Waiting up to 5m0s for pod "pod-host-path-test" in namespace "hostpath-2282" to be "success or failure"
Dec 20 10:41:09.835: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.578066ms
Dec 20 10:41:11.838: INFO: Pod "pod-host-path-test": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006340365s
Dec 20 10:41:13.843: INFO: Pod "pod-host-path-test": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.011315929s
STEP: Saw pod success
Dec 20 10:41:13.843: INFO: Pod "pod-host-path-test" satisfied condition "success or failure"
Dec 20 10:41:13.847: INFO: Trying to get logs from node caasp-worker-th-before-4 pod pod-host-path-test container test-container-1: <nil>
STEP: delete the pod
Dec 20 10:41:13.865: INFO: Waiting for pod pod-host-path-test to disappear
Dec 20 10:41:13.867: INFO: Pod pod-host-path-test no longer exists
[AfterEach] [sig-storage] HostPath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:41:13.867: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "hostpath-2282" for this suite.
Dec 20 10:41:19.881: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:41:19.976: INFO: namespace hostpath-2282 deletion completed in 6.105923892s

• [SLOW TEST:10.287 seconds]
[sig-storage] HostPath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/host_path.go:34
  should give a volume the correct mode [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:41:19.976: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-557
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-upd-3fe1e339-a46d-4638-80aa-2d6d120bc130
STEP: Creating the pod
STEP: Updating configmap configmap-test-upd-3fe1e339-a46d-4638-80aa-2d6d120bc130
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:42:48.493: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-557" for this suite.
Dec 20 10:43:16.507: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:43:16.596: INFO: namespace configmap-557 deletion completed in 28.099278069s

• [SLOW TEST:116.620 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:43:16.596: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-425
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 20 10:43:17.431: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 20 10:43:19.441: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435398, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435398, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435398, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435398, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 20 10:43:22.456: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should mutate custom resource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 10:43:22.460: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Registering the mutating webhook for custom resource e2e-test-webhook-4552-crds.webhook.example.com via the AdmissionRegistration API
STEP: Creating a custom resource that should be mutated by the webhook
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:43:23.553: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-425" for this suite.
Dec 20 10:43:29.568: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:43:29.668: INFO: namespace webhook-425 deletion completed in 6.111071222s
STEP: Destroying namespace "webhook-425-markers" for this suite.
Dec 20 10:43:35.683: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:43:35.775: INFO: namespace webhook-425-markers deletion completed in 6.107471502s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:19.191 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should mutate custom resource [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:43:35.787: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-5722
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-9afcd8e7-a046-4b16-a592-72e1b777e204
STEP: Creating a pod to test consume configMaps
Dec 20 10:43:35.927: INFO: Waiting up to 5m0s for pod "pod-configmaps-59c5da22-5b3f-4eb7-8f58-0b3794c78143" in namespace "configmap-5722" to be "success or failure"
Dec 20 10:43:35.929: INFO: Pod "pod-configmaps-59c5da22-5b3f-4eb7-8f58-0b3794c78143": Phase="Pending", Reason="", readiness=false. Elapsed: 2.290042ms
Dec 20 10:43:37.933: INFO: Pod "pod-configmaps-59c5da22-5b3f-4eb7-8f58-0b3794c78143": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005620307s
Dec 20 10:43:39.936: INFO: Pod "pod-configmaps-59c5da22-5b3f-4eb7-8f58-0b3794c78143": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009087339s
STEP: Saw pod success
Dec 20 10:43:39.936: INFO: Pod "pod-configmaps-59c5da22-5b3f-4eb7-8f58-0b3794c78143" satisfied condition "success or failure"
Dec 20 10:43:39.939: INFO: Trying to get logs from node caasp-worker-th-before-3 pod pod-configmaps-59c5da22-5b3f-4eb7-8f58-0b3794c78143 container configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 10:43:39.965: INFO: Waiting for pod pod-configmaps-59c5da22-5b3f-4eb7-8f58-0b3794c78143 to disappear
Dec 20 10:43:39.969: INFO: Pod pod-configmaps-59c5da22-5b3f-4eb7-8f58-0b3794c78143 no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:43:39.969: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-5722" for this suite.
Dec 20 10:43:45.986: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:43:46.088: INFO: namespace configmap-5722 deletion completed in 6.112503337s

• [SLOW TEST:10.301 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSS
------------------------------
[k8s.io] InitContainer [NodeConformance] 
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:43:46.088: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename init-container
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in init-container-9539
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/init_container.go:44
[It] should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
Dec 20 10:43:46.247: INFO: PodSpec: initContainers in spec.initContainers
[AfterEach] [k8s.io] InitContainer [NodeConformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:43:51.159: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "init-container-9539" for this suite.
Dec 20 10:44:03.174: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:44:03.271: INFO: namespace init-container-9539 deletion completed in 12.107528723s

• [SLOW TEST:17.183 seconds]
[k8s.io] InitContainer [NodeConformance]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should invoke init containers on a RestartAlways pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:44:03.272: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-653
STEP: Waiting for a default service account to be provisioned in namespace
[It] works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 10:44:03.404: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: client-side validation (kubectl create and apply) allows request with any unknown properties
Dec 20 10:44:07.748: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 --namespace=crd-publish-openapi-653 create -f -'
Dec 20 10:44:08.059: INFO: stderr: ""
Dec 20 10:44:08.059: INFO: stdout: "e2e-test-crd-publish-openapi-6056-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 20 10:44:08.059: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 --namespace=crd-publish-openapi-653 delete e2e-test-crd-publish-openapi-6056-crds test-cr'
Dec 20 10:44:08.165: INFO: stderr: ""
Dec 20 10:44:08.165: INFO: stdout: "e2e-test-crd-publish-openapi-6056-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
Dec 20 10:44:08.165: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 --namespace=crd-publish-openapi-653 apply -f -'
Dec 20 10:44:08.331: INFO: stderr: ""
Dec 20 10:44:08.331: INFO: stdout: "e2e-test-crd-publish-openapi-6056-crd.crd-publish-openapi-test-unknown-in-nested.example.com/test-cr created\n"
Dec 20 10:44:08.332: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 --namespace=crd-publish-openapi-653 delete e2e-test-crd-publish-openapi-6056-crds test-cr'
Dec 20 10:44:08.477: INFO: stderr: ""
Dec 20 10:44:08.477: INFO: stdout: "e2e-test-crd-publish-openapi-6056-crd.crd-publish-openapi-test-unknown-in-nested.example.com \"test-cr\" deleted\n"
STEP: kubectl explain works to explain CR
Dec 20 10:44:08.477: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 explain e2e-test-crd-publish-openapi-6056-crds'
Dec 20 10:44:08.709: INFO: stderr: ""
Dec 20 10:44:08.709: INFO: stdout: "KIND:     E2e-test-crd-publish-openapi-6056-crd\nVERSION:  crd-publish-openapi-test-unknown-in-nested.example.com/v1\n\nDESCRIPTION:\n     preserve-unknown-properties in nested field for Testing\n\nFIELDS:\n   apiVersion\t<string>\n     APIVersion defines the versioned schema of this representation of an\n     object. Servers should convert recognized schemas to the latest internal\n     value, and may reject unrecognized values. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#resources\n\n   kind\t<string>\n     Kind is a string value representing the REST resource this object\n     represents. Servers may infer this from the endpoint the client submits\n     requests to. Cannot be updated. In CamelCase. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#types-kinds\n\n   metadata\t<Object>\n     Standard object's metadata. More info:\n     https://git.k8s.io/community/contributors/devel/sig-architecture/api-conventions.md#metadata\n\n   spec\t<map[string]>\n     Specification of Waldo\n\n   status\t<Object>\n     Status of Waldo\n\n"
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:44:13.594: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-653" for this suite.
Dec 20 10:44:19.611: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:44:19.703: INFO: namespace crd-publish-openapi-653 deletion completed in 6.103624076s

• [SLOW TEST:16.431 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  works for CRD preserving unknown fields in an embedded object [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Downward API volume 
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:44:19.703: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename downward-api
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in downward-api-7582
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:40
[It] should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 20 10:44:19.846: INFO: Waiting up to 5m0s for pod "downwardapi-volume-b87db21b-b966-491d-b0cd-d728dbce0432" in namespace "downward-api-7582" to be "success or failure"
Dec 20 10:44:19.851: INFO: Pod "downwardapi-volume-b87db21b-b966-491d-b0cd-d728dbce0432": Phase="Pending", Reason="", readiness=false. Elapsed: 5.474057ms
Dec 20 10:44:21.855: INFO: Pod "downwardapi-volume-b87db21b-b966-491d-b0cd-d728dbce0432": Phase="Pending", Reason="", readiness=false. Elapsed: 2.009355547s
Dec 20 10:44:23.859: INFO: Pod "downwardapi-volume-b87db21b-b966-491d-b0cd-d728dbce0432": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.013106708s
STEP: Saw pod success
Dec 20 10:44:23.859: INFO: Pod "downwardapi-volume-b87db21b-b966-491d-b0cd-d728dbce0432" satisfied condition "success or failure"
Dec 20 10:44:23.862: INFO: Trying to get logs from node caasp-worker-th-before-3 pod downwardapi-volume-b87db21b-b966-491d-b0cd-d728dbce0432 container client-container: <nil>
STEP: delete the pod
Dec 20 10:44:23.877: INFO: Waiting for pod downwardapi-volume-b87db21b-b966-491d-b0cd-d728dbce0432 to disappear
Dec 20 10:44:23.879: INFO: Pod downwardapi-volume-b87db21b-b966-491d-b0cd-d728dbce0432 no longer exists
[AfterEach] [sig-storage] Downward API volume
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:44:23.879: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "downward-api-7582" for this suite.
Dec 20 10:44:29.893: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:44:29.996: INFO: namespace downward-api-7582 deletion completed in 6.113476973s

• [SLOW TEST:10.293 seconds]
[sig-storage] Downward API volume
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/downwardapi_volume.go:35
  should provide container's cpu limit [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:44:29.996: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-76
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-configmap-cvcv
STEP: Creating a pod to test atomic-volume-subpath
Dec 20 10:44:30.143: INFO: Waiting up to 5m0s for pod "pod-subpath-test-configmap-cvcv" in namespace "subpath-76" to be "success or failure"
Dec 20 10:44:30.146: INFO: Pod "pod-subpath-test-configmap-cvcv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.193112ms
Dec 20 10:44:32.149: INFO: Pod "pod-subpath-test-configmap-cvcv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00547691s
Dec 20 10:44:34.153: INFO: Pod "pod-subpath-test-configmap-cvcv": Phase="Running", Reason="", readiness=true. Elapsed: 4.009334983s
Dec 20 10:44:36.156: INFO: Pod "pod-subpath-test-configmap-cvcv": Phase="Running", Reason="", readiness=true. Elapsed: 6.012833982s
Dec 20 10:44:38.160: INFO: Pod "pod-subpath-test-configmap-cvcv": Phase="Running", Reason="", readiness=true. Elapsed: 8.016587636s
Dec 20 10:44:40.164: INFO: Pod "pod-subpath-test-configmap-cvcv": Phase="Running", Reason="", readiness=true. Elapsed: 10.020487368s
Dec 20 10:44:42.167: INFO: Pod "pod-subpath-test-configmap-cvcv": Phase="Running", Reason="", readiness=true. Elapsed: 12.023840641s
Dec 20 10:44:44.171: INFO: Pod "pod-subpath-test-configmap-cvcv": Phase="Running", Reason="", readiness=true. Elapsed: 14.027240027s
Dec 20 10:44:46.174: INFO: Pod "pod-subpath-test-configmap-cvcv": Phase="Running", Reason="", readiness=true. Elapsed: 16.0306341s
Dec 20 10:44:48.178: INFO: Pod "pod-subpath-test-configmap-cvcv": Phase="Running", Reason="", readiness=true. Elapsed: 18.034688276s
Dec 20 10:44:50.182: INFO: Pod "pod-subpath-test-configmap-cvcv": Phase="Running", Reason="", readiness=true. Elapsed: 20.038638855s
Dec 20 10:44:52.186: INFO: Pod "pod-subpath-test-configmap-cvcv": Phase="Running", Reason="", readiness=true. Elapsed: 22.042233323s
Dec 20 10:44:54.189: INFO: Pod "pod-subpath-test-configmap-cvcv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.04530707s
STEP: Saw pod success
Dec 20 10:44:54.189: INFO: Pod "pod-subpath-test-configmap-cvcv" satisfied condition "success or failure"
Dec 20 10:44:54.191: INFO: Trying to get logs from node caasp-worker-th-before-4 pod pod-subpath-test-configmap-cvcv container test-container-subpath-configmap-cvcv: <nil>
STEP: delete the pod
Dec 20 10:44:54.217: INFO: Waiting for pod pod-subpath-test-configmap-cvcv to disappear
Dec 20 10:44:54.221: INFO: Pod pod-subpath-test-configmap-cvcv no longer exists
STEP: Deleting pod pod-subpath-test-configmap-cvcv
Dec 20 10:44:54.221: INFO: Deleting pod "pod-subpath-test-configmap-cvcv" in namespace "subpath-76"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:44:54.224: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-76" for this suite.
Dec 20 10:45:00.241: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:45:00.334: INFO: namespace subpath-76 deletion completed in 6.106737284s

• [SLOW TEST:30.338 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with configmap pod with mountPath of existing file [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:45:00.335: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-1828
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 20 10:45:00.476: INFO: Waiting up to 5m0s for pod "downwardapi-volume-9a6defaf-252b-400b-b368-a95ae7ccbab0" in namespace "projected-1828" to be "success or failure"
Dec 20 10:45:00.479: INFO: Pod "downwardapi-volume-9a6defaf-252b-400b-b368-a95ae7ccbab0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.589142ms
Dec 20 10:45:02.483: INFO: Pod "downwardapi-volume-9a6defaf-252b-400b-b368-a95ae7ccbab0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006599596s
Dec 20 10:45:04.487: INFO: Pod "downwardapi-volume-9a6defaf-252b-400b-b368-a95ae7ccbab0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010818196s
STEP: Saw pod success
Dec 20 10:45:04.487: INFO: Pod "downwardapi-volume-9a6defaf-252b-400b-b368-a95ae7ccbab0" satisfied condition "success or failure"
Dec 20 10:45:04.490: INFO: Trying to get logs from node caasp-worker-th-before-0 pod downwardapi-volume-9a6defaf-252b-400b-b368-a95ae7ccbab0 container client-container: <nil>
STEP: delete the pod
Dec 20 10:45:04.517: INFO: Waiting for pod downwardapi-volume-9a6defaf-252b-400b-b368-a95ae7ccbab0 to disappear
Dec 20 10:45:04.519: INFO: Pod downwardapi-volume-9a6defaf-252b-400b-b368-a95ae7ccbab0 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:45:04.519: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-1828" for this suite.
Dec 20 10:45:10.532: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:45:10.625: INFO: namespace projected-1828 deletion completed in 6.102600146s

• [SLOW TEST:10.290 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's cpu request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Docker Containers 
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:45:10.625: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename containers
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in containers-8818
STEP: Waiting for a default service account to be provisioned in namespace
[It] should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Docker Containers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:45:14.776: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "containers-8818" for this suite.
Dec 20 10:45:22.792: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:45:22.888: INFO: namespace containers-8818 deletion completed in 8.107615659s

• [SLOW TEST:12.263 seconds]
[k8s.io] Docker Containers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should use the image defaults if command and args are blank [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition 
  getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:45:22.888: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename custom-resource-definition
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in custom-resource-definition-3083
STEP: Waiting for a default service account to be provisioned in namespace
[It] getting/updating/patching custom resource definition status sub-resource works  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 10:45:23.018: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
[AfterEach] [sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:45:23.549: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "custom-resource-definition-3083" for this suite.
Dec 20 10:45:29.563: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:45:29.654: INFO: namespace custom-resource-definition-3083 deletion completed in 6.101602776s

• [SLOW TEST:6.766 seconds]
[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  Simple CustomResourceDefinition
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/custom_resource_definition.go:42
    getting/updating/patching custom resource definition status sub-resource works  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
S
------------------------------
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] 
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:45:29.655: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename crd-publish-openapi
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-publish-openapi-6982
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: set up a multi version CRD
Dec 20 10:45:29.784: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: rename a version
STEP: check the new version name is served
STEP: check the old version name is removed
STEP: check the other version is not changed
[AfterEach] [sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:45:58.343: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-publish-openapi-6982" for this suite.
Dec 20 10:46:04.362: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:46:04.457: INFO: namespace crd-publish-openapi-6982 deletion completed in 6.107380754s

• [SLOW TEST:34.802 seconds]
[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  updates the published spec when one version gets renamed [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] 
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:46:04.457: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename crd-webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in crd-webhook-8342
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:126
STEP: Setting up server cert
STEP: Create role binding to let cr conversion webhook read extension-apiserver-authentication
STEP: Deploying the custom resource conversion webhook pod
STEP: Wait for the deployment to be ready
Dec 20 10:46:05.825: INFO: deployment "sample-crd-conversion-webhook-deployment" doesn't have the required revision set
Dec 20 10:46:07.838: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435566, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435566, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435566, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435566, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-crd-conversion-webhook-deployment-64d485d9bb\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 20 10:46:10.859: INFO: Waiting for amount of service:e2e-test-crd-conversion-webhook endpoints to be 1
[It] should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 10:46:10.863: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Creating a v1 custom resource
STEP: v2 custom resource should be converted
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:46:11.986: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "crd-webhook-8342" for this suite.
Dec 20 10:46:18.003: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:46:18.091: INFO: namespace crd-webhook-8342 deletion completed in 6.100343781s
[AfterEach] [sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/crd_conversion_webhook.go:137

• [SLOW TEST:13.650 seconds]
[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to convert from CR v1 to CR v2 [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[k8s.io] Probing container 
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:46:18.107: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename container-probe
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-probe-4391
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/container_probe.go:52
[It] should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod busybox-b66c24af-b1c2-4d55-9b5c-1a9513fe45fe in namespace container-probe-4391
Dec 20 10:46:22.253: INFO: Started pod busybox-b66c24af-b1c2-4d55-9b5c-1a9513fe45fe in namespace container-probe-4391
STEP: checking the pod's current state and verifying that restartCount is present
Dec 20 10:46:22.256: INFO: Initial restart count of pod busybox-b66c24af-b1c2-4d55-9b5c-1a9513fe45fe is 0
STEP: deleting the pod
[AfterEach] [k8s.io] Probing container
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:50:22.757: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-probe-4391" for this suite.
Dec 20 10:50:28.770: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:50:28.863: INFO: namespace container-probe-4391 deletion completed in 6.10194941s

• [SLOW TEST:250.755 seconds]
[k8s.io] Probing container
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should *not* be restarted with a exec "cat /tmp/health" liveness probe [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] Secrets 
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:50:28.863: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename secrets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in secrets-3876
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name secret-test-8dddc268-a2a5-43e7-9e1b-c40ca56277a0
STEP: Creating a pod to test consume secrets
Dec 20 10:50:29.009: INFO: Waiting up to 5m0s for pod "pod-secrets-eaa20ac7-7e83-4355-b45e-64866f4b3831" in namespace "secrets-3876" to be "success or failure"
Dec 20 10:50:29.011: INFO: Pod "pod-secrets-eaa20ac7-7e83-4355-b45e-64866f4b3831": Phase="Pending", Reason="", readiness=false. Elapsed: 2.367179ms
Dec 20 10:50:31.015: INFO: Pod "pod-secrets-eaa20ac7-7e83-4355-b45e-64866f4b3831": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005946026s
Dec 20 10:50:33.019: INFO: Pod "pod-secrets-eaa20ac7-7e83-4355-b45e-64866f4b3831": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010345846s
STEP: Saw pod success
Dec 20 10:50:33.019: INFO: Pod "pod-secrets-eaa20ac7-7e83-4355-b45e-64866f4b3831" satisfied condition "success or failure"
Dec 20 10:50:33.022: INFO: Trying to get logs from node caasp-worker-th-before-4 pod pod-secrets-eaa20ac7-7e83-4355-b45e-64866f4b3831 container secret-env-test: <nil>
STEP: delete the pod
Dec 20 10:50:33.049: INFO: Waiting for pod pod-secrets-eaa20ac7-7e83-4355-b45e-64866f4b3831 to disappear
Dec 20 10:50:33.051: INFO: Pod pod-secrets-eaa20ac7-7e83-4355-b45e-64866f4b3831 no longer exists
[AfterEach] [sig-api-machinery] Secrets
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:50:33.051: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "secrets-3876" for this suite.
Dec 20 10:50:39.064: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:50:39.156: INFO: namespace secrets-3876 deletion completed in 6.101149945s

• [SLOW TEST:10.293 seconds]
[sig-api-machinery] Secrets
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/secrets.go:32
  should be consumable from pods in env vars [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Daemon set [Serial] 
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:50:39.156: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename daemonsets
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in daemonsets-7497
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:102
[It] should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating simple DaemonSet "daemon-set"
STEP: Check that daemon pods launch on every node of the cluster.
Dec 20 10:50:39.315: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:39.315: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:39.318: INFO: Number of nodes with available pods: 0
Dec 20 10:50:39.318: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 10:50:40.323: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:40.323: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:40.327: INFO: Number of nodes with available pods: 0
Dec 20 10:50:40.327: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 10:50:41.322: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:41.322: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:41.325: INFO: Number of nodes with available pods: 1
Dec 20 10:50:41.325: INFO: Node caasp-worker-th-before-0 is running more than one daemon pod
Dec 20 10:50:42.322: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:42.322: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:42.325: INFO: Number of nodes with available pods: 3
Dec 20 10:50:42.325: INFO: Number of running nodes: 3, number of available pods: 3
STEP: Stop a daemon pod, check that the daemon pod is revived.
Dec 20 10:50:42.340: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:42.340: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:42.343: INFO: Number of nodes with available pods: 2
Dec 20 10:50:42.343: INFO: Node caasp-worker-th-before-3 is running more than one daemon pod
Dec 20 10:50:43.349: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:43.349: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:43.353: INFO: Number of nodes with available pods: 2
Dec 20 10:50:43.353: INFO: Node caasp-worker-th-before-3 is running more than one daemon pod
Dec 20 10:50:44.349: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:44.349: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:44.352: INFO: Number of nodes with available pods: 2
Dec 20 10:50:44.352: INFO: Node caasp-worker-th-before-3 is running more than one daemon pod
Dec 20 10:50:45.349: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:45.349: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:45.353: INFO: Number of nodes with available pods: 2
Dec 20 10:50:45.353: INFO: Node caasp-worker-th-before-3 is running more than one daemon pod
Dec 20 10:50:46.350: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:46.350: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:46.354: INFO: Number of nodes with available pods: 2
Dec 20 10:50:46.354: INFO: Node caasp-worker-th-before-3 is running more than one daemon pod
Dec 20 10:50:47.349: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:47.349: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:47.353: INFO: Number of nodes with available pods: 2
Dec 20 10:50:47.353: INFO: Node caasp-worker-th-before-3 is running more than one daemon pod
Dec 20 10:50:48.350: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:48.350: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:48.353: INFO: Number of nodes with available pods: 2
Dec 20 10:50:48.353: INFO: Node caasp-worker-th-before-3 is running more than one daemon pod
Dec 20 10:50:49.349: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:49.349: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:49.353: INFO: Number of nodes with available pods: 2
Dec 20 10:50:49.353: INFO: Node caasp-worker-th-before-3 is running more than one daemon pod
Dec 20 10:50:50.350: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:50.350: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:50.353: INFO: Number of nodes with available pods: 2
Dec 20 10:50:50.353: INFO: Node caasp-worker-th-before-3 is running more than one daemon pod
Dec 20 10:50:51.349: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:51.349: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:51.353: INFO: Number of nodes with available pods: 2
Dec 20 10:50:51.353: INFO: Node caasp-worker-th-before-3 is running more than one daemon pod
Dec 20 10:50:52.352: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:52.352: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:52.358: INFO: Number of nodes with available pods: 2
Dec 20 10:50:52.358: INFO: Node caasp-worker-th-before-3 is running more than one daemon pod
Dec 20 10:50:53.350: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:53.350: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:53.353: INFO: Number of nodes with available pods: 2
Dec 20 10:50:53.353: INFO: Node caasp-worker-th-before-3 is running more than one daemon pod
Dec 20 10:50:54.350: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:54.350: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:54.354: INFO: Number of nodes with available pods: 2
Dec 20 10:50:54.354: INFO: Node caasp-worker-th-before-3 is running more than one daemon pod
Dec 20 10:50:55.349: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:55.349: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:55.352: INFO: Number of nodes with available pods: 2
Dec 20 10:50:55.352: INFO: Node caasp-worker-th-before-3 is running more than one daemon pod
Dec 20 10:50:56.350: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:56.351: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:56.354: INFO: Number of nodes with available pods: 2
Dec 20 10:50:56.354: INFO: Node caasp-worker-th-before-3 is running more than one daemon pod
Dec 20 10:50:57.349: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-0 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:57.349: INFO: DaemonSet pods can't tolerate node caasp-master-th-before-2 with taints [{Key:node-role.kubernetes.io/master Value: Effect:NoSchedule TimeAdded:<nil>}], skip checking this node
Dec 20 10:50:57.353: INFO: Number of nodes with available pods: 3
Dec 20 10:50:57.353: INFO: Number of running nodes: 3, number of available pods: 3
[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/daemon_set.go:68
STEP: Deleting DaemonSet "daemon-set"
STEP: deleting DaemonSet.extensions daemon-set in namespace daemonsets-7497, will wait for the garbage collector to delete the pods
Dec 20 10:50:57.416: INFO: Deleting DaemonSet.extensions daemon-set took: 7.679031ms
Dec 20 10:50:57.816: INFO: Terminating DaemonSet.extensions daemon-set pods took: 400.292957ms
Dec 20 10:51:10.920: INFO: Number of nodes with available pods: 0
Dec 20 10:51:10.920: INFO: Number of running nodes: 0, number of available pods: 0
Dec 20 10:51:10.922: INFO: daemonset: {"kind":"DaemonSetList","apiVersion":"apps/v1","metadata":{"selfLink":"/apis/apps/v1/namespaces/daemonsets-7497/daemonsets","resourceVersion":"136006"},"items":null}

Dec 20 10:51:10.924: INFO: pods: {"kind":"PodList","apiVersion":"v1","metadata":{"selfLink":"/api/v1/namespaces/daemonsets-7497/pods","resourceVersion":"136006"},"items":null}

[AfterEach] [sig-apps] Daemon set [Serial]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:51:10.936: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "daemonsets-7497" for this suite.
Dec 20 10:51:16.949: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:51:17.039: INFO: namespace daemonsets-7497 deletion completed in 6.099799879s

• [SLOW TEST:37.883 seconds]
[sig-apps] Daemon set [Serial]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  should run and stop simple daemon [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:51:17.039: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-4770
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's args
Dec 20 10:51:17.175: INFO: Waiting up to 5m0s for pod "var-expansion-df289294-1ffb-45c0-a74a-0325973b8432" in namespace "var-expansion-4770" to be "success or failure"
Dec 20 10:51:17.178: INFO: Pod "var-expansion-df289294-1ffb-45c0-a74a-0325973b8432": Phase="Pending", Reason="", readiness=false. Elapsed: 2.098168ms
Dec 20 10:51:19.186: INFO: Pod "var-expansion-df289294-1ffb-45c0-a74a-0325973b8432": Phase="Pending", Reason="", readiness=false. Elapsed: 2.010209775s
Dec 20 10:51:21.190: INFO: Pod "var-expansion-df289294-1ffb-45c0-a74a-0325973b8432": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.014883714s
STEP: Saw pod success
Dec 20 10:51:21.190: INFO: Pod "var-expansion-df289294-1ffb-45c0-a74a-0325973b8432" satisfied condition "success or failure"
Dec 20 10:51:21.193: INFO: Trying to get logs from node caasp-worker-th-before-0 pod var-expansion-df289294-1ffb-45c0-a74a-0325973b8432 container dapi-container: <nil>
STEP: delete the pod
Dec 20 10:51:21.225: INFO: Waiting for pod var-expansion-df289294-1ffb-45c0-a74a-0325973b8432 to disappear
Dec 20 10:51:21.228: INFO: Pod var-expansion-df289294-1ffb-45c0-a74a-0325973b8432 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:51:21.228: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-4770" for this suite.
Dec 20 10:51:27.242: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:51:27.322: INFO: namespace var-expansion-4770 deletion completed in 6.090146304s

• [SLOW TEST:10.283 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's args [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:51:27.322: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9450
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 20 10:51:28.287: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 20 10:51:30.296: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435889, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435889, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435889, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435889, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 20 10:51:33.312: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering the webhook via the AdmissionRegistration API
STEP: create a pod
STEP: 'kubectl attach' the pod, should be denied by the webhook
Dec 20 10:51:37.344: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 attach --namespace=webhook-9450 to-be-attached-pod -i -c=container1'
Dec 20 10:51:37.448: INFO: rc: 1
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:51:37.456: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9450" for this suite.
Dec 20 10:51:49.471: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:51:49.560: INFO: namespace webhook-9450 deletion completed in 12.100170329s
STEP: Destroying namespace "webhook-9450-markers" for this suite.
Dec 20 10:51:55.570: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:51:55.660: INFO: namespace webhook-9450-markers deletion completed in 6.099733828s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:28.349 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to deny attaching pod [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should honor timeout [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:51:55.672: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-9722
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 20 10:51:57.661: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 20 10:51:59.672: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435918, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435918, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435918, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712435918, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 20 10:52:02.686: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should honor timeout [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Setting timeout (1s) shorter than webhook latency (5s)
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Request fails when timeout (1s) is shorter than slow webhook latency (5s)
STEP: Having no error when timeout is shorter than webhook latency and failure policy is ignore
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is longer than webhook latency
STEP: Registering slow webhook via the AdmissionRegistration API
STEP: Having no error when timeout is empty (defaulted to 10s in v1)
STEP: Registering slow webhook via the AdmissionRegistration API
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:52:14.799: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-9722" for this suite.
Dec 20 10:52:20.813: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:52:20.905: INFO: namespace webhook-9722 deletion completed in 6.102211439s
STEP: Destroying namespace "webhook-9722-markers" for this suite.
Dec 20 10:52:26.914: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:52:27.016: INFO: namespace webhook-9722-markers deletion completed in 6.11101095s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:31.357 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should honor timeout [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:52:27.029: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2101
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop http hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 20 10:52:35.199: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 20 10:52:35.201: INFO: Pod pod-with-prestop-http-hook still exists
Dec 20 10:52:37.202: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 20 10:52:37.206: INFO: Pod pod-with-prestop-http-hook still exists
Dec 20 10:52:39.202: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 20 10:52:39.205: INFO: Pod pod-with-prestop-http-hook still exists
Dec 20 10:52:41.202: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 20 10:52:41.205: INFO: Pod pod-with-prestop-http-hook still exists
Dec 20 10:52:43.202: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 20 10:52:43.205: INFO: Pod pod-with-prestop-http-hook still exists
Dec 20 10:52:45.202: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 20 10:52:45.206: INFO: Pod pod-with-prestop-http-hook still exists
Dec 20 10:52:47.202: INFO: Waiting for pod pod-with-prestop-http-hook to disappear
Dec 20 10:52:47.205: INFO: Pod pod-with-prestop-http-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:52:47.213: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2101" for this suite.
Dec 20 10:53:15.232: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:53:15.321: INFO: namespace container-lifecycle-hook-2101 deletion completed in 28.10329964s

• [SLOW TEST:48.292 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop http hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:53:15.321: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-1758
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0777 on tmpfs
Dec 20 10:53:15.462: INFO: Waiting up to 5m0s for pod "pod-852b57a5-1f99-4c56-91cd-290afc94d7c0" in namespace "emptydir-1758" to be "success or failure"
Dec 20 10:53:15.464: INFO: Pod "pod-852b57a5-1f99-4c56-91cd-290afc94d7c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.634563ms
Dec 20 10:53:17.470: INFO: Pod "pod-852b57a5-1f99-4c56-91cd-290afc94d7c0": Phase="Pending", Reason="", readiness=false. Elapsed: 2.007992571s
Dec 20 10:53:19.474: INFO: Pod "pod-852b57a5-1f99-4c56-91cd-290afc94d7c0": Phase="Pending", Reason="", readiness=false. Elapsed: 4.012284427s
Dec 20 10:53:21.478: INFO: Pod "pod-852b57a5-1f99-4c56-91cd-290afc94d7c0": Phase="Pending", Reason="", readiness=false. Elapsed: 6.016503894s
Dec 20 10:53:23.482: INFO: Pod "pod-852b57a5-1f99-4c56-91cd-290afc94d7c0": Phase="Succeeded", Reason="", readiness=false. Elapsed: 8.020086902s
STEP: Saw pod success
Dec 20 10:53:23.482: INFO: Pod "pod-852b57a5-1f99-4c56-91cd-290afc94d7c0" satisfied condition "success or failure"
Dec 20 10:53:23.484: INFO: Trying to get logs from node caasp-worker-th-before-0 pod pod-852b57a5-1f99-4c56-91cd-290afc94d7c0 container test-container: <nil>
STEP: delete the pod
Dec 20 10:53:23.499: INFO: Waiting for pod pod-852b57a5-1f99-4c56-91cd-290afc94d7c0 to disappear
Dec 20 10:53:23.501: INFO: Pod pod-852b57a5-1f99-4c56-91cd-290afc94d7c0 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:53:23.501: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-1758" for this suite.
Dec 20 10:53:29.513: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:53:29.609: INFO: namespace emptydir-1758 deletion completed in 6.105576048s

• [SLOW TEST:14.288 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:53:29.610: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-1373
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-1373
[It] Should recreate evicted statefulset [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Looking for a node to schedule stateful set and pod
STEP: Creating pod with conflicting port in namespace statefulset-1373
STEP: Creating statefulset with conflicting port in namespace statefulset-1373
STEP: Waiting until pod test-pod will start running in namespace statefulset-1373
STEP: Waiting until stateful pod ss-0 will be recreated and deleted at least once in namespace statefulset-1373
Dec 20 10:53:33.767: INFO: Observed stateful pod in namespace: statefulset-1373, name: ss-0, uid: 647b6815-ca24-4af6-9664-203fd33fc893, status phase: Pending. Waiting for statefulset controller to delete.
Dec 20 10:53:34.162: INFO: Observed stateful pod in namespace: statefulset-1373, name: ss-0, uid: 647b6815-ca24-4af6-9664-203fd33fc893, status phase: Failed. Waiting for statefulset controller to delete.
Dec 20 10:53:34.168: INFO: Observed stateful pod in namespace: statefulset-1373, name: ss-0, uid: 647b6815-ca24-4af6-9664-203fd33fc893, status phase: Failed. Waiting for statefulset controller to delete.
Dec 20 10:53:34.172: INFO: Observed delete event for stateful pod ss-0 in namespace statefulset-1373
STEP: Removing pod with conflicting port in namespace statefulset-1373
STEP: Waiting when stateful pod ss-0 will be recreated in namespace statefulset-1373 and will be in running state
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 20 10:53:38.188: INFO: Deleting all statefulset in ns statefulset-1373
Dec 20 10:53:38.191: INFO: Scaling statefulset ss to 0
Dec 20 10:53:48.205: INFO: Waiting for statefulset status.replicas updated to 0
Dec 20 10:53:48.208: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:53:48.221: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-1373" for this suite.
Dec 20 10:53:54.235: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:53:54.318: INFO: namespace statefulset-1373 deletion completed in 6.0929339s

• [SLOW TEST:24.708 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Should recreate evicted statefulset [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] 
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:53:54.318: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename webhook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in webhook-6464
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:88
STEP: Setting up server cert
STEP: Create role binding to let webhook read extension-apiserver-authentication
STEP: Deploying the webhook pod
STEP: Wait for the deployment to be ready
Dec 20 10:53:55.163: INFO: deployment "sample-webhook-deployment" doesn't have the required revision set
Dec 20 10:53:57.174: INFO: deployment status: v1.DeploymentStatus{ObservedGeneration:1, Replicas:1, UpdatedReplicas:1, ReadyReplicas:0, AvailableReplicas:0, UnavailableReplicas:1, Conditions:[]v1.DeploymentCondition{v1.DeploymentCondition{Type:"Available", Status:"False", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712436036, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712436036, loc:(*time.Location)(0x84c02a0)}}, Reason:"MinimumReplicasUnavailable", Message:"Deployment does not have minimum availability."}, v1.DeploymentCondition{Type:"Progressing", Status:"True", LastUpdateTime:v1.Time{Time:time.Time{wall:0x0, ext:63712436036, loc:(*time.Location)(0x84c02a0)}}, LastTransitionTime:v1.Time{Time:time.Time{wall:0x0, ext:63712436036, loc:(*time.Location)(0x84c02a0)}}, Reason:"ReplicaSetUpdated", Message:"ReplicaSet \"sample-webhook-deployment-86d95b659d\" is progressing."}}, CollisionCount:(*int32)(nil)}
STEP: Deploying the webhook service
STEP: Verifying the service has paired with the endpoint
Dec 20 10:54:00.191: INFO: Waiting for amount of service:e2e-test-webhook endpoints to be 1
[It] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Registering a validating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Registering a mutating webhook on ValidatingWebhookConfiguration and MutatingWebhookConfiguration objects, via the AdmissionRegistration API
STEP: Creating a dummy validating-webhook-configuration object
STEP: Deleting the validating-webhook-configuration, which should be possible to remove
STEP: Creating a dummy mutating-webhook-configuration object
STEP: Deleting the mutating-webhook-configuration, which should be possible to remove
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:54:00.255: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "webhook-6464" for this suite.
Dec 20 10:54:06.267: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:54:06.397: INFO: namespace webhook-6464 deletion completed in 6.138804142s
STEP: Destroying namespace "webhook-6464-markers" for this suite.
Dec 20 10:54:12.406: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:54:12.492: INFO: namespace webhook-6464-markers deletion completed in 6.094785045s
[AfterEach] [sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/webhook.go:103

• [SLOW TEST:18.185 seconds]
[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin]
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] Networking Granular Checks: Pods 
  should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:54:12.503: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename pod-network-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pod-network-test-7099
STEP: Waiting for a default service account to be provisioned in namespace
[It] should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Performing setup for networking test in namespace pod-network-test-7099
STEP: creating a selector
STEP: Creating the service pods in kubernetes
Dec 20 10:54:12.630: INFO: Waiting up to 10m0s for all (but 0) nodes to be schedulable
STEP: Creating test pods
Dec 20 10:54:34.703: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.6.226:8080/dial?request=hostName&protocol=udp&host=10.244.6.217&port=8081&tries=1'] Namespace:pod-network-test-7099 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 10:54:34.703: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 10:54:34.777: INFO: Waiting for endpoints: map[]
Dec 20 10:54:34.780: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.6.226:8080/dial?request=hostName&protocol=udp&host=10.244.5.8&port=8081&tries=1'] Namespace:pod-network-test-7099 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 10:54:34.780: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 10:54:34.850: INFO: Waiting for endpoints: map[]
Dec 20 10:54:34.852: INFO: ExecWithOptions {Command:[/bin/sh -c curl -g -q -s 'http://10.244.6.226:8080/dial?request=hostName&protocol=udp&host=10.244.7.154&port=8081&tries=1'] Namespace:pod-network-test-7099 PodName:host-test-container-pod ContainerName:agnhost Stdin:<nil> CaptureStdout:true CaptureStderr:true PreserveWhitespace:false}
Dec 20 10:54:34.852: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
Dec 20 10:54:34.923: INFO: Waiting for endpoints: map[]
[AfterEach] [sig-network] Networking
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:54:34.923: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pod-network-test-7099" for this suite.
Dec 20 10:54:46.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:54:47.025: INFO: namespace pod-network-test-7099 deletion completed in 12.097638739s

• [SLOW TEST:34.522 seconds]
[sig-network] Networking
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:25
  Granular Checks: Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/networking.go:28
    should function for intra-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:54:47.025: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-7479
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should provide secure master service  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:54:47.156: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-7479" for this suite.
Dec 20 10:54:53.169: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:54:53.258: INFO: namespace services-7479 deletion completed in 6.098073464s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:6.233 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide secure master service  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[k8s.io] Container Lifecycle Hook when create a pod with lifecycle hook 
  should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:54:53.258: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename container-lifecycle-hook
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-lifecycle-hook-2419
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:64
STEP: create the container to handle the HTTPGet hook request.
[It] should execute prestop exec hook properly [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the pod with lifecycle hook
STEP: delete the pod with lifecycle hook
Dec 20 10:55:01.421: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 20 10:55:01.424: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 20 10:55:03.424: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 20 10:55:03.428: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 20 10:55:05.424: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 20 10:55:05.428: INFO: Pod pod-with-prestop-exec-hook still exists
Dec 20 10:55:07.424: INFO: Waiting for pod pod-with-prestop-exec-hook to disappear
Dec 20 10:55:07.427: INFO: Pod pod-with-prestop-exec-hook no longer exists
STEP: check prestop hook
[AfterEach] [k8s.io] Container Lifecycle Hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:55:07.444: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-lifecycle-hook-2419" for this suite.
Dec 20 10:55:35.459: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:55:35.554: INFO: namespace container-lifecycle-hook-2419 deletion completed in 28.106023955s

• [SLOW TEST:42.296 seconds]
[k8s.io] Container Lifecycle Hook
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when create a pod with lifecycle hook
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/lifecycle_hook.go:42
    should execute prestop exec hook properly [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Watchers 
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:55:35.554: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename watch
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in watch-1263
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a new configmap
STEP: modifying the configmap once
STEP: modifying the configmap a second time
STEP: deleting the configmap
STEP: creating a watch on configmaps from the resource version returned by the first update
STEP: Expecting to observe notifications for all changes to the configmap after the first update
Dec 20 10:55:35.714: INFO: Got : MODIFIED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-1263 /api/v1/namespaces/watch-1263/configmaps/e2e-watch-test-resource-version 7422fc04-a33e-46e7-a7ad-fc693540faa9 137514 0 2019-12-20 10:55:35 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
Dec 20 10:55:35.714: INFO: Got : DELETED &ConfigMap{ObjectMeta:{e2e-watch-test-resource-version  watch-1263 /api/v1/namespaces/watch-1263/configmaps/e2e-watch-test-resource-version 7422fc04-a33e-46e7-a7ad-fc693540faa9 137515 0 2019-12-20 10:55:35 +0000 UTC <nil> <nil> map[watch-this-configmap:from-resource-version] map[] [] []  []},Data:map[string]string{mutation: 2,},BinaryData:map[string][]byte{},}
[AfterEach] [sig-api-machinery] Watchers
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:55:35.714: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "watch-1263" for this suite.
Dec 20 10:55:41.730: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:55:41.816: INFO: namespace watch-1263 deletion completed in 6.098651895s

• [SLOW TEST:6.262 seconds]
[sig-api-machinery] Watchers
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to start watching from a specific resource version [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[k8s.io] Container Runtime blackbox test when starting a container that exits 
  should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:55:41.817: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename container-runtime
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in container-runtime-5176
STEP: Waiting for a default service account to be provisioned in namespace
[It] should run with the expected status [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Container 'terminate-cmd-rpa': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpa': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpa': should get the expected 'State'
STEP: Container 'terminate-cmd-rpa': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpof': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpof': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpof': should get the expected 'State'
STEP: Container 'terminate-cmd-rpof': should be possible to delete [NodeConformance]
STEP: Container 'terminate-cmd-rpn': should get the expected 'RestartCount'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Phase'
STEP: Container 'terminate-cmd-rpn': should get the expected 'Ready' condition
STEP: Container 'terminate-cmd-rpn': should get the expected 'State'
STEP: Container 'terminate-cmd-rpn': should be possible to delete [NodeConformance]
[AfterEach] [k8s.io] Container Runtime
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:56:08.139: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "container-runtime-5176" for this suite.
Dec 20 10:56:14.152: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:56:14.247: INFO: namespace container-runtime-5176 deletion completed in 6.104728187s

• [SLOW TEST:32.431 seconds]
[k8s.io] Container Runtime
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  blackbox test
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:39
    when starting a container that exits
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/runtime.go:40
      should run with the expected status [NodeConformance] [Conformance]
      /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:56:14.248: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-395
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 20 10:56:14.387: INFO: Waiting up to 5m0s for pod "downwardapi-volume-2e4d8eb0-ce83-42f9-a7d9-f2cbc28bb622" in namespace "projected-395" to be "success or failure"
Dec 20 10:56:14.389: INFO: Pod "downwardapi-volume-2e4d8eb0-ce83-42f9-a7d9-f2cbc28bb622": Phase="Pending", Reason="", readiness=false. Elapsed: 2.282474ms
Dec 20 10:56:16.393: INFO: Pod "downwardapi-volume-2e4d8eb0-ce83-42f9-a7d9-f2cbc28bb622": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006019261s
Dec 20 10:56:18.397: INFO: Pod "downwardapi-volume-2e4d8eb0-ce83-42f9-a7d9-f2cbc28bb622": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010540521s
STEP: Saw pod success
Dec 20 10:56:18.397: INFO: Pod "downwardapi-volume-2e4d8eb0-ce83-42f9-a7d9-f2cbc28bb622" satisfied condition "success or failure"
Dec 20 10:56:18.400: INFO: Trying to get logs from node caasp-worker-th-before-4 pod downwardapi-volume-2e4d8eb0-ce83-42f9-a7d9-f2cbc28bb622 container client-container: <nil>
STEP: delete the pod
Dec 20 10:56:18.418: INFO: Waiting for pod downwardapi-volume-2e4d8eb0-ce83-42f9-a7d9-f2cbc28bb622 to disappear
Dec 20 10:56:18.420: INFO: Pod downwardapi-volume-2e4d8eb0-ce83-42f9-a7d9-f2cbc28bb622 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:56:18.420: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-395" for this suite.
Dec 20 10:56:24.433: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:56:24.532: INFO: namespace projected-395 deletion completed in 6.108997206s

• [SLOW TEST:10.285 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] Deployment 
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:56:24.533: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename deployment
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in deployment-9272
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:68
[It] deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
Dec 20 10:56:24.671: INFO: Pod name cleanup-pod: Found 0 pods out of 1
Dec 20 10:56:29.676: INFO: Pod name cleanup-pod: Found 1 pods out of 1
STEP: ensuring each pod is running
Dec 20 10:56:29.676: INFO: Creating deployment test-cleanup-deployment
STEP: Waiting for deployment test-cleanup-deployment history to be cleaned up
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/deployment.go:62
Dec 20 10:56:29.692: INFO: Deployment "test-cleanup-deployment":
&Deployment{ObjectMeta:{test-cleanup-deployment  deployment-9272 /apis/apps/v1/namespaces/deployment-9272/deployments/test-cleanup-deployment 82c6d8c9-f0a2-42fa-8759-b3ac33d31f16 137833 1 2019-12-20 10:56:29 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []},Spec:DeploymentSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod] map[] [] []  []} {[] [] [{redis docker.io/library/redis:5.0.5-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent SecurityContext{Capabilities:nil,Privileged:nil,SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,ReadOnlyRootFilesystem:nil,AllowPrivilegeEscalation:nil,RunAsGroup:nil,ProcMount:nil,WindowsOptions:nil,} false false false}] [] Always 0xc006ebbf68 <nil> ClusterFirst map[]   <nil>  false false false <nil> &PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},Strategy:DeploymentStrategy{Type:RollingUpdate,RollingUpdate:&RollingUpdateDeployment{MaxUnavailable:25%!,(MISSING)MaxSurge:25%!,(MISSING)},},MinReadySeconds:0,RevisionHistoryLimit:*0,Paused:false,ProgressDeadlineSeconds:*600,},Status:DeploymentStatus{ObservedGeneration:0,Replicas:0,UpdatedReplicas:0,AvailableReplicas:0,UnavailableReplicas:0,Conditions:[]DeploymentCondition{},ReadyReplicas:0,CollisionCount:nil,},}

Dec 20 10:56:29.694: INFO: New ReplicaSet of Deployment "test-cleanup-deployment" is nil.
Dec 20 10:56:29.694: INFO: All old ReplicaSets of Deployment "test-cleanup-deployment":
Dec 20 10:56:29.694: INFO: &ReplicaSet{ObjectMeta:{test-cleanup-controller  deployment-9272 /apis/apps/v1/namespaces/deployment-9272/replicasets/test-cleanup-controller e0755c8e-a6b0-440d-987f-dc320e782245 137834 1 2019-12-20 10:56:24 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [{apps/v1 Deployment test-cleanup-deployment 82c6d8c9-f0a2-42fa-8759-b3ac33d31f16 0xc005717997 0xc005717998}] []  []},Spec:ReplicaSetSpec{Replicas:*1,Selector:&v1.LabelSelector{MatchLabels:map[string]string{name: cleanup-pod,pod: httpd,},MatchExpressions:[]LabelSelectorRequirement{},},Template:{{      0 0001-01-01 00:00:00 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[] [] []  []} {[] [] [{httpd docker.io/library/httpd:2.4.38-alpine [] []  [] [] [] {map[] map[]} [] [] nil nil nil nil /dev/termination-log File IfNotPresent nil false false false}] [] Always 0xc0057179f8 <nil> ClusterFirst map[]   <nil>  false false false <nil> PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,} []   nil default-scheduler [] []  <nil> nil [] <nil> <nil> <nil> map[] []}},MinReadySeconds:0,},Status:ReplicaSetStatus{Replicas:1,FullyLabeledReplicas:1,ObservedGeneration:1,ReadyReplicas:1,AvailableReplicas:1,Conditions:[]ReplicaSetCondition{},},}
Dec 20 10:56:29.697: INFO: Pod "test-cleanup-controller-qsms2" is available:
&Pod{ObjectMeta:{test-cleanup-controller-qsms2 test-cleanup-controller- deployment-9272 /api/v1/namespaces/deployment-9272/pods/test-cleanup-controller-qsms2 af28d4b7-39f8-47ca-b38f-72b648b84066 137818 0 2019-12-20 10:56:24 +0000 UTC <nil> <nil> map[name:cleanup-pod pod:httpd] map[kubernetes.io/psp:e2e-test-privileged-psp] [{apps/v1 ReplicaSet test-cleanup-controller e0755c8e-a6b0-440d-987f-dc320e782245 0xc005717d07 0xc005717d08}] []  []},Spec:PodSpec{Volumes:[]Volume{Volume{Name:default-token-hx8ds,VolumeSource:VolumeSource{HostPath:nil,EmptyDir:nil,GCEPersistentDisk:nil,AWSElasticBlockStore:nil,GitRepo:nil,Secret:&SecretVolumeSource{SecretName:default-token-hx8ds,Items:[]KeyToPath{},DefaultMode:*420,Optional:nil,},NFS:nil,ISCSI:nil,Glusterfs:nil,PersistentVolumeClaim:nil,RBD:nil,FlexVolume:nil,Cinder:nil,CephFS:nil,Flocker:nil,DownwardAPI:nil,FC:nil,AzureFile:nil,ConfigMap:nil,VsphereVolume:nil,Quobyte:nil,AzureDisk:nil,PhotonPersistentDisk:nil,PortworxVolume:nil,ScaleIO:nil,Projected:nil,StorageOS:nil,CSI:nil,},},},Containers:[]Container{Container{Name:httpd,Image:docker.io/library/httpd:2.4.38-alpine,Command:[],Args:[],WorkingDir:,Ports:[]ContainerPort{},Env:[]EnvVar{},Resources:ResourceRequirements{Limits:ResourceList{},Requests:ResourceList{},},VolumeMounts:[]VolumeMount{VolumeMount{Name:default-token-hx8ds,ReadOnly:true,MountPath:/var/run/secrets/kubernetes.io/serviceaccount,SubPath:,MountPropagation:nil,SubPathExpr:,},},LivenessProbe:nil,ReadinessProbe:nil,Lifecycle:nil,TerminationMessagePath:/dev/termination-log,ImagePullPolicy:IfNotPresent,SecurityContext:nil,Stdin:false,StdinOnce:false,TTY:false,EnvFrom:[]EnvFromSource{},TerminationMessagePolicy:File,VolumeDevices:[]VolumeDevice{},StartupProbe:nil,},},RestartPolicy:Always,TerminationGracePeriodSeconds:*0,ActiveDeadlineSeconds:nil,DNSPolicy:ClusterFirst,NodeSelector:map[string]string{},ServiceAccountName:default,DeprecatedServiceAccount:default,NodeName:caasp-worker-th-before-0,HostNetwork:false,HostPID:false,HostIPC:false,SecurityContext:&PodSecurityContext{SELinuxOptions:nil,RunAsUser:nil,RunAsNonRoot:nil,SupplementalGroups:[],FSGroup:nil,RunAsGroup:nil,Sysctls:[]Sysctl{},WindowsOptions:nil,},ImagePullSecrets:[]LocalObjectReference{},Hostname:,Subdomain:,Affinity:nil,SchedulerName:default-scheduler,InitContainers:[]Container{},AutomountServiceAccountToken:nil,Tolerations:[]Toleration{Toleration{Key:node.kubernetes.io/not-ready,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},Toleration{Key:node.kubernetes.io/unreachable,Operator:Exists,Value:,Effect:NoExecute,TolerationSeconds:*300,},},HostAliases:[]HostAlias{},PriorityClassName:,Priority:*0,DNSConfig:nil,ShareProcessNamespace:nil,ReadinessGates:[]PodReadinessGate{},RuntimeClassName:nil,EnableServiceLinks:*true,PreemptionPolicy:nil,Overhead:ResourceList{},TopologySpreadConstraints:[]TopologySpreadConstraint{},EphemeralContainers:[]EphemeralContainer{},},Status:PodStatus{Phase:Running,Conditions:[]PodCondition{PodCondition{Type:Initialized,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 10:56:25 +0000 UTC,Reason:,Message:,},PodCondition{Type:Ready,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 10:56:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:ContainersReady,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 10:56:27 +0000 UTC,Reason:,Message:,},PodCondition{Type:PodScheduled,Status:True,LastProbeTime:0001-01-01 00:00:00 +0000 UTC,LastTransitionTime:2019-12-20 10:56:24 +0000 UTC,Reason:,Message:,},},Message:,Reason:,HostIP:10.84.149.223,PodIP:10.244.7.29,StartTime:2019-12-20 10:56:25 +0000 UTC,ContainerStatuses:[]ContainerStatus{ContainerStatus{Name:httpd,State:ContainerState{Waiting:nil,Running:&ContainerStateRunning{StartedAt:2019-12-20 10:56:27 +0000 UTC,},Terminated:nil,},LastTerminationState:ContainerState{Waiting:nil,Running:nil,Terminated:nil,},Ready:true,RestartCount:0,Image:docker.io/library/httpd:2.4.38-alpine,ImageID:docker.io/library/httpd@sha256:6feb0ea7b0967367da66e8d58ba813fde32bdb92f63bfc21a9e170d211539db4,ContainerID:cri-o://4faed00807d746fe1b751a0cac04cef53cd42cfee004b8118279c2484b78271b,Started:*true,},},QOSClass:BestEffort,InitContainerStatuses:[]ContainerStatus{},NominatedNodeName:,PodIPs:[]PodIP{PodIP{IP:10.244.7.29,},},EphemeralContainerStatuses:[]ContainerStatus{},},}
[AfterEach] [sig-apps] Deployment
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:56:29.697: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "deployment-9272" for this suite.
Dec 20 10:56:35.711: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:56:35.805: INFO: namespace deployment-9272 deletion completed in 6.104160767s

• [SLOW TEST:11.272 seconds]
[sig-apps] Deployment
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  deployment should delete old replica sets [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:56:35.805: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-9547
STEP: Waiting for a default service account to be provisioned in namespace
[It] should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for all pods to be garbage collected
STEP: Gathering metrics
Dec 20 10:56:45.963: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W1220 10:56:45.963437      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 20 10:56:45.963: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-9547" for this suite.
Dec 20 10:56:51.980: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:56:52.075: INFO: namespace gc-9547 deletion completed in 6.108939634s

• [SLOW TEST:16.270 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should delete pods created by rc when not orphaning [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Kubectl run job 
  should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:56:52.076: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-5936
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Kubectl run job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1595
[It] should create a job from an image when restart is OnFailure  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: running the image docker.io/library/httpd:2.4.38-alpine
Dec 20 10:56:52.210: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 run e2e-test-httpd-job --restart=OnFailure --generator=job/v1 --image=docker.io/library/httpd:2.4.38-alpine --namespace=kubectl-5936'
Dec 20 10:56:52.392: INFO: stderr: "kubectl run --generator=job/v1 is DEPRECATED and will be removed in a future version. Use kubectl run --generator=run-pod/v1 or kubectl create instead.\n"
Dec 20 10:56:52.392: INFO: stdout: "job.batch/e2e-test-httpd-job created\n"
STEP: verifying the job e2e-test-httpd-job was created
[AfterEach] Kubectl run job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1600
Dec 20 10:56:52.394: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 delete jobs e2e-test-httpd-job --namespace=kubectl-5936'
Dec 20 10:56:52.491: INFO: stderr: ""
Dec 20 10:56:52.491: INFO: stdout: "job.batch \"e2e-test-httpd-job\" deleted\n"
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:56:52.491: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-5936" for this suite.
Dec 20 10:57:04.505: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:57:04.605: INFO: namespace kubectl-5936 deletion completed in 12.109801013s

• [SLOW TEST:12.529 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Kubectl run job
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:1591
    should create a job from an image when restart is OnFailure  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:57:04.605: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-3549
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-3549
[It] should perform rolling updates and roll backs of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec 20 10:57:04.747: INFO: Found 0 stateful pods, waiting for 3
Dec 20 10:57:14.752: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 10:57:14.752: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 10:57:14.752: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 10:57:14.762: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-3549 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 20 10:57:14.931: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 20 10:57:14.931: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 20 10:57:14.931: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

STEP: Updating StatefulSet template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec 20 10:57:24.960: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Updating Pods in reverse ordinal order
Dec 20 10:57:34.978: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-3549 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 10:57:35.145: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 20 10:57:35.145: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 20 10:57:35.145: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 20 10:57:45.167: INFO: Waiting for StatefulSet statefulset-3549/ss2 to complete update
Dec 20 10:57:45.167: INFO: Waiting for Pod statefulset-3549/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 20 10:57:45.167: INFO: Waiting for Pod statefulset-3549/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 20 10:57:45.167: INFO: Waiting for Pod statefulset-3549/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 20 10:57:55.178: INFO: Waiting for StatefulSet statefulset-3549/ss2 to complete update
Dec 20 10:57:55.178: INFO: Waiting for Pod statefulset-3549/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 20 10:57:55.178: INFO: Waiting for Pod statefulset-3549/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 20 10:58:05.174: INFO: Waiting for StatefulSet statefulset-3549/ss2 to complete update
Dec 20 10:58:05.174: INFO: Waiting for Pod statefulset-3549/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 20 10:58:15.178: INFO: Waiting for StatefulSet statefulset-3549/ss2 to complete update
Dec 20 10:58:15.178: INFO: Waiting for Pod statefulset-3549/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 20 10:58:25.175: INFO: Waiting for StatefulSet statefulset-3549/ss2 to complete update
STEP: Rolling back to a previous revision
Dec 20 10:58:35.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-3549 ss2-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 20 10:58:35.362: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 20 10:58:35.362: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 20 10:58:35.362: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss2-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 20 10:58:45.395: INFO: Updating stateful set ss2
STEP: Rolling back update in reverse ordinal order
Dec 20 10:58:55.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-3549 ss2-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 10:58:55.599: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 20 10:58:55.599: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 20 10:58:55.599: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss2-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 20 10:59:15.620: INFO: Deleting all statefulset in ns statefulset-3549
Dec 20 10:59:15.623: INFO: Scaling statefulset ss2 to 0
Dec 20 10:59:35.637: INFO: Waiting for statefulset status.replicas updated to 0
Dec 20 10:59:35.640: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:59:35.652: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-3549" for this suite.
Dec 20 10:59:41.665: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:59:41.750: INFO: namespace statefulset-3549 deletion completed in 6.094680174s

• [SLOW TEST:157.145 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform rolling updates and roll backs of template modifications [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:59:41.750: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6291
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 20 10:59:41.884: INFO: Waiting up to 5m0s for pod "downwardapi-volume-0e7f7c3f-ac6e-48b6-93fc-4922563da8c6" in namespace "projected-6291" to be "success or failure"
Dec 20 10:59:41.886: INFO: Pod "downwardapi-volume-0e7f7c3f-ac6e-48b6-93fc-4922563da8c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.263534ms
Dec 20 10:59:43.889: INFO: Pod "downwardapi-volume-0e7f7c3f-ac6e-48b6-93fc-4922563da8c6": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005805064s
Dec 20 10:59:45.893: INFO: Pod "downwardapi-volume-0e7f7c3f-ac6e-48b6-93fc-4922563da8c6": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009894713s
STEP: Saw pod success
Dec 20 10:59:45.894: INFO: Pod "downwardapi-volume-0e7f7c3f-ac6e-48b6-93fc-4922563da8c6" satisfied condition "success or failure"
Dec 20 10:59:45.897: INFO: Trying to get logs from node caasp-worker-th-before-3 pod downwardapi-volume-0e7f7c3f-ac6e-48b6-93fc-4922563da8c6 container client-container: <nil>
STEP: delete the pod
Dec 20 10:59:45.923: INFO: Waiting for pod downwardapi-volume-0e7f7c3f-ac6e-48b6-93fc-4922563da8c6 to disappear
Dec 20 10:59:45.925: INFO: Pod downwardapi-volume-0e7f7c3f-ac6e-48b6-93fc-4922563da8c6 no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:59:45.925: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6291" for this suite.
Dec 20 10:59:51.938: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 10:59:52.037: INFO: namespace projected-6291 deletion completed in 6.109546243s

• [SLOW TEST:10.288 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir wrapper volumes 
  should not conflict [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 10:59:52.038: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename emptydir-wrapper
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-wrapper-3255
STEP: Waiting for a default service account to be provisioned in namespace
[It] should not conflict [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Cleaning up the secret
STEP: Cleaning up the configmap
STEP: Cleaning up the pod
[AfterEach] [sig-storage] EmptyDir wrapper volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 10:59:56.212: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-wrapper-3255" for this suite.
Dec 20 11:00:02.228: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 11:00:02.318: INFO: namespace emptydir-wrapper-3255 deletion completed in 6.101969092s

• [SLOW TEST:10.280 seconds]
[sig-storage] EmptyDir wrapper volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  should not conflict [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-network] Services 
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 11:00:02.319: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename services
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in services-3221
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:91
[It] should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating a service externalname-service with the type=ExternalName in namespace services-3221
STEP: changing the ExternalName service to type=ClusterIP
STEP: creating replication controller externalname-service in namespace services-3221
I1220 11:00:02.476321      26 runners.go:184] Created replication controller with name: externalname-service, namespace: services-3221, replica count: 2
Dec 20 11:00:05.526: INFO: Creating new exec pod
I1220 11:00:05.526771      26 runners.go:184] externalname-service Pods: 2 out of 2 created, 2 running, 0 pending, 0 waiting, 0 inactive, 0 terminating, 0 unknown, 0 runningButNotReady 
Dec 20 11:00:10.540: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=services-3221 execpodxtgj5 -- /bin/sh -x -c nc -zv -t -w 2 externalname-service 80'
Dec 20 11:00:10.724: INFO: stderr: "+ nc -zv -t -w 2 externalname-service 80\nConnection to externalname-service 80 port [tcp/http] succeeded!\n"
Dec 20 11:00:10.724: INFO: stdout: ""
Dec 20 11:00:10.725: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=services-3221 execpodxtgj5 -- /bin/sh -x -c nc -zv -t -w 2 10.97.5.47 80'
Dec 20 11:00:10.892: INFO: stderr: "+ nc -zv -t -w 2 10.97.5.47 80\nConnection to 10.97.5.47 80 port [tcp/http] succeeded!\n"
Dec 20 11:00:10.892: INFO: stdout: ""
Dec 20 11:00:10.892: INFO: Cleaning up the ExternalName to ClusterIP test service
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 11:00:10.911: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "services-3221" for this suite.
Dec 20 11:00:16.925: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 11:00:17.024: INFO: namespace services-3221 deletion completed in 6.109702401s
[AfterEach] [sig-network] Services
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/service.go:95

• [SLOW TEST:14.706 seconds]
[sig-network] Services
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should be able to change the type from ExternalName to ClusterIP [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 11:00:17.025: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-6885
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-6885
[It] should perform canary updates and phased rolling updates of template modifications [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a new StatefulSet
Dec 20 11:00:17.165: INFO: Found 0 stateful pods, waiting for 3
Dec 20 11:00:27.171: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 11:00:27.171: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 11:00:27.171: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Updating stateful set template: update image from docker.io/library/httpd:2.4.38-alpine to docker.io/library/httpd:2.4.39-alpine
Dec 20 11:00:27.196: INFO: Updating stateful set ss2
STEP: Creating a new revision
STEP: Not applying an update when the partition is greater than the number of replicas
STEP: Performing a canary update
Dec 20 11:00:37.229: INFO: Updating stateful set ss2
Dec 20 11:00:37.235: INFO: Waiting for Pod statefulset-6885/ss2-2 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
STEP: Restoring Pods to the correct revision when they are deleted
Dec 20 11:00:47.262: INFO: Found 1 stateful pods, waiting for 3
Dec 20 11:00:57.267: INFO: Waiting for pod ss2-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 11:00:57.267: INFO: Waiting for pod ss2-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 11:00:57.267: INFO: Waiting for pod ss2-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Performing a phased rolling update
Dec 20 11:00:57.290: INFO: Updating stateful set ss2
Dec 20 11:00:57.296: INFO: Waiting for Pod statefulset-6885/ss2-1 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
Dec 20 11:01:07.321: INFO: Updating stateful set ss2
Dec 20 11:01:07.326: INFO: Waiting for StatefulSet statefulset-6885/ss2 to complete update
Dec 20 11:01:07.326: INFO: Waiting for Pod statefulset-6885/ss2-0 to have revision ss2-84f9d6bf57 update revision ss2-65c7964b94
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 20 11:01:17.335: INFO: Deleting all statefulset in ns statefulset-6885
Dec 20 11:01:17.338: INFO: Scaling statefulset ss2 to 0
Dec 20 11:01:37.355: INFO: Waiting for statefulset status.replicas updated to 0
Dec 20 11:01:37.358: INFO: Deleting statefulset ss2
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 11:01:37.371: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-6885" for this suite.
Dec 20 11:01:43.383: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 11:01:43.465: INFO: namespace statefulset-6885 deletion completed in 6.090536408s

• [SLOW TEST:86.440 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    should perform canary updates and phased rolling updates of template modifications [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[k8s.io] Kubelet when scheduling a busybox command in a pod 
  should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 11:01:43.465: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubelet-test
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubelet-test-7372
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:37
[It] should print the output to logs [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[AfterEach] [k8s.io] Kubelet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 11:01:47.632: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubelet-test-7372" for this suite.
Dec 20 11:02:31.646: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 11:02:31.740: INFO: namespace kubelet-test-7372 deletion completed in 44.103981389s

• [SLOW TEST:48.275 seconds]
[k8s.io] Kubelet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  when scheduling a busybox command in a pod
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/kubelet.go:40
    should print the output to logs [NodeConformance] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected downwardAPI 
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 11:02:31.740: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-4925
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:40
[It] should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test downward API volume plugin
Dec 20 11:02:31.879: INFO: Waiting up to 5m0s for pod "downwardapi-volume-7ce25228-442a-4596-bbcd-451b9a29cf9d" in namespace "projected-4925" to be "success or failure"
Dec 20 11:02:31.882: INFO: Pod "downwardapi-volume-7ce25228-442a-4596-bbcd-451b9a29cf9d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.339583ms
Dec 20 11:02:33.886: INFO: Pod "downwardapi-volume-7ce25228-442a-4596-bbcd-451b9a29cf9d": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006634627s
Dec 20 11:02:35.890: INFO: Pod "downwardapi-volume-7ce25228-442a-4596-bbcd-451b9a29cf9d": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010571621s
STEP: Saw pod success
Dec 20 11:02:35.890: INFO: Pod "downwardapi-volume-7ce25228-442a-4596-bbcd-451b9a29cf9d" satisfied condition "success or failure"
Dec 20 11:02:35.892: INFO: Trying to get logs from node caasp-worker-th-before-4 pod downwardapi-volume-7ce25228-442a-4596-bbcd-451b9a29cf9d container client-container: <nil>
STEP: delete the pod
Dec 20 11:02:35.907: INFO: Waiting for pod downwardapi-volume-7ce25228-442a-4596-bbcd-451b9a29cf9d to disappear
Dec 20 11:02:35.909: INFO: Pod downwardapi-volume-7ce25228-442a-4596-bbcd-451b9a29cf9d no longer exists
[AfterEach] [sig-storage] Projected downwardAPI
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 11:02:35.909: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-4925" for this suite.
Dec 20 11:02:41.922: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 11:02:42.019: INFO: namespace projected-4925 deletion completed in 6.106713407s

• [SLOW TEST:10.279 seconds]
[sig-storage] Projected downwardAPI
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_downwardapi.go:34
  should provide container's memory request [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] ConfigMap 
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 11:02:42.019: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename configmap
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in configmap-4897
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating configMap with name configmap-test-volume-map-bbccde24-e038-4692-807b-7600a4740967
STEP: Creating a pod to test consume configMaps
Dec 20 11:02:42.157: INFO: Waiting up to 5m0s for pod "pod-configmaps-29633c37-cd06-43cd-aee5-9c123112befd" in namespace "configmap-4897" to be "success or failure"
Dec 20 11:02:42.159: INFO: Pod "pod-configmaps-29633c37-cd06-43cd-aee5-9c123112befd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.048478ms
Dec 20 11:02:44.162: INFO: Pod "pod-configmaps-29633c37-cd06-43cd-aee5-9c123112befd": Phase="Pending", Reason="", readiness=false. Elapsed: 2.004952539s
Dec 20 11:02:46.165: INFO: Pod "pod-configmaps-29633c37-cd06-43cd-aee5-9c123112befd": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.007940489s
STEP: Saw pod success
Dec 20 11:02:46.165: INFO: Pod "pod-configmaps-29633c37-cd06-43cd-aee5-9c123112befd" satisfied condition "success or failure"
Dec 20 11:02:46.168: INFO: Trying to get logs from node caasp-worker-th-before-4 pod pod-configmaps-29633c37-cd06-43cd-aee5-9c123112befd container configmap-volume-test: <nil>
STEP: delete the pod
Dec 20 11:02:46.182: INFO: Waiting for pod pod-configmaps-29633c37-cd06-43cd-aee5-9c123112befd to disappear
Dec 20 11:02:46.185: INFO: Pod pod-configmaps-29633c37-cd06-43cd-aee5-9c123112befd no longer exists
[AfterEach] [sig-storage] ConfigMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 11:02:46.185: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "configmap-4897" for this suite.
Dec 20 11:02:52.199: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 11:02:52.288: INFO: namespace configmap-4897 deletion completed in 6.099275688s

• [SLOW TEST:10.269 seconds]
[sig-storage] ConfigMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/configmap_volume.go:34
  should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 11:02:52.288: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-3434
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with secret pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-secret-lspv
STEP: Creating a pod to test atomic-volume-subpath
Dec 20 11:02:52.430: INFO: Waiting up to 5m0s for pod "pod-subpath-test-secret-lspv" in namespace "subpath-3434" to be "success or failure"
Dec 20 11:02:52.432: INFO: Pod "pod-subpath-test-secret-lspv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.208939ms
Dec 20 11:02:54.436: INFO: Pod "pod-subpath-test-secret-lspv": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006026883s
Dec 20 11:02:56.441: INFO: Pod "pod-subpath-test-secret-lspv": Phase="Running", Reason="", readiness=true. Elapsed: 4.010428102s
Dec 20 11:02:58.445: INFO: Pod "pod-subpath-test-secret-lspv": Phase="Running", Reason="", readiness=true. Elapsed: 6.014628422s
Dec 20 11:03:00.448: INFO: Pod "pod-subpath-test-secret-lspv": Phase="Running", Reason="", readiness=true. Elapsed: 8.018169899s
Dec 20 11:03:02.453: INFO: Pod "pod-subpath-test-secret-lspv": Phase="Running", Reason="", readiness=true. Elapsed: 10.02258613s
Dec 20 11:03:04.457: INFO: Pod "pod-subpath-test-secret-lspv": Phase="Running", Reason="", readiness=true. Elapsed: 12.026359307s
Dec 20 11:03:06.460: INFO: Pod "pod-subpath-test-secret-lspv": Phase="Running", Reason="", readiness=true. Elapsed: 14.02983077s
Dec 20 11:03:08.464: INFO: Pod "pod-subpath-test-secret-lspv": Phase="Running", Reason="", readiness=true. Elapsed: 16.033630886s
Dec 20 11:03:10.468: INFO: Pod "pod-subpath-test-secret-lspv": Phase="Running", Reason="", readiness=true. Elapsed: 18.037406703s
Dec 20 11:03:12.473: INFO: Pod "pod-subpath-test-secret-lspv": Phase="Running", Reason="", readiness=true. Elapsed: 20.04288713s
Dec 20 11:03:14.476: INFO: Pod "pod-subpath-test-secret-lspv": Phase="Running", Reason="", readiness=true. Elapsed: 22.04606902s
Dec 20 11:03:16.481: INFO: Pod "pod-subpath-test-secret-lspv": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.050319109s
STEP: Saw pod success
Dec 20 11:03:16.481: INFO: Pod "pod-subpath-test-secret-lspv" satisfied condition "success or failure"
Dec 20 11:03:16.483: INFO: Trying to get logs from node caasp-worker-th-before-4 pod pod-subpath-test-secret-lspv container test-container-subpath-secret-lspv: <nil>
STEP: delete the pod
Dec 20 11:03:16.497: INFO: Waiting for pod pod-subpath-test-secret-lspv to disappear
Dec 20 11:03:16.499: INFO: Pod pod-subpath-test-secret-lspv no longer exists
STEP: Deleting pod pod-subpath-test-secret-lspv
Dec 20 11:03:16.499: INFO: Deleting pod "pod-subpath-test-secret-lspv" in namespace "subpath-3434"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 11:03:16.502: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-3434" for this suite.
Dec 20 11:03:22.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 11:03:22.613: INFO: namespace subpath-3434 deletion completed in 6.107557552s

• [SLOW TEST:30.324 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with secret pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSS
------------------------------
[sig-apps] StatefulSet [k8s.io] Basic StatefulSet functionality [StatefulSetBasic] 
  Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 11:03:22.613: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename statefulset
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in statefulset-912
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:62
[BeforeEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:77
STEP: Creating service test in namespace statefulset-912
[It] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating stateful set ss in namespace statefulset-912
STEP: Waiting until all stateful set ss replicas will be running in namespace statefulset-912
Dec 20 11:03:22.756: INFO: Found 0 stateful pods, waiting for 1
Dec 20 11:03:32.761: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
STEP: Confirming that stateful set scale up will not halt with unhealthy stateful pod
Dec 20 11:03:32.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 20 11:03:32.928: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 20 11:03:32.928: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 20 11:03:32.928: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 20 11:03:32.932: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=true
Dec 20 11:03:42.936: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 20 11:03:42.936: INFO: Waiting for statefulset status.replicas updated to 0
Dec 20 11:03:42.947: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Dec 20 11:03:42.947: INFO: ss-0  caasp-worker-th-before-4  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:34 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:22 +0000 UTC  }]
Dec 20 11:03:42.947: INFO: 
Dec 20 11:03:42.947: INFO: StatefulSet ss has not reached scale 3, at 1
Dec 20 11:03:43.952: INFO: Verifying statefulset ss doesn't scale past 3 for another 8.997342215s
Dec 20 11:03:44.956: INFO: Verifying statefulset ss doesn't scale past 3 for another 7.99186318s
Dec 20 11:03:45.961: INFO: Verifying statefulset ss doesn't scale past 3 for another 6.988100594s
Dec 20 11:03:46.966: INFO: Verifying statefulset ss doesn't scale past 3 for another 5.983635677s
Dec 20 11:03:47.971: INFO: Verifying statefulset ss doesn't scale past 3 for another 4.978805967s
Dec 20 11:03:48.977: INFO: Verifying statefulset ss doesn't scale past 3 for another 3.973233967s
Dec 20 11:03:49.983: INFO: Verifying statefulset ss doesn't scale past 3 for another 2.967582053s
Dec 20 11:03:50.997: INFO: Verifying statefulset ss doesn't scale past 3 for another 1.960827208s
Dec 20 11:03:52.002: INFO: Verifying statefulset ss doesn't scale past 3 for another 946.933125ms
STEP: Scaling up stateful set ss to 3 replicas and waiting until all of them will be running in namespace statefulset-912
Dec 20 11:03:53.008: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:03:53.182: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\n"
Dec 20 11:03:53.182: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 20 11:03:53.182: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 20 11:03:53.182: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-1 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:03:53.355: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 20 11:03:53.355: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 20 11:03:53.355: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-1: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 20 11:03:53.355: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-2 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:03:53.515: INFO: stderr: "+ mv -v /tmp/index.html /usr/local/apache2/htdocs/\nmv: can't rename '/tmp/index.html': No such file or directory\n+ true\n"
Dec 20 11:03:53.515: INFO: stdout: "'/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'\n"
Dec 20 11:03:53.515: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-2: '/tmp/index.html' -> '/usr/local/apache2/htdocs/index.html'

Dec 20 11:03:53.518: INFO: Waiting for pod ss-0 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 11:03:53.518: INFO: Waiting for pod ss-1 to enter Running - Ready=true, currently Running - Ready=true
Dec 20 11:03:53.518: INFO: Waiting for pod ss-2 to enter Running - Ready=true, currently Running - Ready=true
STEP: Scale down will not halt with unhealthy stateful pod
Dec 20 11:03:53.521: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 20 11:03:53.689: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 20 11:03:53.689: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 20 11:03:53.689: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-0: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 20 11:03:53.689: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-1 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 20 11:03:53.849: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 20 11:03:53.849: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 20 11:03:53.849: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-1: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 20 11:03:53.849: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-2 -- /bin/sh -x -c mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true'
Dec 20 11:03:54.010: INFO: stderr: "+ mv -v /usr/local/apache2/htdocs/index.html /tmp/\n"
Dec 20 11:03:54.010: INFO: stdout: "'/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'\n"
Dec 20 11:03:54.010: INFO: stdout of mv -v /usr/local/apache2/htdocs/index.html /tmp/ || true on ss-2: '/usr/local/apache2/htdocs/index.html' -> '/tmp/index.html'

Dec 20 11:03:54.010: INFO: Waiting for statefulset status.replicas updated to 0
Dec 20 11:03:54.013: INFO: Waiting for stateful set status.readyReplicas to become 0, currently 3
Dec 20 11:04:04.022: INFO: Waiting for pod ss-0 to enter Running - Ready=false, currently Running - Ready=false
Dec 20 11:04:04.022: INFO: Waiting for pod ss-1 to enter Running - Ready=false, currently Running - Ready=false
Dec 20 11:04:04.022: INFO: Waiting for pod ss-2 to enter Running - Ready=false, currently Running - Ready=false
Dec 20 11:04:04.031: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Dec 20 11:04:04.031: INFO: ss-0  caasp-worker-th-before-4  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:22 +0000 UTC  }]
Dec 20 11:04:04.031: INFO: ss-1  caasp-worker-th-before-0  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:42 +0000 UTC  }]
Dec 20 11:04:04.031: INFO: ss-2  caasp-worker-th-before-3  Running         [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:42 +0000 UTC  }]
Dec 20 11:04:04.031: INFO: 
Dec 20 11:04:04.031: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 20 11:04:05.036: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Dec 20 11:04:05.036: INFO: ss-0  caasp-worker-th-before-4  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:22 +0000 UTC  }]
Dec 20 11:04:05.036: INFO: ss-1  caasp-worker-th-before-0  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:42 +0000 UTC  }]
Dec 20 11:04:05.036: INFO: ss-2  caasp-worker-th-before-3  Running  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:43 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:42 +0000 UTC  }]
Dec 20 11:04:05.036: INFO: 
Dec 20 11:04:05.036: INFO: StatefulSet ss has not reached scale 0, at 3
Dec 20 11:04:06.041: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Dec 20 11:04:06.041: INFO: ss-0  caasp-worker-th-before-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:22 +0000 UTC  }]
Dec 20 11:04:06.041: INFO: ss-1  caasp-worker-th-before-0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:42 +0000 UTC  }]
Dec 20 11:04:06.041: INFO: 
Dec 20 11:04:06.041: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 20 11:04:07.045: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Dec 20 11:04:07.045: INFO: ss-0  caasp-worker-th-before-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:22 +0000 UTC  }]
Dec 20 11:04:07.045: INFO: ss-1  caasp-worker-th-before-0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:42 +0000 UTC  }]
Dec 20 11:04:07.045: INFO: 
Dec 20 11:04:07.045: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 20 11:04:08.049: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Dec 20 11:04:08.049: INFO: ss-0  caasp-worker-th-before-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:22 +0000 UTC  }]
Dec 20 11:04:08.049: INFO: ss-1  caasp-worker-th-before-0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:42 +0000 UTC  }]
Dec 20 11:04:08.049: INFO: 
Dec 20 11:04:08.049: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 20 11:04:09.053: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Dec 20 11:04:09.053: INFO: ss-0  caasp-worker-th-before-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:22 +0000 UTC  }]
Dec 20 11:04:09.053: INFO: ss-1  caasp-worker-th-before-0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:42 +0000 UTC  }]
Dec 20 11:04:09.053: INFO: 
Dec 20 11:04:09.053: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 20 11:04:10.057: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Dec 20 11:04:10.057: INFO: ss-0  caasp-worker-th-before-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:22 +0000 UTC  }]
Dec 20 11:04:10.057: INFO: ss-1  caasp-worker-th-before-0  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:44 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:42 +0000 UTC  }]
Dec 20 11:04:10.057: INFO: 
Dec 20 11:04:10.057: INFO: StatefulSet ss has not reached scale 0, at 2
Dec 20 11:04:11.061: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Dec 20 11:04:11.061: INFO: ss-0  caasp-worker-th-before-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:22 +0000 UTC  }]
Dec 20 11:04:11.061: INFO: 
Dec 20 11:04:11.061: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 20 11:04:12.065: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Dec 20 11:04:12.065: INFO: ss-0  caasp-worker-th-before-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:22 +0000 UTC  }]
Dec 20 11:04:12.065: INFO: 
Dec 20 11:04:12.065: INFO: StatefulSet ss has not reached scale 0, at 1
Dec 20 11:04:13.070: INFO: POD   NODE                      PHASE    GRACE  CONDITIONS
Dec 20 11:04:13.070: INFO: ss-0  caasp-worker-th-before-4  Pending  30s    [{Initialized True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:23 +0000 UTC  } {Ready False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {ContainersReady False 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:55 +0000 UTC ContainersNotReady containers with unready status: [webserver]} {PodScheduled True 0001-01-01 00:00:00 +0000 UTC 2019-12-20 11:03:22 +0000 UTC  }]
Dec 20 11:04:13.070: INFO: 
Dec 20 11:04:13.070: INFO: StatefulSet ss has not reached scale 0, at 1
STEP: Scaling down stateful set ss to 0 replicas and waiting until none of pods will run in namespacestatefulset-912
Dec 20 11:04:14.076: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:04:14.229: INFO: rc: 1
Dec 20 11:04:14.229: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  error: unable to upgrade connection: container not found ("webserver")
 [] <nil> 0xc00209aed0 exit status 1 <nil> <nil> true [0xc0000ffdd8 0xc002ad6000 0xc002ad6048] [0xc0000ffdd8 0xc002ad6000 0xc002ad6048] [0xc0000fff38 0xc002ad6038] [0x10efce0 0x10efce0] 0xc00381f380 <nil>}:
Command stdout:

stderr:
error: unable to upgrade connection: container not found ("webserver")

error:
exit status 1
Dec 20 11:04:24.229: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:04:24.331: INFO: rc: 1
Dec 20 11:04:24.331: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002466270 exit status 1 <nil> <nil> true [0xc000c473e8 0xc000c47658 0xc000c477e8] [0xc000c473e8 0xc000c47658 0xc000c477e8] [0xc000c47548 0xc000c476f8] [0x10efce0 0x10efce0] 0xc0040066c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:04:34.331: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:04:34.439: INFO: rc: 1
Dec 20 11:04:34.439: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00682ad80 exit status 1 <nil> <nil> true [0xc000dac098 0xc000dac0b0 0xc000dac0c8] [0xc000dac098 0xc000dac0b0 0xc000dac0c8] [0xc000dac0a8 0xc000dac0c0] [0x10efce0 0x10efce0] 0xc003e5aa20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:04:44.440: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:04:44.543: INFO: rc: 1
Dec 20 11:04:44.543: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00682b110 exit status 1 <nil> <nil> true [0xc000dac0d0 0xc000dac0e8 0xc000dac100] [0xc000dac0d0 0xc000dac0e8 0xc000dac100] [0xc000dac0e0 0xc000dac0f8] [0x10efce0 0x10efce0] 0xc003e5ae40 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:04:54.543: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:04:54.639: INFO: rc: 1
Dec 20 11:04:54.639: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00209b350 exit status 1 <nil> <nil> true [0xc002ad6068 0xc002ad6098 0xc002ad60e0] [0xc002ad6068 0xc002ad6098 0xc002ad60e0] [0xc002ad6088 0xc002ad60c0] [0x10efce0 0x10efce0] 0xc00381f920 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:05:04.639: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:05:04.737: INFO: rc: 1
Dec 20 11:05:04.737: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc002466600 exit status 1 <nil> <nil> true [0xc000c477f8 0xc000c47918 0xc000c47a18] [0xc000c477f8 0xc000c47918 0xc000c47a18] [0xc000c47820 0xc000c47a08] [0x10efce0 0x10efce0] 0xc004006a80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:05:14.737: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:05:14.832: INFO: rc: 1
Dec 20 11:05:14.832: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00209b860 exit status 1 <nil> <nil> true [0xc002ad60f0 0xc002ad6130 0xc002ad6168] [0xc002ad60f0 0xc002ad6130 0xc002ad6168] [0xc002ad6120 0xc002ad6158] [0x10efce0 0x10efce0] 0xc00381fc80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:05:24.832: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:05:24.965: INFO: rc: 1
Dec 20 11:05:24.965: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc008238360 exit status 1 <nil> <nil> true [0xc001e2e000 0xc001e2e018 0xc001e2e030] [0xc001e2e000 0xc001e2e018 0xc001e2e030] [0xc001e2e010 0xc001e2e028] [0x10efce0 0x10efce0] 0xc002be2d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:05:34.966: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:05:35.057: INFO: rc: 1
Dec 20 11:05:35.057: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00209bbc0 exit status 1 <nil> <nil> true [0xc002ad6180 0xc002ad61b0 0xc002ad61f0] [0xc002ad6180 0xc002ad61b0 0xc002ad61f0] [0xc002ad61a0 0xc002ad61e0] [0x10efce0 0x10efce0] 0xc0046882a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:05:45.058: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:05:45.158: INFO: rc: 1
Dec 20 11:05:45.158: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00209bf50 exit status 1 <nil> <nil> true [0xc002ad6208 0xc002ad6238 0xc002ad6280] [0xc002ad6208 0xc002ad6238 0xc002ad6280] [0xc002ad6228 0xc002ad6270] [0x10efce0 0x10efce0] 0xc004688780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:05:55.158: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:05:55.254: INFO: rc: 1
Dec 20 11:05:55.254: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0007d2f60 exit status 1 <nil> <nil> true [0xc002ad6290 0xc002ad62d8 0xc002ad6308] [0xc002ad6290 0xc002ad62d8 0xc002ad6308] [0xc002ad62b0 0xc002ad62f8] [0x10efce0 0x10efce0] 0xc004688ba0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:06:05.254: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:06:05.345: INFO: rc: 1
Dec 20 11:06:05.345: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00209a390 exit status 1 <nil> <nil> true [0xc0000fe298 0xc0000fe688 0xc0000fed28] [0xc0000fe298 0xc0000fe688 0xc0000fed28] [0xc0000fe670 0xc0000fea08] [0x10efce0 0x10efce0] 0xc00381e2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:06:15.346: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:06:15.436: INFO: rc: 1
Dec 20 11:06:15.436: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc005a80330 exit status 1 <nil> <nil> true [0xc001e2e000 0xc001e2e018 0xc001e2e030] [0xc001e2e000 0xc001e2e018 0xc001e2e030] [0xc001e2e010 0xc001e2e028] [0x10efce0 0x10efce0] 0xc002be2d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:06:25.437: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:06:25.554: INFO: rc: 1
Dec 20 11:06:25.554: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc005a80690 exit status 1 <nil> <nil> true [0xc001e2e038 0xc001e2e050 0xc001e2e068] [0xc001e2e038 0xc001e2e050 0xc001e2e068] [0xc001e2e048 0xc001e2e060] [0x10efce0 0x10efce0] 0xc0046881e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:06:35.555: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:06:35.661: INFO: rc: 1
Dec 20 11:06:35.662: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc005a809f0 exit status 1 <nil> <nil> true [0xc001e2e070 0xc001e2e088 0xc001e2e0a0] [0xc001e2e070 0xc001e2e088 0xc001e2e0a0] [0xc001e2e080 0xc001e2e098] [0x10efce0 0x10efce0] 0xc004688660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:06:45.662: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:06:45.763: INFO: rc: 1
Dec 20 11:06:45.764: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021bc7b0 exit status 1 <nil> <nil> true [0xc002ad6000 0xc002ad6048 0xc002ad6088] [0xc002ad6000 0xc002ad6048 0xc002ad6088] [0xc002ad6038 0xc002ad6078] [0x10efce0 0x10efce0] 0xc0040062a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:06:55.764: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:06:55.896: INFO: rc: 1
Dec 20 11:06:55.896: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021bcb40 exit status 1 <nil> <nil> true [0xc002ad6098 0xc002ad60e0 0xc002ad6120] [0xc002ad6098 0xc002ad60e0 0xc002ad6120] [0xc002ad60c0 0xc002ad6110] [0x10efce0 0x10efce0] 0xc004006600 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:07:05.896: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:07:05.990: INFO: rc: 1
Dec 20 11:07:05.990: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021bcf00 exit status 1 <nil> <nil> true [0xc002ad6130 0xc002ad6168 0xc002ad61a0] [0xc002ad6130 0xc002ad6168 0xc002ad61a0] [0xc002ad6158 0xc002ad6190] [0x10efce0 0x10efce0] 0xc0040069c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:07:15.990: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:07:16.084: INFO: rc: 1
Dec 20 11:07:16.084: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0035e4360 exit status 1 <nil> <nil> true [0xc000c46028 0xc000c46338 0xc000c467c0] [0xc000c46028 0xc000c46338 0xc000c467c0] [0xc000c461a8 0xc000c46548] [0x10efce0 0x10efce0] 0xc003e5a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:07:26.084: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:07:26.176: INFO: rc: 1
Dec 20 11:07:26.177: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc005a80de0 exit status 1 <nil> <nil> true [0xc001e2e0a8 0xc001e2e0c0 0xc001e2e0d8] [0xc001e2e0a8 0xc001e2e0c0 0xc001e2e0d8] [0xc001e2e0b8 0xc001e2e0d0] [0x10efce0 0x10efce0] 0xc004688a20 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:07:36.177: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:07:36.280: INFO: rc: 1
Dec 20 11:07:36.280: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc005a81140 exit status 1 <nil> <nil> true [0xc001e2e0e0 0xc001e2e0f8 0xc001e2e110] [0xc001e2e0e0 0xc001e2e0f8 0xc001e2e110] [0xc001e2e0f0 0xc001e2e108] [0x10efce0 0x10efce0] 0xc004688ea0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:07:46.281: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:07:46.376: INFO: rc: 1
Dec 20 11:07:46.376: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0035e48a0 exit status 1 <nil> <nil> true [0xc000c46a08 0xc000c46de8 0xc000c47170] [0xc000c46a08 0xc000c46de8 0xc000c47170] [0xc000c46b30 0xc000c46fa0] [0x10efce0 0x10efce0] 0xc003e5a660 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:07:56.376: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:07:56.466: INFO: rc: 1
Dec 20 11:07:56.466: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc008238180 exit status 1 <nil> <nil> true [0xc001e2e118 0xc001e2e130 0xc001e2e148] [0xc001e2e118 0xc001e2e130 0xc001e2e148] [0xc001e2e128 0xc001e2e140] [0x10efce0 0x10efce0] 0xc004689200 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:08:06.467: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:08:06.569: INFO: rc: 1
Dec 20 11:08:06.569: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc005a80360 exit status 1 <nil> <nil> true [0xc001e2e000 0xc001e2e018 0xc001e2e030] [0xc001e2e000 0xc001e2e018 0xc001e2e030] [0xc001e2e010 0xc001e2e028] [0x10efce0 0x10efce0] 0xc002be2d80 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:08:16.570: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:08:16.672: INFO: rc: 1
Dec 20 11:08:16.673: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc008238360 exit status 1 <nil> <nil> true [0xc002ad6000 0xc002ad6048 0xc002ad6088] [0xc002ad6000 0xc002ad6048 0xc002ad6088] [0xc002ad6038 0xc002ad6078] [0x10efce0 0x10efce0] 0xc0046882a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:08:26.673: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:08:26.766: INFO: rc: 1
Dec 20 11:08:26.766: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0082386f0 exit status 1 <nil> <nil> true [0xc002ad6098 0xc002ad60e0 0xc002ad6120] [0xc002ad6098 0xc002ad60e0 0xc002ad6120] [0xc002ad60c0 0xc002ad6110] [0x10efce0 0x10efce0] 0xc004688780 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:08:36.766: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:08:36.856: INFO: rc: 1
Dec 20 11:08:36.856: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc005a80720 exit status 1 <nil> <nil> true [0xc001e2e038 0xc001e2e050 0xc001e2e068] [0xc001e2e038 0xc001e2e050 0xc001e2e068] [0xc001e2e048 0xc001e2e060] [0x10efce0 0x10efce0] 0xc0040061e0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:08:46.857: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:08:46.948: INFO: rc: 1
Dec 20 11:08:46.948: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021bc7e0 exit status 1 <nil> <nil> true [0xc0000fe298 0xc0000fe688 0xc0000fed28] [0xc0000fe298 0xc0000fe688 0xc0000fed28] [0xc0000fe670 0xc0000fea08] [0x10efce0 0x10efce0] 0xc00381e2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:08:56.948: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:08:57.042: INFO: rc: 1
Dec 20 11:08:57.042: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc0021bcb70 exit status 1 <nil> <nil> true [0xc0000fedd8 0xc0000fefd8 0xc0000ff1a0] [0xc0000fedd8 0xc0000fefd8 0xc0000ff1a0] [0xc0000fef58 0xc0000ff068] [0x10efce0 0x10efce0] 0xc00381e6c0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:09:07.042: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:09:07.146: INFO: rc: 1
Dec 20 11:09:07.146: INFO: Waiting 10s to retry failed RunHostCmd: error running &{/usr/local/bin/kubectl [kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true] []  <nil>  Error from server (NotFound): pods "ss-0" not found
 [] <nil> 0xc00209a3c0 exit status 1 <nil> <nil> true [0xc000c46028 0xc000c46338 0xc000c467c0] [0xc000c46028 0xc000c46338 0xc000c467c0] [0xc000c461a8 0xc000c46548] [0x10efce0 0x10efce0] 0xc003e5a2a0 <nil>}:
Command stdout:

stderr:
Error from server (NotFound): pods "ss-0" not found

error:
exit status 1
Dec 20 11:09:17.146: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 exec --namespace=statefulset-912 ss-0 -- /bin/sh -x -c mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true'
Dec 20 11:09:17.232: INFO: rc: 1
Dec 20 11:09:17.232: INFO: stdout of mv -v /tmp/index.html /usr/local/apache2/htdocs/ || true on ss-0: 
Dec 20 11:09:17.232: INFO: Scaling statefulset ss to 0
Dec 20 11:09:17.243: INFO: Waiting for statefulset status.replicas updated to 0
[AfterEach] [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/statefulset.go:88
Dec 20 11:09:17.246: INFO: Deleting all statefulset in ns statefulset-912
Dec 20 11:09:17.249: INFO: Scaling statefulset ss to 0
Dec 20 11:09:17.258: INFO: Waiting for statefulset status.replicas updated to 0
Dec 20 11:09:17.260: INFO: Deleting statefulset ss
[AfterEach] [sig-apps] StatefulSet
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 11:09:17.271: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "statefulset-912" for this suite.
Dec 20 11:09:23.284: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 11:09:23.383: INFO: namespace statefulset-912 deletion completed in 6.108159292s

• [SLOW TEST:360.770 seconds]
[sig-apps] StatefulSet
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apps/framework.go:23
  [k8s.io] Basic StatefulSet functionality [StatefulSetBasic]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
    Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 11:09:23.383: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-5604
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0644 on tmpfs
Dec 20 11:09:23.524: INFO: Waiting up to 5m0s for pod "pod-469249fb-ef06-457b-b9b2-ac542f05b411" in namespace "emptydir-5604" to be "success or failure"
Dec 20 11:09:23.526: INFO: Pod "pod-469249fb-ef06-457b-b9b2-ac542f05b411": Phase="Pending", Reason="", readiness=false. Elapsed: 2.563021ms
Dec 20 11:09:25.530: INFO: Pod "pod-469249fb-ef06-457b-b9b2-ac542f05b411": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00633554s
Dec 20 11:09:27.535: INFO: Pod "pod-469249fb-ef06-457b-b9b2-ac542f05b411": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010882876s
STEP: Saw pod success
Dec 20 11:09:27.535: INFO: Pod "pod-469249fb-ef06-457b-b9b2-ac542f05b411" satisfied condition "success or failure"
Dec 20 11:09:27.538: INFO: Trying to get logs from node caasp-worker-th-before-3 pod pod-469249fb-ef06-457b-b9b2-ac542f05b411 container test-container: <nil>
STEP: delete the pod
Dec 20 11:09:27.566: INFO: Waiting for pod pod-469249fb-ef06-457b-b9b2-ac542f05b411 to disappear
Dec 20 11:09:27.568: INFO: Pod pod-469249fb-ef06-457b-b9b2-ac542f05b411 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 11:09:27.568: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-5604" for this suite.
Dec 20 11:09:33.583: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 11:09:33.683: INFO: namespace emptydir-5604 deletion completed in 6.111240046s

• [SLOW TEST:10.300 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[sig-network] DNS 
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 11:09:33.684: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename dns
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in dns-4266
STEP: Waiting for a default service account to be provisioned in namespace
[It] should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Running these commands on wheezy: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4266.svc.cluster.local)" && echo OK > /results/wheezy_hosts@dns-querier-1.dns-test-service.dns-4266.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/wheezy_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4266.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/wheezy_tcp@PodARecord;sleep 1; done

STEP: Running these commands on jessie: for i in `seq 1 600`; do test -n "$$(getent hosts dns-querier-1.dns-test-service.dns-4266.svc.cluster.local)" && echo OK > /results/jessie_hosts@dns-querier-1.dns-test-service.dns-4266.svc.cluster.local;test -n "$$(getent hosts dns-querier-1)" && echo OK > /results/jessie_hosts@dns-querier-1;podARec=$$(hostname -i| awk -F. '{print $$1"-"$$2"-"$$3"-"$$4".dns-4266.pod.cluster.local"}');check="$$(dig +notcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_udp@PodARecord;check="$$(dig +tcp +noall +answer +search $${podARec} A)" && test -n "$$check" && echo OK > /results/jessie_tcp@PodARecord;sleep 1; done

STEP: creating a pod to probe /etc/hosts
STEP: submitting the pod to kubernetes
STEP: retrieving the pod
STEP: looking for the results for each expected name from probers
Dec 20 11:09:37.868: INFO: DNS probes using dns-4266/dns-test-ec357834-608a-47a7-9424-8065046e1cf5 succeeded

STEP: deleting the pod
[AfterEach] [sig-network] DNS
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 11:09:37.876: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "dns-4266" for this suite.
Dec 20 11:09:43.889: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 11:09:43.983: INFO: namespace dns-4266 deletion completed in 6.103160207s

• [SLOW TEST:10.300 seconds]
[sig-network] DNS
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/network/framework.go:23
  should provide /etc/hosts entries for the cluster [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSS
------------------------------
[sig-storage] Projected secret 
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 11:09:43.983: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-8392
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating secret with name projected-secret-test-80970945-5d17-44b5-af95-e52e7378c2f3
STEP: Creating a pod to test consume secrets
Dec 20 11:09:44.125: INFO: Waiting up to 5m0s for pod "pod-projected-secrets-28944131-2b02-48ca-a1e3-e0e0e81c69c9" in namespace "projected-8392" to be "success or failure"
Dec 20 11:09:44.128: INFO: Pod "pod-projected-secrets-28944131-2b02-48ca-a1e3-e0e0e81c69c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.31741ms
Dec 20 11:09:46.131: INFO: Pod "pod-projected-secrets-28944131-2b02-48ca-a1e3-e0e0e81c69c9": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005716208s
Dec 20 11:09:48.135: INFO: Pod "pod-projected-secrets-28944131-2b02-48ca-a1e3-e0e0e81c69c9": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.009818078s
STEP: Saw pod success
Dec 20 11:09:48.135: INFO: Pod "pod-projected-secrets-28944131-2b02-48ca-a1e3-e0e0e81c69c9" satisfied condition "success or failure"
Dec 20 11:09:48.138: INFO: Trying to get logs from node caasp-worker-th-before-0 pod pod-projected-secrets-28944131-2b02-48ca-a1e3-e0e0e81c69c9 container secret-volume-test: <nil>
STEP: delete the pod
Dec 20 11:09:48.168: INFO: Waiting for pod pod-projected-secrets-28944131-2b02-48ca-a1e3-e0e0e81c69c9 to disappear
Dec 20 11:09:48.170: INFO: Pod pod-projected-secrets-28944131-2b02-48ca-a1e3-e0e0e81c69c9 no longer exists
[AfterEach] [sig-storage] Projected secret
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 11:09:48.170: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-8392" for this suite.
Dec 20 11:09:54.183: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 11:09:54.278: INFO: namespace projected-8392 deletion completed in 6.104004311s

• [SLOW TEST:10.294 seconds]
[sig-storage] Projected secret
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_secret.go:35
  should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSS
------------------------------
[sig-cli] Kubectl client Update Demo 
  should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 11:09:54.278: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename kubectl
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in kubectl-927
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:225
[BeforeEach] Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:277
[It] should do a rolling update of a replication controller  [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the initial replication controller
Dec 20 11:09:54.412: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 create -f - --namespace=kubectl-927'
Dec 20 11:09:54.654: INFO: stderr: ""
Dec 20 11:09:54.654: INFO: stdout: "replicationcontroller/update-demo-nautilus created\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 20 11:09:54.654: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-927'
Dec 20 11:09:54.749: INFO: stderr: ""
Dec 20 11:09:54.749: INFO: stdout: "update-demo-nautilus-7ptxz update-demo-nautilus-tm6rx "
Dec 20 11:09:54.749: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-7ptxz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-927'
Dec 20 11:09:54.833: INFO: stderr: ""
Dec 20 11:09:54.833: INFO: stdout: ""
Dec 20 11:09:54.833: INFO: update-demo-nautilus-7ptxz is created but not running
Dec 20 11:09:59.833: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-927'
Dec 20 11:09:59.925: INFO: stderr: ""
Dec 20 11:09:59.925: INFO: stdout: "update-demo-nautilus-7ptxz update-demo-nautilus-tm6rx "
Dec 20 11:09:59.925: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-7ptxz -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-927'
Dec 20 11:10:00.020: INFO: stderr: ""
Dec 20 11:10:00.020: INFO: stdout: "true"
Dec 20 11:10:00.020: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-7ptxz -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-927'
Dec 20 11:10:00.112: INFO: stderr: ""
Dec 20 11:10:00.112: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 20 11:10:00.112: INFO: validating pod update-demo-nautilus-7ptxz
Dec 20 11:10:00.117: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 20 11:10:00.117: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 20 11:10:00.117: INFO: update-demo-nautilus-7ptxz is verified up and running
Dec 20 11:10:00.117: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-tm6rx -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-927'
Dec 20 11:10:00.203: INFO: stderr: ""
Dec 20 11:10:00.203: INFO: stdout: "true"
Dec 20 11:10:00.203: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-nautilus-tm6rx -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-927'
Dec 20 11:10:00.289: INFO: stderr: ""
Dec 20 11:10:00.289: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/nautilus:1.0"
Dec 20 11:10:00.289: INFO: validating pod update-demo-nautilus-tm6rx
Dec 20 11:10:00.294: INFO: got data: {
  "image": "nautilus.jpg"
}

Dec 20 11:10:00.294: INFO: Unmarshalled json jpg/img => {nautilus.jpg} , expecting nautilus.jpg .
Dec 20 11:10:00.294: INFO: update-demo-nautilus-tm6rx is verified up and running
STEP: rolling-update to new replication controller
Dec 20 11:10:00.296: INFO: scanned /root for discovery docs: <nil>
Dec 20 11:10:00.296: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 rolling-update update-demo-nautilus --update-period=1s -f - --namespace=kubectl-927'
Dec 20 11:10:27.700: INFO: stderr: "Command \"rolling-update\" is deprecated, use \"rollout\" instead\n"
Dec 20 11:10:27.700: INFO: stdout: "Created update-demo-kitten\nScaling up update-demo-kitten from 0 to 2, scaling down update-demo-nautilus from 2 to 0 (keep 2 pods available, don't exceed 3 pods)\nScaling update-demo-kitten up to 1\nScaling update-demo-nautilus down to 1\nScaling update-demo-kitten up to 2\nScaling update-demo-nautilus down to 0\nUpdate succeeded. Deleting old controller: update-demo-nautilus\nRenaming update-demo-kitten to update-demo-nautilus\nreplicationcontroller/update-demo-nautilus rolling updated\n"
STEP: waiting for all containers in name=update-demo pods to come up.
Dec 20 11:10:27.700: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods -o template --template={{range.items}}{{.metadata.name}} {{end}} -l name=update-demo --namespace=kubectl-927'
Dec 20 11:10:27.790: INFO: stderr: ""
Dec 20 11:10:27.790: INFO: stdout: "update-demo-kitten-2c5m5 update-demo-kitten-zlcdr "
Dec 20 11:10:27.790: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-kitten-2c5m5 -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-927'
Dec 20 11:10:27.881: INFO: stderr: ""
Dec 20 11:10:27.881: INFO: stdout: "true"
Dec 20 11:10:27.881: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-kitten-2c5m5 -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-927'
Dec 20 11:10:27.965: INFO: stderr: ""
Dec 20 11:10:27.966: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 20 11:10:27.966: INFO: validating pod update-demo-kitten-2c5m5
Dec 20 11:10:27.972: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 20 11:10:27.972: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 20 11:10:27.972: INFO: update-demo-kitten-2c5m5 is verified up and running
Dec 20 11:10:27.972: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-kitten-zlcdr -o template --template={{if (exists . "status" "containerStatuses")}}{{range .status.containerStatuses}}{{if (and (eq .name "update-demo") (exists . "state" "running"))}}true{{end}}{{end}}{{end}} --namespace=kubectl-927'
Dec 20 11:10:28.060: INFO: stderr: ""
Dec 20 11:10:28.060: INFO: stdout: "true"
Dec 20 11:10:28.060: INFO: Running '/usr/local/bin/kubectl --kubeconfig=/tmp/kubeconfig-816092167 get pods update-demo-kitten-zlcdr -o template --template={{if (exists . "spec" "containers")}}{{range .spec.containers}}{{if eq .name "update-demo"}}{{.image}}{{end}}{{end}}{{end}} --namespace=kubectl-927'
Dec 20 11:10:28.156: INFO: stderr: ""
Dec 20 11:10:28.157: INFO: stdout: "gcr.io/kubernetes-e2e-test-images/kitten:1.0"
Dec 20 11:10:28.157: INFO: validating pod update-demo-kitten-zlcdr
Dec 20 11:10:28.161: INFO: got data: {
  "image": "kitten.jpg"
}

Dec 20 11:10:28.161: INFO: Unmarshalled json jpg/img => {kitten.jpg} , expecting kitten.jpg .
Dec 20 11:10:28.161: INFO: update-demo-kitten-zlcdr is verified up and running
[AfterEach] [sig-cli] Kubectl client
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 11:10:28.161: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "kubectl-927" for this suite.
Dec 20 11:10:56.177: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 11:10:56.275: INFO: namespace kubectl-927 deletion completed in 28.109019478s

• [SLOW TEST:61.997 seconds]
[sig-cli] Kubectl client
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/framework.go:23
  Update Demo
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/kubectl/kubectl.go:275
    should do a rolling update of a replication controller  [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSS
------------------------------
[sig-storage] Subpath Atomic writer volumes 
  should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 11:10:56.275: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename subpath
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in subpath-7425
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:37
STEP: Setting up data
[It] should support subpaths with projected pod [LinuxOnly] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating pod pod-subpath-test-projected-vwnp
STEP: Creating a pod to test atomic-volume-subpath
Dec 20 11:10:56.419: INFO: Waiting up to 5m0s for pod "pod-subpath-test-projected-vwnp" in namespace "subpath-7425" to be "success or failure"
Dec 20 11:10:56.421: INFO: Pod "pod-subpath-test-projected-vwnp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.333635ms
Dec 20 11:10:58.425: INFO: Pod "pod-subpath-test-projected-vwnp": Phase="Pending", Reason="", readiness=false. Elapsed: 2.00616257s
Dec 20 11:11:00.430: INFO: Pod "pod-subpath-test-projected-vwnp": Phase="Running", Reason="", readiness=true. Elapsed: 4.010958565s
Dec 20 11:11:02.434: INFO: Pod "pod-subpath-test-projected-vwnp": Phase="Running", Reason="", readiness=true. Elapsed: 6.014963134s
Dec 20 11:11:04.437: INFO: Pod "pod-subpath-test-projected-vwnp": Phase="Running", Reason="", readiness=true. Elapsed: 8.018516725s
Dec 20 11:11:06.442: INFO: Pod "pod-subpath-test-projected-vwnp": Phase="Running", Reason="", readiness=true. Elapsed: 10.022815419s
Dec 20 11:11:08.446: INFO: Pod "pod-subpath-test-projected-vwnp": Phase="Running", Reason="", readiness=true. Elapsed: 12.027211956s
Dec 20 11:11:10.451: INFO: Pod "pod-subpath-test-projected-vwnp": Phase="Running", Reason="", readiness=true. Elapsed: 14.032301494s
Dec 20 11:11:12.455: INFO: Pod "pod-subpath-test-projected-vwnp": Phase="Running", Reason="", readiness=true. Elapsed: 16.03584357s
Dec 20 11:11:14.458: INFO: Pod "pod-subpath-test-projected-vwnp": Phase="Running", Reason="", readiness=true. Elapsed: 18.039566411s
Dec 20 11:11:16.462: INFO: Pod "pod-subpath-test-projected-vwnp": Phase="Running", Reason="", readiness=true. Elapsed: 20.043570127s
Dec 20 11:11:18.466: INFO: Pod "pod-subpath-test-projected-vwnp": Phase="Running", Reason="", readiness=true. Elapsed: 22.047240804s
Dec 20 11:11:20.473: INFO: Pod "pod-subpath-test-projected-vwnp": Phase="Succeeded", Reason="", readiness=false. Elapsed: 24.054003741s
STEP: Saw pod success
Dec 20 11:11:20.473: INFO: Pod "pod-subpath-test-projected-vwnp" satisfied condition "success or failure"
Dec 20 11:11:20.477: INFO: Trying to get logs from node caasp-worker-th-before-4 pod pod-subpath-test-projected-vwnp container test-container-subpath-projected-vwnp: <nil>
STEP: delete the pod
Dec 20 11:11:20.509: INFO: Waiting for pod pod-subpath-test-projected-vwnp to disappear
Dec 20 11:11:20.512: INFO: Pod pod-subpath-test-projected-vwnp no longer exists
STEP: Deleting pod pod-subpath-test-projected-vwnp
Dec 20 11:11:20.512: INFO: Deleting pod "pod-subpath-test-projected-vwnp" in namespace "subpath-7425"
[AfterEach] [sig-storage] Subpath
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 11:11:20.514: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "subpath-7425" for this suite.
Dec 20 11:11:26.528: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 11:11:26.628: INFO: namespace subpath-7425 deletion completed in 6.110697385s

• [SLOW TEST:30.353 seconds]
[sig-storage] Subpath
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/utils/framework.go:23
  Atomic writer volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/storage/subpath.go:33
    should support subpaths with projected pod [LinuxOnly] [Conformance]
    /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Pods 
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 11:11:26.628: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename pods
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in pods-3196
STEP: Waiting for a default service account to be provisioned in namespace
[BeforeEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/pods.go:165
[It] should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: creating the pod
STEP: submitting the pod to kubernetes
STEP: verifying the pod is in kubernetes
STEP: updating the pod
Dec 20 11:11:31.288: INFO: Successfully updated pod "pod-update-1ec40dd5-8aee-491b-a6e4-fdcfede26c1d"
STEP: verifying the updated pod is in kubernetes
Dec 20 11:11:31.293: INFO: Pod update OK
[AfterEach] [k8s.io] Pods
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 11:11:31.293: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "pods-3196" for this suite.
Dec 20 11:11:43.307: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 11:11:43.402: INFO: namespace pods-3196 deletion completed in 12.105330055s

• [SLOW TEST:16.774 seconds]
[k8s.io] Pods
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should be updated [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSS
------------------------------
[sig-storage] EmptyDir volumes 
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 11:11:43.403: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename emptydir
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in emptydir-640
STEP: Waiting for a default service account to be provisioned in namespace
[It] should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test emptydir 0666 on tmpfs
Dec 20 11:11:43.542: INFO: Waiting up to 5m0s for pod "pod-8d4b8533-a5e5-47d4-8838-9d409f7fd871" in namespace "emptydir-640" to be "success or failure"
Dec 20 11:11:43.545: INFO: Pod "pod-8d4b8533-a5e5-47d4-8838-9d409f7fd871": Phase="Pending", Reason="", readiness=false. Elapsed: 2.403758ms
Dec 20 11:11:45.548: INFO: Pod "pod-8d4b8533-a5e5-47d4-8838-9d409f7fd871": Phase="Pending", Reason="", readiness=false. Elapsed: 2.006094565s
Dec 20 11:11:47.552: INFO: Pod "pod-8d4b8533-a5e5-47d4-8838-9d409f7fd871": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.010085282s
STEP: Saw pod success
Dec 20 11:11:47.552: INFO: Pod "pod-8d4b8533-a5e5-47d4-8838-9d409f7fd871" satisfied condition "success or failure"
Dec 20 11:11:47.556: INFO: Trying to get logs from node caasp-worker-th-before-3 pod pod-8d4b8533-a5e5-47d4-8838-9d409f7fd871 container test-container: <nil>
STEP: delete the pod
Dec 20 11:11:47.582: INFO: Waiting for pod pod-8d4b8533-a5e5-47d4-8838-9d409f7fd871 to disappear
Dec 20 11:11:47.584: INFO: Pod pod-8d4b8533-a5e5-47d4-8838-9d409f7fd871 no longer exists
[AfterEach] [sig-storage] EmptyDir volumes
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 11:11:47.584: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "emptydir-640" for this suite.
Dec 20 11:11:53.600: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 11:11:53.689: INFO: namespace emptydir-640 deletion completed in 6.101866594s

• [SLOW TEST:10.286 seconds]
[sig-storage] EmptyDir volumes
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/empty_dir.go:41
  should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] Garbage collector 
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 11:11:53.689: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename gc
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in gc-4347
STEP: Waiting for a default service account to be provisioned in namespace
[It] should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: create the rc
STEP: delete the rc
STEP: wait for the rc to be deleted
STEP: Gathering metrics
Dec 20 11:11:59.852: INFO: For apiserver_request_total:
For apiserver_request_latencies_summary:
For apiserver_init_events_total:
For garbage_collector_attempt_to_delete_queue_latency:
For garbage_collector_attempt_to_delete_work_duration:
For garbage_collector_attempt_to_orphan_queue_latency:
For garbage_collector_attempt_to_orphan_work_duration:
For garbage_collector_dirty_processing_latency_microseconds:
For garbage_collector_event_processing_latency_microseconds:
For garbage_collector_graph_changes_queue_latency:
For garbage_collector_graph_changes_work_duration:
For garbage_collector_orphan_processing_latency_microseconds:
For namespace_queue_latency:
For namespace_queue_latency_sum:
For namespace_queue_latency_count:
For namespace_retries:
For namespace_work_duration:
For namespace_work_duration_sum:
For namespace_work_duration_count:
For function_duration_seconds:
For errors_total:
For evicted_pods_total:

[AfterEach] [sig-api-machinery] Garbage collector
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
W1220 11:11:59.852740      26 metrics_grabber.go:79] Master node is not registered. Grabbing metrics from Scheduler, ControllerManager and ClusterAutoscaler is disabled.
Dec 20 11:11:59.852: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "gc-4347" for this suite.
Dec 20 11:12:05.871: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 11:12:05.962: INFO: namespace gc-4347 deletion completed in 6.105532859s

• [SLOW TEST:12.273 seconds]
[sig-api-machinery] Garbage collector
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should keep the rc around until all its pods are deleted if the deleteOptions says so [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSS
------------------------------
[sig-storage] Projected configMap 
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 11:12:05.963: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename projected
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in projected-6066
STEP: Waiting for a default service account to be provisioned in namespace
[It] updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating projection with configMap that has name projected-configmap-test-upd-6bd6f099-b364-42ef-af15-4f722eefa5a9
STEP: Creating the pod
STEP: Updating configmap projected-configmap-test-upd-6bd6f099-b364-42ef-af15-4f722eefa5a9
STEP: waiting to observe update in volume
[AfterEach] [sig-storage] Projected configMap
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 11:13:34.500: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "projected-6066" for this suite.
Dec 20 11:13:46.515: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 11:13:46.612: INFO: namespace projected-6066 deletion completed in 12.108048835s

• [SLOW TEST:100.650 seconds]
[sig-storage] Projected configMap
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/common/projected_configmap.go:35
  updates should be reflected in volume [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSS
------------------------------
[k8s.io] Variable Expansion 
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 11:13:46.612: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename var-expansion
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in var-expansion-8216
STEP: Waiting for a default service account to be provisioned in namespace
[It] should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a pod to test substitution in container's command
Dec 20 11:13:46.751: INFO: Waiting up to 5m0s for pod "var-expansion-5a11505f-06d4-4b09-942b-8952d9dc9850" in namespace "var-expansion-8216" to be "success or failure"
Dec 20 11:13:46.753: INFO: Pod "var-expansion-5a11505f-06d4-4b09-942b-8952d9dc9850": Phase="Pending", Reason="", readiness=false. Elapsed: 2.069636ms
Dec 20 11:13:48.757: INFO: Pod "var-expansion-5a11505f-06d4-4b09-942b-8952d9dc9850": Phase="Pending", Reason="", readiness=false. Elapsed: 2.005748826s
Dec 20 11:13:50.760: INFO: Pod "var-expansion-5a11505f-06d4-4b09-942b-8952d9dc9850": Phase="Succeeded", Reason="", readiness=false. Elapsed: 4.008949232s
STEP: Saw pod success
Dec 20 11:13:50.760: INFO: Pod "var-expansion-5a11505f-06d4-4b09-942b-8952d9dc9850" satisfied condition "success or failure"
Dec 20 11:13:50.762: INFO: Trying to get logs from node caasp-worker-th-before-4 pod var-expansion-5a11505f-06d4-4b09-942b-8952d9dc9850 container dapi-container: <nil>
STEP: delete the pod
Dec 20 11:13:50.792: INFO: Waiting for pod var-expansion-5a11505f-06d4-4b09-942b-8952d9dc9850 to disappear
Dec 20 11:13:50.794: INFO: Pod var-expansion-5a11505f-06d4-4b09-942b-8952d9dc9850 no longer exists
[AfterEach] [k8s.io] Variable Expansion
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 11:13:50.794: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "var-expansion-8216" for this suite.
Dec 20 11:13:56.809: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 11:13:56.905: INFO: namespace var-expansion-8216 deletion completed in 6.106927321s

• [SLOW TEST:10.292 seconds]
[k8s.io] Variable Expansion
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:693
  should allow substituting values in a container's command [NodeConformance] [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSSS
------------------------------
[sig-api-machinery] ResourceQuota 
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
[BeforeEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:151
STEP: Creating a kubernetes client
Dec 20 11:13:56.905: INFO: >>> kubeConfig: /tmp/kubeconfig-816092167
STEP: Building a namespace api object, basename resourcequota
STEP: Binding the e2e-test-privileged-psp PodSecurityPolicy to the default service account in resourcequota-6954
STEP: Waiting for a default service account to be provisioned in namespace
[It] should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
STEP: Creating a ResourceQuota
STEP: Getting a ResourceQuota
STEP: Updating a ResourceQuota
STEP: Verifying a ResourceQuota was modified
STEP: Deleting a ResourceQuota
STEP: Verifying the deleted ResourceQuota
[AfterEach] [sig-api-machinery] ResourceQuota
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:152
Dec 20 11:13:57.056: INFO: Waiting up to 3m0s for all (but 0) nodes to be ready
STEP: Destroying namespace "resourcequota-6954" for this suite.
Dec 20 11:14:03.069: INFO: Waiting up to 30s for server preferred namespaced resources to be successfully discovered
Dec 20 11:14:03.165: INFO: namespace resourcequota-6954 deletion completed in 6.106195981s

• [SLOW TEST:6.260 seconds]
[sig-api-machinery] ResourceQuota
/workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/apimachinery/framework.go:23
  should be able to update and delete ResourceQuota. [Conformance]
  /workspace/anago-v1.16.2-beta.0.19+c97fe5036ef3df/src/k8s.io/kubernetes/_output/dockerized/go/src/k8s.io/kubernetes/test/e2e/framework/framework.go:698
------------------------------
SSSSSSSSSSSSSSSSSSSSSSSSSSSDec 20 11:14:03.166: INFO: Running AfterSuite actions on all nodes
Dec 20 11:14:03.166: INFO: Running AfterSuite actions on node 1
Dec 20 11:14:03.166: INFO: Skipping dumping logs from cluster

Ran 274 of 4897 Specs in 7641.612 seconds
SUCCESS! -- 274 Passed | 0 Failed | 0 Pending | 4623 Skipped
PASS

Ginkgo ran 1 suite in 2h7m23.995759145s
Test Suite Passed
